record_number,buggy_code,fixed_code,code_similarity
55001,"/** 
 * Uses webdav put to delete url
 */
public void delete(String url) throws SardineException ;","/** 
 * Delete a resource at the specified url
 */
public void delete(String url) throws SardineException ;",0.7609756097560976
55002,"public List<DavResource> getResources(String url) throws SardineException {
  HttpPropFind propFind=new HttpPropFind(url);
  propFind.setEntity(SardineUtil.getResourcesEntity());
  HttpResponse response=this.executeWrapper(propFind);
  StatusLine statusLine=response.getStatusLine();
  if (!SardineUtil.isGoodResponse(statusLine.getStatusCode()))   throw new SardineException(""String_Node_Str"",url,statusLine.getStatusCode(),statusLine.getReasonPhrase());
  Multistatus multistatus=null;
  try {
    multistatus=(Multistatus)this.factory.getUnmarshaller().unmarshal(response.getEntity().getContent());
  }
 catch (  JAXBException ex) {
    throw new SardineException(""String_Node_Str"",url,ex);
  }
catch (  IOException ex) {
    throw new SardineException(ex);
  }
  List<Response> responses=multistatus.getResponse();
  List<DavResource> resources=new ArrayList<DavResource>(responses.size());
  String path=responses.get(0).getHref().get(0);
  for (  Response resp : responses) {
    String href=resp.getHref().get(0);
    if (href.equals(path))     continue;
    String name=href.substring(path.length(),href.length());
    if (name.equals(""String_Node_Str""))     continue;
    if (name.endsWith(""String_Node_Str""))     name=name.substring(0,name.length() - 1);
    String creationdate=resp.getPropstat().get(0).getProp().getCreationdate().getContent().get(0);
    String modifieddate=resp.getPropstat().get(0).getProp().getGetlastmodified().getContent().get(0);
    String contentType=""String_Node_Str"";
    Getcontenttype gtt=resp.getPropstat().get(0).getProp().getGetcontenttype();
    if (gtt != null)     contentType=gtt.getContent().get(0);
    String contentLength=""String_Node_Str"";
    Getcontentlength gcl=resp.getPropstat().get(0).getProp().getGetcontentlength();
    if (gcl != null)     contentLength=gcl.getContent().get(0);
    DavResource dr=new DavResource(url,name,SardineUtil.parseDate(creationdate),SardineUtil.parseDate(modifieddate),contentType,Long.valueOf(contentLength));
    resources.add(dr);
  }
  return resources;
}","public List<DavResource> getResources(String url) throws SardineException {
  HttpPropFind propFind=new HttpPropFind(url);
  propFind.setEntity(SardineUtil.getResourcesEntity());
  HttpResponse response=this.executeWrapper(propFind);
  StatusLine statusLine=response.getStatusLine();
  if (!SardineUtil.isGoodResponse(statusLine.getStatusCode()))   throw new SardineException(""String_Node_Str"",url,statusLine.getStatusCode(),statusLine.getReasonPhrase());
  Multistatus multistatus=SardineUtil.getMulitstatus(this.factory.getUnmarshaller(),response,url);
  List<Response> responses=multistatus.getResponse();
  List<DavResource> resources=new ArrayList<DavResource>(responses.size());
  String path=responses.get(0).getHref().get(0);
  for (  Response resp : responses) {
    String href=resp.getHref().get(0);
    if (href.equals(path))     continue;
    String name=href.substring(path.length(),href.length());
    if (name.equals(""String_Node_Str""))     continue;
    if (name.endsWith(""String_Node_Str""))     name=name.substring(0,name.length() - 1);
    String creationdate=resp.getPropstat().get(0).getProp().getCreationdate().getContent().get(0);
    String modifieddate=resp.getPropstat().get(0).getProp().getGetlastmodified().getContent().get(0);
    String contentType=""String_Node_Str"";
    Getcontenttype gtt=resp.getPropstat().get(0).getProp().getGetcontenttype();
    if (gtt != null)     contentType=gtt.getContent().get(0);
    String contentLength=""String_Node_Str"";
    Getcontentlength gcl=resp.getPropstat().get(0).getProp().getGetcontentlength();
    if (gcl != null)     contentLength=gcl.getContent().get(0);
    DavResource dr=new DavResource(url,name,SardineUtil.parseDate(creationdate),SardineUtil.parseDate(modifieddate),contentType,Long.valueOf(contentLength));
    resources.add(dr);
  }
  return resources;
}",0.3268142048378795
55003,"/** 
 */
public SardineImpl(Factory factory,String username,String password){
  this.factory=factory;
  HttpParams params=new BasicHttpParams();
  ConnManagerParams.setMaxTotalConnections(params,100);
  HttpProtocolParams.setVersion(params,HttpVersion.HTTP_1_1);
  SchemeRegistry schemeRegistry=new SchemeRegistry();
  schemeRegistry.register(new Scheme(""String_Node_Str"",PlainSocketFactory.getSocketFactory(),80));
  ClientConnectionManager cm=new ThreadSafeClientConnManager(params,schemeRegistry);
  this.client=new DefaultHttpClient(cm,params);
  if (username != null && password != null)   this.client.getCredentialsProvider().setCredentials(new AuthScope(AuthScope.ANY_HOST,AuthScope.ANY_PORT),new UsernamePasswordCredentials(username,password));
}","/** 
 */
public SardineImpl(Factory factory,String username,String password){
  this.factory=factory;
  HttpParams params=new BasicHttpParams();
  ConnManagerParams.setMaxTotalConnections(params,100);
  HttpProtocolParams.setVersion(params,HttpVersion.HTTP_1_1);
  SchemeRegistry schemeRegistry=new SchemeRegistry();
  schemeRegistry.register(new Scheme(""String_Node_Str"",PlainSocketFactory.getSocketFactory(),80));
  ClientConnectionManager cm=new ThreadSafeClientConnManager(params,schemeRegistry);
  this.client=new DefaultHttpClient(cm,params);
  if ((username != null) && (password != null))   this.client.getCredentialsProvider().setCredentials(new AuthScope(AuthScope.ANY_HOST,AuthScope.ANY_PORT),new UsernamePasswordCredentials(username,password));
}",0.9973544973544972
55004,"public HttpMove(String sourceUrl,String destinationUrl){
  super(sourceUrl);
  this.setHeader(""String_Node_Str"",destinationUrl);
}","public HttpMove(String sourceUrl,String destinationUrl) throws SardineException {
  super();
  this.setHeader(""String_Node_Str"",destinationUrl);
  this.setURI(URI.create(sourceUrl));
  if (sourceUrl.endsWith(""String_Node_Str"") && !destinationUrl.endsWith(""String_Node_Str""))   throw new SardineException(""String_Node_Str"",destinationUrl);
}",0.5148936170212766
55005,"/** 
 * Is the status code 2xx
 */
public static boolean isGoodResponse(int statusCode){
  return (statusCode >= 200 && statusCode <= 299);
}","/** 
 * Is the status code 2xx
 */
public static boolean isGoodResponse(int statusCode){
  return ((statusCode >= 200) && (statusCode <= 299));
}",0.986013986013986
55006,"public List<DavResource> getResources(String url) throws SardineException {
  HttpPropFind propFind=new HttpPropFind(url);
  propFind.setEntity(SardineUtil.getResourcesEntity());
  HttpResponse response=this.executeWrapper(propFind);
  StatusLine statusLine=response.getStatusLine();
  if (!SardineUtil.isGoodResponse(statusLine.getStatusCode()))   throw new SardineException(""String_Node_Str"",url,statusLine.getStatusCode(),statusLine.getReasonPhrase());
  Multistatus multistatus=SardineUtil.getMulitstatus(this.factory.getUnmarshaller(),response,url);
  List<Response> responses=multistatus.getResponse();
  List<DavResource> resources=new ArrayList<DavResource>(responses.size());
  String path=responses.get(0).getHref().get(0);
  for (  Response resp : responses) {
    String href=resp.getHref().get(0);
    if (href.equals(path))     continue;
    String name=href.substring(path.length(),href.length());
    if (name.equals(""String_Node_Str""))     continue;
    if (name.endsWith(""String_Node_Str""))     name=name.substring(0,name.length() - 1);
    String creationdate=resp.getPropstat().get(0).getProp().getCreationdate().getContent().get(0);
    String modifieddate=resp.getPropstat().get(0).getProp().getGetlastmodified().getContent().get(0);
    String contentType=""String_Node_Str"";
    Getcontenttype gtt=resp.getPropstat().get(0).getProp().getGetcontenttype();
    if (gtt != null)     contentType=gtt.getContent().get(0);
    String contentLength=""String_Node_Str"";
    Getcontentlength gcl=resp.getPropstat().get(0).getProp().getGetcontentlength();
    if (gcl != null)     contentLength=gcl.getContent().get(0);
    DavResource dr=new DavResource(url,name,SardineUtil.parseDate(creationdate),SardineUtil.parseDate(modifieddate),contentType,Long.valueOf(contentLength));
    resources.add(dr);
  }
  return resources;
}","public List<DavResource> getResources(String url) throws SardineException {
  HttpPropFind propFind=new HttpPropFind(url);
  propFind.setEntity(SardineUtil.getResourcesEntity());
  HttpResponse response=this.executeWrapper(propFind);
  StatusLine statusLine=response.getStatusLine();
  if (!SardineUtil.isGoodResponse(statusLine.getStatusCode()))   throw new SardineException(""String_Node_Str"",url,statusLine.getStatusCode(),statusLine.getReasonPhrase());
  Multistatus multistatus=SardineUtil.getMulitstatus(this.factory.getUnmarshaller(),response,url);
  List<Response> responses=multistatus.getResponse();
  List<DavResource> resources=new ArrayList<DavResource>(responses.size());
  String path=responses.get(0).getHref().get(0);
  for (  Response resp : responses) {
    String href=resp.getHref().get(0);
    if (href.equals(path))     continue;
    String name=href.substring(path.length(),href.length());
    if (name.equals(""String_Node_Str""))     continue;
    if (name.endsWith(""String_Node_Str""))     name=name.substring(0,name.length() - 1);
    Prop prop=resp.getPropstat().get(0).getProp();
    String creationdate=prop.getCreationdate().getContent().get(0);
    String modifieddate;
    Getlastmodified glm=prop.getGetlastmodified();
    if (glm != null)     modifieddate=glm.getContent().get(0);
 else     modifieddate=creationdate;
    String contentType=""String_Node_Str"";
    Getcontenttype gtt=prop.getGetcontenttype();
    if (gtt != null)     contentType=gtt.getContent().get(0);
    String contentLength=""String_Node_Str"";
    Getcontentlength gcl=prop.getGetcontentlength();
    if (gcl != null)     contentLength=gcl.getContent().get(0);
    DavResource dr=new DavResource(url,name,SardineUtil.parseDate(creationdate),SardineUtil.parseDate(modifieddate),contentType,Long.valueOf(contentLength));
    resources.add(dr);
  }
  return resources;
}",0.906688241639698
55007,"public HttpPropFind(String url){
  super(url);
  this.setDepth(1);
}","public HttpPropFind(String url){
  super();
  this.setDepth(1);
  this.setURI(URI.create(url));
}",0.7878787878787878
55008,"/** 
 * Is the status code < 200 || > 299
 */
public static boolean isGoodResponse(int statusCode){
  return (statusCode < 200 || statusCode > 299);
}","/** 
 * Is the status code 2xx
 */
public static boolean isGoodResponse(int statusCode){
  return (statusCode >= 200 && statusCode <= 299);
}",0.9140893470790378
55009,"/** 
 * Uses webdav put to send data to a server
 */
public void put(String url,byte[] data) throws SardineException ;","/** 
 * Uses webdav put to send data to a server
 */
public void put(String url,InputStream dataStream) throws SardineException ;",0.9230769230769232
55010,"public void put(String url,byte[] data) throws SardineException {
  HttpPut put=new HttpPut(url);
  ByteArrayEntity entity=new ByteArrayEntity(data);
  put.setEntity(entity);
  HttpResponse response=this.executeWrapper(put);
  StatusLine statusLine=response.getStatusLine();
  if (!SardineUtil.isGoodResponse(statusLine.getStatusCode()))   throw new SardineException(url,statusLine.getStatusCode(),statusLine.getReasonPhrase());
}","public void put(String url,InputStream dataStream) throws SardineException {
  HttpPut put=new HttpPut(url);
  InputStreamEntity entity=new InputStreamEntity(dataStream,-1);
  put.setEntity(entity);
  HttpResponse response=this.executeWrapper(put);
  StatusLine statusLine=response.getStatusLine();
  if (!SardineUtil.isGoodResponse(statusLine.getStatusCode()))   throw new SardineException(url,statusLine.getStatusCode(),statusLine.getReasonPhrase());
}",0.8846153846153846
55011,"public List<DavResource> getResources(String url) throws IOException {
  HttpPropFind propFind=new HttpPropFind(url);
  propFind.setEntity(SardineUtil.getResourcesEntity());
  HttpResponse response=this.client.execute(propFind);
  int statusCode=response.getStatusLine().getStatusCode();
  if (!SardineUtil.isGoodResponse(statusCode))   throw new IOException(""String_Node_Str"" + statusCode + ""String_Node_Str""+ url);
  Multistatus r=null;
  try {
    r=(Multistatus)this.factory.getUnmarshaller().unmarshal(response.getEntity().getContent());
  }
 catch (  JAXBException ex) {
    throw new IOException(""String_Node_Str"" + url,ex);
  }
  List<Response> responses=r.getResponse();
  List<DavResource> resources=new ArrayList<DavResource>(responses.size());
  String path=responses.get(0).getHref().get(0);
  for (  Response resp : responses) {
    String href=resp.getHref().get(0);
    if (href.equals(path))     continue;
    String name=href.substring(path.length(),href.length());
    if (name.equals(""String_Node_Str""))     continue;
    if (name.endsWith(""String_Node_Str""))     name=name.substring(0,name.length() - 1);
    String creationdate=resp.getPropstat().get(0).getProp().getCreationdate().getContent().get(0);
    String modifieddate=resp.getPropstat().get(0).getProp().getGetlastmodified().getContent().get(0);
    String contentType=""String_Node_Str"";
    Getcontenttype gtt=resp.getPropstat().get(0).getProp().getGetcontenttype();
    if (gtt != null)     contentType=gtt.getContent().get(0);
    String contentLength=""String_Node_Str"";
    Getcontentlength gcl=resp.getPropstat().get(0).getProp().getGetcontentlength();
    if (gcl != null)     contentLength=gcl.getContent().get(0);
    DavResource dr=new DavResource(url,name,SardineUtil.parseDate(creationdate),SardineUtil.parseDate(modifieddate),contentType,Long.valueOf(contentLength));
    resources.add(dr);
  }
  return resources;
}","public List<DavResource> getResources(String url) throws IOException {
  HttpPropFind propFind=new HttpPropFind(url);
  propFind.setEntity(SardineUtil.getResourcesEntity());
  HttpResponse response=this.client.execute(propFind);
  int statusCode=response.getStatusLine().getStatusCode();
  if (!SardineUtil.isGoodResponse(statusCode))   throw new IOException(""String_Node_Str"" + statusCode + ""String_Node_Str""+ url);
  Multistatus r=null;
  try {
    r=(Multistatus)this.factory.getUnmarshaller().unmarshal(response.getEntity().getContent());
  }
 catch (  JAXBException ex) {
    IOException exception=new IOException(""String_Node_Str"" + url);
    exception.initCause(ex);
    throw exception;
  }
  List<Response> responses=r.getResponse();
  List<DavResource> resources=new ArrayList<DavResource>(responses.size());
  String path=responses.get(0).getHref().get(0);
  for (  Response resp : responses) {
    String href=resp.getHref().get(0);
    if (href.equals(path))     continue;
    String name=href.substring(path.length(),href.length());
    if (name.equals(""String_Node_Str""))     continue;
    if (name.endsWith(""String_Node_Str""))     name=name.substring(0,name.length() - 1);
    String creationdate=resp.getPropstat().get(0).getProp().getCreationdate().getContent().get(0);
    String modifieddate=resp.getPropstat().get(0).getProp().getGetlastmodified().getContent().get(0);
    String contentType=""String_Node_Str"";
    Getcontenttype gtt=resp.getPropstat().get(0).getProp().getGetcontenttype();
    if (gtt != null)     contentType=gtt.getContent().get(0);
    String contentLength=""String_Node_Str"";
    Getcontentlength gcl=resp.getPropstat().get(0).getProp().getGetcontentlength();
    if (gcl != null)     contentLength=gcl.getContent().get(0);
    DavResource dr=new DavResource(url,name,SardineUtil.parseDate(creationdate),SardineUtil.parseDate(modifieddate),contentType,Long.valueOf(contentLength));
    resources.add(dr);
  }
  return resources;
}",0.9775830971399124
55012,"public List<DavResource> getResources(String url) throws IOException {
  URL urlObj=new URL(url);
  String path=urlObj.getPath();
  HttpPropFind pf=new HttpPropFind(url);
  HttpResponse response=this.client.execute(pf);
  int statusCode=response.getStatusLine().getStatusCode();
  if (!SardineUtil.isGoodResponse(statusCode))   throw new IOException(""String_Node_Str"" + statusCode + ""String_Node_Str""+ url);
  Multistatus r=null;
  try {
    r=(Multistatus)this.factory.getUnmarshaller().unmarshal(response.getEntity().getContent());
  }
 catch (  JAXBException ex) {
    throw new IOException(""String_Node_Str"" + url,ex);
  }
  List<Response> responses=r.getResponse();
  List<DavResource> resources=new ArrayList<DavResource>(responses.size());
  for (  Response resp : responses) {
    String href=resp.getHref().get(0);
    if (href.equals(path))     continue;
    String name=href.substring(path.length(),href.length());
    if (name.equals(""String_Node_Str""))     continue;
    if (name.endsWith(""String_Node_Str""))     name=name.substring(0,name.length() - 1);
    String creationdate=resp.getPropstat().get(0).getProp().getCreationdate().getContent().get(0);
    String modifieddate=resp.getPropstat().get(0).getProp().getGetlastmodified().getContent().get(0);
    String contentType=""String_Node_Str"";
    Getcontenttype gtt=resp.getPropstat().get(0).getProp().getGetcontenttype();
    if (gtt != null)     contentType=gtt.getContent().get(0);
    String contentLength=""String_Node_Str"";
    Getcontentlength gcl=resp.getPropstat().get(0).getProp().getGetcontentlength();
    if (gcl != null)     contentLength=gcl.getContent().get(0);
    DavResource dr=new DavResource(url,name,SardineUtil.parseDate(creationdate),SardineUtil.parseDate(modifieddate),contentType,Long.valueOf(contentLength));
    resources.add(dr);
  }
  return resources;
}","public List<DavResource> getResources(String url) throws IOException {
  HttpPropFind propFind=new HttpPropFind(url);
  propFind.setEntity(SardineUtil.getResourcesEntity());
  HttpResponse response=this.client.execute(propFind);
  int statusCode=response.getStatusLine().getStatusCode();
  if (!SardineUtil.isGoodResponse(statusCode))   throw new IOException(""String_Node_Str"" + statusCode + ""String_Node_Str""+ url);
  Multistatus r=null;
  try {
    r=(Multistatus)this.factory.getUnmarshaller().unmarshal(response.getEntity().getContent());
  }
 catch (  JAXBException ex) {
    throw new IOException(""String_Node_Str"" + url,ex);
  }
  List<Response> responses=r.getResponse();
  List<DavResource> resources=new ArrayList<DavResource>(responses.size());
  String path=responses.get(0).getHref().get(0);
  for (  Response resp : responses) {
    String href=resp.getHref().get(0);
    if (href.equals(path))     continue;
    String name=href.substring(path.length(),href.length());
    if (name.equals(""String_Node_Str""))     continue;
    if (name.endsWith(""String_Node_Str""))     name=name.substring(0,name.length() - 1);
    String creationdate=resp.getPropstat().get(0).getProp().getCreationdate().getContent().get(0);
    String modifieddate=resp.getPropstat().get(0).getProp().getGetlastmodified().getContent().get(0);
    String contentType=""String_Node_Str"";
    Getcontenttype gtt=resp.getPropstat().get(0).getProp().getGetcontenttype();
    if (gtt != null)     contentType=gtt.getContent().get(0);
    String contentLength=""String_Node_Str"";
    Getcontentlength gcl=resp.getPropstat().get(0).getProp().getGetcontentlength();
    if (gcl != null)     contentLength=gcl.getContent().get(0);
    DavResource dr=new DavResource(url,name,SardineUtil.parseDate(creationdate),SardineUtil.parseDate(modifieddate),contentType,Long.valueOf(contentLength));
    resources.add(dr);
  }
  return resources;
}",0.9132978723404256
55013,"public InputStream getInputStream(String url) throws IOException {
  HttpGet get=new HttpGet(url);
  HttpResponse response=this.client.execute(get);
  int statusCode=response.getStatusLine().getStatusCode();
  if (!SardineUtil.isGoodResponse(statusCode))   throw new IOException(""String_Node_Str"" + statusCode + ""String_Node_Str""+ url);
  return response.getEntity().getContent();
}","public InputStream getInputStream(String url) throws IOException {
  HttpGet get=new HttpGet(url);
  HttpResponse response=this.client.execute(get);
  StatusLine statusLine=response.getStatusLine();
  if (!SardineUtil.isGoodResponse(statusLine.getStatusCode()))   throw new IOException(""String_Node_Str"" + statusLine.getStatusCode() + ""String_Node_Str""+ statusLine.getReasonPhrase()+ ""String_Node_Str""+ url);
  return response.getEntity().getContent();
}",0.69377990430622
55014,"/** 
 * Uses webdav put to move a url to another
 */
public void move(String sourceUrl,String destinationUrl) throws IOException ;","/** 
 * Uses webdav put to move a url to another
 */
public void move(String sourceUrl,String destinationUrl) throws SardineException ;",0.9660377358490566
55015,"/** 
 * Gets a directory listing.
 */
public List<DavResource> getResources(String url) throws IOException ;","/** 
 * Gets a directory listing.
 */
public List<DavResource> getResources(String url) throws SardineException ;",0.9592760180995475
55016,"/** 
 * Uses HttpGet to get an input stream for a url
 */
public InputStream getInputStream(String url) throws IOException ;","/** 
 * Uses HttpGet to get an input stream for a url
 */
public InputStream getInputStream(String url) throws SardineException ;",0.9644268774703556
55017,"/** 
 * Uses webdav put to delete url
 */
public void delete(String url) throws IOException ;","/** 
 * Uses webdav put to delete url
 */
public void delete(String url) throws SardineException ;",0.9528795811518324
55018,"/** 
 * Uses webdav put to send data to a server
 */
public void put(String url,byte[] data) throws IOException ;","/** 
 * Uses webdav put to send data to a server
 */
public void put(String url,byte[] data) throws SardineException ;",0.961038961038961
55019,"public void move(String sourceUrl,String destinationUrl) throws IOException {
  HttpMove move=new HttpMove(sourceUrl,destinationUrl);
  HttpResponse response=this.client.execute(move);
  StatusLine statusLine=response.getStatusLine();
  if (!SardineUtil.isGoodResponse(statusLine.getStatusCode()))   throw new IOException(""String_Node_Str"" + statusLine.getStatusCode() + ""String_Node_Str""+ statusLine.getReasonPhrase());
}","public void move(String sourceUrl,String destinationUrl) throws SardineException {
  HttpMove move=new HttpMove(sourceUrl,destinationUrl);
  HttpResponse response=this.executeWrapper(move);
  StatusLine statusLine=response.getStatusLine();
  if (!SardineUtil.isGoodResponse(statusLine.getStatusCode()))   throw new SardineException(""String_Node_Str"" + sourceUrl + ""String_Node_Str""+ destinationUrl,statusLine.getStatusCode(),statusLine.getReasonPhrase());
}",0.8782707622298066
55020,"public List<DavResource> getResources(String url) throws IOException {
  HttpPropFind propFind=new HttpPropFind(url);
  propFind.setEntity(SardineUtil.getResourcesEntity());
  HttpResponse response=this.client.execute(propFind);
  int statusCode=response.getStatusLine().getStatusCode();
  if (!SardineUtil.isGoodResponse(statusCode))   throw new IOException(""String_Node_Str"" + statusCode + ""String_Node_Str""+ url);
  Multistatus r=null;
  try {
    r=(Multistatus)this.factory.getUnmarshaller().unmarshal(response.getEntity().getContent());
  }
 catch (  JAXBException ex) {
    IOException exception=new IOException(""String_Node_Str"" + url);
    exception.initCause(ex);
    throw exception;
  }
  List<Response> responses=r.getResponse();
  List<DavResource> resources=new ArrayList<DavResource>(responses.size());
  String path=responses.get(0).getHref().get(0);
  for (  Response resp : responses) {
    String href=resp.getHref().get(0);
    if (href.equals(path))     continue;
    String name=href.substring(path.length(),href.length());
    if (name.equals(""String_Node_Str""))     continue;
    if (name.endsWith(""String_Node_Str""))     name=name.substring(0,name.length() - 1);
    String creationdate=resp.getPropstat().get(0).getProp().getCreationdate().getContent().get(0);
    String modifieddate=resp.getPropstat().get(0).getProp().getGetlastmodified().getContent().get(0);
    String contentType=""String_Node_Str"";
    Getcontenttype gtt=resp.getPropstat().get(0).getProp().getGetcontenttype();
    if (gtt != null)     contentType=gtt.getContent().get(0);
    String contentLength=""String_Node_Str"";
    Getcontentlength gcl=resp.getPropstat().get(0).getProp().getGetcontentlength();
    if (gcl != null)     contentLength=gcl.getContent().get(0);
    DavResource dr=new DavResource(url,name,SardineUtil.parseDate(creationdate),SardineUtil.parseDate(modifieddate),contentType,Long.valueOf(contentLength));
    resources.add(dr);
  }
  return resources;
}","public List<DavResource> getResources(String url) throws SardineException {
  HttpPropFind propFind=new HttpPropFind(url);
  propFind.setEntity(SardineUtil.getResourcesEntity());
  HttpResponse response=this.executeWrapper(propFind);
  StatusLine statusLine=response.getStatusLine();
  if (!SardineUtil.isGoodResponse(statusLine.getStatusCode()))   throw new SardineException(""String_Node_Str"",url,statusLine.getStatusCode(),statusLine.getReasonPhrase());
  Multistatus multistatus=null;
  try {
    multistatus=(Multistatus)this.factory.getUnmarshaller().unmarshal(response.getEntity().getContent());
  }
 catch (  JAXBException ex) {
    throw new SardineException(""String_Node_Str"",url,ex);
  }
catch (  IOException ex) {
    throw new SardineException(ex);
  }
  List<Response> responses=multistatus.getResponse();
  List<DavResource> resources=new ArrayList<DavResource>(responses.size());
  String path=responses.get(0).getHref().get(0);
  for (  Response resp : responses) {
    String href=resp.getHref().get(0);
    if (href.equals(path))     continue;
    String name=href.substring(path.length(),href.length());
    if (name.equals(""String_Node_Str""))     continue;
    if (name.endsWith(""String_Node_Str""))     name=name.substring(0,name.length() - 1);
    String creationdate=resp.getPropstat().get(0).getProp().getCreationdate().getContent().get(0);
    String modifieddate=resp.getPropstat().get(0).getProp().getGetlastmodified().getContent().get(0);
    String contentType=""String_Node_Str"";
    Getcontenttype gtt=resp.getPropstat().get(0).getProp().getGetcontenttype();
    if (gtt != null)     contentType=gtt.getContent().get(0);
    String contentLength=""String_Node_Str"";
    Getcontentlength gcl=resp.getPropstat().get(0).getProp().getGetcontentlength();
    if (gcl != null)     contentLength=gcl.getContent().get(0);
    DavResource dr=new DavResource(url,name,SardineUtil.parseDate(creationdate),SardineUtil.parseDate(modifieddate),contentType,Long.valueOf(contentLength));
    resources.add(dr);
  }
  return resources;
}",0.3054726368159204
55021,"public InputStream getInputStream(String url) throws IOException {
  HttpGet get=new HttpGet(url);
  HttpResponse response=this.client.execute(get);
  StatusLine statusLine=response.getStatusLine();
  if (!SardineUtil.isGoodResponse(statusLine.getStatusCode()))   throw new IOException(""String_Node_Str"" + statusLine.getStatusCode() + ""String_Node_Str""+ statusLine.getReasonPhrase()+ ""String_Node_Str""+ url);
  return response.getEntity().getContent();
}","public InputStream getInputStream(String url) throws SardineException {
  HttpGet get=new HttpGet(url);
  HttpResponse response=this.executeWrapper(get);
  StatusLine statusLine=response.getStatusLine();
  if (!SardineUtil.isGoodResponse(statusLine.getStatusCode()))   throw new SardineException(url,statusLine.getStatusCode(),statusLine.getReasonPhrase());
  try {
    return response.getEntity().getContent();
  }
 catch (  IOException ex) {
    throw new SardineException(ex);
  }
}",0.1703940362087327
55022,"public void delete(String url) throws IOException {
  HttpDelete delete=new HttpDelete(url);
  HttpResponse response=this.client.execute(delete);
  StatusLine statusLine=response.getStatusLine();
  if (!SardineUtil.isGoodResponse(statusLine.getStatusCode()))   throw new IOException(""String_Node_Str"" + statusLine.getStatusCode() + ""String_Node_Str""+ statusLine.getReasonPhrase());
}","public void delete(String url) throws SardineException {
  HttpDelete delete=new HttpDelete(url);
  HttpResponse response=this.executeWrapper(delete);
  StatusLine statusLine=response.getStatusLine();
  if (!SardineUtil.isGoodResponse(statusLine.getStatusCode()))   throw new SardineException(url,statusLine.getStatusCode(),statusLine.getReasonPhrase());
}",0.8768606224627875
55023,"public void put(String url,byte[] data) throws IOException {
  HttpPut put=new HttpPut(url);
  ByteArrayEntity entity=new ByteArrayEntity(data);
  put.setEntity(entity);
  HttpResponse response=this.client.execute(put);
  StatusLine statusLine=response.getStatusLine();
  if (!SardineUtil.isGoodResponse(statusLine.getStatusCode()))   throw new IOException(""String_Node_Str"" + statusLine.getStatusCode() + ""String_Node_Str""+ statusLine.getReasonPhrase());
}","public void put(String url,byte[] data) throws SardineException {
  HttpPut put=new HttpPut(url);
  ByteArrayEntity entity=new ByteArrayEntity(data);
  put.setEntity(entity);
  HttpResponse response=this.executeWrapper(put);
  StatusLine statusLine=response.getStatusLine();
  if (!SardineUtil.isGoodResponse(statusLine.getStatusCode()))   throw new SardineException(url,statusLine.getStatusCode(),statusLine.getReasonPhrase());
}",0.649379932356257
55024,"private boolean existsExternal(String channel){
  String channelPartial=""String_Node_Str"";
  String[] parts=channel.split(""String_Node_Str"");
  if (externalChannels.contains(channelPartial))   return true;
  for (  String part : parts) {
    if (channelPartial.isEmpty())     channelPartial+=part;
 else     channelPartial+=""String_Node_Str"" + part;
    if (externalChannels.contains(channelPartial))     return true;
  }
  return false;
}","private boolean existsExternal(String channel){
  if (channel.equals(LISTEN_CHAN))   return true;
  String channelPartial=""String_Node_Str"";
  String[] parts=channel.split(""String_Node_Str"");
  if (externalChannels.contains(channelPartial))   return true;
  for (  String part : parts) {
    if (channelPartial.isEmpty())     channelPartial+=part;
 else     channelPartial+=""String_Node_Str"" + part;
    if (externalChannels.contains(channelPartial))     return true;
  }
  return false;
}",0.9461206896551724
55025,"private void publishChannels(int delay){
  new Thread(new Runnable(){
    public void run(){
      Log.w(TAG,""String_Node_Str"");
      publish(LISTEN_CHAN,WearScriptConnection.this.groupDevice,channelsValue());
      try {
        Thread.sleep(500);
      }
 catch (      InterruptedException e) {
      }
    }
  }
).start();
}","private void publishChannels(int delay){
  new Thread(new Runnable(){
    public void run(){
      Log.w(TAG,""String_Node_Str"");
      Log.d(TAG,""String_Node_Str"" + channelsValue());
      publish(LISTEN_CHAN,WearScriptConnection.this.groupDevice,channelsValue());
      try {
        Thread.sleep(500);
      }
 catch (      InterruptedException e) {
      }
    }
  }
).start();
}",0.923943661971831
55026,"public void publish(String channel,byte[] outBytes){
  if (client == null || !exists(channel) && !channel.equals(LISTEN_CHAN))   return;
  if (outBytes != null) {
    onReceiveDispatch(channel,outBytes,null);
    if (existsExternal(channel))     client.send(outBytes);
  }
}","public void publish(String channel,byte[] outBytes){
  if (client == null || !exists(channel)) {
    Log.d(TAG,String.format(""String_Node_Str"",channel,client != null,outBytes != null));
    return;
  }
  if (outBytes != null) {
    onReceiveDispatch(channel,outBytes,null);
    if (existsExternal(channel))     client.send(outBytes);
  }
}",0.763458401305057
55027,"private GlassDevice(){
  mBluetoothAdapter=BluetoothAdapter.getDefaultAdapter();
  if (mBluetoothAdapter == null) {
    Log.e(TAG,""String_Node_Str"");
    return;
  }
  if (!mBluetoothAdapter.isEnabled()) {
    Log.e(TAG,""String_Node_Str"");
  }
  mac=findMac();
  if (mac == null || mac.length() < 1)   throw new RuntimeException(""String_Node_Str"");
  Log.d(TAG,""String_Node_Str"" + mac);
  BluetoothDevice bluetoothDevice=mBluetoothAdapter.getRemoteDevice(mac);
  try {
    mSocket=bluetoothDevice.createRfcommSocketToServiceRecord(SECURE_UUID);
  }
 catch (  IOException e) {
    Log.e(TAG,""String_Node_Str"",e);
    return;
  }
  mBluetoothAdapter.cancelDiscovery();
  try {
    mSocket.connect();
    Log.i(TAG,""String_Node_Str"");
  }
 catch (  IOException connectException) {
    Log.e(TAG,""String_Node_Str"");
    try {
      mSocket.close();
    }
 catch (    IOException closeException) {
    }
    return;
  }
}","private GlassDevice(){
  mBluetoothAdapter=BluetoothAdapter.getDefaultAdapter();
  Log.d(TAG,""String_Node_Str"");
  if (mBluetoothAdapter == null) {
    Log.e(TAG,""String_Node_Str"");
    return;
  }
  if (!mBluetoothAdapter.isEnabled()) {
    Log.e(TAG,""String_Node_Str"");
  }
  mac=findMac();
  if (mac == null || mac.length() < 1)   throw new RuntimeException(""String_Node_Str"");
  Log.d(TAG,""String_Node_Str"" + mac);
  BluetoothDevice bluetoothDevice=mBluetoothAdapter.getRemoteDevice(mac);
  try {
    mSocket=bluetoothDevice.createRfcommSocketToServiceRecord(SECURE_UUID);
  }
 catch (  IOException e) {
    Log.e(TAG,""String_Node_Str"",e);
    return;
  }
  mBluetoothAdapter.cancelDiscovery();
  try {
    mSocket.connect();
    Log.i(TAG,""String_Node_Str"");
  }
 catch (  IOException connectException) {
    Log.e(TAG,""String_Node_Str"");
    try {
      mSocket.close();
    }
 catch (    IOException closeException) {
    }
    return;
  }
}",0.9828326180257512
55028,"public void setup(){
  if (isSetup)   return;
  isSetup=true;
  mBluetoothAdapter=BluetoothAdapter.getDefaultAdapter();
  if (mBluetoothAdapter == null) {
    return;
  }
  if (!mBluetoothAdapter.isEnabled()) {
    Log.w(TAG,""String_Node_Str"");
  }
}","public void setup(){
  if (isSetup) {
    log();
    return;
  }
  isSetup=true;
  mBluetoothAdapter=BluetoothAdapter.getDefaultAdapter();
  log();
  if (mBluetoothAdapter == null) {
    Log.e(TAG,""String_Node_Str"");
    return;
  }
  if (!mBluetoothAdapter.isEnabled()) {
    Log.w(TAG,""String_Node_Str"");
  }
}",0.8576512455516014
55029,"public void pairWithDevice(String address){
  BluetoothDevice device=findBondedDevice(address);
  if (device == null) {
    Log.e(TAG,""String_Node_Str"" + address);
    return;
  }
  device.fetchUuidsWithSdp();
  if (device.getUuids() == null) {
    Log.e(TAG,""String_Node_Str"");
    return;
  }
  for (  ParcelUuid uid : device.getUuids()) {
    Log.d(TAG,""String_Node_Str"" + uid.toString());
  }
  ParcelUuid uuid=device.getUuids()[0];
  Log.d(TAG,""String_Node_Str"" + uuid.toString());
  Log.d(TAG,""String_Node_Str"");
  try {
    mSockets.put(device.getAddress(),device.createInsecureRfcommSocketToServiceRecord(uuid.getUuid()));
  }
 catch (  IOException e2) {
    Log.e(TAG,""String_Node_Str"");
    return;
  }
  try {
    mSockets.get(device.getAddress()).connect();
  }
 catch (  IOException e3) {
    mSockets.remove(device.getAddress());
    Log.e(TAG,""String_Node_Str"");
    return;
  }
  Log.d(TAG,""String_Node_Str"");
}","public void pairWithDevice(String address){
  mBluetoothAdapter.cancelDiscovery();
  BluetoothDevice device=findBondedDevice(address);
  if (device == null) {
    Log.e(TAG,""String_Node_Str"" + address);
    return;
  }
  device.fetchUuidsWithSdp();
  if (device.getUuids() == null) {
    Log.e(TAG,""String_Node_Str"");
    return;
  }
  for (  ParcelUuid uid : device.getUuids()) {
    Log.d(TAG,""String_Node_Str"" + uid.toString());
  }
  ParcelUuid uuid=device.getUuids()[0];
  Log.d(TAG,""String_Node_Str"" + uuid.toString());
  Log.d(TAG,""String_Node_Str"");
  try {
    mSockets.put(device.getAddress(),device.createInsecureRfcommSocketToServiceRecord(uuid.getUuid()));
  }
 catch (  IOException e2) {
    Log.e(TAG,""String_Node_Str"");
    return;
  }
  try {
    mSockets.get(device.getAddress()).connect();
  }
 catch (  IOException e3) {
    mSockets.remove(device.getAddress());
    Log.e(TAG,""String_Node_Str"");
    return;
  }
  Log.d(TAG,""String_Node_Str"");
}",0.9793977812995246
55030,"@Override public void onPause(){
  Log.i(TAG,""String_Node_Str"");
  isForeground=false;
  getWindow().clearFlags(WindowManager.LayoutParams.FLAG_KEEP_SCREEN_ON);
  if (bs != null) {
    ((CameraManager)bs.getManager(CameraManager.class)).pauseBackground();
  }
  super.onPause();
}","@Override public void onPause(){
  Log.i(TAG,""String_Node_Str"");
  isForeground=false;
  getWindow().clearFlags(WindowManager.LayoutParams.FLAG_KEEP_SCREEN_ON);
  if (bs != null) {
    CameraManager cm=((CameraManager)bs.getManager(CameraManager.class));
    if (cm != null)     cm.pauseBackground();
  }
  super.onPause();
}",0.91900826446281
55031,"public static byte[] encode(Object... data){
  List<Value> out=new ArrayList<Value>();
  for (  Object i : data) {
    Class c=i.getClass();
    if (c.equals(String.class))     out.add(ValueFactory.createRawValue((String)i));
 else     if (c.equals(Double.class))     out.add(ValueFactory.createFloatValue((Double)i));
 else     if (Value.class.isAssignableFrom(c))     out.add((Value)i);
 else {
      Log.e(TAG,""String_Node_Str"" + c);
      return null;
    }
  }
  try {
    return msgpack.write(out);
  }
 catch (  IOException e) {
    Log.e(TAG,""String_Node_Str"");
  }
  return null;
}","public static byte[] encode(Object... data){
  List<Value> out=new ArrayList<Value>();
  for (  Object i : data) {
    Class c=i.getClass();
    if (c.equals(String.class))     out.add(ValueFactory.createRawValue((String)i));
 else     if (c.equals(Double.class))     out.add(ValueFactory.createFloatValue((Double)i));
 else     if (Value.class.isAssignableFrom(c))     out.add((Value)i);
 else     if (c.equals(Boolean.class))     out.add(ValueFactory.createBooleanValue((Boolean)i));
 else {
      Log.e(TAG,""String_Node_Str"" + c);
      return null;
    }
  }
  try {
    return msgpack.write(out);
  }
 catch (  IOException e) {
    Log.e(TAG,""String_Node_Str"");
  }
  return null;
}",0.9240407204385278
55032,"public void connect(URI uri){
synchronized (this) {
    if (shutdown) {
      Log.w(TAG,""String_Node_Str"");
      return;
    }
    Log.i(TAG,uri.toString());
    if (uri.equals(this.uri) && connected) {
      onConnect();
      return;
    }
    this.uri=uri;
    List<BasicNameValuePair> extraHeaders=Arrays.asList();
    Log.i(TAG,""String_Node_Str"");
    if (client != null)     client.disconnect();
    client=new WebSocketClient(uri,new LocalListener(),extraHeaders);
    reconnect();
  }
}","public void connect(URI uri){
  Log.d(TAG,""String_Node_Str"");
synchronized (this) {
    if (shutdown) {
      Log.w(TAG,""String_Node_Str"");
      return;
    }
    Log.i(TAG,uri.toString());
    if (uri.equals(this.uri) && connected) {
      onConnect();
      return;
    }
    this.uri=uri;
    List<BasicNameValuePair> extraHeaders=Arrays.asList();
    Log.i(TAG,""String_Node_Str"");
    if (client != null)     client.disconnect();
    client=new WebSocketClient(uri,new LocalListener(),extraHeaders);
    reconnect();
  }
}",0.471624266144814
55033,"private void handleMessage(byte[] message) throws IOException {
  String channel=""String_Node_Str"";
  List<Value> input=msgpack.read(message,tList(TValue));
  channel=input.get(0).asRawValue().getString();
  Log.d(TAG,String.format(""String_Node_Str"",channel));
  if (channel.equals(LISTEN_CHAN)) {
    String d=input.get(1).asRawValue().getString();
    Value[] channels=input.get(2).asArrayValue().getElementArray();
    setDeviceChannels(d,channels);
  }
  if (scriptChannels.contains(channel)) {
    Log.i(TAG,""String_Node_Str"" + channel);
    WearScriptConnection.this.onReceive(channel,message,input);
  }
}","private void handleMessage(byte[] message) throws IOException {
  String channel=""String_Node_Str"";
  List<Value> input=msgpack.read(message,tList(TValue));
  channel=input.get(0).asRawValue().getString();
  Log.d(TAG,String.format(""String_Node_Str"",channel));
  if (channel.equals(LISTEN_CHAN)) {
    String d=input.get(1).asRawValue().getString();
    Value[] channels=input.get(2).asArrayValue().getElementArray();
    setDeviceChannels(d,channels);
  }
  String channelPart=null;
  for (  String part : channel.split(""String_Node_Str"")) {
    if (channelPart == null) {
      channelPart=part;
    }
 else {
      channelPart+=""String_Node_Str"" + part;
    }
    if (scriptChannels.contains(channelPart)) {
      Log.i(TAG,""String_Node_Str"" + channel);
      WearScriptConnection.this.onReceive(channel,message,input);
      break;
    }
  }
}",0.8375599725839616
55034,"public TreeSet<String> channelsInternal(){
  return externalChannels;
}","public TreeSet<String> channelsInternal(){
  return scriptChannels;
}",0.9142857142857144
55035,"private Value listValue(Iterable<String> channels){
  ArrayList<Value> channelsArray=new ArrayList<Value>();
  for (  String c : channels)   channelsArray.add(ValueFactory.createRawValue(c));
  return ValueFactory.createArrayValue(channelsArray.toArray(new Value[channelsArray.size()]));
}","public static Value listValue(Iterable<String> channels){
  ArrayList<Value> channelsArray=new ArrayList<Value>();
  for (  String c : channels)   channelsArray.add(ValueFactory.createRawValue(c));
  return ValueFactory.createArrayValue(channelsArray.toArray(new Value[channelsArray.size()]));
}",0.9691780821917808
55036,"private void setDeviceChannels(String device,Value[] channels){
synchronized (this) {
    ArrayList<String> channelsArray=new ArrayList();
    for (    Value channel : channels)     channelsArray.add(channel.asRawValue().getString());
    deviceToChannels.put(device,channelsArray);
    TreeSet<String> externalChannelsNew=new TreeSet<String>();
    for (    ArrayList<String> deviceChannels : deviceToChannels.values())     for (    String channel : deviceChannels)     externalChannelsNew.add(channel);
    externalChannels=externalChannelsNew;
    for (    String c : externalChannels)     Log.d(TAG,""String_Node_Str"" + c);
  }
}","private void setDeviceChannels(String device,Value[] channels){
synchronized (this) {
    ArrayList<String> channelsArray=new ArrayList();
    for (    Value channel : channels)     channelsArray.add(channel.asRawValue().getString());
    deviceToChannels.put(device,channelsArray);
    TreeSet<String> externalChannelsNew=new TreeSet<String>();
    for (    ArrayList<String> deviceChannels : deviceToChannels.values())     for (    String channel : deviceChannels)     externalChannelsNew.add(channel);
    externalChannels=externalChannelsNew;
  }
}",0.9324324324324323
55037,"public void reset(){
synchronized (this) {
    for (    String channel : connection.channelsInternal()) {
      unregisterCallback(channel);
    }
    connection.unsubscribe(connection.channelsInternal());
    connection.subscribe(connection.group());
    connection.subscribe(connection.groupDevice());
    connection.subscribe(GIST_LIST_SYNC_CHAN);
    connection.subscribe(GIST_GET_SYNC_CHAN);
  }
  super.reset();
}","public void reset(){
synchronized (this) {
    for (    String channel : connection.channelsInternal()) {
      unregisterCallback(channel);
    }
    connection.unsubscribe(new TreeSet<String>(connection.channelsInternal()));
    testChannels=new TreeSet<String>();
    String testChannel=""String_Node_Str"" + connection.groupDevice();
    testChannels.add(testChannel);
    connection.subscribe(testChannel);
    connection.subscribe(connection.group());
    connection.subscribe(connection.groupDevice());
    connection.subscribe(GIST_LIST_SYNC_CHAN);
    connection.subscribe(GIST_GET_SYNC_CHAN);
  }
  super.reset();
}",0.8042226487523992
55038,"@Override public void onReceive(String channel,byte[] dataRaw,List<Value> data){
  if (channel.equals(this.groupDevice) || channel.equals(this.group)) {
    String command=data.get(1).asRawValue().getString();
    Log.d(TAG,String.format(""String_Node_Str"",channel,command));
    if (command.equals(""String_Node_Str"")) {
      Value[] files=data.get(2).asMapValue().getKeyValueArray();
      String path=null;
      for (int i=0; i < files.length / 2; i++) {
        String name=files[i * 2].asRawValue().getString();
        String pathCur=Utils.SaveData(files[i * 2 + 1].asRawValue().getByteArray(),""String_Node_Str"",false,name);
        if (name.equals(""String_Node_Str""))         path=pathCur;
      }
      if (path != null) {
        Utils.eventBusPost(new ScriptEvent(path));
      }
 else {
        Log.w(TAG,""String_Node_Str"");
      }
    }
 else     if (command.equals(""String_Node_Str"")) {
      Utils.eventBusPost(new LambdaEvent(data.get(2).asRawValue().getString()));
    }
 else     if (command.equals(""String_Node_Str"")) {
      shutdown();
      String error=data.get(2).asRawValue().getString();
      Log.e(TAG,""String_Node_Str"" + error);
      Utils.eventBusPost(new SayEvent(error,true));
    }
 else     if (command.equals(""String_Node_Str"")) {
      int versionExpected=1;
      int version=data.get(2).asIntegerValue().getInt();
      if (version != versionExpected) {
        Utils.eventBusPost(new SayEvent(""String_Node_Str"" + version + ""String_Node_Str""+ versionExpected+ ""String_Node_Str"",true));
      }
    }
 else     if (channel.equals(""String_Node_Str"")) {
      Log.setDsn(data.get(1).asRawValue().getString());
    }
  }
  if (channel.equals(GIST_LIST_SYNC_CHAN)) {
    Log.d(TAG,""String_Node_Str"" + data.get(1).toString());
    for (    Value v : data.get(1).asArrayValue()) {
      Value gistid=(Value)toMap(v).get(""String_Node_Str"");
      if (gistid != null) {
        Log.d(TAG,""String_Node_Str"" + gistid);
        Utils.eventBusPost(new SendEvent(""String_Node_Str"",""String_Node_Str"",GIST_GET_SYNC_CHAN,gistid.asRawValue().getString()));
      }
    }
  }
  if (channel.equals(GIST_GET_SYNC_CHAN)) {
    Log.d(TAG,""String_Node_Str"" + data.get(1).toString());
    TreeMap<String,Value> gist=toMap(data.get(1));
    TreeMap<String,Value> files=toMap(gist.get(""String_Node_Str""));
    String gistid=gist.get(""String_Node_Str"").asRawValue().getString();
    for (    Value v : files.values()) {
      TreeMap<String,Value> file=toMap(v);
      byte[] content=file.get(""String_Node_Str"").asRawValue().getByteArray();
      String filename=file.get(""String_Node_Str"").asRawValue().getString();
      String pathCur=Utils.SaveData(content,""String_Node_Str"" + gistid,false,filename);
      Log.d(TAG,""String_Node_Str"" + filename + ""String_Node_Str""+ gistid);
    }
  }
  makeCall(channel,""String_Node_Str"" + Base64.encodeToString(dataRaw,Base64.NO_WRAP) + ""String_Node_Str"");
}","@Override public void onReceive(String channel,byte[] dataRaw,List<Value> data){
  if (channel.equals(this.groupDevice) || channel.equals(this.group)) {
    String command=data.get(1).asRawValue().getString();
    Log.d(TAG,String.format(""String_Node_Str"",channel,command));
    if (command.equals(""String_Node_Str"")) {
      Value[] files=data.get(2).asMapValue().getKeyValueArray();
      String path=null;
      for (int i=0; i < files.length / 2; i++) {
        String name=files[i * 2].asRawValue().getString();
        String pathCur=Utils.SaveData(files[i * 2 + 1].asRawValue().getByteArray(),""String_Node_Str"",false,name);
        if (name.equals(""String_Node_Str""))         path=pathCur;
      }
      if (path != null) {
        Utils.eventBusPost(new ScriptEvent(path));
      }
 else {
        Log.w(TAG,""String_Node_Str"");
      }
    }
 else     if (command.equals(""String_Node_Str"")) {
      Utils.eventBusPost(new LambdaEvent(data.get(2).asRawValue().getString()));
    }
 else     if (command.equals(""String_Node_Str"")) {
      shutdown();
      String error=data.get(2).asRawValue().getString();
      Log.e(TAG,""String_Node_Str"" + error);
      Utils.eventBusPost(new SayEvent(error,true));
    }
 else     if (command.equals(""String_Node_Str"")) {
      int versionExpected=1;
      int version=data.get(2).asIntegerValue().getInt();
      if (version != versionExpected) {
        Utils.eventBusPost(new SayEvent(""String_Node_Str"" + version + ""String_Node_Str""+ versionExpected+ ""String_Node_Str"",true));
      }
    }
 else     if (channel.equals(""String_Node_Str"")) {
      Log.setDsn(data.get(1).asRawValue().getString());
    }
  }
  if (channel.equals(GIST_LIST_SYNC_CHAN)) {
    Log.d(TAG,""String_Node_Str"" + data.get(1).toString());
    for (    Value v : data.get(1).asArrayValue()) {
      Value gistid=(Value)toMap(v).get(""String_Node_Str"");
      if (gistid != null) {
        Log.d(TAG,""String_Node_Str"" + gistid);
        Utils.eventBusPost(new SendEvent(""String_Node_Str"",""String_Node_Str"",GIST_GET_SYNC_CHAN,gistid.asRawValue().getString()));
      }
    }
  }
  Log.d(TAG,""String_Node_Str"" + channel);
  testHandler(data);
  if (channel.equals(GIST_GET_SYNC_CHAN)) {
    Log.d(TAG,""String_Node_Str"" + data.get(1).toString());
    TreeMap<String,Value> gist=toMap(data.get(1));
    TreeMap<String,Value> files=toMap(gist.get(""String_Node_Str""));
    String gistid=gist.get(""String_Node_Str"").asRawValue().getString();
    for (    Value v : files.values()) {
      TreeMap<String,Value> file=toMap(v);
      byte[] content=file.get(""String_Node_Str"").asRawValue().getByteArray();
      String filename=file.get(""String_Node_Str"").asRawValue().getString();
      String pathCur=Utils.SaveData(content,""String_Node_Str"" + gistid,false,filename);
      Log.d(TAG,""String_Node_Str"" + filename + ""String_Node_Str""+ gistid);
    }
  }
  makeCall(channel,""String_Node_Str"" + Base64.encodeToString(dataRaw,Base64.NO_WRAP) + ""String_Node_Str"");
}",0.7910219350450604
55039,"protected void makeCall(String key,String data){
  Log.d(TAG,jsCallbacks.toString());
  if (!jsCallbacks.containsKey(key)) {
    Log.d(TAG,""String_Node_Str"");
    return;
  }
  String url=buildCallbackString(key,data);
  Utils.eventBusPost(new JsCall(url));
}","protected void makeCall(String key,String data){
  Log.d(TAG,jsCallbacks.toString());
  if (!jsCallbacks.containsKey(key)) {
    Log.d(TAG,""String_Node_Str"" + key);
    return;
  }
  String url=buildCallbackString(key,data);
  Utils.eventBusPost(new JsCall(url));
}",0.9885496183206108
55040,"public void data(int type,String name,String values){
  Log.i(TAG,""String_Node_Str"");
  DataPoint dp=new DataPoint(name,type,System.currentTimeMillis() / 1000.,System.nanoTime());
  for (  Double p : (List<Double>)JSONValue.parse(values)) {
    dp.addValue(p);
  }
  bs.handleSensor(dp,null);
}","public void data(int type,String name,String values){
  Log.i(TAG,""String_Node_Str"");
  DataPoint dp=new DataPoint(name,type,System.currentTimeMillis() / 1000.,System.nanoTime());
  JSONArray valuesArray=(JSONArray)JSONValue.parse(values);
  for (  Object j : valuesArray) {
    try {
      dp.addValue((Double)j);
    }
 catch (    ClassCastException e) {
      dp.addValue(((Long)j).doubleValue());
    }
  }
  bs.handleSensor(dp,null);
}",0.7029972752043597
55041,"public void data(int type,String name,String values){
  Log.i(TAG,""String_Node_Str"");
  DataPoint dp=new DataPoint(name,type,System.currentTimeMillis() / 1000.,System.nanoTime());
  for (  Double p : (List<Double>)JSONValue.parse(values)) {
    dp.addValue(p);
  }
  bs.handleSensor(dp,null);
}","public void data(int type,String name,String values){
  Log.i(TAG,""String_Node_Str"");
  DataPoint dp=new DataPoint(name,type,System.currentTimeMillis() / 1000.,System.nanoTime());
  JSONArray valuesArray=(JSONArray)JSONValue.parse(values);
  for (  Object j : valuesArray) {
    try {
      dp.addValue((Double)j);
    }
 catch (    ClassCastException e) {
      dp.addValue(((Long)j).doubleValue());
    }
  }
  bs.handleSensor(dp,null);
}",0.7029972752043597
55042,"public void startDefaultScript(){
  byte[] defaultScriptArray=LoadData(""String_Node_Str"",""String_Node_Str"");
  if (defaultScriptArray == null) {
    runScript(""String_Node_Str"");
  }
 else {
    runScript(new String(defaultScriptArray));
  }
}","public void startDefaultScript(){
  runScript(""String_Node_Str"");
}",0.432258064516129
55043,"public void onSocketMessage(byte[] message){
  try {
    Log.i(TAG,""String_Node_Str"" + Base64.encodeToString(message,Base64.NO_WRAP));
    List<Value> input=msgpack.read(message,tList(TValue));
    String action=input.get(0).asRawValue().getString();
    Log.i(TAG,String.format(""String_Node_Str"",action));
    if (action.equals(""String_Node_Str"") || action.equals(""String_Node_Str"")) {
      final String script=input.get(1).asRawValue().getString();
      Log.i(TAG,""String_Node_Str"" + Integer.toString(script.length()));
      if (activity == null)       return;
      final MainActivity a=activity.get();
      if (a == null)       return;
      if (action.equals(""String_Node_Str""))       SaveData(script.getBytes(),""String_Node_Str"",false,""String_Node_Str"");
      a.runOnUiThread(new Thread(){
        public void run(){
          runScript(script);
        }
      }
);
    }
 else     if (action.equals(""String_Node_Str"")) {
      final String url=input.get(1).asRawValue().getString();
      if (activity == null)       return;
      final MainActivity a=activity.get();
      if (a == null)       return;
      a.runOnUiThread(new Thread(){
        public void run(){
          runScriptUrl(url);
        }
      }
);
    }
 else     if (action.equals(""String_Node_Str"")) {
      List<Value> output=new ArrayList<Value>();
      output.add(ValueFactory.createRawValue(""String_Node_Str""));
      output.add(ValueFactory.createRawValue(glassID));
synchronized (lock) {
        client.send(msgpack.write(output));
      }
    }
 else     if (action.equals(""String_Node_Str"")) {
    }
 else     if (action.equals(""String_Node_Str"")) {
      if (webview != null) {
        String jsCallback=cameraManager.buildCallbackString(1,input.get(3).asRawValue().getByteArray());
        if (jsCallback != null)         webview.loadUrl(jsCallback);
      }
    }
 else     if (action.equals(""String_Node_Str"")) {
      int versionExpected=0;
      int version=input.get(1).asIntegerValue().getInt();
      if (version != versionExpected) {
        say(""String_Node_Str"" + version + ""String_Node_Str""+ versionExpected+ ""String_Node_Str"");
      }
    }
 else     if (action.equals(""String_Node_Str"")) {
      Log.i(TAG,""String_Node_Str"");
      shutdown();
    }
 else     if (action.equals(""String_Node_Str"")) {
    }
    Log.d(TAG,String.format(""String_Node_Str"",message.length));
  }
 catch (  Exception e) {
    Log.e(TAG,e.toString());
  }
}","public void onSocketMessage(byte[] message){
  try {
    Log.i(TAG,""String_Node_Str"" + Base64.encodeToString(message,Base64.NO_WRAP));
    List<Value> input=msgpack.read(message,tList(TValue));
    String action=input.get(0).asRawValue().getString();
    Log.i(TAG,String.format(""String_Node_Str"",action));
    if (action.equals(""String_Node_Str"")) {
      final String script=input.get(1).asRawValue().getString();
      Log.i(TAG,""String_Node_Str"" + Integer.toString(script.length()));
      if (activity == null)       return;
      final MainActivity a=activity.get();
      if (a == null)       return;
      a.runOnUiThread(new Thread(){
        public void run(){
          runScript(script);
        }
      }
);
    }
 else     if (action.equals(""String_Node_Str"")) {
      final String script=input.get(1).asRawValue().getString();
      final String name=input.get(2).asRawValue().getString();
      Pattern p=Pattern.compile(""String_Node_Str"");
      if (name == null || name.isEmpty() || p.matcher(name).find()) {
        Log.w(TAG,""String_Node_Str"");
        return;
      }
      SaveData(script.getBytes(),""String_Node_Str"",false,""String_Node_Str"" + name + ""String_Node_Str"");
    }
 else     if (action.equals(""String_Node_Str"")) {
      final String url=input.get(1).asRawValue().getString();
      if (activity == null)       return;
      final MainActivity a=activity.get();
      if (a == null)       return;
      a.runOnUiThread(new Thread(){
        public void run(){
          runScriptUrl(url);
        }
      }
);
    }
 else     if (action.equals(""String_Node_Str"")) {
      List<Value> output=new ArrayList<Value>();
      output.add(ValueFactory.createRawValue(""String_Node_Str""));
      output.add(ValueFactory.createRawValue(glassID));
synchronized (lock) {
        client.send(msgpack.write(output));
      }
    }
 else     if (action.equals(""String_Node_Str"")) {
    }
 else     if (action.equals(""String_Node_Str"")) {
      if (webview != null) {
        String jsCallback=cameraManager.buildCallbackString(1,input.get(3).asRawValue().getByteArray());
        if (jsCallback != null)         webview.loadUrl(jsCallback);
      }
    }
 else     if (action.equals(""String_Node_Str"")) {
      int versionExpected=0;
      int version=input.get(1).asIntegerValue().getInt();
      if (version != versionExpected) {
        say(""String_Node_Str"" + version + ""String_Node_Str""+ versionExpected+ ""String_Node_Str"");
      }
    }
 else     if (action.equals(""String_Node_Str"")) {
      Log.i(TAG,""String_Node_Str"");
      shutdown();
    }
 else     if (action.equals(""String_Node_Str"")) {
    }
    Log.d(TAG,String.format(""String_Node_Str"",message.length));
  }
 catch (  Exception e) {
    Log.e(TAG,e.toString());
  }
}",0.3879161054454493
55044,"/** 
 * Called when the activity is first created.
 */
@Override public void onCreate(Bundle savedInstanceState){
  getWindow().addFlags(WindowManager.LayoutParams.FLAG_KEEP_SCREEN_ON);
  Intent thisIntent=getIntent();
  if (thisIntent.getStringExtra(EXTRA_NAME) != null) {
    mHadUrlExtra=true;
    extra=thisIntent.getStringExtra(EXTRA_NAME);
    Log.v(TAG,""String_Node_Str"" + extra);
  }
 else {
    Log.v(TAG,""String_Node_Str"");
  }
  super.onCreate(savedInstanceState);
  mConnection=new ServiceConnection(){
    public void onServiceConnected(    ComponentName className,    IBinder service){
      Log.i(TAG,""String_Node_Str"");
      bs=((BackgroundService.LocalBinder)service).getService();
      if (bs.activity != null) {
        MainActivity activity=bs.activity.get();
        if (activity != null)         activity.finish();
      }
      bs.activity=new WeakReference<MainActivity>(MainActivity.this);
      if (bs.webview != null) {
        ViewGroup parentViewGroup=(ViewGroup)bs.webview.getParent();
        if (parentViewGroup != null)         parentViewGroup.removeAllViews();
        bs.updateActivityView();
        return;
      }
      byte[] wsUrlArray=bs.LoadData(""String_Node_Str"",""String_Node_Str"");
      if (wsUrlArray == null) {
        bs.say(""String_Node_Str"");
        finish();
        return;
      }
      bs.reset();
      bs.wsUrl=(new String(wsUrlArray)).trim();
      if (extra != null) {
        bs.runScriptUrl(extra);
      }
 else {
        bs.startDefaultScript();
      }
    }
    public void onServiceDisconnected(    ComponentName className){
      Log.i(TAG,""String_Node_Str"");
    }
  }
;
  Log.i(TAG,""String_Node_Str"");
  startService(new Intent(this,BackgroundService.class));
  bindService(new Intent(this,BackgroundService.class),mConnection,Context.BIND_AUTO_CREATE);
}","/** 
 * Called when the activity is first created.
 */
@Override public void onCreate(Bundle savedInstanceState){
  getWindow().addFlags(WindowManager.LayoutParams.FLAG_KEEP_SCREEN_ON);
  Intent thisIntent=getIntent();
  if (thisIntent.getStringExtra(EXTRA_NAME) != null) {
    mHadUrlExtra=true;
    extra=thisIntent.getStringExtra(EXTRA_NAME);
    Log.v(TAG,""String_Node_Str"" + extra);
  }
 else {
    Log.v(TAG,""String_Node_Str"");
  }
  super.onCreate(savedInstanceState);
  mConnection=new ServiceConnection(){
    public void onServiceConnected(    ComponentName className,    IBinder service){
      Log.i(TAG,""String_Node_Str"");
      bs=((BackgroundService.LocalBinder)service).getService();
      if (bs.activity != null) {
        MainActivity activity=bs.activity.get();
        if (activity != null)         activity.finish();
      }
      bs.activity=new WeakReference<MainActivity>(MainActivity.this);
      if (bs.webview != null && extra == null) {
        ViewGroup parentViewGroup=(ViewGroup)bs.webview.getParent();
        if (parentViewGroup != null)         parentViewGroup.removeAllViews();
        bs.updateActivityView();
        return;
      }
      byte[] wsUrlArray=bs.LoadData(""String_Node_Str"",""String_Node_Str"");
      if (wsUrlArray == null) {
        bs.say(""String_Node_Str"");
        finish();
        return;
      }
      bs.reset();
      bs.wsUrl=(new String(wsUrlArray)).trim();
      if (extra != null) {
        Log.i(TAG,""String_Node_Str"");
        bs.runScriptUrl(extra);
      }
 else {
        Log.i(TAG,""String_Node_Str"");
        bs.startDefaultScript();
      }
    }
    public void onServiceDisconnected(    ComponentName className){
      Log.i(TAG,""String_Node_Str"");
    }
  }
;
  Log.i(TAG,""String_Node_Str"");
  startService(new Intent(this,BackgroundService.class));
  bindService(new Intent(this,BackgroundService.class),mConnection,Context.BIND_AUTO_CREATE);
}",0.9751668891855808
55045,"public void onServiceConnected(ComponentName className,IBinder service){
  Log.i(TAG,""String_Node_Str"");
  bs=((BackgroundService.LocalBinder)service).getService();
  if (bs.activity != null) {
    MainActivity activity=bs.activity.get();
    if (activity != null)     activity.finish();
  }
  bs.activity=new WeakReference<MainActivity>(MainActivity.this);
  if (bs.webview != null) {
    ViewGroup parentViewGroup=(ViewGroup)bs.webview.getParent();
    if (parentViewGroup != null)     parentViewGroup.removeAllViews();
    bs.updateActivityView();
    return;
  }
  byte[] wsUrlArray=bs.LoadData(""String_Node_Str"",""String_Node_Str"");
  if (wsUrlArray == null) {
    bs.say(""String_Node_Str"");
    finish();
    return;
  }
  bs.reset();
  bs.wsUrl=(new String(wsUrlArray)).trim();
  if (extra != null) {
    bs.runScriptUrl(extra);
  }
 else {
    bs.startDefaultScript();
  }
}","public void onServiceConnected(ComponentName className,IBinder service){
  Log.i(TAG,""String_Node_Str"");
  bs=((BackgroundService.LocalBinder)service).getService();
  if (bs.activity != null) {
    MainActivity activity=bs.activity.get();
    if (activity != null)     activity.finish();
  }
  bs.activity=new WeakReference<MainActivity>(MainActivity.this);
  if (bs.webview != null && extra == null) {
    ViewGroup parentViewGroup=(ViewGroup)bs.webview.getParent();
    if (parentViewGroup != null)     parentViewGroup.removeAllViews();
    bs.updateActivityView();
    return;
  }
  byte[] wsUrlArray=bs.LoadData(""String_Node_Str"",""String_Node_Str"");
  if (wsUrlArray == null) {
    bs.say(""String_Node_Str"");
    finish();
    return;
  }
  bs.reset();
  bs.wsUrl=(new String(wsUrlArray)).trim();
  if (extra != null) {
    Log.i(TAG,""String_Node_Str"");
    bs.runScriptUrl(extra);
  }
 else {
    Log.i(TAG,""String_Node_Str"");
    bs.startDefaultScript();
  }
}",0.9539794260963724
55046,"SocketClient(URI uri,SocketListener listener,String callback){
  this.listener=listener;
  this.uri=uri;
  List<BasicNameValuePair> extraHeaders=Arrays.asList();
  client=new WebSocketClient(uri,new LocalListener(listener),extraHeaders);
}","SocketClient(URI uri,SocketListener listener,String callback){
  this.listener=listener;
  this.uri=uri;
  this.callback=callback;
  List<BasicNameValuePair> extraHeaders=Arrays.asList();
  client=new WebSocketClient(uri,new LocalListener(listener),extraHeaders);
}",0.9484126984126984
55047,"public void saveDataPacket(final Mat frame){
  final JSONArray curSensorBuffer=sensorBuffer;
  final JSONArray curWifiBuffer=wifiBuffer;
  final Double Tsave=new Double(System.currentTimeMillis() / 1000.);
  sensorBuffer=new JSONArray();
  wifiBuffer=new JSONArray();
  JSONObject data=new JSONObject();
  if (frame != null) {
    Log.i(TAG,""String_Node_Str"" + frame.size().toString());
    MatOfByte jpgFrame=new MatOfByte();
    Highgui.imencode(""String_Node_Str"",frame,jpgFrame);
    final byte[] out=jpgFrame.toArray();
    data.put(""String_Node_Str"",Base64.encodeToString(out,Base64.NO_WRAP));
  }
  if (!curSensorBuffer.isEmpty())   data.put(""String_Node_Str"",curSensorBuffer);
  if (!wifiBuffer.isEmpty())   data.put(""String_Node_Str"",wifiBuffer);
  data.put(""String_Node_Str"",Tsave);
  data.put(""String_Node_Str"",new Double(System.currentTimeMillis() / 1000.));
  data.put(""String_Node_Str"",glassID);
  data.put(""String_Node_Str"",""String_Node_Str"");
  final String dataStr=data.toJSONString();
  if (dataLocal) {
    SaveData(dataStr.getBytes(),""String_Node_Str"",true,""String_Node_Str"");
  }
  if (dataRemote) {
    remoteImageCount++;
    if (clientConnected())     client.send(dataStr);
  }
}","public void saveDataPacket(final Mat frame){
  final JSONArray curSensorBuffer=sensorBuffer;
  final JSONArray curWifiBuffer=wifiBuffer;
  final Double Tsave=new Double(System.currentTimeMillis() / 1000.);
  sensorBuffer=new JSONArray();
  wifiBuffer=new JSONArray();
  JSONObject data=new JSONObject();
  if (frame != null) {
    Log.i(TAG,""String_Node_Str"" + frame.size().toString());
    MatOfByte jpgFrame=new MatOfByte();
    Highgui.imencode(""String_Node_Str"",frame,jpgFrame);
    final byte[] out=jpgFrame.toArray();
    data.put(""String_Node_Str"",Base64.encodeToString(out,Base64.NO_WRAP));
  }
  if (!curSensorBuffer.isEmpty())   data.put(""String_Node_Str"",curSensorBuffer);
  if (!wifiBuffer.isEmpty())   data.put(""String_Node_Str"",wifiBuffer);
  data.put(""String_Node_Str"",Tsave);
  data.put(""String_Node_Str"",new Double(System.currentTimeMillis() / 1000.));
  data.put(""String_Node_Str"",glassID);
  data.put(""String_Node_Str"",""String_Node_Str"");
  final String dataStr=data.toJSONString();
  if (dataLocal) {
    SaveData(dataStr.getBytes(),""String_Node_Str"",true,""String_Node_Str"");
  }
  if (dataRemote) {
    if (frame != null)     remoteImageCount++;
    if (clientConnected())     client.send(dataStr);
  }
}",0.9905232797692624
55048,"@SuppressWarnings({""String_Node_Str"",""String_Node_Str""}) private static <IN1,IN2,OUT>TypeInformation<OUT> createTypeInfoWithTypeHierarchy(ArrayList<Type> typeHierarchy,Type t,TypeInformation<IN1> in1Type,TypeInformation<IN2> in2Type){
  if ((t instanceof Class<?> && Tuple.class.isAssignableFrom((Class<?>)t)) || (t instanceof ParameterizedType && Tuple.class.isAssignableFrom((Class<?>)((ParameterizedType)t).getRawType()))) {
    Type curT=t;
    if (curT instanceof Class<?> && ((Class<?>)curT).equals(Tuple.class)) {
      throw new InvalidTypesException(""String_Node_Str"");
    }
    while (!(curT instanceof ParameterizedType && ((Class<?>)((ParameterizedType)curT).getRawType()).getSuperclass().equals(Tuple.class)) && !(curT instanceof Class<?> && ((Class<?>)curT).getSuperclass().equals(Tuple.class))) {
      typeHierarchy.add(curT);
      if (curT instanceof ParameterizedType) {
        curT=((Class<?>)((ParameterizedType)curT).getRawType()).getGenericSuperclass();
      }
 else {
        curT=((Class<?>)curT).getGenericSuperclass();
      }
    }
    if (curT instanceof Class<?>) {
      throw new InvalidTypesException(""String_Node_Str"");
    }
    ParameterizedType tupleChild=(ParameterizedType)curT;
    Type[] subtypes=new Type[tupleChild.getActualTypeArguments().length];
    for (int i=0; i < subtypes.length; i++) {
      if (tupleChild.getActualTypeArguments()[i] instanceof TypeVariable<?>) {
        Type varContent=materializeTypeVariable(typeHierarchy,(TypeVariable<?>)tupleChild.getActualTypeArguments()[i]);
        if (varContent == null) {
          subtypes[i]=tupleChild.getActualTypeArguments()[i];
        }
 else {
          subtypes[i]=varContent;
        }
      }
 else {
        subtypes[i]=tupleChild.getActualTypeArguments()[i];
      }
    }
    TypeInformation<?>[] tupleSubTypes=new TypeInformation<?>[subtypes.length];
    for (int i=0; i < subtypes.length; i++) {
      if (subtypes[i] instanceof TypeVariable<?>) {
        ParameterizedType immediateBaseChild=(ParameterizedType)typeHierarchy.get(typeHierarchy.size() - 1);
        tupleSubTypes[i]=createTypeInfoWithImmediateBaseChildInput(immediateBaseChild,(TypeVariable<?>)subtypes[i],in1Type,in2Type);
        if (tupleSubTypes[i] == null) {
          throw new InvalidTypesException(""String_Node_Str"" + ((TypeVariable<?>)t).getName() + ""String_Node_Str""+ ((TypeVariable<?>)t).getGenericDeclaration()+ ""String_Node_Str"");
        }
      }
 else {
        tupleSubTypes[i]=createTypeInfoWithTypeHierarchy(new ArrayList<Type>(typeHierarchy),subtypes[i],in1Type,in2Type);
      }
    }
    if (t instanceof Class<?>) {
      return new TupleTypeInfo(((Class<? extends Tuple>)t),tupleSubTypes);
    }
 else     if (t instanceof ParameterizedType) {
      return new TupleTypeInfo(((Class<? extends Tuple>)((ParameterizedType)t).getRawType()),tupleSubTypes);
    }
  }
 else   if (t instanceof TypeVariable) {
    Type typeVar=materializeTypeVariable(typeHierarchy,(TypeVariable<?>)t);
    if (typeVar != null) {
      return createTypeInfoWithTypeHierarchy(typeHierarchy,typeVar,in1Type,in2Type);
    }
 else {
      ParameterizedType immediateBaseChild=(ParameterizedType)typeHierarchy.get(typeHierarchy.size() - 1);
      TypeInformation<OUT> typeInfo=(TypeInformation<OUT>)createTypeInfoWithImmediateBaseChildInput(immediateBaseChild,(TypeVariable<?>)t,in1Type,in2Type);
      if (typeInfo != null) {
        return typeInfo;
      }
 else {
        throw new InvalidTypesException(""String_Node_Str"" + ((TypeVariable<?>)t).getName() + ""String_Node_Str""+ ((TypeVariable<?>)t).getGenericDeclaration()+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str"");
      }
    }
  }
 else   if (t instanceof GenericArrayType) {
    GenericArrayType genericArray=(GenericArrayType)t;
    TypeInformation<?> componentInfo=createTypeInfoWithTypeHierarchy(typeHierarchy,genericArray.getGenericComponentType(),in1Type,in2Type);
    return ObjectArrayTypeInfo.getInfoFor(t,componentInfo);
  }
 else   if (t instanceof ParameterizedType) {
    return getForClass((Class<OUT>)((ParameterizedType)t).getRawType());
  }
 else   if (t instanceof Class) {
    return getForClass((Class<OUT>)t);
  }
  throw new InvalidTypesException(""String_Node_Str"");
}","@SuppressWarnings({""String_Node_Str"",""String_Node_Str""}) private static <IN1,IN2,OUT>TypeInformation<OUT> createTypeInfoWithTypeHierarchy(ArrayList<Type> typeHierarchy,Type t,TypeInformation<IN1> in1Type,TypeInformation<IN2> in2Type){
  if ((t instanceof Class<?> && Tuple.class.isAssignableFrom((Class<?>)t)) || (t instanceof ParameterizedType && Tuple.class.isAssignableFrom((Class<?>)((ParameterizedType)t).getRawType()))) {
    Type curT=t;
    if (curT instanceof Class<?> && ((Class<?>)curT).equals(Tuple.class)) {
      throw new InvalidTypesException(""String_Node_Str"");
    }
    while (!(curT instanceof ParameterizedType && ((Class<?>)((ParameterizedType)curT).getRawType()).getSuperclass().equals(Tuple.class)) && !(curT instanceof Class<?> && ((Class<?>)curT).getSuperclass().equals(Tuple.class))) {
      typeHierarchy.add(curT);
      if (curT instanceof ParameterizedType) {
        curT=((Class<?>)((ParameterizedType)curT).getRawType()).getGenericSuperclass();
      }
 else {
        curT=((Class<?>)curT).getGenericSuperclass();
      }
    }
    if (curT instanceof Class<?>) {
      throw new InvalidTypesException(""String_Node_Str"");
    }
    ParameterizedType tupleChild=(ParameterizedType)curT;
    Type[] subtypes=new Type[tupleChild.getActualTypeArguments().length];
    for (int i=0; i < subtypes.length; i++) {
      if (tupleChild.getActualTypeArguments()[i] instanceof TypeVariable<?>) {
        Type varContent=materializeTypeVariable(typeHierarchy,(TypeVariable<?>)tupleChild.getActualTypeArguments()[i]);
        if (varContent == null) {
          subtypes[i]=tupleChild.getActualTypeArguments()[i];
        }
 else {
          subtypes[i]=varContent;
        }
      }
 else {
        subtypes[i]=tupleChild.getActualTypeArguments()[i];
      }
    }
    TypeInformation<?>[] tupleSubTypes=new TypeInformation<?>[subtypes.length];
    for (int i=0; i < subtypes.length; i++) {
      if (subtypes[i] instanceof TypeVariable<?>) {
        ParameterizedType immediateBaseChild=(ParameterizedType)typeHierarchy.get(typeHierarchy.size() - 1);
        tupleSubTypes[i]=createTypeInfoWithImmediateBaseChildInput(immediateBaseChild,(TypeVariable<?>)subtypes[i],in1Type,in2Type);
        if (tupleSubTypes[i] == null) {
          throw new InvalidTypesException(""String_Node_Str"" + ((TypeVariable<?>)subtypes[i]).getName() + ""String_Node_Str""+ ((TypeVariable<?>)subtypes[i]).getGenericDeclaration()+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str"");
        }
      }
 else {
        tupleSubTypes[i]=createTypeInfoWithTypeHierarchy(new ArrayList<Type>(typeHierarchy),subtypes[i],in1Type,in2Type);
      }
    }
    if (t instanceof Class<?>) {
      return new TupleTypeInfo(((Class<? extends Tuple>)t),tupleSubTypes);
    }
 else     if (t instanceof ParameterizedType) {
      return new TupleTypeInfo(((Class<? extends Tuple>)((ParameterizedType)t).getRawType()),tupleSubTypes);
    }
  }
 else   if (t instanceof TypeVariable) {
    Type typeVar=materializeTypeVariable(typeHierarchy,(TypeVariable<?>)t);
    if (typeVar != null) {
      return createTypeInfoWithTypeHierarchy(typeHierarchy,typeVar,in1Type,in2Type);
    }
 else {
      ParameterizedType immediateBaseChild=(ParameterizedType)typeHierarchy.get(typeHierarchy.size() - 1);
      TypeInformation<OUT> typeInfo=(TypeInformation<OUT>)createTypeInfoWithImmediateBaseChildInput(immediateBaseChild,(TypeVariable<?>)t,in1Type,in2Type);
      if (typeInfo != null) {
        return typeInfo;
      }
 else {
        throw new InvalidTypesException(""String_Node_Str"" + ((TypeVariable<?>)t).getName() + ""String_Node_Str""+ ((TypeVariable<?>)t).getGenericDeclaration()+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str"");
      }
    }
  }
 else   if (t instanceof GenericArrayType) {
    GenericArrayType genericArray=(GenericArrayType)t;
    TypeInformation<?> componentInfo=createTypeInfoWithTypeHierarchy(typeHierarchy,genericArray.getGenericComponentType(),in1Type,in2Type);
    return ObjectArrayTypeInfo.getInfoFor(t,componentInfo);
  }
 else   if (t instanceof ParameterizedType) {
    return getForClass((Class<OUT>)((ParameterizedType)t).getRawType());
  }
 else   if (t instanceof Class) {
    return getForClass((Class<OUT>)t);
  }
  throw new InvalidTypesException(""String_Node_Str"");
}",0.9927400468384074
55049,"@Override public void flatMap(Tuple3<Tuple1<String>,Tuple1<Integer>,Tuple2<Long,Long>> value,Collector<Tuple3<Tuple1<String>,Tuple1<Integer>,Tuple2<Long,Long>>> out) throws Exception {
}","@Override public void flatMap(Tuple2<A,B> value,Collector<Tuple2<C,D>> out) throws Exception {
}",0.6524822695035462
55050,"public FSDataInputStreamWrapper(final FSDataInputStream stream,final int len){
  this.stream=stream;
  this.len=len;
  this.pos=0;
}","public FSDataInputStreamWrapper(FSDataInputStream stream,long len){
  this.stream=stream;
  this.len=len;
  this.pos=0;
}",0.932806324110672
55051,"/** 
 * Applies a GroupReduce transformation on a non-grouped   {@link DataSet}.<br/> The transformation calls a   {@link GroupReduceFunction} once with the full DataSet.The GroupReduceFunction can iterate over all elements of the DataSet and emit any number of output elements including none.
 * @param reducer The GroupReduceFunction that is applied on the DataSet.
 * @return A GroupReduceOperator that represents the reduced DataSet.
 * @see GroupReduceFunction
 * @see GroupReduceOperator
 * @see DataSet
 */
public <R>ReduceGroupOperator<T,R> reduceGroup(GroupReduceFunction<T,R> reducer){
  return new ReduceGroupOperator<T,R>(this,reducer);
}","/** 
 * Applies a GroupReduce transformation on a non-grouped   {@link DataSet}.<br/> The transformation calls a   {@link GroupReduceFunction} once with the full DataSet.The GroupReduceFunction can iterate over all elements of the DataSet and emit any number of output elements including none.
 * @param reducer The GroupReduceFunction that is applied on the DataSet.
 * @return A GroupReduceOperator that represents the reduced DataSet.
 * @see GroupReduceFunction
 * @see GroupReduceOperator
 * @see DataSet
 */
public <R>ReduceGroupOperator<T,R> reduceGroup(GroupReduceFunction<T,R> reducer){
  if (reducer == null) {
    throw new NullPointerException(""String_Node_Str"");
  }
  return new ReduceGroupOperator<T,R>(this,reducer);
}",0.9393063583815028
55052,"/** 
 * Applies a Map transformation on a   {@link DataSet}.<br/> The transformation calls a   {@link MapFunction} for each element of the DataSet.Each MapFunction call returns exactly one element.
 * @param mapper The MapFunction that is called for each element of the DataSet.
 * @return A MapOperator that represents the transformed DataSet.
 * @see MapFunction
 * @see MapOperator
 * @see DataSet
 */
public <R>MapOperator<T,R> map(MapFunction<T,R> mapper){
  return new MapOperator<T,R>(this,mapper);
}","/** 
 * Applies a Map transformation on a   {@link DataSet}.<br/> The transformation calls a   {@link MapFunction} for each element of the DataSet.Each MapFunction call returns exactly one element.
 * @param mapper The MapFunction that is called for each element of the DataSet.
 * @return A MapOperator that represents the transformed DataSet.
 * @see MapFunction
 * @see MapOperator
 * @see DataSet
 */
public <R>MapOperator<T,R> map(MapFunction<T,R> mapper){
  if (mapper == null) {
    throw new NullPointerException(""String_Node_Str"");
  }
  return new MapOperator<T,R>(this,mapper);
}",0.9243391066545124
55053,"/** 
 * Applies a Reduce transformation on a non-grouped   {@link DataSet}.<br/> The transformation consecutively calls a   {@link ReduceFunction} until only a single element remains which is the result of the transformation. A ReduceFunction combines two elements into one new element of the same type.
 * @param reducer The ReduceFunction that is applied on the DataSet.
 * @return A ReduceOperator that represents the reduced DataSet.
 * @see ReduceFunction
 * @see ReduceOperator
 * @see DataSet
 */
public ReduceOperator<T> reduce(ReduceFunction<T> reducer){
  return new ReduceOperator<T>(this,reducer);
}","/** 
 * Applies a Reduce transformation on a non-grouped   {@link DataSet}.<br/> The transformation consecutively calls a   {@link ReduceFunction} until only a single element remains which is the result of the transformation. A ReduceFunction combines two elements into one new element of the same type.
 * @param reducer The ReduceFunction that is applied on the DataSet.
 * @return A ReduceOperator that represents the reduced DataSet.
 * @see ReduceFunction
 * @see ReduceOperator
 * @see DataSet
 */
public ReduceOperator<T> reduce(ReduceFunction<T> reducer){
  if (reducer == null) {
    throw new NullPointerException(""String_Node_Str"");
  }
  return new ReduceOperator<T>(this,reducer);
}",0.9356814701378254
55054,"/** 
 * Applies a FlatMap transformation on a   {@link DataSet}.<br/> The transformation calls a   {@link FlatMapFunction} for each element of the DataSet.Each FlatMapFunction call can return any number of elements including none.
 * @param flatMapper The FlatMapFunction that is called for each element of the DataSet. 
 * @return A FlatMapOperator that represents the transformed DataSet.
 * @see FlatMapFunction
 * @see FlatMapOperator
 * @see DataSet
 */
public <R>FlatMapOperator<T,R> flatMap(FlatMapFunction<T,R> flatMapper){
  return new FlatMapOperator<T,R>(this,flatMapper);
}","/** 
 * Applies a FlatMap transformation on a   {@link DataSet}.<br/> The transformation calls a   {@link FlatMapFunction} for each element of the DataSet.Each FlatMapFunction call can return any number of elements including none.
 * @param flatMapper The FlatMapFunction that is called for each element of the DataSet. 
 * @return A FlatMapOperator that represents the transformed DataSet.
 * @see FlatMapFunction
 * @see FlatMapOperator
 * @see DataSet
 */
public <R>FlatMapOperator<T,R> flatMap(FlatMapFunction<T,R> flatMapper){
  if (flatMapper == null) {
    throw new NullPointerException(""String_Node_Str"");
  }
  return new FlatMapOperator<T,R>(this,flatMapper);
}",0.9307875894988068
55055,"/** 
 * Applies a Filter transformation on a   {@link DataSet}.<br/> The transformation calls a   {@link FilterFunction} for each element of the DataSet and retains only those element for which the function returns true. Elements for  which the function returns false are filtered. 
 * @param filter The FilterFunction that is called for each element of the DataSet.
 * @return A FilterOperator that represents the filtered DataSet.
 * @see FilterFunction
 * @see FilterOperator
 * @see DataSet
 */
public FilterOperator<T> filter(FilterFunction<T> filter){
  return new FilterOperator<T>(this,filter);
}","/** 
 * Applies a Filter transformation on a   {@link DataSet}.<br/> The transformation calls a   {@link FilterFunction} for each element of the DataSet and retains only those element for which the function returns true. Elements for  which the function returns false are filtered. 
 * @param filter The FilterFunction that is called for each element of the DataSet.
 * @return A FilterOperator that represents the filtered DataSet.
 * @see FilterFunction
 * @see FilterOperator
 * @see DataSet
 */
public FilterOperator<T> filter(FilterFunction<T> filter){
  if (filter == null) {
    throw new NullPointerException(""String_Node_Str"");
  }
  return new FilterOperator<T>(this,filter);
}",0.935708752904725
55056,"/** 
 * Finalizes a CoGroup transformation by applying a   {@link CoGroupFunction} to groups of elements with identical keys.<br/>Each CoGroupFunction call returns an arbitrary number of keys. 
 * @param function The CoGroupFunction that is called for all groups of elements with identical keys.
 * @return An CoGroupOperator that represents the co-grouped result DataSet.
 * @see CoGroupFunction
 * @see DataSet
 */
public <R>CoGroupOperator<I1,I2,R> with(CoGroupFunction<I1,I2,R> function){
  TypeInformation<R> returnType=TypeExtractor.getCoGroupReturnTypes(function,input1.getType(),input2.getType());
  return new CoGroupOperator<I1,I2,R>(input1,input2,keys1,keys2,function,returnType);
}","/** 
 * Finalizes a CoGroup transformation by applying a   {@link CoGroupFunction} to groups of elements with identical keys.<br/>Each CoGroupFunction call returns an arbitrary number of keys. 
 * @param function The CoGroupFunction that is called for all groups of elements with identical keys.
 * @return An CoGroupOperator that represents the co-grouped result DataSet.
 * @see CoGroupFunction
 * @see DataSet
 */
public <R>CoGroupOperator<I1,I2,R> with(CoGroupFunction<I1,I2,R> function){
  if (function == null) {
    throw new NullPointerException(""String_Node_Str"");
  }
  TypeInformation<R> returnType=TypeExtractor.getCoGroupReturnTypes(function,input1.getType(),input2.getType());
  return new CoGroupOperator<I1,I2,R>(input1,input2,keys1,keys2,function,returnType);
}",0.9422161794697484
55057,"/** 
 * Finalizes a Cross transformation by applying a   {@link CrossFunction} to each pair of crossed elements.<br/>Each CrossFunction call returns exactly one element. 
 * @param function The CrossFunction that is called for each pair of crossed elements.
 * @return An CrossOperator that represents the crossed result DataSet
 * @see CrossFunction
 * @see DataSet
 */
public <R>CrossOperator<I1,I2,R> with(CrossFunction<I1,I2,R> function){
  TypeInformation<R> returnType=TypeExtractor.getCrossReturnTypes(function,input1.getType(),input2.getType());
  return new CrossOperator<I1,I2,R>(input1,input2,function,returnType);
}","/** 
 * Finalizes a Cross transformation by applying a   {@link CrossFunction} to each pair of crossed elements.<br/>Each CrossFunction call returns exactly one element. 
 * @param function The CrossFunction that is called for each pair of crossed elements.
 * @return An CrossOperator that represents the crossed result DataSet
 * @see CrossFunction
 * @see DataSet
 */
public <R>CrossOperator<I1,I2,R> with(CrossFunction<I1,I2,R> function){
  if (function == null) {
    throw new NullPointerException(""String_Node_Str"");
  }
  TypeInformation<R> returnType=TypeExtractor.getCrossReturnTypes(function,input1.getType(),input2.getType());
  return new CrossOperator<I1,I2,R>(input1,input2,function,returnType);
}",0.936519790888723
55058,"public FilterOperator(DataSet<T> input,FilterFunction<T> function){
  super(input,input.getType());
  if (function == null) {
    throw new NullPointerException(""String_Node_Str"");
  }
  this.function=function;
  extractSemanticAnnotationsFromUdf(function.getClass());
}","public FilterOperator(DataSet<T> input,FilterFunction<T> function){
  super(input,input.getType());
  this.function=function;
  extractSemanticAnnotationsFromUdf(function.getClass());
}",0.8131868131868132
55059,"public FlatMapOperator(DataSet<IN> input,FlatMapFunction<IN,OUT> function){
  super(input,TypeExtractor.getFlatMapReturnTypes(function,input.getType()));
  if (function == null) {
    throw new NullPointerException(""String_Node_Str"");
  }
  this.function=function;
  extractSemanticAnnotationsFromUdf(function.getClass());
}","public FlatMapOperator(DataSet<IN> input,FlatMapFunction<IN,OUT> function){
  super(input,TypeExtractor.getFlatMapReturnTypes(function,input.getType()));
  this.function=function;
  extractSemanticAnnotationsFromUdf(function.getClass());
}",0.8490230905861457
55060,"/** 
 * Finalizes a Join transformation by applying a   {@link JoinFunction} to each pair of joined elements.<br/>Each JoinFunction call returns exactly one element. 
 * @param function The JoinFunction that is called for each pair of joined elements.
 * @return An EquiJoin that represents the joined result DataSet
 * @see JoinFunction
 * @see EquiJoin
 * @see DataSet
 */
public <R>EquiJoin<I1,I2,R> with(JoinFunction<I1,I2,R> function){
  TypeInformation<R> returnType=TypeExtractor.getJoinReturnTypes(function,getInput1Type(),getInput2Type());
  return new EquiJoin<I1,I2,R>(getInput1(),getInput2(),getKeys1(),getKeys2(),function,returnType,getJoinHint());
}","/** 
 * Finalizes a Join transformation by applying a   {@link JoinFunction} to each pair of joined elements.<br/>Each JoinFunction call returns exactly one element. 
 * @param function The JoinFunction that is called for each pair of joined elements.
 * @return An EquiJoin that represents the joined result DataSet
 * @see JoinFunction
 * @see EquiJoin
 * @see DataSet
 */
public <R>EquiJoin<I1,I2,R> with(JoinFunction<I1,I2,R> function){
  if (function == null) {
    throw new NullPointerException(""String_Node_Str"");
  }
  TypeInformation<R> returnType=TypeExtractor.getJoinReturnTypes(function,getInput1Type(),getInput2Type());
  return new EquiJoin<I1,I2,R>(getInput1(),getInput2(),getKeys1(),getKeys2(),function,returnType,getJoinHint());
}",0.9397590361445785
55061,"public MapOperator(DataSet<IN> input,MapFunction<IN,OUT> function){
  super(input,TypeExtractor.getMapReturnTypes(function,input.getType()));
  if (function == null) {
    throw new NullPointerException(""String_Node_Str"");
  }
  this.function=function;
  extractSemanticAnnotationsFromUdf(function.getClass());
}","public MapOperator(DataSet<IN> input,MapFunction<IN,OUT> function){
  super(input,TypeExtractor.getMapReturnTypes(function,input.getType()));
  this.function=function;
  extractSemanticAnnotationsFromUdf(function.getClass());
}",0.8423005565862709
55062,"/** 
 * Constructor for a grouped reduce.
 * @param input The grouped input to be processed group-wise by the groupReduce function.
 * @param function The user-defined GroupReduce function.
 */
public ReduceGroupOperator(Grouping<IN> input,GroupReduceFunction<IN,OUT> function){
  super(input != null ? input.getDataSet() : null,TypeExtractor.getGroupReduceReturnTypes(function,input.getDataSet().getType()));
  if (function == null) {
    throw new NullPointerException(""String_Node_Str"");
  }
  this.function=function;
  this.grouper=input;
  checkCombinability();
  extractSemanticAnnotationsFromUdf(function.getClass());
}","/** 
 * Constructor for a grouped reduce.
 * @param input The grouped input to be processed group-wise by the groupReduce function.
 * @param function The user-defined GroupReduce function.
 */
public ReduceGroupOperator(Grouping<IN> input,GroupReduceFunction<IN,OUT> function){
  super(input != null ? input.getDataSet() : null,TypeExtractor.getGroupReduceReturnTypes(function,input.getDataSet().getType()));
  this.function=function;
  this.grouper=input;
  checkCombinability();
  extractSemanticAnnotationsFromUdf(function.getClass());
}",0.9271636675235648
55063,"public ReduceOperator(Grouping<IN> input,ReduceFunction<IN> function){
  super(input.getDataSet(),input.getDataSet().getType());
  if (function == null) {
    throw new NullPointerException(""String_Node_Str"");
  }
  this.function=function;
  this.grouper=input;
  extractSemanticAnnotationsFromUdf(function.getClass());
}","public ReduceOperator(Grouping<IN> input,ReduceFunction<IN> function){
  super(input.getDataSet(),input.getDataSet().getType());
  this.function=function;
  this.grouper=input;
  extractSemanticAnnotationsFromUdf(function.getClass());
}",0.8473967684021544
55064,"/** 
 * Applies a GroupReduce transformation on a grouped and sorted   {@link DataSet}.<br/> The transformation calls a   {@link GroupReduceFunction} for each group of the DataSet.A GroupReduceFunction can iterate over all elements of a group and emit any number of output elements including none.
 * @param reducer The GroupReduceFunction that is applied on each group of the DataSet.
 * @return A GroupReduceOperator that represents the reduced DataSet.
 * @see GroupReduceFunction
 * @see GroupReduceOperator
 * @see DataSet
 */
public <R>ReduceGroupOperator<T,R> reduceGroup(GroupReduceFunction<T,R> reducer){
  return new ReduceGroupOperator<T,R>(this,reducer);
}","/** 
 * Applies a GroupReduce transformation on a grouped and sorted   {@link DataSet}.<br/> The transformation calls a   {@link GroupReduceFunction} for each group of the DataSet.A GroupReduceFunction can iterate over all elements of a group and emit any number of output elements including none.
 * @param reducer The GroupReduceFunction that is applied on each group of the DataSet.
 * @return A GroupReduceOperator that represents the reduced DataSet.
 * @see GroupReduceFunction
 * @see GroupReduceOperator
 * @see DataSet
 */
public <R>ReduceGroupOperator<T,R> reduceGroup(GroupReduceFunction<T,R> reducer){
  if (reducer == null) {
    throw new NullPointerException(""String_Node_Str"");
  }
  return new ReduceGroupOperator<T,R>(this,reducer);
}",0.9408450704225352
55065,"/** 
 * Applies a Reduce transformation on a grouped   {@link DataSet}.<br/> For each group, the transformation consecutively calls a   {@link ReduceFunction} until only a single element for each group remains.  A ReduceFunction combines two elements into one new element of the same type.
 * @param reducer The ReduceFunction that is applied on each group of the DataSet.
 * @return A ReduceOperator that represents the reduced DataSet.
 * @see ReduceFunction
 * @see ReduceOperator
 * @see DataSet
 */
public ReduceOperator<T> reduce(ReduceFunction<T> reducer){
  return new ReduceOperator<T>(this,reducer);
}","/** 
 * Applies a Reduce transformation on a grouped   {@link DataSet}.<br/> For each group, the transformation consecutively calls a   {@link ReduceFunction} until only a single element for each group remains.  A ReduceFunction combines two elements into one new element of the same type.
 * @param reducer The ReduceFunction that is applied on each group of the DataSet.
 * @return A ReduceOperator that represents the reduced DataSet.
 * @see ReduceFunction
 * @see ReduceOperator
 * @see DataSet
 */
public ReduceOperator<T> reduce(ReduceFunction<T> reducer){
  if (reducer == null) {
    throw new NullPointerException(""String_Node_Str"");
  }
  return new ReduceOperator<T>(this,reducer);
}",0.9356814701378254
55066,"/** 
 * Applies a GroupReduce transformation on a grouped   {@link DataSet}.<br/> The transformation calls a   {@link GroupReduceFunction} for each group of the DataSet.A GroupReduceFunction can iterate over all elements of a group and emit any number of output elements including none.
 * @param reducer The GroupReduceFunction that is applied on each group of the DataSet.
 * @return A GroupReduceOperator that represents the reduced DataSet.
 * @see GroupReduceFunction
 * @see GroupReduceOperator
 * @see DataSet
 */
public <R>ReduceGroupOperator<T,R> reduceGroup(GroupReduceFunction<T,R> reducer){
  return new ReduceGroupOperator<T,R>(this,reducer);
}","/** 
 * Applies a GroupReduce transformation on a grouped   {@link DataSet}.<br/> The transformation calls a   {@link GroupReduceFunction} for each group of the DataSet.A GroupReduceFunction can iterate over all elements of a group and emit any number of output elements including none.
 * @param reducer The GroupReduceFunction that is applied on each group of the DataSet.
 * @return A GroupReduceOperator that represents the reduced DataSet.
 * @see GroupReduceFunction
 * @see GroupReduceOperator
 * @see DataSet
 */
public <R>ReduceGroupOperator<T,R> reduceGroup(GroupReduceFunction<T,R> reducer){
  if (reducer == null) {
    throw new NullPointerException(""String_Node_Str"");
  }
  return new ReduceGroupOperator<T,R>(this,reducer);
}",0.9399141630901288
55067,"/** 
 * Compares two records in serialized from. The return value indicates the order of the two in the same way as defined by   {@link java.util.Comparator#compare(Object,Object)}. <p> This method may de-serialize the records or compare them directly based on their binary representation. 
 * @param firstSource The input view containing the first record.
 * @param secondSource The input view containing the second record.
 * @return An integer defining the oder among the objects in the same way as {@link Comparator#compare(Object,Object)}.
 * @throws IOException Thrown, if any of the input views raised an exception when reading the records.
 * @see java.util.Comparator#compare(Object,Object)
 */
public abstract int compare(DataInputView firstSource,DataInputView secondSource) throws IOException ;","/** 
 * Compares two records in serialized from. The return value indicates the order of the two in the same way as defined by   {@link java.util.Comparator#compare(Object,Object)}. <p> This method may de-serialize the records or compare them directly based on their binary representation. 
 * @param firstSource The input view containing the first record.
 * @param secondSource The input view containing the second record.
 * @return An integer defining the oder among the objects in the same way as {@link java.util.Comparator#compare(Object,Object)}.
 * @throws IOException Thrown, if any of the input views raised an exception when reading the records.
 * @see java.util.Comparator#compare(Object,Object)
 */
public abstract int compare(DataInputView firstSource,DataInputView secondSource) throws IOException ;",0.9938347718865598
55068,"@Override public TypeComparator<T> duplicate(){
  return new TupleLeadingFieldComparator<T,K>(comparator);
}","@Override public TypeComparator<T> duplicate(){
  return new TupleLeadingFieldComparator<T,K>(comparator.duplicate());
}",0.9473684210526316
55069,"/** 
 * Gets the solution set of the delta iteration. The solution set represents the state that is kept across iterations.
 * @return The solution set of the delta iteration.
 */
public DataSet<ST> getSolutionSet(){
  return solutionSetPlaceholder;
}","/** 
 * Gets the solution set of the delta iteration. The solution set represents the state that is kept across iterations.
 * @return The solution set of the delta iteration.
 */
public SolutionSetPlaceHolder<ST> getSolutionSet(){
  return solutionSetPlaceholder;
}",0.943907156673114
55070,"DeltaIteration(ExecutionEnvironment context,TypeInformation<ST> type,DataSet<ST> solutionSet,DataSet<WT> workset,Keys<ST> keys,int maxIterations){
  initialSolutionSet=solutionSet;
  initialWorkset=workset;
  solutionSetPlaceholder=new SolutionSetPlaceHolder(context,solutionSet.getType());
  worksetPlaceholder=new WorksetPlaceHolder(context,workset.getType());
  this.keys=keys;
  this.maxIterations=maxIterations;
}","DeltaIteration(ExecutionEnvironment context,TypeInformation<ST> type,DataSet<ST> solutionSet,DataSet<WT> workset,Keys<ST> keys,int maxIterations){
  initialSolutionSet=solutionSet;
  initialWorkset=workset;
  solutionSetPlaceholder=new SolutionSetPlaceHolder<ST>(context,solutionSet.getType());
  worksetPlaceholder=new WorksetPlaceHolder<WT>(context,workset.getType());
  this.keys=keys;
  this.maxIterations=maxIterations;
}",0.990521327014218
55071,"/** 
 * Gets the working set of the delta iteration. The working set is constructed by the previous iteration.
 * @return The working set of the delta iteration.
 */
public DataSet<WT> getWorkset(){
  return worksetPlaceholder;
}","/** 
 * Gets the working set of the delta iteration. The working set is constructed by the previous iteration.
 * @return The working set of the delta iteration.
 */
public WorksetPlaceHolder<WT> getWorkset(){
  return worksetPlaceholder;
}",0.9466950959488272
55072,"private <D,W>eu.stratosphere.api.common.operators.DeltaIteration translateDeltaIteration(DeltaIterationResultSet<D,W> iterationEnd){
  PlanDeltaIterationOperator<D,W> iterationOperator=new PlanDeltaIterationOperator<D,W>(iterationEnd.getKeyPositions(),""String_Node_Str"",iterationEnd.getType(),iterationEnd.getWorksetType());
  iterationOperator.setMaximumNumberOfIterations(iterationEnd.getMaxIterations());
  DeltaIteration<?,?> iterationHead=iterationEnd.getIterationHead();
  DeltaIteration<D,W>.SolutionSetPlaceHolder solutionSetPlaceHolder=(DeltaIteration<D,W>.SolutionSetPlaceHolder)iterationHead.getSolutionSet();
  DeltaIteration<D,W>.WorksetPlaceHolder worksetPlaceHolder=(DeltaIteration<D,W>.WorksetPlaceHolder)iterationHead.getWorkset();
  translated.put(solutionSetPlaceHolder,iterationOperator.getSolutionSet());
  translated.put(worksetPlaceHolder,iterationOperator.getWorkset());
  Operator translatedSolutionSet=translate(iterationEnd.getNextSolutionSet());
  Operator translatedWorkset=translate(iterationEnd.getNextWorkset());
  iterationOperator.setNextWorkset(translatedWorkset);
  iterationOperator.setSolutionSetDelta(translatedSolutionSet);
  iterationOperator.setInitialSolutionSet(translate(iterationHead.getInitialSolutionSet()));
  iterationOperator.setInitialWorkset(translate(iterationHead.getInitialWorkset()));
  return iterationOperator;
}","private <D,W>eu.stratosphere.api.common.operators.DeltaIteration translateDeltaIteration(DeltaIterationResultSet<D,W> iterationEnd){
  PlanDeltaIterationOperator<D,W> iterationOperator=new PlanDeltaIterationOperator<D,W>(iterationEnd.getKeyPositions(),""String_Node_Str"",iterationEnd.getType(),iterationEnd.getWorksetType());
  iterationOperator.setMaximumNumberOfIterations(iterationEnd.getMaxIterations());
  DeltaIteration<D,W> iterationHead=iterationEnd.getIterationHead();
  DeltaIteration.SolutionSetPlaceHolder<D> solutionSetPlaceHolder=iterationHead.getSolutionSet();
  DeltaIteration.WorksetPlaceHolder<W> worksetPlaceHolder=iterationHead.getWorkset();
  translated.put(solutionSetPlaceHolder,iterationOperator.getSolutionSet());
  translated.put(worksetPlaceHolder,iterationOperator.getWorkset());
  Operator translatedSolutionSet=translate(iterationEnd.getNextSolutionSet());
  Operator translatedWorkset=translate(iterationEnd.getNextWorkset());
  iterationOperator.setNextWorkset(translatedWorkset);
  iterationOperator.setSolutionSetDelta(translatedSolutionSet);
  iterationOperator.setInitialSolutionSet(translate(iterationHead.getInitialSolutionSet()));
  iterationOperator.setInitialWorkset(translate(iterationHead.getInitialWorkset()));
  return iterationOperator;
}",0.4152223059532781
55073,"protected void resetAllInputs() throws Exception {
  for (int i=0; i < this.localStrategies.length; i++) {
    if (this.localStrategies[i] != null) {
      this.localStrategies[i].close();
      this.localStrategies[i]=null;
    }
  }
  final MemoryManager memMan=getMemoryManager();
  final IOManager ioMan=getIOManager();
  for (int i=0; i < this.inputs.length; i++) {
    if (this.excludeFromReset[i]) {
      if (this.tempBarriers[i] != null) {
        this.tempBarriers[i].close();
        this.tempBarriers[i]=null;
      }
 else       if (this.resettableInputs[i] != null) {
        this.resettableInputs[i].close();
        this.resettableInputs[i]=null;
      }
    }
 else {
      this.inputs[i]=null;
      if (this.inputIsCached[i]) {
        if (this.tempBarriers[i] != null) {
          this.inputs[i]=this.tempBarriers[i].getIterator();
        }
 else         if (this.resettableInputs[i] != null) {
          this.resettableInputs[i].reset();
          this.inputs[i]=this.resettableInputs[i];
        }
 else {
          throw new RuntimeException(""String_Node_Str"");
        }
      }
 else {
        if (this.tempBarriers[i] != null) {
          this.tempBarriers[i].close();
        }
        initInputLocalStrategy(i);
        if (this.inputIsAsyncMaterialized[i]) {
          final int pages=this.materializationMemory[i];
          @SuppressWarnings({""String_Node_Str"",""String_Node_Str""}) TempBarrier<?> barrier=new TempBarrier(this,getInput(i),this.inputSerializers[i],memMan,ioMan,pages);
          barrier.startReading();
          this.tempBarriers[i]=barrier;
          this.inputs[i]=null;
        }
      }
    }
  }
}","protected void resetAllInputs() throws Exception {
  for (int i=0; i < this.localStrategies.length; i++) {
    if (this.localStrategies[i] != null) {
      this.localStrategies[i].close();
      this.localStrategies[i]=null;
    }
  }
  final MemoryManager memMan=getMemoryManager();
  final IOManager ioMan=getIOManager();
  for (int i=0; i < this.inputs.length; i++) {
    if (this.excludeFromReset[i]) {
      if (this.tempBarriers[i] != null) {
        this.tempBarriers[i].close();
        this.tempBarriers[i]=null;
      }
 else       if (this.resettableInputs[i] != null) {
        this.resettableInputs[i].close();
        this.resettableInputs[i]=null;
      }
    }
 else {
      this.inputs[i]=null;
      if (this.inputIsCached[i]) {
        if (this.tempBarriers[i] != null) {
          this.inputs[i]=this.tempBarriers[i].getIterator();
        }
 else         if (this.resettableInputs[i] != null) {
          this.resettableInputs[i].consumeAndCacheRemainingData();
          this.resettableInputs[i].reset();
          this.inputs[i]=this.resettableInputs[i];
        }
 else {
          throw new RuntimeException(""String_Node_Str"");
        }
      }
 else {
        if (this.tempBarriers[i] != null) {
          this.tempBarriers[i].close();
        }
        initInputLocalStrategy(i);
        if (this.inputIsAsyncMaterialized[i]) {
          final int pages=this.materializationMemory[i];
          @SuppressWarnings({""String_Node_Str"",""String_Node_Str""}) TempBarrier<?> barrier=new TempBarrier(this,getInput(i),this.inputSerializers[i],memMan,ioMan,pages);
          barrier.startReading();
          this.tempBarriers[i]=barrier;
          this.inputs[i]=null;
        }
      }
    }
  }
}",0.9800891530460624
55074,"@Override public String toString(){
  return ""String_Node_Str"" + (getDegreeOfParallelism() == -1 ? ""String_Node_Str"" : getDegreeOfParallelism()) + ""String_Node_Str""+ getIdString();
}","@Override public String toString(){
  return ""String_Node_Str"" + (getDegreeOfParallelism() == -1 ? ""String_Node_Str"" : getDegreeOfParallelism()) + ""String_Node_Str""+ getNumTaskManager()+ ""String_Node_Str""+ getIdString();
}",0.900990099009901
55075,"/** 
 * Writes the given double-precision floating-point value (64bit, 8 bytes) to the given position in the system's native byte order. This method offers the best speed for double writing and should be used unless a specific byte order is required. In most cases, it suffices to know that the byte order in which the value is written is the same as the one in which it is read  (such as transient storage in memory, or serialization for I/O and network), making this method the preferable choice.
 * @param index The position at which the memory will be written.
 * @param value The double value to be written.
 * @return This view itself.
 * @throws IndexOutOfBoundsException Thrown, if the index is negative, or larger then the segmentsize minus 8.
 */
public final void putDouble(int index,double value){
  putLong(index,Double.doubleToRawLongBits(value));
}","/** 
 * Writes the given double-precision floating-point value (64bit, 8 bytes) to the given position in the system's native byte order. This method offers the best speed for double writing and should be used unless a specific byte order is required. In most cases, it suffices to know that the byte order in which the value is written is the same as the one in which it is read  (such as transient storage in memory, or serialization for I/O and network), making this method the preferable choice.
 * @param index The position at which the memory will be written.
 * @param value The double value to be written.
 * @throws IndexOutOfBoundsException Thrown, if the index is negative, or larger then the segmentsize minus 8.
 */
public final void putDouble(int index,double value){
  putLong(index,Double.doubleToRawLongBits(value));
}",0.9829110194460812
55076,"/** 
 * Reads one byte at the given position and returns its boolean representation.
 * @param index The position from which the memory will be read.
 * @return The char value at the given position.
 * @throws IndexOutOfBoundsException Thrown, if the index is negative, or larger then the segmentsize minus 1.
 */
public final boolean getBoolean(int index){
  return this.memory[index] != 0;
}","/** 
 * Reads one byte at the given position and returns its boolean representation.
 * @param index The position from which the memory will be read.
 * @return The boolean value at the given position.
 * @throws IndexOutOfBoundsException Thrown, if the index is negative, or larger then the segmentsize minus 1.
 */
public final boolean getBoolean(int index){
  return this.memory[index] != 0;
}",0.9860583016476552
55077,"/** 
 * Writes one byte containing the byte value into this buffer at the given position.
 * @param index The position at which the memory will be written.
 * @param value The char value to be written.
 * @return This view itself.
 * @throws IndexOutOfBoundsException Thrown, if the index is negative, or larger then the segmentsize minus 1.
 */
public final void putBoolean(int index,boolean value){
  this.memory[index]=(byte)(value ? 1 : 0);
}","/** 
 * Writes one byte containing the byte value into this buffer at the given position.
 * @param index The position at which the memory will be written.
 * @param value The char value to be written.
 * @throws IndexOutOfBoundsException Thrown, if the index is negative, or larger then the segmentsize minus 1.
 */
public final void putBoolean(int index,boolean value){
  this.memory[index]=(byte)(value ? 1 : 0);
}",0.966396292004635
55078,"/** 
 * Writes two memory containing the given char value, in the current byte order, into this buffer at the given position.
 * @param index The position at which the memory will be written.
 * @param value The char value to be written.
 * @return This view itself.
 * @throws IndexOutOfBoundsException Thrown, if the index is negative, or larger then the segmentsize minus 2.
 */
public final void putChar(int index,char value){
  this.memory[index]=(byte)(value >> 8);
  this.memory[index + 1]=(byte)value;
}","/** 
 * Writes two memory containing the given char value, in the current byte order, into this buffer at the given position.
 * @param index The position at which the memory will be written.
 * @param value The char value to be written.
 * @throws IndexOutOfBoundsException Thrown, if the index is negative, or larger then the segmentsize minus 2.
 */
public final void putChar(int index,char value){
  this.memory[index]=(byte)(value >> 8);
  this.memory[index + 1]=(byte)value;
}",0.97079556898288
55079,"/** 
 * Used by system internally to merge the collected parts of an accumulator at the end of the job.
 * @param other reference to accumulator to merge in
 * @return Reference to this (for efficiency), after data from other weremerged in
 */
void merge(Accumulator<V,R> other);","/** 
 * Used by system internally to merge the collected parts of an accumulator at the end of the job.
 * @param other Reference to accumulator to merge in.
 */
void merge(Accumulator<V,R> other);",0.819327731092437
55080,"/** 
 * Adds the given value to the current aggregate.
 * @param value The value to add to the aggregate.
 */
public void aggregate(double element){
  sum+=element;
}","/** 
 * Adds the given value to the current aggregate.
 * @param value The value to add to the aggregate.
 */
public void aggregate(double value){
  sum+=value;
}",0.9390243902439024
55081,"/** 
 * Clears all previous broadcast inputs and binds the given inputs as broadcast variables of this operator.
 * @param inputs The <name, root> pairs to be set as broadcast inputs.
 */
public void setBroadcastVariables(Map<String,Operator> roots){
  this.broadcastInputs.clear();
  this.broadcastInputs.putAll(roots);
}","/** 
 * Clears all previous broadcast inputs and binds the given inputs as broadcast variables of this operator.
 * @param inputs The <name, root> pairs to be set as broadcast inputs.
 */
public void setBroadcastVariables(Map<String,Operator> inputs){
  this.broadcastInputs.clear();
  this.broadcastInputs.putAll(inputs);
}",0.978328173374613
55082,"/** 
 * Adds to the input the union of the given operators.
 * @param input The operator(s) to be unioned with the input.
 * @deprecated This method will be removed in future versions. Use the {@link Union} operator instead.
 */
@Deprecated public void addInput(Operator... inputs){
  Preconditions.checkNotNull(inputs,""String_Node_Str"");
  this.input=Operator.createUnionCascade(this.input,inputs);
}","/** 
 * Adds to the input the union of the given operators.
 * @param inputs The operator(s) to be unioned with the input.
 * @deprecated This method will be removed in future versions. Use the {@link Union} operator instead.
 */
@Deprecated public void addInput(Operator... inputs){
  Preconditions.checkNotNull(inputs,""String_Node_Str"");
  this.input=Operator.createUnionCascade(this.input,inputs);
}",0.9987546699875468
55083,"/** 
 * Adds a suffix to the final name in the path.
 * @param the suffix to be added
 * @return the new path including the suffix
 */
public Path suffix(String suffix){
  return new Path(getParent(),getName() + suffix);
}","/** 
 * Adds a suffix to the final name in the path.
 * @param suffix The suffix to be added
 * @return the new path including the suffix
 */
public Path suffix(String suffix){
  return new Path(getParent(),getName() + suffix);
}",0.9800443458980044
55084,"/** 
 * Creates a generic input split with the given split number.
 * @param number the number of the split
 */
public GenericInputSplit(int partitionNumber,int totalNumberOfPartitions){
  this.partitionNumber=partitionNumber;
  this.totalNumberOfPartitions=totalNumberOfPartitions;
}","/** 
 * Creates a generic input split with the given split number.
 * @param partitionNumber The number of the split's partition.
 * @param totalNumberOfPartitions The total number of the splits (partitions).
 */
public GenericInputSplit(int partitionNumber,int totalNumberOfPartitions){
  this.partitionNumber=partitionNumber;
  this.totalNumberOfPartitions=totalNumberOfPartitions;
}",0.7593423019431988
55085,"/** 
 * serialize write this object to out length uses zero-compressed encoding
 * @see Writable#writeTo(DataOutput)
 */
public void write(final DataOutput out) throws IOException {
  out.writeInt(this.length);
  out.write(this.bytes,0,this.length);
}","@Override public void write(final DataOutput out) throws IOException {
  out.writeInt(this.length);
  out.write(this.bytes,0,this.length);
}",0.690537084398977
55086,"/** 
 * Bulk put method. Copies   {@code numBytes} bytes from the given {@code ByteBuffer}, into this memory segment. The bytes will be read from the target buffer starting at the buffer's current position, and will be written to this memory segment starting at   {@code offset}. If this method attempts to read more bytes than the target byte buffer has remaining (with respect to   {@link ByteBuffer#remaining()}), this method will cause a   {@link BufferUnderflowException}.
 * @param offset The position where the bytes are started to be written to in this memory segment.
 * @param target The ByteBuffer to copy the bytes from.
 * @param numBytes The number of bytes to copy.
 * @throws IndexOutOfBoundsException If the offset is invalid, or the source buffer does notcontain the given number of bytes, or this segment does not have enough space for the bytes (counting from offset).
 */
public final void put(int offset,ByteBuffer source,int numBytes){
  source.get(this.memory,offset,numBytes);
}","/** 
 * Bulk put method. Copies   {@code numBytes} bytes from the given {@code ByteBuffer}, into this memory segment. The bytes will be read from the target buffer starting at the buffer's current position, and will be written to this memory segment starting at   {@code offset}. If this method attempts to read more bytes than the target byte buffer has remaining (with respect to   {@link ByteBuffer#remaining()}), this method will cause a   {@link BufferUnderflowException}.
 * @param offset The position where the bytes are started to be written to in this memory segment.
 * @param source The ByteBuffer to copy the bytes from.
 * @param numBytes The number of bytes to copy.
 * @throws IndexOutOfBoundsException If the offset is invalid, or the source buffer does notcontain the given number of bytes, or this segment does not have enough space for the bytes (counting from offset).
 */
public final void put(int offset,ByteBuffer source,int numBytes){
  source.get(this.memory,offset,numBytes);
}",0.9940179461615156
55087,"/** 
 * Creates a new memory segment of given size with the provided views.
 * @param size The size of the memory segment.
 * @param inputView The input view to use.
 * @param outputView The output view to use.
 */
public MemorySegment(byte[] memory){
  this.memory=memory;
}","/** 
 * Creates a new memory segment that represents the data in the given byte array.
 * @param memory The byte array that holds the data.
 */
public MemorySegment(byte[] memory){
  this.memory=memory;
}",0.5219206680584552
55088,"@SuppressWarnings(""String_Node_Str"") private ObjectArrayTypeInfo(Type arrayType,Type componentType){
  this.arrayType=arrayType;
  this.componentType=componentType;
  this.componentInfo=(TypeInformation<C>)TypeExtractor.createTypeInfo(componentType);
}","private ObjectArrayTypeInfo(Type arrayType,Type componentType,TypeInformation<C> componentInfo){
  this.arrayType=arrayType;
  this.componentType=componentType;
  this.componentInfo=componentInfo;
}",0.7155555555555555
55089,"@SuppressWarnings(""String_Node_Str"") public static <T,C>ObjectArrayTypeInfo<T,C> getInfoFor(Type type){
  if (type instanceof GenericArrayType) {
    GenericArrayType genericArray=(GenericArrayType)type;
    return new ObjectArrayTypeInfo<T,C>(type,genericArray.getGenericComponentType());
  }
 else   if (type instanceof Class<?> && ((Class<?>)type).isArray() && BasicTypeInfo.getInfoFor((Class<C>)type) == null) {
    Class<C> array=(Class<C>)type;
    return new ObjectArrayTypeInfo<T,C>(type,array.getComponentType());
  }
  throw new InvalidTypesException(""String_Node_Str"");
}","@SuppressWarnings(""String_Node_Str"") public static <T,C>ObjectArrayTypeInfo<T,C> getInfoFor(Type type){
  if (type instanceof Class<?> && ((Class<?>)type).isArray() && BasicTypeInfo.getInfoFor((Class<C>)type) == null) {
    Class<C> array=(Class<C>)type;
    return new ObjectArrayTypeInfo<T,C>(type,array.getComponentType());
  }
  throw new InvalidTypesException(""String_Node_Str"");
}",0.5847107438016529
55090,"@SuppressWarnings({""String_Node_Str"",""String_Node_Str""}) private static <IN1,IN2,OUT>TypeInformation<OUT> createTypeInfoWithTypeHierarchy(ArrayList<Type> typeHierarchy,Type t,TypeInformation<IN1> in1Type,TypeInformation<IN2> in2Type){
  if ((t instanceof Class<?> && Tuple.class.isAssignableFrom((Class<?>)t)) || (t instanceof ParameterizedType && Tuple.class.isAssignableFrom((Class<?>)((ParameterizedType)t).getRawType()))) {
    Type curT=t;
    if (curT instanceof Class<?> && ((Class<?>)curT).equals(Tuple.class)) {
      throw new InvalidTypesException(""String_Node_Str"");
    }
    while (!(curT instanceof ParameterizedType && ((Class<?>)((ParameterizedType)curT).getRawType()).getSuperclass().equals(Tuple.class)) && !(curT instanceof Class<?> && ((Class<?>)curT).getSuperclass().equals(Tuple.class))) {
      typeHierarchy.add(curT);
      if (curT instanceof ParameterizedType) {
        curT=((Class<?>)((ParameterizedType)curT).getRawType()).getGenericSuperclass();
      }
 else {
        curT=((Class<?>)curT).getGenericSuperclass();
      }
    }
    if (curT instanceof Class<?>) {
      throw new InvalidTypesException(""String_Node_Str"");
    }
    ParameterizedType tupleChild=(ParameterizedType)curT;
    Type[] subtypes=new Type[tupleChild.getActualTypeArguments().length];
    for (int i=0; i < subtypes.length; i++) {
      if (tupleChild.getActualTypeArguments()[i] instanceof TypeVariable<?>) {
        Type varContent=materializeTypeVariable(typeHierarchy,(TypeVariable<?>)tupleChild.getActualTypeArguments()[i]);
        if (varContent == null) {
          subtypes[i]=tupleChild.getActualTypeArguments()[i];
        }
 else {
          subtypes[i]=varContent;
        }
      }
 else {
        subtypes[i]=tupleChild.getActualTypeArguments()[i];
      }
    }
    TypeInformation<?>[] tupleSubTypes=new TypeInformation<?>[subtypes.length];
    for (int i=0; i < subtypes.length; i++) {
      if (subtypes[i] instanceof TypeVariable<?>) {
        ParameterizedType immediateBaseChild=(ParameterizedType)typeHierarchy.get(typeHierarchy.size() - 1);
        tupleSubTypes[i]=createTypeInfoWithImmediateBaseChildInput(immediateBaseChild,(TypeVariable<?>)subtypes[i],in1Type,in2Type);
        if (tupleSubTypes[i] == null) {
          throw new InvalidTypesException(""String_Node_Str"" + ((TypeVariable<?>)t).getName() + ""String_Node_Str""+ ((TypeVariable<?>)t).getGenericDeclaration()+ ""String_Node_Str"");
        }
      }
 else {
        tupleSubTypes[i]=createTypeInfoWithTypeHierarchy(typeHierarchy,subtypes[i],in1Type,in2Type);
      }
    }
    if (t instanceof Class<?>) {
      return new TupleTypeInfo(((Class<? extends Tuple>)t),tupleSubTypes);
    }
 else     if (t instanceof ParameterizedType) {
      return new TupleTypeInfo(((Class<? extends Tuple>)((ParameterizedType)t).getRawType()),tupleSubTypes);
    }
  }
 else   if (t instanceof TypeVariable) {
    Type typeVar=materializeTypeVariable(typeHierarchy,(TypeVariable<?>)t);
    if (typeVar != null) {
      return createTypeInfoWithTypeHierarchy(typeHierarchy,typeVar,in1Type,in2Type);
    }
 else {
      ParameterizedType immediateBaseChild=(ParameterizedType)typeHierarchy.get(typeHierarchy.size() - 1);
      TypeInformation<OUT> typeInfo=(TypeInformation<OUT>)createTypeInfoWithImmediateBaseChildInput(immediateBaseChild,(TypeVariable<?>)t,in1Type,in2Type);
      if (typeInfo != null) {
        return typeInfo;
      }
 else {
        throw new InvalidTypesException(""String_Node_Str"" + ((TypeVariable<?>)t).getName() + ""String_Node_Str""+ ((TypeVariable<?>)t).getGenericDeclaration()+ ""String_Node_Str"");
      }
    }
  }
 else   if (t instanceof GenericArrayType) {
    return ObjectArrayTypeInfo.getInfoFor(t);
  }
 else   if (t instanceof Class) {
    return getForClass((Class<OUT>)t);
  }
  throw new InvalidTypesException(""String_Node_Str"");
}","@SuppressWarnings({""String_Node_Str"",""String_Node_Str""}) private static <IN1,IN2,OUT>TypeInformation<OUT> createTypeInfoWithTypeHierarchy(ArrayList<Type> typeHierarchy,Type t,TypeInformation<IN1> in1Type,TypeInformation<IN2> in2Type){
  if ((t instanceof Class<?> && Tuple.class.isAssignableFrom((Class<?>)t)) || (t instanceof ParameterizedType && Tuple.class.isAssignableFrom((Class<?>)((ParameterizedType)t).getRawType()))) {
    Type curT=t;
    if (curT instanceof Class<?> && ((Class<?>)curT).equals(Tuple.class)) {
      throw new InvalidTypesException(""String_Node_Str"");
    }
    while (!(curT instanceof ParameterizedType && ((Class<?>)((ParameterizedType)curT).getRawType()).getSuperclass().equals(Tuple.class)) && !(curT instanceof Class<?> && ((Class<?>)curT).getSuperclass().equals(Tuple.class))) {
      typeHierarchy.add(curT);
      if (curT instanceof ParameterizedType) {
        curT=((Class<?>)((ParameterizedType)curT).getRawType()).getGenericSuperclass();
      }
 else {
        curT=((Class<?>)curT).getGenericSuperclass();
      }
    }
    if (curT instanceof Class<?>) {
      throw new InvalidTypesException(""String_Node_Str"");
    }
    ParameterizedType tupleChild=(ParameterizedType)curT;
    Type[] subtypes=new Type[tupleChild.getActualTypeArguments().length];
    for (int i=0; i < subtypes.length; i++) {
      if (tupleChild.getActualTypeArguments()[i] instanceof TypeVariable<?>) {
        Type varContent=materializeTypeVariable(typeHierarchy,(TypeVariable<?>)tupleChild.getActualTypeArguments()[i]);
        if (varContent == null) {
          subtypes[i]=tupleChild.getActualTypeArguments()[i];
        }
 else {
          subtypes[i]=varContent;
        }
      }
 else {
        subtypes[i]=tupleChild.getActualTypeArguments()[i];
      }
    }
    TypeInformation<?>[] tupleSubTypes=new TypeInformation<?>[subtypes.length];
    for (int i=0; i < subtypes.length; i++) {
      if (subtypes[i] instanceof TypeVariable<?>) {
        ParameterizedType immediateBaseChild=(ParameterizedType)typeHierarchy.get(typeHierarchy.size() - 1);
        tupleSubTypes[i]=createTypeInfoWithImmediateBaseChildInput(immediateBaseChild,(TypeVariable<?>)subtypes[i],in1Type,in2Type);
        if (tupleSubTypes[i] == null) {
          throw new InvalidTypesException(""String_Node_Str"" + ((TypeVariable<?>)t).getName() + ""String_Node_Str""+ ((TypeVariable<?>)t).getGenericDeclaration()+ ""String_Node_Str"");
        }
      }
 else {
        tupleSubTypes[i]=createTypeInfoWithTypeHierarchy(typeHierarchy,subtypes[i],in1Type,in2Type);
      }
    }
    if (t instanceof Class<?>) {
      return new TupleTypeInfo(((Class<? extends Tuple>)t),tupleSubTypes);
    }
 else     if (t instanceof ParameterizedType) {
      return new TupleTypeInfo(((Class<? extends Tuple>)((ParameterizedType)t).getRawType()),tupleSubTypes);
    }
  }
 else   if (t instanceof TypeVariable) {
    Type typeVar=materializeTypeVariable(typeHierarchy,(TypeVariable<?>)t);
    if (typeVar != null) {
      return createTypeInfoWithTypeHierarchy(typeHierarchy,typeVar,in1Type,in2Type);
    }
 else {
      ParameterizedType immediateBaseChild=(ParameterizedType)typeHierarchy.get(typeHierarchy.size() - 1);
      TypeInformation<OUT> typeInfo=(TypeInformation<OUT>)createTypeInfoWithImmediateBaseChildInput(immediateBaseChild,(TypeVariable<?>)t,in1Type,in2Type);
      if (typeInfo != null) {
        return typeInfo;
      }
 else {
        throw new InvalidTypesException(""String_Node_Str"" + ((TypeVariable<?>)t).getName() + ""String_Node_Str""+ ((TypeVariable<?>)t).getGenericDeclaration()+ ""String_Node_Str"");
      }
    }
  }
 else   if (t instanceof GenericArrayType) {
    GenericArrayType genericArray=(GenericArrayType)t;
    TypeInformation<?> componentInfo=createTypeInfoWithTypeHierarchy(typeHierarchy,genericArray.getGenericComponentType(),in1Type,in2Type);
    return ObjectArrayTypeInfo.getInfoFor(t,componentInfo);
  }
 else   if (t instanceof ParameterizedType) {
    return getForClass((Class<OUT>)((ParameterizedType)t).getRawType());
  }
 else   if (t instanceof Class) {
    return getForClass((Class<OUT>)t);
  }
  throw new InvalidTypesException(""String_Node_Str"");
}",0.9574203187250996
55091,"@Test public void testBasicArray(){
  CoGroupFunction<?,?,?> function=new CoGroupFunction<String,String,String[]>(){
    private static final long serialVersionUID=1L;
    @Override public void combineFirst(    Iterator<String> records,    Collector<String> out) throws Exception {
    }
    @Override public void combineSecond(    Iterator<String> records,    Collector<String> out) throws Exception {
    }
    @Override public void coGroup(    Iterator<String> first,    Iterator<String> second,    Collector<String[]> out) throws Exception {
    }
  }
;
  TypeInformation<?> ti=TypeExtractor.getCoGroupReturnTypes(function,null,null);
  Assert.assertFalse(ti.isBasicType());
  Assert.assertFalse(ti.isTupleType());
  Assert.assertTrue(ti instanceof BasicArrayTypeInfo);
  Assert.assertEquals(BasicArrayTypeInfo.STRING_ARRAY_TYPE_INFO,ti);
}","@Test public void testBasicArray(){
  CoGroupFunction<?,?,?> function=new CoGroupFunction<String,String,String[]>(){
    private static final long serialVersionUID=1L;
    @Override public void combineFirst(    Iterator<String> records,    Collector<String> out) throws Exception {
    }
    @Override public void combineSecond(    Iterator<String> records,    Collector<String> out) throws Exception {
    }
    @Override public void coGroup(    Iterator<String> first,    Iterator<String> second,    Collector<String[]> out) throws Exception {
    }
  }
;
  TypeInformation<?> ti=TypeExtractor.getCoGroupReturnTypes(function,null,null);
  Assert.assertFalse(ti.isBasicType());
  Assert.assertFalse(ti.isTupleType());
  Assert.assertTrue(ti instanceof BasicArrayTypeInfo<?,?> || ti instanceof ObjectArrayTypeInfo<?,?>);
  if (ti instanceof BasicArrayTypeInfo<?,?>) {
    Assert.assertEquals(BasicArrayTypeInfo.STRING_ARRAY_TYPE_INFO,ti);
  }
 else {
    Assert.assertEquals(BasicTypeInfo.STRING_TYPE_INFO,((ObjectArrayTypeInfo<?,?>)ti).getComponentInfo());
  }
}",0.8851599370739381
55092,"@Override public Tuple2<String,String>[] map(String value) throws Exception {
  return null;
}","@Override public MyObject<String> map(Boolean value) throws Exception {
  return null;
}",0.8241758241758241
55093,"@Override public NumberSequenceIterator[] split(int numPartitions){
  if (numPartitions < 1) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (numPartitions == 1) {
    return new NumberSequenceIterator[]{new NumberSequenceIterator(current,to)};
  }
  long elementsPerSplit;
  if (to - current >= 0) {
    elementsPerSplit=(to - current) / numPartitions;
  }
 else {
    final long halfDiff;
    if (current == Long.MIN_VALUE) {
      halfDiff=(Long.MAX_VALUE / 2 + 1) + to / 2;
    }
 else {
      long posFrom=-current;
      if (posFrom > to) {
        halfDiff=to + ((posFrom - to) / 2);
      }
 else {
        halfDiff=posFrom + ((to - posFrom) / 2);
      }
    }
    elementsPerSplit=halfDiff / numPartitions * 2;
  }
  if (elementsPerSplit < Long.MAX_VALUE) {
    long numWithExtra=-(elementsPerSplit * numPartitions) + to - current;
    if (numWithExtra > numPartitions) {
      elementsPerSplit++;
      numWithExtra-=numPartitions;
      if (numWithExtra > numPartitions) {
        throw new RuntimeException(""String_Node_Str"");
      }
    }
    NumberSequenceIterator[] iters=new NumberSequenceIterator[numPartitions];
    long curr=current;
    int i=0;
    for (; i < numWithExtra; i++) {
      long next=curr + elementsPerSplit + 1;
      iters[i]=new NumberSequenceIterator(curr,next);
      curr=next;
    }
    for (; i < numPartitions; i++) {
      long next=curr + elementsPerSplit;
      iters[i]=new NumberSequenceIterator(curr,next);
      curr=next;
    }
    return iters;
  }
 else {
    if (numPartitions != 2) {
      throw new RuntimeException(""String_Node_Str"");
    }
    return new NumberSequenceIterator[]{new NumberSequenceIterator(current,current + elementsPerSplit),new NumberSequenceIterator(current + elementsPerSplit,to)};
  }
}","@Override public NumberSequenceIterator[] split(int numPartitions){
  if (numPartitions < 1) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (numPartitions == 1) {
    return new NumberSequenceIterator[]{new NumberSequenceIterator(current,to)};
  }
  long elementsPerSplit;
  if (to - current + 1 >= 0) {
    elementsPerSplit=(to - current + 1) / numPartitions;
  }
 else {
    final long halfDiff;
    if (current == Long.MIN_VALUE) {
      halfDiff=(Long.MAX_VALUE / 2 + 1) + to / 2;
    }
 else {
      long posFrom=-current;
      if (posFrom > to) {
        halfDiff=to + ((posFrom - to) / 2);
      }
 else {
        halfDiff=posFrom + ((to - posFrom) / 2);
      }
    }
    elementsPerSplit=halfDiff / numPartitions * 2;
  }
  if (elementsPerSplit < Long.MAX_VALUE) {
    long numWithExtra=-(elementsPerSplit * numPartitions) + to - current + 1;
    if (numWithExtra > numPartitions) {
      elementsPerSplit++;
      numWithExtra-=numPartitions;
      if (numWithExtra > numPartitions) {
        throw new RuntimeException(""String_Node_Str"");
      }
    }
    NumberSequenceIterator[] iters=new NumberSequenceIterator[numPartitions];
    long curr=current;
    int i=0;
    for (; i < numWithExtra; i++) {
      long next=curr + elementsPerSplit + 1;
      iters[i]=new NumberSequenceIterator(curr,next - 1);
      curr=next;
    }
    for (; i < numPartitions; i++) {
      long next=curr + elementsPerSplit;
      iters[i]=new NumberSequenceIterator(curr,next - 1,true);
      curr=next;
    }
    return iters;
  }
 else {
    if (numPartitions != 2) {
      throw new RuntimeException(""String_Node_Str"");
    }
    return new NumberSequenceIterator[]{new NumberSequenceIterator(current,current + elementsPerSplit),new NumberSequenceIterator(current + elementsPerSplit,to)};
  }
}",0.9930651872399444
55094,"public NumberSequenceIterator(long from,long to){
  if (from > to)   throw new IllegalArgumentException(""String_Node_Str"");
  this.current=from;
  this.to=to;
}","/** 
 * Internal constructor to allow for empty iterators.
 * @param from
 * @param to
 * @param mark
 */
private NumberSequenceIterator(long from,long to,boolean mark){
  this.current=from;
  this.to=to;
}",0.1202185792349726
55095,"private static final void testSplitting(NumberSequenceIterator iter,int numSplits){
  NumberSequenceIterator[] splits=iter.split(numSplits);
  assertEquals(numSplits,splits.length);
  assertEquals(iter.getCurrent(),splits[0].getCurrent());
  assertEquals(iter.getTo(),splits[numSplits - 1].getTo());
  testMaxSplitDiff(splits);
}","private static final void testSplitting(NumberSequenceIterator iter,int numSplits){
  NumberSequenceIterator[] splits=iter.split(numSplits);
  assertEquals(numSplits,splits.length);
  assertEquals(iter.getCurrent(),splits[0].getCurrent());
  assertEquals(iter.getTo(),splits[numSplits - 1].getTo());
  for (int i=1; i < splits.length; i++) {
    assertEquals(splits[i - 1].getTo() + 1,splits[i].getCurrent());
  }
  testMaxSplitDiff(splits);
}",0.8523316062176166
55096,"private static final void testMaxSplitDiff(NumberSequenceIterator[] iters){
  long minSplitSize=Long.MAX_VALUE;
  long maxSplitSize=Long.MIN_VALUE;
  for (  NumberSequenceIterator iter : iters) {
    long diff=iter.getTo() - iter.getCurrent();
    if (diff < 0)     diff=Long.MAX_VALUE;
    minSplitSize=Math.min(minSplitSize,diff);
    maxSplitSize=Math.max(maxSplitSize,diff);
  }
  assertTrue(maxSplitSize == minSplitSize || maxSplitSize - 1 == minSplitSize);
}","private static final void testMaxSplitDiff(NumberSequenceIterator[] iters){
  long minSplitSize=Long.MAX_VALUE;
  long maxSplitSize=Long.MIN_VALUE;
  for (  NumberSequenceIterator iter : iters) {
    long diff;
    if (iter.getTo() < iter.getCurrent()) {
      diff=0;
    }
 else {
      diff=iter.getTo() - iter.getCurrent();
    }
    if (diff < 0)     diff=Long.MAX_VALUE;
    minSplitSize=Math.min(minSplitSize,diff);
    maxSplitSize=Math.max(maxSplitSize,diff);
  }
  assertTrue(maxSplitSize == minSplitSize || maxSplitSize - 1 == minSplitSize);
}",0.9096267190569745
55097,"@Override public String readRecord(String reusable,byte[] bytes,int offset,int numBytes){
  return new String(bytes,offset,numBytes,this.charset);
}","@Override public String readRecord(String reusable,byte[] bytes,int offset,int numBytes){
  if (this.getDelimiter() != null && this.getDelimiter().length == 1 && this.getDelimiter()[0] == NEW_LINE && offset + numBytes >= 1 && bytes[offset + numBytes - 1] == CARRIAGE_RETURN) {
    numBytes-=1;
  }
  return new String(bytes,offset,numBytes,this.charset);
}",0.5873015873015873
55098,"public Record readRecord(Record reuse,byte[] bytes,int offset,int numBytes){
  StringValue str=this.theString;
  if (this.ascii) {
    str.setValueAscii(bytes,offset,numBytes);
  }
 else {
    ByteBuffer byteWrapper=this.byteWrapper;
    if (bytes != byteWrapper.array()) {
      byteWrapper=ByteBuffer.wrap(bytes,0,bytes.length);
      this.byteWrapper=byteWrapper;
    }
    byteWrapper.limit(offset + numBytes);
    byteWrapper.position(offset);
    try {
      CharBuffer result=this.decoder.decode(byteWrapper);
      str.setValue(result);
    }
 catch (    CharacterCodingException e) {
      byte[] copy=new byte[numBytes];
      System.arraycopy(bytes,offset,copy,0,numBytes);
      LOG.warn(""String_Node_Str"" + Arrays.toString(copy),e);
      return null;
    }
  }
  reuse.clear();
  reuse.setField(this.pos,str);
  return reuse;
}","public Record readRecord(Record reuse,byte[] bytes,int offset,int numBytes){
  StringValue str=this.theString;
  if (this.getDelimiter() != null && this.getDelimiter().length == 1 && this.getDelimiter()[0] == NEW_LINE && offset + numBytes >= 1 && bytes[offset + numBytes - 1] == CARRIAGE_RETURN) {
    numBytes-=1;
  }
  if (this.ascii) {
    str.setValueAscii(bytes,offset,numBytes);
  }
 else {
    ByteBuffer byteWrapper=this.byteWrapper;
    if (bytes != byteWrapper.array()) {
      byteWrapper=ByteBuffer.wrap(bytes,0,bytes.length);
      this.byteWrapper=byteWrapper;
    }
    byteWrapper.limit(offset + numBytes);
    byteWrapper.position(offset);
    try {
      CharBuffer result=this.decoder.decode(byteWrapper);
      str.setValue(result);
    }
 catch (    CharacterCodingException e) {
      byte[] copy=new byte[numBytes];
      System.arraycopy(bytes,offset,copy,0,numBytes);
      LOG.warn(""String_Node_Str"" + Arrays.toString(copy),e);
      return null;
    }
  }
  reuse.clear();
  reuse.setField(this.pos,str);
  return reuse;
}",0.8899470899470899
55099,"/** 
 * Checks, whether the given number of bytes for a normalized suffice to determine the order of elements of the data type for which this comparator provides the comparison methods. For example, if the data type is ordered with respect to an integer value it contains, then this method would return true, if the number of key bytes was larger or equal to four.
 * @return True, if the given number of bytes for a normalized suffice to determine the order of elements,false otherwise.
 */
public abstract boolean isNormalizedKeyPrefixOnly(int keyBytes);","/** 
 * Checks, whether the given number of bytes for a normalized is only a prefix to determine the order of elements of the data type for which this comparator provides the comparison methods. For example, if the data type is ordered with respect to an integer value it contains, then this method would return true, if the number of key bytes is smaller than four.
 * @return True, if the given number of bytes is only a prefix,false otherwise.
 */
public abstract boolean isNormalizedKeyPrefixOnly(int keyBytes);",0.8739495798319328
55100,"/** 
 * Writes a given record to this sort buffer. The written record will be appended and take the last logical position.
 * @param record The record to be written.
 * @return True, if the record was successfully written, false, if the sort buffer was full.
 * @throws IOException Thrown, if an error occurred while serializing the record into the buffers.
 */
@Override public boolean write(T record) throws IOException {
  if (this.currentSortIndexOffset > this.lastIndexEntryOffset) {
    if (memoryAvailable()) {
      this.currentSortIndexSegment=nextMemorySegment();
      this.sortIndex.add(this.currentSortIndexSegment);
      this.currentSortIndexOffset=0;
      this.sortIndexBytes+=this.segmentSize;
    }
 else     return false;
  }
  this.currentSortIndexSegment.putLong(this.currentSortIndexOffset,this.currentDataBufferOffset);
  this.comparator.putNormalizedKey(record,this.currentSortIndexSegment,this.currentSortIndexOffset + OFFSET_LEN,this.numKeyBytes);
  try {
    this.serializer.serialize(record,this.recordCollector);
    this.currentSortIndexOffset+=this.indexEntrySize;
    this.currentDataBufferOffset=this.recordCollector.getCurrentOffset();
    this.numRecords++;
    return true;
  }
 catch (  EOFException eofex) {
    return false;
  }
}","/** 
 * Writes a given record to this sort buffer. The written record will be appended and take the last logical position.
 * @param record The record to be written.
 * @return True, if the record was successfully written, false, if the sort buffer was full.
 * @throws IOException Thrown, if an error occurred while serializing the record into the buffers.
 */
@Override public boolean write(T record) throws IOException {
  if (this.currentSortIndexOffset > this.lastIndexEntryOffset) {
    if (memoryAvailable()) {
      this.currentSortIndexSegment=nextMemorySegment();
      this.sortIndex.add(this.currentSortIndexSegment);
      this.currentSortIndexOffset=0;
      this.sortIndexBytes+=this.segmentSize;
    }
 else     return false;
  }
  this.currentSortIndexSegment.putLong(this.currentSortIndexOffset,this.currentDataBufferOffset);
  if (this.numKeyBytes != 0) {
    this.comparator.putNormalizedKey(record,this.currentSortIndexSegment,this.currentSortIndexOffset + OFFSET_LEN,this.numKeyBytes);
  }
  try {
    this.serializer.serialize(record,this.recordCollector);
    this.currentSortIndexOffset+=this.indexEntrySize;
    this.currentDataBufferOffset=this.recordCollector.getCurrentOffset();
    this.numRecords++;
    return true;
  }
 catch (  EOFException eofex) {
    return false;
  }
}",0.9856422196352348
55101,"@Override public List<PlanNode> getAlternativePlans(CostEstimator estimator){
  if (this.cachedPlans != null) {
    return this.cachedPlans;
  }
  SourcePlanNode candidate=new SourcePlanNode(this,""String_Node_Str"" + this.getPactContract().getName() + ""String_Node_Str"");
  candidate.updatePropertiesWithUniqueSets(getUniqueFields());
  final Costs costs=new Costs();
  if (FileInputFormat.class.isAssignableFrom(getPactContract().getFormatWrapper().getUserCodeObject().getClass()) && this.estimatedOutputSize >= 0) {
    estimator.addFileInputCost(this.estimatedOutputSize,costs);
  }
  candidate.setCosts(costs);
  List<PlanNode> plans=new ArrayList<PlanNode>(1);
  plans.add(candidate);
  this.cachedPlans=plans;
  return plans;
}","@Override public List<PlanNode> getAlternativePlans(CostEstimator estimator){
  if (this.cachedPlans != null) {
    return this.cachedPlans;
  }
  SourcePlanNode candidate=new SourcePlanNode(this,""String_Node_Str"" + this.getPactContract().getName() + ""String_Node_Str"");
  candidate.updatePropertiesWithUniqueSets(getUniqueFields());
  final Costs costs=new Costs();
  if (FileInputFormat.class.isAssignableFrom(getPactContract().getFormatWrapper().getUserCodeClass()) && this.estimatedOutputSize >= 0) {
    estimator.addFileInputCost(this.estimatedOutputSize,costs);
  }
  candidate.setCosts(costs);
  List<PlanNode> plans=new ArrayList<PlanNode>(1);
  plans.add(candidate);
  this.cachedPlans=plans;
  return plans;
}",0.9917355371900828
55102,"public void compareResultsByLinesInMemory(String expectedResultStr,String resultPath) throws Exception {
  ArrayList<String> list=new ArrayList<String>();
  readAllResultLines(list,resultPath);
  String[] result=(String[])list.toArray(new String[list.size()]);
  Arrays.sort(result);
  String[] expected=expectedResultStr.split(""String_Node_Str"");
  Arrays.sort(expected);
  Assert.assertEquals(""String_Node_Str"",expected.length,result.length);
  Assert.assertArrayEquals(expected,result);
}","public void compareResultsByLinesInMemory(String expectedResultStr,String resultPath) throws Exception {
  ArrayList<String> list=new ArrayList<String>();
  readAllResultLines(list,resultPath,false);
  String[] result=(String[])list.toArray(new String[list.size()]);
  Arrays.sort(result);
  String[] expected=expectedResultStr.split(""String_Node_Str"");
  Arrays.sort(expected);
  Assert.assertEquals(""String_Node_Str"",expected.length,result.length);
  Assert.assertArrayEquals(expected,result);
}",0.9939271255060728
55103,"public void readAllResultLines(List<String> target,String resultPath) throws IOException {
  for (  BufferedReader reader : getResultReader(resultPath)) {
    String s=null;
    while ((s=reader.readLine()) != null) {
      target.add(s);
    }
  }
}","public void readAllResultLines(List<String> target,String resultPath,boolean inOrderOfFiles) throws IOException {
  for (  BufferedReader reader : getResultReader(resultPath,inOrderOfFiles)) {
    String s=null;
    while ((s=reader.readLine()) != null) {
      target.add(s);
    }
  }
}",0.929368029739777
55104,"public BufferedReader[] getResultReader(String resultPath) throws IOException {
  File[] files=getAllInvolvedFiles(resultPath);
  BufferedReader[] readers=new BufferedReader[files.length];
  for (int i=0; i < files.length; i++) {
    readers[i]=new BufferedReader(new FileReader(files[i]));
  }
  return readers;
}","public BufferedReader[] getResultReader(String resultPath,boolean inOrderOfFiles) throws IOException {
  File[] files=getAllInvolvedFiles(resultPath);
  if (inOrderOfFiles) {
    Arrays.sort(files,new Comparator<File>(){
      @Override public int compare(      File o1,      File o2){
        try {
          int f1=Integer.parseInt(o1.getName());
          int f2=Integer.parseInt(o2.getName());
          return f1 < f2 ? -1 : (f1 > f2 ? 1 : 0);
        }
 catch (        NumberFormatException e) {
          throw new RuntimeException(""String_Node_Str"" + o1.getName() + ""String_Node_Str""+ o2.getName());
        }
      }
    }
);
  }
  BufferedReader[] readers=new BufferedReader[files.length];
  for (int i=0; i < files.length; i++) {
    readers[i]=new BufferedReader(new FileReader(files[i]));
  }
  return readers;
}",0.5513608428446005
55105,"@Override protected void postSubmit() throws Exception {
  Collections.sort(this.records);
  compareResultsByLinesInMemoryStrictOrder(this.records,this.resultPath);
}","@Override protected void postSubmit() throws Exception {
  compareResultsByLinesInMemoryWithStrictOrder(this.sortedRecords,this.resultPath);
}",0.8571428571428571
55106,"@Override protected void preSubmit() throws Exception {
  recordsPath=getFilesystemProvider().getTempDirPath() + ""String_Node_Str"";
  resultPath=getFilesystemProvider().getTempDirPath() + ""String_Node_Str"";
  records=new ArrayList<Integer>();
  Random rnd=new Random(1988);
  int numRecordsPerSplit=1000;
  getFilesystemProvider().createDir(recordsPath);
  int numSplits=4;
  for (int i=0; i < numSplits; i++) {
    StringBuilder sb=new StringBuilder(numSplits * 2);
    for (int j=0; j < numRecordsPerSplit; j++) {
      int number=rnd.nextInt();
      records.add(number);
      sb.append(number);
      sb.append('\n');
    }
    getFilesystemProvider().createFile(recordsPath + ""String_Node_Str"" + i+ ""String_Node_Str"",sb.toString());
    if (LOG.isDebugEnabled())     LOG.debug(""String_Node_Str"" + (i + 1) + ""String_Node_Str""+ sb.toString()+ ""String_Node_Str"");
  }
}","@Override protected void preSubmit() throws Exception {
  ArrayList<Integer> records=new ArrayList<Integer>();
  Random rnd=new Random(1988);
  StringBuilder sb=new StringBuilder(NUM_RECORDS * 7);
  for (int i=0; i < NUM_RECORDS; i++) {
    int number=rnd.nextInt();
    records.add(number);
    sb.append(number);
    sb.append('\n');
  }
  recordsPath=createTempFile(""String_Node_Str"",sb.toString());
  resultPath=getTempDirPath(""String_Node_Str"");
  Collections.sort(records);
  sb.setLength(0);
  for (  Integer i : records) {
    sb.append(i.intValue());
    sb.append('\n');
  }
  this.sortedRecords=sb.toString();
}",0.3319946452476573
55107,"@Override public void configure(Configuration config){
  super.configure(config);
  final String fieldDelimStr=config.getString(FIELD_DELIMITER_PARAMETER,null);
  if (fieldDelimStr != null) {
    if (fieldDelimStr.length() != 1) {
      throw new IllegalArgumentException(""String_Node_Str"" + ""String_Node_Str"");
    }
 else {
      setFieldDelim(fieldDelimStr.charAt(0));
    }
  }
  int numConfigFields=config.getInteger(NUM_FIELDS_PARAMETER,-1);
  if (numConfigFields != -1) {
    if (numConfigFields <= 0) {
      throw new IllegalConfigurationException(""String_Node_Str"");
    }
    if (getNumberOfNonNullFields() > 0) {
      throw new IllegalConfigurationException(""String_Node_Str"");
    }
    int[] textPosIdx=new int[numConfigFields];
    boolean anyTextPosSet=false;
    boolean allTextPosSet=true;
    int maxTextPos=-1;
    for (int i=0; i < numConfigFields; i++) {
      int pos=config.getInteger(TEXT_POSITION_PARAMETER_PREFIX + i,-1);
      if (pos == -1) {
        allTextPosSet=false;
        textPosIdx[i]=i;
        maxTextPos=i;
      }
 else {
        anyTextPosSet=true;
        textPosIdx[i]=pos;
        maxTextPos=pos > maxTextPos ? pos : maxTextPos;
      }
    }
    if (anyTextPosSet && !allTextPosSet) {
      throw new IllegalArgumentException(""String_Node_Str"" + ""String_Node_Str"");
    }
    @SuppressWarnings(""String_Node_Str"") Class<? extends Value>[] types=(Class<? extends Value>[])new Class[maxTextPos + 1];
    int[] targetPos=new int[maxTextPos + 1];
    for (int i=0; i < numConfigFields; i++) {
      int pos=textPosIdx[i];
      Class<? extends Value> clazz=config.getClass(FIELD_TYPE_PARAMETER_PREFIX + i,null).asSubclass(Value.class);
      if (clazz == null) {
        throw new IllegalConfigurationException(""String_Node_Str"" + ""String_Node_Str"" + i);
      }
      types[pos]=clazz;
      targetPos[pos]=i;
    }
    setFieldTypes(types);
    this.targetPositions=new int[numConfigFields];
    for (int i=0, k=0; i < targetPos.length; i++) {
      if (types[i] != null) {
        this.targetPositions[k++]=targetPos[i];
      }
    }
  }
 else {
    this.targetPositions=new int[getNumberOfNonNullFields()];
    for (int i=0; i < this.targetPositions.length; i++) {
      this.targetPositions[i]=i;
    }
  }
  if (getNumberOfNonNullFields() == 0) {
    throw new IllegalConfigurationException(""String_Node_Str"");
  }
}","@Override public void configure(Configuration config){
  super.configure(config);
  if (configured) {
    return;
  }
  final String fieldDelimStr=config.getString(FIELD_DELIMITER_PARAMETER,null);
  if (fieldDelimStr != null) {
    if (fieldDelimStr.length() != 1) {
      throw new IllegalArgumentException(""String_Node_Str"" + ""String_Node_Str"");
    }
 else {
      setFieldDelim(fieldDelimStr.charAt(0));
    }
  }
  int numConfigFields=config.getInteger(NUM_FIELDS_PARAMETER,-1);
  if (numConfigFields != -1) {
    if (numConfigFields <= 0) {
      throw new IllegalConfigurationException(""String_Node_Str"");
    }
    if (getNumberOfNonNullFields() > 0) {
      throw new IllegalConfigurationException(""String_Node_Str"");
    }
    int[] textPosIdx=new int[numConfigFields];
    boolean anyTextPosSet=false;
    boolean allTextPosSet=true;
    int maxTextPos=-1;
    for (int i=0; i < numConfigFields; i++) {
      int pos=config.getInteger(TEXT_POSITION_PARAMETER_PREFIX + i,-1);
      if (pos == -1) {
        allTextPosSet=false;
        textPosIdx[i]=i;
        maxTextPos=i;
      }
 else {
        anyTextPosSet=true;
        textPosIdx[i]=pos;
        maxTextPos=pos > maxTextPos ? pos : maxTextPos;
      }
    }
    if (anyTextPosSet && !allTextPosSet) {
      throw new IllegalArgumentException(""String_Node_Str"" + ""String_Node_Str"");
    }
    @SuppressWarnings(""String_Node_Str"") Class<? extends Value>[] types=(Class<? extends Value>[])new Class[maxTextPos + 1];
    int[] targetPos=new int[maxTextPos + 1];
    for (int i=0; i < numConfigFields; i++) {
      int pos=textPosIdx[i];
      Class<? extends Value> clazz=config.getClass(FIELD_TYPE_PARAMETER_PREFIX + i,null).asSubclass(Value.class);
      if (clazz == null) {
        throw new IllegalConfigurationException(""String_Node_Str"" + ""String_Node_Str"" + i);
      }
      types[pos]=clazz;
      targetPos[pos]=i;
    }
    setFieldTypes(types);
    this.targetPositions=new int[numConfigFields];
    for (int i=0, k=0; i < targetPos.length; i++) {
      if (types[i] != null) {
        this.targetPositions[k++]=targetPos[i];
      }
    }
  }
 else {
    if (this.targetPositions.length == 0) {
      this.targetPositions=new int[getNumberOfNonNullFields()];
      for (int i=0; i < this.targetPositions.length; i++) {
        this.targetPositions[i]=i;
      }
    }
  }
  if (getNumberOfNonNullFields() == 0) {
    throw new IllegalConfigurationException(""String_Node_Str"");
  }
  this.configured=true;
}",0.9756701030927836
55108,"@Override protected void preSubmit() throws Exception {
  orders1Path=getFilesystemProvider().getTempDirPath() + ""String_Node_Str"";
  orders2Path=getFilesystemProvider().getTempDirPath() + ""String_Node_Str"";
  partJoin1Path=getFilesystemProvider().getTempDirPath() + ""String_Node_Str"";
  partJoin2Path=getFilesystemProvider().getTempDirPath() + ""String_Node_Str"";
  lineitemsPath=getFilesystemProvider().getTempDirPath() + ""String_Node_Str"";
  resultPath=getFilesystemProvider().getTempDirPath() + ""String_Node_Str"";
  String[] splits=splitInputString(ORDERS1,'\n',4);
  getFilesystemProvider().createDir(orders1Path);
  for (int i=0; i < splits.length; i++) {
    getFilesystemProvider().createFile(orders1Path + ""String_Node_Str"" + i+ ""String_Node_Str"",splits[i]);
    LOG.debug(""String_Node_Str"" + (i + 1) + ""String_Node_Str""+ splits[i]+ ""String_Node_Str"");
  }
  splits=splitInputString(ORDERS2,'\n',4);
  getFilesystemProvider().createDir(orders2Path);
  for (int i=0; i < splits.length; i++) {
    getFilesystemProvider().createFile(orders2Path + ""String_Node_Str"" + i+ ""String_Node_Str"",splits[i]);
    LOG.debug(""String_Node_Str"" + (i + 1) + ""String_Node_Str""+ splits[i]+ ""String_Node_Str"");
  }
  splits=splitInputString(PART_JOIN_1,'\n',4);
  getFilesystemProvider().createDir(partJoin1Path);
  for (int i=0; i < splits.length; i++) {
    getFilesystemProvider().createFile(partJoin1Path + ""String_Node_Str"" + i+ ""String_Node_Str"",splits[i]);
    LOG.debug(""String_Node_Str"" + (i + 1) + ""String_Node_Str""+ splits[i]+ ""String_Node_Str"");
  }
  splits=splitInputString(PART_JOIN_2,'\n',4);
  getFilesystemProvider().createDir(partJoin2Path);
  for (int i=0; i < splits.length; i++) {
    getFilesystemProvider().createFile(partJoin2Path + ""String_Node_Str"" + i+ ""String_Node_Str"",splits[i]);
    LOG.debug(""String_Node_Str"" + (i + 1) + ""String_Node_Str""+ splits[i]+ ""String_Node_Str"");
  }
  splits=splitInputString(LINEITEMS,'\n',4);
  getFilesystemProvider().createDir(lineitemsPath);
  for (int i=0; i < splits.length; i++) {
    getFilesystemProvider().createFile(lineitemsPath + ""String_Node_Str"" + i+ ""String_Node_Str"",splits[i]);
    LOG.debug(""String_Node_Str"" + (i + 1) + ""String_Node_Str""+ splits[i]+ ""String_Node_Str"");
  }
}","@Override protected void preSubmit() throws Exception {
  orders1Path=createTempFile(""String_Node_Str"",ORDERS1);
  orders2Path=createTempFile(""String_Node_Str"",ORDERS2);
  partJoin1Path=createTempFile(""String_Node_Str"",PART_JOIN_1);
  partJoin2Path=createTempFile(""String_Node_Str"",PART_JOIN_2);
  lineitemsPath=createTempFile(""String_Node_Str"",LINEITEMS);
  resultPath=getTempDirPath(""String_Node_Str"");
}",0.1071698113207547
55109,"@Override public void setItemCount(long itemCount) throws IOException {
  writeVarLongCount(out,itemCount);
}","@Override public void setItemCount(long itemCount) throws IOException {
  if (itemCount > 0) {
    writeVarLongCount(out,itemCount);
  }
}",0.8825910931174089
55110,"@Test public void testObjects(){
  testObjectSerialization(new Book(976243875L,""String_Node_Str"",42));
{
    ArrayList<String> list=new ArrayList<String>();
    list.add(""String_Node_Str"");
    list.add(""String_Node_Str"");
    list.add(""String_Node_Str"");
    list.add(""String_Node_Str"");
    list.add(""String_Node_Str"");
    testObjectSerialization(new BookAuthor(976243875L,list,""String_Node_Str""));
  }
}","@Test public void testObjects(){
{
    testObjectSerialization(new Book(976243875L,""String_Node_Str"",42));
  }
{
    ArrayList<String> list=new ArrayList<String>();
    list.add(""String_Node_Str"");
    list.add(""String_Node_Str"");
    list.add(""String_Node_Str"");
    list.add(""String_Node_Str"");
    list.add(""String_Node_Str"");
    testObjectSerialization(new BookAuthor(976243875L,list,""String_Node_Str""));
  }
{
    ArrayList<String> list=new ArrayList<String>();
    testObjectSerialization(new BookAuthor(987654321L,list,""String_Node_Str""));
  }
}",0.8479166666666667
55111,"public static void main(String[] args) throws Exception {
  WordCountOptimized wc=new WordCountOptimized();
  Plan plan=wc.getPlan(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"");
  LocalExecutor.execute(plan);
  System.exit(0);
}","public static void main(String[] args) throws Exception {
  WordCountOptimized wc=new WordCountOptimized();
  Plan plan=wc.getPlan(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"");
  LocalExecutor.execute(plan);
}",0.9605263157894736
55112,"@Override public void run() throws Exception {
  final String brokerKey=brokerKey();
  final int workerIndex=getEnvironment().getIndexInSubtaskGroup();
  MutableHashTable<X,?> solutionSet=null;
  boolean waitForSolutionSetUpdate=config.getWaitForSolutionSetUpdate();
  boolean isWorksetIteration=config.getIsWorksetIteration();
  try {
    BlockingBackChannel backChannel=initBackChannel();
    SuperstepBarrier barrier=initSuperstepBarrier();
    SolutionSetUpdateBarrier solutionSetUpdateBarrier=null;
    feedbackDataInput=config.getIterationHeadPartialSolutionOrWorksetInputIndex();
    feedbackTypeSerializer=getInputSerializer(feedbackDataInput);
    excludeFromReset(feedbackDataInput);
    if (isWorksetIteration) {
      initialSolutionSetInput=config.getIterationHeadSolutionSetInputIndex();
      TypeSerializerFactory<X> solutionTypeSerializerFactory=config.getSolutionSetSerializer(userCodeClassLoader);
      solutionTypeSerializer=solutionTypeSerializerFactory.getSerializer();
      solutionSet=initHashTable();
      MutableObjectIterator<X> solutionSetInput=getInput(initialSolutionSetInput);
      readInitialSolutionSet(solutionSet,solutionSetInput);
      SolutionSetBroker.instance().handIn(brokerKey,solutionSet);
      if (waitForSolutionSetUpdate) {
        solutionSetUpdateBarrier=new SolutionSetUpdateBarrier();
        SolutionSetUpdateBarrierBroker.instance().handIn(brokerKey,solutionSetUpdateBarrier);
      }
    }
 else {
      initialSolutionSetInput=-1;
      @SuppressWarnings(""String_Node_Str"") TypeSerializer<X> solSer=(TypeSerializer<X>)feedbackTypeSerializer;
      solutionTypeSerializer=solSer;
    }
    aggregatorRegistry=new RuntimeAggregatorRegistry(config.getIterationAggregators());
    IterationAggregatorBroker.instance().handIn(brokerKey,aggregatorRegistry);
    DataInputView superstepResult=null;
    while (this.running && !terminationRequested()) {
      if (log.isInfoEnabled()) {
        log.info(formatLogString(""String_Node_Str"" + currentIteration() + ""String_Node_Str""));
      }
      barrier.setup();
      if (waitForSolutionSetUpdate) {
        solutionSetUpdateBarrier.setup();
      }
      if (!inFirstIteration()) {
        feedBackSuperstepResult(superstepResult);
      }
      super.run();
      sendEndOfSuperstepToAllIterationOutputs();
      if (waitForSolutionSetUpdate) {
        solutionSetUpdateBarrier.waitForSolutionSetUpdate();
      }
      superstepResult=backChannel.getReadEndAfterSuperstepEnded();
      if (log.isInfoEnabled()) {
        log.info(formatLogString(""String_Node_Str"" + currentIteration() + ""String_Node_Str""));
      }
      sendEventToSync(new WorkerDoneEvent(workerIndex,aggregatorRegistry.getAllAggregators()));
      if (log.isInfoEnabled()) {
        log.info(formatLogString(""String_Node_Str"" + currentIteration() + ""String_Node_Str""));
      }
      barrier.waitForOtherWorkers();
      if (barrier.terminationSignaled()) {
        if (log.isInfoEnabled()) {
          log.info(formatLogString(""String_Node_Str"" + currentIteration() + ""String_Node_Str""));
        }
        requestTermination();
      }
 else {
        incrementIterationCounter();
        String[] globalAggregateNames=barrier.getAggregatorNames();
        Value[] globalAggregates=barrier.getAggregates();
        aggregatorRegistry.updateGlobalAggregatesAndReset(globalAggregateNames,globalAggregates);
      }
    }
    if (log.isInfoEnabled()) {
      log.info(formatLogString(""String_Node_Str"" + currentIteration() + ""String_Node_Str""));
    }
    if (isWorksetIteration) {
      streamSolutionSetToFinalOutput(solutionSet);
    }
 else {
      streamOutFinalOutputBulk(new InputViewIterator<X>(superstepResult,this.solutionTypeSerializer));
    }
  }
  finally {
    IterationAggregatorBroker.instance().remove(brokerKey);
    BlockingBackChannelBroker.instance().remove(brokerKey);
    if (isWorksetIteration) {
      SolutionSetBroker.instance().remove(brokerKey);
      if (waitForSolutionSetUpdate) {
        SolutionSetUpdateBarrierBroker.instance().remove(brokerKey);
      }
    }
    if (solutionSet != null) {
      solutionSet.close();
      solutionSet=null;
    }
  }
}","@Override public void run() throws Exception {
  final String brokerKey=brokerKey();
  final int workerIndex=getEnvironment().getIndexInSubtaskGroup();
  MutableHashTable<X,?> solutionSet=null;
  boolean waitForSolutionSetUpdate=config.getWaitForSolutionSetUpdate();
  boolean isWorksetIteration=config.getIsWorksetIteration();
  try {
    BlockingBackChannel backChannel=initBackChannel();
    SuperstepBarrier barrier=initSuperstepBarrier();
    SolutionSetUpdateBarrier solutionSetUpdateBarrier=null;
    feedbackDataInput=config.getIterationHeadPartialSolutionOrWorksetInputIndex();
    feedbackTypeSerializer=getInputSerializer(feedbackDataInput);
    excludeFromReset(feedbackDataInput);
    if (isWorksetIteration) {
      initialSolutionSetInput=config.getIterationHeadSolutionSetInputIndex();
      TypeSerializerFactory<X> solutionTypeSerializerFactory=config.getSolutionSetSerializer(userCodeClassLoader);
      solutionTypeSerializer=solutionTypeSerializerFactory.getSerializer();
      solutionSet=initHashTable();
      @SuppressWarnings(""String_Node_Str"") MutableObjectIterator<X> solutionSetInput=(MutableObjectIterator<X>)createInputIterator(inputReaders[initialSolutionSetInput],solutionTypeSerializer);
      readInitialSolutionSet(solutionSet,solutionSetInput);
      SolutionSetBroker.instance().handIn(brokerKey,solutionSet);
      if (waitForSolutionSetUpdate) {
        solutionSetUpdateBarrier=new SolutionSetUpdateBarrier();
        SolutionSetUpdateBarrierBroker.instance().handIn(brokerKey,solutionSetUpdateBarrier);
      }
    }
 else {
      initialSolutionSetInput=-1;
      @SuppressWarnings(""String_Node_Str"") TypeSerializer<X> solSer=(TypeSerializer<X>)feedbackTypeSerializer;
      solutionTypeSerializer=solSer;
    }
    aggregatorRegistry=new RuntimeAggregatorRegistry(config.getIterationAggregators());
    IterationAggregatorBroker.instance().handIn(brokerKey,aggregatorRegistry);
    DataInputView superstepResult=null;
    while (this.running && !terminationRequested()) {
      if (log.isInfoEnabled()) {
        log.info(formatLogString(""String_Node_Str"" + currentIteration() + ""String_Node_Str""));
      }
      barrier.setup();
      if (waitForSolutionSetUpdate) {
        solutionSetUpdateBarrier.setup();
      }
      if (!inFirstIteration()) {
        feedBackSuperstepResult(superstepResult);
      }
      super.run();
      sendEndOfSuperstepToAllIterationOutputs();
      if (waitForSolutionSetUpdate) {
        solutionSetUpdateBarrier.waitForSolutionSetUpdate();
      }
      superstepResult=backChannel.getReadEndAfterSuperstepEnded();
      if (log.isInfoEnabled()) {
        log.info(formatLogString(""String_Node_Str"" + currentIteration() + ""String_Node_Str""));
      }
      sendEventToSync(new WorkerDoneEvent(workerIndex,aggregatorRegistry.getAllAggregators()));
      if (log.isInfoEnabled()) {
        log.info(formatLogString(""String_Node_Str"" + currentIteration() + ""String_Node_Str""));
      }
      barrier.waitForOtherWorkers();
      if (barrier.terminationSignaled()) {
        if (log.isInfoEnabled()) {
          log.info(formatLogString(""String_Node_Str"" + currentIteration() + ""String_Node_Str""));
        }
        requestTermination();
      }
 else {
        incrementIterationCounter();
        String[] globalAggregateNames=barrier.getAggregatorNames();
        Value[] globalAggregates=barrier.getAggregates();
        aggregatorRegistry.updateGlobalAggregatesAndReset(globalAggregateNames,globalAggregates);
      }
    }
    if (log.isInfoEnabled()) {
      log.info(formatLogString(""String_Node_Str"" + currentIteration() + ""String_Node_Str""));
    }
    if (isWorksetIteration) {
      streamSolutionSetToFinalOutput(solutionSet);
    }
 else {
      streamOutFinalOutputBulk(new InputViewIterator<X>(superstepResult,this.solutionTypeSerializer));
    }
  }
  finally {
    IterationAggregatorBroker.instance().remove(brokerKey);
    BlockingBackChannelBroker.instance().remove(brokerKey);
    if (isWorksetIteration) {
      SolutionSetBroker.instance().remove(brokerKey);
      if (waitForSolutionSetUpdate) {
        SolutionSetUpdateBarrierBroker.instance().remove(brokerKey);
      }
    }
    if (solutionSet != null) {
      solutionSet.close();
      solutionSet=null;
    }
  }
}",0.9792629458466644
55113,"@Override public void teardown(){
  this.hashJoin.close();
}","@Override public void teardown(){
  MutableHashTable<?,?> ht=this.hashJoin;
  if (ht != null) {
    ht.close();
  }
}",0.6779661016949152
55114,"@Override protected JobGraph getJobGraph() throws Exception {
  return createJobGraph(dataPath,clusterPath,this.resultPath,1,20);
}","@Override protected JobGraph getJobGraph() throws Exception {
  return createJobGraph(dataPath,clusterPath,this.resultPath,4,20);
}",0.9923664122137404
55115,"public KMeansIterativeNepheleITCase(){
  LogUtils.initializeDefaultConsoleLogger();
}","public KMeansIterativeNepheleITCase(){
  LogUtils.initializeDefaultTestConsoleLogger();
}",0.9770114942528736
55116,"@Test public void testLocalExecutorWithWordCount(){
  try {
    File inFile=File.createTempFile(""String_Node_Str"",""String_Node_Str"");
    File outFile=File.createTempFile(""String_Node_Str"",""String_Node_Str"");
    inFile.deleteOnExit();
    outFile.deleteOnExit();
    FileWriter fw=new FileWriter(inFile);
    fw.write(WordCountITCase.TEXT);
    fw.close();
    WordCount wc=new WordCount();
    LocalExecutor.execute(wc,""String_Node_Str"",inFile.toURI().toString(),outFile.toURI().toString());
  }
 catch (  Exception e) {
    e.printStackTrace();
    Assert.fail(e.getMessage());
  }
}","@Test public void testLocalExecutorWithWordCount(){
  try {
    File inFile=File.createTempFile(""String_Node_Str"",""String_Node_Str"");
    File outFile=File.createTempFile(""String_Node_Str"",""String_Node_Str"");
    inFile.deleteOnExit();
    outFile.deleteOnExit();
    FileWriter fw=new FileWriter(inFile);
    fw.write(WordCountData.TEXT);
    fw.close();
    WordCount wc=new WordCount();
    LocalExecutor executor=new LocalExecutor();
    LogUtils.initializeDefaultConsoleLogger(Level.ERROR);
    executor.start();
    executor.executePlan(wc.getPlan(""String_Node_Str"",inFile.toURI().toString(),outFile.toURI().toString()));
    executor.stop();
  }
 catch (  Exception e) {
    e.printStackTrace();
    Assert.fail(e.getMessage());
  }
}",0.8560663149962321
55117,"private JobTaskVertex createSingleInputVertex(SingleInputPlanNode node) throws CompilerException {
  final String taskName=node.getNodeName();
  final DriverStrategy ds=node.getDriverStrategy();
  boolean chaining=false;
{
    Channel inConn=node.getInput();
    PlanNode pred=inConn.getSource();
    chaining=ds.getPushChainDriverClass() != null && !(pred instanceof NAryUnionPlanNode) && !(pred instanceof BulkPartialSolutionPlanNode) && !(pred instanceof IterationPlanNode) && inConn.getShipStrategy() == ShipStrategyType.FORWARD && inConn.getLocalStrategy() == LocalStrategy.NONE && pred.getOutgoingChannels().size() == 1 && node.getDegreeOfParallelism() == pred.getDegreeOfParallelism() && node.getSubtasksPerInstance() == pred.getSubtasksPerInstance();
    if (this.currentIteration != null && this.currentIteration instanceof WorksetIterationPlanNode && node.getOutgoingChannels().size() > 0) {
      WorksetIterationPlanNode wspn=(WorksetIterationPlanNode)this.currentIteration;
      if (wspn.getSolutionSetDeltaPlanNode() == pred || wspn.getNextWorkSetPlanNode() == pred) {
        chaining=false;
      }
    }
  }
  final JobTaskVertex vertex;
  final TaskConfig config;
  if (chaining) {
    vertex=null;
    config=new TaskConfig(new Configuration());
    this.chainedTasks.put(node,new TaskInChain(ds.getPushChainDriverClass(),config,taskName));
  }
 else {
    vertex=new JobTaskVertex(taskName,this.jobGraph);
    vertex.setTaskClass(this.currentIteration == null ? RegularPactTask.class : IterationIntermediatePactTask.class);
    config=new TaskConfig(vertex.getConfiguration());
    config.setDriver(ds.getDriverClass());
  }
  config.setStubWrapper(node.getPactContract().getUserCodeWrapper());
  config.setStubParameters(node.getPactContract().getParameters());
  config.setDriverStrategy(ds);
  if (node.getComparator() != null) {
    config.setDriverComparator(node.getComparator(),0);
  }
  assignDriverResources(node,config);
  return vertex;
}","private JobTaskVertex createSingleInputVertex(SingleInputPlanNode node) throws CompilerException {
  final String taskName=node.getNodeName();
  final DriverStrategy ds=node.getDriverStrategy();
  boolean chaining=false;
{
    Channel inConn=node.getInput();
    PlanNode pred=inConn.getSource();
    chaining=ds.getPushChainDriverClass() != null && !(pred instanceof NAryUnionPlanNode) && !(pred instanceof BulkPartialSolutionPlanNode) && !(pred instanceof IterationPlanNode) && inConn.getShipStrategy() == ShipStrategyType.FORWARD && inConn.getLocalStrategy() == LocalStrategy.NONE && pred.getOutgoingChannels().size() == 1 && node.getDegreeOfParallelism() == pred.getDegreeOfParallelism() && node.getSubtasksPerInstance() == pred.getSubtasksPerInstance();
    if (this.currentIteration != null && this.currentIteration instanceof WorksetIterationPlanNode && node.getOutgoingChannels().size() > 0) {
      WorksetIterationPlanNode wspn=(WorksetIterationPlanNode)this.currentIteration;
      if (wspn.getSolutionSetDeltaPlanNode() == pred || wspn.getNextWorkSetPlanNode() == pred) {
        chaining=false;
      }
    }
  }
  final JobTaskVertex vertex;
  final TaskConfig config;
  if (chaining) {
    vertex=null;
    config=new TaskConfig(new Configuration());
    this.chainedTasks.put(node,new TaskInChain(ds.getPushChainDriverClass(),config,taskName));
  }
 else {
    vertex=new JobTaskVertex(taskName,this.jobGraph);
    vertex.setTaskClass((this.currentIteration != null && node.isOnDynamicPath()) ? IterationIntermediatePactTask.class : RegularPactTask.class);
    config=new TaskConfig(vertex.getConfiguration());
    config.setDriver(ds.getDriverClass());
  }
  config.setStubWrapper(node.getPactContract().getUserCodeWrapper());
  config.setStubParameters(node.getPactContract().getParameters());
  config.setDriverStrategy(ds);
  if (node.getComparator() != null) {
    config.setDriverComparator(node.getComparator(),0);
  }
  assignDriverResources(node,config);
  return vertex;
}",0.9702620967741936
55118,"private JobTaskVertex createDualInputVertex(DualInputPlanNode node) throws CompilerException {
  final String taskName=node.getNodeName();
  final DriverStrategy ds=node.getDriverStrategy();
  final JobTaskVertex vertex=new JobTaskVertex(taskName,this.jobGraph);
  final TaskConfig config=new TaskConfig(vertex.getConfiguration());
  vertex.setTaskClass(this.currentIteration == null ? RegularPactTask.class : IterationIntermediatePactTask.class);
  config.setStubWrapper(node.getPactContract().getUserCodeWrapper());
  config.setStubParameters(node.getPactContract().getParameters());
  config.setDriver(ds.getDriverClass());
  config.setDriverStrategy(ds);
  if (node.getComparator1() != null) {
    config.setDriverComparator(node.getComparator1(),0);
  }
  if (node.getComparator2() != null) {
    config.setDriverComparator(node.getComparator2(),1);
  }
  if (node.getPairComparator() != null) {
    config.setDriverPairComparator(node.getPairComparator());
  }
  assignDriverResources(node,config);
  return vertex;
}","private JobTaskVertex createDualInputVertex(DualInputPlanNode node) throws CompilerException {
  final String taskName=node.getNodeName();
  final DriverStrategy ds=node.getDriverStrategy();
  final JobTaskVertex vertex=new JobTaskVertex(taskName,this.jobGraph);
  final TaskConfig config=new TaskConfig(vertex.getConfiguration());
  vertex.setTaskClass((this.currentIteration != null && node.isOnDynamicPath()) ? IterationIntermediatePactTask.class : RegularPactTask.class);
  config.setStubWrapper(node.getPactContract().getUserCodeWrapper());
  config.setStubParameters(node.getPactContract().getParameters());
  config.setDriver(ds.getDriverClass());
  config.setDriverStrategy(ds);
  if (node.getComparator1() != null) {
    config.setDriverComparator(node.getComparator1(),0);
  }
  if (node.getComparator2() != null) {
    config.setDriverComparator(node.getComparator2(),1);
  }
  if (node.getPairComparator() != null) {
    config.setDriverPairComparator(node.getPairComparator());
  }
  assignDriverResources(node,config);
  return vertex;
}",0.944069431051109
55119,"@Override public void read(DataInput in) throws IOException {
  wrappedType=in.readUTF();
  try {
    Class wrClass=Class.forName(wrappedType);
    wrapped=InstantiationUtil.instantiate(wrClass,Writable.class);
  }
 catch (  ClassNotFoundException e) {
    throw new RuntimeException(""String_Node_Str"");
  }
  wrapped.readFields(in);
}","@Override public void read(DataInput in) throws IOException {
  wrappedType=in.readUTF();
  try {
    Class wrClass=Class.forName(wrappedType);
    wrapped=(Writable)InstantiationUtil.instantiate(wrClass,Writable.class);
  }
 catch (  ClassNotFoundException e) {
    throw new RuntimeException(""String_Node_Str"");
  }
  wrapped.readFields(in);
}",0.9852941176470588
55120,"/** 
 * Configures this JDBCOutputFormat.
 * @param parameters Configuration containing all parameters.
 */
@Override public void configure(Configuration parameters){
  this.driverName=parameters.getString(DRIVER_KEY,null);
  this.username=parameters.getString(USERNAME_KEY,null);
  this.password=parameters.getString(PASSWORD_KEY,null);
  this.dbURL=parameters.getString(URL_KEY,null);
  this.query=parameters.getString(QUERY_KEY,null);
  this.fieldCount=parameters.getInteger(FIELD_COUNT_KEY,0);
  @SuppressWarnings(""String_Node_Str"") Class<Value>[] classes=new Class[this.fieldCount];
  this.fieldClasses=classes;
  for (int i=0; i < this.fieldCount; i++) {
    @SuppressWarnings(""String_Node_Str"") Class<? extends Value> clazz=(Class<? extends Value>)parameters.getClass(FIELD_TYPE_KEY + i,null);
    if (clazz == null) {
      throw new IllegalArgumentException(""String_Node_Str"" + ""String_Node_Str"" + i);
    }
    this.fieldClasses[i]=clazz;
  }
}","/** 
 * Configures this JDBCOutputFormat.
 * @param parameters Configuration containing all parameters.
 */
@Override public void configure(Configuration parameters){
  this.driverName=parameters.getString(DRIVER_KEY,null);
  this.username=parameters.getString(USERNAME_KEY,null);
  this.password=parameters.getString(PASSWORD_KEY,null);
  this.dbURL=parameters.getString(URL_KEY,null);
  this.query=parameters.getString(QUERY_KEY,null);
  this.fieldCount=parameters.getInteger(FIELD_COUNT_KEY,0);
  this.batchInterval=parameters.getInteger(BATCH_INTERVAL,DEFAULT_BATCH_INTERVERAL);
  @SuppressWarnings(""String_Node_Str"") Class<Value>[] classes=new Class[this.fieldCount];
  this.fieldClasses=classes;
  for (int i=0; i < this.fieldCount; i++) {
    @SuppressWarnings(""String_Node_Str"") Class<? extends Value> clazz=(Class<? extends Value>)parameters.getClass(FIELD_TYPE_KEY + i,null);
    if (clazz == null) {
      throw new IllegalArgumentException(""String_Node_Str"" + ""String_Node_Str"" + i);
    }
    this.fieldClasses[i]=clazz;
  }
}",0.9573507275464124
55121,"/** 
 * Adds a record to the prepared statement. <p> When this method is called, the output format is guaranteed to be opened.
 * @param record The records to add to the output.
 * @throws IOException Thrown, if the records could not be added due to anI/O problem.
 */
@Override public void writeRecord(Record record) throws IOException {
  try {
    for (int x=0; x < record.getNumFields(); x++) {
      Value temp=record.getField(x,fieldClasses[x]);
      addValue(x + 1,temp);
    }
    upload.addBatch();
  }
 catch (  SQLException sqe) {
    throw new IllegalArgumentException(""String_Node_Str"",sqe);
  }
catch (  IllegalArgumentException iae) {
    throw new IllegalArgumentException(""String_Node_Str"",iae);
  }
}","/** 
 * Adds a record to the prepared statement. <p> When this method is called, the output format is guaranteed to be opened.
 * @param record The records to add to the output.
 * @throws IOException Thrown, if the records could not be added due to anI/O problem.
 */
@Override public void writeRecord(Record record) throws IOException {
  try {
    for (int x=0; x < record.getNumFields(); x++) {
      Value temp=record.getField(x,fieldClasses[x]);
      addValue(x + 1,temp);
    }
    upload.addBatch();
    batchCount++;
    if (batchCount >= batchInterval) {
      upload.executeBatch();
      batchCount=0;
    }
  }
 catch (  SQLException sqe) {
    throw new IllegalArgumentException(""String_Node_Str"",sqe);
  }
catch (  IllegalArgumentException iae) {
    throw new IllegalArgumentException(""String_Node_Str"",iae);
  }
}",0.927741935483871
55122,"/** 
 * Executes prepared statement and closes all resources of this instance.
 * @throws IOException Thrown, if the input could not be closed properly.
 */
@Override public void close() throws IOException {
  try {
    upload.executeBatch();
    upload.close();
    dbConn.close();
  }
 catch (  SQLException sqe) {
    throw new IllegalArgumentException(""String_Node_Str"",sqe);
  }
}","/** 
 * Executes prepared statement and closes all resources of this instance.
 * @throws IOException Thrown, if the input could not be closed properly.
 */
@Override public void close() throws IOException {
  try {
    upload.executeBatch();
    batchCount=0;
    upload.close();
    dbConn.close();
  }
 catch (  SQLException sqe) {
    throw new IllegalArgumentException(""String_Node_Str"",sqe);
  }
}",0.9771573604060914
55123,"@BeforeClass public static void setUpClass(){
  try {
    prepareDerbyDatabase();
  }
 catch (  ClassNotFoundException e) {
    e.printStackTrace();
    Assert.fail();
  }
}","@BeforeClass public static void setUpClass(){
  try {
    prepareDerbyDatabase();
  }
 catch (  Exception e) {
    e.printStackTrace();
    Assert.fail();
  }
}",0.960960960960961
55124,"private static void createConnection(String dbURL){
  try {
    Class.forName(""String_Node_Str"");
    conn=DriverManager.getConnection(dbURL);
    createTable();
    insertDataToSQLTables();
    conn.close();
  }
 catch (  ClassNotFoundException e) {
    e.printStackTrace();
    Assert.fail();
  }
catch (  SQLException e) {
    e.printStackTrace();
    Assert.fail();
  }
}","private static void createConnection(String dbURL){
  try {
    Class.forName(""String_Node_Str"");
    conn=DriverManager.getConnection(dbURL);
    createTable();
    insertDataToSQLTables();
    conn.close();
  }
 catch (  Exception e) {
    e.printStackTrace();
    Assert.fail();
  }
}",0.8670694864048338
55125,"@Test public void testJDBCInputFormat() throws IOException {
  jdbcInputFormat=new JDBCInputFormat(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"");
  jdbcInputFormat.configure(null);
  Record record=new Record();
  int recordCount=0;
  while (!jdbcInputFormat.reachedEnd()) {
    jdbcInputFormat.nextRecord(record);
    Assert.assertEquals(5,record.getNumFields());
    Assert.assertEquals(""String_Node_Str"",IntValue.class,record.getField(0,IntValue.class).getClass());
    Assert.assertEquals(""String_Node_Str"",StringValue.class,record.getField(1,StringValue.class).getClass());
    Assert.assertEquals(""String_Node_Str"",StringValue.class,record.getField(2,StringValue.class).getClass());
    Assert.assertEquals(""String_Node_Str"",DoubleValue.class,record.getField(3,DoubleValue.class).getClass());
    Assert.assertEquals(""String_Node_Str"",IntValue.class,record.getField(4,IntValue.class).getClass());
    int[] pos={0,1,2,3,4};
    Value[] values={new IntValue(),new StringValue(),new StringValue(),new DoubleValue(),new IntValue()};
    Assert.assertTrue(record.equalsFields(pos,dbData[recordCount],values));
    recordCount++;
  }
  Assert.assertEquals(5,recordCount);
}","@Test public void testJDBCInputFormat() throws IOException {
  jdbcInputFormat=new JDBCInputFormat(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"");
  jdbcInputFormat.configure(null);
  Record record=new Record();
  int recordCount=0;
  while (!jdbcInputFormat.reachedEnd()) {
    jdbcInputFormat.nextRecord(record);
    Assert.assertEquals(5,record.getNumFields());
    Assert.assertEquals(""String_Node_Str"",IntValue.class,record.getField(0,IntValue.class).getClass());
    Assert.assertEquals(""String_Node_Str"",StringValue.class,record.getField(1,StringValue.class).getClass());
    Assert.assertEquals(""String_Node_Str"",StringValue.class,record.getField(2,StringValue.class).getClass());
    Assert.assertEquals(""String_Node_Str"",DoubleValue.class,record.getField(3,DoubleValue.class).getClass());
    Assert.assertEquals(""String_Node_Str"",IntValue.class,record.getField(4,IntValue.class).getClass());
    int[] pos={0,1,2,3,4};
    Value[] values={new IntValue(),new StringValue(),new StringValue(),new DoubleValue(),new IntValue()};
    Assert.assertTrue(record.equalsFields(pos,dbData[recordCount],values));
    recordCount++;
  }
  Assert.assertEquals(5,recordCount);
  cleanUpDerbyDatabases();
}",0.98870765370138
55126,"@BeforeClass public static void setUpClass(){
  try {
    System.setProperty(""String_Node_Str"",""String_Node_Str"");
    prepareDerbyInputDatabase();
    prepareDerbyOutputDatabase();
  }
 catch (  ClassNotFoundException e) {
    Assert.fail();
  }
}","@BeforeClass public static void setUpClass(){
  try {
    System.setProperty(""String_Node_Str"",""String_Node_Str"");
    prepareDerbyInputDatabase();
    prepareDerbyOutputDatabase();
  }
 catch (  ClassNotFoundException e) {
    e.printStackTrace();
    Assert.fail();
  }
}",0.9520153550863724
55127,"private static void prepareDerbyInputDatabase() throws ClassNotFoundException {
  try {
    String dbURL=""String_Node_Str"";
    Class.forName(""String_Node_Str"");
    conn=DriverManager.getConnection(dbURL);
    createTableBooks();
    insertDataToSQLTables();
    conn.close();
  }
 catch (  ClassNotFoundException e) {
    Assert.fail();
  }
catch (  SQLException e) {
    Assert.fail();
  }
}","private static void prepareDerbyInputDatabase() throws ClassNotFoundException {
  try {
    String dbURL=""String_Node_Str"";
    Class.forName(""String_Node_Str"");
    conn=DriverManager.getConnection(dbURL);
    createTableBooks();
    insertDataToSQLTables();
    conn.close();
  }
 catch (  ClassNotFoundException e) {
    e.printStackTrace();
    Assert.fail();
  }
catch (  SQLException e) {
    e.printStackTrace();
    Assert.fail();
  }
}",0.9403341288782816
55128,"private static void prepareDerbyOutputDatabase() throws ClassNotFoundException {
  try {
    String dbURL=""String_Node_Str"";
    Class.forName(""String_Node_Str"");
    conn=DriverManager.getConnection(dbURL);
    createTableNewBooks();
    conn.close();
  }
 catch (  ClassNotFoundException e) {
    Assert.fail();
  }
catch (  SQLException e) {
    Assert.fail();
  }
}","private static void prepareDerbyOutputDatabase() throws ClassNotFoundException {
  try {
    String dbURL=""String_Node_Str"";
    Class.forName(""String_Node_Str"");
    conn=DriverManager.getConnection(dbURL);
    createTableNewBooks();
    conn.close();
  }
 catch (  ClassNotFoundException e) {
    e.printStackTrace();
    Assert.fail();
  }
catch (  SQLException e) {
    e.printStackTrace();
    Assert.fail();
  }
}",0.9365482233502538
55129,"@After public void tearDown(){
  jdbcOutputFormat=null;
}","@After public void tearDown(){
  jdbcOutputFormat=null;
  cleanUpDerbyDatabases();
}",0.8085106382978723
55130,"public void setConsoleStreamForReporting(PrintStream stream){
  if (stream == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  this.console=stream;
}","public void setConsoleStreamForReporting(PrintStream stream){
  this.console=stream;
}",0.6640926640926641
55131,"@Test public void dumpWorksetConnectedComponents(){
  dump(new WorksetConnectedComponents().getPlan(""String_Node_Str"",IN_FILE,IN_FILE,OUT_FILE));
}","@Test public void dumpWorksetConnectedComponents(){
  dump(new WorksetConnectedComponents().getPlan(""String_Node_Str"",IN_FILE,IN_FILE,OUT_FILE));
  dump(new WorksetConnectedComponents().getPlan(NO_ARGS));
}",0.8328611898016998
55132,"@Test public void dumpTPCH3(){
  dump(new TPCHQuery3().getPlan(""String_Node_Str"",IN_FILE,IN_FILE,OUT_FILE));
}","@Test public void dumpTPCH3(){
  dump(new TPCHQuery3().getPlan(""String_Node_Str"",IN_FILE,IN_FILE,OUT_FILE));
  dump(new TPCHQuery3().getPlan(NO_ARGS));
}",0.8365019011406845
55133,"@Test public void dumpWordCount(){
  dump(new WordCount().getPlan(""String_Node_Str"",IN_FILE,OUT_FILE));
}","@Test public void dumpWordCount(){
  dump(new WordCount().getPlan(""String_Node_Str"",IN_FILE,OUT_FILE));
  dump(new WordCount().getPlan(NO_ARGS));
}",0.8333333333333334
55134,"@Test public void dumpBulkIterationKMeans(){
  dump(new KMeansIterative().getPlan(""String_Node_Str"",IN_FILE,OUT_FILE));
}","@Test public void dumpBulkIterationKMeans(){
  dump(new KMeansIterative().getPlan(""String_Node_Str"",IN_FILE,OUT_FILE));
  dump(new KMeansIterative().getPlan(NO_ARGS));
}",0.8344827586206897
55135,"@Test public void dumpWebLogAnalysis(){
  dump(new WebLogAnalysis().getPlan(""String_Node_Str"",IN_FILE,IN_FILE,IN_FILE,OUT_FILE));
}","@Test public void dumpWebLogAnalysis(){
  dump(new WebLogAnalysis().getPlan(""String_Node_Str"",IN_FILE,IN_FILE,IN_FILE,OUT_FILE));
  dump(new WebLogAnalysis().getPlan(NO_ARGS));
}",0.8478964401294499
55136,"@Test public void dumpKMeans(){
  dump(new KMeansSingleStep().getPlan(""String_Node_Str"",IN_FILE,IN_FILE,OUT_FILE));
}","@Test public void dumpKMeans(){
  dump(new KMeansSingleStep().getPlan(""String_Node_Str"",IN_FILE,IN_FILE,OUT_FILE));
  dump(new KMeansSingleStep().getPlan(NO_ARGS));
}",0.8268551236749117
55137,"/** 
 * Submits the job assigned to this job client to the job manager and queries the job manager about the progress of the job until it is either finished or aborted.
 * @return the duration of the job execution in milliseconds
 * @throws IOException thrown if an error occurred while transmitting the request
 * @throws JobExecutionException thrown if the job has been aborted either by the user or as a result of an error
 */
public long submitJobAndWait() throws IOException, JobExecutionException {
synchronized (this.jobSubmitClient) {
    final JobSubmissionResult submissionResult=this.jobSubmitClient.submitJob(this.jobGraph);
    if (submissionResult.getReturnCode() == AbstractJobResult.ReturnCode.ERROR) {
      LOG.error(""String_Node_Str"" + submissionResult.getDescription());
      throw new JobExecutionException(submissionResult.getDescription(),false);
    }
    Runtime.getRuntime().addShutdownHook(this.jobCleanUp);
  }
  long sleep=0;
  try {
    final IntegerRecord interval=this.jobSubmitClient.getRecommendedPollingInterval();
    sleep=interval.getValue() * 1000;
  }
 catch (  IOException ioe) {
    Runtime.getRuntime().removeShutdownHook(this.jobCleanUp);
    throw ioe;
  }
  try {
    Thread.sleep(sleep / 2);
  }
 catch (  InterruptedException e) {
    Runtime.getRuntime().removeShutdownHook(this.jobCleanUp);
    logErrorAndRethrow(StringUtils.stringifyException(e));
  }
  long startTimestamp=-1;
  while (true) {
    if (Thread.interrupted()) {
      logErrorAndRethrow(""String_Node_Str"");
    }
    JobProgressResult jobProgressResult=null;
    try {
      jobProgressResult=getJobProgress();
    }
 catch (    IOException ioe) {
      Runtime.getRuntime().removeShutdownHook(this.jobCleanUp);
      throw ioe;
    }
    if (jobProgressResult == null) {
      logErrorAndRethrow(""String_Node_Str"");
    }
    if (jobProgressResult.getReturnCode() == AbstractJobResult.ReturnCode.ERROR) {
      logErrorAndRethrow(""String_Node_Str"" + jobProgressResult.getDescription());
    }
    final Iterator<AbstractEvent> it=jobProgressResult.getEvents();
    while (it.hasNext()) {
      final AbstractEvent event=it.next();
      if (this.lastProcessedEventSequenceNumber >= event.getSequenceNumber()) {
        continue;
      }
      this.console.println(event.toString());
      this.lastProcessedEventSequenceNumber=event.getSequenceNumber();
      if (event instanceof JobEvent) {
        final JobEvent jobEvent=(JobEvent)event;
        final JobStatus jobStatus=jobEvent.getCurrentJobStatus();
        if (jobStatus == JobStatus.SCHEDULED) {
          startTimestamp=jobEvent.getTimestamp();
        }
        if (jobStatus == JobStatus.FINISHED) {
          Runtime.getRuntime().removeShutdownHook(this.jobCleanUp);
          final long jobDuration=jobEvent.getTimestamp() - startTimestamp;
          this.console.println(""String_Node_Str"" + jobDuration);
          return jobDuration;
        }
 else         if (jobStatus == JobStatus.CANCELED || jobStatus == JobStatus.FAILED) {
          Runtime.getRuntime().removeShutdownHook(this.jobCleanUp);
          LOG.info(jobEvent.getOptionalMessage());
          if (jobStatus == JobStatus.CANCELED) {
            throw new JobExecutionException(jobEvent.getOptionalMessage(),true);
          }
 else {
            throw new JobExecutionException(jobEvent.getOptionalMessage(),false);
          }
        }
      }
    }
    try {
      Thread.sleep(sleep);
    }
 catch (    InterruptedException e) {
      logErrorAndRethrow(StringUtils.stringifyException(e));
    }
  }
}","/** 
 * Submits the job assigned to this job client to the job manager and queries the job manager about the progress of the job until it is either finished or aborted.
 * @return the duration of the job execution in milliseconds
 * @throws IOException thrown if an error occurred while transmitting the request
 * @throws JobExecutionException thrown if the job has been aborted either by the user or as a result of an error
 */
public long submitJobAndWait() throws IOException, JobExecutionException {
synchronized (this.jobSubmitClient) {
    final JobSubmissionResult submissionResult=this.jobSubmitClient.submitJob(this.jobGraph);
    if (submissionResult.getReturnCode() == AbstractJobResult.ReturnCode.ERROR) {
      LOG.error(""String_Node_Str"" + submissionResult.getDescription());
      throw new JobExecutionException(submissionResult.getDescription(),false);
    }
    Runtime.getRuntime().addShutdownHook(this.jobCleanUp);
  }
  long sleep=0;
  try {
    final IntegerRecord interval=this.jobSubmitClient.getRecommendedPollingInterval();
    sleep=interval.getValue() * 1000;
  }
 catch (  IOException ioe) {
    Runtime.getRuntime().removeShutdownHook(this.jobCleanUp);
    throw ioe;
  }
  try {
    Thread.sleep(sleep / 2);
  }
 catch (  InterruptedException e) {
    Runtime.getRuntime().removeShutdownHook(this.jobCleanUp);
    logErrorAndRethrow(StringUtils.stringifyException(e));
  }
  long startTimestamp=-1;
  while (true) {
    if (Thread.interrupted()) {
      logErrorAndRethrow(""String_Node_Str"");
    }
    JobProgressResult jobProgressResult=null;
    try {
      jobProgressResult=getJobProgress();
    }
 catch (    IOException ioe) {
      Runtime.getRuntime().removeShutdownHook(this.jobCleanUp);
      throw ioe;
    }
    if (jobProgressResult == null) {
      logErrorAndRethrow(""String_Node_Str"");
    }
    if (jobProgressResult.getReturnCode() == AbstractJobResult.ReturnCode.ERROR) {
      logErrorAndRethrow(""String_Node_Str"" + jobProgressResult.getDescription());
    }
    final Iterator<AbstractEvent> it=jobProgressResult.getEvents();
    while (it.hasNext()) {
      final AbstractEvent event=it.next();
      if (this.lastProcessedEventSequenceNumber >= event.getSequenceNumber()) {
        continue;
      }
      LOG.info(event.toString());
      this.lastProcessedEventSequenceNumber=event.getSequenceNumber();
      if (event instanceof JobEvent) {
        final JobEvent jobEvent=(JobEvent)event;
        final JobStatus jobStatus=jobEvent.getCurrentJobStatus();
        if (jobStatus == JobStatus.SCHEDULED) {
          startTimestamp=jobEvent.getTimestamp();
        }
        if (jobStatus == JobStatus.FINISHED) {
          Runtime.getRuntime().removeShutdownHook(this.jobCleanUp);
          final long jobDuration=jobEvent.getTimestamp() - startTimestamp;
          this.console.println(""String_Node_Str"" + jobDuration);
          return jobDuration;
        }
 else         if (jobStatus == JobStatus.CANCELED || jobStatus == JobStatus.FAILED) {
          Runtime.getRuntime().removeShutdownHook(this.jobCleanUp);
          LOG.info(jobEvent.getOptionalMessage());
          if (jobStatus == JobStatus.CANCELED) {
            throw new JobExecutionException(jobEvent.getOptionalMessage(),true);
          }
 else {
            throw new JobExecutionException(jobEvent.getOptionalMessage(),false);
          }
        }
      }
    }
    try {
      Thread.sleep(sleep);
    }
 catch (    InterruptedException e) {
      logErrorAndRethrow(StringUtils.stringifyException(e));
    }
  }
}",0.9960563380281692
55138,"/** 
 * Returns a reference to the   {@link FileSystem} instance for accessing thelocal file system.
 * @return a reference to the {@link FileSystem} instance for accessing thelocal file system.
 * @throws IOException thrown if a reference to the file system instance could not be obtained
 */
public static FileSystem getLocalFileSystem() throws IOException {
  URI localUri;
  try {
    localUri=new URI(""String_Node_Str"");
  }
 catch (  URISyntaxException e) {
    throw new IOException(""String_Node_Str"");
  }
  return get(localUri);
}","/** 
 * Returns a reference to the   {@link FileSystem} instance for accessing thelocal file system.
 * @return a reference to the {@link FileSystem} instance for accessing thelocal file system.
 * @throws IOException thrown if a reference to the file system instance could not be obtained
 */
public static FileSystem getLocalFileSystem() throws IOException {
  URI localUri;
  try {
    localUri=isWindows() ? new URI(""String_Node_Str"") : new URI(""String_Node_Str"");
  }
 catch (  URISyntaxException e) {
    throw new IOException(""String_Node_Str"");
  }
  return get(localUri);
}",0.9616413916146298
55139,"/** 
 * The entry point to the application.
 * @param args the command line arguments
 */
public static void main(String[] args){
  if (args.length < 7) {
    System.err.println(""String_Node_Str"");
    System.err.println(""String_Node_Str"");
    System.exit(-1);
  }
  JOB_MANAGER_ADDRESS=args[0];
  INSTANCE_TYPE=args[1];
  TOPOLOGY_TREE=args[2];
  try {
    NUMBER_OF_RUNS=Integer.parseInt(args[3]);
  }
 catch (  NumberFormatException nfe) {
    System.err.println(""String_Node_Str"" + args[3]);
    System.exit(-1);
  }
  if (NUMBER_OF_RUNS <= 0) {
    System.err.println(""String_Node_Str"");
    System.exit(-1);
  }
  try {
    NUMBER_OF_CONSUMERS=Integer.parseInt(args[4]);
  }
 catch (  NumberFormatException nfe) {
    System.err.println(""String_Node_Str"" + args[4]);
    System.exit(-1);
  }
  if (NUMBER_OF_CONSUMERS <= 0) {
    System.err.println(""String_Node_Str"");
    System.exit(-1);
  }
  try {
    NUMBER_OF_RECORDS=Integer.parseInt(args[5]);
  }
 catch (  NumberFormatException nfe) {
    System.err.println(""String_Node_Str"" + args[5]);
    System.exit(-1);
  }
  if (NUMBER_OF_RECORDS <= 0) {
    System.err.println(""String_Node_Str"");
    System.exit(-1);
  }
  OUTPUT_PATH=args[6];
  JAR_FILE=new File(""String_Node_Str"");
  final JarFileCreator jarFileCreator=new JarFileCreator(JAR_FILE);
  jarFileCreator.addClass(BroadcastProducer.class);
  jarFileCreator.addClass(BroadcastConsumer.class);
  jarFileCreator.addClass(BroadcastRecord.class);
  try {
    jarFileCreator.createJarFile();
  }
 catch (  IOException ioe) {
    if (JAR_FILE.exists()) {
      JAR_FILE.delete();
    }
    System.err.println(""String_Node_Str"" + StringUtils.stringifyException(ioe));
    System.exit(-1);
  }
  try {
    final BufferedWriter throughputWriter=new BufferedWriter(new FileWriter(getThroughputFilename()));
    final BufferedWriter durationWriter=new BufferedWriter(new FileWriter(getDurationFilename()));
    for (int i=0; i < NUMBER_OF_RUNS; ++i) {
      try {
        runJob(i,throughputWriter,durationWriter);
      }
 catch (      Exception e) {
        System.err.println(""String_Node_Str"" + i + ""String_Node_Str""+ StringUtils.stringifyException(e));
        break;
      }
    }
    throughputWriter.close();
    durationWriter.close();
  }
 catch (  IOException ioe) {
    System.err.println(""String_Node_Str"" + StringUtils.stringifyException(ioe));
  }
  if (JAR_FILE.exists()) {
    JAR_FILE.delete();
  }
}","/** 
 * The entry point to the application.
 * @param args the command line arguments
 */
public static void main(String[] args){
  if (args.length < 7) {
    System.err.println(""String_Node_Str"");
    System.err.println(""String_Node_Str"");
    System.exit(-1);
  }
  JOB_MANAGER_ADDRESS=args[0];
  INSTANCE_TYPE=args[1];
  TOPOLOGY_TREE=args[2];
  try {
    NUMBER_OF_RUNS=Integer.parseInt(args[3]);
  }
 catch (  NumberFormatException nfe) {
    System.err.println(""String_Node_Str"" + args[3]);
    System.exit(-1);
  }
  if (NUMBER_OF_RUNS <= 0) {
    System.err.println(""String_Node_Str"");
    System.exit(-1);
  }
  try {
    NUMBER_OF_CONSUMERS=Integer.parseInt(args[4]);
  }
 catch (  NumberFormatException nfe) {
    System.err.println(""String_Node_Str"" + args[4]);
    System.exit(-1);
  }
  if (NUMBER_OF_CONSUMERS <= 0) {
    System.err.println(""String_Node_Str"");
    System.exit(-1);
  }
  try {
    NUMBER_OF_RECORDS=Integer.parseInt(args[5]);
  }
 catch (  NumberFormatException nfe) {
    System.err.println(""String_Node_Str"" + args[5]);
    System.exit(-1);
  }
  if (NUMBER_OF_RECORDS <= 0) {
    System.err.println(""String_Node_Str"");
    System.exit(-1);
  }
  OUTPUT_PATH=args[6];
  JAR_FILE=new File(Path.constructTestPath(""String_Node_Str"") + ""String_Node_Str"");
  final JarFileCreator jarFileCreator=new JarFileCreator(JAR_FILE);
  jarFileCreator.addClass(BroadcastProducer.class);
  jarFileCreator.addClass(BroadcastConsumer.class);
  jarFileCreator.addClass(BroadcastRecord.class);
  try {
    jarFileCreator.createJarFile();
  }
 catch (  IOException ioe) {
    if (JAR_FILE.exists()) {
      JAR_FILE.delete();
    }
    System.err.println(""String_Node_Str"" + StringUtils.stringifyException(ioe));
    System.exit(-1);
  }
  try {
    final BufferedWriter throughputWriter=new BufferedWriter(new FileWriter(getThroughputFilename()));
    final BufferedWriter durationWriter=new BufferedWriter(new FileWriter(getDurationFilename()));
    for (int i=0; i < NUMBER_OF_RUNS; ++i) {
      try {
        runJob(i,throughputWriter,durationWriter);
      }
 catch (      Exception e) {
        System.err.println(""String_Node_Str"" + i + ""String_Node_Str""+ StringUtils.stringifyException(e));
        break;
      }
    }
    throughputWriter.close();
    durationWriter.close();
  }
 catch (  IOException ioe) {
    System.err.println(""String_Node_Str"" + StringUtils.stringifyException(ioe));
  }
  if (JAR_FILE.exists()) {
    JAR_FILE.delete();
  }
}",0.9910204081632652
55140,"/** 
 * Executes a specific run of the job.
 * @param run the run of the job
 * @param throughputWriter writer object to write the throughput results for each run
 * @param durationWriter writer object to write the duration results for each run
 */
private static void runJob(final int run,final BufferedWriter throughputWriter,final BufferedWriter durationWriter) throws JobGraphDefinitionException, IOException, JobExecutionException {
  final JobGraph jobGraph=new JobGraph(""String_Node_Str"" + run + ""String_Node_Str"");
  final JobInputVertex producer=new JobInputVertex(""String_Node_Str"",jobGraph);
  producer.setInputClass(BroadcastProducer.class);
  producer.setInstanceType(INSTANCE_TYPE);
  producer.getConfiguration().setInteger(BroadcastProducer.NUMBER_OF_RECORDS_KEY,NUMBER_OF_RECORDS);
  producer.getConfiguration().setInteger(BroadcastProducer.RUN_KEY,run);
  producer.setNumberOfSubtasks(1);
  producer.setNumberOfSubtasksPerInstance(1);
  final JobOutputVertex consumer=new JobOutputVertex(""String_Node_Str"",jobGraph);
  consumer.setOutputClass(BroadcastConsumer.class);
  consumer.setNumberOfSubtasks(NUMBER_OF_CONSUMERS);
  consumer.setNumberOfSubtasksPerInstance(1);
  consumer.setInstanceType(INSTANCE_TYPE);
  consumer.getConfiguration().setInteger(BroadcastProducer.RUN_KEY,run);
  consumer.getConfiguration().setString(BroadcastConsumer.OUTPUT_PATH_KEY,OUTPUT_PATH);
  consumer.getConfiguration().setString(BroadcastConsumer.TOPOLOGY_TREE_KEY,TOPOLOGY_TREE);
  consumer.getConfiguration().setString(BroadcastConsumer.INSTANCE_TYPE_KEY,INSTANCE_TYPE);
  consumer.getConfiguration().setInteger(BroadcastProducer.NUMBER_OF_RECORDS_KEY,NUMBER_OF_RECORDS);
  producer.connectTo(consumer,ChannelType.NETWORK);
  jobGraph.addJar(new Path(""String_Node_Str"" + JAR_FILE.getAbsolutePath()));
  Configuration conf=new Configuration();
  conf.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY,JOB_MANAGER_ADDRESS);
  conf.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY,ConfigConstants.DEFAULT_JOB_MANAGER_IPC_PORT);
  final JobClient jobClient=new JobClient(jobGraph,conf);
  final long jobDuration=jobClient.submitJobAndWait();
  final long numberOfBytesSent=(long)BroadcastRecord.RECORD_SIZE * (long)NUMBER_OF_RECORDS * (long)NUMBER_OF_CONSUMERS;
  final double throughput=(double)(numberOfBytesSent * 1000L * 8L) / (double)(jobDuration * 1024L * 1024L);
  throughputWriter.write(throughput + ""String_Node_Str"");
  durationWriter.write(jobDuration + ""String_Node_Str"");
}","/** 
 * Executes a specific run of the job.
 * @param run the run of the job
 * @param throughputWriter writer object to write the throughput results for each run
 * @param durationWriter writer object to write the duration results for each run
 */
private static void runJob(final int run,final BufferedWriter throughputWriter,final BufferedWriter durationWriter) throws JobGraphDefinitionException, IOException, JobExecutionException {
  final JobGraph jobGraph=new JobGraph(""String_Node_Str"" + run + ""String_Node_Str"");
  final JobInputVertex producer=new JobInputVertex(""String_Node_Str"",jobGraph);
  producer.setInputClass(BroadcastProducer.class);
  producer.setInstanceType(INSTANCE_TYPE);
  producer.getConfiguration().setInteger(BroadcastProducer.NUMBER_OF_RECORDS_KEY,NUMBER_OF_RECORDS);
  producer.getConfiguration().setInteger(BroadcastProducer.RUN_KEY,run);
  producer.setNumberOfSubtasks(1);
  producer.setNumberOfSubtasksPerInstance(1);
  final JobOutputVertex consumer=new JobOutputVertex(""String_Node_Str"",jobGraph);
  consumer.setOutputClass(BroadcastConsumer.class);
  consumer.setNumberOfSubtasks(NUMBER_OF_CONSUMERS);
  consumer.setNumberOfSubtasksPerInstance(1);
  consumer.setInstanceType(INSTANCE_TYPE);
  consumer.getConfiguration().setInteger(BroadcastProducer.RUN_KEY,run);
  consumer.getConfiguration().setString(BroadcastConsumer.OUTPUT_PATH_KEY,OUTPUT_PATH);
  consumer.getConfiguration().setString(BroadcastConsumer.TOPOLOGY_TREE_KEY,TOPOLOGY_TREE);
  consumer.getConfiguration().setString(BroadcastConsumer.INSTANCE_TYPE_KEY,INSTANCE_TYPE);
  consumer.getConfiguration().setInteger(BroadcastProducer.NUMBER_OF_RECORDS_KEY,NUMBER_OF_RECORDS);
  producer.connectTo(consumer,ChannelType.NETWORK);
  jobGraph.addJar(new Path(JAR_FILE.toURI().toString()));
  Configuration conf=new Configuration();
  conf.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY,JOB_MANAGER_ADDRESS);
  conf.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY,ConfigConstants.DEFAULT_JOB_MANAGER_IPC_PORT);
  final JobClient jobClient=new JobClient(jobGraph,conf);
  final long jobDuration=jobClient.submitJobAndWait();
  final long numberOfBytesSent=(long)BroadcastRecord.RECORD_SIZE * (long)NUMBER_OF_RECORDS * (long)NUMBER_OF_CONSUMERS;
  final double throughput=(double)(numberOfBytesSent * 1000L * 8L) / (double)(jobDuration * 1024L * 1024L);
  throughputWriter.write(throughput + ""String_Node_Str"");
  durationWriter.write(jobDuration + ""String_Node_Str"");
}",0.9897239572839008
55141,"@Test public void testOpen(){
  Configuration config=new Configuration();
  config.setInteger(ExternalProcessFixedLengthInputFormat.RECORDLENGTH_PARAMETER_KEY,8);
  ExternalProcessInputSplit split=new ExternalProcessInputSplit(1,this.neverEndingCommand);
  boolean processDestroyed=false;
  try {
    format.configure(config);
    format.open(split);
    String[] cmd={""String_Node_Str"",""String_Node_Str"",""String_Node_Str""};
    byte[] wcOut=new byte[128];
    Process p=Runtime.getRuntime().exec(cmd);
    p.getInputStream().read(wcOut);
    int pCnt=Integer.parseInt(new String(wcOut).trim());
    Assert.assertTrue(pCnt > 0);
    format.close();
  }
 catch (  IOException e) {
    Assert.fail();
  }
catch (  RuntimeException e) {
    if (e.getMessage().equals(""String_Node_Str"")) {
      processDestroyed=true;
    }
  }
 finally {
    Assert.assertTrue(processDestroyed);
  }
}","@Test public void testOpen(){
  if (FileSystem.isWindows())   return;
  Configuration config=new Configuration();
  config.setInteger(ExternalProcessFixedLengthInputFormat.RECORDLENGTH_PARAMETER_KEY,8);
  ExternalProcessInputSplit split=new ExternalProcessInputSplit(1,this.neverEndingCommand);
  boolean processDestroyed=false;
  try {
    format.configure(config);
    format.open(split);
    String[] cmd={""String_Node_Str"",""String_Node_Str"",""String_Node_Str""};
    byte[] wcOut=new byte[128];
    Process p=Runtime.getRuntime().exec(cmd);
    p.getInputStream().read(wcOut);
    int pCnt=Integer.parseInt(new String(wcOut).trim());
    Assert.assertTrue(pCnt > 0);
    format.close();
  }
 catch (  IOException e) {
    Assert.fail();
  }
catch (  RuntimeException e) {
    if (e.getMessage().equals(""String_Node_Str"")) {
      processDestroyed=true;
    }
  }
 finally {
    Assert.assertTrue(processDestroyed);
  }
}",0.9778270509977828
55142,"@Test public void testOpen(){
  Configuration config=new Configuration();
  ExternalProcessInputSplit split=new ExternalProcessInputSplit(1,this.neverEndingCommand);
  boolean processDestroyed=false;
  try {
    format.configure(config);
    format.open(split);
    String[] cmd={""String_Node_Str"",""String_Node_Str"",""String_Node_Str""};
    byte[] wcOut=new byte[128];
    Process p=Runtime.getRuntime().exec(cmd);
    p.getInputStream().read(wcOut);
    int pCnt=Integer.parseInt(new String(wcOut).trim());
    Assert.assertTrue(pCnt > 0);
    format.close();
  }
 catch (  IOException e) {
    Assert.fail();
  }
catch (  RuntimeException e) {
    if (e.getMessage().equals(""String_Node_Str"")) {
      processDestroyed=true;
    }
  }
 finally {
    Assert.assertTrue(processDestroyed);
  }
}","@Test public void testOpen(){
  if (FileSystem.isWindows())   return;
  Configuration config=new Configuration();
  ExternalProcessInputSplit split=new ExternalProcessInputSplit(1,this.neverEndingCommand);
  boolean processDestroyed=false;
  try {
    format.configure(config);
    format.open(split);
    String[] cmd={""String_Node_Str"",""String_Node_Str"",""String_Node_Str""};
    byte[] wcOut=new byte[128];
    Process p=Runtime.getRuntime().exec(cmd);
    p.getInputStream().read(wcOut);
    int pCnt=Integer.parseInt(new String(wcOut).trim());
    Assert.assertTrue(pCnt > 0);
    format.close();
  }
 catch (  IOException e) {
    Assert.fail();
  }
catch (  RuntimeException e) {
    if (e.getMessage().equals(""String_Node_Str"")) {
      processDestroyed=true;
    }
  }
 finally {
    Assert.assertTrue(processDestroyed);
  }
}",0.97539975399754
55143,"private FileInputSplit createTempFile(int[] contents) throws IOException {
  this.tempFile=File.createTempFile(""String_Node_Str"",""String_Node_Str"");
  DataOutputStream dos=new DataOutputStream(new FileOutputStream(tempFile));
  for (  int i : contents) {
    dos.writeInt(i);
  }
  dos.close();
  return new FileInputSplit(0,new Path(""String_Node_Str"" + this.tempFile.getAbsolutePath()),0,this.tempFile.length(),new String[]{""String_Node_Str""});
}","private FileInputSplit createTempFile(int[] contents) throws IOException {
  this.tempFile=File.createTempFile(""String_Node_Str"",""String_Node_Str"");
  DataOutputStream dos=new DataOutputStream(new FileOutputStream(tempFile));
  for (  int i : contents) {
    dos.writeInt(i);
  }
  dos.close();
  return new FileInputSplit(0,new Path(this.tempFile.toURI().toString()),0,this.tempFile.length(),new String[]{""String_Node_Str""});
}",0.9097142857142856
55144,"private FileInputSplit createTempFile(String content) throws IOException {
  this.tempFile=File.createTempFile(""String_Node_Str"",""String_Node_Str"");
  this.tempFile.deleteOnExit();
  DataOutputStream dos=new DataOutputStream(new FileOutputStream(tempFile));
  dos.writeBytes(content);
  dos.close();
  return new FileInputSplit(0,new Path(""String_Node_Str"" + this.tempFile.getAbsolutePath()),0,this.tempFile.length(),new String[]{""String_Node_Str""});
}","private FileInputSplit createTempFile(String content) throws IOException {
  this.tempFile=File.createTempFile(""String_Node_Str"",""String_Node_Str"");
  this.tempFile.deleteOnExit();
  DataOutputStream dos=new DataOutputStream(new FileOutputStream(tempFile));
  dos.writeBytes(content);
  dos.close();
  return new FileInputSplit(0,new Path(this.tempFile.toURI().toString()),0,this.tempFile.length(),new String[]{""String_Node_Str""});
}",0.9107344632768362
55145,"@Test public void testWriteNoRecPosNoLenient(){
  try {
    Configuration config=new Configuration();
    config.setString(RecordOutputFormat.FILE_PARAMETER_KEY,""String_Node_Str"" + this.tempFile.getAbsolutePath());
    config.setString(RecordOutputFormat.FIELD_DELIMITER_PARAMETER,""String_Node_Str"");
    config.setInteger(RecordOutputFormat.NUM_FIELDS_PARAMETER,2);
    config.setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 0,PactString.class);
    config.setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 1,PactInteger.class);
    format.configure(config);
    try {
      format.open(0);
    }
 catch (    IOException e) {
      fail(e.getMessage());
    }
    PactRecord r=new PactRecord(2);
    try {
      r.setField(0,new PactString(""String_Node_Str""));
      r.setField(1,new PactInteger(42));
      format.writeRecord(r);
      r.setField(0,new PactString(""String_Node_Str""));
      r.setField(1,new PactInteger(13));
      format.writeRecord(r);
      format.close();
      BufferedReader dis=new BufferedReader(new FileReader(tempFile));
      assertTrue((dis.readLine() + ""String_Node_Str"").equals(""String_Node_Str""));
      assertTrue((dis.readLine() + ""String_Node_Str"").equals(""String_Node_Str""));
      dis.close();
    }
 catch (    IOException e) {
      fail(e.getMessage());
    }
  }
 catch (  Exception ex) {
    Assert.fail(""String_Node_Str"" + ex.getClass().getSimpleName() + ""String_Node_Str""+ ex.getMessage());
  }
}","@Test public void testWriteNoRecPosNoLenient(){
  try {
    Configuration config=new Configuration();
    config.setString(RecordOutputFormat.FILE_PARAMETER_KEY,this.tempFile.toURI().toString());
    config.setString(RecordOutputFormat.FIELD_DELIMITER_PARAMETER,""String_Node_Str"");
    config.setInteger(RecordOutputFormat.NUM_FIELDS_PARAMETER,2);
    config.setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 0,PactString.class);
    config.setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 1,PactInteger.class);
    format.configure(config);
    try {
      format.open(0);
    }
 catch (    IOException e) {
      fail(e.getMessage());
    }
    PactRecord r=new PactRecord(2);
    try {
      r.setField(0,new PactString(""String_Node_Str""));
      r.setField(1,new PactInteger(42));
      format.writeRecord(r);
      r.setField(0,new PactString(""String_Node_Str""));
      r.setField(1,new PactInteger(13));
      format.writeRecord(r);
      format.close();
      BufferedReader dis=new BufferedReader(new FileReader(tempFile));
      assertTrue((dis.readLine() + ""String_Node_Str"").equals(""String_Node_Str""));
      assertTrue((dis.readLine() + ""String_Node_Str"").equals(""String_Node_Str""));
      dis.close();
    }
 catch (    IOException e) {
      fail(e.getMessage());
    }
  }
 catch (  Exception ex) {
    Assert.fail(""String_Node_Str"" + ex.getClass().getSimpleName() + ""String_Node_Str""+ ex.getMessage());
  }
}",0.9824198552223372
55146,"@Test public void testWriteRecPosNoLenient(){
  try {
    Configuration config=new Configuration();
    config.setString(RecordOutputFormat.FILE_PARAMETER_KEY,""String_Node_Str"" + this.tempFile.getAbsolutePath());
    config.setString(RecordOutputFormat.FIELD_DELIMITER_PARAMETER,""String_Node_Str"");
    config.setInteger(RecordOutputFormat.NUM_FIELDS_PARAMETER,2);
    config.setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 0,PactString.class);
    config.setInteger(RecordOutputFormat.RECORD_POSITION_PARAMETER_PREFIX + 0,2);
    config.setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 1,PactString.class);
    config.setInteger(RecordOutputFormat.RECORD_POSITION_PARAMETER_PREFIX + 1,0);
    format.configure(config);
    try {
      format.open(0);
    }
 catch (    IOException e) {
      fail(e.getMessage());
    }
    PactRecord r=new PactRecord(2);
    try {
      r.setField(0,new PactString(""String_Node_Str""));
      r.setField(1,new PactInteger(42));
      r.setField(2,new PactString(""String_Node_Str""));
      format.writeRecord(r);
      r.setField(0,new PactString(""String_Node_Str""));
      r.setField(1,new PactInteger(13));
      r.setField(2,new PactString(""String_Node_Str""));
      format.writeRecord(r);
      format.close();
      BufferedReader dis=new BufferedReader(new FileReader(tempFile));
      assertTrue((dis.readLine() + ""String_Node_Str"").equals(""String_Node_Str""));
      assertTrue((dis.readLine() + ""String_Node_Str"").equals(""String_Node_Str""));
      dis.close();
    }
 catch (    IOException e) {
      fail(e.getMessage());
    }
  }
 catch (  Exception ex) {
    Assert.fail(""String_Node_Str"" + ex.getClass().getSimpleName() + ""String_Node_Str""+ ex.getMessage());
  }
}","@Test public void testWriteRecPosNoLenient(){
  try {
    Configuration config=new Configuration();
    config.setString(RecordOutputFormat.FILE_PARAMETER_KEY,this.tempFile.toURI().toString());
    config.setString(RecordOutputFormat.FIELD_DELIMITER_PARAMETER,""String_Node_Str"");
    config.setInteger(RecordOutputFormat.NUM_FIELDS_PARAMETER,2);
    config.setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 0,PactString.class);
    config.setInteger(RecordOutputFormat.RECORD_POSITION_PARAMETER_PREFIX + 0,2);
    config.setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 1,PactString.class);
    config.setInteger(RecordOutputFormat.RECORD_POSITION_PARAMETER_PREFIX + 1,0);
    format.configure(config);
    try {
      format.open(0);
    }
 catch (    IOException e) {
      fail(e.getMessage());
    }
    PactRecord r=new PactRecord(2);
    try {
      r.setField(0,new PactString(""String_Node_Str""));
      r.setField(1,new PactInteger(42));
      r.setField(2,new PactString(""String_Node_Str""));
      format.writeRecord(r);
      r.setField(0,new PactString(""String_Node_Str""));
      r.setField(1,new PactInteger(13));
      r.setField(2,new PactString(""String_Node_Str""));
      format.writeRecord(r);
      format.close();
      BufferedReader dis=new BufferedReader(new FileReader(tempFile));
      assertTrue((dis.readLine() + ""String_Node_Str"").equals(""String_Node_Str""));
      assertTrue((dis.readLine() + ""String_Node_Str"").equals(""String_Node_Str""));
      dis.close();
    }
 catch (    IOException e) {
      fail(e.getMessage());
    }
  }
 catch (  Exception ex) {
    Assert.fail(""String_Node_Str"" + ex.getClass().getSimpleName() + ""String_Node_Str""+ ex.getMessage());
  }
}",0.9851873366250364
55147,"@Test public void testWriteRecPosNoLenientFail(){
  try {
    Configuration config=new Configuration();
    config.setString(RecordOutputFormat.FILE_PARAMETER_KEY,""String_Node_Str"" + this.tempFile.getAbsolutePath());
    config.setString(RecordOutputFormat.FIELD_DELIMITER_PARAMETER,""String_Node_Str"");
    config.setInteger(RecordOutputFormat.NUM_FIELDS_PARAMETER,2);
    config.setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 0,PactString.class);
    config.setInteger(RecordOutputFormat.RECORD_POSITION_PARAMETER_PREFIX + 0,2);
    config.setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 1,PactString.class);
    config.setInteger(RecordOutputFormat.RECORD_POSITION_PARAMETER_PREFIX + 1,0);
    format.configure(config);
    try {
      format.open(0);
    }
 catch (    IOException e) {
      fail(e.getMessage());
    }
    PactRecord r=new PactRecord(2);
    boolean success=true;
    try {
      r.setField(0,new PactString(""String_Node_Str""));
      r.setField(1,new PactInteger(42));
      r.setField(2,new PactString(""String_Node_Str""));
      format.writeRecord(r);
      r=new PactRecord();
      r.setField(0,new PactString(""String_Node_Str""));
      r.setField(1,new PactInteger(13));
      format.writeRecord(r);
      format.close();
    }
 catch (    IOException e) {
      success=false;
    }
catch (    RuntimeException re) {
      success=false;
    }
    assertFalse(success);
  }
 catch (  Exception ex) {
    Assert.fail(""String_Node_Str"" + ex.getClass().getSimpleName() + ""String_Node_Str""+ ex.getMessage());
  }
}","@Test public void testWriteRecPosNoLenientFail(){
  try {
    Configuration config=new Configuration();
    config.setString(RecordOutputFormat.FILE_PARAMETER_KEY,this.tempFile.toURI().toString());
    config.setString(RecordOutputFormat.FIELD_DELIMITER_PARAMETER,""String_Node_Str"");
    config.setInteger(RecordOutputFormat.NUM_FIELDS_PARAMETER,2);
    config.setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 0,PactString.class);
    config.setInteger(RecordOutputFormat.RECORD_POSITION_PARAMETER_PREFIX + 0,2);
    config.setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 1,PactString.class);
    config.setInteger(RecordOutputFormat.RECORD_POSITION_PARAMETER_PREFIX + 1,0);
    format.configure(config);
    try {
      format.open(0);
    }
 catch (    IOException e) {
      fail(e.getMessage());
    }
    PactRecord r=new PactRecord(2);
    boolean success=true;
    try {
      r.setField(0,new PactString(""String_Node_Str""));
      r.setField(1,new PactInteger(42));
      r.setField(2,new PactString(""String_Node_Str""));
      format.writeRecord(r);
      r=new PactRecord();
      r.setField(0,new PactString(""String_Node_Str""));
      r.setField(1,new PactInteger(13));
      format.writeRecord(r);
      format.close();
    }
 catch (    IOException e) {
      success=false;
    }
catch (    RuntimeException re) {
      success=false;
    }
    assertFalse(success);
  }
 catch (  Exception ex) {
    Assert.fail(""String_Node_Str"" + ex.getClass().getSimpleName() + ""String_Node_Str""+ ex.getMessage());
  }
}",0.9835324507587988
55148,"@Test public void testWriteNoRecPosNoLenientFail(){
  try {
    Configuration config=new Configuration();
    config.setString(RecordOutputFormat.FILE_PARAMETER_KEY,""String_Node_Str"" + this.tempFile.getAbsolutePath());
    config.setString(RecordOutputFormat.FIELD_DELIMITER_PARAMETER,""String_Node_Str"");
    config.setInteger(RecordOutputFormat.NUM_FIELDS_PARAMETER,2);
    config.setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 0,PactString.class);
    config.setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 1,PactInteger.class);
    format.configure(config);
    try {
      format.open(0);
    }
 catch (    IOException e) {
      fail(e.getMessage());
    }
    PactRecord r=new PactRecord(2);
    boolean success=true;
    try {
      r.setField(0,new PactString(""String_Node_Str""));
      r.setField(1,new PactInteger(42));
      format.writeRecord(r);
      r.setNull(0);
      r.setField(1,new PactInteger(13));
      format.writeRecord(r);
      format.close();
    }
 catch (    IOException e) {
      success=false;
    }
catch (    RuntimeException re) {
      success=false;
    }
    assertFalse(success);
  }
 catch (  Exception ex) {
    Assert.fail(""String_Node_Str"" + ex.getClass().getSimpleName() + ""String_Node_Str""+ ex.getMessage());
  }
}","@Test public void testWriteNoRecPosNoLenientFail(){
  try {
    Configuration config=new Configuration();
    config.setString(RecordOutputFormat.FILE_PARAMETER_KEY,this.tempFile.toURI().toString());
    config.setString(RecordOutputFormat.FIELD_DELIMITER_PARAMETER,""String_Node_Str"");
    config.setInteger(RecordOutputFormat.NUM_FIELDS_PARAMETER,2);
    config.setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 0,PactString.class);
    config.setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 1,PactInteger.class);
    format.configure(config);
    try {
      format.open(0);
    }
 catch (    IOException e) {
      fail(e.getMessage());
    }
    PactRecord r=new PactRecord(2);
    boolean success=true;
    try {
      r.setField(0,new PactString(""String_Node_Str""));
      r.setField(1,new PactInteger(42));
      format.writeRecord(r);
      r.setNull(0);
      r.setField(1,new PactInteger(13));
      format.writeRecord(r);
      format.close();
    }
 catch (    IOException e) {
      success=false;
    }
catch (    RuntimeException re) {
      success=false;
    }
    assertFalse(success);
  }
 catch (  Exception ex) {
    Assert.fail(""String_Node_Str"" + ex.getClass().getSimpleName() + ""String_Node_Str""+ ex.getMessage());
  }
}",0.9799449469130947
55149,"@Test public void testWriteNoRecPosLenient(){
  try {
    Configuration config=new Configuration();
    config.setString(RecordOutputFormat.FILE_PARAMETER_KEY,""String_Node_Str"" + this.tempFile.getAbsolutePath());
    config.setString(RecordOutputFormat.FIELD_DELIMITER_PARAMETER,""String_Node_Str"");
    config.setInteger(RecordOutputFormat.NUM_FIELDS_PARAMETER,2);
    config.setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 0,PactString.class);
    config.setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 1,PactInteger.class);
    config.setBoolean(RecordOutputFormat.LENIENT_PARSING,true);
    format.configure(config);
    try {
      format.open(0);
    }
 catch (    IOException e) {
      fail(e.getMessage());
    }
    PactRecord r=new PactRecord(2);
    try {
      r.setField(0,new PactString(""String_Node_Str""));
      r.setField(1,new PactInteger(42));
      format.writeRecord(r);
      r.setNull(0);
      r.setField(1,new PactInteger(13));
      format.writeRecord(r);
      format.close();
      BufferedReader dis=new BufferedReader(new FileReader(tempFile));
      assertTrue((dis.readLine() + ""String_Node_Str"").equals(""String_Node_Str""));
      assertTrue((dis.readLine() + ""String_Node_Str"").equals(""String_Node_Str""));
      dis.close();
    }
 catch (    IOException e) {
      fail(e.getMessage());
    }
  }
 catch (  Exception ex) {
    Assert.fail(""String_Node_Str"" + ex.getClass().getSimpleName() + ""String_Node_Str""+ ex.getMessage());
  }
}","@Test public void testWriteNoRecPosLenient(){
  try {
    Configuration config=new Configuration();
    config.setString(RecordOutputFormat.FILE_PARAMETER_KEY,this.tempFile.toURI().toString());
    config.setString(RecordOutputFormat.FIELD_DELIMITER_PARAMETER,""String_Node_Str"");
    config.setInteger(RecordOutputFormat.NUM_FIELDS_PARAMETER,2);
    config.setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 0,PactString.class);
    config.setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 1,PactInteger.class);
    config.setBoolean(RecordOutputFormat.LENIENT_PARSING,true);
    format.configure(config);
    try {
      format.open(0);
    }
 catch (    IOException e) {
      fail(e.getMessage());
    }
    PactRecord r=new PactRecord(2);
    try {
      r.setField(0,new PactString(""String_Node_Str""));
      r.setField(1,new PactInteger(42));
      format.writeRecord(r);
      r.setNull(0);
      r.setField(1,new PactInteger(13));
      format.writeRecord(r);
      format.close();
      BufferedReader dis=new BufferedReader(new FileReader(tempFile));
      assertTrue((dis.readLine() + ""String_Node_Str"").equals(""String_Node_Str""));
      assertTrue((dis.readLine() + ""String_Node_Str"").equals(""String_Node_Str""));
      dis.close();
    }
 catch (    IOException e) {
      fail(e.getMessage());
    }
  }
 catch (  Exception ex) {
    Assert.fail(""String_Node_Str"" + ex.getClass().getSimpleName() + ""String_Node_Str""+ ex.getMessage());
  }
}",0.9827411167512692
55150,"@Test public void testConfigure(){
  try {
    Configuration config=new Configuration();
    config.setString(RecordOutputFormat.FILE_PARAMETER_KEY,""String_Node_Str"" + this.tempFile.getAbsolutePath());
    boolean validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertFalse(validConfig);
    config.setInteger(RecordOutputFormat.NUM_FIELDS_PARAMETER,2);
    validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertFalse(validConfig);
    config.setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 0,PactString.class);
    config.setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 1,PactInteger.class);
    validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertTrue(validConfig);
    config.setInteger(RecordOutputFormat.NUM_FIELDS_PARAMETER,3);
    validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertFalse(validConfig);
    config.setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 2,PactString.class);
    validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertTrue(validConfig);
    config.setString(RecordOutputFormat.FIELD_DELIMITER_PARAMETER,""String_Node_Str"");
    validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
      System.out.println(iae.getMessage());
    }
    assertTrue(validConfig);
    config.setInteger(RecordOutputFormat.RECORD_POSITION_PARAMETER_PREFIX + 1,0);
    validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertFalse(validConfig);
    config.setInteger(RecordOutputFormat.RECORD_POSITION_PARAMETER_PREFIX + 0,3);
    config.setInteger(RecordOutputFormat.RECORD_POSITION_PARAMETER_PREFIX + 2,9);
    validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertTrue(validConfig);
  }
 catch (  Exception ex) {
    Assert.fail(""String_Node_Str"" + ex.getClass().getSimpleName() + ""String_Node_Str""+ ex.getMessage());
  }
}","@Test public void testConfigure(){
  try {
    Configuration config=new Configuration();
    config.setString(RecordOutputFormat.FILE_PARAMETER_KEY,this.tempFile.toURI().toString());
    boolean validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertFalse(validConfig);
    config.setInteger(RecordOutputFormat.NUM_FIELDS_PARAMETER,2);
    validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertFalse(validConfig);
    config.setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 0,PactString.class);
    config.setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 1,PactInteger.class);
    validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertTrue(validConfig);
    config.setInteger(RecordOutputFormat.NUM_FIELDS_PARAMETER,3);
    validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertFalse(validConfig);
    config.setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 2,PactString.class);
    validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertTrue(validConfig);
    config.setString(RecordOutputFormat.FIELD_DELIMITER_PARAMETER,""String_Node_Str"");
    validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
      System.out.println(iae.getMessage());
    }
    assertTrue(validConfig);
    config.setInteger(RecordOutputFormat.RECORD_POSITION_PARAMETER_PREFIX + 1,0);
    validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertFalse(validConfig);
    config.setInteger(RecordOutputFormat.RECORD_POSITION_PARAMETER_PREFIX + 0,3);
    config.setInteger(RecordOutputFormat.RECORD_POSITION_PARAMETER_PREFIX + 2,9);
    validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertTrue(validConfig);
  }
 catch (  Exception ex) {
    Assert.fail(""String_Node_Str"" + ex.getClass().getSimpleName() + ""String_Node_Str""+ ex.getMessage());
  }
}",0.4456370502882131
55151,"@Test public void testWriteRecPosLenient(){
  try {
    Configuration config=new Configuration();
    config.setString(RecordOutputFormat.FILE_PARAMETER_KEY,""String_Node_Str"" + this.tempFile.getAbsolutePath());
    config.setString(RecordOutputFormat.FIELD_DELIMITER_PARAMETER,""String_Node_Str"");
    config.setInteger(RecordOutputFormat.NUM_FIELDS_PARAMETER,2);
    config.setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 0,PactString.class);
    config.setInteger(RecordOutputFormat.RECORD_POSITION_PARAMETER_PREFIX + 0,2);
    config.setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 1,PactString.class);
    config.setInteger(RecordOutputFormat.RECORD_POSITION_PARAMETER_PREFIX + 1,0);
    config.setBoolean(RecordOutputFormat.LENIENT_PARSING,true);
    format.configure(config);
    try {
      format.open(0);
    }
 catch (    IOException e) {
      fail(e.getMessage());
    }
    PactRecord r=new PactRecord(2);
    try {
      r.setField(0,new PactString(""String_Node_Str""));
      r.setField(1,new PactInteger(42));
      r.setField(2,new PactString(""String_Node_Str""));
      format.writeRecord(r);
      r=new PactRecord();
      r.setField(0,new PactString(""String_Node_Str""));
      r.setField(1,new PactInteger(13));
      format.writeRecord(r);
      format.close();
      BufferedReader dis=new BufferedReader(new FileReader(tempFile));
      assertTrue((dis.readLine() + ""String_Node_Str"").equals(""String_Node_Str""));
      assertTrue((dis.readLine() + ""String_Node_Str"").equals(""String_Node_Str""));
      dis.close();
    }
 catch (    IOException e) {
      fail(e.getMessage());
    }
  }
 catch (  Exception ex) {
    Assert.fail(""String_Node_Str"" + ex.getClass().getSimpleName() + ""String_Node_Str""+ ex.getMessage());
  }
}","@Test public void testWriteRecPosLenient(){
  try {
    Configuration config=new Configuration();
    config.setString(RecordOutputFormat.FILE_PARAMETER_KEY,this.tempFile.toURI().toString());
    config.setString(RecordOutputFormat.FIELD_DELIMITER_PARAMETER,""String_Node_Str"");
    config.setInteger(RecordOutputFormat.NUM_FIELDS_PARAMETER,2);
    config.setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 0,PactString.class);
    config.setInteger(RecordOutputFormat.RECORD_POSITION_PARAMETER_PREFIX + 0,2);
    config.setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 1,PactString.class);
    config.setInteger(RecordOutputFormat.RECORD_POSITION_PARAMETER_PREFIX + 1,0);
    config.setBoolean(RecordOutputFormat.LENIENT_PARSING,true);
    format.configure(config);
    try {
      format.open(0);
    }
 catch (    IOException e) {
      fail(e.getMessage());
    }
    PactRecord r=new PactRecord(2);
    try {
      r.setField(0,new PactString(""String_Node_Str""));
      r.setField(1,new PactInteger(42));
      r.setField(2,new PactString(""String_Node_Str""));
      format.writeRecord(r);
      r=new PactRecord();
      r.setField(0,new PactString(""String_Node_Str""));
      r.setField(1,new PactInteger(13));
      format.writeRecord(r);
      format.close();
      BufferedReader dis=new BufferedReader(new FileReader(tempFile));
      assertTrue((dis.readLine() + ""String_Node_Str"").equals(""String_Node_Str""));
      assertTrue((dis.readLine() + ""String_Node_Str"").equals(""String_Node_Str""));
      dis.close();
    }
 catch (    IOException e) {
      fail(e.getMessage());
    }
  }
 catch (  Exception ex) {
    Assert.fail(""String_Node_Str"" + ex.getClass().getSimpleName() + ""String_Node_Str""+ ex.getMessage());
  }
}",0.9854659447135936
55152,"/** 
 * The TextInputFormat seems to fail reading more than one record. I guess its an off by one error. The easiest workaround is to setParameter(TextInputFormat.CHARSET_NAME, ""ASCII"");
 * @throws IOException
 */
@Test public void testPositionBug() throws IOException {
  File tempFile=File.createTempFile(""String_Node_Str"",null);
  tempFile.setWritable(true);
  PrintStream ps=new PrintStream(tempFile);
  ps.println(""String_Node_Str"");
  ps.println(""String_Node_Str"");
  ps.close();
  tempFile.deleteOnExit();
  TextInputFormat inputFormat=new TextInputFormat();
  Configuration parameters=new Configuration();
  parameters.setString(FileInputFormat.FILE_PARAMETER_KEY,""String_Node_Str"" + tempFile.getAbsolutePath());
  inputFormat.configure(parameters);
  FileInputSplit[] splits=inputFormat.createInputSplits(1);
  assertTrue(""String_Node_Str"",splits.length >= 1);
  inputFormat.open(splits[0]);
  PactRecord r=new PactRecord();
  assertTrue(""String_Node_Str"",inputFormat.nextRecord(r));
  try {
    assertTrue(""String_Node_Str"",inputFormat.nextRecord(r));
  }
 catch (  IllegalArgumentException iae) {
    iae.printStackTrace();
    fail(""String_Node_Str"");
  }
  assertFalse(""String_Node_Str"",inputFormat.nextRecord(r));
}","/** 
 * The TextInputFormat seems to fail reading more than one record. I guess its an off by one error. The easiest workaround is to setParameter(TextInputFormat.CHARSET_NAME, ""ASCII"");
 * @throws IOException
 */
@Test public void testPositionBug() throws IOException {
  File tempFile=File.createTempFile(""String_Node_Str"",null);
  tempFile.setWritable(true);
  PrintStream ps=new PrintStream(tempFile);
  ps.println(""String_Node_Str"");
  ps.println(""String_Node_Str"");
  ps.close();
  tempFile.deleteOnExit();
  TextInputFormat inputFormat=new TextInputFormat();
  Configuration parameters=new Configuration();
  parameters.setString(FileInputFormat.FILE_PARAMETER_KEY,tempFile.toURI().toString());
  inputFormat.configure(parameters);
  FileInputSplit[] splits=inputFormat.createInputSplits(1);
  assertTrue(""String_Node_Str"",splits.length >= 1);
  inputFormat.open(splits[0]);
  PactRecord r=new PactRecord();
  assertTrue(""String_Node_Str"",inputFormat.nextRecord(r));
  try {
    assertTrue(""String_Node_Str"",inputFormat.nextRecord(r));
  }
 catch (  IllegalArgumentException iae) {
    iae.printStackTrace();
    fail(""String_Node_Str"");
  }
  assertFalse(""String_Node_Str"",inputFormat.nextRecord(r));
}",0.971709717097171
55153,"public static String createTempFileDir(String... contents) throws IOException {
  File tempDir=new File(System.getProperty(""String_Node_Str""));
  File f=null;
  do {
    f=new File(tempDir,randomFileName());
  }
 while (f.exists());
  f.mkdirs();
  f.deleteOnExit();
  for (  String s : contents) {
    File child=new File(f,randomFileName());
    child.deleteOnExit();
    BufferedWriter out=new BufferedWriter(new FileWriter(child));
    try {
      out.write(s);
    }
  finally {
      out.close();
    }
  }
  return f.getAbsolutePath();
}","public static String createTempFileDir(String... contents) throws IOException {
  File tempDir=new File(System.getProperty(""String_Node_Str""));
  File f=null;
  do {
    f=new File(tempDir,randomFileName());
  }
 while (f.exists());
  f.mkdirs();
  f.deleteOnExit();
  for (  String s : contents) {
    File child=new File(f,randomFileName());
    child.deleteOnExit();
    BufferedWriter out=new BufferedWriter(new FileWriter(child));
    try {
      out.write(s);
    }
  finally {
      out.close();
    }
  }
  return f.toURI().toString();
}",0.9733700642791552
55154,"public static Configuration getConfigForFile(long bytes) throws IOException {
  final String filePath=createTempFile(bytes);
  final Configuration config=new Configuration();
  config.setString(FileInputFormat.FILE_PARAMETER_KEY,""String_Node_Str"" + filePath);
  return config;
}","public static Configuration getConfigForFile(long bytes) throws IOException {
  final String filePath=createTempFile(bytes);
  final Configuration config=new Configuration();
  config.setString(FileInputFormat.FILE_PARAMETER_KEY,filePath);
  return config;
}",0.9626865671641792
55155,"public static String createTempFile(String contents) throws IOException {
  File f=File.createTempFile(FILE_PREFIX,FILE_SUFFIX);
  f.deleteOnExit();
  BufferedWriter out=new BufferedWriter(new FileWriter(f));
  try {
    out.write(contents);
  }
  finally {
    out.close();
  }
  return f.getAbsolutePath();
}","public static String createTempFile(String contents) throws IOException {
  File f=File.createTempFile(FILE_PREFIX,FILE_SUFFIX);
  f.deleteOnExit();
  BufferedWriter out=new BufferedWriter(new FileWriter(f));
  try {
    out.write(contents);
  }
  finally {
    out.close();
  }
  return f.toURI().toString();
}",0.9533011272141708
55156,"public static Configuration getConfigForDir(long... bytes) throws IOException {
  final String filePath=createTempFileDir(bytes);
  final Configuration config=new Configuration();
  config.setString(FileInputFormat.FILE_PARAMETER_KEY,""String_Node_Str"" + filePath);
  return config;
}","public static Configuration getConfigForDir(long... bytes) throws IOException {
  final String filePath=createTempFileDir(bytes);
  final Configuration config=new Configuration();
  config.setString(FileInputFormat.FILE_PARAMETER_KEY,filePath);
  return config;
}",0.9633699633699634
55157,"@Test public void testNumSamplesOneFile(){
  try {
    final String tempFile=TestFileUtils.createTempFile(TEST_DATA1);
    final Configuration conf=new Configuration();
    conf.setString(FileInputFormat.FILE_PARAMETER_KEY,""String_Node_Str"" + tempFile);
    final TestDelimitedInputFormat format=new TestDelimitedInputFormat();
    format.configure(conf);
    TestFileSystem.resetStreamOpenCounter();
    format.getStatistics(null);
    Assert.assertEquals(""String_Node_Str"",DEFAULT_NUM_SAMPLES,TestFileSystem.getNumtimeStreamOpened());
    conf.setString(TestDelimitedInputFormat.NUM_STATISTICS_SAMPLES,""String_Node_Str"");
    final TestDelimitedInputFormat format2=new TestDelimitedInputFormat();
    format2.configure(conf);
    TestFileSystem.resetStreamOpenCounter();
    format2.getStatistics(null);
    Assert.assertEquals(""String_Node_Str"",8,TestFileSystem.getNumtimeStreamOpened());
  }
 catch (  Exception e) {
    e.printStackTrace();
    Assert.fail(e.getMessage());
  }
}","@Test public void testNumSamplesOneFile(){
  try {
    final String tempFile=TestFileUtils.createTempFile(TEST_DATA1);
    final Configuration conf=new Configuration();
    conf.setString(FileInputFormat.FILE_PARAMETER_KEY,tempFile.replace(""String_Node_Str"",""String_Node_Str""));
    final TestDelimitedInputFormat format=new TestDelimitedInputFormat();
    format.configure(conf);
    TestFileSystem.resetStreamOpenCounter();
    format.getStatistics(null);
    Assert.assertEquals(""String_Node_Str"",DEFAULT_NUM_SAMPLES,TestFileSystem.getNumtimeStreamOpened());
    conf.setString(TestDelimitedInputFormat.NUM_STATISTICS_SAMPLES,""String_Node_Str"");
    final TestDelimitedInputFormat format2=new TestDelimitedInputFormat();
    format2.configure(conf);
    TestFileSystem.resetStreamOpenCounter();
    format2.getStatistics(null);
    Assert.assertEquals(""String_Node_Str"",8,TestFileSystem.getNumtimeStreamOpened());
  }
 catch (  Exception e) {
    e.printStackTrace();
    Assert.fail(e.getMessage());
  }
}",0.9764174611138986
55158,"@Test public void testSamplingDirectory(){
  try {
    final String tempFile=TestFileUtils.createTempFileDir(TEST_DATA1,TEST_DATA2);
    final Configuration conf=new Configuration();
    conf.setString(FileInputFormat.FILE_PARAMETER_KEY,""String_Node_Str"" + tempFile);
    final TestDelimitedInputFormat format=new TestDelimitedInputFormat();
    format.configure(conf);
    BaseStatistics stats=format.getStatistics(null);
    final int maxNumLines=(int)Math.ceil(TOTAL_SIZE / ((double)Math.min(TEST_DATA_1_LINEWIDTH,TEST_DATA_2_LINEWIDTH)));
    final int minNumLines=(int)(TOTAL_SIZE / ((double)Math.max(TEST_DATA_1_LINEWIDTH,TEST_DATA_2_LINEWIDTH)));
    final float maxAvgWidth=((float)(TOTAL_SIZE)) / minNumLines;
    final float minAvgWidth=((float)(TOTAL_SIZE)) / maxNumLines;
    if (!(stats.getNumberOfRecords() <= maxNumLines & stats.getNumberOfRecords() >= minNumLines)) {
      System.err.println(""String_Node_Str"" + stats.getNumberOfRecords() + ""String_Node_Str""+ minNumLines+ ""String_Node_Str""+ maxNumLines+ ""String_Node_Str"");
      Assert.fail(""String_Node_Str"");
    }
    if (!(stats.getAverageRecordWidth() <= maxAvgWidth & stats.getAverageRecordWidth() >= minAvgWidth)) {
      Assert.fail(""String_Node_Str"");
    }
  }
 catch (  Exception e) {
    e.printStackTrace();
    Assert.fail(e.getMessage());
  }
}","@Test public void testSamplingDirectory(){
  try {
    final String tempFile=TestFileUtils.createTempFileDir(TEST_DATA1,TEST_DATA2);
    final Configuration conf=new Configuration();
    conf.setString(FileInputFormat.FILE_PARAMETER_KEY,tempFile);
    final TestDelimitedInputFormat format=new TestDelimitedInputFormat();
    format.configure(conf);
    BaseStatistics stats=format.getStatistics(null);
    final int maxNumLines=(int)Math.ceil(TOTAL_SIZE / ((double)Math.min(TEST_DATA_1_LINEWIDTH,TEST_DATA_2_LINEWIDTH)));
    final int minNumLines=(int)(TOTAL_SIZE / ((double)Math.max(TEST_DATA_1_LINEWIDTH,TEST_DATA_2_LINEWIDTH)));
    final float maxAvgWidth=((float)(TOTAL_SIZE)) / minNumLines;
    final float minAvgWidth=((float)(TOTAL_SIZE)) / maxNumLines;
    if (!(stats.getNumberOfRecords() <= maxNumLines & stats.getNumberOfRecords() >= minNumLines)) {
      System.err.println(""String_Node_Str"" + stats.getNumberOfRecords() + ""String_Node_Str""+ minNumLines+ ""String_Node_Str""+ maxNumLines+ ""String_Node_Str"");
      Assert.fail(""String_Node_Str"");
    }
    if (!(stats.getAverageRecordWidth() <= maxAvgWidth & stats.getAverageRecordWidth() >= minAvgWidth)) {
      Assert.fail(""String_Node_Str"");
    }
  }
 catch (  Exception e) {
    e.printStackTrace();
    Assert.fail(e.getMessage());
  }
}",0.992412746585736
55159,"@Test public void testNumSamplesMultipleFiles(){
  try {
    final String tempFile=TestFileUtils.createTempFileDir(TEST_DATA1,TEST_DATA1,TEST_DATA1,TEST_DATA1);
    final Configuration conf=new Configuration();
    conf.setString(FileInputFormat.FILE_PARAMETER_KEY,""String_Node_Str"" + tempFile);
    final TestDelimitedInputFormat format=new TestDelimitedInputFormat();
    format.configure(conf);
    TestFileSystem.resetStreamOpenCounter();
    format.getStatistics(null);
    Assert.assertEquals(""String_Node_Str"",DEFAULT_NUM_SAMPLES,TestFileSystem.getNumtimeStreamOpened());
    conf.setString(TestDelimitedInputFormat.NUM_STATISTICS_SAMPLES,""String_Node_Str"");
    final TestDelimitedInputFormat format2=new TestDelimitedInputFormat();
    format2.configure(conf);
    TestFileSystem.resetStreamOpenCounter();
    format2.getStatistics(null);
    Assert.assertEquals(""String_Node_Str"",8,TestFileSystem.getNumtimeStreamOpened());
  }
 catch (  Exception e) {
    e.printStackTrace();
    Assert.fail(e.getMessage());
  }
}","@Test public void testNumSamplesMultipleFiles(){
  try {
    final String tempFile=TestFileUtils.createTempFileDir(TEST_DATA1,TEST_DATA1,TEST_DATA1,TEST_DATA1);
    final Configuration conf=new Configuration();
    conf.setString(FileInputFormat.FILE_PARAMETER_KEY,tempFile.replace(""String_Node_Str"",""String_Node_Str""));
    final TestDelimitedInputFormat format=new TestDelimitedInputFormat();
    format.configure(conf);
    TestFileSystem.resetStreamOpenCounter();
    format.getStatistics(null);
    Assert.assertEquals(""String_Node_Str"",DEFAULT_NUM_SAMPLES,TestFileSystem.getNumtimeStreamOpened());
    conf.setString(TestDelimitedInputFormat.NUM_STATISTICS_SAMPLES,""String_Node_Str"");
    final TestDelimitedInputFormat format2=new TestDelimitedInputFormat();
    format2.configure(conf);
    TestFileSystem.resetStreamOpenCounter();
    format2.getStatistics(null);
    Assert.assertEquals(""String_Node_Str"",8,TestFileSystem.getNumtimeStreamOpened());
  }
 catch (  Exception e) {
    e.printStackTrace();
    Assert.fail(e.getMessage());
  }
}",0.9773712084737602
55160,"@Test public void testSamplingOverlyLongRecord(){
  try {
    final String tempFile=TestFileUtils.createTempFile(2 * PactConfigConstants.DEFAULT_DELIMITED_FORMAT_MAX_SAMPLE_LEN);
    final Configuration conf=new Configuration();
    conf.setString(FileInputFormat.FILE_PARAMETER_KEY,""String_Node_Str"" + tempFile);
    final TestDelimitedInputFormat format=new TestDelimitedInputFormat();
    format.configure(conf);
    Assert.assertNull(""String_Node_Str"",format.getStatistics(null));
  }
 catch (  Exception e) {
    e.printStackTrace();
    Assert.fail(e.getMessage());
  }
}","@Test public void testSamplingOverlyLongRecord(){
  try {
    final String tempFile=TestFileUtils.createTempFile(2 * PactConfigConstants.DEFAULT_DELIMITED_FORMAT_MAX_SAMPLE_LEN);
    final Configuration conf=new Configuration();
    conf.setString(FileInputFormat.FILE_PARAMETER_KEY,tempFile);
    final TestDelimitedInputFormat format=new TestDelimitedInputFormat();
    format.configure(conf);
    Assert.assertNull(""String_Node_Str"",format.getStatistics(null));
  }
 catch (  Exception e) {
    e.printStackTrace();
    Assert.fail(e.getMessage());
  }
}",0.982363315696649
55161,"@Test public void testSamplingOneFile(){
  try {
    final String tempFile=TestFileUtils.createTempFile(TEST_DATA1);
    final Configuration conf=new Configuration();
    conf.setString(FileInputFormat.FILE_PARAMETER_KEY,""String_Node_Str"" + tempFile);
    final TestDelimitedInputFormat format=new TestDelimitedInputFormat();
    format.configure(conf);
    BaseStatistics stats=format.getStatistics(null);
    final int numLines=TEST_DATA_1_LINES;
    final float avgWidth=((float)TEST_DATA1.length()) / TEST_DATA_1_LINES;
    Assert.assertTrue(""String_Node_Str"",stats.getNumberOfRecords() < numLines + 1 & stats.getNumberOfRecords() > numLines - 1);
    Assert.assertTrue(""String_Node_Str"",stats.getAverageRecordWidth() < avgWidth + 1 & stats.getAverageRecordWidth() > avgWidth - 1);
  }
 catch (  Exception e) {
    e.printStackTrace();
    Assert.fail(e.getMessage());
  }
}","@Test public void testSamplingOneFile(){
  try {
    final String tempFile=TestFileUtils.createTempFile(TEST_DATA1);
    final Configuration conf=new Configuration();
    conf.setString(FileInputFormat.FILE_PARAMETER_KEY,tempFile);
    final TestDelimitedInputFormat format=new TestDelimitedInputFormat();
    format.configure(conf);
    BaseStatistics stats=format.getStatistics(null);
    final int numLines=TEST_DATA_1_LINES;
    final float avgWidth=((float)TEST_DATA1.length()) / TEST_DATA_1_LINES;
    Assert.assertTrue(""String_Node_Str"",stats.getNumberOfRecords() < numLines + 1 & stats.getNumberOfRecords() > numLines - 1);
    Assert.assertTrue(""String_Node_Str"",stats.getAverageRecordWidth() < avgWidth + 1 & stats.getAverageRecordWidth() > avgWidth - 1);
  }
 catch (  Exception e) {
    e.printStackTrace();
    Assert.fail(e.getMessage());
  }
}",0.988479262672811
55162,"@Test public void testDifferentDelimiter(){
  try {
    final String DELIMITER=""String_Node_Str"";
    String testData=TEST_DATA1.replace(""String_Node_Str"",DELIMITER);
    final String tempFile=TestFileUtils.createTempFile(testData);
    final Configuration conf=new Configuration();
    conf.setString(FileInputFormat.FILE_PARAMETER_KEY,""String_Node_Str"" + tempFile);
    conf.setString(TestDelimitedInputFormat.RECORD_DELIMITER,DELIMITER);
    final TestDelimitedInputFormat format=new TestDelimitedInputFormat();
    format.configure(conf);
    BaseStatistics stats=format.getStatistics(null);
    final int numLines=TEST_DATA_1_LINES;
    final float avgWidth=((float)testData.length()) / TEST_DATA_1_LINES;
    Assert.assertTrue(""String_Node_Str"",stats.getNumberOfRecords() < numLines + 1 & stats.getNumberOfRecords() > numLines - 1);
    Assert.assertTrue(""String_Node_Str"",stats.getAverageRecordWidth() < avgWidth + 1 & stats.getAverageRecordWidth() > avgWidth - 1);
  }
 catch (  Exception e) {
    e.printStackTrace();
    Assert.fail(e.getMessage());
  }
}","@Test public void testDifferentDelimiter(){
  try {
    final String DELIMITER=""String_Node_Str"";
    String testData=TEST_DATA1.replace(""String_Node_Str"",DELIMITER);
    final String tempFile=TestFileUtils.createTempFile(testData);
    final Configuration conf=new Configuration();
    conf.setString(FileInputFormat.FILE_PARAMETER_KEY,tempFile);
    conf.setString(TestDelimitedInputFormat.RECORD_DELIMITER,DELIMITER);
    final TestDelimitedInputFormat format=new TestDelimitedInputFormat();
    format.configure(conf);
    BaseStatistics stats=format.getStatistics(null);
    final int numLines=TEST_DATA_1_LINES;
    final float avgWidth=((float)testData.length()) / TEST_DATA_1_LINES;
    Assert.assertTrue(""String_Node_Str"",stats.getNumberOfRecords() < numLines + 1 & stats.getNumberOfRecords() > numLines - 1);
    Assert.assertTrue(""String_Node_Str"",stats.getAverageRecordWidth() < avgWidth + 1 & stats.getAverageRecordWidth() > avgWidth - 1);
  }
 catch (  Exception e) {
    e.printStackTrace();
    Assert.fail(e.getMessage());
  }
}",0.990521327014218
55163,"private FileInputSplit createTempFile(String contents) throws IOException {
  this.tempFile=File.createTempFile(""String_Node_Str"",""String_Node_Str"");
  OutputStreamWriter wrt=new OutputStreamWriter(new FileOutputStream(this.tempFile));
  wrt.write(contents);
  wrt.close();
  return new FileInputSplit(0,new Path(""String_Node_Str"" + this.tempFile.getAbsolutePath()),0,this.tempFile.length(),new String[]{""String_Node_Str""});
}","private FileInputSplit createTempFile(String contents) throws IOException {
  this.tempFile=File.createTempFile(""String_Node_Str"",""String_Node_Str"");
  OutputStreamWriter wrt=new OutputStreamWriter(new FileOutputStream(this.tempFile));
  wrt.write(contents);
  wrt.close();
  return new FileInputSplit(0,new Path(this.tempFile.toURI().toString()),0,this.tempFile.length(),new String[]{""String_Node_Str""});
}",0.9051620648259304
55164,"/** 
 * Write out the tuples in a temporary file and return it.
 */
@Before public void writeTuples() throws IOException {
  this.tempFile=File.createTempFile(""String_Node_Str"",null);
  this.tempFile.deleteOnExit();
  Configuration configuration=new Configuration();
  configuration.setLong(BinaryOutputFormat.BLOCK_SIZE_PARAMETER_KEY,this.blockSize);
  if (this.degreeOfParallelism == 1) {
    SequentialOutputFormat output=FormatUtil.openOutput(SequentialOutputFormat.class,""String_Node_Str"" + this.tempFile.getAbsolutePath(),configuration);
    for (int index=0; index < this.numberOfTuples; index++)     output.writeRecord(this.getRecord(index));
    output.close();
  }
 else {
    this.tempFile.delete();
    this.tempFile.mkdir();
    int recordIndex=0;
    for (int fileIndex=0; fileIndex < this.degreeOfParallelism; fileIndex++) {
      SequentialOutputFormat output=FormatUtil.openOutput(SequentialOutputFormat.class,""String_Node_Str"" + this.tempFile.getAbsolutePath() + ""String_Node_Str""+ (fileIndex + 1),configuration);
      for (int fileCount=0; fileCount < this.getNumberOfTuplesPerFile(fileIndex); fileCount++, recordIndex++)       output.writeRecord(this.getRecord(recordIndex));
      output.close();
    }
  }
}","/** 
 * Write out the tuples in a temporary file and return it.
 */
@Before public void writeTuples() throws IOException {
  this.tempFile=File.createTempFile(""String_Node_Str"",null);
  this.tempFile.deleteOnExit();
  Configuration configuration=new Configuration();
  configuration.setLong(BinaryOutputFormat.BLOCK_SIZE_PARAMETER_KEY,this.blockSize);
  if (this.degreeOfParallelism == 1) {
    SequentialOutputFormat output=FormatUtil.openOutput(SequentialOutputFormat.class,this.tempFile.toURI().toString(),configuration);
    for (int index=0; index < this.numberOfTuples; index++)     output.writeRecord(this.getRecord(index));
    output.close();
  }
 else {
    this.tempFile.delete();
    this.tempFile.mkdir();
    int recordIndex=0;
    for (int fileIndex=0; fileIndex < this.degreeOfParallelism; fileIndex++) {
      SequentialOutputFormat output=FormatUtil.openOutput(SequentialOutputFormat.class,this.tempFile.toURI() + ""String_Node_Str"" + (fileIndex + 1),configuration);
      for (int fileCount=0; fileCount < this.getNumberOfTuplesPerFile(fileIndex); fileCount++, recordIndex++)       output.writeRecord(this.getRecord(recordIndex));
      output.close();
    }
  }
}",0.6019900497512438
55165,"protected SequentialInputFormat<PactRecord> createInputFormat(){
  Configuration configuration=new Configuration();
  configuration.setString(FileInputFormat.FILE_PARAMETER_KEY,""String_Node_Str"" + this.tempFile.getAbsolutePath());
  configuration.setLong(BinaryInputFormat.BLOCK_SIZE_PARAMETER_KEY,this.blockSize);
  final SequentialInputFormat<PactRecord> inputFormat=new SequentialInputFormat<PactRecord>();
  inputFormat.configure(configuration);
  return inputFormat;
}","protected SequentialInputFormat<PactRecord> createInputFormat(){
  Configuration configuration=new Configuration();
  configuration.setString(FileInputFormat.FILE_PARAMETER_KEY,this.tempFile.toURI().toString());
  configuration.setLong(BinaryInputFormat.BLOCK_SIZE_PARAMETER_KEY,this.blockSize);
  final SequentialInputFormat<PactRecord> inputFormat=new SequentialInputFormat<PactRecord>();
  inputFormat.configure(configuration);
  return inputFormat;
}",0.9449838187702264
55166,"/** 
 * This methods implements the pre-visiting during a depth-first traversal. It create the job vertex and sets local strategy.
 * @param node The node that is currently processed.
 * @return True, if the visitor should descend to the node's children, false if not.
 * @see eu.stratosphere.pact.common.util.Visitor#preVisit(eu.stratosphere.pact.common.plan.Visitable)
 */
@Override public boolean preVisit(PlanNode node){
  if (this.vertices.containsKey(node) || this.chainedTasks.containsKey(node)) {
    return false;
  }
  final AbstractJobVertex vertex;
  try {
    if (node instanceof SinkPlanNode) {
      vertex=createDataSinkVertex((SinkPlanNode)node);
    }
 else     if (node instanceof SourcePlanNode) {
      vertex=createDataSourceVertex((SourcePlanNode)node);
    }
 else     if (node instanceof BulkIterationPlanNode) {
      BulkIterationPlanNode iterationNode=(BulkIterationPlanNode)node;
      PlanNode root=iterationNode.getRootOfStepFunction();
      if (root.getDegreeOfParallelism() != node.getDegreeOfParallelism() || root.getSubtasksPerInstance() != node.getSubtasksPerInstance()) {
        throw new CompilerException(""String_Node_Str"" + ""String_Node_Str"");
      }
      IterationDescriptor descr=new IterationDescriptor(iterationNode,this.iterationIdEnumerator++);
      this.iterations.put(iterationNode,descr);
      vertex=null;
    }
 else     if (node instanceof WorksetIterationPlanNode) {
      WorksetIterationPlanNode iterationNode=(WorksetIterationPlanNode)node;
      PlanNode nextWorkSet=iterationNode.getNextWorkSetPlanNode();
      PlanNode solutionSetDelta=iterationNode.getSolutionSetDeltaPlanNode();
      if (nextWorkSet.getDegreeOfParallelism() != node.getDegreeOfParallelism() || nextWorkSet.getSubtasksPerInstance() != node.getSubtasksPerInstance()) {
        throw new CompilerException(""String_Node_Str"" + ""String_Node_Str"");
      }
      if (solutionSetDelta.getDegreeOfParallelism() != node.getDegreeOfParallelism() || solutionSetDelta.getSubtasksPerInstance() != node.getSubtasksPerInstance()) {
        throw new CompilerException(""String_Node_Str"" + ""String_Node_Str"");
      }
      IterationDescriptor descr=new IterationDescriptor(iterationNode,this.iterationIdEnumerator++);
      this.iterations.put(iterationNode,descr);
      vertex=null;
    }
 else     if (node instanceof SingleInputPlanNode) {
      vertex=createSingleInputVertex((SingleInputPlanNode)node);
    }
 else     if (node instanceof DualInputPlanNode) {
      vertex=createDualInputVertex((DualInputPlanNode)node);
    }
 else     if (node instanceof NAryUnionPlanNode) {
      vertex=null;
    }
 else     if (node instanceof BulkPartialSolutionPlanNode) {
      vertex=createBulkIterationHead((BulkPartialSolutionPlanNode)node);
    }
 else     if (node instanceof SolutionSetPlanNode) {
      vertex=null;
    }
 else     if (node instanceof WorksetPlanNode) {
      vertex=createWorksetIterationHead((WorksetPlanNode)node);
    }
 else {
      throw new CompilerException(""String_Node_Str"" + node.getClass().getName());
    }
  }
 catch (  Exception e) {
    throw new CompilerException(""String_Node_Str"" + node + ""String_Node_Str""+ e.getMessage(),e);
  }
  if (vertex != null) {
    int pd=node.getDegreeOfParallelism();
    vertex.setNumberOfSubtasks(pd);
    if (this.maxDegreeVertex == null || this.maxDegreeVertex.getNumberOfSubtasks() < pd) {
      this.maxDegreeVertex=vertex;
    }
    if (node.getSubtasksPerInstance() >= 1) {
      vertex.setNumberOfSubtasksPerInstance(node.getSubtasksPerInstance());
    }
    if (this.currentIteration != null) {
      PlanNode iterationNode=(PlanNode)this.currentIteration;
      if (iterationNode.getDegreeOfParallelism() != pd) {
        throw new CompilerException(""String_Node_Str"");
      }
      if (iterationNode.getSubtasksPerInstance() != node.getSubtasksPerInstance()) {
        throw new CompilerException(""String_Node_Str"");
      }
      IterationDescriptor descr=this.iterations.get(this.currentIteration);
      new TaskConfig(vertex.getConfiguration()).setIterationId(descr.getId());
    }
    this.vertices.put(node,vertex);
  }
  return true;
}","/** 
 * This methods implements the pre-visiting during a depth-first traversal. It create the job vertex and sets local strategy.
 * @param node The node that is currently processed.
 * @return True, if the visitor should descend to the node's children, false if not.
 * @see eu.stratosphere.pact.common.util.Visitor#preVisit(eu.stratosphere.pact.common.plan.Visitable)
 */
@Override public boolean preVisit(PlanNode node){
  if (this.vertices.containsKey(node) || this.chainedTasks.containsKey(node) || this.iterations.containsKey(node)) {
    return false;
  }
  final AbstractJobVertex vertex;
  try {
    if (node instanceof SinkPlanNode) {
      vertex=createDataSinkVertex((SinkPlanNode)node);
    }
 else     if (node instanceof SourcePlanNode) {
      vertex=createDataSourceVertex((SourcePlanNode)node);
    }
 else     if (node instanceof BulkIterationPlanNode) {
      BulkIterationPlanNode iterationNode=(BulkIterationPlanNode)node;
      PlanNode root=iterationNode.getRootOfStepFunction();
      if (root.getDegreeOfParallelism() != node.getDegreeOfParallelism() || root.getSubtasksPerInstance() != node.getSubtasksPerInstance()) {
        throw new CompilerException(""String_Node_Str"" + ""String_Node_Str"");
      }
      IterationDescriptor descr=new IterationDescriptor(iterationNode,this.iterationIdEnumerator++);
      this.iterations.put(iterationNode,descr);
      vertex=null;
    }
 else     if (node instanceof WorksetIterationPlanNode) {
      WorksetIterationPlanNode iterationNode=(WorksetIterationPlanNode)node;
      PlanNode nextWorkSet=iterationNode.getNextWorkSetPlanNode();
      PlanNode solutionSetDelta=iterationNode.getSolutionSetDeltaPlanNode();
      if (nextWorkSet.getDegreeOfParallelism() != node.getDegreeOfParallelism() || nextWorkSet.getSubtasksPerInstance() != node.getSubtasksPerInstance()) {
        throw new CompilerException(""String_Node_Str"" + ""String_Node_Str"");
      }
      if (solutionSetDelta.getDegreeOfParallelism() != node.getDegreeOfParallelism() || solutionSetDelta.getSubtasksPerInstance() != node.getSubtasksPerInstance()) {
        throw new CompilerException(""String_Node_Str"" + ""String_Node_Str"");
      }
      IterationDescriptor descr=new IterationDescriptor(iterationNode,this.iterationIdEnumerator++);
      this.iterations.put(iterationNode,descr);
      vertex=null;
    }
 else     if (node instanceof SingleInputPlanNode) {
      vertex=createSingleInputVertex((SingleInputPlanNode)node);
    }
 else     if (node instanceof DualInputPlanNode) {
      vertex=createDualInputVertex((DualInputPlanNode)node);
    }
 else     if (node instanceof NAryUnionPlanNode) {
      vertex=null;
    }
 else     if (node instanceof BulkPartialSolutionPlanNode) {
      vertex=createBulkIterationHead((BulkPartialSolutionPlanNode)node);
    }
 else     if (node instanceof SolutionSetPlanNode) {
      vertex=null;
    }
 else     if (node instanceof WorksetPlanNode) {
      vertex=createWorksetIterationHead((WorksetPlanNode)node);
    }
 else {
      throw new CompilerException(""String_Node_Str"" + node.getClass().getName());
    }
  }
 catch (  Exception e) {
    throw new CompilerException(""String_Node_Str"" + node + ""String_Node_Str""+ e.getMessage(),e);
  }
  if (vertex != null) {
    int pd=node.getDegreeOfParallelism();
    vertex.setNumberOfSubtasks(pd);
    if (this.maxDegreeVertex == null || this.maxDegreeVertex.getNumberOfSubtasks() < pd) {
      this.maxDegreeVertex=vertex;
    }
    if (node.getSubtasksPerInstance() >= 1) {
      vertex.setNumberOfSubtasksPerInstance(node.getSubtasksPerInstance());
    }
    if (this.currentIteration != null) {
      PlanNode iterationNode=(PlanNode)this.currentIteration;
      if (iterationNode.getDegreeOfParallelism() != pd) {
        throw new CompilerException(""String_Node_Str"");
      }
      if (iterationNode.getSubtasksPerInstance() != node.getSubtasksPerInstance()) {
        throw new CompilerException(""String_Node_Str"");
      }
      IterationDescriptor descr=this.iterations.get(this.currentIteration);
      new TaskConfig(vertex.getConfiguration()).setIterationId(descr.getId());
    }
    this.vertices.put(node,vertex);
  }
  return true;
}",0.9955566230335056
55167,"public static Object readObjectFormConfig(Configuration config,String key) throws IOException, ClassNotFoundException {
  byte[] bytes=config.getBytes(key,null);
  if (bytes == null) {
    return null;
  }
  ObjectInputStream oois=null;
  try {
    oois=new ObjectInputStream(new ByteArrayInputStream(bytes));
    return oois.readObject();
  }
  finally {
    if (oois != null) {
      oois.close();
    }
  }
}","public static Object readObjectFormConfig(Configuration config,String key,ClassLoader cl) throws IOException, ClassNotFoundException {
  byte[] bytes=config.getBytes(key,null);
  if (bytes == null) {
    return null;
  }
  ObjectInputStream oois=null;
  try {
    oois=new ClassLoaderObjectInputStream(new ByteArrayInputStream(bytes),cl);
    return oois.readObject();
  }
  finally {
    if (oois != null) {
      oois.close();
    }
  }
}",0.9659224441833136
55168,"/** 
 * Initializes the OutputFormat implementation and configuration.
 * @throws RuntimeException Throws if instance of OutputFormat implementation can not be obtained.
 */
@SuppressWarnings(""String_Node_Str"") private void initOutputFormat(){
  if (this.userCodeClassLoader == null) {
    try {
      this.userCodeClassLoader=LibraryCacheManager.getClassLoader(getEnvironment().getJobID());
    }
 catch (    IOException ioe) {
      throw new RuntimeException(""String_Node_Str"",ioe);
    }
  }
  Configuration taskConf=getTaskConfiguration();
  taskConf.setClassLoader(this.userCodeClassLoader);
  this.config=new TaskConfig(taskConf);
  try {
    this.format=(OutputFormat<IT>)this.config.getStubWrapper().getUserCodeObject();
    if (!OutputFormat.class.isAssignableFrom(this.format.getClass())) {
      throw new RuntimeException(""String_Node_Str"" + this.format.getClass().getName() + ""String_Node_Str""+ OutputFormat.class.getName()+ ""String_Node_Str"");
    }
  }
 catch (  ClassCastException ccex) {
    throw new RuntimeException(""String_Node_Str"" + OutputFormat.class.getName(),ccex);
  }
  try {
    this.format.configure(this.config.getStubParameters());
  }
 catch (  Throwable t) {
    throw new RuntimeException(""String_Node_Str"" + t.getMessage(),t);
  }
}","/** 
 * Initializes the OutputFormat implementation and configuration.
 * @throws RuntimeException Throws if instance of OutputFormat implementation can not be obtained.
 */
private void initOutputFormat(){
  if (this.userCodeClassLoader == null) {
    try {
      this.userCodeClassLoader=LibraryCacheManager.getClassLoader(getEnvironment().getJobID());
    }
 catch (    IOException ioe) {
      throw new RuntimeException(""String_Node_Str"",ioe);
    }
  }
  Configuration taskConf=getTaskConfiguration();
  taskConf.setClassLoader(this.userCodeClassLoader);
  this.config=new TaskConfig(taskConf);
  try {
    this.format=config.<OutputFormat<IT>>getStubWrapper(this.userCodeClassLoader).getUserCodeObject(OutputFormat.class,this.userCodeClassLoader);
    if (!OutputFormat.class.isAssignableFrom(this.format.getClass())) {
      throw new RuntimeException(""String_Node_Str"" + this.format.getClass().getName() + ""String_Node_Str""+ OutputFormat.class.getName()+ ""String_Node_Str"");
    }
  }
 catch (  ClassCastException ccex) {
    throw new RuntimeException(""String_Node_Str"" + OutputFormat.class.getName(),ccex);
  }
  try {
    this.format.configure(this.config.getStubParameters());
  }
 catch (  Throwable t) {
    throw new RuntimeException(""String_Node_Str"" + t.getMessage(),t);
  }
}",0.9504486929379632
55169,"/** 
 * Initializes the Stub class implementation and configuration.
 * @throws RuntimeException Thrown, if the stub class could not be loaded, instantiated,or caused an exception while being configured.
 */
@SuppressWarnings(""String_Node_Str"") protected <T>T initStub(Class<? super T> stubSuperClass) throws Exception {
  try {
    T stub=(T)((UserCodeWrapper<T>)config.getStubWrapper()).getUserCodeObject(stubSuperClass,this.userCodeClassLoader);
    if (stubSuperClass != null && !stubSuperClass.isAssignableFrom(stub.getClass())) {
      throw new RuntimeException(""String_Node_Str"" + stub.getClass().getName() + ""String_Node_Str""+ stubSuperClass.getName()+ ""String_Node_Str"");
    }
    return stub;
  }
 catch (  ClassCastException ccex) {
    throw new Exception(""String_Node_Str"" + stubSuperClass.getName(),ccex);
  }
}","/** 
 * Initializes the Stub class implementation and configuration.
 * @throws RuntimeException Thrown, if the stub class could not be loaded, instantiated,or caused an exception while being configured.
 */
protected S initStub(Class<? super S> stubSuperClass) throws Exception {
  try {
    S stub=config.<S>getStubWrapper(this.userCodeClassLoader).getUserCodeObject(stubSuperClass,this.userCodeClassLoader);
    if (stubSuperClass != null && !stubSuperClass.isAssignableFrom(stub.getClass())) {
      throw new RuntimeException(""String_Node_Str"" + stub.getClass().getName() + ""String_Node_Str""+ stubSuperClass.getName()+ ""String_Node_Str"");
    }
    return stub;
  }
 catch (  ClassCastException ccex) {
    throw new Exception(""String_Node_Str"" + stubSuperClass.getName(),ccex);
  }
}",0.3774752475247525
55170,"/** 
 * Instantiates a user code class from is definition in the task configuration. The class is instantiated without arguments using the null-ary constructor. Instantiation will fail if this constructor does not exist or is not public.
 * @param < T > The generic type of the user code class.
 * @param config The task configuration containing the class description.
 * @param cl The class loader to be used to load the class.
 * @param superClass The super class that the user code class extends or implements, for type checking.
 * @return An instance of the user code class.
 */
@SuppressWarnings(""String_Node_Str"") public static <T>T instantiateUserCode(TaskConfig config,ClassLoader cl,Class<? super T> superClass){
  try {
    T stub=(T)((UserCodeWrapper<T>)config.getStubWrapper()).getUserCodeObject(superClass,cl);
    if (superClass != null && !superClass.isAssignableFrom(stub.getClass())) {
      throw new RuntimeException(""String_Node_Str"" + stub.getClass().getName() + ""String_Node_Str""+ superClass.getName()+ ""String_Node_Str"");
    }
    return stub;
  }
 catch (  ClassCastException ccex) {
    throw new RuntimeException(""String_Node_Str"" + superClass.getName(),ccex);
  }
}","/** 
 * Instantiates a user code class from is definition in the task configuration. The class is instantiated without arguments using the null-ary constructor. Instantiation will fail if this constructor does not exist or is not public.
 * @param < T > The generic type of the user code class.
 * @param config The task configuration containing the class description.
 * @param cl The class loader to be used to load the class.
 * @param superClass The super class that the user code class extends or implements, for type checking.
 * @return An instance of the user code class.
 */
public static <T>T instantiateUserCode(TaskConfig config,ClassLoader cl,Class<? super T> superClass){
  try {
    T stub=config.<T>getStubWrapper(cl).getUserCodeObject(superClass,cl);
    if (superClass != null && !superClass.isAssignableFrom(stub.getClass())) {
      throw new RuntimeException(""String_Node_Str"" + stub.getClass().getName() + ""String_Node_Str""+ superClass.getName()+ ""String_Node_Str"");
    }
    return stub;
  }
 catch (  ClassCastException ccex) {
    throw new RuntimeException(""String_Node_Str"" + superClass.getName(),ccex);
  }
}",0.967824967824968
55171,"@SuppressWarnings(""String_Node_Str"") public <T>UserCodeWrapper<T> getStubWrapper(){
  try {
    return (UserCodeWrapper<T>)InstantiationUtil.readObjectFormConfig(this.config,STUB_OBJECT);
  }
 catch (  ClassNotFoundException e) {
    throw new CorruptConfigurationException(""String_Node_Str"" + e);
  }
catch (  IOException e) {
    throw new CorruptConfigurationException(""String_Node_Str"" + e);
  }
}","@SuppressWarnings(""String_Node_Str"") public <T>UserCodeWrapper<T> getStubWrapper(ClassLoader cl){
  try {
    return (UserCodeWrapper<T>)InstantiationUtil.readObjectFormConfig(this.config,STUB_OBJECT,cl);
  }
 catch (  ClassNotFoundException e) {
    throw new CorruptConfigurationException(""String_Node_Str"" + e);
  }
catch (  IOException e) {
    throw new CorruptConfigurationException(""String_Node_Str"" + e);
  }
}",0.9792429792429792
55172,"public TaskConfig getHeadConfig(){
  return headConfig;
}","public TaskConfig getHeadConfig(){
  if (this.headConfig == null) {
    this.headConfig=new TaskConfig(new Configuration());
  }
  return headConfig;
}",0.5480769230769231
55173,"private void translateChannel(Channel input,int inputIndex,AbstractJobVertex targetVertex,TaskConfig targetVertexConfig) throws Exception {
  final PlanNode inputPlanNode=input.getSource();
  final Iterator<Channel> allInChannels;
  if (inputPlanNode instanceof UnionPlanNode) {
    allInChannels=((UnionPlanNode)inputPlanNode).getListOfInputs().iterator();
  }
 else   if (inputPlanNode instanceof BulkPartialSolutionPlanNode) {
    if (this.vertices.get(inputPlanNode) == null) {
      final BulkPartialSolutionPlanNode pspn=(BulkPartialSolutionPlanNode)inputPlanNode;
      final BulkIterationPlanNode iterationNode=pspn.getContainingIterationNode();
      if (iterationNode.getInput().getSource() instanceof UnionPlanNode) {
        allInChannels=((UnionPlanNode)iterationNode.getInput().getSource()).getInputs();
      }
 else {
        allInChannels=Collections.singletonList(iterationNode.getInput()).iterator();
      }
      targetVertexConfig.setIterationHeadPartialSolutionOrWorksetInputIndex(inputIndex);
    }
 else {
      allInChannels=Collections.singletonList(input).iterator();
    }
  }
 else   if (inputPlanNode instanceof WorksetPlanNode) {
    if (this.vertices.get(inputPlanNode) == null) {
      final WorksetPlanNode wspn=(WorksetPlanNode)inputPlanNode;
      final WorksetIterationPlanNode iterationNode=wspn.getContainingIterationNode();
      if (iterationNode.getInput2().getSource() instanceof UnionPlanNode) {
        allInChannels=((UnionPlanNode)iterationNode.getInput2().getSource()).getInputs();
      }
 else {
        allInChannels=Collections.singletonList(iterationNode.getInput2()).iterator();
      }
      targetVertexConfig.setIterationHeadPartialSolutionOrWorksetInputIndex(inputIndex);
    }
 else {
      allInChannels=Collections.singletonList(input).iterator();
    }
  }
 else   if (inputPlanNode instanceof SolutionSetPlanNode) {
    return;
  }
 else {
    allInChannels=Collections.singletonList(input).iterator();
  }
  TypeSerializerFactory<?> typeSerFact=null;
  int numChannelsTotal=0;
  int numChannelsDynamicPath=0;
  int numDynamicSenderTasksTotal=0;
  while (allInChannels.hasNext()) {
    final Channel inConn=allInChannels.next();
    if (typeSerFact == null) {
      typeSerFact=inConn.getSerializer();
    }
 else     if (!typeSerFact.equals(inConn.getSerializer())) {
      throw new CompilerException(""String_Node_Str"");
    }
    final PlanNode sourceNode=inConn.getSource();
    AbstractJobVertex sourceVertex=this.vertices.get(sourceNode);
    TaskConfig sourceVertexConfig;
    if (sourceVertex == null) {
      final TaskInChain chainedTask;
      final IterationDescriptor iteration;
      if ((chainedTask=this.chainedTasks.get(sourceNode)) != null) {
        if (chainedTask.getContainingVertex() == null)         throw new IllegalStateException(""String_Node_Str"");
        sourceVertex=chainedTask.getContainingVertex();
        sourceVertexConfig=chainedTask.getTaskConfig();
      }
 else       if ((iteration=this.iterations.get(sourceNode)) != null) {
        sourceVertex=iteration.getHeadTask();
        sourceVertexConfig=iteration.getHeadFinalResultConfig();
      }
 else {
        throw new CompilerException(""String_Node_Str"");
      }
    }
 else {
      sourceVertexConfig=new TaskConfig(sourceVertex.getConfiguration());
    }
    DistributionPattern pattern=connectJobVertices(inConn,inputIndex,sourceVertex,sourceVertexConfig,targetVertex,targetVertexConfig);
    numChannelsTotal++;
    if (inConn.isOnDynamicPath()) {
      numChannelsDynamicPath++;
      numDynamicSenderTasksTotal+=getNumberOfSendersPerReceiver(pattern,sourceVertex.getNumberOfSubtasks(),targetVertex.getNumberOfSubtasks());
    }
  }
  if (numChannelsDynamicPath > 0 && numChannelsTotal != numChannelsDynamicPath) {
    throw new CompilerException(""String_Node_Str"");
  }
  if (numDynamicSenderTasksTotal > 0) {
    targetVertexConfig.setGateIterativeWithNumberOfEventsUntilInterrupt(inputIndex,numDynamicSenderTasksTotal);
  }
  addLocalInfoFromChannelToConfig(input,targetVertexConfig,inputIndex);
}","private int translateChannel(Channel input,int inputIndex,AbstractJobVertex targetVertex,TaskConfig targetVertexConfig) throws Exception {
  final PlanNode inputPlanNode=input.getSource();
  final Iterator<Channel> allInChannels;
  if (inputPlanNode instanceof UnionPlanNode) {
    allInChannels=((UnionPlanNode)inputPlanNode).getListOfInputs().iterator();
  }
 else   if (inputPlanNode instanceof BulkPartialSolutionPlanNode) {
    if (this.vertices.get(inputPlanNode) == null) {
      final BulkPartialSolutionPlanNode pspn=(BulkPartialSolutionPlanNode)inputPlanNode;
      final BulkIterationPlanNode iterationNode=pspn.getContainingIterationNode();
      if (iterationNode.getInput().getSource() instanceof UnionPlanNode) {
        allInChannels=((UnionPlanNode)iterationNode.getInput().getSource()).getInputs();
      }
 else {
        allInChannels=Collections.singletonList(iterationNode.getInput()).iterator();
      }
      targetVertexConfig.setIterationHeadPartialSolutionOrWorksetInputIndex(inputIndex);
    }
 else {
      allInChannels=Collections.singletonList(input).iterator();
    }
  }
 else   if (inputPlanNode instanceof WorksetPlanNode) {
    if (this.vertices.get(inputPlanNode) == null) {
      final WorksetPlanNode wspn=(WorksetPlanNode)inputPlanNode;
      final WorksetIterationPlanNode iterationNode=wspn.getContainingIterationNode();
      if (iterationNode.getInput2().getSource() instanceof UnionPlanNode) {
        allInChannels=((UnionPlanNode)iterationNode.getInput2().getSource()).getInputs();
      }
 else {
        allInChannels=Collections.singletonList(iterationNode.getInput2()).iterator();
      }
      targetVertexConfig.setIterationHeadPartialSolutionOrWorksetInputIndex(inputIndex);
    }
 else {
      allInChannels=Collections.singletonList(input).iterator();
    }
  }
 else   if (inputPlanNode instanceof SolutionSetPlanNode) {
    return 0;
  }
 else {
    allInChannels=Collections.singletonList(input).iterator();
  }
  TypeSerializerFactory<?> typeSerFact=null;
  int numChannelsTotal=0;
  int numChannelsDynamicPath=0;
  int numDynamicSenderTasksTotal=0;
  while (allInChannels.hasNext()) {
    final Channel inConn=allInChannels.next();
    if (typeSerFact == null) {
      typeSerFact=inConn.getSerializer();
    }
 else     if (!typeSerFact.equals(inConn.getSerializer())) {
      throw new CompilerException(""String_Node_Str"");
    }
    final PlanNode sourceNode=inConn.getSource();
    AbstractJobVertex sourceVertex=this.vertices.get(sourceNode);
    TaskConfig sourceVertexConfig;
    if (sourceVertex == null) {
      final TaskInChain chainedTask;
      final IterationDescriptor iteration;
      if ((chainedTask=this.chainedTasks.get(sourceNode)) != null) {
        if (chainedTask.getContainingVertex() == null)         throw new IllegalStateException(""String_Node_Str"");
        sourceVertex=chainedTask.getContainingVertex();
        sourceVertexConfig=chainedTask.getTaskConfig();
      }
 else       if ((iteration=this.iterations.get(sourceNode)) != null) {
        sourceVertex=iteration.getHeadTask();
        sourceVertexConfig=iteration.getHeadFinalResultConfig();
      }
 else {
        throw new CompilerException(""String_Node_Str"");
      }
    }
 else {
      sourceVertexConfig=new TaskConfig(sourceVertex.getConfiguration());
    }
    DistributionPattern pattern=connectJobVertices(inConn,inputIndex,sourceVertex,sourceVertexConfig,targetVertex,targetVertexConfig);
    numChannelsTotal++;
    if (inConn.isOnDynamicPath()) {
      numChannelsDynamicPath++;
      numDynamicSenderTasksTotal+=getNumberOfSendersPerReceiver(pattern,sourceVertex.getNumberOfSubtasks(),targetVertex.getNumberOfSubtasks());
    }
  }
  if (numChannelsDynamicPath > 0 && numChannelsTotal != numChannelsDynamicPath) {
    throw new CompilerException(""String_Node_Str"");
  }
  if (numDynamicSenderTasksTotal > 0) {
    targetVertexConfig.setGateIterativeWithNumberOfEventsUntilInterrupt(inputIndex,numDynamicSenderTasksTotal);
  }
  addLocalInfoFromChannelToConfig(input,targetVertexConfig,inputIndex);
  return 1;
}",0.9974204643164232
55174,"/** 
 * This method implements the post-visit during the depth-first traversal. When the post visit happens, all of the descendants have been processed, so this method connects all of the current node's predecessors to the current node.
 * @param node The node currently processed during the post-visit.
 * @see eu.stratosphere.pact.common.util.Visitor#postVisit(eu.stratosphere.pact.common.plan.Visitable)
 */
@Override public void postVisit(PlanNode node){
  try {
    if (node instanceof SourcePlanNode || node instanceof UnionPlanNode) {
      return;
    }
    if (node instanceof IterationPlanNode) {
      if (this.currentIteration != null) {
        throw new CompilerException(""String_Node_Str"");
      }
      this.currentIteration=(IterationPlanNode)node;
      this.currentIteration.acceptForStepFunction(this);
      this.currentIteration=null;
      if (node instanceof WorksetIterationPlanNode) {
        WorksetIterationPlanNode wsNode=(WorksetIterationPlanNode)node;
        AbstractJobVertex headVertex=this.iterations.get(wsNode).getHeadTask();
        TaskConfig headConfig=new TaskConfig(headVertex.getConfiguration());
        int inputIndex=headConfig.getDriverStrategy().getNumInputs();
        headConfig.setIterationHeadSolutionSetInputIndex(inputIndex);
        translateChannel(wsNode.getInitialSolutionSetInput(),inputIndex,headVertex,headConfig);
      }
      return;
    }
 else     if (node instanceof SolutionSetPlanNode) {
      if (node.getOutgoingChannels().size() != 1) {
        throw new CompilerException(""String_Node_Str"");
      }
      Channel c=node.getOutgoingChannels().get(0);
      DualInputPlanNode target=(DualInputPlanNode)c.getTarget();
      AbstractJobVertex accessingVertex=this.vertices.get(target);
      TaskConfig conf=new TaskConfig(accessingVertex.getConfiguration());
      int inputNum=c == target.getInput1() ? 0 : c == target.getInput2() ? 1 : -1;
      if (inputNum == -1) {
        throw new CompilerException();
      }
      if (conf.getDriver().equals(MatchDriver.class)) {
        conf.setDriver(inputNum == 0 ? SolutionSetFirstJoinDriver.class : SolutionSetSecondJoinDriver.class);
      }
 else       if (conf.getDriver().equals(CoGroupDriver.class)) {
        conf.setDriver(inputNum == 0 ? SolutionSetFirstCoGroupDriver.class : SolutionSetSecondCoGroupDriver.class);
      }
 else {
        throw new CompilerException(""String_Node_Str"");
      }
      conf.setSolutionSetSerializer(((SolutionSetPlanNode)node).getContainingIterationNode().getSolutionSetSerializer());
      IterationDescriptor iter=this.iterations.get(((SolutionSetPlanNode)node).getContainingIterationNode());
      TaskConfig headConf=iter.getHeadConfig();
      TypeSerializerFactory<?> otherSerializer;
      TypeComparatorFactory<?> otherComparator;
      if (inputNum == 0) {
        otherSerializer=target.getInput2().getSerializer();
        otherComparator=target.getComparator2();
      }
 else {
        otherSerializer=target.getInput1().getSerializer();
        otherComparator=target.getComparator1();
      }
      headConf.setSolutionSetProberSerializer(otherSerializer);
      headConf.setSolutionSetProberComparator(otherComparator);
      headConf.setSolutionSetPairComparator(target.getPairComparator());
      return;
    }
    final AbstractJobVertex targetVertex=this.vertices.get(node);
    if (targetVertex == null) {
      final TaskInChain chainedTask;
      if ((chainedTask=this.chainedTasks.get(node)) != null) {
        final Iterator<Channel> inConns=node.getInputs();
        if (!inConns.hasNext()) {
          throw new CompilerException(""String_Node_Str"");
        }
        final Channel inConn=inConns.next();
        if (inConns.hasNext()) {
          throw new CompilerException(""String_Node_Str"");
        }
        if (inConn.getLocalStrategy() != null && inConn.getLocalStrategy() != LocalStrategy.NONE) {
          throw new CompilerException(""String_Node_Str"");
        }
        if (inConn.getShipStrategy() != null && inConn.getShipStrategy() != ShipStrategyType.FORWARD) {
          throw new CompilerException(""String_Node_Str"");
        }
        AbstractJobVertex container=chainedTask.getContainingVertex();
        if (container == null) {
          final PlanNode sourceNode=inConn.getSource();
          container=this.vertices.get(sourceNode);
          if (container == null) {
            container=this.chainedTasks.get(sourceNode).getContainingVertex();
            if (container == null)             throw new IllegalStateException(""String_Node_Str"");
          }
 else {
            new TaskConfig(container.getConfiguration()).addOutputShipStrategy(ShipStrategyType.FORWARD);
          }
          chainedTask.setContainingVertex(container);
        }
        chainedTask.getTaskConfig().setInputSerializer(inConn.getSerializer(),0);
        this.chainedTasksInSequence.add(chainedTask);
        return;
      }
 else       if (node instanceof BulkPartialSolutionPlanNode || node instanceof WorksetPlanNode) {
        return;
      }
 else {
        throw new CompilerException(""String_Node_Str"");
      }
    }
    final TaskConfig targetVertexConfig=new TaskConfig(targetVertex.getConfiguration());
    final Iterator<Channel> inConns;
    if (node instanceof BulkPartialSolutionPlanNode) {
      inConns=((BulkPartialSolutionPlanNode)node).getContainingIterationNode().getInputs();
      targetVertexConfig.setIterationHeadPartialSolutionOrWorksetInputIndex(0);
    }
 else     if (node instanceof WorksetPlanNode) {
      WorksetPlanNode wspn=(WorksetPlanNode)node;
      inConns=Collections.singleton(wspn.getContainingIterationNode().getInput2()).iterator();
      targetVertexConfig.setIterationHeadPartialSolutionOrWorksetInputIndex(0);
      targetVertexConfig.setIterationHeadSolutionSetInputIndex(1);
    }
 else {
      inConns=node.getInputs();
    }
    if (!inConns.hasNext()) {
      throw new CompilerException(""String_Node_Str"");
    }
    for (int inputIndex=0; inConns.hasNext(); inputIndex++) {
      Channel input=inConns.next();
      translateChannel(input,inputIndex,targetVertex,targetVertexConfig);
    }
  }
 catch (  Exception e) {
    throw new CompilerException(""String_Node_Str"" + e.getMessage(),e);
  }
}","/** 
 * This method implements the post-visit during the depth-first traversal. When the post visit happens, all of the descendants have been processed, so this method connects all of the current node's predecessors to the current node.
 * @param node The node currently processed during the post-visit.
 * @see eu.stratosphere.pact.common.util.Visitor#postVisit(eu.stratosphere.pact.common.plan.Visitable)
 */
@Override public void postVisit(PlanNode node){
  try {
    if (node instanceof SourcePlanNode || node instanceof UnionPlanNode) {
      return;
    }
    if (node instanceof IterationPlanNode) {
      if (this.currentIteration != null) {
        throw new CompilerException(""String_Node_Str"");
      }
      this.currentIteration=(IterationPlanNode)node;
      this.currentIteration.acceptForStepFunction(this);
      this.currentIteration=null;
      if (node instanceof WorksetIterationPlanNode) {
        WorksetIterationPlanNode wsNode=(WorksetIterationPlanNode)node;
        AbstractJobVertex headVertex=this.iterations.get(wsNode).getHeadTask();
        TaskConfig headConfig=new TaskConfig(headVertex.getConfiguration());
        int inputIndex=headConfig.getDriverStrategy().getNumInputs();
        headConfig.setIterationHeadSolutionSetInputIndex(inputIndex);
        translateChannel(wsNode.getInitialSolutionSetInput(),inputIndex,headVertex,headConfig);
      }
      return;
    }
 else     if (node instanceof SolutionSetPlanNode) {
      if (node.getOutgoingChannels().size() != 1) {
        throw new CompilerException(""String_Node_Str"");
      }
      Channel c=node.getOutgoingChannels().get(0);
      DualInputPlanNode target=(DualInputPlanNode)c.getTarget();
      AbstractJobVertex accessingVertex=this.vertices.get(target);
      TaskConfig conf=new TaskConfig(accessingVertex.getConfiguration());
      int inputNum=c == target.getInput1() ? 0 : c == target.getInput2() ? 1 : -1;
      if (inputNum == -1) {
        throw new CompilerException();
      }
      if (conf.getDriver().equals(MatchDriver.class)) {
        conf.setDriver(inputNum == 0 ? SolutionSetFirstJoinDriver.class : SolutionSetSecondJoinDriver.class);
      }
 else       if (conf.getDriver().equals(CoGroupDriver.class)) {
        conf.setDriver(inputNum == 0 ? SolutionSetFirstCoGroupDriver.class : SolutionSetSecondCoGroupDriver.class);
      }
 else {
        throw new CompilerException(""String_Node_Str"");
      }
      conf.setSolutionSetSerializer(((SolutionSetPlanNode)node).getContainingIterationNode().getSolutionSetSerializer());
      IterationDescriptor iter=this.iterations.get(((SolutionSetPlanNode)node).getContainingIterationNode());
      TaskConfig headConf=iter.getHeadConfig();
      TypeSerializerFactory<?> otherSerializer;
      TypeComparatorFactory<?> otherComparator;
      if (inputNum == 0) {
        otherSerializer=target.getInput2().getSerializer();
        otherComparator=target.getComparator2();
      }
 else {
        otherSerializer=target.getInput1().getSerializer();
        otherComparator=target.getComparator1();
      }
      headConf.setSolutionSetProberSerializer(otherSerializer);
      headConf.setSolutionSetProberComparator(otherComparator);
      headConf.setSolutionSetPairComparator(target.getPairComparator());
      return;
    }
    final AbstractJobVertex targetVertex=this.vertices.get(node);
    if (targetVertex == null) {
      final TaskInChain chainedTask;
      if ((chainedTask=this.chainedTasks.get(node)) != null) {
        final Iterator<Channel> inConns=node.getInputs();
        if (!inConns.hasNext()) {
          throw new CompilerException(""String_Node_Str"");
        }
        final Channel inConn=inConns.next();
        if (inConns.hasNext()) {
          throw new CompilerException(""String_Node_Str"");
        }
        if (inConn.getLocalStrategy() != null && inConn.getLocalStrategy() != LocalStrategy.NONE) {
          throw new CompilerException(""String_Node_Str"");
        }
        if (inConn.getShipStrategy() != null && inConn.getShipStrategy() != ShipStrategyType.FORWARD) {
          throw new CompilerException(""String_Node_Str"");
        }
        AbstractJobVertex container=chainedTask.getContainingVertex();
        if (container == null) {
          final PlanNode sourceNode=inConn.getSource();
          container=this.vertices.get(sourceNode);
          if (container == null) {
            container=this.chainedTasks.get(sourceNode).getContainingVertex();
            if (container == null)             throw new IllegalStateException(""String_Node_Str"");
          }
 else {
            new TaskConfig(container.getConfiguration()).addOutputShipStrategy(ShipStrategyType.FORWARD);
          }
          chainedTask.setContainingVertex(container);
        }
        chainedTask.getTaskConfig().setInputSerializer(inConn.getSerializer(),0);
        this.chainedTasksInSequence.add(chainedTask);
        return;
      }
 else       if (node instanceof BulkPartialSolutionPlanNode || node instanceof WorksetPlanNode) {
        return;
      }
 else {
        throw new CompilerException(""String_Node_Str"");
      }
    }
    final TaskConfig targetVertexConfig=new TaskConfig(targetVertex.getConfiguration());
    final Iterator<Channel> inConns;
    if (node instanceof BulkPartialSolutionPlanNode) {
      inConns=((BulkPartialSolutionPlanNode)node).getContainingIterationNode().getInputs();
      targetVertexConfig.setIterationHeadPartialSolutionOrWorksetInputIndex(0);
    }
 else     if (node instanceof WorksetPlanNode) {
      WorksetPlanNode wspn=(WorksetPlanNode)node;
      inConns=Collections.singleton(wspn.getContainingIterationNode().getInput2()).iterator();
      targetVertexConfig.setIterationHeadPartialSolutionOrWorksetInputIndex(0);
      targetVertexConfig.setIterationHeadSolutionSetInputIndex(1);
    }
 else {
      inConns=node.getInputs();
    }
    if (!inConns.hasNext()) {
      throw new CompilerException(""String_Node_Str"");
    }
    int inputIndex=0;
    while (inConns.hasNext()) {
      Channel input=inConns.next();
      inputIndex+=translateChannel(input,inputIndex,targetVertex,targetVertexConfig);
    }
  }
 catch (  Exception e) {
    throw new CompilerException(""String_Node_Str"" + e.getMessage(),e);
  }
}",0.9911943643932116
55175,"public void setHeadTask(JobTaskVertex headTask,TaskConfig headConfig){
  this.headTask=headTask;
  this.headFinalResultConfig=new TaskConfig(new Configuration());
  this.headConfig=headConfig;
}","public void setHeadTask(JobTaskVertex headTask,TaskConfig headConfig){
  this.headTask=headTask;
  this.headFinalResultConfig=new TaskConfig(new Configuration());
  if (this.headConfig != null) {
    headConfig.getConfiguration().addAll(this.headConfig.getConfiguration());
  }
  this.headConfig=headConfig;
}",0.6719681908548708
55176,"public static Object readObjectFormConfig(Configuration config,String key) throws IOException, ClassNotFoundException {
  byte[] bytes=config.getBytes(key,null);
  if (bytes == null) {
    return null;
  }
  ObjectInputStream oois=null;
  try {
    oois=new ObjectInputStream(new ByteArrayInputStream(bytes));
    return oois.readObject();
  }
  finally {
    if (oois != null) {
      oois.close();
    }
  }
}","public static Object readObjectFormConfig(Configuration config,String key,ClassLoader cl) throws IOException, ClassNotFoundException {
  byte[] bytes=config.getBytes(key,null);
  if (bytes == null) {
    return null;
  }
  ObjectInputStream oois=null;
  try {
    oois=new ClassLoaderObjectInputStream(new ByteArrayInputStream(bytes),cl);
    return oois.readObject();
  }
  finally {
    if (oois != null) {
      oois.close();
    }
  }
}",0.9659224441833136
55177,"/** 
 * Initializes the OutputFormat implementation and configuration.
 * @throws RuntimeException Throws if instance of OutputFormat implementation can not be obtained.
 */
@SuppressWarnings(""String_Node_Str"") private void initOutputFormat(){
  if (this.userCodeClassLoader == null) {
    try {
      this.userCodeClassLoader=LibraryCacheManager.getClassLoader(getEnvironment().getJobID());
    }
 catch (    IOException ioe) {
      throw new RuntimeException(""String_Node_Str"",ioe);
    }
  }
  Configuration taskConf=getTaskConfiguration();
  taskConf.setClassLoader(this.userCodeClassLoader);
  this.config=new TaskConfig(taskConf);
  try {
    this.format=(OutputFormat<IT>)this.config.getStubWrapper().getUserCodeObject();
    if (!OutputFormat.class.isAssignableFrom(this.format.getClass())) {
      throw new RuntimeException(""String_Node_Str"" + this.format.getClass().getName() + ""String_Node_Str""+ OutputFormat.class.getName()+ ""String_Node_Str"");
    }
  }
 catch (  ClassCastException ccex) {
    throw new RuntimeException(""String_Node_Str"" + OutputFormat.class.getName(),ccex);
  }
  try {
    this.format.configure(this.config.getStubParameters());
  }
 catch (  Throwable t) {
    throw new RuntimeException(""String_Node_Str"" + t.getMessage(),t);
  }
}","/** 
 * Initializes the OutputFormat implementation and configuration.
 * @throws RuntimeException Throws if instance of OutputFormat implementation can not be obtained.
 */
private void initOutputFormat(){
  if (this.userCodeClassLoader == null) {
    try {
      this.userCodeClassLoader=LibraryCacheManager.getClassLoader(getEnvironment().getJobID());
    }
 catch (    IOException ioe) {
      throw new RuntimeException(""String_Node_Str"",ioe);
    }
  }
  Configuration taskConf=getTaskConfiguration();
  taskConf.setClassLoader(this.userCodeClassLoader);
  this.config=new TaskConfig(taskConf);
  try {
    this.format=config.<OutputFormat<IT>>getStubWrapper(this.userCodeClassLoader).getUserCodeObject(OutputFormat.class,this.userCodeClassLoader);
    if (!OutputFormat.class.isAssignableFrom(this.format.getClass())) {
      throw new RuntimeException(""String_Node_Str"" + this.format.getClass().getName() + ""String_Node_Str""+ OutputFormat.class.getName()+ ""String_Node_Str"");
    }
  }
 catch (  ClassCastException ccex) {
    throw new RuntimeException(""String_Node_Str"" + OutputFormat.class.getName(),ccex);
  }
  try {
    this.format.configure(this.config.getStubParameters());
  }
 catch (  Throwable t) {
    throw new RuntimeException(""String_Node_Str"" + t.getMessage(),t);
  }
}",0.9504486929379632
55178,"/** 
 * Initializes the Stub class implementation and configuration.
 * @throws RuntimeException Thrown, if the stub class could not be loaded, instantiated,or caused an exception while being configured.
 */
@SuppressWarnings(""String_Node_Str"") protected <T>T initStub(Class<? super T> stubSuperClass) throws Exception {
  try {
    T stub=(T)((UserCodeWrapper<T>)config.getStubWrapper()).getUserCodeObject(stubSuperClass,this.userCodeClassLoader);
    if (stubSuperClass != null && !stubSuperClass.isAssignableFrom(stub.getClass())) {
      throw new RuntimeException(""String_Node_Str"" + stub.getClass().getName() + ""String_Node_Str""+ stubSuperClass.getName()+ ""String_Node_Str"");
    }
    return stub;
  }
 catch (  ClassCastException ccex) {
    throw new Exception(""String_Node_Str"" + stubSuperClass.getName(),ccex);
  }
}","/** 
 * Initializes the Stub class implementation and configuration.
 * @throws RuntimeException Thrown, if the stub class could not be loaded, instantiated,or caused an exception while being configured.
 */
protected S initStub(Class<? super S> stubSuperClass) throws Exception {
  try {
    S stub=config.<S>getStubWrapper(this.userCodeClassLoader).getUserCodeObject(stubSuperClass,this.userCodeClassLoader);
    if (stubSuperClass != null && !stubSuperClass.isAssignableFrom(stub.getClass())) {
      throw new RuntimeException(""String_Node_Str"" + stub.getClass().getName() + ""String_Node_Str""+ stubSuperClass.getName()+ ""String_Node_Str"");
    }
    return stub;
  }
 catch (  ClassCastException ccex) {
    throw new Exception(""String_Node_Str"" + stubSuperClass.getName(),ccex);
  }
}",0.3774752475247525
55179,"/** 
 * Instantiates a user code class from is definition in the task configuration. The class is instantiated without arguments using the null-ary constructor. Instantiation will fail if this constructor does not exist or is not public.
 * @param < T > The generic type of the user code class.
 * @param config The task configuration containing the class description.
 * @param cl The class loader to be used to load the class.
 * @param superClass The super class that the user code class extends or implements, for type checking.
 * @return An instance of the user code class.
 */
@SuppressWarnings(""String_Node_Str"") public static <T>T instantiateUserCode(TaskConfig config,ClassLoader cl,Class<? super T> superClass){
  try {
    T stub=(T)((UserCodeWrapper<T>)config.getStubWrapper()).getUserCodeObject(superClass,cl);
    if (superClass != null && !superClass.isAssignableFrom(stub.getClass())) {
      throw new RuntimeException(""String_Node_Str"" + stub.getClass().getName() + ""String_Node_Str""+ superClass.getName()+ ""String_Node_Str"");
    }
    return stub;
  }
 catch (  ClassCastException ccex) {
    throw new RuntimeException(""String_Node_Str"" + superClass.getName(),ccex);
  }
}","/** 
 * Instantiates a user code class from is definition in the task configuration. The class is instantiated without arguments using the null-ary constructor. Instantiation will fail if this constructor does not exist or is not public.
 * @param < T > The generic type of the user code class.
 * @param config The task configuration containing the class description.
 * @param cl The class loader to be used to load the class.
 * @param superClass The super class that the user code class extends or implements, for type checking.
 * @return An instance of the user code class.
 */
public static <T>T instantiateUserCode(TaskConfig config,ClassLoader cl,Class<? super T> superClass){
  try {
    T stub=config.<T>getStubWrapper(cl).getUserCodeObject(superClass,cl);
    if (superClass != null && !superClass.isAssignableFrom(stub.getClass())) {
      throw new RuntimeException(""String_Node_Str"" + stub.getClass().getName() + ""String_Node_Str""+ superClass.getName()+ ""String_Node_Str"");
    }
    return stub;
  }
 catch (  ClassCastException ccex) {
    throw new RuntimeException(""String_Node_Str"" + superClass.getName(),ccex);
  }
}",0.967824967824968
55180,"@SuppressWarnings(""String_Node_Str"") public <T>UserCodeWrapper<T> getStubWrapper(){
  try {
    return (UserCodeWrapper<T>)InstantiationUtil.readObjectFormConfig(this.config,STUB_OBJECT);
  }
 catch (  ClassNotFoundException e) {
    throw new CorruptConfigurationException(""String_Node_Str"" + e);
  }
catch (  IOException e) {
    throw new CorruptConfigurationException(""String_Node_Str"" + e);
  }
}","@SuppressWarnings(""String_Node_Str"") public <T>UserCodeWrapper<T> getStubWrapper(ClassLoader cl){
  try {
    return (UserCodeWrapper<T>)InstantiationUtil.readObjectFormConfig(this.config,STUB_OBJECT,cl);
  }
 catch (  ClassNotFoundException e) {
    throw new CorruptConfigurationException(""String_Node_Str"" + e);
  }
catch (  IOException e) {
    throw new CorruptConfigurationException(""String_Node_Str"" + e);
  }
}",0.9792429792429792
55181,"private void initInputLocalStrategy(int inputNum) throws Exception {
  if (this.localStrategies[inputNum] != null) {
    throw new IllegalStateException();
  }
  final LocalStrategy localStrategy=this.config.getInputLocalStrategy(inputNum);
  if (localStrategy != null) {
switch (localStrategy) {
case NONE:
      this.inputs[inputNum]=this.inputIterators[inputNum];
    break;
case SORT:
  @SuppressWarnings({""String_Node_Str"",""String_Node_Str""}) UnilateralSortMerger<?> sorter=new UnilateralSortMerger(getMemoryManager(),getIOManager(),this.inputIterators[inputNum],this,this.inputSerializers[inputNum],getLocalStrategyComparator(inputNum),this.config.getMemoryInput(inputNum),this.config.getFilehandlesInput(inputNum),this.config.getSpillingThresholdInput(inputNum));
this.inputs[inputNum]=null;
this.localStrategies[inputNum]=sorter;
break;
case COMBININGSORT:
if (inputNum != 0) {
throw new IllegalStateException(""String_Node_Str"");
}
final S localStub;
try {
final Class<S> userCodeFunctionType=this.driver.getStubType();
if (userCodeFunctionType != null && GenericReducer.class.isAssignableFrom(userCodeFunctionType)) {
localStub=initStub(userCodeFunctionType);
}
 else {
throw new IllegalStateException(""String_Node_Str"");
}
}
 catch (Exception e) {
throw new RuntimeException(""String_Node_Str"" + e.getMessage() == null ? ""String_Node_Str"" : ""String_Node_Str"" + e.getMessage(),e);
}
@SuppressWarnings({""String_Node_Str"",""String_Node_Str""}) CombiningUnilateralSortMerger<?> cSorter=new CombiningUnilateralSortMerger((GenericReducer)localStub,getMemoryManager(),getIOManager(),this.inputIterators[inputNum],this,this.inputSerializers[inputNum],getLocalStrategyComparator(inputNum),this.config.getMemoryInput(inputNum),this.config.getFilehandlesInput(inputNum),this.config.getSpillingThresholdInput(inputNum),false);
this.inputs[inputNum]=null;
this.localStrategies[inputNum]=cSorter;
break;
default :
throw new Exception(""String_Node_Str"" + localStrategy.name());
}
}
 else {
this.inputs[inputNum]=this.inputIterators[inputNum];
}
}","private void initInputLocalStrategy(int inputNum) throws Exception {
  if (this.localStrategies[inputNum] != null) {
    throw new IllegalStateException();
  }
  final LocalStrategy localStrategy=this.config.getInputLocalStrategy(inputNum);
  if (localStrategy != null) {
switch (localStrategy) {
case NONE:
      this.inputs[inputNum]=this.inputIterators[inputNum];
    break;
case SORT:
  @SuppressWarnings({""String_Node_Str"",""String_Node_Str""}) UnilateralSortMerger<?> sorter=new UnilateralSortMerger(getMemoryManager(),getIOManager(),this.inputIterators[inputNum],this,this.inputSerializers[inputNum],getLocalStrategyComparator(inputNum),this.config.getMemoryInput(inputNum),this.config.getFilehandlesInput(inputNum),this.config.getSpillingThresholdInput(inputNum));
this.inputs[inputNum]=null;
this.localStrategies[inputNum]=sorter;
break;
case COMBININGSORT:
if (inputNum != 0) {
throw new IllegalStateException(""String_Node_Str"");
}
final S localStub;
try {
final Class<S> userCodeFunctionType=this.driver.getStubType();
if (userCodeFunctionType != null && GenericReducer.class.isAssignableFrom(userCodeFunctionType)) {
localStub=initStub(userCodeFunctionType);
localStub.open(this.config.getStubParameters());
}
 else {
throw new IllegalStateException(""String_Node_Str"");
}
}
 catch (Exception e) {
throw new RuntimeException(""String_Node_Str"" + e.getMessage() == null ? ""String_Node_Str"" : ""String_Node_Str"" + e.getMessage(),e);
}
@SuppressWarnings({""String_Node_Str"",""String_Node_Str""}) CombiningUnilateralSortMerger<?> cSorter=new CombiningUnilateralSortMerger((GenericReducer)localStub,getMemoryManager(),getIOManager(),this.inputIterators[inputNum],this,this.inputSerializers[inputNum],getLocalStrategyComparator(inputNum),this.config.getMemoryInput(inputNum),this.config.getFilehandlesInput(inputNum),this.config.getSpillingThresholdInput(inputNum),false);
this.inputs[inputNum]=null;
this.localStrategies[inputNum]=cSorter;
break;
default :
throw new Exception(""String_Node_Str"" + localStrategy.name());
}
}
 else {
this.inputs[inputNum]=this.inputIterators[inputNum];
}
}",0.988121212121212
55182,"/** 
 * Opens the given stub using its   {@link Stub#open(Configuration)} method. If the open call producesan exception, a new exception with a standard error message is created, using the encountered exception as its cause.
 * @param stub The user code instance to be opened.
 * @param parameters The parameters supplied to the user code.
 * @throws Exception Thrown, if the user code's open method produces an exception.
 */
public static void openUserCode(Stub stub,Configuration parameters) throws Exception {
  try {
    stub.open(parameters);
  }
 catch (  Throwable t) {
    throw new Exception(""String_Node_Str"" + t.getMessage(),t);
  }
}","/** 
 * Opens the given stub using its   {@link Stub#open(Configuration)} method. If the open call producesan exception, a new exception with a standard error message is created, using the encountered exception as its cause.
 * @param stub The user code instance to be opened.
 * @param parameters The parameters supplied to the user code.
 * @throws Exception Thrown, if the user code's open method produces an exception.
 */
public static void openUserCode(Stub stub,Configuration parameters) throws Exception {
  try {
    stub.open(parameters);
  }
 catch (  Throwable t) {
    throw new Exception(""String_Node_Str"" + stub.getClass().toString() + ""String_Node_Str""+ t.getMessage(),t);
  }
}",0.964179104477612
55183,"/** 
 * Creates a new channel selector that uses the given strategy (broadcasting, partitioning, ...) and uses the supplied comparator to hash / compare records for partitioning them deterministically.
 * @param strategy The distribution strategy to be used.
 * @param comparator The comparator used to hash / compare the records.
 * @param distr The distribution pattern used in the case of a range partitioning.
 */
public PactRecordOutputEmitter(ShipStrategyType strategy,PactRecordComparator comparator,DataDistribution distr){
  if (strategy == null) {
    throw new NullPointerException();
  }
  this.strategy=strategy;
  this.comparator=comparator;
  this.distribution=distr;
switch (strategy) {
case FORWARD:
case PARTITION_HASH:
case PARTITION_LOCAL_HASH:
case PARTITION_RANGE:
    this.channels=new int[1];
  break;
case BROADCAST:
break;
default :
throw new IllegalArgumentException(""String_Node_Str"" + strategy.name());
}
if ((strategy == ShipStrategyType.PARTITION_RANGE) && distr == null) throw new NullPointerException(""String_Node_Str"");
}","/** 
 * Creates a new channel selector that uses the given strategy (broadcasting, partitioning, ...) and uses the supplied comparator to hash / compare records for partitioning them deterministically.
 * @param strategy The distribution strategy to be used.
 * @param comparator The comparator used to hash / compare the records.
 * @param distr The distribution pattern used in the case of a range partitioning.
 */
public PactRecordOutputEmitter(ShipStrategyType strategy,PactRecordComparator comparator,DataDistribution distr){
  if (strategy == null) {
    throw new NullPointerException();
  }
  this.strategy=strategy;
  this.comparator=comparator;
  this.distribution=distr;
switch (strategy) {
case FORWARD:
case PARTITION_HASH:
case PARTITION_LOCAL_HASH:
case PARTITION_RANGE:
case PARTITION_RANDOM:
    this.channels=new int[1];
  break;
case BROADCAST:
break;
default :
throw new IllegalArgumentException(""String_Node_Str"" + strategy.name());
}
if ((strategy == ShipStrategyType.PARTITION_RANGE) && distr == null) throw new NullPointerException(""String_Node_Str"");
}",0.9892170651664324
55184,"public String getTempFilePath(String fileName) throws IOException {
  File baseDir=new File(System.getProperty(""String_Node_Str""));
  File f=new File(baseDir,fileName);
  return ""String_Node_Str"" + f.getAbsolutePath();
}","public String getTempFilePath(String fileName) throws IOException {
  File f=createAndRegisterTempFile(fileName);
  return ""String_Node_Str"" + f.getAbsolutePath();
}",0.7636363636363637
55185,"public String createTempFile(String fileName,String contents) throws IOException {
  File baseDir=new File(System.getProperty(""String_Node_Str""));
  File f=new File(baseDir,fileName);
  if (f.exists()) {
    deleteRecursively(f);
  }
  File parentToDelete=f;
  while (true) {
    File parent=parentToDelete.getParentFile();
    if (parent == null) {
      throw new IOException(""String_Node_Str"");
    }
    if (parent.equals(baseDir)) {
      break;
    }
    parentToDelete=parent;
  }
  Files.createParentDirs(f);
  Files.write(contents,f,Charsets.UTF_8);
  this.tempFiles.add(parentToDelete);
  return ""String_Node_Str"" + f.getAbsolutePath();
}","public String createTempFile(String fileName,String contents) throws IOException {
  File f=createAndRegisterTempFile(fileName);
  Files.write(contents,f,Charsets.UTF_8);
  return ""String_Node_Str"" + f.getAbsolutePath();
}",0.432183908045977
55186,"public String getTempDirPath(String dirName) throws IOException {
  File baseDir=new File(System.getProperty(""String_Node_Str""));
  File f=new File(baseDir,dirName);
  return ""String_Node_Str"" + f.getAbsolutePath();
}","public String getTempDirPath(String dirName) throws IOException {
  File f=createAndRegisterTempFile(dirName);
  return ""String_Node_Str"" + f.getAbsolutePath();
}",0.7598944591029023
55187,"public Plan getPlan(String... args){
  int dop=1;
  String pageWithRankInputPath=""String_Node_Str"";
  String adjacencyListInputPath=""String_Node_Str"";
  String outputPath=""String_Node_Str"";
  int numIterations=25;
  long numVertices=5;
  long numDanglingVertices=1;
  if (args.length >= 7) {
    dop=Integer.parseInt(args[0]);
    pageWithRankInputPath=args[1];
    adjacencyListInputPath=args[2];
    outputPath=args[3];
    numIterations=Integer.parseInt(args[4]);
    numVertices=Long.parseLong(args[5]);
    numDanglingVertices=Long.parseLong(args[6]);
  }
  FileDataSource pageWithRankInput=new FileDataSource(DanglingPageRankInputFormat.class,pageWithRankInputPath,""String_Node_Str"");
  pageWithRankInput.getParameters().setLong(DanglingPageRankInputFormat.NUM_VERTICES_PARAMETER,numVertices);
  BulkIteration iteration=new BulkIteration(""String_Node_Str"");
  iteration.setInput(pageWithRankInput);
  FileDataSource adjacencyListInput=new FileDataSource(ImprovedAdjacencyListInputFormat.class,adjacencyListInputPath,""String_Node_Str"");
  MatchContract join=MatchContract.builder(DotProductMatch.class,PactLong.class,0,0).input1(iteration.getPartialSolution()).input2(adjacencyListInput).name(""String_Node_Str"").build();
  join.getParameters().setString(""String_Node_Str"",""String_Node_Str"");
  CoGroupContract rankAggregation=CoGroupContract.builder(DotProductCoGroup.class,PactLong.class,0,0).input1(iteration.getPartialSolution()).input2(join).name(""String_Node_Str"").build();
  rankAggregation.getParameters().setLong(DotProductCoGroup.NUM_VERTICES_PARAMETER,numVertices);
  rankAggregation.getParameters().setLong(DotProductCoGroup.NUM_DANGLING_VERTICES_PARAMETER,numDanglingVertices);
  iteration.setNextPartialSolution(rankAggregation);
  iteration.setMaximumNumberOfIterations(numIterations);
  iteration.getAggregators().registerAggregationConvergenceCriterion(DotProductCoGroup.AGGREGATOR_NAME,PageRankStatsAggregator.class,DiffL1NormConvergenceCriterion.class);
  FileDataSink out=new FileDataSink(PageWithRankOutFormat.class,outputPath,iteration,""String_Node_Str"");
  Plan p=new Plan(out,""String_Node_Str"");
  p.setDefaultParallelism(dop);
  return p;
}","public Plan getPlan(String... args){
  int dop=1;
  String pageWithRankInputPath=""String_Node_Str"";
  String adjacencyListInputPath=""String_Node_Str"";
  String outputPath=""String_Node_Str"";
  int numIterations=25;
  long numVertices=5;
  long numDanglingVertices=1;
  if (args.length >= 7) {
    dop=Integer.parseInt(args[0]);
    pageWithRankInputPath=args[1];
    adjacencyListInputPath=args[2];
    outputPath=args[3];
    numIterations=Integer.parseInt(args[4]);
    numVertices=Long.parseLong(args[5]);
    numDanglingVertices=Long.parseLong(args[6]);
  }
  FileDataSource pageWithRankInput=new FileDataSource(DanglingPageRankInputFormat.class,pageWithRankInputPath,""String_Node_Str"");
  pageWithRankInput.getParameters().setLong(DanglingPageRankInputFormat.NUM_VERTICES_PARAMETER,numVertices);
  BulkIteration iteration=new BulkIteration(""String_Node_Str"");
  iteration.setInput(pageWithRankInput);
  FileDataSource adjacencyListInput=new FileDataSource(ImprovedAdjacencyListInputFormat.class,adjacencyListInputPath,""String_Node_Str"");
  MatchContract join=MatchContract.builder(DotProductMatch.class,PactLong.class,0,0).input1(iteration.getPartialSolution()).input2(adjacencyListInput).name(""String_Node_Str"").build();
  CoGroupContract rankAggregation=CoGroupContract.builder(DotProductCoGroup.class,PactLong.class,0,0).input1(iteration.getPartialSolution()).input2(join).name(""String_Node_Str"").build();
  rankAggregation.getParameters().setLong(DotProductCoGroup.NUM_VERTICES_PARAMETER,numVertices);
  rankAggregation.getParameters().setLong(DotProductCoGroup.NUM_DANGLING_VERTICES_PARAMETER,numDanglingVertices);
  iteration.setNextPartialSolution(rankAggregation);
  iteration.setMaximumNumberOfIterations(numIterations);
  iteration.getAggregators().registerAggregationConvergenceCriterion(DotProductCoGroup.AGGREGATOR_NAME,PageRankStatsAggregator.class,DiffL1NormConvergenceCriterion.class);
  FileDataSink out=new FileDataSink(PageWithRankOutFormat.class,outputPath,iteration,""String_Node_Str"");
  Plan p=new Plan(out,""String_Node_Str"");
  p.setDefaultParallelism(dop);
  return p;
}",0.9833606749472698
55188,"@Override public void run() throws Exception {
  while (this.running && !terminationRequested()) {
    if (log.isInfoEnabled()) {
      log.info(formatLogString(""String_Node_Str"" + currentIteration() + ""String_Node_Str""));
    }
    System.out.println(formatLogString(""String_Node_Str"" + currentIteration() + ""String_Node_Str""));
    super.run();
    System.out.println(formatLogString(""String_Node_Str"" + currentIteration() + ""String_Node_Str""));
    if (log.isInfoEnabled()) {
      log.info(formatLogString(""String_Node_Str"" + currentIteration() + ""String_Node_Str""));
    }
    if (!terminationRequested()) {
      propagateEvent(EndOfSuperstepEvent.INSTANCE);
      incrementIterationCounter();
    }
 else {
      propagateEvent(TerminationEvent.INSTANCE);
    }
  }
}","@Override public void run() throws Exception {
  while (this.running && !terminationRequested()) {
    if (log.isInfoEnabled()) {
      log.info(formatLogString(""String_Node_Str"" + currentIteration() + ""String_Node_Str""));
    }
    super.run();
    if (log.isInfoEnabled()) {
      log.info(formatLogString(""String_Node_Str"" + currentIteration() + ""String_Node_Str""));
    }
    if (!terminationRequested()) {
      propagateEvent(EndOfSuperstepEvent.INSTANCE);
      incrementIterationCounter();
    }
 else {
      propagateEvent(TerminationEvent.INSTANCE);
    }
  }
}",0.8350668647845468
55189,"/** 
 * Calls the <code>MatchStub#match()</code> method for all two key-value pairs that share the same key and come  from different inputs. The output of the <code>match()</code> method is forwarded. <p> This method first zig-zags between the two sorted inputs in order to find a common key, and then calls the match stub with the cross product of the values.
 * @throws Exception Forwards all exceptions from the user code and the I/O system.
 * @see eu.stratosphere.pact.runtime.task.util.MatchTaskIterator#callWithNextKey()
 */
@Override public boolean callWithNextKey(final GenericMatcher<T1,T2,O> matchFunction,final Collector<O> collector) throws Exception {
  if (!this.iterator1.nextKey() || !this.iterator2.nextKey()) {
    return false;
  }
  final TypePairComparator<T1,T2> comparator=this.comp;
  comparator.setReference(this.iterator1.getCurrent());
  T2 current2=this.iterator2.getCurrent();
  while (true) {
    final int comp=comparator.compareToReference(current2);
    if (comp == 0)     break;
    if (comp < 0) {
      if (!this.iterator2.nextKey()) {
        return false;
      }
      current2=this.iterator2.getCurrent();
    }
 else {
      if (!this.iterator1.nextKey()) {
        return false;
      }
      comparator.setReference(this.iterator1.getCurrent());
    }
  }
  final KeyGroupedIterator<T1>.ValuesIterator values1=this.iterator1.getValues();
  final KeyGroupedIterator<T2>.ValuesIterator values2=this.iterator2.getValues();
  final T1 firstV1=values1.next();
  final T2 firstV2=values2.next();
  final boolean v1HasNext=values1.hasNext();
  final boolean v2HasNext=values2.hasNext();
  if (v1HasNext) {
    if (v2HasNext) {
      crossMwithNValues(firstV1,values1,firstV2,values2,matchFunction,collector);
    }
 else {
      crossSecond1withNValues(firstV2,firstV1,values1,matchFunction,collector);
    }
  }
 else {
    if (v2HasNext) {
      crossFirst1withNValues(firstV1,firstV2,values2,matchFunction,collector);
    }
 else {
      matchFunction.match(firstV1,firstV2,collector);
    }
  }
  return true;
}","/** 
 * Calls the <code>MatchStub#match()</code> method for all two key-value pairs that share the same key and come  from different inputs. The output of the <code>match()</code> method is forwarded. <p> This method first zig-zags between the two sorted inputs in order to find a common key, and then calls the match stub with the cross product of the values.
 * @throws Exception Forwards all exceptions from the user code and the I/O system.
 * @see eu.stratosphere.pact.runtime.task.util.MatchTaskIterator#callWithNextKey()
 */
@Override public boolean callWithNextKey(final GenericMatcher<T1,T2,O> matchFunction,final Collector<O> collector) throws Exception {
  if (!this.iterator1.nextKey() || !this.iterator2.nextKey()) {
    while (this.iterator1.nextKey())     ;
    while (this.iterator2.nextKey())     ;
    return false;
  }
  final TypePairComparator<T1,T2> comparator=this.comp;
  comparator.setReference(this.iterator1.getCurrent());
  T2 current2=this.iterator2.getCurrent();
  while (true) {
    final int comp=comparator.compareToReference(current2);
    if (comp == 0)     break;
    if (comp < 0) {
      if (!this.iterator2.nextKey()) {
        return false;
      }
      current2=this.iterator2.getCurrent();
    }
 else {
      if (!this.iterator1.nextKey()) {
        return false;
      }
      comparator.setReference(this.iterator1.getCurrent());
    }
  }
  final KeyGroupedIterator<T1>.ValuesIterator values1=this.iterator1.getValues();
  final KeyGroupedIterator<T2>.ValuesIterator values2=this.iterator2.getValues();
  final T1 firstV1=values1.next();
  final T2 firstV2=values2.next();
  final boolean v1HasNext=values1.hasNext();
  final boolean v2HasNext=values2.hasNext();
  if (v1HasNext) {
    if (v2HasNext) {
      crossMwithNValues(firstV1,values1,firstV2,values2,matchFunction,collector);
    }
 else {
      crossSecond1withNValues(firstV2,firstV1,values1,matchFunction,collector);
    }
  }
 else {
    if (v2HasNext) {
      crossFirst1withNValues(firstV1,firstV2,values2,matchFunction,collector);
    }
 else {
      matchFunction.match(firstV1,firstV2,collector);
    }
  }
  return true;
}",0.9794749403341289
55190,"private void compilePlanToJSON(List<DumpableNode<?>> nodes,PrintWriter writer){
  this.nodeIds=new HashMap<DumpableNode<?>,Integer>();
  this.nodeCnt=0;
  writer.print(""String_Node_Str"");
  for (int i=0; i < nodes.size(); i++) {
    visit(nodes.get(i),writer,i == 0);
  }
  writer.println(""String_Node_Str"");
}","private void compilePlanToJSON(List<DumpableNode<?>> nodes,PrintWriter writer){
  this.nodeIds=new HashMap<DumpableNode<?>,Integer>();
  this.nodeCnt=0;
  writer.print(""String_Node_Str"");
  for (int i=0; i < nodes.size(); i++) {
    visit(nodes.get(i),writer);
  }
  writer.println(""String_Node_Str"");
}",0.9885807504078304
55191,"private void visit(DumpableNode<?> node,PrintWriter writer,boolean first){
  if (this.nodeIds.containsKey(node)) {
    return;
  }
  this.nodeIds.put(node,this.nodeCnt++);
  for (Iterator<? extends DumpableNode<?>> children=node.getPredecessors(); children.hasNext(); ) {
    final DumpableNode<?> child=children.next();
    visit(child,writer,false);
  }
  final OptimizerNode n=node.getOptimizerNode();
  writer.print(""String_Node_Str"" + this.nodeIds.get(node));
  final String type;
  final String contents;
  if (n instanceof DataSinkNode) {
    type=""String_Node_Str"";
    contents=n.getPactContract().toString();
  }
 else   if (n instanceof DataSourceNode) {
    type=""String_Node_Str"";
    contents=n.getPactContract().toString();
  }
 else   if (n instanceof BinaryUnionNode) {
    type=""String_Node_Str"";
    contents=""String_Node_Str"";
  }
 else {
    type=""String_Node_Str"";
    contents=n.getPactContract().getName();
  }
  writer.print(""String_Node_Str"" + type + ""String_Node_Str"");
  writer.print(""String_Node_Str"" + n.getName() + ""String_Node_Str"");
  writer.print(""String_Node_Str"" + contents + ""String_Node_Str"");
  writer.print(""String_Node_Str"" + (n.getDegreeOfParallelism() >= 1 ? n.getDegreeOfParallelism() : ""String_Node_Str"") + ""String_Node_Str"");
  Iterator<? extends DumpableConnection<?>> inConns=node.getDumpableInputs();
  String child1name=""String_Node_Str"", child2name=""String_Node_Str"";
  if (inConns != null && inConns.hasNext()) {
    writer.print(""String_Node_Str"");
    int connNum=0;
    int inputNum=0;
    while (inConns.hasNext()) {
      final DumpableConnection<?> conn=inConns.next();
      final Collection<DumpableConnection<?>> inConnsForInput;
      if (conn.getSource() instanceof UnionPlanNode) {
        inConnsForInput=new ArrayList<DumpableConnection<?>>();
        for (Iterator<? extends DumpableConnection<?>> inputOfUnion=conn.getSource().getDumpableInputs(); inputOfUnion.hasNext(); ) {
          inConnsForInput.add(inputOfUnion.next());
        }
      }
 else {
        inConnsForInput=Collections.<DumpableConnection<?>>singleton(conn);
      }
      for (      DumpableConnection<?> inConn : inConnsForInput) {
        final DumpableNode<?> source=inConn.getSource();
        writer.print(connNum == 0 ? ""String_Node_Str"" : ""String_Node_Str"");
        if (connNum == 0) {
          child1name+=child1name.length() > 0 ? ""String_Node_Str"" : ""String_Node_Str"";
          child1name+=source.getOptimizerNode().getPactContract().getName();
        }
 else         if (connNum == 1) {
          child2name+=child2name.length() > 0 ? ""String_Node_Str"" : ""String_Node_Str"";
          child2name=source.getOptimizerNode().getPactContract().getName();
        }
        writer.print(""String_Node_Str"" + this.nodeIds.get(source));
        if (inConns.hasNext()) {
          writer.print(""String_Node_Str"" + (inputNum == 0 ? ""String_Node_Str"" : ""String_Node_Str"") + ""String_Node_Str"");
        }
        final Channel channel=(inConn instanceof Channel) ? (Channel)inConn : null;
        String shipStrategy=null;
switch (conn.getShipStrategy()) {
case NONE:
          break;
case FORWARD:
        shipStrategy=""String_Node_Str"";
      break;
case BROADCAST:
    shipStrategy=""String_Node_Str"";
  break;
case PARTITION_HASH:
shipStrategy=""String_Node_Str"";
break;
case PARTITION_RANGE:
shipStrategy=""String_Node_Str"";
break;
case PARTITION_LOCAL_HASH:
shipStrategy=""String_Node_Str"";
break;
default :
throw new CompilerException(""String_Node_Str"" + conn.getShipStrategy().name() + ""String_Node_Str"");
}
if (channel != null && channel.getShipStrategyKeys() != null && channel.getShipStrategyKeys().size() > 0) {
shipStrategy+=""String_Node_Str"" + (channel.getShipStrategySortOrder() == null ? channel.getShipStrategyKeys().toString() : Utils.createOrdering(channel.getShipStrategyKeys(),channel.getShipStrategySortOrder()).toString());
}
if (shipStrategy != null) {
writer.print(""String_Node_Str"" + shipStrategy + ""String_Node_Str"");
}
if (channel != null) {
String localStrategy=null;
switch (channel.getLocalStrategy()) {
case NONE:
break;
case SORT:
localStrategy=""String_Node_Str"";
break;
case COMBININGSORT:
localStrategy=""String_Node_Str"";
break;
default :
throw new CompilerException(""String_Node_Str"" + channel.getLocalStrategy().name());
}
if (channel.getLocalStrategyKeys() != null && channel.getLocalStrategyKeys().size() > 0) {
localStrategy+=""String_Node_Str"" + (channel.getLocalStrategySortOrder() == null ? channel.getLocalStrategyKeys().toString() : Utils.createOrdering(channel.getLocalStrategyKeys(),channel.getLocalStrategySortOrder()).toString());
}
if (localStrategy != null) {
writer.print(""String_Node_Str"" + localStrategy + ""String_Node_Str"");
}
if (channel.getTempMode() != TempMode.NONE) {
String tempMode=channel.getTempMode().toString();
writer.print(""String_Node_Str"" + tempMode + ""String_Node_Str"");
}
}
writer.print('}');
connNum++;
}
inputNum++;
}
writer.print(""String_Node_Str"");
}
final PlanNode p=node.getPlanNode();
if (p == null) {
return;
}
String locString=null;
if (p.getDriverStrategy() != null) {
switch (p.getDriverStrategy()) {
case NONE:
break;
case MAP:
locString=""String_Node_Str"";
break;
case PARTIAL_GROUP:
locString=""String_Node_Str"";
break;
case GROUP_OVER_ORDERED:
locString=""String_Node_Str"";
break;
case HYBRIDHASH_BUILD_FIRST:
locString=""String_Node_Str"" + child1name + ""String_Node_Str"";
break;
case HYBRIDHASH_BUILD_SECOND:
locString=""String_Node_Str"" + child2name + ""String_Node_Str"";
break;
case NESTEDLOOP_BLOCKED_OUTER_FIRST:
locString=""String_Node_Str"" + child1name + ""String_Node_Str"";
break;
case NESTEDLOOP_BLOCKED_OUTER_SECOND:
locString=""String_Node_Str"" + child2name + ""String_Node_Str"";
break;
case NESTEDLOOP_STREAMED_OUTER_FIRST:
locString=""String_Node_Str"" + child1name + ""String_Node_Str"";
break;
case NESTEDLOOP_STREAMED_OUTER_SECOND:
locString=""String_Node_Str"" + child2name + ""String_Node_Str"";
break;
case MERGE:
locString=""String_Node_Str"";
break;
case CO_GROUP:
locString=""String_Node_Str"";
break;
default :
throw new CompilerException(""String_Node_Str"" + p.getDriverStrategy().name() + ""String_Node_Str"");
}
if (locString != null) {
writer.print(""String_Node_Str"");
writer.print(locString);
writer.print(""String_Node_Str"");
}
}
{
final GlobalProperties gp=p.getGlobalProperties();
writer.print(""String_Node_Str"");
addProperty(writer,""String_Node_Str"",gp.getPartitioning().name(),true);
if (gp.getPartitioningFields() != null) {
addProperty(writer,""String_Node_Str"",gp.getPartitioningFields().toString(),false);
}
if (gp.getPartitioningOrdering() != null) {
addProperty(writer,""String_Node_Str"",gp.getPartitioningOrdering().toString(),false);
}
 else {
addProperty(writer,""String_Node_Str"",""String_Node_Str"",false);
}
if (n.getUniqueFields() == null || n.getUniqueFields().size() == 0) {
addProperty(writer,""String_Node_Str"",""String_Node_Str"",false);
}
 else {
addProperty(writer,""String_Node_Str"",n.getUniqueFields().toString(),false);
}
writer.print(""String_Node_Str"");
}
{
LocalProperties lp=p.getLocalProperties();
writer.print(""String_Node_Str"");
if (lp.getOrdering() != null) {
addProperty(writer,""String_Node_Str"",lp.getOrdering().toString(),true);
}
 else {
addProperty(writer,""String_Node_Str"",""String_Node_Str"",true);
}
if (lp.getGroupedFields() != null && lp.getGroupedFields().size() > 0) {
addProperty(writer,""String_Node_Str"",lp.getGroupedFields().toString(),false);
}
 else {
addProperty(writer,""String_Node_Str"",""String_Node_Str"",false);
}
if (n.getUniqueFields() == null || n.getUniqueFields().size() == 0) {
addProperty(writer,""String_Node_Str"",""String_Node_Str"",false);
}
 else {
addProperty(writer,""String_Node_Str"",n.getUniqueFields().toString(),false);
}
writer.print(""String_Node_Str"");
}
writer.print(""String_Node_Str"");
addProperty(writer,""String_Node_Str"",n.getEstimatedNumRecords() == -1 ? ""String_Node_Str"" : formatNumber(n.getEstimatedNumRecords()),true);
String estCardinality=""String_Node_Str"";
if (n.getEstimatedCardinalities().size() > 0) {
estCardinality=""String_Node_Str"";
for (Entry<FieldSet,Long> entry : n.getEstimatedCardinalities().entrySet()) {
estCardinality+=""String_Node_Str"" + entry.getKey().toString() + ""String_Node_Str""+ entry.getValue()+ ""String_Node_Str"";
}
}
addProperty(writer,""String_Node_Str"",estCardinality,false);
addProperty(writer,""String_Node_Str"",n.getEstimatedOutputSize() == -1 ? ""String_Node_Str"" : formatNumber(n.getEstimatedOutputSize(),""String_Node_Str""),false);
writer.print(""String_Node_Str"");
if (p.getNodeCosts() != null) {
writer.print(""String_Node_Str"");
addProperty(writer,""String_Node_Str"",p.getNodeCosts().getNetworkCost() == -1 ? ""String_Node_Str"" : formatNumber(p.getNodeCosts().getNetworkCost(),""String_Node_Str""),true);
addProperty(writer,""String_Node_Str"",p.getNodeCosts().getDiskCost() == -1 ? ""String_Node_Str"" : formatNumber(p.getNodeCosts().getDiskCost(),""String_Node_Str""),false);
addProperty(writer,""String_Node_Str"",p.getCumulativeCosts().getNetworkCost() == -1 ? ""String_Node_Str"" : formatNumber(p.getCumulativeCosts().getNetworkCost(),""String_Node_Str""),false);
addProperty(writer,""String_Node_Str"",p.getCumulativeCosts().getDiskCost() == -1 ? ""String_Node_Str"" : formatNumber(p.getCumulativeCosts().getDiskCost(),""String_Node_Str""),false);
writer.print(""String_Node_Str"");
}
if (n.getPactContract().getCompilerHints() != null) {
CompilerHints hints=n.getPactContract().getCompilerHints();
CompilerHints defaults=new CompilerHints();
writer.print(""String_Node_Str"");
String hintCardinality;
if (hints.getDistinctCounts().size() > 0) {
hintCardinality=""String_Node_Str"";
for (Entry<FieldSet,Long> entry : hints.getDistinctCounts().entrySet()) {
hintCardinality+=""String_Node_Str"" + entry.getKey().toString() + ""String_Node_Str""+ entry.getValue()+ ""String_Node_Str"";
}
}
 else {
hintCardinality=""String_Node_Str"";
}
addProperty(writer,""String_Node_Str"",hintCardinality,true);
addProperty(writer,""String_Node_Str"",hints.getAvgRecordsEmittedPerStubCall() == defaults.getAvgRecordsEmittedPerStubCall() ? ""String_Node_Str"" : String.valueOf(hints.getAvgRecordsEmittedPerStubCall()),false);
String valuesKey;
if (hints.getAvgNumRecordsPerDistinctFields().size() > 0) {
valuesKey=""String_Node_Str"";
for (Entry<FieldSet,Float> entry : hints.getAvgNumRecordsPerDistinctFields().entrySet()) {
valuesKey+=""String_Node_Str"" + entry.getKey().toString() + ""String_Node_Str""+ entry.getValue()+ ""String_Node_Str"";
}
}
 else {
valuesKey=""String_Node_Str"";
}
addProperty(writer,""String_Node_Str"",valuesKey,false);
addProperty(writer,""String_Node_Str"",hints.getAvgBytesPerRecord() == defaults.getAvgBytesPerRecord() ? ""String_Node_Str"" : String.valueOf(hints.getAvgBytesPerRecord()),false);
writer.print(""String_Node_Str"");
}
writer.print(""String_Node_Str"");
}","private void visit(DumpableNode<?> node,PrintWriter writer){
  if (this.nodeIds.containsKey(node)) {
    return;
  }
  this.nodeIds.put(node,this.nodeCnt++);
  for (Iterator<? extends DumpableNode<?>> children=node.getPredecessors(); children.hasNext(); ) {
    final DumpableNode<?> child=children.next();
    visit(child,writer);
  }
  final OptimizerNode n=node.getOptimizerNode();
  if (this.firstInList) {
    firstInList=false;
  }
 else {
    writer.print(""String_Node_Str"");
  }
  writer.print(""String_Node_Str"" + this.nodeIds.get(node));
  final String type;
  final String contents;
  if (n instanceof DataSinkNode) {
    type=""String_Node_Str"";
    contents=n.getPactContract().toString();
  }
 else   if (n instanceof DataSourceNode) {
    type=""String_Node_Str"";
    contents=n.getPactContract().toString();
  }
 else   if (n instanceof BinaryUnionNode) {
    type=""String_Node_Str"";
    contents=""String_Node_Str"";
  }
 else {
    type=""String_Node_Str"";
    contents=n.getPactContract().getName();
  }
  writer.print(""String_Node_Str"" + type + ""String_Node_Str"");
  writer.print(""String_Node_Str"" + n.getName() + ""String_Node_Str"");
  writer.print(""String_Node_Str"" + contents + ""String_Node_Str"");
  writer.print(""String_Node_Str"" + (n.getDegreeOfParallelism() >= 1 ? n.getDegreeOfParallelism() : ""String_Node_Str"") + ""String_Node_Str"");
  Iterator<? extends DumpableConnection<?>> inConns=node.getDumpableInputs();
  String child1name=""String_Node_Str"", child2name=""String_Node_Str"";
  if (inConns != null && inConns.hasNext()) {
    writer.print(""String_Node_Str"");
    int connNum=0;
    int inputNum=0;
    while (inConns.hasNext()) {
      final DumpableConnection<?> conn=inConns.next();
      final Collection<DumpableConnection<?>> inConnsForInput;
      if (conn.getSource() instanceof UnionPlanNode) {
        inConnsForInput=new ArrayList<DumpableConnection<?>>();
        for (Iterator<? extends DumpableConnection<?>> inputOfUnion=conn.getSource().getDumpableInputs(); inputOfUnion.hasNext(); ) {
          inConnsForInput.add(inputOfUnion.next());
        }
      }
 else {
        inConnsForInput=Collections.<DumpableConnection<?>>singleton(conn);
      }
      for (      DumpableConnection<?> inConn : inConnsForInput) {
        final DumpableNode<?> source=inConn.getSource();
        writer.print(connNum == 0 ? ""String_Node_Str"" : ""String_Node_Str"");
        if (connNum == 0) {
          child1name+=child1name.length() > 0 ? ""String_Node_Str"" : ""String_Node_Str"";
          child1name+=source.getOptimizerNode().getPactContract().getName();
        }
 else         if (connNum == 1) {
          child2name+=child2name.length() > 0 ? ""String_Node_Str"" : ""String_Node_Str"";
          child2name=source.getOptimizerNode().getPactContract().getName();
        }
        writer.print(""String_Node_Str"" + this.nodeIds.get(source));
        if (inConns.hasNext() || inputNum > 0) {
          writer.print(""String_Node_Str"" + (inputNum == 0 ? ""String_Node_Str"" : ""String_Node_Str"") + ""String_Node_Str"");
        }
        final Channel channel=(inConn instanceof Channel) ? (Channel)inConn : null;
        final ShipStrategyType shipType=channel != null ? channel.getShipStrategy() : ((PactConnection)inConn).getShipStrategy();
        String shipStrategy=null;
        if (shipType != null) {
switch (shipType) {
case NONE:
            break;
case FORWARD:
          shipStrategy=""String_Node_Str"";
        break;
case BROADCAST:
      shipStrategy=""String_Node_Str"";
    break;
case PARTITION_HASH:
  shipStrategy=""String_Node_Str"";
break;
case PARTITION_RANGE:
shipStrategy=""String_Node_Str"";
break;
case PARTITION_LOCAL_HASH:
shipStrategy=""String_Node_Str"";
break;
default :
throw new CompilerException(""String_Node_Str"" + conn.getShipStrategy().name() + ""String_Node_Str"");
}
}
if (channel != null && channel.getShipStrategyKeys() != null && channel.getShipStrategyKeys().size() > 0) {
shipStrategy+=""String_Node_Str"" + (channel.getShipStrategySortOrder() == null ? channel.getShipStrategyKeys().toString() : Utils.createOrdering(channel.getShipStrategyKeys(),channel.getShipStrategySortOrder()).toString());
}
if (shipStrategy != null) {
writer.print(""String_Node_Str"" + shipStrategy + ""String_Node_Str"");
}
if (channel != null) {
String localStrategy=null;
switch (channel.getLocalStrategy()) {
case NONE:
break;
case SORT:
localStrategy=""String_Node_Str"";
break;
case COMBININGSORT:
localStrategy=""String_Node_Str"";
break;
default :
throw new CompilerException(""String_Node_Str"" + channel.getLocalStrategy().name());
}
if (channel != null && channel.getLocalStrategyKeys() != null && channel.getLocalStrategyKeys().size() > 0) {
localStrategy+=""String_Node_Str"" + (channel.getLocalStrategySortOrder() == null ? channel.getLocalStrategyKeys().toString() : Utils.createOrdering(channel.getLocalStrategyKeys(),channel.getLocalStrategySortOrder()).toString());
}
if (localStrategy != null) {
writer.print(""String_Node_Str"" + localStrategy + ""String_Node_Str"");
}
if (channel != null && channel.getTempMode() != TempMode.NONE) {
String tempMode=channel.getTempMode().toString();
writer.print(""String_Node_Str"" + tempMode + ""String_Node_Str"");
}
}
writer.print('}');
connNum++;
}
inputNum++;
}
writer.print(""String_Node_Str"");
}
final PlanNode p=node.getPlanNode();
if (p == null) {
writer.print(""String_Node_Str"");
return;
}
String locString=null;
if (p.getDriverStrategy() != null) {
switch (p.getDriverStrategy()) {
case NONE:
break;
case MAP:
locString=""String_Node_Str"";
break;
case PARTIAL_GROUP:
locString=""String_Node_Str"";
break;
case GROUP_OVER_ORDERED:
locString=""String_Node_Str"";
break;
case HYBRIDHASH_BUILD_FIRST:
locString=""String_Node_Str"" + child1name + ""String_Node_Str"";
break;
case HYBRIDHASH_BUILD_SECOND:
locString=""String_Node_Str"" + child2name + ""String_Node_Str"";
break;
case NESTEDLOOP_BLOCKED_OUTER_FIRST:
locString=""String_Node_Str"" + child1name + ""String_Node_Str"";
break;
case NESTEDLOOP_BLOCKED_OUTER_SECOND:
locString=""String_Node_Str"" + child2name + ""String_Node_Str"";
break;
case NESTEDLOOP_STREAMED_OUTER_FIRST:
locString=""String_Node_Str"" + child1name + ""String_Node_Str"";
break;
case NESTEDLOOP_STREAMED_OUTER_SECOND:
locString=""String_Node_Str"" + child2name + ""String_Node_Str"";
break;
case MERGE:
locString=""String_Node_Str"";
break;
case CO_GROUP:
locString=""String_Node_Str"";
break;
default :
throw new CompilerException(""String_Node_Str"" + p.getDriverStrategy().name() + ""String_Node_Str"");
}
if (locString != null) {
writer.print(""String_Node_Str"");
writer.print(locString);
writer.print(""String_Node_Str"");
}
}
{
final GlobalProperties gp=p.getGlobalProperties();
writer.print(""String_Node_Str"");
addProperty(writer,""String_Node_Str"",gp.getPartitioning().name(),true);
if (gp.getPartitioningFields() != null) {
addProperty(writer,""String_Node_Str"",gp.getPartitioningFields().toString(),false);
}
if (gp.getPartitioningOrdering() != null) {
addProperty(writer,""String_Node_Str"",gp.getPartitioningOrdering().toString(),false);
}
 else {
addProperty(writer,""String_Node_Str"",""String_Node_Str"",false);
}
if (n.getUniqueFields() == null || n.getUniqueFields().size() == 0) {
addProperty(writer,""String_Node_Str"",""String_Node_Str"",false);
}
 else {
addProperty(writer,""String_Node_Str"",n.getUniqueFields().toString(),false);
}
writer.print(""String_Node_Str"");
}
{
LocalProperties lp=p.getLocalProperties();
writer.print(""String_Node_Str"");
if (lp.getOrdering() != null) {
addProperty(writer,""String_Node_Str"",lp.getOrdering().toString(),true);
}
 else {
addProperty(writer,""String_Node_Str"",""String_Node_Str"",true);
}
if (lp.getGroupedFields() != null && lp.getGroupedFields().size() > 0) {
addProperty(writer,""String_Node_Str"",lp.getGroupedFields().toString(),false);
}
 else {
addProperty(writer,""String_Node_Str"",""String_Node_Str"",false);
}
if (n.getUniqueFields() == null || n.getUniqueFields().size() == 0) {
addProperty(writer,""String_Node_Str"",""String_Node_Str"",false);
}
 else {
addProperty(writer,""String_Node_Str"",n.getUniqueFields().toString(),false);
}
writer.print(""String_Node_Str"");
}
writer.print(""String_Node_Str"");
addProperty(writer,""String_Node_Str"",n.getEstimatedNumRecords() == -1 ? ""String_Node_Str"" : formatNumber(n.getEstimatedNumRecords()),true);
String estCardinality=""String_Node_Str"";
if (n.getEstimatedCardinalities().size() > 0) {
estCardinality=""String_Node_Str"";
for (Entry<FieldSet,Long> entry : n.getEstimatedCardinalities().entrySet()) {
estCardinality+=""String_Node_Str"" + entry.getKey().toString() + ""String_Node_Str""+ entry.getValue()+ ""String_Node_Str"";
}
}
addProperty(writer,""String_Node_Str"",estCardinality,false);
addProperty(writer,""String_Node_Str"",n.getEstimatedOutputSize() == -1 ? ""String_Node_Str"" : formatNumber(n.getEstimatedOutputSize(),""String_Node_Str""),false);
writer.print(""String_Node_Str"");
if (p.getNodeCosts() != null) {
writer.print(""String_Node_Str"");
addProperty(writer,""String_Node_Str"",p.getNodeCosts().getNetworkCost() == -1 ? ""String_Node_Str"" : formatNumber(p.getNodeCosts().getNetworkCost(),""String_Node_Str""),true);
addProperty(writer,""String_Node_Str"",p.getNodeCosts().getDiskCost() == -1 ? ""String_Node_Str"" : formatNumber(p.getNodeCosts().getDiskCost(),""String_Node_Str""),false);
addProperty(writer,""String_Node_Str"",p.getCumulativeCosts().getNetworkCost() == -1 ? ""String_Node_Str"" : formatNumber(p.getCumulativeCosts().getNetworkCost(),""String_Node_Str""),false);
addProperty(writer,""String_Node_Str"",p.getCumulativeCosts().getDiskCost() == -1 ? ""String_Node_Str"" : formatNumber(p.getCumulativeCosts().getDiskCost(),""String_Node_Str""),false);
writer.print(""String_Node_Str"");
}
if (n.getPactContract().getCompilerHints() != null) {
CompilerHints hints=n.getPactContract().getCompilerHints();
CompilerHints defaults=new CompilerHints();
writer.print(""String_Node_Str"");
String hintCardinality;
if (hints.getDistinctCounts().size() > 0) {
hintCardinality=""String_Node_Str"";
for (Entry<FieldSet,Long> entry : hints.getDistinctCounts().entrySet()) {
hintCardinality+=""String_Node_Str"" + entry.getKey().toString() + ""String_Node_Str""+ entry.getValue()+ ""String_Node_Str"";
}
}
 else {
hintCardinality=""String_Node_Str"";
}
addProperty(writer,""String_Node_Str"",hintCardinality,true);
addProperty(writer,""String_Node_Str"",hints.getAvgRecordsEmittedPerStubCall() == defaults.getAvgRecordsEmittedPerStubCall() ? ""String_Node_Str"" : String.valueOf(hints.getAvgRecordsEmittedPerStubCall()),false);
String valuesKey;
if (hints.getAvgNumRecordsPerDistinctFields().size() > 0) {
valuesKey=""String_Node_Str"";
for (Entry<FieldSet,Float> entry : hints.getAvgNumRecordsPerDistinctFields().entrySet()) {
valuesKey+=""String_Node_Str"" + entry.getKey().toString() + ""String_Node_Str""+ entry.getValue()+ ""String_Node_Str"";
}
}
 else {
valuesKey=""String_Node_Str"";
}
addProperty(writer,""String_Node_Str"",valuesKey,false);
addProperty(writer,""String_Node_Str"",hints.getAvgBytesPerRecord() == defaults.getAvgBytesPerRecord() ? ""String_Node_Str"" : String.valueOf(hints.getAvgBytesPerRecord()),false);
writer.print(""String_Node_Str"");
}
writer.print(""String_Node_Str"");
}",0.9735842146225336
55192,"@Before public void setup(){
  InetSocketAddress dummyAddr=new InetSocketAddress(""String_Node_Str"",12345);
  DataStatistics dataStats=new DataStatistics();
  dataStats.cacheBaseStatistics(new FileInputFormat.FileBaseStatistics(1000,128 * 1024 * 1024,8.0f),CACHE_KEY);
  this.compiler=new PactCompiler(dataStats,new DefaultCostEstimator(),dummyAddr);
  InstanceType iType=InstanceTypeFactory.construct(""String_Node_Str"",6,2,4096,100,0);
  HardwareDescription hDesc=HardwareDescriptionFactory.construct(2,4096 * 1024 * 1024,2000 * 1024 * 1024);
  this.instanceType=InstanceTypeDescriptionFactory.construct(iType,hDesc,defaultParallelism * 2);
}","@Before public void setup(){
  InetSocketAddress dummyAddr=new InetSocketAddress(""String_Node_Str"",12345);
  DataStatistics dataStats=new DataStatistics();
  dataStats.cacheBaseStatistics(new FileInputFormat.FileBaseStatistics(1000,128 * 1024 * 1024,8.0f),CACHE_KEY);
  this.compiler=new PactCompiler(dataStats,new DefaultCostEstimator(),dummyAddr);
  InstanceType iType=InstanceTypeFactory.construct(""String_Node_Str"",6,2,4096,100,0);
  HardwareDescription hDesc=HardwareDescriptionFactory.construct(2,4096 * 1024 * 1024,2000 * 1024 * 1024);
  this.instanceType=InstanceTypeDescriptionFactory.construct(iType,hDesc,DEFAULT_PARALLELISM * 2);
}",0.9727626459143968
55193,"/** 
 * Simple Job: Map -> Reduce -> Map -> Reduce. All functions preserve all fields (hence all properties). Increases DOP between 2nd map and 2nd reduce, so the hash partitioning from 1st reduce is not reusable. Expected to re-establish partitioning between map and reduce (hash).
 */
@Test public void checkPropertyHandlingWithIncreasingGlobalParallelism2(){
  final int degOfPar=defaultParallelism;
  FileDataSource source=new FileDataSource(DummyInputFormat.class,IN_FILE_1,""String_Node_Str"");
  source.setDegreeOfParallelism(degOfPar);
  MapContract map1=MapContract.builder(IdentityMap.class).name(""String_Node_Str"").build();
  map1.setDegreeOfParallelism(degOfPar);
  map1.setInput(source);
  ReduceContract reduce1=ReduceContract.builder(IdentityReduce.class,PactInteger.class,0).name(""String_Node_Str"").build();
  reduce1.setDegreeOfParallelism(degOfPar);
  reduce1.setInput(map1);
  MapContract map2=MapContract.builder(IdentityMap.class).name(""String_Node_Str"").build();
  map2.setDegreeOfParallelism(degOfPar);
  map2.setInput(reduce1);
  ReduceContract reduce2=ReduceContract.builder(IdentityReduce.class,PactInteger.class,0).name(""String_Node_Str"").build();
  reduce2.setDegreeOfParallelism(degOfPar * 2);
  reduce2.setInput(map2);
  FileDataSink sink=new FileDataSink(DummyOutputFormat.class,OUT_FILE_1,""String_Node_Str"");
  sink.setDegreeOfParallelism(degOfPar * 2);
  sink.setInput(reduce2);
  Plan plan=new Plan(sink,""String_Node_Str"");
  OptimizedPlan oPlan=compile(plan);
  SinkPlanNode sinkNode=oPlan.getDataSinks().iterator().next();
  SingleInputPlanNode red2Node=(SingleInputPlanNode)sinkNode.getPredecessor();
  SingleInputPlanNode map2Node=(SingleInputPlanNode)red2Node.getPredecessor();
  ShipStrategyType mapIn=map2Node.getInput().getShipStrategy();
  ShipStrategyType reduceIn=red2Node.getInput().getShipStrategy();
  Assert.assertEquals(""String_Node_Str"",ShipStrategyType.FORWARD,mapIn);
  Assert.assertEquals(""String_Node_Str"",ShipStrategyType.PARTITION_HASH,reduceIn);
}","/** 
 * Simple Job: Map -> Reduce -> Map -> Reduce. All functions preserve all fields (hence all properties). Increases DOP between 2nd map and 2nd reduce, so the hash partitioning from 1st reduce is not reusable. Expected to re-establish partitioning between map and reduce (hash).
 */
@Test public void checkPropertyHandlingWithIncreasingGlobalParallelism2(){
  final int degOfPar=DEFAULT_PARALLELISM;
  FileDataSource source=new FileDataSource(DummyInputFormat.class,IN_FILE_1,""String_Node_Str"");
  source.setDegreeOfParallelism(degOfPar);
  MapContract map1=MapContract.builder(IdentityMap.class).name(""String_Node_Str"").build();
  map1.setDegreeOfParallelism(degOfPar);
  map1.setInput(source);
  ReduceContract reduce1=ReduceContract.builder(IdentityReduce.class,PactInteger.class,0).name(""String_Node_Str"").build();
  reduce1.setDegreeOfParallelism(degOfPar);
  reduce1.setInput(map1);
  MapContract map2=MapContract.builder(IdentityMap.class).name(""String_Node_Str"").build();
  map2.setDegreeOfParallelism(degOfPar);
  map2.setInput(reduce1);
  ReduceContract reduce2=ReduceContract.builder(IdentityReduce.class,PactInteger.class,0).name(""String_Node_Str"").build();
  reduce2.setDegreeOfParallelism(degOfPar * 2);
  reduce2.setInput(map2);
  FileDataSink sink=new FileDataSink(DummyOutputFormat.class,OUT_FILE_1,""String_Node_Str"");
  sink.setDegreeOfParallelism(degOfPar * 2);
  sink.setInput(reduce2);
  Plan plan=new Plan(sink,""String_Node_Str"");
  OptimizedPlan oPlan=compile(plan);
  SinkPlanNode sinkNode=oPlan.getDataSinks().iterator().next();
  SingleInputPlanNode red2Node=(SingleInputPlanNode)sinkNode.getPredecessor();
  SingleInputPlanNode map2Node=(SingleInputPlanNode)red2Node.getPredecessor();
  ShipStrategyType mapIn=map2Node.getInput().getShipStrategy();
  ShipStrategyType reduceIn=red2Node.getInput().getShipStrategy();
  Assert.assertEquals(""String_Node_Str"",ShipStrategyType.FORWARD,mapIn);
  Assert.assertEquals(""String_Node_Str"",ShipStrategyType.PARTITION_HASH,reduceIn);
}",0.9907661592213626
55194,"/** 
 * Simple Job: Map -> Reduce -> Map -> Reduce. All functions preserve all fields (hence all properties). Increases DOP between 1st reduce and 2nd map, such that more tasks are on one instance. Expected to re-establish partitioning between map and reduce via a local hash.
 */
@Test public void checkPropertyHandlingWithIncreasingLocalParallelism(){
  final int degOfPar=2 * defaultParallelism;
  FileDataSource source=new FileDataSource(DummyInputFormat.class,IN_FILE_1,""String_Node_Str"");
  source.setDegreeOfParallelism(degOfPar);
  MapContract map1=MapContract.builder(IdentityMap.class).name(""String_Node_Str"").build();
  map1.setDegreeOfParallelism(degOfPar);
  map1.setInput(source);
  ReduceContract reduce1=ReduceContract.builder(IdentityReduce.class,PactInteger.class,0).name(""String_Node_Str"").build();
  reduce1.setDegreeOfParallelism(degOfPar);
  reduce1.setInput(map1);
  MapContract map2=MapContract.builder(IdentityMap.class).name(""String_Node_Str"").build();
  map2.setDegreeOfParallelism(degOfPar * 2);
  map2.setInput(reduce1);
  ReduceContract reduce2=ReduceContract.builder(IdentityReduce.class,PactInteger.class,0).name(""String_Node_Str"").build();
  reduce2.setDegreeOfParallelism(degOfPar * 2);
  reduce2.setInput(map2);
  FileDataSink sink=new FileDataSink(DummyOutputFormat.class,OUT_FILE_1,""String_Node_Str"");
  sink.setDegreeOfParallelism(degOfPar * 2);
  sink.setInput(reduce2);
  Plan plan=new Plan(sink,""String_Node_Str"");
  OptimizedPlan oPlan=compile(plan);
  SinkPlanNode sinkNode=oPlan.getDataSinks().iterator().next();
  SingleInputPlanNode red2Node=(SingleInputPlanNode)sinkNode.getPredecessor();
  SingleInputPlanNode map2Node=(SingleInputPlanNode)red2Node.getPredecessor();
  ShipStrategyType mapIn=map2Node.getInput().getShipStrategy();
  ShipStrategyType reduceIn=red2Node.getInput().getShipStrategy();
  Assert.assertEquals(""String_Node_Str"",ShipStrategyType.PARTITION_LOCAL_HASH,mapIn);
  Assert.assertEquals(""String_Node_Str"",ShipStrategyType.FORWARD,reduceIn);
}","/** 
 * Simple Job: Map -> Reduce -> Map -> Reduce. All functions preserve all fields (hence all properties). Increases DOP between 1st reduce and 2nd map, such that more tasks are on one instance. Expected to re-establish partitioning between map and reduce via a local hash.
 */
@Test public void checkPropertyHandlingWithIncreasingLocalParallelism(){
  final int degOfPar=2 * DEFAULT_PARALLELISM;
  FileDataSource source=new FileDataSource(DummyInputFormat.class,IN_FILE_1,""String_Node_Str"");
  source.setDegreeOfParallelism(degOfPar);
  MapContract map1=MapContract.builder(IdentityMap.class).name(""String_Node_Str"").build();
  map1.setDegreeOfParallelism(degOfPar);
  map1.setInput(source);
  ReduceContract reduce1=ReduceContract.builder(IdentityReduce.class,PactInteger.class,0).name(""String_Node_Str"").build();
  reduce1.setDegreeOfParallelism(degOfPar);
  reduce1.setInput(map1);
  MapContract map2=MapContract.builder(IdentityMap.class).name(""String_Node_Str"").build();
  map2.setDegreeOfParallelism(degOfPar * 2);
  map2.setInput(reduce1);
  ReduceContract reduce2=ReduceContract.builder(IdentityReduce.class,PactInteger.class,0).name(""String_Node_Str"").build();
  reduce2.setDegreeOfParallelism(degOfPar * 2);
  reduce2.setInput(map2);
  FileDataSink sink=new FileDataSink(DummyOutputFormat.class,OUT_FILE_1,""String_Node_Str"");
  sink.setDegreeOfParallelism(degOfPar * 2);
  sink.setInput(reduce2);
  Plan plan=new Plan(sink,""String_Node_Str"");
  OptimizedPlan oPlan=compile(plan);
  SinkPlanNode sinkNode=oPlan.getDataSinks().iterator().next();
  SingleInputPlanNode red2Node=(SingleInputPlanNode)sinkNode.getPredecessor();
  SingleInputPlanNode map2Node=(SingleInputPlanNode)red2Node.getPredecessor();
  ShipStrategyType mapIn=map2Node.getInput().getShipStrategy();
  ShipStrategyType reduceIn=red2Node.getInput().getShipStrategy();
  Assert.assertEquals(""String_Node_Str"",ShipStrategyType.PARTITION_LOCAL_HASH,mapIn);
  Assert.assertEquals(""String_Node_Str"",ShipStrategyType.FORWARD,reduceIn);
}",0.9907937297835282
55195,"/** 
 * Simple Job: Map -> Reduce -> Map -> Reduce. All functions preserve all fields (hence all properties). Increases DOP between 1st reduce and 2nd map, so the hash partitioning from 1st reduce is not reusable. Expected to re-establish partitioning between reduce and map, via hash, because random is a full network transit as well.
 */
@Test public void checkPropertyHandlingWithIncreasingGlobalParallelism1(){
  final int degOfPar=defaultParallelism;
  FileDataSource source=new FileDataSource(DummyInputFormat.class,IN_FILE_1,""String_Node_Str"");
  source.setDegreeOfParallelism(degOfPar);
  MapContract map1=MapContract.builder(IdentityMap.class).name(""String_Node_Str"").build();
  map1.setDegreeOfParallelism(degOfPar);
  map1.setInput(source);
  ReduceContract reduce1=ReduceContract.builder(IdentityReduce.class,PactInteger.class,0).name(""String_Node_Str"").build();
  reduce1.setDegreeOfParallelism(degOfPar);
  reduce1.setInput(map1);
  MapContract map2=MapContract.builder(IdentityMap.class).name(""String_Node_Str"").build();
  map2.setDegreeOfParallelism(degOfPar * 2);
  map2.setInput(reduce1);
  ReduceContract reduce2=ReduceContract.builder(IdentityReduce.class,PactInteger.class,0).name(""String_Node_Str"").build();
  reduce2.setDegreeOfParallelism(degOfPar * 2);
  reduce2.setInput(map2);
  FileDataSink sink=new FileDataSink(DummyOutputFormat.class,OUT_FILE_1,""String_Node_Str"");
  sink.setDegreeOfParallelism(degOfPar * 2);
  sink.setInput(reduce2);
  Plan plan=new Plan(sink,""String_Node_Str"");
  OptimizedPlan oPlan=compile(plan);
  SinkPlanNode sinkNode=oPlan.getDataSinks().iterator().next();
  SingleInputPlanNode red2Node=(SingleInputPlanNode)sinkNode.getPredecessor();
  SingleInputPlanNode map2Node=(SingleInputPlanNode)red2Node.getPredecessor();
  ShipStrategyType mapIn=map2Node.getInput().getShipStrategy();
  ShipStrategyType redIn=red2Node.getInput().getShipStrategy();
  Assert.assertEquals(""String_Node_Str"",ShipStrategyType.PARTITION_HASH,mapIn);
  Assert.assertEquals(""String_Node_Str"",ShipStrategyType.FORWARD,redIn);
}","/** 
 * Simple Job: Map -> Reduce -> Map -> Reduce. All functions preserve all fields (hence all properties). Increases DOP between 1st reduce and 2nd map, so the hash partitioning from 1st reduce is not reusable. Expected to re-establish partitioning between reduce and map, via hash, because random is a full network transit as well.
 */
@Test public void checkPropertyHandlingWithIncreasingGlobalParallelism1(){
  final int degOfPar=DEFAULT_PARALLELISM;
  FileDataSource source=new FileDataSource(DummyInputFormat.class,IN_FILE_1,""String_Node_Str"");
  source.setDegreeOfParallelism(degOfPar);
  MapContract map1=MapContract.builder(IdentityMap.class).name(""String_Node_Str"").build();
  map1.setDegreeOfParallelism(degOfPar);
  map1.setInput(source);
  ReduceContract reduce1=ReduceContract.builder(IdentityReduce.class,PactInteger.class,0).name(""String_Node_Str"").build();
  reduce1.setDegreeOfParallelism(degOfPar);
  reduce1.setInput(map1);
  MapContract map2=MapContract.builder(IdentityMap.class).name(""String_Node_Str"").build();
  map2.setDegreeOfParallelism(degOfPar * 2);
  map2.setInput(reduce1);
  ReduceContract reduce2=ReduceContract.builder(IdentityReduce.class,PactInteger.class,0).name(""String_Node_Str"").build();
  reduce2.setDegreeOfParallelism(degOfPar * 2);
  reduce2.setInput(map2);
  FileDataSink sink=new FileDataSink(DummyOutputFormat.class,OUT_FILE_1,""String_Node_Str"");
  sink.setDegreeOfParallelism(degOfPar * 2);
  sink.setInput(reduce2);
  Plan plan=new Plan(sink,""String_Node_Str"");
  OptimizedPlan oPlan=compile(plan);
  SinkPlanNode sinkNode=oPlan.getDataSinks().iterator().next();
  SingleInputPlanNode red2Node=(SingleInputPlanNode)sinkNode.getPredecessor();
  SingleInputPlanNode map2Node=(SingleInputPlanNode)red2Node.getPredecessor();
  ShipStrategyType mapIn=map2Node.getInput().getShipStrategy();
  ShipStrategyType redIn=red2Node.getInput().getShipStrategy();
  Assert.assertEquals(""String_Node_Str"",ShipStrategyType.PARTITION_HASH,mapIn);
  Assert.assertEquals(""String_Node_Str"",ShipStrategyType.FORWARD,redIn);
}",0.990995376003894
55196,"/** 
 * This method tests that with word count and a range partitioned sink, the range partitioner is pushed down.
 */
@Test public void testWordCountWithSortedSink(){
  FileDataSource sourceNode=new FileDataSource(TextInputFormat.class,IN_FILE_1,""String_Node_Str"");
  MapContract mapNode=MapContract.builder(TokenizeLine.class).input(sourceNode).name(""String_Node_Str"").build();
  ReduceContract reduceNode=new ReduceContract.Builder(CountWords.class,PactString.class,0).input(mapNode).name(""String_Node_Str"").build();
  FileDataSink out=new FileDataSink(RecordOutputFormat.class,OUT_FILE_1,reduceNode,""String_Node_Str"");
  RecordOutputFormat.configureRecordFormat(out).recordDelimiter('\n').fieldDelimiter(' ').lenient(true).field(PactString.class,0).field(PactInteger.class,1);
  out.setGlobalOrder(new Ordering(0,PactString.class,Order.DESCENDING),new MockDataDistribution());
  Plan p=new Plan(out,""String_Node_Str"");
  p.setDefaultParallelism(defaultParallelism);
  OptimizedPlan plan=compile(p);
  SinkPlanNode sink=plan.getDataSinks().iterator().next();
  SingleInputPlanNode reducer=(SingleInputPlanNode)sink.getPredecessor();
  SingleInputPlanNode mapper=(SingleInputPlanNode)reducer.getPredecessor();
  Assert.assertEquals(ShipStrategyType.FORWARD,mapper.getInput().getShipStrategy());
  Assert.assertEquals(ShipStrategyType.PARTITION_RANGE,reducer.getInput().getShipStrategy());
  Assert.assertEquals(ShipStrategyType.FORWARD,sink.getInput().getShipStrategy());
  Channel c=reducer.getInput();
  Assert.assertEquals(LocalStrategy.COMBININGSORT,c.getLocalStrategy());
  FieldList l=new FieldList(0);
  Assert.assertEquals(l,c.getShipStrategyKeys());
  Assert.assertEquals(l,c.getLocalStrategyKeys());
  Assert.assertFalse(c.getShipStrategySortOrder()[0]);
  Assert.assertFalse(c.getLocalStrategySortOrder()[0]);
}","/** 
 * This method tests that with word count and a range partitioned sink, the range partitioner is pushed down.
 */
@Test public void testWordCountWithSortedSink(){
  FileDataSource sourceNode=new FileDataSource(TextInputFormat.class,IN_FILE_1,""String_Node_Str"");
  MapContract mapNode=MapContract.builder(TokenizeLine.class).input(sourceNode).name(""String_Node_Str"").build();
  ReduceContract reduceNode=new ReduceContract.Builder(CountWords.class,PactString.class,0).input(mapNode).name(""String_Node_Str"").build();
  FileDataSink out=new FileDataSink(RecordOutputFormat.class,OUT_FILE_1,reduceNode,""String_Node_Str"");
  RecordOutputFormat.configureRecordFormat(out).recordDelimiter('\n').fieldDelimiter(' ').lenient(true).field(PactString.class,0).field(PactInteger.class,1);
  out.setGlobalOrder(new Ordering(0,PactString.class,Order.DESCENDING),new MockDataDistribution());
  Plan p=new Plan(out,""String_Node_Str"");
  p.setDefaultParallelism(DEFAULT_PARALLELISM);
  OptimizedPlan plan=compile(p);
  SinkPlanNode sink=plan.getDataSinks().iterator().next();
  SingleInputPlanNode reducer=(SingleInputPlanNode)sink.getPredecessor();
  SingleInputPlanNode mapper=(SingleInputPlanNode)reducer.getPredecessor();
  Assert.assertEquals(ShipStrategyType.FORWARD,mapper.getInput().getShipStrategy());
  Assert.assertEquals(ShipStrategyType.PARTITION_RANGE,reducer.getInput().getShipStrategy());
  Assert.assertEquals(ShipStrategyType.FORWARD,sink.getInput().getShipStrategy());
  Channel c=reducer.getInput();
  Assert.assertEquals(LocalStrategy.COMBININGSORT,c.getLocalStrategy());
  FieldList l=new FieldList(0);
  Assert.assertEquals(l,c.getShipStrategyKeys());
  Assert.assertEquals(l,c.getLocalStrategyKeys());
  Assert.assertFalse(c.getShipStrategySortOrder()[0]);
  Assert.assertFalse(c.getLocalStrategySortOrder()[0]);
}",0.9904083310496028
55197,"/** 
 * This method tests the simple word count.
 */
@Test public void testWordCount(){
  WordCount wc=new WordCount();
  Plan p=wc.getPlan(String.valueOf(defaultParallelism),IN_FILE_1,OUT_FILE_1);
  OptimizedPlan plan=compile(p);
  SinkPlanNode sink=plan.getDataSinks().iterator().next();
  SingleInputPlanNode reducer=(SingleInputPlanNode)sink.getPredecessor();
  SingleInputPlanNode mapper=(SingleInputPlanNode)reducer.getPredecessor();
  Assert.assertEquals(ShipStrategyType.FORWARD,mapper.getInput().getShipStrategy());
  Assert.assertEquals(ShipStrategyType.PARTITION_HASH,reducer.getInput().getShipStrategy());
  Assert.assertEquals(ShipStrategyType.FORWARD,sink.getInput().getShipStrategy());
  Channel c=reducer.getInput();
  Assert.assertEquals(LocalStrategy.COMBININGSORT,c.getLocalStrategy());
  FieldList l=new FieldList(0);
  Assert.assertEquals(l,c.getShipStrategyKeys());
  Assert.assertEquals(l,c.getLocalStrategyKeys());
  Assert.assertTrue(Arrays.equals(c.getLocalStrategySortOrder(),reducer.getSortOrders()));
}","/** 
 * This method tests the simple word count.
 */
@Test public void testWordCount(){
  WordCount wc=new WordCount();
  Plan p=wc.getPlan(String.valueOf(DEFAULT_PARALLELISM),IN_FILE_1,OUT_FILE_1);
  OptimizedPlan plan=compile(p);
  SinkPlanNode sink=plan.getDataSinks().iterator().next();
  SingleInputPlanNode reducer=(SingleInputPlanNode)sink.getPredecessor();
  SingleInputPlanNode mapper=(SingleInputPlanNode)reducer.getPredecessor();
  Assert.assertEquals(ShipStrategyType.FORWARD,mapper.getInput().getShipStrategy());
  Assert.assertEquals(ShipStrategyType.PARTITION_HASH,reducer.getInput().getShipStrategy());
  Assert.assertEquals(ShipStrategyType.FORWARD,sink.getInput().getShipStrategy());
  Channel c=reducer.getInput();
  Assert.assertEquals(LocalStrategy.COMBININGSORT,c.getLocalStrategy());
  FieldList l=new FieldList(0);
  Assert.assertEquals(l,c.getShipStrategyKeys());
  Assert.assertEquals(l,c.getLocalStrategyKeys());
  Assert.assertTrue(Arrays.equals(c.getLocalStrategySortOrder(),reducer.getSortOrders()));
}",0.9820649539505576
55198,"/** 
 * Source -> Map -> Reduce -> Cross -> Reduce -> Cross -> Reduce -> |--------------------------/                  / |--------------------------------------------/ First cross has SameKeyFirst output contract
 */
@Test public void testTicket158(){
  FileDataSource source=new FileDataSource(DummyInputFormat.class,IN_FILE_1,""String_Node_Str"");
  MapContract map=MapContract.builder(IdentityMap.class).name(""String_Node_Str"").input(source).build();
  ReduceContract reduce1=ReduceContract.builder(IdentityReduce.class,PactInteger.class,0).name(""String_Node_Str"").input(map).build();
  CrossContract cross1=CrossContract.builder(DummyCrossStub.class).name(""String_Node_Str"").input1(reduce1).input2(source).build();
  ReduceContract reduce2=ReduceContract.builder(IdentityReduce.class,PactInteger.class,0).name(""String_Node_Str"").input(cross1).build();
  CrossContract cross2=CrossContract.builder(DummyCrossStub.class).name(""String_Node_Str"").input1(reduce2).input2(source).build();
  ReduceContract reduce3=ReduceContract.builder(IdentityReduce.class,PactInteger.class,0).name(""String_Node_Str"").input(cross2).build();
  FileDataSink sink=new FileDataSink(DummyOutputFormat.class,OUT_FILE_1,""String_Node_Str"");
  sink.setInput(reduce3);
  Plan plan=new Plan(sink,""String_Node_Str"");
  plan.setDefaultParallelism(defaultParallelism);
  OptimizedPlan oPlan=compile(plan);
  NepheleJobGraphGenerator jobGen=new NepheleJobGraphGenerator();
  jobGen.compileJobGraph(oPlan);
}","/** 
 * Source -> Map -> Reduce -> Cross -> Reduce -> Cross -> Reduce -> |--------------------------/                  / |--------------------------------------------/ First cross has SameKeyFirst output contract
 */
@Test public void testTicket158(){
  FileDataSource source=new FileDataSource(DummyInputFormat.class,IN_FILE_1,""String_Node_Str"");
  MapContract map=MapContract.builder(IdentityMap.class).name(""String_Node_Str"").input(source).build();
  ReduceContract reduce1=ReduceContract.builder(IdentityReduce.class,PactInteger.class,0).name(""String_Node_Str"").input(map).build();
  CrossContract cross1=CrossContract.builder(DummyCrossStub.class).name(""String_Node_Str"").input1(reduce1).input2(source).build();
  ReduceContract reduce2=ReduceContract.builder(IdentityReduce.class,PactInteger.class,0).name(""String_Node_Str"").input(cross1).build();
  CrossContract cross2=CrossContract.builder(DummyCrossStub.class).name(""String_Node_Str"").input1(reduce2).input2(source).build();
  ReduceContract reduce3=ReduceContract.builder(IdentityReduce.class,PactInteger.class,0).name(""String_Node_Str"").input(cross2).build();
  FileDataSink sink=new FileDataSink(DummyOutputFormat.class,OUT_FILE_1,""String_Node_Str"");
  sink.setInput(reduce3);
  Plan plan=new Plan(sink,""String_Node_Str"");
  plan.setDefaultParallelism(DEFAULT_PARALLELISM);
  OptimizedPlan oPlan=compile(plan);
  NepheleJobGraphGenerator jobGen=new NepheleJobGraphGenerator();
  jobGen.compileJobGraph(oPlan);
}",0.98812351543943
55199,"@Test public void testCompileConnectedComponents(){
  WorksetConnectedComponents cc=new WorksetConnectedComponents();
  Plan plan=cc.getPlan(String.valueOf(defaultParallelism),IN_FILE_1,IN_FILE_1,OUT_FILE_1,String.valueOf(100));
  OptimizedPlan op=compile(plan);
  NepheleJobGraphGenerator jgg=new NepheleJobGraphGenerator();
  jgg.compileJobGraph(op);
}","@Test public void testCompileConnectedComponents(){
  WorksetConnectedComponents cc=new WorksetConnectedComponents();
  Plan plan=cc.getPlan(String.valueOf(DEFAULT_PARALLELISM),IN_FILE_1,IN_FILE_1,OUT_FILE_1,String.valueOf(100));
  OptimizedPlan op=compile(plan);
  NepheleJobGraphGenerator jgg=new NepheleJobGraphGenerator();
  jgg.compileJobGraph(op);
}",0.9506346967559944
55200,"public void testCompileKMeansIteration2(){
  IterativeKMeans kmi=new IterativeKMeans();
  Plan plan=kmi.getPlan(String.valueOf(defaultParallelism),IN_FILE_1,IN_FILE_1,OUT_FILE_1,String.valueOf(20));
  setParameterToCross(plan,""String_Node_Str"",""String_Node_Str"");
  OptimizedPlan op=compile(plan);
  NepheleJobGraphGenerator jgg=new NepheleJobGraphGenerator();
  jgg.compileJobGraph(op);
}","public void testCompileKMeansIteration2(){
  IterativeKMeans kmi=new IterativeKMeans();
  Plan plan=kmi.getPlan(String.valueOf(DEFAULT_PARALLELISM),IN_FILE_1,IN_FILE_1,OUT_FILE_1,String.valueOf(20));
  setParameterToCross(plan,""String_Node_Str"",""String_Node_Str"");
  OptimizedPlan op=compile(plan);
  NepheleJobGraphGenerator jgg=new NepheleJobGraphGenerator();
  jgg.compileJobGraph(op);
}",0.9525032092426188
55201,"public void testCompileKMeansIteration1(){
  IterativeKMeans kmi=new IterativeKMeans();
  Plan plan=kmi.getPlan(String.valueOf(defaultParallelism),IN_FILE_1,IN_FILE_1,OUT_FILE_1,String.valueOf(20));
  setParameterToCross(plan,""String_Node_Str"",""String_Node_Str"");
  OptimizedPlan op=compile(plan);
  NepheleJobGraphGenerator jgg=new NepheleJobGraphGenerator();
  jgg.compileJobGraph(op);
}","public void testCompileKMeansIteration1(){
  IterativeKMeans kmi=new IterativeKMeans();
  Plan plan=kmi.getPlan(String.valueOf(DEFAULT_PARALLELISM),IN_FILE_1,IN_FILE_1,OUT_FILE_1,String.valueOf(20));
  setParameterToCross(plan,""String_Node_Str"",""String_Node_Str"");
  OptimizedPlan op=compile(plan);
  NepheleJobGraphGenerator jgg=new NepheleJobGraphGenerator();
  jgg.compileJobGraph(op);
}",0.9525032092426188
55202,"/** 
 * Filters these properties by what can be preserved through the given output contract.
 * @param contract The output contract.
 * @return True, if any non-default value is preserved, false otherwise.
 */
public GlobalProperties filterByNodesConstantSet(OptimizerNode node,int input){
  if (this.ordering != null) {
    for (    int col : this.ordering.getInvolvedIndexes()) {
      if (!node.isFieldConstant(input,col)) {
        return new GlobalProperties();
      }
    }
  }
 else   if (this.partitioningFields != null) {
    for (    int colIndex : this.partitioningFields) {
      if (!node.isFieldConstant(input,colIndex)) {
        return new GlobalProperties();
      }
    }
  }
  return this;
}","/** 
 * Filters these properties by what can be preserved through the given output contract.
 * @param contract The output contract.
 * @return True, if any non-default value is preserved, false otherwise.
 */
public GlobalProperties filterByNodesConstantSet(OptimizerNode node,int input){
  if (this.ordering != null) {
    for (    int col : this.ordering.getInvolvedIndexes()) {
      if (!node.isFieldConstant(input,col)) {
        return new GlobalProperties();
      }
    }
  }
  if (this.partitioningFields != null) {
    for (    int colIndex : this.partitioningFields) {
      if (!node.isFieldConstant(input,colIndex)) {
        return new GlobalProperties();
      }
    }
  }
  if (this.uniqueFieldCombinations != null) {
    HashSet<FieldSet> newSet=new HashSet<FieldSet>();
    newSet.addAll(this.uniqueFieldCombinations);
    for (Iterator<FieldSet> combos=newSet.iterator(); combos.hasNext(); ) {
      FieldSet current=combos.next();
      for (      Integer field : current) {
        if (!node.isFieldConstant(input,field)) {
          combos.remove();
          break;
        }
      }
    }
    if (newSet.size() != this.uniqueFieldCombinations.size()) {
      GlobalProperties gp=clone();
      gp.uniqueFieldCombinations=newSet.isEmpty() ? null : newSet;
      return gp;
    }
  }
  return this;
}",0.6823992133726647
55203,"/** 
 * {@inheritDoc}
 */
@Override public int getMaximumNumberOfSubtasks(){
  if (!(this.format instanceof FileOutputFormat)) {
    return -1;
  }
  final String pathName=this.config.getStubParameter(FileOutputFormat.FILE_PARAMETER_KEY,null);
  final Path path;
  if (pathName == null) {
    return 0;
  }
  try {
    path=new Path(pathName);
  }
 catch (  Throwable t) {
    return 0;
  }
  try {
    final FileSystem fs=path.getFileSystem();
    try {
      final FileStatus f=fs.getFileStatus(path);
      if (f == null) {
        return 1;
      }
      if (f.isDir()) {
        return -1;
      }
 else {
        fs.delete(path,false);
        return -1;
      }
    }
 catch (    FileNotFoundException fnfex) {
      int dop=getTaskConfiguration().getInteger(DEGREE_OF_PARALLELISM_KEY,-1);
      if (dop == 1) {
        return 1;
      }
      fs.mkdirs(path);
      return -1;
    }
  }
 catch (  IOException e) {
    LOG.error(""String_Node_Str"",e);
    return 1;
  }
}","/** 
 * {@inheritDoc}
 */
@Override public int getMaximumNumberOfSubtasks(){
  if (!(this.format instanceof FileOutputFormat)) {
    return -1;
  }
  final String pathName=this.config.getStubParameter(FileOutputFormat.FILE_PARAMETER_KEY,null);
  final Path path;
  if (pathName == null) {
    return 0;
  }
  try {
    path=new Path(pathName);
  }
 catch (  Throwable t) {
    return 0;
  }
  try {
    final FileSystem fs=path.getFileSystem();
    try {
      final FileStatus f=fs.getFileStatus(path);
      if (f == null) {
        return 1;
      }
      if (f.isDir()) {
        return -1;
      }
 else {
        fs.delete(path,false);
        int dop=getTaskConfiguration().getInteger(DEGREE_OF_PARALLELISM_KEY,-1);
        if (dop == 1) {
          return 1;
        }
 else {
          fs.mkdirs(path);
          return -1;
        }
      }
    }
 catch (    FileNotFoundException fnfex) {
      int dop=getTaskConfiguration().getInteger(DEGREE_OF_PARALLELISM_KEY,-1);
      if (dop == 1) {
        return 1;
      }
      fs.mkdirs(path);
      return -1;
    }
  }
 catch (  IOException e) {
    LOG.error(""String_Node_Str"",e);
    return 1;
  }
}",0.8455056179775281
55204,"@Override public void close() throws IOException {
  this.stream.write(this.buffer,0,this.pos);
  super.close();
}","@Override public void close() throws IOException {
  if (this.stream != null) {
    this.stream.write(this.buffer,0,this.pos);
  }
  super.close();
}",0.8669201520912547
55205,"public <T extends Value>Class<? extends ConvergenceCriterion<T>> getConvergenceCriterion(){
  @SuppressWarnings(""String_Node_Str"") Class<? extends ConvergenceCriterion<T>> clazz=(Class<? extends ConvergenceCriterion<T>>)this.config.getClass(ITERATION_CONVERGENCE_CRITERION,null,ConvergenceCriterion.class);
  if (clazz == null) {
    throw new NullPointerException();
  }
  return clazz;
}","public <T extends Value>Class<? extends ConvergenceCriterion<T>> getConvergenceCriterion(){
  @SuppressWarnings(""String_Node_Str"") Class<? extends ConvergenceCriterion<T>> clazz=(Class<? extends ConvergenceCriterion<T>>)(Class<?>)this.config.getClass(ITERATION_CONVERGENCE_CRITERION,null,ConvergenceCriterion.class);
  if (clazz == null) {
    throw new NullPointerException();
  }
  return clazz;
}",0.9873096446700508
55206,"/** 
 * Unassigns a cloud instance from the job.
 * @param instance the cloud instance which will be unassigned
 * @return <code>true</code> if the given cloud instance has been assigned to the job, <code>false</code> otherwise
 */
public boolean unassignInstanceFromJob(final AbstractInstance instance){
synchronized (this.assignedInstances) {
    return (this.assignedInstances.remove(instance) != null);
  }
}","/** 
 * Unassigns a cloud instance from the job.
 * @param instance the cloud instance which will be unassigned
 * @return <code>true</code> if the given cloud instance has been assigned to the job, <code>false</code> otherwise
 */
public boolean unassignInstanceFromJob(final AbstractInstance instance){
synchronized (this.assignedInstances) {
    return (this.assignedInstances.remove(instance.getInstanceConnectionInfo()) != null);
  }
}",0.9671361502347418
55207,"/** 
 * Registers the given task with the byte buffered channel manager.
 * @param task the task to be registered
 * @param activeOutputChannels the set of output channels which are initially active
 * @param hasAlreadyBeenDeployed stores if the task has already been deployed before at least once
 * @throws InsufficientResourcesException thrown if the channel manager does not have enough memory buffers to safely run this task
 */
public void register(final Task task,final Set<ChannelID> activeOutputChannels,final boolean hasAlreadyBeenDeployed) throws InsufficientResourcesException {
  checkBufferAvailability(task);
  final Environment environment=task.getEnvironment();
  final TaskContext taskContext=task.createTaskContext(this,this.localBufferPoolOwner.remove(task.getVertexID()));
  final Set<GateID> outputGateIDs=environment.getOutputGateIDs();
  for (final Iterator<GateID> gateIt=outputGateIDs.iterator(); gateIt.hasNext(); ) {
    final GateID gateID=gateIt.next();
    final OutputGateContext outputGateContext=taskContext.createOutputGateContext(gateID);
    final Set<ChannelID> outputChannelIDs=environment.getOutputChannelIDsOfGate(gateID);
    for (final Iterator<ChannelID> channelIt=outputChannelIDs.iterator(); channelIt.hasNext(); ) {
      final ChannelID channelID=channelIt.next();
      final OutputChannelContext previousContext=(OutputChannelContext)this.registeredChannels.get(channelID);
      final boolean isActive=true;
      final OutputChannelContext outputChannelContext=outputGateContext.createOutputChannelContext(channelID,previousContext,isActive,this.mergeSpilledBuffers);
      if (outputChannelContext.getType() == ChannelType.INMEMORY && !hasAlreadyBeenDeployed) {
        addReceiverListHint(outputChannelContext);
      }
      if (LOG.isDebugEnabled())       LOG.debug(""String_Node_Str"" + outputChannelContext.getChannelID() + ""String_Node_Str""+ (isActive ? ""String_Node_Str"" : ""String_Node_Str"")+ ""String_Node_Str"");
      this.registeredChannels.put(outputChannelContext.getChannelID(),outputChannelContext);
    }
  }
  final Set<GateID> inputGateIDs=environment.getInputGateIDs();
  for (final Iterator<GateID> gateIt=inputGateIDs.iterator(); gateIt.hasNext(); ) {
    final GateID gateID=gateIt.next();
    final InputGateContext inputGateContext=taskContext.createInputGateContext(gateID);
    final Set<ChannelID> inputChannelIDs=environment.getInputChannelIDsOfGate(gateID);
    for (final Iterator<ChannelID> channelIt=inputChannelIDs.iterator(); channelIt.hasNext(); ) {
      final ChannelID channelID=channelIt.next();
      final InputChannelContext previousContext=(InputChannelContext)this.registeredChannels.get(channelID);
      final InputChannelContext inputChannelContext=inputGateContext.createInputChannelContext(channelID,previousContext);
      if (inputChannelContext.getType() == ChannelType.INMEMORY && !hasAlreadyBeenDeployed) {
        addReceiverListHint(inputChannelContext);
      }
      this.registeredChannels.put(inputChannelContext.getChannelID(),inputChannelContext);
    }
    final LocalBufferPoolOwner bufferPoolOwner=inputGateContext.getLocalBufferPoolOwner();
    if (bufferPoolOwner != null) {
      this.localBufferPoolOwner.put(inputGateContext.getGateID(),bufferPoolOwner);
    }
  }
  this.localBufferPoolOwner.put(task.getVertexID(),taskContext);
  redistributeGlobalBuffers();
}","/** 
 * Registers the given task with the byte buffered channel manager.
 * @param task the task to be registered
 * @param activeOutputChannels the set of output channels which are initially active
 * @param hasAlreadyBeenDeployed stores if the task has already been deployed before at least once
 * @throws InsufficientResourcesException thrown if the channel manager does not have enough memory buffers to safely run this task
 */
public void register(final Task task,final Set<ChannelID> activeOutputChannels,final boolean hasAlreadyBeenDeployed) throws InsufficientResourcesException {
  checkBufferAvailability(task);
  final Environment environment=task.getEnvironment();
  final TaskContext taskContext=task.createTaskContext(this,this.localBufferPoolOwner.remove(task.getVertexID()));
  final Set<GateID> outputGateIDs=environment.getOutputGateIDs();
  for (final Iterator<GateID> gateIt=outputGateIDs.iterator(); gateIt.hasNext(); ) {
    final GateID gateID=gateIt.next();
    final OutputGateContext outputGateContext=taskContext.createOutputGateContext(gateID);
    final Set<ChannelID> outputChannelIDs=environment.getOutputChannelIDsOfGate(gateID);
    for (final Iterator<ChannelID> channelIt=outputChannelIDs.iterator(); channelIt.hasNext(); ) {
      final ChannelID channelID=channelIt.next();
      final OutputChannelContext previousContext=(OutputChannelContext)this.registeredChannels.get(channelID);
      final boolean isActive=true;
      final OutputChannelContext outputChannelContext=outputGateContext.createOutputChannelContext(channelID,previousContext,isActive,this.mergeSpilledBuffers);
      if (outputChannelContext.getType() == ChannelType.INMEMORY && !hasAlreadyBeenDeployed) {
        addReceiverListHint(outputChannelContext);
      }
      if (LOG.isDebugEnabled()) {
        LOG.debug(""String_Node_Str"" + outputChannelContext.getChannelID() + ""String_Node_Str""+ (isActive ? ""String_Node_Str"" : ""String_Node_Str"")+ ""String_Node_Str"");
      }
      this.registeredChannels.put(outputChannelContext.getChannelID(),outputChannelContext);
    }
  }
  final Set<GateID> inputGateIDs=environment.getInputGateIDs();
  for (final Iterator<GateID> gateIt=inputGateIDs.iterator(); gateIt.hasNext(); ) {
    final GateID gateID=gateIt.next();
    final InputGateContext inputGateContext=taskContext.createInputGateContext(gateID);
    final Set<ChannelID> inputChannelIDs=environment.getInputChannelIDsOfGate(gateID);
    for (final Iterator<ChannelID> channelIt=inputChannelIDs.iterator(); channelIt.hasNext(); ) {
      final ChannelID channelID=channelIt.next();
      final InputChannelContext previousContext=(InputChannelContext)this.registeredChannels.get(channelID);
      final InputChannelContext inputChannelContext=inputGateContext.createInputChannelContext(channelID,previousContext);
      if (inputChannelContext.getType() == ChannelType.INMEMORY && !hasAlreadyBeenDeployed) {
        addReceiverListHint(inputChannelContext);
      }
      this.registeredChannels.put(inputChannelContext.getChannelID(),inputChannelContext);
    }
    final LocalBufferPoolOwner bufferPoolOwner=inputGateContext.getLocalBufferPoolOwner();
    if (bufferPoolOwner != null) {
      this.localBufferPoolOwner.put(inputGateContext.getGateID(),bufferPoolOwner);
    }
  }
  this.localBufferPoolOwner.put(task.getVertexID(),taskContext);
  redistributeGlobalBuffers();
}",0.9982285208148804
55208,"private boolean transferLibraries(SopremoPlan plan,ProgressListener progressListener){
  final JobID dummyKey=JobID.generate();
  List<String> requiredLibraries=new ArrayList<String>(plan.getRequiredPackages());
  try {
    progressListener.progressUpdate(ExecutionState.SETUP,""String_Node_Str"");
    List<Path> libraryPaths=new ArrayList<Path>();
    for (    String library : requiredLibraries) {
      final Input dis=new Input(new FileInputStream(library));
      final Path libraryPath=new Path(library);
      LibraryCacheManager.addLibrary(dummyKey,libraryPath,(int)new File(library).length(),dis);
      dis.close();
      libraryPaths.add(libraryPath);
    }
    LibraryCacheManager.register(dummyKey,libraryPaths.toArray(new Path[libraryPaths.size()]));
    LibraryCacheProfileRequest request=new LibraryCacheProfileRequest();
    final String[] internalJarNames=LibraryCacheManager.getRequiredJarFiles(dummyKey);
    request.setRequiredLibraries(internalJarNames);
    LibraryCacheProfileResponse response=null;
    response=this.executor.getLibraryCacheProfile(request);
    for (int k=0; k < internalJarNames.length; k++)     if (!response.isCached(k)) {
      final String library=internalJarNames[k];
      progressListener.progressUpdate(ExecutionState.SETUP,""String_Node_Str"" + requiredLibraries.get(k));
      LibraryCacheUpdate update=new LibraryCacheUpdate(library);
      this.executor.updateLibraryCache(update);
    }
    for (int index=0; index < internalJarNames.length; index++)     requiredLibraries.set(index,internalJarNames[index]);
    plan.setRequiredPackages(requiredLibraries);
    return true;
  }
 catch (  IOException e) {
    dealWithError(progressListener,e,""String_Node_Str"");
    return false;
  }
 finally {
    try {
      LibraryCacheManager.unregister(dummyKey);
    }
 catch (    IOException e) {
    }
  }
}","private boolean transferLibraries(SopremoPlan plan,ProgressListener progressListener){
  final JobID dummyKey=JobID.generate();
  List<String> requiredLibraries=new ArrayList<String>(plan.getRequiredPackages());
  try {
    progressListener.progressUpdate(ExecutionState.SETUP,""String_Node_Str"");
    List<Path> libraryPaths=new ArrayList<Path>();
    for (    String library : requiredLibraries) {
      final Input dis=new Input(new FileInputStream(library));
      final Path libraryPath=new Path(library);
      LibraryCacheManager.addLibrary(dummyKey,libraryPath,(int)new File(library).length(),dis);
      dis.close();
      libraryPaths.add(libraryPath);
    }
    LibraryCacheManager.register(dummyKey,libraryPaths.toArray(new Path[libraryPaths.size()]));
    LibraryCacheProfileRequest request=new LibraryCacheProfileRequest();
    final String[] internalJarNames=LibraryCacheManager.getRequiredJarFiles(dummyKey);
    request.setRequiredLibraries(internalJarNames);
    LibraryCacheProfileResponse response=null;
    response=this.executor.getLibraryCacheProfile(request);
    for (int k=0; k < internalJarNames.length; k++)     if (!response.isCached(k)) {
      final String library=internalJarNames[k];
      progressListener.progressUpdate(ExecutionState.SETUP,""String_Node_Str"" + requiredLibraries.get(k));
      LibraryCacheUpdate update=new LibraryCacheUpdate(library);
      this.executor.updateLibraryCache(update);
    }
    for (int index=0; index < internalJarNames.length; index++)     requiredLibraries.set(index,internalJarNames[index]);
    plan.setRequiredPackages(requiredLibraries);
    return true;
  }
 catch (  Exception e) {
    dealWithError(progressListener,e,""String_Node_Str"");
    return false;
  }
 finally {
    try {
      LibraryCacheManager.unregister(dummyKey);
    }
 catch (    IOException e) {
    }
  }
}",0.9017808958445764
55209,"/** 
 * Queries the task manager about the cache status of the libraries stated in the   {@link LibraryCacheProfileRequest}object.
 * @param request a  {@link LibraryCacheProfileRequest} containing a list of libraries whose cache status is to be determined
 * @return a {@link LibraryCacheProfileResponse} containing the cache status for each library included in therequest
 * @throws IOException thrown if an error occurs during this remote procedure call
 */
LibraryCacheProfileResponse getLibraryCacheProfile(LibraryCacheProfileRequest request) throws IOException ;","/** 
 * Queries the task manager about the cache status of the libraries stated in the   {@link LibraryCacheProfileRequest}object.
 * @param request a  {@link LibraryCacheProfileRequest} containing a list of libraries whose cache status is to be determined
 * @return a {@link LibraryCacheProfileResponse} containing the cache status for each library included in therequest
 * @throws IOException thrown if an error occurs during this remote procedure call
 */
LibraryCacheProfileResponse getLibraryCacheProfile(LibraryCacheProfileRequest request) throws IOException, InterruptedException ;",0.9810017271157168
55210,"/** 
 * Updates the task manager's library cache.
 * @param update a  {@link LibraryCacheUpdate} object used to transmit the library data
 * @throws IOException thrown if an error occurs during this remote procedure call
 */
void updateLibraryCache(LibraryCacheUpdate update) throws IOException ;","/** 
 * Updates the task manager's library cache.
 * @param update a  {@link LibraryCacheUpdate} object used to transmit the library data
 * @throws IOException thrown if an error occurs during this remote procedure call
 */
void updateLibraryCache(LibraryCacheUpdate update) throws IOException, InterruptedException ;",0.9641693811074918
55211,"/** 
 * Queries the state of the given job.
 * @param jobId the job id
 * @return the {@link ExecutionResponse} with the state
 */
public ExecutionResponse getState(SopremoID jobId);","/** 
 * Queries the state of the given job.
 * @param jobId the job id
 * @return the {@link ExecutionResponse} with the state
 */
ExecutionResponse getState(SopremoID jobId) throws IOException, InterruptedException ;",0.8771929824561403
55212,"/** 
 * Executes the query specified in the   {@link ExecutionRequest}.
 * @param request the request with the query
 * @return the {@link ExecutionResponse}
 */
public ExecutionResponse execute(ExecutionRequest request);","/** 
 * Executes the query specified in the   {@link ExecutionRequest}.
 * @param request the request with the query
 * @return the {@link ExecutionResponse}
 */
ExecutionResponse execute(ExecutionRequest request) throws IOException, InterruptedException ;",0.8972746331236897
55213,"private void startServer() throws IOException {
  InetSocketAddress rpcServerAddress=getServerAddress();
  this.rpcService=new RPCService(rpcServerAddress.getPort(),null);
}","private void startServer() throws IOException {
  InetSocketAddress rpcServerAddress=getServerAddress();
  this.rpcService=new RPCService(rpcServerAddress.getPort(),2,null);
  this.rpcService.setProtocolCallbackHandler(SopremoExecutionProtocol.class,this);
}",0.802784222737819
55214,"@Test public void testSuccessfulExecution() throws IOException {
  final SopremoPlan plan=createPlan(""String_Node_Str"");
  ExecutionResponse response=this.testServer.execute(new ExecutionRequest(plan));
  response=waitForStateToFinish(response,ExecutionState.ENQUEUED);
  response=waitForStateToFinish(response,ExecutionState.RUNNING);
  Assert.assertSame(ExecutionState.FINISHED,response.getState());
  Assert.assertSame(""String_Node_Str"",response.getDetails());
  this.testServer.checkContentsOf(""String_Node_Str"",JsonUtil.createObjectNode(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",32500,""String_Node_Str"",false),JsonUtil.createObjectNode(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",72000,""String_Node_Str"",true));
}","@Test public void testSuccessfulExecution() throws IOException, InterruptedException {
  final SopremoPlan plan=createPlan(""String_Node_Str"");
  ExecutionResponse response=this.testServer.execute(new ExecutionRequest(plan));
  response=waitForStateToFinish(response,ExecutionState.ENQUEUED);
  response=waitForStateToFinish(response,ExecutionState.RUNNING);
  Assert.assertSame(ExecutionState.FINISHED,response.getState());
  Assert.assertSame(""String_Node_Str"",response.getDetails());
  this.testServer.checkContentsOf(""String_Node_Str"",JsonUtil.createObjectNode(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",32500,""String_Node_Str"",false),JsonUtil.createObjectNode(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",72000,""String_Node_Str"",true));
}",0.985352862849534
55215,"@Test public void testFailIfInvalidPlan(){
  final SopremoPlan plan=new SopremoPlan();
  plan.setSinks(new Sink(""String_Node_Str""));
  ExecutionResponse response=this.testServer.execute(new ExecutionRequest(plan));
  response=waitForStateToFinish(response,ExecutionState.ENQUEUED);
  Assert.assertSame(ExecutionState.ERROR,response.getState());
  Assert.assertNotSame(""String_Node_Str"",response.getDetails());
}","@Test public void testFailIfInvalidPlan() throws IOException, InterruptedException {
  final SopremoPlan plan=new SopremoPlan();
  plan.setSinks(new Sink(""String_Node_Str""));
  ExecutionResponse response=this.testServer.execute(new ExecutionRequest(plan));
  response=waitForStateToFinish(response,ExecutionState.ENQUEUED);
  Assert.assertSame(ExecutionState.ERROR,response.getState());
  Assert.assertNotSame(""String_Node_Str"",response.getDetails());
}",0.9513888888888888
55216,"private ExecutionResponse waitForStateToFinish(ExecutionResponse response,ExecutionState status){
  return SopremoTestServer.waitForStateToFinish(this.testServer,response,status);
}","private ExecutionResponse waitForStateToFinish(ExecutionResponse response,ExecutionState status) throws IOException, InterruptedException {
  return SopremoTestServer.waitForStateToFinish(this.testServer,response,status);
}",0.8960396039603961
55217,"@Test public void testFailIfSubmissionFails() throws IOException {
  this.testServer.delete(""String_Node_Str"",true);
  final SopremoPlan plan=createPlan(""String_Node_Str"");
  ExecutionResponse response=this.testServer.execute(new ExecutionRequest(plan));
  response=waitForStateToFinish(response,ExecutionState.ENQUEUED);
  response=waitForStateToFinish(response,ExecutionState.RUNNING);
  Assert.assertSame(ExecutionState.ERROR,response.getState());
  Assert.assertNotSame(""String_Node_Str"",response.getDetails());
}","@Test public void testFailIfSubmissionFails() throws IOException, InterruptedException {
  this.testServer.delete(""String_Node_Str"",true);
  final SopremoPlan plan=createPlan(""String_Node_Str"");
  ExecutionResponse response=this.testServer.execute(new ExecutionRequest(plan));
  response=waitForStateToFinish(response,ExecutionState.ENQUEUED);
  response=waitForStateToFinish(response,ExecutionState.RUNNING);
  Assert.assertSame(ExecutionState.ERROR,response.getState());
  Assert.assertNotSame(""String_Node_Str"",response.getDetails());
}",0.9791666666666666
55218,"@Test public void testMultipleSuccessfulExecutions() throws IOException {
  ExecutionResponse[] responses=new ExecutionResponse[3];
  for (int index=0; index < responses.length; index++) {
    final SopremoPlan plan=createPlan(""String_Node_Str"" + index + ""String_Node_Str"");
    responses[index]=this.testServer.execute(new ExecutionRequest(plan));
  }
  for (int index=0; index < responses.length; index++) {
    responses[index]=waitForStateToFinish(responses[index],ExecutionState.ENQUEUED);
    responses[index]=waitForStateToFinish(responses[index],ExecutionState.RUNNING);
    Assert.assertSame(ExecutionState.FINISHED,responses[index].getState());
    Assert.assertSame(""String_Node_Str"",responses[index].getDetails());
    this.testServer.checkContentsOf(""String_Node_Str"" + index + ""String_Node_Str"",JsonUtil.createObjectNode(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",32500,""String_Node_Str"",false),JsonUtil.createObjectNode(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",72000,""String_Node_Str"",true));
  }
}","@Test public void testMultipleSuccessfulExecutions() throws IOException, InterruptedException {
  ExecutionResponse[] responses=new ExecutionResponse[3];
  for (int index=0; index < responses.length; index++) {
    final SopremoPlan plan=createPlan(""String_Node_Str"" + index + ""String_Node_Str"");
    responses[index]=this.testServer.execute(new ExecutionRequest(plan));
  }
  for (int index=0; index < responses.length; index++) {
    responses[index]=waitForStateToFinish(responses[index],ExecutionState.ENQUEUED);
    responses[index]=waitForStateToFinish(responses[index],ExecutionState.RUNNING);
    Assert.assertSame(ExecutionState.FINISHED,responses[index].getState());
    Assert.assertSame(""String_Node_Str"",responses[index].getDetails());
    this.testServer.checkContentsOf(""String_Node_Str"" + index + ""String_Node_Str"",JsonUtil.createObjectNode(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",32500,""String_Node_Str"",false),JsonUtil.createObjectNode(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",72000,""String_Node_Str"",true));
  }
}",0.9895038167938932
55219,"@Test public void testFailIfRuntimeException(){
  final SopremoPlan plan=createPlan(""String_Node_Str"");
  for (  Operator<?> op : plan.getContainedOperators())   if (op instanceof Selection)   ((Selection)op).setCondition(new UnaryExpression(new UnevaluableExpression(""String_Node_Str"")));
  ExecutionResponse response=this.testServer.execute(new ExecutionRequest(plan));
  response=waitForStateToFinish(response,ExecutionState.ENQUEUED);
  response=waitForStateToFinish(response,ExecutionState.RUNNING);
  Assert.assertSame(ExecutionState.ERROR,response.getState());
  Assert.assertNotSame(""String_Node_Str"",response.getDetails());
}","@Test public void testFailIfRuntimeException() throws IOException, InterruptedException {
  final SopremoPlan plan=createPlan(""String_Node_Str"");
  for (  Operator<?> op : plan.getContainedOperators())   if (op instanceof Selection)   ((Selection)op).setCondition(new UnaryExpression(new UnevaluableExpression(""String_Node_Str"")));
  ExecutionResponse response=this.testServer.execute(new ExecutionRequest(plan));
  response=waitForStateToFinish(response,ExecutionState.ENQUEUED);
  response=waitForStateToFinish(response,ExecutionState.RUNNING);
  Assert.assertSame(ExecutionState.ERROR,response.getState());
  Assert.assertNotSame(""String_Node_Str"",response.getDetails());
}",0.96793893129771
55220,"private ExecutionResponse waitForStateToFinish(ExecutionResponse response,ExecutionState status){
  return SopremoTestServer.waitForStateToFinish(this.server,response,status);
}","private ExecutionResponse waitForStateToFinish(ExecutionResponse response,ExecutionState status){
  try {
    return SopremoTestServer.waitForStateToFinish(this.server,response,status);
  }
 catch (  Exception e) {
    e.printStackTrace();
    return null;
  }
}",0.806378132118451
55221,"public static ExecutionResponse waitForStateToFinish(SopremoExecutionProtocol server,ExecutionResponse response,ExecutionState status){
  for (int waits=0; response.getState() == status && waits < 1000; waits++) {
    try {
      Thread.sleep(100);
    }
 catch (    InterruptedException e) {
    }
    response=server.getState(response.getJobId());
  }
  return response;
}","public static ExecutionResponse waitForStateToFinish(SopremoExecutionProtocol server,ExecutionResponse response,ExecutionState status) throws IOException, InterruptedException {
  for (int waits=0; response.getState() == status && waits < 1000; waits++) {
    Thread.sleep(100);
    response=server.getState(response.getJobId());
  }
  return response;
}",0.8571428571428571
55222,"@Override public ExecutionResponse execute(ExecutionRequest request){
  correctPathsOfPlan(request.getQuery());
  return this.executor.execute(request);
}","@Override public ExecutionResponse execute(ExecutionRequest request) throws IOException, InterruptedException {
  correctPathsOfPlan(request.getQuery());
  return this.executor.execute(request);
}",0.88
55223,"@Override public ExecutionResponse getState(SopremoID jobId){
  return this.executor.getState(jobId);
}","@Override public ExecutionResponse getState(SopremoID jobId) throws IOException, InterruptedException {
  return this.executor.getState(jobId);
}",0.8306451612903226
55224,"/** 
 * Tries to read the AWS access key and the AWS secret key from the environments variables. If accessing these keys fails, all tests will be skipped and marked as successful.
 */
@Before public void initKeys(){
  final String accessKey=System.getenv(""String_Node_Str"");
  final String secretKey=System.getenv(""String_Node_Str"");
  final Configuration conf=new Configuration();
  conf.setString(S3FileSystem.S3_ACCESS_KEY_KEY,accessKey);
  conf.setString(S3FileSystem.S3_SECRET_KEY_KEY,secretKey);
  GlobalConfiguration.includeConfiguration(conf);
}","/** 
 * Tries to read the AWS access key and the AWS secret key from the environments variables. If accessing these keys fails, all tests will be skipped and marked as successful.
 */
@Before public void initKeys(){
  final String accessKey=System.getenv(""String_Node_Str"");
  final String secretKey=System.getenv(""String_Node_Str"");
  final Configuration conf=new Configuration();
  if (accessKey != null) {
    conf.setString(S3FileSystem.S3_ACCESS_KEY_KEY,accessKey);
  }
  if (secretKey != null) {
    conf.setString(S3FileSystem.S3_SECRET_KEY_KEY,secretKey);
  }
  GlobalConfiguration.includeConfiguration(conf);
}",0.9436860068259386
55225,"/** 
 * Returns a list of types frequently used by the RPC protocols of this package and its parent packages.
 * @return a list of types frequently used by the RPC protocols of this package
 */
public static List<Class<?>> getRPCTypesToRegister(){
  final List<Class<?>> types=ManagementTypeUtils.getRPCTypesToRegister();
  types.add(AbstractTaskResult.ReturnCode.class);
  types.add(ChannelDeploymentDescriptor.class);
  types.add(CheckpointState.class);
  types.add(ConnectionInfoLookupResponse.class);
  types.add(ConnectionInfoLookupResponse.ReturnCode.class);
  types.add(ExecutionVertexID.class);
  types.add(FileInputSplit.class);
  types.add(GateDeploymentDescriptor.class);
  types.add(HashSet.class);
  types.add(Inet4Address.class);
  types.add(InetSocketAddress.class);
  types.add(InputSplitWrapper.class);
  types.add(InstanceConnectionInfo.class);
  types.add(LocalInstance.class);
  types.add(RemoteReceiver.class);
  types.add(TaskCancelResult.class);
  types.add(TaskCheckpointState.class);
  types.add(TaskDeploymentDescriptor.class);
  types.add(TaskExecutionState.class);
  types.add(TaskSubmissionResult.class);
  return types;
}","/** 
 * Returns a list of types frequently used by the RPC protocols of this package and its parent packages.
 * @return a list of types frequently used by the RPC protocols of this package
 */
public static List<Class<?>> getRPCTypesToRegister(){
  final List<Class<?>> types=ManagementTypeUtils.getRPCTypesToRegister();
  types.add(AbstractTaskResult.ReturnCode.class);
  types.add(ChannelDeploymentDescriptor.class);
  types.add(CheckpointState.class);
  types.add(ConnectionInfoLookupResponse.class);
  types.add(ConnectionInfoLookupResponse.ReturnCode.class);
  types.add(ExecutionVertexID.class);
  types.add(FileInputSplit.class);
  types.add(GateDeploymentDescriptor.class);
  types.add(GenericInputSplit.class);
  types.add(HashSet.class);
  types.add(Inet4Address.class);
  types.add(InetSocketAddress.class);
  types.add(InputSplitWrapper.class);
  types.add(InstanceConnectionInfo.class);
  types.add(LocalInstance.class);
  types.add(RemoteReceiver.class);
  types.add(TaskCancelResult.class);
  types.add(TaskCheckpointState.class);
  types.add(TaskDeploymentDescriptor.class);
  types.add(TaskExecutionState.class);
  types.add(TaskSubmissionResult.class);
  return types;
}",0.9837606837606836
55226,"private static void addBasicRPCTypes(final List<Class<?>> typesToRegister){
  typesToRegister.add(ArrayList.class);
  typesToRegister.add(AssertionError.class);
  typesToRegister.add(boolean[].class);
  typesToRegister.add(Class.class);
  typesToRegister.add(Class[].class);
  typesToRegister.add(IllegalArgumentException.class);
  typesToRegister.add(KryoException.class);
  typesToRegister.add(List.class);
  typesToRegister.add(Object[].class);
  typesToRegister.add(RPCEnvelope.class);
  typesToRegister.add(RPCRequest.class);
  typesToRegister.add(RPCReturnValue.class);
  typesToRegister.add(RPCCleanup.class);
  typesToRegister.add(RPCThrowable.class);
  typesToRegister.add(StackTraceElement[].class);
  typesToRegister.add(String[].class);
  typesToRegister.add(StringBuffer.class);
}","private static void addBasicRPCTypes(final List<Class<?>> typesToRegister){
  typesToRegister.add(ArrayList.class);
  typesToRegister.add(AssertionError.class);
  typesToRegister.add(boolean[].class);
  typesToRegister.add(Class.class);
  typesToRegister.add(Class[].class);
  typesToRegister.add(IllegalArgumentException.class);
  typesToRegister.add(InterruptedException.class);
  typesToRegister.add(IOException.class);
  typesToRegister.add(KryoException.class);
  typesToRegister.add(List.class);
  typesToRegister.add(Object[].class);
  typesToRegister.add(RPCEnvelope.class);
  typesToRegister.add(RPCRequest.class);
  typesToRegister.add(RPCReturnValue.class);
  typesToRegister.add(RPCCleanup.class);
  typesToRegister.add(RPCThrowable.class);
  typesToRegister.add(StackTraceElement.class);
  typesToRegister.add(StackTraceElement[].class);
  typesToRegister.add(String[].class);
  typesToRegister.add(StringBuffer.class);
}",0.918355529820498
55227,"private void processIncomingRPCRequest(final InetSocketAddress remoteSocketAddress,final RPCRequest rpcRequest){
  final Integer messageID=Integer.valueOf(rpcRequest.getMessageID());
  if (this.requestsBeingProcessed.putIfAbsent(messageID,rpcRequest) != null) {
    Log.debug(""String_Node_Str"" + rpcRequest.getMessageID() + ""String_Node_Str"");
    return;
  }
  final CachedResponse cachedResponse=this.cachedResponses.get(messageID);
  if (cachedResponse != null) {
    try {
      sendPackets(cachedResponse.packets);
    }
 catch (    IOException e) {
      Log.error(""String_Node_Str"",e);
    }
 finally {
      this.requestsBeingProcessed.remove(messageID);
    }
    return;
  }
  final RPCProtocol callbackHandler=callbackHandlers.get(rpcRequest.getInterfaceName());
  if (callbackHandler == null) {
    Log.error(""String_Node_Str"" + rpcRequest.getInterfaceName());
    this.requestsBeingProcessed.remove(messageID);
    return;
  }
  try {
    final Method method=callbackHandler.getClass().getMethod(rpcRequest.getMethodName(),rpcRequest.getParameterTypes());
    RPCResponse rpcResponse=null;
    try {
      final Object retVal=method.invoke(callbackHandler,rpcRequest.getArgs());
      rpcResponse=new RPCReturnValue(rpcRequest.getMessageID(),retVal);
    }
 catch (    InvocationTargetException ite) {
      rpcResponse=new RPCThrowable(rpcRequest.getMessageID(),ite.getTargetException());
    }
    final DatagramPacket[] packets=messageToPackets(remoteSocketAddress,rpcResponse);
    cachedResponses.put(messageID,new CachedResponse(System.currentTimeMillis(),packets));
    sendPackets(packets);
  }
 catch (  Exception e) {
    Log.error(""String_Node_Str"",e);
  }
 finally {
    this.requestsBeingProcessed.remove(messageID);
  }
}","private void processIncomingRPCRequest(final InetSocketAddress remoteSocketAddress,final RPCRequest rpcRequest){
  final Integer messageID=Integer.valueOf(rpcRequest.getMessageID());
  if (this.requestsBeingProcessed.putIfAbsent(messageID,rpcRequest) != null) {
    Log.debug(""String_Node_Str"" + rpcRequest.getMessageID() + ""String_Node_Str"");
    return;
  }
  final CachedResponse cachedResponse=this.cachedResponses.get(messageID);
  if (cachedResponse != null) {
    try {
      sendPackets(cachedResponse.packets);
    }
 catch (    IOException e) {
      Log.error(""String_Node_Str"",e);
    }
 finally {
      this.requestsBeingProcessed.remove(messageID);
    }
    return;
  }
  final RPCProtocol callbackHandler=callbackHandlers.get(rpcRequest.getInterfaceName());
  if (callbackHandler == null) {
    Log.error(""String_Node_Str"" + rpcRequest.getInterfaceName());
    this.requestsBeingProcessed.remove(messageID);
    return;
  }
  try {
    final Method method=callbackHandler.getClass().getMethod(rpcRequest.getMethodName(),rpcRequest.getParameterTypes());
    RPCResponse rpcResponse=null;
    try {
      final Object retVal=method.invoke(callbackHandler,rpcRequest.getArgs());
      rpcResponse=new RPCReturnValue(rpcRequest.getMessageID(),retVal);
    }
 catch (    InvocationTargetException ite) {
      Throwable targetException=ite.getTargetException();
      targetException.getStackTrace();
      if (!isThrowableRegistered(targetException.getClass())) {
        targetException=wrapInIOException(rpcRequest,targetException);
      }
      rpcResponse=new RPCThrowable(rpcRequest.getMessageID(),targetException);
    }
    final DatagramPacket[] packets=messageToPackets(remoteSocketAddress,rpcResponse);
    cachedResponses.put(messageID,new CachedResponse(System.currentTimeMillis(),packets));
    sendPackets(packets);
  }
 catch (  Exception e) {
    Log.error(""String_Node_Str"",e);
  }
 finally {
    this.requestsBeingProcessed.remove(messageID);
  }
}",0.932653608800644
55228,"/** 
 * {@inheritDoc}
 */
@Override protected Kryo initialValue(){
  final Kryo kryo=new Kryo();
  if (kryoTypesToRegister != null) {
    kryo.setAutoReset(false);
    kryo.setRegistrationRequired(true);
    kryo.setReferences(true);
    for (    final Class<?> kryoType : kryoTypesToRegister) {
      kryo.register(kryoType);
    }
  }
  return kryo;
}","/** 
 * {@inheritDoc}
 */
@Override protected Kryo initialValue(){
  final Kryo kryo=new Kryo();
  if (kryoTypesToRegister != null) {
    kryo.setAutoReset(false);
    kryo.setRegistrationRequired(true);
    kryo.setReferences(true);
    kryo.addDefaultSerializer(StackTraceElement.class,new StackTraceElementSerializer());
    for (    final Class<?> kryoType : kryoTypesToRegister) {
      kryo.register(kryoType);
    }
  }
  return kryo;
}",0.8869346733668342
55229,"@Override public int testMethod(final boolean par1,final int par2,final List<String> par3){
  if (par1) {
    assertEquals(this.counter.getAndIncrement(),par2);
  }
  assertEquals(NUMBER_OF_TEST_STRINGS,par3.size());
  for (int i=0; i < NUMBER_OF_TEST_STRINGS; ++i) {
    assertEquals(constructTestString(i),par3.get(i));
  }
  if (!this.processedRequestsSet.add(Integer.valueOf(par2))) {
    fail(""String_Node_Str"" + par2 + ""String_Node_Str"");
  }
  return par2;
}","/** 
 * {@inheritDoc}
 */
@Override public int testMethod(final boolean par1,final int par2,final List<String> par3){
  if (par1) {
    assertEquals(this.counter.getAndIncrement(),par2);
  }
  assertEquals(NUMBER_OF_TEST_STRINGS,par3.size());
  for (int i=0; i < NUMBER_OF_TEST_STRINGS; ++i) {
    assertEquals(constructTestString(i),par3.get(i));
  }
  if (!this.processedRequestsSet.add(Integer.valueOf(par2))) {
    fail(""String_Node_Str"" + par2 + ""String_Node_Str"");
  }
  return par2;
}",0.9728033472803348
55230,"/** 
 * Registers the   {@link ExecutionStateListener} object for this vertex. This objectwill be notified about particular events during the vertex's lifetime.
 * @param executionListener the object to be notified about particular events during the vertex's lifetime
 */
public void registerExecutionStateListener(final ExecutionStateListener executionStateListener){
  final Integer priority=Integer.valueOf(executionStateListener.getPriority());
  if (priority.intValue() < 0) {
    LOG.error(""String_Node_Str"" + executionStateListener.getClass() + ""String_Node_Str"");
    return;
  }
  final ExecutionStateListener previousValue=this.executionStateListeners.putIfAbsent(priority,executionStateListener);
  if (previousValue != null) {
    LOG.error(""String_Node_Str"" + executionStateListener.getClass() + ""String_Node_Str""+ priority.intValue()+ ""String_Node_Str"");
  }
}","/** 
 * Registers the   {@link ExecutionStateListener} object for this vertex. This objectwill be notified about particular events during the vertex's lifetime.
 * @param executionStateListener the object to be notified about particular events during the vertex's lifetime
 */
public void registerExecutionStateListener(final ExecutionStateListener executionStateListener){
  final Integer priority=Integer.valueOf(executionStateListener.getPriority());
  if (priority.intValue() < 0) {
    LOG.error(""String_Node_Str"" + executionStateListener.getClass() + ""String_Node_Str"");
    return;
  }
  final ExecutionStateListener previousValue=this.executionStateListeners.putIfAbsent(priority,executionStateListener);
  if (previousValue != null) {
    LOG.error(""String_Node_Str"" + executionStateListener.getClass() + ""String_Node_Str""+ priority.intValue()+ ""String_Node_Str"");
  }
}",0.9971477467199088
55231,"/** 
 * Unregisters the   {@link ExecutionStateListener} object for this vertex. This objectwill no longer be notified about particular events during the vertex's lifetime.
 * @param checkpointStateChangeListener the object to be unregistered
 */
public void unregisterExecutionStateListener(final ExecutionStateListener executionListener){
  this.executionStateListeners.remove(Integer.valueOf(executionListener.getPriority()));
}","/** 
 * Unregisters the   {@link ExecutionStateListener} object for this vertex. This objectwill no longer be notified about particular events during the vertex's lifetime.
 * @param checkpointStateChangeListener the object to be unregistered
 */
public void unregisterExecutionStateListener(final ExecutionStateListener executionStateListener){
  this.executionStateListeners.remove(Integer.valueOf(executionStateListener.getPriority()));
}",0.9885321100917432
55232,"/** 
 * Unregisters all previously register   {@link ExecutionObserver} objects forthe vertex identified by the given ID.
 * @param id the ID of the vertex to unregister the  {@link ExecutionListener} objects for
 */
void unregisterExecutionObserver(ExecutionVertexID id);","/** 
 * Unregisters all previously register   {@link ExecutionObserver} objects forthe vertex identified by the given ID.
 * @param id the ID of the vertex to unregister the  {@link ExecutionObserver} objects for
 */
void unregisterExecutionObserver(ExecutionVertexID id);",0.9779411764705882
55233,"/** 
 * {@inheritDoc}
 */
@Override public void startExecution(){
  final ReplayThread thread=this.environment.getExecutingThread();
  if (this.replayThreadStarted.compareAndSet(false,true)) {
    thread.start();
  }
 else {
    thread.restart();
  }
}","/** 
 * {@inheritDoc}
 */
@Override public void startExecution(){
  final ReplayThread thread=this.environment.getExecutingThread();
  thread.start();
}",0.7524752475247525
55234,"private void replayCheckpoint() throws Exception {
  final CheckpointDeserializer deserializer=new CheckpointDeserializer(this.vertexID,!this.isCheckpointLocal);
  final Path checkpointPath=this.isCheckpointLocal ? CheckpointUtils.getLocalCheckpointPath() : CheckpointUtils.getDistributedCheckpointPath();
  if (checkpointPath == null) {
    throw new IOException(""String_Node_Str"" + this.vertexID);
  }
  final FileSystem fileSystem=checkpointPath.getFileSystem();
  int metaDataIndex=0;
  Buffer firstDeserializedFileBuffer=null;
  FileChannel fileChannel=null;
  try {
    while (true) {
      if (this.restartRequested.compareAndSet(true,false)) {
        metaDataIndex=0;
        resetAllOutputBroker();
      }
      final Path metaDataFile=checkpointPath.suffix(Path.SEPARATOR + CheckpointUtils.METADATA_PREFIX + ""String_Node_Str""+ this.vertexID+ ""String_Node_Str""+ metaDataIndex);
      while (!fileSystem.exists(metaDataFile)) {
        final Path finalMetaDataFile=checkpointPath.suffix(Path.SEPARATOR + CheckpointUtils.METADATA_PREFIX + ""String_Node_Str""+ this.vertexID+ ""String_Node_Str"");
        if (fileSystem.exists(finalMetaDataFile)) {
          return;
        }
        if (this.isCheckpointComplete) {
          throw new FileNotFoundException(""String_Node_Str"" + metaDataIndex + ""String_Node_Str""+ this.vertexID);
        }
        Thread.sleep(1000);
        if (this.executionObserver.isCanceled()) {
          return;
        }
      }
      fileChannel=getFileChannel(fileSystem,metaDataFile);
      while (true) {
        try {
          deserializer.read(fileChannel);
          final TransferEnvelope transferEnvelope=deserializer.getFullyDeserializedTransferEnvelope();
          if (transferEnvelope != null) {
            final ReplayOutputChannelBroker broker=this.outputBrokerMap.get(transferEnvelope.getSource());
            if (broker == null) {
              throw new IOException(""String_Node_Str"" + transferEnvelope.getSource());
            }
            final Buffer srcBuffer=transferEnvelope.getBuffer();
            if (srcBuffer != null) {
              if (firstDeserializedFileBuffer == null) {
                firstDeserializedFileBuffer=srcBuffer.duplicate();
              }
              if (transferEnvelope.getSequenceNumber() < broker.getNextEnvelopeToSend()) {
                srcBuffer.recycleBuffer();
                continue;
              }
              final Buffer destBuffer=broker.requestEmptyBufferBlocking(srcBuffer.size());
              srcBuffer.copyToBuffer(destBuffer);
              transferEnvelope.setBuffer(destBuffer);
              srcBuffer.recycleBuffer();
            }
            broker.outputEnvelope(transferEnvelope);
            if (this.executionObserver.isCanceled()) {
              return;
            }
          }
        }
 catch (        EOFException eof) {
          fileChannel.close();
          fileChannel=null;
          ++metaDataIndex;
          break;
        }
      }
    }
  }
  finally {
    if (firstDeserializedFileBuffer != null) {
      firstDeserializedFileBuffer.recycleBuffer();
      firstDeserializedFileBuffer=null;
    }
    if (fileChannel != null) {
      fileChannel.close();
      fileChannel=null;
    }
  }
}","private void replayCheckpoint() throws Exception {
  final CheckpointDeserializer deserializer=new CheckpointDeserializer(this.vertexID,!this.isCheckpointLocal);
  final Path checkpointPath=this.isCheckpointLocal ? CheckpointUtils.getLocalCheckpointPath() : CheckpointUtils.getDistributedCheckpointPath();
  if (checkpointPath == null) {
    throw new IOException(""String_Node_Str"" + this.vertexID);
  }
  final FileSystem fileSystem=checkpointPath.getFileSystem();
  int metaDataIndex=0;
  Buffer firstDeserializedFileBuffer=null;
  FileChannel fileChannel=null;
  try {
    while (true) {
      final Path metaDataFile=checkpointPath.suffix(Path.SEPARATOR + CheckpointUtils.METADATA_PREFIX + ""String_Node_Str""+ this.vertexID+ ""String_Node_Str""+ metaDataIndex);
      while (!fileSystem.exists(metaDataFile)) {
        final Path finalMetaDataFile=checkpointPath.suffix(Path.SEPARATOR + CheckpointUtils.METADATA_PREFIX + ""String_Node_Str""+ this.vertexID+ ""String_Node_Str"");
        if (fileSystem.exists(finalMetaDataFile)) {
          return;
        }
        if (this.isCheckpointComplete) {
          throw new FileNotFoundException(""String_Node_Str"" + metaDataIndex + ""String_Node_Str""+ this.vertexID);
        }
        Thread.sleep(1000);
        if (this.executionObserver.isCanceled()) {
          return;
        }
      }
      fileChannel=getFileChannel(fileSystem,metaDataFile);
      while (true) {
        try {
          deserializer.read(fileChannel);
          final TransferEnvelope transferEnvelope=deserializer.getFullyDeserializedTransferEnvelope();
          if (transferEnvelope != null) {
            final ReplayOutputChannelBroker broker=this.outputBrokerMap.get(transferEnvelope.getSource());
            if (broker == null) {
              throw new IOException(""String_Node_Str"" + transferEnvelope.getSource());
            }
            final Buffer srcBuffer=transferEnvelope.getBuffer();
            if (srcBuffer != null) {
              if (firstDeserializedFileBuffer == null) {
                firstDeserializedFileBuffer=srcBuffer.duplicate();
              }
              if (transferEnvelope.getSequenceNumber() < broker.getNextEnvelopeToSend()) {
                srcBuffer.recycleBuffer();
                continue;
              }
              final Buffer destBuffer=broker.requestEmptyBufferBlocking(srcBuffer.size());
              srcBuffer.copyToBuffer(destBuffer);
              transferEnvelope.setBuffer(destBuffer);
              srcBuffer.recycleBuffer();
            }
            broker.outputEnvelope(transferEnvelope);
            if (this.executionObserver.isCanceled()) {
              return;
            }
          }
        }
 catch (        EOFException eof) {
          fileChannel.close();
          fileChannel=null;
          ++metaDataIndex;
          break;
        }
      }
    }
  }
  finally {
    if (firstDeserializedFileBuffer != null) {
      firstDeserializedFileBuffer.recycleBuffer();
      firstDeserializedFileBuffer=null;
    }
    if (fileChannel != null) {
      fileChannel.close();
      fileChannel=null;
    }
  }
}",0.9801324503311258
55235,"/** 
 * Checks the transition of the execution state and outputs an error in case of an unexpected state transition.
 * @param jobManager <code>true</code> to indicate the method is called by the job manager, <code>false/<code> to indicate it is called by a task manager
 * @param taskName the name of the task whose execution has changed
 * @param oldState the old execution state
 * @param newState the new execution state
 */
public static void checkTransition(final boolean jobManager,final String taskName,final ExecutionState oldState,final ExecutionState newState){
  LOG.info((jobManager ? ""String_Node_Str"" : ""String_Node_Str"") + ""String_Node_Str"" + oldState+ ""String_Node_Str""+ newState+ ""String_Node_Str""+ taskName);
  boolean unexpectedStateChange=true;
  if (oldState == ExecutionState.CREATED && newState == ExecutionState.SCHEDULED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.SCHEDULED && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.ASSIGNED && newState == ExecutionState.READY) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.READY && newState == ExecutionState.STARTING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.STARTING && newState == ExecutionState.RUNNING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.RUNNING && newState == ExecutionState.FINISHING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FINISHING && newState == ExecutionState.FINISHED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FAILED && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FAILED && newState == ExecutionState.CREATED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FINISHED && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FINISHED && newState == ExecutionState.CREATED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.CANCELED && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.CANCELED && newState == ExecutionState.CREATED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.STARTING && newState == ExecutionState.REPLAYING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.REPLAYING && newState == ExecutionState.FINISHING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.CREATED && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.SCHEDULED && newState == ExecutionState.CANCELING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.ASSIGNED && newState == ExecutionState.CANCELING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.READY && newState == ExecutionState.CANCELING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.STARTING && newState == ExecutionState.FAILED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.RUNNING && newState == ExecutionState.FAILED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FINISHING && newState == ExecutionState.FAILED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.REPLAYING && newState == ExecutionState.FAILED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.RUNNING && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.REPLAYING && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FINISHING && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.RUNNING && newState == ExecutionState.CANCELING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FINISHING && newState == ExecutionState.CANCELING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.CANCELING && newState == ExecutionState.CANCELED) {
    unexpectedStateChange=false;
  }
  if (unexpectedStateChange) {
    try {
      throw new IllegalStateException(""String_Node_Str"" + oldState + ""String_Node_Str""+ newState);
    }
 catch (    IllegalStateException e) {
      LOG.error(StringUtils.stringifyException(e));
    }
  }
}","/** 
 * Checks the transition of the execution state and outputs an error in case of an unexpected state transition.
 * @param jobManager <code>true</code> to indicate the method is called by the job manager, <code>false/<code> to indicate it is called by a task manager
 * @param taskName the name of the task whose execution has changed
 * @param oldState the old execution state
 * @param newState the new execution state
 */
public static void checkTransition(final boolean jobManager,final String taskName,final ExecutionState oldState,final ExecutionState newState){
  LOG.info((jobManager ? ""String_Node_Str"" : ""String_Node_Str"") + ""String_Node_Str"" + oldState+ ""String_Node_Str""+ newState+ ""String_Node_Str""+ taskName);
  boolean unexpectedStateChange=true;
  if (oldState == ExecutionState.CREATED && newState == ExecutionState.SCHEDULED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.SCHEDULED && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.ASSIGNED && newState == ExecutionState.READY) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.READY && newState == ExecutionState.STARTING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.STARTING && newState == ExecutionState.RUNNING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.RUNNING && newState == ExecutionState.FINISHING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FINISHING && newState == ExecutionState.FINISHED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FAILED && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FAILED && newState == ExecutionState.CREATED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FINISHED && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FINISHED && newState == ExecutionState.CREATED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.CANCELED && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.CANCELED && newState == ExecutionState.CREATED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.STARTING && newState == ExecutionState.REPLAYING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.REPLAYING && newState == ExecutionState.FINISHING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.CREATED && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.SCHEDULED && newState == ExecutionState.CANCELING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.ASSIGNED && newState == ExecutionState.CANCELING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.READY && newState == ExecutionState.CANCELING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.STARTING && newState == ExecutionState.FAILED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.RUNNING && newState == ExecutionState.FAILED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FINISHING && newState == ExecutionState.FAILED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.REPLAYING && newState == ExecutionState.FAILED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.RUNNING && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.REPLAYING && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FINISHING && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.RUNNING && newState == ExecutionState.CANCELING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.REPLAYING && newState == ExecutionState.CANCELING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FINISHING && newState == ExecutionState.CANCELING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.CANCELING && newState == ExecutionState.CANCELED) {
    unexpectedStateChange=false;
  }
  if (unexpectedStateChange) {
    try {
      throw new IllegalStateException(taskName + ""String_Node_Str"" + oldState+ ""String_Node_Str""+ newState);
    }
 catch (    IllegalStateException e) {
      LOG.error(StringUtils.stringifyException(e));
    }
  }
}",0.9839432004369196
55236,"/** 
 * Cancels and removes the task represented by this vertex from the instance it is currently running on. If the task is not currently running, its execution state is simply updated to <code>CANCELLED</code>.
 * @throws InterruptedException thrown if the caller is interrupted while waiting for the response of the remote procedure call
 * @return the result of the task cancel attempt
 */
public TaskCancelResult cancelTask() throws InterruptedException {
  while (true) {
    final ExecutionState previousState=this.executionState.get();
    if (previousState == ExecutionState.CANCELED) {
      return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
    }
    if (previousState == ExecutionState.FAILED) {
      return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
    }
    if (previousState == ExecutionState.FINISHED) {
      return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
    }
    if (previousState == ExecutionState.CANCELING) {
      return new TaskCancelResult(getID(),ReturnCode.SUCCESS);
    }
    if (previousState == ExecutionState.STARTING) {
      this.cancelRequested.set(true);
      if (this.executionState.get() != ExecutionState.STARTING) {
        this.cancelRequested.set(false);
        continue;
      }
      return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
    }
    if (compareAndUpdateExecutionState(previousState,ExecutionState.CANCELING)) {
      if (this.groupVertex.getStageNumber() != this.executionGraph.getIndexOfCurrentExecutionStage()) {
        updateExecutionState(ExecutionState.CANCELED,null);
        return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
      }
      if (previousState != ExecutionState.RUNNING && previousState != ExecutionState.FINISHING && previousState != ExecutionState.REPLAYING) {
        updateExecutionState(ExecutionState.CANCELED,null);
        return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
      }
      final AllocatedResource ar=this.allocatedResource.get();
      if (ar == null) {
        final TaskCancelResult result=new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.NO_INSTANCE);
        result.setDescription(""String_Node_Str"" + this.toString() + ""String_Node_Str"");
        return result;
      }
      try {
        return ar.getInstance().cancelTask(this.vertexID);
      }
 catch (      IOException e) {
        final TaskCancelResult result=new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.IPC_ERROR);
        result.setDescription(StringUtils.stringifyException(e));
        return result;
      }
    }
  }
}","/** 
 * Cancels and removes the task represented by this vertex from the instance it is currently running on. If the task is not currently running, its execution state is simply updated to <code>CANCELLED</code>.
 * @throws InterruptedException thrown if the caller is interrupted while waiting for the response of the remote procedure call
 * @return the result of the task cancel attempt
 */
public TaskCancelResult cancelTask() throws InterruptedException {
  while (true) {
    final ExecutionState previousState=this.executionState.get();
    if (previousState == ExecutionState.CANCELED) {
      return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
    }
    if (previousState == ExecutionState.FAILED) {
      return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
    }
    if (previousState == ExecutionState.FINISHED) {
      return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
    }
    if (previousState == ExecutionState.CANCELING) {
      return new TaskCancelResult(getID(),ReturnCode.SUCCESS);
    }
    if (previousState == ExecutionState.STARTING) {
      this.cancelRequested.set(true);
      if (this.executionState.get() != ExecutionState.STARTING) {
        this.cancelRequested.set(false);
        continue;
      }
      return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
    }
    if (compareAndUpdateExecutionState(previousState,ExecutionState.CANCELING)) {
      if (this.groupVertex.getStageNumber() != this.executionGraph.getIndexOfCurrentExecutionStage() && previousState != ExecutionState.REPLAYING && previousState != ExecutionState.FINISHING) {
        updateExecutionState(ExecutionState.CANCELED,null);
        return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
      }
      if (previousState != ExecutionState.RUNNING && previousState != ExecutionState.FINISHING && previousState != ExecutionState.REPLAYING) {
        updateExecutionState(ExecutionState.CANCELED,null);
        return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
      }
      final AllocatedResource ar=this.allocatedResource.get();
      if (ar == null) {
        final TaskCancelResult result=new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.NO_INSTANCE);
        result.setDescription(""String_Node_Str"" + this.toString() + ""String_Node_Str"");
        return result;
      }
      try {
        return ar.getInstance().cancelTask(this.vertexID);
      }
 catch (      IOException e) {
        final TaskCancelResult result=new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.IPC_ERROR);
        result.setDescription(StringUtils.stringifyException(e));
        return result;
      }
    }
  }
}",0.8516746411483254
55237,"private static void findVerticesToRestart(final ExecutionVertex failedVertex,final Set<ExecutionVertex> verticesToBeCanceled,final Set<ExecutionVertex> checkpointsToBeReplayed) throws InterruptedException {
  final Queue<ExecutionVertex> verticesToTest=new ArrayDeque<ExecutionVertex>();
  final Set<ExecutionVertex> visited=new HashSet<ExecutionVertex>();
  verticesToTest.add(failedVertex);
  while (!verticesToTest.isEmpty()) {
    final ExecutionVertex vertex=verticesToTest.poll();
    for (int j=0; j < vertex.getNumberOfPredecessors(); j++) {
      final ExecutionVertex predecessor=vertex.getPredecessor(j);
      if (hasInstanceAssigned(predecessor)) {
        if (predecessor.getCheckpointState() == CheckpointState.UNDECIDED) {
          final TaskCheckpointResult result=predecessor.requestCheckpointDecision();
          if (result.getReturnCode() != ReturnCode.SUCCESS) {
            predecessor.updateCheckpointState(CheckpointState.NONE);
          }
 else {
            try {
              predecessor.waitForCheckpointStateChange(CheckpointState.UNDECIDED,100L);
            }
 catch (            InterruptedException e) {
            }
            if (predecessor.getCheckpointState() == CheckpointState.UNDECIDED) {
              predecessor.updateCheckpointState(CheckpointState.NONE);
            }
          }
        }
        if (predecessor.getCheckpointState() == CheckpointState.NONE) {
          verticesToBeCanceled.add(predecessor);
        }
 else {
          checkpointsToBeReplayed.add(predecessor);
          continue;
        }
      }
      if (!visited.contains(predecessor)) {
        verticesToTest.add(predecessor);
      }
    }
    visited.add(vertex);
  }
}","private static void findVerticesToRestart(final ExecutionVertex failedVertex,final Set<ExecutionVertex> verticesToBeCanceled,final Set<ExecutionVertex> checkpointsToBeReplayed) throws InterruptedException {
  final Queue<ExecutionVertex> verticesToTest=new ArrayDeque<ExecutionVertex>();
  final Set<ExecutionVertex> visited=new HashSet<ExecutionVertex>();
  verticesToTest.add(failedVertex);
  while (!verticesToTest.isEmpty()) {
    final ExecutionVertex vertex=verticesToTest.poll();
    for (int j=0; j < vertex.getNumberOfPredecessors(); j++) {
      final ExecutionVertex predecessor=vertex.getPredecessor(j);
      if (hasInstanceAssigned(predecessor)) {
        if (predecessor.getCheckpointState() == CheckpointState.UNDECIDED) {
          final TaskCheckpointResult result=predecessor.requestCheckpointDecision();
          if (result.getReturnCode() != ReturnCode.SUCCESS) {
            predecessor.updateCheckpointState(CheckpointState.NONE);
          }
 else {
            try {
              predecessor.waitForCheckpointStateChange(CheckpointState.UNDECIDED,100L);
            }
 catch (            InterruptedException e) {
            }
            if (predecessor.getCheckpointState() == CheckpointState.UNDECIDED) {
              predecessor.updateCheckpointState(CheckpointState.NONE);
            }
          }
        }
        final CheckpointState checkpointState=predecessor.getCheckpointState();
switch (checkpointState) {
case NONE:
          verticesToBeCanceled.add(predecessor);
        break;
case COMPLETE:
      verticesToBeCanceled.add(predecessor);
    continue;
case PARTIAL:
  checkpointsToBeReplayed.add(predecessor);
continue;
default :
LOG.error(predecessor + ""String_Node_Str"" + checkpointState);
}
}
if (!visited.contains(predecessor)) {
verticesToTest.add(predecessor);
}
}
visited.add(vertex);
}
}",0.8738357324301439
55238,"public void executionStateChanged(final JobID jobID,final ExecutionVertexID id,final ExecutionState newExecutionState,final String optionalDescription){
  if (newExecutionState == ExecutionState.CANCELING) {
    return;
  }
  if (newExecutionState == ExecutionState.FINISHED || newExecutionState == ExecutionState.CANCELED || newExecutionState == ExecutionState.FAILED) {
    unregisterTask(id);
  }
  try {
    this.jobManager.updateTaskExecutionState(new TaskExecutionState(jobID,id,newExecutionState,optionalDescription));
  }
 catch (  Exception e) {
    LOG.error(StringUtils.stringifyException(e));
  }
}","public void executionStateChanged(final JobID jobID,final ExecutionVertexID id,final ExecutionState newExecutionState,final String optionalDescription){
  if (newExecutionState == ExecutionState.CANCELING) {
    return;
  }
  if (newExecutionState == ExecutionState.FINISHED || newExecutionState == ExecutionState.CANCELED || newExecutionState == ExecutionState.FAILED) {
    unregisterTask(id);
  }
  if (newExecutionState == ExecutionState.CANCELED) {
    final Runnable runnable=new Runnable(){
      @Override public void run(){
        try {
          jobManager.updateTaskExecutionState(new TaskExecutionState(jobID,id,newExecutionState,optionalDescription));
        }
 catch (        Exception e) {
          LOG.error(StringUtils.stringifyException(e));
        }
      }
    }
;
    this.executorService.execute(runnable);
    return;
  }
  try {
    jobManager.updateTaskExecutionState(new TaskExecutionState(jobID,id,newExecutionState,optionalDescription));
  }
 catch (  Exception e) {
    LOG.error(StringUtils.stringifyException(e));
  }
}",0.7271634615384616
55239,"/** 
 * Registers an newly incoming runtime task with the task manager.
 * @param id the ID of the task to register
 * @param jobConfiguration the job configuration that has been attached to the original job graph
 * @param environment the environment of the task to be registered
 * @param initialCheckpointState the task's initial checkpoint state
 * @param activeOutputChannels the set of initially active output channels
 * @return the task to be started or <code>null</code> if a task with the same ID was already running
 */
private Task createAndRegisterTask(final ExecutionVertexID id,final Configuration jobConfiguration,final RuntimeEnvironment environment,final CheckpointState initialCheckpointState,final Set<ChannelID> activeOutputChannels) throws InsufficientResourcesException, IOException {
  if (id == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (environment == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (initialCheckpointState == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  Task task=null;
synchronized (this) {
    final Task runningTask=this.runningTasks.get(id);
    boolean registerTask=true;
    if (runningTask == null) {
      if (CheckpointUtils.hasCompleteCheckpointAvailable(id)) {
        task=new ReplayTask(id,environment,this);
      }
 else {
        task=new RuntimeTask(id,environment,initialCheckpointState,this);
      }
    }
 else {
      if (runningTask instanceof RuntimeTask) {
        if (CheckpointUtils.hasPartialCheckpointAvailable(id)) {
          task=new ReplayTask((RuntimeTask)runningTask,this);
        }
 else {
          return null;
        }
      }
 else {
        task=runningTask;
        registerTask=false;
      }
    }
    final Environment ee=task.getEnvironment();
    if (registerTask) {
      this.byteBufferedChannelManager.register(task,activeOutputChannels);
      boolean enableProfiling=false;
      if (this.profiler != null && jobConfiguration.getBoolean(ProfilingUtils.PROFILE_JOB_KEY,true)) {
        enableProfiling=true;
      }
      if (enableProfiling) {
        task.registerProfiler(this.profiler,jobConfiguration);
      }
      if (!this.taskManagerPlugins.isEmpty()) {
        final Iterator<TaskManagerPlugin> it=this.taskManagerPlugins.values().iterator();
        while (it.hasNext()) {
          it.next().registerTask(id,jobConfiguration,ee);
        }
      }
      this.runningTasks.put(id,task);
    }
  }
  return task;
}","/** 
 * Registers an newly incoming runtime task with the task manager.
 * @param id the ID of the task to register
 * @param jobConfiguration the job configuration that has been attached to the original job graph
 * @param environment the environment of the task to be registered
 * @param initialCheckpointState the task's initial checkpoint state
 * @param activeOutputChannels the set of initially active output channels
 * @return the task to be started or <code>null</code> if a task with the same ID was already running
 */
private Task createAndRegisterTask(final ExecutionVertexID id,final Configuration jobConfiguration,final RuntimeEnvironment environment,final CheckpointState initialCheckpointState,final Set<ChannelID> activeOutputChannels) throws InsufficientResourcesException, IOException {
  if (id == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (environment == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (initialCheckpointState == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  Task task=null;
synchronized (this) {
    final Task runningTask=this.runningTasks.get(id);
    if (runningTask == null) {
      if (CheckpointUtils.hasCompleteCheckpointAvailable(id)) {
        task=new ReplayTask(id,environment,this);
      }
 else {
        task=new RuntimeTask(id,environment,initialCheckpointState,this);
      }
    }
 else {
      if (CheckpointUtils.hasPartialCheckpointAvailable(id)) {
        task=new ReplayTask((RuntimeTask)runningTask,this);
      }
 else {
        return null;
      }
    }
    final Environment ee=task.getEnvironment();
    this.byteBufferedChannelManager.register(task,activeOutputChannels);
    boolean enableProfiling=false;
    if (this.profiler != null && jobConfiguration.getBoolean(ProfilingUtils.PROFILE_JOB_KEY,true)) {
      enableProfiling=true;
    }
    if (enableProfiling) {
      task.registerProfiler(this.profiler,jobConfiguration);
    }
    if (!this.taskManagerPlugins.isEmpty()) {
      final Iterator<TaskManagerPlugin> it=this.taskManagerPlugins.values().iterator();
      while (it.hasNext()) {
        it.next().registerTask(id,jobConfiguration,ee);
      }
    }
    this.runningTasks.put(id,task);
  }
  return task;
}",0.9289139045236606
55240,"@Override public void read(DataInput in) throws IOException {
  workerIndex=in.readInt();
  String classname=in.readUTF();
  try {
    aggregate=Class.forName(classname).asSubclass(Value.class).newInstance();
  }
 catch (  Exception e) {
    throw new IOException(e);
  }
  aggregate.read(in);
}","@Override public void read(DataInput in) throws IOException {
  workerIndex=in.readInt();
  boolean hasAggregate=in.readBoolean();
  if (hasAggregate) {
    String classname=in.readUTF();
    try {
      aggregate=Class.forName(classname).asSubclass(Value.class).newInstance();
    }
 catch (    Exception e) {
      throw new IOException(e);
    }
    aggregate.read(in);
  }
 else {
    aggregate=null;
  }
}",0.7801418439716312
55241,"@Override public void write(DataOutput out) throws IOException {
  out.writeInt(workerIndex);
  out.writeUTF(aggregate.getClass().getName());
  aggregate.write(out);
}","@Override public void write(DataOutput out) throws IOException {
  out.writeInt(workerIndex);
  boolean hasAggregate=aggregate != null;
  out.writeBoolean(hasAggregate);
  if (hasAggregate) {
    out.writeUTF(aggregate.getClass().getName());
    aggregate.write(out);
  }
}",0.6590909090909091
55242,"public static void main(String[] args) throws Exception {
  int degreeOfParallelism=2;
  int numSubTasksPerInstance=degreeOfParallelism;
  String pageWithRankInputPath=""String_Node_Str"" + PlayConstants.PLAY_DIR + ""String_Node_Str"";
  String transitionMatrixInputPath=""String_Node_Str"" + PlayConstants.PLAY_DIR + ""String_Node_Str"";
  String outputPath=""String_Node_Str"";
  String confPath=PlayConstants.PLAY_DIR + ""String_Node_Str"";
  int memoryPerTask=25;
  int memoryForMatch=memoryPerTask;
  int numIterations=5;
  if (args.length == 9) {
    degreeOfParallelism=Integer.parseInt(args[0]);
    numSubTasksPerInstance=Integer.parseInt(args[1]);
    pageWithRankInputPath=args[2];
    transitionMatrixInputPath=args[3];
    outputPath=args[4];
    confPath=args[5];
    memoryPerTask=Integer.parseInt(args[6]);
    memoryForMatch=Integer.parseInt(args[7]);
    numIterations=Integer.parseInt(args[8]);
  }
  JobGraph jobGraph=new JobGraph(""String_Node_Str"");
  JobInputVertex pageWithRankInput=JobGraphUtils.createInput(PageWithRankInputFormat.class,pageWithRankInputPath,""String_Node_Str"",jobGraph,degreeOfParallelism,numSubTasksPerInstance);
  TaskConfig pageWithRankInputConfig=new TaskConfig(pageWithRankInput.getConfiguration());
  pageWithRankInputConfig.setComparatorFactoryForOutput(PactRecordComparatorFactory.class,0);
  PactRecordComparatorFactory.writeComparatorSetupToConfig(pageWithRankInputConfig.getConfigForOutputParameters(0),new int[]{0},new Class[]{PactLong.class},new boolean[]{true});
  JobInputVertex transitionMatrixInput=JobGraphUtils.createInput(RowPartitionedTransitionMatrixInputFormat.class,transitionMatrixInputPath,""String_Node_Str"",jobGraph,degreeOfParallelism,numSubTasksPerInstance);
  TaskConfig transitionMatrixInputConfig=new TaskConfig(transitionMatrixInput.getConfiguration());
  transitionMatrixInputConfig.setComparatorFactoryForOutput(PactRecordComparatorFactory.class,0);
  PactRecordComparatorFactory.writeComparatorSetupToConfig(transitionMatrixInputConfig.getConfigForOutputParameters(0),new int[]{0},new Class[]{PactLong.class},new boolean[]{true});
  JobTaskVertex head=JobGraphUtils.createTask(IterationHeadPactTask.class,""String_Node_Str"",jobGraph,degreeOfParallelism,numSubTasksPerInstance);
  TaskConfig headConfig=new TaskConfig(head.getConfiguration());
  headConfig.setDriver(MapDriver.class);
  headConfig.setStubClass(IdentityMap.class);
  headConfig.setMemorySize(memoryPerTask * JobGraphUtils.MEGABYTE);
  headConfig.setBackChannelMemoryFraction(0.8f);
  JobTaskVertex intermediate=JobGraphUtils.createTask(IterationIntermediatePactTask.class,""String_Node_Str"",jobGraph,degreeOfParallelism,numSubTasksPerInstance);
  TaskConfig intermediateConfig=new TaskConfig(intermediate.getConfiguration());
  intermediateConfig.setDriver(RepeatableHashjoinMatchDriverWithCachedBuildside.class);
  intermediateConfig.setStubClass(DotProductRowMatch.class);
  PactRecordComparatorFactory.writeComparatorSetupToConfig(intermediateConfig.getConfigForInputParameters(0),new int[]{0},new Class[]{PactLong.class},new boolean[]{true});
  PactRecordComparatorFactory.writeComparatorSetupToConfig(intermediateConfig.getConfigForInputParameters(1),new int[]{0},new Class[]{PactLong.class},new boolean[]{true});
  intermediateConfig.setMemorySize(memoryForMatch * JobGraphUtils.MEGABYTE);
  intermediateConfig.setComparatorFactoryForOutput(PactRecordComparatorFactory.class,0);
  PactRecordComparatorFactory.writeComparatorSetupToConfig(intermediateConfig.getConfigForOutputParameters(0),new int[]{0},new Class[]{PactLong.class},new boolean[]{true});
  JobTaskVertex tail=JobGraphUtils.createTask(IterationTailPactTask.class,""String_Node_Str"",jobGraph,degreeOfParallelism,numSubTasksPerInstance);
  TaskConfig tailConfig=new TaskConfig(tail.getConfiguration());
  tailConfig.setLocalStrategy(TaskConfig.LocalStrategy.COMBININGSORT);
  tailConfig.setDriver(ReduceDriver.class);
  tailConfig.setStubClass(DotProductReducer.class);
  PactRecordComparatorFactory.writeComparatorSetupToConfig(tailConfig.getConfigForInputParameters(0),new int[]{0},new Class[]{PactLong.class},new boolean[]{true});
  tailConfig.setMemorySize(memoryPerTask * JobGraphUtils.MEGABYTE);
  tailConfig.setNumFilehandles(10);
  JobOutputVertex sync=JobGraphUtils.createSync(jobGraph,degreeOfParallelism);
  TaskConfig syncConfig=new TaskConfig(sync.getConfiguration());
  syncConfig.setNumberOfIterations(numIterations);
  JobOutputVertex output=JobGraphUtils.createFileOutput(jobGraph,""String_Node_Str"",degreeOfParallelism,numSubTasksPerInstance);
  TaskConfig outputConfig=new TaskConfig(output.getConfiguration());
  outputConfig.setStubClass(PageWithRankOutFormat.class);
  outputConfig.setStubParameter(FileOutputFormat.FILE_PARAMETER_KEY,outputPath);
  JobOutputVertex fakeTailOutput=JobGraphUtils.createFakeOutput(jobGraph,""String_Node_Str"",degreeOfParallelism,numSubTasksPerInstance);
  JobGraphUtils.connect(pageWithRankInput,head,ChannelType.NETWORK,DistributionPattern.BIPARTITE,ShipStrategyType.PARTITION_HASH);
  JobGraphUtils.connect(head,intermediate,ChannelType.NETWORK,DistributionPattern.BIPARTITE,ShipStrategyType.BROADCAST);
  JobGraphUtils.connect(transitionMatrixInput,intermediate,ChannelType.NETWORK,DistributionPattern.BIPARTITE,ShipStrategyType.PARTITION_HASH);
  intermediateConfig.setGateIterativeWithNumberOfEventsUntilInterrupt(0,degreeOfParallelism);
  JobGraphUtils.connect(head,sync,ChannelType.NETWORK,DistributionPattern.POINTWISE,ShipStrategyType.FORWARD);
  JobGraphUtils.connect(head,output,ChannelType.INMEMORY,DistributionPattern.POINTWISE,ShipStrategyType.FORWARD);
  JobGraphUtils.connect(tail,fakeTailOutput,ChannelType.INMEMORY,DistributionPattern.POINTWISE,ShipStrategyType.FORWARD);
  JobGraphUtils.connect(intermediate,tail,ChannelType.NETWORK,DistributionPattern.BIPARTITE,ShipStrategyType.PARTITION_HASH);
  tailConfig.setGateIterativeWithNumberOfEventsUntilInterrupt(0,degreeOfParallelism);
  fakeTailOutput.setVertexToShareInstancesWith(tail);
  tail.setVertexToShareInstancesWith(head);
  pageWithRankInput.setVertexToShareInstancesWith(head);
  transitionMatrixInput.setVertexToShareInstancesWith(head);
  intermediate.setVertexToShareInstancesWith(head);
  output.setVertexToShareInstancesWith(head);
  sync.setVertexToShareInstancesWith(head);
  GlobalConfiguration.loadConfiguration(confPath);
  Configuration conf=GlobalConfiguration.getConfiguration();
  JobGraphUtils.submit(jobGraph,conf);
}","public static void main(String[] args) throws Exception {
  int degreeOfParallelism=2;
  int numSubTasksPerInstance=degreeOfParallelism;
  String pageWithRankInputPath=""String_Node_Str"" + PlayConstants.PLAY_DIR + ""String_Node_Str"";
  String transitionMatrixInputPath=""String_Node_Str"" + PlayConstants.PLAY_DIR + ""String_Node_Str"";
  String outputPath=""String_Node_Str"";
  String confPath=PlayConstants.PLAY_DIR + ""String_Node_Str"";
  int memoryPerTask=25;
  int memoryForMatch=memoryPerTask;
  int numIterations=5;
  if (args.length == 9) {
    degreeOfParallelism=Integer.parseInt(args[0]);
    numSubTasksPerInstance=Integer.parseInt(args[1]);
    pageWithRankInputPath=args[2];
    transitionMatrixInputPath=args[3];
    outputPath=args[4];
    confPath=args[5];
    memoryPerTask=Integer.parseInt(args[6]);
    memoryForMatch=Integer.parseInt(args[7]);
    numIterations=Integer.parseInt(args[8]);
  }
  JobGraph jobGraph=new JobGraph(""String_Node_Str"");
  JobInputVertex pageWithRankInput=JobGraphUtils.createInput(PageWithRankInputFormat.class,pageWithRankInputPath,""String_Node_Str"",jobGraph,degreeOfParallelism,numSubTasksPerInstance);
  TaskConfig pageWithRankInputConfig=new TaskConfig(pageWithRankInput.getConfiguration());
  pageWithRankInputConfig.setComparatorFactoryForOutput(PactRecordComparatorFactory.class,0);
  PactRecordComparatorFactory.writeComparatorSetupToConfig(pageWithRankInputConfig.getConfigForOutputParameters(0),new int[]{0},new Class[]{PactLong.class},new boolean[]{true});
  JobInputVertex transitionMatrixInput=JobGraphUtils.createInput(RowPartitionedTransitionMatrixInputFormat.class,transitionMatrixInputPath,""String_Node_Str"",jobGraph,degreeOfParallelism,numSubTasksPerInstance);
  TaskConfig transitionMatrixInputConfig=new TaskConfig(transitionMatrixInput.getConfiguration());
  transitionMatrixInputConfig.setComparatorFactoryForOutput(PactRecordComparatorFactory.class,0);
  PactRecordComparatorFactory.writeComparatorSetupToConfig(transitionMatrixInputConfig.getConfigForOutputParameters(0),new int[]{0},new Class[]{PactLong.class},new boolean[]{true});
  JobTaskVertex head=JobGraphUtils.createTask(IterationHeadPactTask.class,""String_Node_Str"",jobGraph,degreeOfParallelism,numSubTasksPerInstance);
  TaskConfig headConfig=new TaskConfig(head.getConfiguration());
  headConfig.setDriver(MapDriver.class);
  headConfig.setStubClass(IdentityMap.class);
  headConfig.setMemorySize(memoryPerTask * JobGraphUtils.MEGABYTE);
  headConfig.setBackChannelMemoryFraction(0.8f);
  JobTaskVertex intermediate=JobGraphUtils.createTask(IterationIntermediatePactTask.class,""String_Node_Str"",jobGraph,degreeOfParallelism,numSubTasksPerInstance);
  TaskConfig intermediateConfig=new TaskConfig(intermediate.getConfiguration());
  intermediateConfig.setDriver(RepeatableHashjoinMatchDriverWithCachedBuildside.class);
  intermediateConfig.setStubClass(DotProductRowMatch.class);
  PactRecordComparatorFactory.writeComparatorSetupToConfig(intermediateConfig.getConfigForInputParameters(0),new int[]{0},new Class[]{PactLong.class},new boolean[]{true});
  PactRecordComparatorFactory.writeComparatorSetupToConfig(intermediateConfig.getConfigForInputParameters(1),new int[]{0},new Class[]{PactLong.class},new boolean[]{true});
  intermediateConfig.setMemorySize(memoryForMatch * JobGraphUtils.MEGABYTE);
  intermediateConfig.setComparatorFactoryForOutput(PactRecordComparatorFactory.class,0);
  PactRecordComparatorFactory.writeComparatorSetupToConfig(intermediateConfig.getConfigForOutputParameters(0),new int[]{0},new Class[]{PactLong.class},new boolean[]{true});
  JobTaskVertex tail=JobGraphUtils.createTask(IterationTailPactTask.class,""String_Node_Str"",jobGraph,degreeOfParallelism,numSubTasksPerInstance);
  TaskConfig tailConfig=new TaskConfig(tail.getConfiguration());
  tailConfig.setLocalStrategy(TaskConfig.LocalStrategy.COMBININGSORT);
  tailConfig.setDriver(ReduceDriver.class);
  tailConfig.setStubClass(DotProductReducer.class);
  PactRecordComparatorFactory.writeComparatorSetupToConfig(tailConfig.getConfigForInputParameters(0),new int[]{0},new Class[]{PactLong.class},new boolean[]{true});
  tailConfig.setMemorySize(memoryPerTask * JobGraphUtils.MEGABYTE);
  tailConfig.setNumFilehandles(10);
  JobOutputVertex sync=JobGraphUtils.createSync(jobGraph,degreeOfParallelism);
  TaskConfig syncConfig=new TaskConfig(sync.getConfiguration());
  syncConfig.setNumberOfIterations(numIterations);
  JobOutputVertex output=JobGraphUtils.createFileOutput(jobGraph,""String_Node_Str"",degreeOfParallelism,numSubTasksPerInstance);
  TaskConfig outputConfig=new TaskConfig(output.getConfiguration());
  outputConfig.setStubClass(PageWithRankOutFormat.class);
  outputConfig.setStubParameter(FileOutputFormat.FILE_PARAMETER_KEY,outputPath);
  JobOutputVertex fakeTailOutput=JobGraphUtils.createFakeOutput(jobGraph,""String_Node_Str"",degreeOfParallelism,numSubTasksPerInstance);
  JobGraphUtils.connect(pageWithRankInput,head,ChannelType.NETWORK,DistributionPattern.BIPARTITE,ShipStrategyType.PARTITION_HASH);
  JobGraphUtils.connect(head,intermediate,ChannelType.NETWORK,DistributionPattern.POINTWISE,ShipStrategyType.FORWARD);
  JobGraphUtils.connect(transitionMatrixInput,intermediate,ChannelType.NETWORK,DistributionPattern.BIPARTITE,ShipStrategyType.PARTITION_HASH);
  intermediateConfig.setGateIterativeWithNumberOfEventsUntilInterrupt(0,1);
  JobGraphUtils.connect(head,sync,ChannelType.NETWORK,DistributionPattern.POINTWISE,ShipStrategyType.FORWARD);
  JobGraphUtils.connect(head,output,ChannelType.INMEMORY,DistributionPattern.POINTWISE,ShipStrategyType.FORWARD);
  JobGraphUtils.connect(tail,fakeTailOutput,ChannelType.INMEMORY,DistributionPattern.POINTWISE,ShipStrategyType.FORWARD);
  JobGraphUtils.connect(intermediate,tail,ChannelType.NETWORK,DistributionPattern.BIPARTITE,ShipStrategyType.PARTITION_HASH);
  tailConfig.setGateIterativeWithNumberOfEventsUntilInterrupt(0,degreeOfParallelism);
  fakeTailOutput.setVertexToShareInstancesWith(tail);
  tail.setVertexToShareInstancesWith(head);
  pageWithRankInput.setVertexToShareInstancesWith(head);
  transitionMatrixInput.setVertexToShareInstancesWith(head);
  intermediate.setVertexToShareInstancesWith(head);
  output.setVertexToShareInstancesWith(head);
  sync.setVertexToShareInstancesWith(head);
  GlobalConfiguration.loadConfiguration(confPath);
  Configuration conf=GlobalConfiguration.getConfiguration();
  JobGraphUtils.submit(jobGraph,conf);
}",0.94727047146402
55243,"private void sendEventToSync(WorkerDoneEvent event) throws IOException, InterruptedException {
  if (log.isInfoEnabled()) {
    log.info(formatLogString(""String_Node_Str"" + WorkerDoneEvent.class.getSimpleName() + ""String_Node_Str""+ event.aggregate()+ ""String_Node_Str""));
  }
  getSyncOutput().publishEvent(event);
}","private void sendEventToSync(WorkerDoneEvent event) throws IOException, InterruptedException {
  if (log.isInfoEnabled()) {
    log.info(formatLogString(""String_Node_Str"" + WorkerDoneEvent.class.getSimpleName() + ""String_Node_Str""));
  }
  getSyncOutput().publishEvent(event);
}",0.936026936026936
55244,"/** 
 * Returns either this BooleanNode represents the value <code>true</code> or not.
 */
public boolean getBooleanValue(){
  return this == TRUE;
}","/** 
 * Returns either this BooleanNode represents the value <code>true</code> or not.
 */
public boolean getBooleanValue(){
  return value;
}",0.9415807560137456
55245,"/** 
 * {@inheritDoc}
 */
@Override public <T extends Record>OutputGate<T> createAndRegisterOutputGate(final ChannelSelector<T> selector,final boolean isBroadcast){
  if (this.unboundOutputGates == null) {
    final RuntimeOutputGate<T> rog=new RuntimeOutputGate<T>(getJobID(),null,getNumberOfOutputGates(),ChannelType.NETWORK,CompressionLevel.NO_COMPRESSION,selector,isBroadcast,null);
    this.outputGates.add(rog);
    return rog;
  }
  final GateDeploymentDescriptor gdd=this.unboundOutputGates.poll();
  if (gdd == null) {
    throw new IllegalStateException(""String_Node_Str"");
  }
  RecordSerializerFactory<T> serializerFactory;
  if (gdd.spanningRecordsAllowed()) {
    serializerFactory=new SpanningRecordSerializerFactory<T>();
  }
 else {
    serializerFactory=new DefaultRecordSerializerFactory<T>();
  }
  final RuntimeOutputGate<T> rog=new RuntimeOutputGate<T>(getJobID(),gdd.getGateID(),getNumberOfInputGates(),gdd.getChannelType(),gdd.getCompressionLevel(),selector,isBroadcast,serializerFactory);
  this.outputGates.add(rog);
  return rog;
}","/** 
 * {@inheritDoc}
 */
@Override public <T extends Record>OutputGate<T> createAndRegisterOutputGate(final ChannelSelector<T> selector,final boolean isBroadcast){
  if (this.unboundOutputGates == null) {
    final RuntimeOutputGate<T> rog=new RuntimeOutputGate<T>(getJobID(),null,getNumberOfOutputGates(),ChannelType.NETWORK,CompressionLevel.NO_COMPRESSION,selector,isBroadcast,null);
    this.outputGates.add(rog);
    return rog;
  }
  final GateDeploymentDescriptor gdd=this.unboundOutputGates.poll();
  if (gdd == null) {
    throw new IllegalStateException(""String_Node_Str"");
  }
  RecordSerializerFactory<T> serializerFactory;
  if (gdd.spanningRecordsAllowed()) {
    serializerFactory=new SpanningRecordSerializerFactory<T>();
  }
 else {
    serializerFactory=new DefaultRecordSerializerFactory<T>();
  }
  final RuntimeOutputGate<T> rog=new RuntimeOutputGate<T>(getJobID(),gdd.getGateID(),getNumberOfOutputGates(),gdd.getChannelType(),gdd.getCompressionLevel(),selector,isBroadcast,serializerFactory);
  this.outputGates.add(rog);
  return rog;
}",0.997638167217761
55246,"/** 
 * Creates a copy of the given object by an in-memory serialization and subsequent deserialization.
 * @param original the original object to be copied
 * @return the copy of original object
 */
public static <T>T createCopy(final T original){
  final Kryo kryo=new Kryo();
  return (T)kryo.copy(original);
}","/** 
 * Creates a copy of the given object by an in-memory serialization and subsequent deserialization.
 * @param original the original object to be copied
 * @return the copy of original object
 */
@SuppressWarnings(""String_Node_Str"") public static <T>T createCopy(final T original){
  final Kryo kryo=new Kryo();
  final byte[] buf=new byte[8192];
  final Output output=new Output(buf);
  kryo.writeObject(output,original);
  output.flush();
  final Input input=new Input(buf);
  return (T)kryo.readObject(input,original.getClass());
}",0.7050528789659224
55247,"public static void main(String[] args) throws Exception {
  int degreeOfParallelism=2;
  int numSubTasksPerInstance=degreeOfParallelism;
  String pageWithRankInputPath=""String_Node_Str"" + PlayConstants.PLAY_DIR + ""String_Node_Str"";
  String transitionMatrixInputPath=""String_Node_Str"" + PlayConstants.PLAY_DIR + ""String_Node_Str"";
  String outputPath=""String_Node_Str"";
  String confPath=PlayConstants.PLAY_DIR + ""String_Node_Str"";
  int memoryPerTask=25;
  int memoryForMatch=memoryPerTask;
  int numIterations=5;
  if (args.length == 9) {
    degreeOfParallelism=Integer.parseInt(args[0]);
    numSubTasksPerInstance=Integer.parseInt(args[1]);
    pageWithRankInputPath=args[2];
    transitionMatrixInputPath=args[3];
    outputPath=args[4];
    confPath=args[5];
    memoryPerTask=Integer.parseInt(args[6]);
    memoryForMatch=Integer.parseInt(args[7]);
    numIterations=Integer.parseInt(args[8]);
  }
  JobGraph jobGraph=new JobGraph(""String_Node_Str"");
  JobInputVertex pageWithRankInput=JobGraphUtils.createInput(PageWithRankInputFormat.class,pageWithRankInputPath,""String_Node_Str"",jobGraph,degreeOfParallelism,numSubTasksPerInstance);
  TaskConfig pageWithRankInputConfig=new TaskConfig(pageWithRankInput.getConfiguration());
  pageWithRankInputConfig.setComparatorFactoryForOutput(PactRecordComparatorFactory.class,0);
  PactRecordComparatorFactory.writeComparatorSetupToConfig(pageWithRankInputConfig.getConfigForOutputParameters(0),new int[]{0},new Class[]{PactLong.class},new boolean[]{true});
  JobInputVertex transitionMatrixInput=JobGraphUtils.createInput(RowPartitionedTransitionMatrixInputFormat.class,transitionMatrixInputPath,""String_Node_Str"",jobGraph,degreeOfParallelism,numSubTasksPerInstance);
  TaskConfig transitionMatrixInputConfig=new TaskConfig(transitionMatrixInput.getConfiguration());
  transitionMatrixInputConfig.setComparatorFactoryForOutput(PactRecordComparatorFactory.class,0);
  PactRecordComparatorFactory.writeComparatorSetupToConfig(transitionMatrixInputConfig.getConfigForOutputParameters(0),new int[]{0},new Class[]{PactLong.class},new boolean[]{true});
  JobTaskVertex head=JobGraphUtils.createTask(IterationHeadPactTask.class,""String_Node_Str"",jobGraph,degreeOfParallelism,numSubTasksPerInstance);
  TaskConfig headConfig=new TaskConfig(head.getConfiguration());
  headConfig.setDriver(MapDriver.class);
  headConfig.setStubClass(IdentityMap.class);
  headConfig.setMemorySize(memoryPerTask * JobGraphUtils.MEGABYTE);
  headConfig.setBackChannelMemoryFraction(0.8f);
  JobTaskVertex intermediate=JobGraphUtils.createTask(IterationIntermediatePactTask.class,""String_Node_Str"",jobGraph,degreeOfParallelism,numSubTasksPerInstance);
  TaskConfig intermediateConfig=new TaskConfig(intermediate.getConfiguration());
  intermediateConfig.setDriver(RepeatableHashjoinMatchDriverWithCachedBuildside.class);
  intermediateConfig.setStubClass(DotProductRowMatch.class);
  PactRecordComparatorFactory.writeComparatorSetupToConfig(intermediateConfig.getConfigForInputParameters(0),new int[]{0},new Class[]{PactLong.class},new boolean[]{true});
  PactRecordComparatorFactory.writeComparatorSetupToConfig(intermediateConfig.getConfigForInputParameters(1),new int[]{0},new Class[]{PactLong.class},new boolean[]{true});
  intermediateConfig.setMemorySize(memoryForMatch * JobGraphUtils.MEGABYTE);
  intermediateConfig.setComparatorFactoryForOutput(PactRecordComparatorFactory.class,0);
  PactRecordComparatorFactory.writeComparatorSetupToConfig(intermediateConfig.getConfigForOutputParameters(0),new int[]{0},new Class[]{PactLong.class},new boolean[]{true});
  JobTaskVertex tail=JobGraphUtils.createTask(IterationTailPactTask.class,""String_Node_Str"",jobGraph,degreeOfParallelism,numSubTasksPerInstance);
  TaskConfig tailConfig=new TaskConfig(tail.getConfiguration());
  tailConfig.setLocalStrategy(TaskConfig.LocalStrategy.COMBININGSORT);
  tailConfig.setDriver(ReduceDriver.class);
  tailConfig.setStubClass(DotProductReducer.class);
  PactRecordComparatorFactory.writeComparatorSetupToConfig(tailConfig.getConfigForInputParameters(0),new int[]{0},new Class[]{PactLong.class},new boolean[]{true});
  tailConfig.setMemorySize(memoryPerTask * JobGraphUtils.MEGABYTE);
  tailConfig.setNumFilehandles(10);
  JobOutputVertex sync=JobGraphUtils.createSync(jobGraph,degreeOfParallelism);
  TaskConfig syncConfig=new TaskConfig(sync.getConfiguration());
  syncConfig.setNumberOfIterations(numIterations);
  JobOutputVertex output=JobGraphUtils.createFileOutput(jobGraph,""String_Node_Str"",degreeOfParallelism,numSubTasksPerInstance);
  TaskConfig outputConfig=new TaskConfig(output.getConfiguration());
  outputConfig.setStubClass(PageWithRankOutFormat.class);
  outputConfig.setStubParameter(FileOutputFormat.FILE_PARAMETER_KEY,outputPath);
  JobOutputVertex fakeTailOutput=JobGraphUtils.createFakeOutput(jobGraph,""String_Node_Str"",degreeOfParallelism,numSubTasksPerInstance);
  JobGraphUtils.connect(pageWithRankInput,head,ChannelType.NETWORK,DistributionPattern.BIPARTITE,ShipStrategyType.PARTITION_HASH);
  JobGraphUtils.connect(head,intermediate,ChannelType.NETWORK,DistributionPattern.POINTWISE,ShipStrategyType.FORWARD);
  JobGraphUtils.connect(transitionMatrixInput,intermediate,ChannelType.NETWORK,DistributionPattern.BIPARTITE,ShipStrategyType.PARTITION_HASH);
  intermediateConfig.setGateIterativeWithNumberOfEventsUntilInterrupt(0,1);
  JobGraphUtils.connect(head,sync,ChannelType.NETWORK,DistributionPattern.POINTWISE,ShipStrategyType.FORWARD);
  JobGraphUtils.connect(head,output,ChannelType.INMEMORY,DistributionPattern.POINTWISE,ShipStrategyType.FORWARD);
  JobGraphUtils.connect(tail,fakeTailOutput,ChannelType.INMEMORY,DistributionPattern.POINTWISE,ShipStrategyType.FORWARD);
  JobGraphUtils.connect(intermediate,tail,ChannelType.NETWORK,DistributionPattern.BIPARTITE,ShipStrategyType.PARTITION_HASH);
  tailConfig.setGateIterativeWithNumberOfEventsUntilInterrupt(0,degreeOfParallelism);
  fakeTailOutput.setVertexToShareInstancesWith(tail);
  tail.setVertexToShareInstancesWith(head);
  pageWithRankInput.setVertexToShareInstancesWith(head);
  transitionMatrixInput.setVertexToShareInstancesWith(head);
  intermediate.setVertexToShareInstancesWith(head);
  output.setVertexToShareInstancesWith(head);
  sync.setVertexToShareInstancesWith(head);
  GlobalConfiguration.loadConfiguration(confPath);
  Configuration conf=GlobalConfiguration.getConfiguration();
  JobGraphUtils.submit(jobGraph,conf);
}","public static void main(String[] args) throws Exception {
  int degreeOfParallelism=2;
  int numSubTasksPerInstance=degreeOfParallelism;
  String pageWithRankInputPath=""String_Node_Str"" + PlayConstants.PLAY_DIR + ""String_Node_Str"";
  String transitionMatrixInputPath=""String_Node_Str"" + PlayConstants.PLAY_DIR + ""String_Node_Str"";
  String outputPath=""String_Node_Str"";
  String confPath=PlayConstants.PLAY_DIR + ""String_Node_Str"";
  int memoryPerTask=25;
  int memoryForMatch=memoryPerTask;
  int numIterations=5;
  long numVertices=4;
  if (args.length == 10) {
    degreeOfParallelism=Integer.parseInt(args[0]);
    numSubTasksPerInstance=Integer.parseInt(args[1]);
    pageWithRankInputPath=args[2];
    transitionMatrixInputPath=args[3];
    outputPath=args[4];
    confPath=args[5];
    memoryPerTask=Integer.parseInt(args[6]);
    memoryForMatch=Integer.parseInt(args[7]);
    numIterations=Integer.parseInt(args[8]);
    numVertices=Long.parseLong(args[9]);
  }
  JobGraph jobGraph=new JobGraph(""String_Node_Str"");
  JobInputVertex pageWithRankInput=JobGraphUtils.createInput(PageWithRankInputFormat.class,pageWithRankInputPath,""String_Node_Str"",jobGraph,degreeOfParallelism,numSubTasksPerInstance);
  TaskConfig pageWithRankInputConfig=new TaskConfig(pageWithRankInput.getConfiguration());
  pageWithRankInputConfig.setComparatorFactoryForOutput(PactRecordComparatorFactory.class,0);
  PactRecordComparatorFactory.writeComparatorSetupToConfig(pageWithRankInputConfig.getConfigForOutputParameters(0),new int[]{0},new Class[]{PactLong.class},new boolean[]{true});
  JobInputVertex transitionMatrixInput=JobGraphUtils.createInput(RowPartitionedTransitionMatrixInputFormat.class,transitionMatrixInputPath,""String_Node_Str"",jobGraph,degreeOfParallelism,numSubTasksPerInstance);
  TaskConfig transitionMatrixInputConfig=new TaskConfig(transitionMatrixInput.getConfiguration());
  transitionMatrixInputConfig.setComparatorFactoryForOutput(PactRecordComparatorFactory.class,0);
  PactRecordComparatorFactory.writeComparatorSetupToConfig(transitionMatrixInputConfig.getConfigForOutputParameters(0),new int[]{0},new Class[]{PactLong.class},new boolean[]{true});
  JobTaskVertex head=JobGraphUtils.createTask(IterationHeadPactTask.class,""String_Node_Str"",jobGraph,degreeOfParallelism,numSubTasksPerInstance);
  TaskConfig headConfig=new TaskConfig(head.getConfiguration());
  headConfig.setDriver(MapDriver.class);
  headConfig.setStubClass(IdentityMap.class);
  headConfig.setMemorySize(memoryPerTask * JobGraphUtils.MEGABYTE);
  headConfig.setBackChannelMemoryFraction(0.8f);
  JobTaskVertex intermediate=JobGraphUtils.createTask(IterationIntermediatePactTask.class,""String_Node_Str"",jobGraph,degreeOfParallelism,numSubTasksPerInstance);
  TaskConfig intermediateConfig=new TaskConfig(intermediate.getConfiguration());
  intermediateConfig.setDriver(RepeatableHashjoinMatchDriverWithCachedBuildside.class);
  intermediateConfig.setStubClass(DotProductRowMatch.class);
  PactRecordComparatorFactory.writeComparatorSetupToConfig(intermediateConfig.getConfigForInputParameters(0),new int[]{0},new Class[]{PactLong.class},new boolean[]{true});
  PactRecordComparatorFactory.writeComparatorSetupToConfig(intermediateConfig.getConfigForInputParameters(1),new int[]{0},new Class[]{PactLong.class},new boolean[]{true});
  intermediateConfig.setMemorySize(memoryForMatch * JobGraphUtils.MEGABYTE);
  intermediateConfig.setComparatorFactoryForOutput(PactRecordComparatorFactory.class,0);
  PactRecordComparatorFactory.writeComparatorSetupToConfig(intermediateConfig.getConfigForOutputParameters(0),new int[]{0},new Class[]{PactLong.class},new boolean[]{true});
  JobTaskVertex tail=JobGraphUtils.createTask(IterationTailPactTask.class,""String_Node_Str"",jobGraph,degreeOfParallelism,numSubTasksPerInstance);
  TaskConfig tailConfig=new TaskConfig(tail.getConfiguration());
  tailConfig.setLocalStrategy(TaskConfig.LocalStrategy.COMBININGSORT);
  tailConfig.setDriver(ReduceDriver.class);
  tailConfig.setStubClass(DotProductReducer.class);
  PactRecordComparatorFactory.writeComparatorSetupToConfig(tailConfig.getConfigForInputParameters(0),new int[]{0},new Class[]{PactLong.class},new boolean[]{true});
  tailConfig.setMemorySize(memoryPerTask * JobGraphUtils.MEGABYTE);
  tailConfig.setNumFilehandles(10);
  tailConfig.setStubParameter(""String_Node_Str"",String.valueOf(numVertices));
  JobOutputVertex sync=JobGraphUtils.createSync(jobGraph,degreeOfParallelism);
  TaskConfig syncConfig=new TaskConfig(sync.getConfiguration());
  syncConfig.setNumberOfIterations(numIterations);
  JobOutputVertex output=JobGraphUtils.createFileOutput(jobGraph,""String_Node_Str"",degreeOfParallelism,numSubTasksPerInstance);
  TaskConfig outputConfig=new TaskConfig(output.getConfiguration());
  outputConfig.setStubClass(PageWithRankOutFormat.class);
  outputConfig.setStubParameter(FileOutputFormat.FILE_PARAMETER_KEY,outputPath);
  JobOutputVertex fakeTailOutput=JobGraphUtils.createFakeOutput(jobGraph,""String_Node_Str"",degreeOfParallelism,numSubTasksPerInstance);
  JobGraphUtils.connect(pageWithRankInput,head,ChannelType.NETWORK,DistributionPattern.BIPARTITE,ShipStrategyType.PARTITION_HASH);
  JobGraphUtils.connect(head,intermediate,ChannelType.NETWORK,DistributionPattern.POINTWISE,ShipStrategyType.FORWARD);
  JobGraphUtils.connect(transitionMatrixInput,intermediate,ChannelType.NETWORK,DistributionPattern.BIPARTITE,ShipStrategyType.PARTITION_HASH);
  intermediateConfig.setGateIterativeWithNumberOfEventsUntilInterrupt(0,1);
  JobGraphUtils.connect(head,sync,ChannelType.NETWORK,DistributionPattern.POINTWISE,ShipStrategyType.FORWARD);
  JobGraphUtils.connect(head,output,ChannelType.INMEMORY,DistributionPattern.POINTWISE,ShipStrategyType.FORWARD);
  JobGraphUtils.connect(tail,fakeTailOutput,ChannelType.INMEMORY,DistributionPattern.POINTWISE,ShipStrategyType.FORWARD);
  JobGraphUtils.connect(intermediate,tail,ChannelType.NETWORK,DistributionPattern.BIPARTITE,ShipStrategyType.PARTITION_HASH);
  tailConfig.setGateIterativeWithNumberOfEventsUntilInterrupt(0,degreeOfParallelism);
  fakeTailOutput.setVertexToShareInstancesWith(tail);
  tail.setVertexToShareInstancesWith(head);
  pageWithRankInput.setVertexToShareInstancesWith(head);
  transitionMatrixInput.setVertexToShareInstancesWith(head);
  intermediate.setVertexToShareInstancesWith(head);
  output.setVertexToShareInstancesWith(head);
  sync.setVertexToShareInstancesWith(head);
  GlobalConfiguration.loadConfiguration(confPath);
  Configuration conf=GlobalConfiguration.getConfiguration();
  JobGraphUtils.submit(jobGraph,conf);
}",0.9889383929943156
55248,"@Override public void invoke() throws Exception {
  while (!terminationRequested()) {
    notifyMonitor(IterationMonitoring.Event.SYNC_STARTING,currentIteration);
    if (log.isInfoEnabled()) {
      log.info(formatLogString(""String_Node_Str"" + currentIteration + ""String_Node_Str""));
    }
    readHeadEventChannel();
    if (log.isInfoEnabled()) {
      log.info(formatLogString(""String_Node_Str"" + currentIteration + ""String_Node_Str""));
    }
    if (checkForConvergence()) {
      if (log.isInfoEnabled()) {
        log.info(formatLogString(""String_Node_Str"" + currentIteration + ""String_Node_Str""));
      }
      requestTermination();
      sendToAllWorkers(new TerminationEvent());
      notifyMonitor(IterationMonitoring.Event.SYNC_FINISHED,currentIteration);
    }
 else {
      if (log.isInfoEnabled()) {
        log.info(formatLogString(""String_Node_Str"" + currentIteration + ""String_Node_Str""));
      }
      AllWorkersDoneEvent allWorkersDoneEvent=taskConfig.usesConvergenceCriterion() ? new AllWorkersDoneEvent(aggregator.getAggregate()) : new AllWorkersDoneEvent();
      aggregator.reset();
      sendToAllWorkers(allWorkersDoneEvent);
      notifyMonitor(IterationMonitoring.Event.SYNC_FINISHED,currentIteration);
      currentIteration++;
    }
  }
}","@Override public void invoke() throws Exception {
  while (!terminationRequested()) {
    notifyMonitor(IterationMonitoring.Event.SYNC_STARTING,currentIteration);
    if (log.isInfoEnabled()) {
      log.info(formatLogString(""String_Node_Str"" + currentIteration + ""String_Node_Str""));
    }
    readHeadEventChannel();
    if (log.isInfoEnabled()) {
      log.info(formatLogString(""String_Node_Str"" + currentIteration + ""String_Node_Str""));
    }
    if (checkForConvergence()) {
      if (log.isInfoEnabled()) {
        log.info(formatLogString(""String_Node_Str"" + currentIteration + ""String_Node_Str""));
      }
      requestTermination();
      sendToAllWorkers(new TerminationEvent());
      notifyMonitor(IterationMonitoring.Event.SYNC_FINISHED,currentIteration);
    }
 else {
      if (log.isInfoEnabled()) {
        log.info(formatLogString(""String_Node_Str"" + currentIteration + ""String_Node_Str""));
      }
      AllWorkersDoneEvent allWorkersDoneEvent=taskConfig.usesConvergenceCriterion() ? new AllWorkersDoneEvent(aggregator.getAggregate()) : new AllWorkersDoneEvent();
      if (taskConfig.usesConvergenceCriterion()) {
        aggregator.reset();
      }
      sendToAllWorkers(allWorkersDoneEvent);
      notifyMonitor(IterationMonitoring.Event.SYNC_FINISHED,currentIteration);
      currentIteration++;
    }
  }
}",0.9765474817377932
55249,"/** 
 * Checks if the given new execution state of the   {@link ExecutionVertex} also leads to a new execution state of thethis group vertex. If so, the group vertex will update it's execution state and notify the registered {@link GroupExecutionListener} objects about the state change.
 * @param newExecutionState the new execution state of the  {@link ExecutionVertex}
 * @param optionalMessage an optional message providing additional information about the state change
 */
void updateGroupExecutionState(final ExecutionState newExecutionState,final String optionalMessage){
  if (newExecutionState == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (allMembersMustShareState(newExecutionState)) {
    final Iterator<ExecutionVertex> it=this.groupMembers.iterator();
    while (it.hasNext()) {
      if (it.next().getExecutionState() != newExecutionState) {
        return;
      }
    }
  }
  if (this.groupExecutionState.getAndSet(newExecutionState) == newExecutionState) {
    return;
  }
  final Iterator<GroupExecutionListener> it=this.groupExecutionListeners.iterator();
  while (it.hasNext()) {
    it.next().groupExecutionStateChanged(this,newExecutionState,optionalMessage);
  }
}","/** 
 * Checks if the given new execution state of the   {@link ExecutionVertex} also leads to a new execution state of thethis group vertex. If so, the group vertex will update it's execution state and notify the registered {@link GroupExecutionListener} objects about the state change.
 * @param newExecutionState the new execution state of the  {@link ExecutionVertex}
 * @param optionalMessage an optional message providing additional information about the state change
 */
void updateGroupExecutionState(final ExecutionState newExecutionState,final String optionalMessage){
  if (newExecutionState == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (allMembersMustShareState(newExecutionState)) {
    final Iterator<ExecutionVertex> it=this.groupMembers.iterator();
    while (it.hasNext()) {
      final ExecutionState es=it.next().getExecutionState();
      if (es != newExecutionState && es != ExecutionState.FAILED) {
        return;
      }
    }
  }
  if (this.groupExecutionState.getAndSet(newExecutionState) == newExecutionState) {
    return;
  }
  final Iterator<GroupExecutionListener> it=this.groupExecutionListeners.iterator();
  while (it.hasNext()) {
    it.next().groupExecutionStateChanged(this,newExecutionState,optionalMessage);
  }
}",0.947746310331073
55250,"/** 
 * Unassigns a cloud instance from the job.
 * @param instance the cloud instance which will be unassigned
 * @return the unassigned cloud instance
 */
public boolean unassignInstanceFromJob(final AbstractInstance instance){
synchronized (this.assignedInstances) {
    return this.assignedInstances.remove(instance);
  }
}","/** 
 * Unassigns a cloud instance from the job.
 * @param instance the cloud instance which will be unassigned
 * @return <code>true</code> if the given cloud instance has been assigned to the job, <code>false</code> otherwise
 */
public boolean unassignInstanceFromJob(final AbstractInstance instance){
synchronized (this.assignedInstances) {
    return (this.assignedInstances.remove(instance) != null);
  }
}",0.8092016238159675
55251,"/** 
 * Unassigns all currently assigned instances from that job and returns them.
 * @return the list of instances previously assigned to this job. The list is possibly empty.
 */
public List<EC2CloudInstance> unassignAllInstancesFromJob(){
  final List<EC2CloudInstance> unassignedInstances;
synchronized (this.assignedInstances) {
    unassignedInstances=new ArrayList<EC2CloudInstance>(this.assignedInstances);
    this.assignedInstances.clear();
  }
  return unassignedInstances;
}","/** 
 * Unassigns all currently assigned instances from that job and returns them.
 * @return the list of instances previously assigned to this job. The list is possibly empty.
 */
public List<EC2CloudInstance> unassignAllInstancesFromJob(){
  final List<EC2CloudInstance> unassignedInstances;
synchronized (this.assignedInstances) {
    unassignedInstances=new ArrayList<EC2CloudInstance>(this.assignedInstances.values());
    this.assignedInstances.clear();
  }
  return unassignedInstances;
}",0.9908256880733946
55252,"/** 
 * Assigns a cloud instance to the job.
 * @param instance the cloud instance which will be assigned
 */
public void assignInstanceToJob(final EC2CloudInstance instance){
synchronized (this.assignedInstances) {
    this.assignedInstances.add(instance);
  }
}","/** 
 * Assigns a cloud instance to the job.
 * @param instance the cloud instance which will be assigned
 */
public void assignInstanceToJob(final EC2CloudInstance instance){
synchronized (this.assignedInstances) {
    this.assignedInstances.put(instance.getInstanceConnectionInfo(),instance);
  }
}",0.9236234458259324
55253,"/** 
 * Returns the cloud instance matching the given connection information.
 * @param instanceConnectionInfo the  {@link InstanceConnectionInfo} object identifying the instance
 * @return the cloud instance matching the given connection information or <code>null</code> if no matching instanceexists
 */
public EC2CloudInstance getInstanceByConnectionInfo(final InstanceConnectionInfo instanceConnectionInfo){
  if (instanceConnectionInfo == null) {
    return null;
  }
synchronized (this.assignedInstances) {
    final Iterator<EC2CloudInstance> it=this.assignedInstances.iterator();
    while (it.hasNext()) {
      final EC2CloudInstance ci=it.next();
      if (instanceConnectionInfo.equals(ci.getInstanceConnectionInfo())) {
        return ci;
      }
    }
  }
  return null;
}","/** 
 * Returns the cloud instance matching the given connection information.
 * @param instanceConnectionInfo the  {@link InstanceConnectionInfo} object identifying the instance
 * @return the cloud instance matching the given connection information or <code>null</code> if no matching instanceexists
 */
public EC2CloudInstance getInstanceByConnectionInfo(final InstanceConnectionInfo instanceConnectionInfo){
  if (instanceConnectionInfo == null) {
    return null;
  }
synchronized (this.assignedInstances) {
    return this.assignedInstances.get(instanceConnectionInfo);
  }
}",0.803218727139722
55254,"/** 
 * {@inheritDoc}
 */
@Override public void run(){
  final Kryo kryo=threadLocalKryo.get();
  kryo.reset();
  final RPCEnvelope envelope=kryo.readObject(input,RPCEnvelope.class);
  final RPCMessage msg=envelope.getRPCMessage();
  if (fragmentationID != msg.getMessageID()) {
    Log.error(""String_Node_Str"");
    return;
  }
  if (msg instanceof RPCRequest) {
    processIncomingRPCRequest(remoteSocketAddress,(RPCRequest)msg);
  }
 else   if (msg instanceof RPCResponse) {
    processIncomingRPCResponse((RPCResponse)msg);
  }
 else {
    processIncomingRPCCleanup(remoteSocketAddress,(RPCCleanup)msg);
  }
}","/** 
 * {@inheritDoc}
 */
@Override public void run(){
  final Kryo k=kryo.get();
  k.reset();
  final RPCEnvelope envelope=k.readObject(input,RPCEnvelope.class);
  final RPCMessage msg=envelope.getRPCMessage();
  if (fragmentationID != msg.getMessageID()) {
    Log.error(""String_Node_Str"");
    return;
  }
  if (msg instanceof RPCRequest) {
    processIncomingRPCRequest(remoteSocketAddress,(RPCRequest)msg);
  }
 else   if (msg instanceof RPCResponse) {
    processIncomingRPCResponse((RPCResponse)msg);
  }
 else {
    processIncomingRPCCleanup(remoteSocketAddress,(RPCCleanup)msg);
  }
}",0.8988391376451078
55255,"/** 
 * Sends an RPC request to the given   {@link InetSocketAddress}.
 * @param remoteSocketAddress the remote address to send the request to
 * @param request the RPC request to send
 * @return the return value of the RPC call, possibly <code>null</code>
 * @throws Throwable any exception that is thrown by the remote receiver of the RPC call
 */
Object sendRPCRequest(final InetSocketAddress remoteSocketAddress,final RPCRequest request) throws Throwable {
  if (this.shutdownRequested.get()) {
    throw new IOException(""String_Node_Str"");
  }
  DatagramPacket[] packets=messageToPackets(remoteSocketAddress,request);
  final Integer messageID=Integer.valueOf(request.getMessageID());
  final RPCRequestMonitor requestMonitor=new RPCRequestMonitor();
  this.pendingRequests.put(messageID,requestMonitor);
  for (int i=0; i < RETRY_LIMIT; ++i) {
    sendPackets(packets);
    RPCResponse rpcResponse;
    try {
synchronized (requestMonitor) {
        if (requestMonitor.rpcResponse == null) {
          requestMonitor.wait(this.statistics.calculateTimeout(packets.length,i));
        }
        rpcResponse=requestMonitor.rpcResponse;
      }
    }
 catch (    InterruptedException ie) {
      Log.debug(""String_Node_Str"",ie);
      return null;
    }
    if (rpcResponse == null) {
      Log.debug(""String_Node_Str"" + request.getMessageID());
      continue;
    }
    this.pendingRequests.remove(messageID);
    this.statistics.reportSuccessfulCall(request.getMethodName(),packets.length,i);
    packets=messageToPackets(remoteSocketAddress,new RPCCleanup(request.getMessageID()));
    sendPackets(packets);
    if (rpcResponse instanceof RPCReturnValue) {
      return ((RPCReturnValue)rpcResponse).getRetVal();
    }
    throw ((RPCThrowable)rpcResponse).getThrowable();
  }
  this.pendingRequests.remove(messageID);
  throw new IOException(""String_Node_Str"" + request.getMethodName() + ""String_Node_Str""+ remoteSocketAddress);
}","/** 
 * Sends an RPC request to the given   {@link InetSocketAddress}.
 * @param remoteSocketAddress the remote address to send the request to
 * @param request the RPC request to send
 * @return the return value of the RPC call, possibly <code>null</code>
 * @throws Throwable any exception that is thrown by the remote receiver of the RPC call
 */
Object sendRPCRequest(final InetSocketAddress remoteSocketAddress,final RPCRequest request) throws Throwable {
  if (this.shutdownRequested.get()) {
    throw new IOException(""String_Node_Str"");
  }
  DatagramPacket[] packets=messageToPackets(remoteSocketAddress,request);
  final Integer messageID=Integer.valueOf(request.getMessageID());
  final RPCRequestMonitor requestMonitor=new RPCRequestMonitor();
  this.pendingRequests.put(messageID,requestMonitor);
  for (int i=0; i < RETRY_LIMIT; ++i) {
    sendPackets(packets);
    RPCResponse rpcResponse;
    try {
synchronized (requestMonitor) {
        if (requestMonitor.rpcResponse == null) {
          requestMonitor.wait(this.statistics.calculateTimeout(packets.length,i));
        }
        rpcResponse=requestMonitor.rpcResponse;
      }
    }
 catch (    InterruptedException ie) {
      Log.debug(""String_Node_Str"",ie);
      return null;
    }
    if (rpcResponse == null) {
      Log.debug(""String_Node_Str"" + request.getMessageID());
      continue;
    }
    this.pendingRequests.remove(messageID);
    this.statistics.reportSuccessfulCall(request.getMethodName(),packets.length,i);
    if (i == 0) {
      packets=messageToPackets(remoteSocketAddress,new RPCCleanup(request.getMessageID()));
      sendPackets(packets);
    }
    if (rpcResponse instanceof RPCReturnValue) {
      return ((RPCReturnValue)rpcResponse).getRetVal();
    }
    throw ((RPCThrowable)rpcResponse).getThrowable();
  }
  this.pendingRequests.remove(messageID);
  throw new IOException(""String_Node_Str"" + request.getMethodName() + ""String_Node_Str""+ remoteSocketAddress);
}",0.9928205128205128
55256,"/** 
 * {@inheritDoc}
 */
@Override protected Kryo initialValue(){
  final Kryo kryo=new Kryo();
  if (kryoTypesToRegister != null) {
    kryo.setAutoReset(false);
    kryo.setRegistrationRequired(true);
    for (    final Class<?> kryoType : kryoTypesToRegister) {
      kryo.register(kryoType);
    }
  }
  return kryo;
}","/** 
 * {@inheritDoc}
 */
@Override protected Kryo initialValue(){
  final Kryo kryo=new Kryo();
  if (kryoTypesToRegister != null) {
    kryo.setAutoReset(false);
    kryo.setRegistrationRequired(true);
    kryo.setReferences(false);
    for (    final Class<?> kryoType : kryoTypesToRegister) {
      kryo.register(kryoType);
    }
  }
  return kryo;
}",0.9542097488921714
55257,"void processIncomingRPCMessage(final InetSocketAddress remoteSocketAddress,final Input input,final int fragmentationID){
  final ThreadLocal<Kryo> threadLocalKryo=this.kryo;
  final Runnable runnable=new Runnable(){
    /** 
 * {@inheritDoc}
 */
    @Override public void run(){
      final Kryo kryo=threadLocalKryo.get();
      kryo.reset();
      final RPCEnvelope envelope=kryo.readObject(input,RPCEnvelope.class);
      final RPCMessage msg=envelope.getRPCMessage();
      if (fragmentationID != msg.getMessageID()) {
        Log.error(""String_Node_Str"");
        return;
      }
      if (msg instanceof RPCRequest) {
        processIncomingRPCRequest(remoteSocketAddress,(RPCRequest)msg);
      }
 else       if (msg instanceof RPCResponse) {
        processIncomingRPCResponse((RPCResponse)msg);
      }
 else {
        processIncomingRPCCleanup(remoteSocketAddress,(RPCCleanup)msg);
      }
    }
  }
;
  this.rpcHandlers.execute(runnable);
}","void processIncomingRPCMessage(final InetSocketAddress remoteSocketAddress,final Input input,final int fragmentationID){
  final Runnable runnable=new Runnable(){
    /** 
 * {@inheritDoc}
 */
    @Override public void run(){
      final Kryo k=kryo.get();
      k.reset();
      final RPCEnvelope envelope=k.readObject(input,RPCEnvelope.class);
      final RPCMessage msg=envelope.getRPCMessage();
      if (fragmentationID != msg.getMessageID()) {
        Log.error(""String_Node_Str"");
        return;
      }
      if (msg instanceof RPCRequest) {
        processIncomingRPCRequest(remoteSocketAddress,(RPCRequest)msg);
      }
 else       if (msg instanceof RPCResponse) {
        processIncomingRPCResponse((RPCResponse)msg);
      }
 else {
        processIncomingRPCCleanup(remoteSocketAddress,(RPCCleanup)msg);
      }
    }
  }
;
  this.rpcHandlers.execute(runnable);
}",0.8955713504647348
55258,"/** 
 * Stops the discovery service.
 */
public static synchronized void stopDiscoveryService(){
  if (discoveryService != null) {
    if (discoveryService.isRunning()) {
      discoveryService.stopService();
    }
  }
}","/** 
 * Stops the discovery service.
 */
public static synchronized void stopDiscoveryService(){
  if (discoveryService != null && discoveryService.isRunning()) {
    discoveryService.stopService();
  }
}",0.9433962264150944
55259,"/** 
 * Sets up an execution graph from a job graph.
 * @param jobGraph the job graph to create the execution graph from
 * @param instanceManager the instance manager
 * @throws GraphConversionException thrown if the job graph is not valid and no execution graph can be constructed from it
 */
private void constructExecutionGraph(final JobGraph jobGraph,final InstanceManager instanceManager) throws GraphConversionException {
  final HashMap<AbstractJobVertex,ExecutionVertex> temporaryVertexMap=new HashMap<AbstractJobVertex,ExecutionVertex>();
  final HashMap<AbstractJobVertex,ExecutionGroupVertex> temporaryGroupVertexMap=new HashMap<AbstractJobVertex,ExecutionGroupVertex>();
  final ExecutionStage initialExecutionStage=new ExecutionStage(this,0);
  this.stages.add(initialExecutionStage);
  final JobID jobID=jobGraph.getJobID();
  ClassLoader jobClassLoader=null;
  try {
    jobClassLoader=LibraryCacheManager.getClassLoader(jobID);
  }
 catch (  IOException e) {
    LOG.error(e);
    throw new GraphConversionException(StringUtils.stringifyException(e));
  }
  if (jobClassLoader == null) {
    throw new GraphConversionException(""String_Node_Str"" + jobID);
  }
  final AbstractJobVertex[] all=jobGraph.getAllJobVertices();
  for (int i=0; i < all.length; i++) {
    final ExecutionVertex createdVertex=createVertex(all[i],instanceManager,initialExecutionStage,jobGraph.getJobConfiguration(),jobClassLoader);
    temporaryVertexMap.put(all[i],createdVertex);
    temporaryGroupVertexMap.put(all[i],createdVertex.getGroupVertex());
  }
  createInitialGroupEdges(temporaryVertexMap);
  applyUserDefinedSettings(temporaryGroupVertexMap);
  calculateConnectionIDs();
  reconstructExecutionPipelines();
}","/** 
 * Sets up an execution graph from a job graph.
 * @param jobGraph the job graph to create the execution graph from
 * @param instanceManager the instance manager
 * @throws GraphConversionException thrown if the job graph is not valid and no execution graph can be constructed from it
 */
private void constructExecutionGraph(final JobGraph jobGraph,final InstanceManager instanceManager) throws GraphConversionException {
  final HashMap<AbstractJobVertex,ExecutionVertex> temporaryVertexMap=new HashMap<AbstractJobVertex,ExecutionVertex>();
  final HashMap<AbstractJobVertex,ExecutionGroupVertex> temporaryGroupVertexMap=new HashMap<AbstractJobVertex,ExecutionGroupVertex>();
  final ExecutionStage initialExecutionStage=new ExecutionStage(this,0);
  this.stages.add(initialExecutionStage);
  final JobID jobID=jobGraph.getJobID();
  ClassLoader jobClassLoader=null;
  try {
    jobClassLoader=LibraryCacheManager.getClassLoader(jobID);
  }
 catch (  IOException e) {
    LOG.error(e);
    throw new GraphConversionException(StringUtils.stringifyException(e));
  }
  if (jobClassLoader == null) {
    throw new GraphConversionException(""String_Node_Str"" + jobID);
  }
  final AbstractJobVertex[] all=jobGraph.getAllJobVertices();
  for (int i=0; i < all.length; i++) {
    final ExecutionVertex createdVertex=createVertex(all[i],instanceManager,initialExecutionStage,jobClassLoader);
    temporaryVertexMap.put(all[i],createdVertex);
    temporaryGroupVertexMap.put(all[i],createdVertex.getGroupVertex());
  }
  createInitialGroupEdges(temporaryVertexMap);
  applyUserDefinedSettings(temporaryGroupVertexMap);
  calculateConnectionIDs();
  reconstructExecutionPipelines();
}",0.9908689248895436
55260,"/** 
 * Creates an execution vertex from a job vertex.
 * @param jobVertex the job vertex to create the execution vertex from
 * @param instanceManager the instanceManager
 * @param initialExecutionStage the initial execution stage all group vertices are added to
 * @param jobConfiguration the configuration object originally attached to the  {@link JobGraph}
 * @param jobClassLoader the class loader of the job
 * @return the new execution vertex
 * @throws GraphConversionException thrown if the job vertex is of an unknown subclass
 */
@SuppressWarnings(""String_Node_Str"") private ExecutionVertex createVertex(final AbstractJobVertex jobVertex,final InstanceManager instanceManager,final ExecutionStage initialExecutionStage,final Configuration jobConfiguration,final ClassLoader jobClassLoader) throws GraphConversionException {
  InstanceType instanceType=null;
  boolean userDefinedInstanceType=false;
  if (jobVertex.getInstanceType() != null) {
    userDefinedInstanceType=true;
    instanceType=instanceManager.getInstanceTypeByName(jobVertex.getInstanceType());
    if (instanceType == null) {
      throw new GraphConversionException(""String_Node_Str"" + jobVertex.getInstanceType() + ""String_Node_Str"");
    }
  }
  if (instanceType == null) {
    instanceType=instanceManager.getDefaultInstanceType();
  }
  Class<? extends AbstractInvokable> invokableClass=null;
  try {
    invokableClass=(Class<? extends AbstractInvokable>)Class.forName(jobVertex.getInvokableClassName(),false,jobClassLoader);
  }
 catch (  ClassNotFoundException e) {
    LOG.error(e);
    throw new GraphConversionException(StringUtils.stringifyException(e));
  }
  if (invokableClass == null) {
    throw new GraphConversionException(""String_Node_Str"" + jobVertex.getID() + ""String_Node_Str""+ jobVertex.getName()+ ""String_Node_Str"");
  }
  final ExecutionSignature signature=ExecutionSignature.createSignature(invokableClass,jobVertex.getJobGraph().getJobID());
  ExecutionGroupVertex groupVertex=null;
  try {
    groupVertex=new ExecutionGroupVertex(jobVertex.getName(),jobVertex.getID(),this,jobVertex.getNumberOfSubtasks(),instanceType,userDefinedInstanceType,jobVertex.getNumberOfSubtasksPerInstance(),jobVertex.getVertexToShareInstancesWith() != null ? true : false,jobVertex.getNumberOfExecutionRetries(),jobVertex.getConfiguration(),signature,invokableClass);
  }
 catch (  Throwable t) {
    throw new GraphConversionException(StringUtils.stringifyException(t));
  }
  groupVertex.registerGroupExecutionListener(this);
  try {
    jobVertex.checkConfiguration(groupVertex.getEnvironment().getInvokable());
  }
 catch (  IllegalConfigurationException e) {
    throw new GraphConversionException(StringUtils.stringifyException(e));
  }
  final int minimumNumberOfSubtasks=jobVertex.getMinimumNumberOfSubtasks(groupVertex.getEnvironment().getInvokable());
  final int maximumNumberOfSubtasks=jobVertex.getMaximumNumberOfSubtasks(groupVertex.getEnvironment().getInvokable());
  if (jobVertex.getNumberOfSubtasks() != -1) {
    if (jobVertex.getNumberOfSubtasks() < 1) {
      throw new GraphConversionException(""String_Node_Str"" + jobVertex.getName() + ""String_Node_Str""+ jobVertex.getNumberOfSubtasks()+ ""String_Node_Str"");
    }
    if (jobVertex.getNumberOfSubtasks() < minimumNumberOfSubtasks) {
      throw new GraphConversionException(""String_Node_Str"" + minimumNumberOfSubtasks);
    }
    if (maximumNumberOfSubtasks != -1) {
      if (jobVertex.getNumberOfSubtasks() > maximumNumberOfSubtasks) {
        throw new GraphConversionException(""String_Node_Str"" + jobVertex.getName() + ""String_Node_Str""+ maximumNumberOfSubtasks);
      }
    }
  }
  if (jobVertex.getNumberOfSubtasksPerInstance() != -1 && jobVertex.getNumberOfSubtasksPerInstance() < 1) {
    throw new GraphConversionException(""String_Node_Str"" + jobVertex.getNumberOfSubtasksPerInstance() + ""String_Node_Str""+ jobVertex.getName());
  }
  groupVertex.setMinMemberSize(minimumNumberOfSubtasks);
  groupVertex.setMaxMemberSize(maximumNumberOfSubtasks);
  if (jobVertex instanceof AbstractJobInputVertex) {
    final InputSplit[] inputSplits;
    if (groupVertex.getEnvironment().getInvokable() instanceof AbstractInputTask) {
      try {
        inputSplits=((AbstractInputTask<?>)groupVertex.getEnvironment().getInvokable()).computeInputSplits(jobVertex.getNumberOfSubtasks());
      }
 catch (      Exception e) {
        throw new GraphConversionException(""String_Node_Str"" + groupVertex.getName() + ""String_Node_Str""+ StringUtils.stringifyException(e));
      }
    }
 else {
      throw new GraphConversionException(""String_Node_Str"");
    }
    if (inputSplits == null) {
      LOG.info(""String_Node_Str"" + jobVertex.getName() + ""String_Node_Str"");
    }
 else {
      LOG.info(""String_Node_Str"" + jobVertex.getName() + ""String_Node_Str""+ inputSplits.length+ ""String_Node_Str"");
    }
    groupVertex.setInputSplits(inputSplits);
  }
  if (jobVertex instanceof JobFileOutputVertex) {
    final JobFileOutputVertex jbov=(JobFileOutputVertex)jobVertex;
    jobVertex.getConfiguration().setString(""String_Node_Str"",jbov.getFilePath().toString());
  }
  initialExecutionStage.addStageMember(groupVertex);
  final ExecutionVertex ev=new ExecutionVertex(this,groupVertex,jobVertex.getNumberOfForwardConnections(),jobVertex.getNumberOfBackwardConnections());
  ev.setAllocatedResource(new AllocatedResource(DummyInstance.createDummyInstance(instanceType),instanceType,null));
  return ev;
}","/** 
 * Creates an execution vertex from a job vertex.
 * @param jobVertex the job vertex to create the execution vertex from
 * @param instanceManager the instanceManager
 * @param initialExecutionStage the initial execution stage all group vertices are added to
 * @param jobClassLoader the class loader of the job
 * @return the new execution vertex
 * @throws GraphConversionException thrown if the job vertex is of an unknown subclass
 */
@SuppressWarnings(""String_Node_Str"") private ExecutionVertex createVertex(final AbstractJobVertex jobVertex,final InstanceManager instanceManager,final ExecutionStage initialExecutionStage,final ClassLoader jobClassLoader) throws GraphConversionException {
  InstanceType instanceType=null;
  boolean userDefinedInstanceType=false;
  if (jobVertex.getInstanceType() != null) {
    userDefinedInstanceType=true;
    instanceType=instanceManager.getInstanceTypeByName(jobVertex.getInstanceType());
    if (instanceType == null) {
      throw new GraphConversionException(""String_Node_Str"" + jobVertex.getInstanceType() + ""String_Node_Str"");
    }
  }
  if (instanceType == null) {
    instanceType=instanceManager.getDefaultInstanceType();
  }
  Class<? extends AbstractInvokable> invokableClass=null;
  try {
    invokableClass=(Class<? extends AbstractInvokable>)Class.forName(jobVertex.getInvokableClassName(),false,jobClassLoader);
  }
 catch (  ClassNotFoundException e) {
    LOG.error(e);
    throw new GraphConversionException(StringUtils.stringifyException(e));
  }
  if (invokableClass == null) {
    throw new GraphConversionException(""String_Node_Str"" + jobVertex.getID() + ""String_Node_Str""+ jobVertex.getName()+ ""String_Node_Str"");
  }
  final ExecutionSignature signature=ExecutionSignature.createSignature(invokableClass,jobVertex.getJobGraph().getJobID());
  ExecutionGroupVertex groupVertex=null;
  try {
    groupVertex=new ExecutionGroupVertex(jobVertex.getName(),jobVertex.getID(),this,jobVertex.getNumberOfSubtasks(),instanceType,userDefinedInstanceType,jobVertex.getNumberOfSubtasksPerInstance(),jobVertex.getVertexToShareInstancesWith() != null ? true : false,jobVertex.getNumberOfExecutionRetries(),jobVertex.getConfiguration(),signature,invokableClass);
  }
 catch (  Throwable t) {
    throw new GraphConversionException(StringUtils.stringifyException(t));
  }
  groupVertex.registerGroupExecutionListener(this);
  try {
    jobVertex.checkConfiguration(groupVertex.getEnvironment().getInvokable());
  }
 catch (  IllegalConfigurationException e) {
    throw new GraphConversionException(StringUtils.stringifyException(e));
  }
  final int minimumNumberOfSubtasks=jobVertex.getMinimumNumberOfSubtasks(groupVertex.getEnvironment().getInvokable());
  final int maximumNumberOfSubtasks=jobVertex.getMaximumNumberOfSubtasks(groupVertex.getEnvironment().getInvokable());
  if (jobVertex.getNumberOfSubtasks() != -1) {
    if (jobVertex.getNumberOfSubtasks() < 1) {
      throw new GraphConversionException(""String_Node_Str"" + jobVertex.getName() + ""String_Node_Str""+ jobVertex.getNumberOfSubtasks()+ ""String_Node_Str"");
    }
    if (jobVertex.getNumberOfSubtasks() < minimumNumberOfSubtasks) {
      throw new GraphConversionException(""String_Node_Str"" + minimumNumberOfSubtasks);
    }
    if (maximumNumberOfSubtasks != -1) {
      if (jobVertex.getNumberOfSubtasks() > maximumNumberOfSubtasks) {
        throw new GraphConversionException(""String_Node_Str"" + jobVertex.getName() + ""String_Node_Str""+ maximumNumberOfSubtasks);
      }
    }
  }
  if (jobVertex.getNumberOfSubtasksPerInstance() != -1 && jobVertex.getNumberOfSubtasksPerInstance() < 1) {
    throw new GraphConversionException(""String_Node_Str"" + jobVertex.getNumberOfSubtasksPerInstance() + ""String_Node_Str""+ jobVertex.getName());
  }
  groupVertex.setMinMemberSize(minimumNumberOfSubtasks);
  groupVertex.setMaxMemberSize(maximumNumberOfSubtasks);
  if (jobVertex instanceof AbstractJobInputVertex) {
    final InputSplit[] inputSplits;
    if (groupVertex.getEnvironment().getInvokable() instanceof AbstractInputTask) {
      try {
        inputSplits=((AbstractInputTask<?>)groupVertex.getEnvironment().getInvokable()).computeInputSplits(jobVertex.getNumberOfSubtasks());
      }
 catch (      Exception e) {
        throw new GraphConversionException(""String_Node_Str"" + groupVertex.getName() + ""String_Node_Str""+ StringUtils.stringifyException(e));
      }
    }
 else {
      throw new GraphConversionException(""String_Node_Str"");
    }
    if (inputSplits == null) {
      LOG.info(""String_Node_Str"" + jobVertex.getName() + ""String_Node_Str"");
    }
 else {
      LOG.info(""String_Node_Str"" + jobVertex.getName() + ""String_Node_Str""+ inputSplits.length+ ""String_Node_Str"");
    }
    groupVertex.setInputSplits(inputSplits);
  }
  if (jobVertex instanceof JobFileOutputVertex) {
    final JobFileOutputVertex jbov=(JobFileOutputVertex)jobVertex;
    jobVertex.getConfiguration().setString(""String_Node_Str"",jbov.getFilePath().toString());
  }
  initialExecutionStage.addStageMember(groupVertex);
  final ExecutionVertex ev=new ExecutionVertex(this,groupVertex,jobVertex.getNumberOfForwardConnections(),jobVertex.getNumberOfBackwardConnections());
  ev.setAllocatedResource(new AllocatedResource(DummyInstance.createDummyInstance(instanceType),instanceType,null));
  return ev;
}",0.9875603416264388
55261,"/** 
 * Creates the initial execution vertices managed by this group vertex.
 * @param initialNumberOfVertices the initial number of execution vertices
 * @throws GraphConversionException thrown if the number of execution vertices for this group vertex cannot be set to the desired value
 */
void createInitialExecutionVertices(final int initalNumberOfVertices) throws GraphConversionException {
  if (initalNumberOfVertices == this.getCurrentNumberOfGroupMembers()) {
    return;
  }
  if (this.getCurrentNumberOfGroupMembers() != 1) {
    throw new IllegalStateException(""String_Node_Str"");
  }
  if (this.userDefinedNumberOfMembers != -1) {
    if (this.userDefinedNumberOfMembers == getCurrentNumberOfGroupMembers()) {
      throw new GraphConversionException(""String_Node_Str"");
    }
  }
  if (initalNumberOfVertices < this.getMinimumNumberOfGroupMember()) {
    throw new GraphConversionException(""String_Node_Str"" + this.getMinimumNumberOfGroupMember());
  }
  if ((this.getMaximumNumberOfGroupMembers() != -1) && (initalNumberOfVertices > this.getMaximumNumberOfGroupMembers())) {
    throw new GraphConversionException(""String_Node_Str"" + this.getMaximumNumberOfGroupMembers());
  }
  final ExecutionVertex originalVertex=this.getGroupMember(0);
  int currentNumberOfExecutionVertices=this.getCurrentNumberOfGroupMembers();
  while (currentNumberOfExecutionVertices++ < initalNumberOfVertices) {
    final ExecutionVertex vertex=originalVertex.splitVertex();
    vertex.setAllocatedResource(new AllocatedResource(DummyInstance.createDummyInstance(this.instanceType),this.instanceType,null));
    this.groupMembers.add(vertex);
  }
  int index=0;
  final Iterator<ExecutionVertex> it=this.groupMembers.iterator();
  while (it.hasNext()) {
    final ExecutionVertex vertex=it.next();
    vertex.setIndexInVertexGroup(index++);
  }
}","/** 
 * Creates the initial execution vertices managed by this group vertex.
 * @param initialNumberOfVertices the initial number of execution vertices
 * @throws GraphConversionException thrown if the number of execution vertices for this group vertex cannot be set to the desired value
 */
void createInitialExecutionVertices(final int initalNumberOfVertices) throws GraphConversionException {
  if (initalNumberOfVertices == this.getCurrentNumberOfGroupMembers()) {
    return;
  }
  if (this.getCurrentNumberOfGroupMembers() != 1) {
    throw new IllegalStateException(""String_Node_Str"");
  }
  if (this.userDefinedNumberOfMembers != -1 && this.userDefinedNumberOfMembers == getCurrentNumberOfGroupMembers()) {
    throw new GraphConversionException(""String_Node_Str"");
  }
  if (initalNumberOfVertices < this.getMinimumNumberOfGroupMember()) {
    throw new GraphConversionException(""String_Node_Str"" + this.getMinimumNumberOfGroupMember());
  }
  if ((this.getMaximumNumberOfGroupMembers() != -1) && (initalNumberOfVertices > this.getMaximumNumberOfGroupMembers())) {
    throw new GraphConversionException(""String_Node_Str"" + this.getMaximumNumberOfGroupMembers());
  }
  final ExecutionVertex originalVertex=this.getGroupMember(0);
  int currentNumberOfExecutionVertices=this.getCurrentNumberOfGroupMembers();
  while (currentNumberOfExecutionVertices++ < initalNumberOfVertices) {
    final ExecutionVertex vertex=originalVertex.splitVertex();
    vertex.setAllocatedResource(new AllocatedResource(DummyInstance.createDummyInstance(this.instanceType),this.instanceType,null));
    this.groupMembers.add(vertex);
  }
  int index=0;
  final Iterator<ExecutionVertex> it=this.groupMembers.iterator();
  while (it.hasNext()) {
    final ExecutionVertex vertex=it.next();
    vertex.setIndexInVertexGroup(index++);
  }
}",0.9934497816593888
55262,"/** 
 * Submits the job assigned to this job client to the job manager.
 * @return a <code>JobSubmissionResult</code> object encapsulating the results of the job submission
 * @throws IOException thrown in case of submission errors while transmitting the data to the job manager
 */
public JobSubmissionResult submitJob() throws IOException {
synchronized (this.jobSubmitClient) {
    return this.jobSubmitClient.submitJob(this.jobGraph);
  }
}","/** 
 * Submits the job assigned to this job client to the job manager.
 * @return a <code>JobSubmissionResult</code> object encapsulating the results of the job submission
 * @throws IOException thrown in case of submission errors while transmitting the data to the job manager
 */
public JobSubmissionResult submitJob() throws IOException {
  return this.jobSubmitClient.submitJob(this.jobGraph);
}",0.9478672985781992
55263,"/** 
 * Cancels the job assigned to this job client.
 * @return a <code>JobCancelResult</code> object encapsulating the result of the job cancel request
 * @throws IOException thrown if an error occurred while transmitting the request to the job manager
 */
public JobCancelResult cancelJob() throws IOException {
synchronized (this.jobSubmitClient) {
    return this.jobSubmitClient.cancelJob(this.jobGraph.getJobID());
  }
}","/** 
 * Cancels the job assigned to this job client.
 * @return a <code>JobCancelResult</code> object encapsulating the result of the job cancel request
 * @throws IOException thrown if an error occurred while transmitting the request to the job manager
 */
public JobCancelResult cancelJob() throws IOException {
  return this.jobSubmitClient.cancelJob(this.jobGraph.getJobID());
}",0.9455445544554456
55264,"/** 
 * Retrieves the current status of the job assigned to this job client.
 * @return a <code>JobProgressResult</code> object including the current job progress
 * @throws IOException thrown if an error occurred while transmitting the request
 */
public JobProgressResult getJobProgress() throws IOException {
synchronized (this.jobSubmitClient) {
    return this.jobSubmitClient.getJobProgress(this.jobGraph.getJobID());
  }
}","/** 
 * Retrieves the current status of the job assigned to this job client.
 * @return a <code>JobProgressResult</code> object including the current job progress
 * @throws IOException thrown if an error occurred while transmitting the request
 */
public JobProgressResult getJobProgress() throws IOException {
  return this.jobSubmitClient.getJobProgress(this.jobGraph.getJobID());
}",0.945945945945946
55265,"/** 
 * Submits the job assigned to this job client to the job manager and queries the job manager about the progress of the job until it is either finished or aborted.
 * @return the duration of the job execution in milliseconds
 * @throws IOException thrown if an error occurred while transmitting the request
 * @throws JobExecutionException thrown if the job has been aborted either by the user or as a result of an error
 */
public long submitJobAndWait() throws IOException, JobExecutionException {
synchronized (this.jobSubmitClient) {
    final JobSubmissionResult submissionResult=this.jobSubmitClient.submitJob(this.jobGraph);
    if (submissionResult.getReturnCode() == AbstractJobResult.ReturnCode.ERROR) {
      LOG.error(""String_Node_Str"" + submissionResult.getDescription());
      throw new JobExecutionException(submissionResult.getDescription(),false);
    }
    Runtime.getRuntime().addShutdownHook(this.jobCleanUp);
  }
  long sleep=0;
  try {
    final int interval=this.jobSubmitClient.getRecommendedPollingInterval();
    sleep=interval * 1000;
  }
 catch (  IOException ioe) {
    Runtime.getRuntime().removeShutdownHook(this.jobCleanUp);
    throw ioe;
  }
  try {
    Thread.sleep(sleep / 2);
  }
 catch (  InterruptedException e) {
    Runtime.getRuntime().removeShutdownHook(this.jobCleanUp);
    logErrorAndRethrow(StringUtils.stringifyException(e));
  }
  long startTimestamp=-1;
  while (true) {
    if (Thread.interrupted()) {
      logErrorAndRethrow(""String_Node_Str"");
    }
    JobProgressResult jobProgressResult=null;
    try {
      jobProgressResult=getJobProgress();
    }
 catch (    IOException ioe) {
      Runtime.getRuntime().removeShutdownHook(this.jobCleanUp);
      throw ioe;
    }
    if (jobProgressResult == null) {
      logErrorAndRethrow(""String_Node_Str"");
    }
    if (jobProgressResult.getReturnCode() == AbstractJobResult.ReturnCode.ERROR) {
      logErrorAndRethrow(""String_Node_Str"" + jobProgressResult.getDescription());
    }
    final Iterator<AbstractEvent> it=jobProgressResult.getEvents();
    while (it.hasNext()) {
      final AbstractEvent event=it.next();
      if (this.lastProcessedEventSequenceNumber >= event.getSequenceNumber()) {
        continue;
      }
      System.out.println(event.toString());
      this.lastProcessedEventSequenceNumber=event.getSequenceNumber();
      if (event instanceof JobEvent) {
        final JobEvent jobEvent=(JobEvent)event;
        final JobStatus jobStatus=jobEvent.getCurrentJobStatus();
        if (jobStatus == JobStatus.SCHEDULED) {
          startTimestamp=jobEvent.getTimestamp();
        }
        if (jobStatus == JobStatus.FINISHED) {
          Runtime.getRuntime().removeShutdownHook(this.jobCleanUp);
          final long jobDuration=jobEvent.getTimestamp() - startTimestamp;
          System.out.println(""String_Node_Str"" + jobDuration);
          return jobDuration;
        }
 else         if (jobStatus == JobStatus.CANCELED || jobStatus == JobStatus.FAILED) {
          Runtime.getRuntime().removeShutdownHook(this.jobCleanUp);
          LOG.info(jobEvent.getOptionalMessage());
          if (jobStatus == JobStatus.CANCELED) {
            throw new JobExecutionException(jobEvent.getOptionalMessage(),true);
          }
 else {
            throw new JobExecutionException(jobEvent.getOptionalMessage(),false);
          }
        }
      }
    }
    try {
      Thread.sleep(sleep);
    }
 catch (    InterruptedException e) {
      logErrorAndRethrow(StringUtils.stringifyException(e));
    }
  }
}","/** 
 * Submits the job assigned to this job client to the job manager and queries the job manager about the progress of the job until it is either finished or aborted.
 * @return the duration of the job execution in milliseconds
 * @throws IOException thrown if an error occurred while transmitting the request
 * @throws JobExecutionException thrown if the job has been aborted either by the user or as a result of an error
 */
public long submitJobAndWait() throws IOException, JobExecutionException {
  final JobSubmissionResult submissionResult=this.jobSubmitClient.submitJob(this.jobGraph);
  if (submissionResult.getReturnCode() == AbstractJobResult.ReturnCode.ERROR) {
    LOG.error(""String_Node_Str"" + submissionResult.getDescription());
    throw new JobExecutionException(submissionResult.getDescription(),false);
  }
  Runtime.getRuntime().addShutdownHook(this.jobCleanUp);
  long sleep=0;
  try {
    final int interval=this.jobSubmitClient.getRecommendedPollingInterval();
    sleep=interval * 1000;
  }
 catch (  IOException ioe) {
    Runtime.getRuntime().removeShutdownHook(this.jobCleanUp);
    throw ioe;
  }
  try {
    Thread.sleep(sleep / 2);
  }
 catch (  InterruptedException e) {
    Runtime.getRuntime().removeShutdownHook(this.jobCleanUp);
    logErrorAndRethrow(StringUtils.stringifyException(e));
  }
  long startTimestamp=-1;
  while (true) {
    if (Thread.interrupted()) {
      logErrorAndRethrow(""String_Node_Str"");
    }
    JobProgressResult jobProgressResult=null;
    try {
      jobProgressResult=getJobProgress();
    }
 catch (    IOException ioe) {
      Runtime.getRuntime().removeShutdownHook(this.jobCleanUp);
      throw ioe;
    }
    if (jobProgressResult == null) {
      logErrorAndRethrow(""String_Node_Str"");
    }
    if (jobProgressResult.getReturnCode() == AbstractJobResult.ReturnCode.ERROR) {
      logErrorAndRethrow(""String_Node_Str"" + jobProgressResult.getDescription());
    }
    final Iterator<AbstractEvent> it=jobProgressResult.getEvents();
    while (it.hasNext()) {
      final AbstractEvent event=it.next();
      if (this.lastProcessedEventSequenceNumber >= event.getSequenceNumber()) {
        continue;
      }
      System.out.println(event.toString());
      this.lastProcessedEventSequenceNumber=event.getSequenceNumber();
      if (event instanceof JobEvent) {
        final JobEvent jobEvent=(JobEvent)event;
        final JobStatus jobStatus=jobEvent.getCurrentJobStatus();
        if (jobStatus == JobStatus.SCHEDULED) {
          startTimestamp=jobEvent.getTimestamp();
        }
        if (jobStatus == JobStatus.FINISHED) {
          close();
          Runtime.getRuntime().removeShutdownHook(this.jobCleanUp);
          final long jobDuration=jobEvent.getTimestamp() - startTimestamp;
          System.out.println(""String_Node_Str"" + jobDuration);
          return jobDuration;
        }
 else         if (jobStatus == JobStatus.CANCELED || jobStatus == JobStatus.FAILED) {
          close();
          Runtime.getRuntime().removeShutdownHook(this.jobCleanUp);
          LOG.info(jobEvent.getOptionalMessage());
          if (jobStatus == JobStatus.CANCELED) {
            throw new JobExecutionException(jobEvent.getOptionalMessage(),true);
          }
 else {
            throw new JobExecutionException(jobEvent.getOptionalMessage(),false);
          }
        }
      }
    }
    try {
      Thread.sleep(sleep);
    }
 catch (    InterruptedException e) {
      logErrorAndRethrow(StringUtils.stringifyException(e));
    }
  }
}",0.9721827987510644
55266,"/** 
 * Closes the <code>JobClient</code> by destroying the RPC stub object.
 */
public void close(){
synchronized (this.rpcService) {
    this.rpcService.shutDown();
  }
}","/** 
 * Closes the <code>JobClient</code> by destroying the RPC stub object.
 */
public void close(){
  this.rpcService.shutDown();
}",0.8721311475409836
55267,"/** 
 * Returns the recommended interval in seconds in which a client is supposed to poll for progress information.
 * @return the interval in seconds
 * @throws IOException thrown if an error occurred while transmitting the request
 */
public int getRecommendedPollingInterval() throws IOException {
synchronized (this.jobSubmitClient) {
    return this.jobSubmitClient.getRecommendedPollingInterval();
  }
}","/** 
 * Returns the recommended interval in seconds in which a client is supposed to poll for progress information.
 * @return the interval in seconds
 * @throws IOException thrown if an error occurred while transmitting the request
 */
public int getRecommendedPollingInterval() throws IOException {
  return this.jobSubmitClient.getRecommendedPollingInterval();
}",0.9431524547803618
55268,"/** 
 * Converts the timestamp of an event from its ""milliseconds since beginning the epoch"" representation into a unified string representation.
 * @param timestamp the timestamp in milliseconds since the beginning of ""the epoch""
 * @return the string unified representation of the timestamp
 */
public static String timestampToString(final long timestamp){
  return DATA_FORMATTER.format(new Date(timestamp));
}","/** 
 * Converts the timestamp of an event from its ""milliseconds since beginning the epoch"" representation into a unified string representation.
 * @param timestamp the timestamp in milliseconds since the beginning of ""the epoch""
 * @return the string unified representation of the timestamp
 */
public static String timestampToString(final long timestamp){
  return DATA_FORMATTER.get().format(new Date(timestamp));
}",0.9927884615384616
55269,"/** 
 * {@inheritDoc}
 */
@Override public void read(final Kryo kryo,final Input input){
  this.jobID=kryo.readObject(input,JobID.class);
  this.jobName=input.readString();
  try {
    readRequiredJarFiles(kryo,input);
  }
 catch (  IOException ioe) {
    new RuntimeException(ioe);
  }
  final int numVertices=input.readInt();
  for (int i=0; i < numVertices; i++) {
    final String className=input.readString();
    final JobVertexID id=kryo.readObject(input,JobVertexID.class);
    final String vertexName=input.readString();
    Class<? extends Record> c;
    try {
      c=ClassUtils.getRecordByName(className);
    }
 catch (    ClassNotFoundException cnfe) {
      throw new RuntimeException(cnfe.toString());
    }
    Constructor<? extends Record> cst;
    try {
      cst=c.getConstructor(String.class,JobVertexID.class,JobGraph.class);
      cst.newInstance(vertexName,id,this);
    }
 catch (    Exception e) {
      throw new RuntimeException(e.toString());
    }
  }
  for (int i=0; i < numVertices; i++) {
    AbstractJobVertex jv;
    final JobVertexID tmpID=kryo.readObject(input,JobVertexID.class);
    if (inputVertices.containsKey(tmpID)) {
      jv=inputVertices.get(tmpID);
    }
 else {
      if (outputVertices.containsKey(tmpID)) {
        jv=outputVertices.get(tmpID);
      }
 else {
        if (taskVertices.containsKey(tmpID)) {
          jv=taskVertices.get(tmpID);
        }
 else {
          throw new IllegalStateException(""String_Node_Str"" + tmpID + ""String_Node_Str"");
        }
      }
    }
    jv.read(kryo,input);
  }
  ClassLoader cl=null;
  try {
    cl=LibraryCacheManager.getClassLoader(this.jobID);
  }
 catch (  IOException ioe) {
    throw new RuntimeException(""String_Node_Str"" + StringUtils.stringifyException(ioe));
  }
  this.jobConfiguration=new Configuration(cl);
  this.jobConfiguration.read(kryo,input);
  this.taskManagerConfiguration.read(kryo,input);
}","/** 
 * {@inheritDoc}
 */
@Override public void read(final Kryo kryo,final Input input){
  this.jobID=kryo.readObject(input,JobID.class);
  this.jobName=input.readString();
  try {
    readRequiredJarFiles(kryo,input);
  }
 catch (  IOException ioe) {
    throw new RuntimeException(ioe);
  }
  final int numVertices=input.readInt();
  for (int i=0; i < numVertices; i++) {
    final String className=input.readString();
    final JobVertexID id=kryo.readObject(input,JobVertexID.class);
    final String vertexName=input.readString();
    Class<? extends Record> c;
    try {
      c=ClassUtils.getRecordByName(className);
    }
 catch (    ClassNotFoundException cnfe) {
      throw new RuntimeException(cnfe.toString());
    }
    Constructor<? extends Record> cst;
    try {
      cst=c.getConstructor(String.class,JobVertexID.class,JobGraph.class);
      cst.newInstance(vertexName,id,this);
    }
 catch (    Exception e) {
      throw new RuntimeException(e.toString());
    }
  }
  for (int i=0; i < numVertices; i++) {
    AbstractJobVertex jv;
    final JobVertexID tmpID=kryo.readObject(input,JobVertexID.class);
    if (inputVertices.containsKey(tmpID)) {
      jv=inputVertices.get(tmpID);
    }
 else {
      if (outputVertices.containsKey(tmpID)) {
        jv=outputVertices.get(tmpID);
      }
 else {
        if (taskVertices.containsKey(tmpID)) {
          jv=taskVertices.get(tmpID);
        }
 else {
          throw new IllegalStateException(""String_Node_Str"" + tmpID + ""String_Node_Str"");
        }
      }
    }
    jv.read(kryo,input);
  }
  ClassLoader cl=null;
  try {
    cl=LibraryCacheManager.getClassLoader(this.jobID);
  }
 catch (  IOException ioe) {
    throw new RuntimeException(""String_Node_Str"" + StringUtils.stringifyException(ioe));
  }
  this.jobConfiguration=new Configuration(cl);
  this.jobConfiguration.read(kryo,input);
  this.taskManagerConfiguration.read(kryo,input);
}",0.9984317825405122
55270,"/** 
 * Auxiliary method implementing Tarjan's algorithm for strongly-connected components to determine whether the job graph is acyclic.
 */
private boolean tarjan(final AbstractJobVertex jv,Integer index,final HashMap<AbstractJobVertex,Integer> indexMap,final HashMap<AbstractJobVertex,Integer> lowLinkMap,final Stack<AbstractJobVertex> stack){
  indexMap.put(jv,Integer.valueOf(index));
  lowLinkMap.put(jv,Integer.valueOf(index));
  index=Integer.valueOf(index.intValue() + 1);
  stack.push(jv);
  for (int i=0; i < jv.getNumberOfForwardConnections(); i++) {
    final AbstractJobVertex jv2=jv.getForwardConnection(i).getConnectedVertex();
    if (!indexMap.containsKey(jv2) || stack.contains(jv2)) {
      if (!indexMap.containsKey(jv2)) {
        if (!tarjan(jv2,index,indexMap,lowLinkMap,stack)) {
          return false;
        }
      }
      if (lowLinkMap.get(jv) > lowLinkMap.get(jv2)) {
        lowLinkMap.put(jv,Integer.valueOf(lowLinkMap.get(jv2)));
      }
    }
  }
  if (lowLinkMap.get(jv).equals(indexMap.get(jv))) {
    int count=0;
    while (stack.size() > 0) {
      final AbstractJobVertex jv2=stack.pop();
      if (jv == jv2) {
        break;
      }
      count++;
    }
    if (count > 0) {
      return false;
    }
  }
  return true;
}","/** 
 * Auxiliary method implementing Tarjan's algorithm for strongly-connected components to determine whether the job graph is acyclic.
 */
private boolean tarjan(final AbstractJobVertex jv,Integer index,final HashMap<AbstractJobVertex,Integer> indexMap,final HashMap<AbstractJobVertex,Integer> lowLinkMap,final Stack<AbstractJobVertex> stack){
  indexMap.put(jv,index);
  lowLinkMap.put(jv,index);
  index=Integer.valueOf(index.intValue() + 1);
  stack.push(jv);
  for (int i=0; i < jv.getNumberOfForwardConnections(); i++) {
    final AbstractJobVertex jv2=jv.getForwardConnection(i).getConnectedVertex();
    if (!indexMap.containsKey(jv2) || stack.contains(jv2)) {
      if (!indexMap.containsKey(jv2)) {
        if (!tarjan(jv2,index,indexMap,lowLinkMap,stack)) {
          return false;
        }
      }
      if (lowLinkMap.get(jv) > lowLinkMap.get(jv2)) {
        lowLinkMap.put(jv,lowLinkMap.get(jv2));
      }
    }
  }
  if (lowLinkMap.get(jv).equals(indexMap.get(jv))) {
    int count=0;
    while (stack.size() > 0) {
      final AbstractJobVertex jv2=stack.pop();
      if (jv == jv2) {
        break;
      }
      count++;
    }
    if (count > 0) {
      return false;
    }
  }
  return true;
}",0.9713825070536074
55271,"/** 
 * Loads an XML document of key-values pairs.
 * @param file the XML document file
 */
private void loadResource(final File file){
  final DocumentBuilderFactory docBuilderFactory=DocumentBuilderFactory.newInstance();
  docBuilderFactory.setIgnoringComments(true);
  docBuilderFactory.setNamespaceAware(true);
  try {
    final DocumentBuilder builder=docBuilderFactory.newDocumentBuilder();
    Document doc=null;
    Element root=null;
    doc=builder.parse(file);
    if (doc == null) {
      LOG.warn(""String_Node_Str"");
      return;
    }
    root=doc.getDocumentElement();
    if (root == null) {
      LOG.warn(""String_Node_Str"");
      return;
    }
    if (!""String_Node_Str"".equals(root.getNodeName())) {
      LOG.warn(""String_Node_Str"" + root.getNodeName());
      return;
    }
    final NodeList props=root.getChildNodes();
    int propNumber=-1;
synchronized (this.confData) {
      for (int i=0; i < props.getLength(); i++) {
        final Node propNode=props.item(i);
        String key=null;
        String value=null;
        if (propNode instanceof Text) {
          continue;
        }
        if (!(propNode instanceof Element)) {
          LOG.warn(""String_Node_Str"" + propNode.getNodeName() + ""String_Node_Str"");
          continue;
        }
        Element property=(Element)propNode;
        if (!""String_Node_Str"".equals(property.getNodeName())) {
          LOG.warn(""String_Node_Str"" + property.getNodeName());
          continue;
        }
        propNumber++;
        final NodeList propChildren=property.getChildNodes();
        if (propChildren == null) {
          LOG.warn(""String_Node_Str"");
          continue;
        }
        for (int j=0; j < propChildren.getLength(); j++) {
          final Node propChild=propChildren.item(j);
          if (propChild instanceof Element) {
            if (""String_Node_Str"".equals(propChild.getNodeName())) {
              if (propChild.getChildNodes() != null && propChild.getChildNodes().getLength() == 1) {
                if (propChild.getChildNodes().item(0) instanceof Text) {
                  final Text t=(Text)propChild.getChildNodes().item(0);
                  key=t.getTextContent();
                }
              }
            }
            if (""String_Node_Str"".equals(propChild.getNodeName())) {
              if (propChild.getChildNodes() != null && propChild.getChildNodes().getLength() == 1) {
                if (propChild.getChildNodes().item(0) instanceof Text) {
                  final Text t=(Text)propChild.getChildNodes().item(0);
                  value=t.getTextContent();
                }
              }
            }
          }
        }
        if (key != null && value != null) {
          LOG.debug(""String_Node_Str"" + key + ""String_Node_Str""+ value);
          this.confData.put(key,value);
        }
 else {
          LOG.warn(""String_Node_Str"" + propNumber);
          continue;
        }
      }
    }
  }
 catch (  ParserConfigurationException e) {
    LOG.warn(""String_Node_Str"" + StringUtils.stringifyException(e));
  }
catch (  IOException e) {
    LOG.warn(""String_Node_Str"" + StringUtils.stringifyException(e));
  }
catch (  SAXException e) {
    LOG.warn(""String_Node_Str"" + StringUtils.stringifyException(e));
  }
}","/** 
 * Loads an XML document of key-values pairs.
 * @param file the XML document file
 */
private void loadResource(final File file){
  final DocumentBuilderFactory docBuilderFactory=DocumentBuilderFactory.newInstance();
  docBuilderFactory.setIgnoringComments(true);
  docBuilderFactory.setNamespaceAware(true);
  try {
    final DocumentBuilder builder=docBuilderFactory.newDocumentBuilder();
    Document doc=null;
    Element root=null;
    doc=builder.parse(file);
    if (doc == null) {
      LOG.warn(""String_Node_Str"");
      return;
    }
    root=doc.getDocumentElement();
    if (root == null) {
      LOG.warn(""String_Node_Str"");
      return;
    }
    if (!""String_Node_Str"".equals(root.getNodeName())) {
      LOG.warn(""String_Node_Str"" + root.getNodeName());
      return;
    }
    final NodeList props=root.getChildNodes();
    int propNumber=-1;
synchronized (this.confData) {
      for (int i=0; i < props.getLength(); i++) {
        final Node propNode=props.item(i);
        String key=null;
        String value=null;
        if (propNode instanceof Text) {
          continue;
        }
        if (!(propNode instanceof Element)) {
          LOG.warn(""String_Node_Str"" + propNode.getNodeName() + ""String_Node_Str"");
          continue;
        }
        Element property=(Element)propNode;
        if (!""String_Node_Str"".equals(property.getNodeName())) {
          LOG.warn(""String_Node_Str"" + property.getNodeName());
          continue;
        }
        propNumber++;
        final NodeList propChildren=property.getChildNodes();
        if (propChildren == null) {
          LOG.warn(""String_Node_Str"");
          continue;
        }
        for (int j=0; j < propChildren.getLength(); j++) {
          final Node propChild=propChildren.item(j);
          if (propChild instanceof Element) {
            if (""String_Node_Str"".equals(propChild.getNodeName()) && propChild.getChildNodes() != null && propChild.getChildNodes().getLength() == 1 && propChild.getChildNodes().item(0) instanceof Text) {
              final Text t=(Text)propChild.getChildNodes().item(0);
              key=t.getTextContent();
            }
            if (""String_Node_Str"".equals(propChild.getNodeName()) && propChild.getChildNodes() != null && propChild.getChildNodes().getLength() == 1 && propChild.getChildNodes().item(0) instanceof Text) {
              final Text t=(Text)propChild.getChildNodes().item(0);
              value=t.getTextContent();
            }
          }
        }
        if (key != null && value != null) {
          LOG.debug(""String_Node_Str"" + key + ""String_Node_Str""+ value);
          this.confData.put(key,value);
        }
 else {
          LOG.warn(""String_Node_Str"" + propNumber);
          continue;
        }
      }
    }
  }
 catch (  ParserConfigurationException e) {
    LOG.warn(""String_Node_Str"" + StringUtils.stringifyException(e));
  }
catch (  IOException e) {
    LOG.warn(""String_Node_Str"" + StringUtils.stringifyException(e));
  }
catch (  SAXException e) {
    LOG.warn(""String_Node_Str"" + StringUtils.stringifyException(e));
  }
}",0.8728305459135374
55272,"/** 
 * Constructs a <code>LibraryManagerEntry</code> object from the given job ID and array of required library files.
 * @param id the ID of the job to create a <code>LibraryManagerEntry</code> for.
 * @param requiredJarFiles an array with the names of required libraries by the corresponding job (plain names)
 * @param urls an array with the names of required libraries by the corresponding job (URL objects required by the class loader)
 */
public LibraryManagerEntry(final JobID id,final String[] requiredJarFiles,URL[] urls){
  String[] temp=requiredJarFiles;
  if (temp == null) {
    temp=new String[0];
  }
  this.requiredJarFiles=temp;
  if (urls == null) {
    urls=new URL[0];
  }
  this.classLoader=new URLClassLoader(urls,ClassLoader.getSystemClassLoader());
}","/** 
 * Constructs a <code>LibraryManagerEntry</code> object from the given job ID and array of required library files.
 * @param requiredJarFiles an array with the names of required libraries by the corresponding job (plain names)
 * @param urls an array with the names of required libraries by the corresponding job (URL objects required by the class loader)
 */
public LibraryManagerEntry(final String[] requiredJarFiles,URL[] urls){
  String[] temp=requiredJarFiles;
  if (temp == null) {
    temp=new String[0];
  }
  this.requiredJarFiles=temp;
  if (urls == null) {
    urls=new URL[0];
  }
  this.classLoader=new URLClassLoader(urls,ClassLoader.getSystemClassLoader());
}",0.9339752407152684
55273,"/** 
 * Registers a job ID with a set of library paths that are required to run the job. For every registered job the library cache manager creates a class loader that is used to instantiate the vertex's environment later on.
 * @param id the ID of the job to be registered.
 * @param clientPaths the client path's of the required libraries
 * @throws IOException thrown if one of the requested libraries is not in the cache
 */
private void registerInternal(final JobID id,final String[] requiredJarFiles) throws IOException {
  while (this.lockMap.putIfAbsent(id,LOCK_OBJECT) != null)   ;
  try {
    if (incrementReferenceCounter(id) > 1) {
      return;
    }
    if (this.libraryManagerEntries.containsKey(id)) {
      throw new IllegalStateException(""String_Node_Str"" + id);
    }
    URL[] urls=null;
    if (requiredJarFiles != null) {
      urls=new URL[requiredJarFiles.length];
      for (int i=0; i < requiredJarFiles.length; i++) {
        final Path p=contains(requiredJarFiles[i]);
        if (p == null) {
          throw new IOException(requiredJarFiles[i] + ""String_Node_Str"");
        }
        try {
          urls[i]=p.toUri().toURL();
        }
 catch (        MalformedURLException e) {
          throw new IOException(StringUtils.stringifyException(e));
        }
      }
    }
    final LibraryManagerEntry entry=new LibraryManagerEntry(id,requiredJarFiles,urls);
    this.libraryManagerEntries.put(id,entry);
  }
  finally {
    this.lockMap.remove(id);
  }
}","/** 
 * Registers a job ID with a set of library paths that are required to run the job. For every registered job the library cache manager creates a class loader that is used to instantiate the vertex's environment later on.
 * @param id the ID of the job to be registered.
 * @param clientPaths the client path's of the required libraries
 * @throws IOException thrown if one of the requested libraries is not in the cache
 */
private void registerInternal(final JobID id,final String[] requiredJarFiles) throws IOException {
  while (this.lockMap.putIfAbsent(id,LOCK_OBJECT) != null)   ;
  try {
    if (incrementReferenceCounter(id) > 1) {
      return;
    }
    if (this.libraryManagerEntries.containsKey(id)) {
      throw new IllegalStateException(""String_Node_Str"" + id);
    }
    URL[] urls=null;
    if (requiredJarFiles != null) {
      urls=new URL[requiredJarFiles.length];
      for (int i=0; i < requiredJarFiles.length; i++) {
        final Path p=contains(requiredJarFiles[i]);
        if (p == null) {
          throw new IOException(requiredJarFiles[i] + ""String_Node_Str"");
        }
        try {
          urls[i]=p.toUri().toURL();
        }
 catch (        MalformedURLException e) {
          throw new IOException(StringUtils.stringifyException(e));
        }
      }
    }
    final LibraryManagerEntry entry=new LibraryManagerEntry(requiredJarFiles,urls);
    this.libraryManagerEntries.put(id,entry);
  }
  finally {
    this.lockMap.remove(id);
  }
}",0.9989888776541962
55274,"/** 
 * Creates a random byte sequence using the provided   {@code random} generator and returns its hex representation.
 * @param random The random number generator to be used.
 * @return A hex representation of the generated byte sequence
 */
private static final String randomString(final Random random){
  final byte[] bytes=new byte[RANDOM_BYTES_LENGTH];
  random.nextBytes(bytes);
  return StringUtils.byteToHexString(bytes);
}","/** 
 * Creates a random byte sequence using the provided   {@code random} generator and returns its hex representation.
 * @param random The random number generator to be used.
 * @return A hex representation of the generated byte sequence
 */
private static String randomString(final Random random){
  final byte[] bytes=new byte[RANDOM_BYTES_LENGTH];
  random.nextBytes(bytes);
  return StringUtils.byteToHexString(bytes);
}",0.9930232558139536
55275,"private void ensureAvailable(final int numberOfBytes) throws IOException {
  if (this.buf.capacity() < numberOfBytes) {
    final ByteBuffer newBuf=ByteBuffer.allocate(numberOfBytes);
    newBuf.put(this.buf);
    newBuf.flip();
    this.buf=newBuf;
  }
  final int remaining=this.buf.remaining();
  if (remaining < numberOfBytes) {
    final int offset=this.buf.position();
    if (offset > 0) {
      for (int i=0; i < remaining; ++i) {
        this.buf.put(i,this.buf.get(offset + i));
      }
    }
    this.buf.position(remaining);
    this.buf.limit(this.buf.capacity());
    final int read=this.readableByteChannel.read(this.buf);
    this.buf.flip();
  }
}","private void ensureAvailable(final int numberOfBytes) throws IOException {
  if (this.buf.capacity() < numberOfBytes) {
    final ByteBuffer newBuf=ByteBuffer.allocate(numberOfBytes);
    newBuf.put(this.buf);
    newBuf.flip();
    this.buf=newBuf;
  }
  int remaining=this.buf.remaining();
  while (remaining < numberOfBytes) {
    final int offset=this.buf.position();
    if (offset > 0) {
      for (int i=0; i < remaining; ++i) {
        this.buf.put(i,this.buf.get(offset + i));
      }
    }
    this.buf.position(remaining);
    this.buf.limit(this.buf.capacity());
    final int read=this.readableByteChannel.read(this.buf);
    if (read < 0) {
      throw new BufferUnderflowException();
    }
    this.buf.flip();
    remaining=this.buf.remaining();
  }
}",0.8930817610062893
55276,"/** 
 * {@inheritDoc}
 */
@Override public void clear(){
}","/** 
 * {@inheritDoc}
 */
@Override public void clear(){
  this.dataInput=null;
  this.lastReadableByteChannel=null;
}",0.6590909090909091
55277,"/** 
 * Adds the given key/value pair to the configuration object. If either the key or the value is <code>null</code> the pair is not added.
 * @param key the key of the key/value pair to be added
 * @param value the value of the key/value pair to be added
 */
public void setString(final String key,final String value){
  if (key == null || value == null) {
    LOG.warn(""String_Node_Str"" + key + ""String_Node_Str""+ value+ ""String_Node_Str"");
    return;
  }
synchronized (this.confData) {
    this.confData.put(key,value);
  }
}","/** 
 * Adds the given key/value pair to the configuration object. If either the key or the value is <code>null</code> the pair is not added.
 * @param key the key of the key/value pair to be added
 * @param value the value of the key/value pair to be added
 */
public void setString(final String key,final String value){
  if (key == null) {
    throw new NullPointerException(""String_Node_Str"");
  }
  if (value == null) {
    throw new NullPointerException(""String_Node_Str"");
  }
synchronized (this.confData) {
    this.confData.put(key,value);
  }
}",0.7225806451612903
55278,"/** 
 * Loads an XML document of key-values pairs.
 * @param file the XML document file
 */
private void loadResource(final File file){
  final DocumentBuilderFactory docBuilderFactory=DocumentBuilderFactory.newInstance();
  docBuilderFactory.setIgnoringComments(true);
  docBuilderFactory.setNamespaceAware(true);
  try {
    final DocumentBuilder builder=docBuilderFactory.newDocumentBuilder();
    Document doc=null;
    Element root=null;
    doc=builder.parse(file);
    if (doc == null) {
      LOG.warn(""String_Node_Str"");
      return;
    }
    root=doc.getDocumentElement();
    if (root == null) {
      LOG.warn(""String_Node_Str"");
      return;
    }
    if (!""String_Node_Str"".equals(root.getNodeName())) {
      LOG.warn(""String_Node_Str"" + root.getNodeName());
      return;
    }
    final NodeList props=root.getChildNodes();
    int propNumber=-1;
synchronized (this.confData) {
      for (int i=0; i < props.getLength(); i++) {
        final Node propNode=props.item(i);
        String key=null;
        String value=null;
        if (propNode instanceof Text) {
          continue;
        }
        if (!(propNode instanceof Element)) {
          LOG.warn(""String_Node_Str"" + propNode.getNodeName() + ""String_Node_Str"");
          continue;
        }
        Element property=(Element)propNode;
        if (!""String_Node_Str"".equals(property.getNodeName())) {
          LOG.warn(""String_Node_Str"" + property.getNodeName());
          continue;
        }
        propNumber++;
        final NodeList propChildren=property.getChildNodes();
        if (propChildren == null) {
          LOG.warn(""String_Node_Str"");
          continue;
        }
        for (int j=0; j < propChildren.getLength(); j++) {
          final Node propChild=propChildren.item(j);
          if (propChild instanceof Element) {
            if (""String_Node_Str"".equals(propChild.getNodeName())) {
              if (propChild.getChildNodes() != null) {
                if (propChild.getChildNodes().getLength() == 1) {
                  if (propChild.getChildNodes().item(0) instanceof Text) {
                    final Text t=(Text)propChild.getChildNodes().item(0);
                    key=t.getTextContent();
                  }
                }
              }
            }
            if (""String_Node_Str"".equals(propChild.getNodeName())) {
              if (propChild.getChildNodes() != null) {
                if (propChild.getChildNodes().getLength() == 1) {
                  if (propChild.getChildNodes().item(0) instanceof Text) {
                    final Text t=(Text)propChild.getChildNodes().item(0);
                    value=t.getTextContent();
                  }
                }
              }
            }
          }
        }
        if (key != null && value != null) {
          LOG.debug(""String_Node_Str"" + key + ""String_Node_Str""+ value);
          this.confData.put(key,value);
        }
 else {
          LOG.warn(""String_Node_Str"" + propNumber);
          continue;
        }
      }
    }
  }
 catch (  ParserConfigurationException e) {
    LOG.warn(""String_Node_Str"" + StringUtils.stringifyException(e));
  }
catch (  IOException e) {
    LOG.warn(""String_Node_Str"" + StringUtils.stringifyException(e));
  }
catch (  SAXException e) {
    LOG.warn(""String_Node_Str"" + StringUtils.stringifyException(e));
  }
}","/** 
 * Loads an XML document of key-values pairs.
 * @param file the XML document file
 */
private void loadResource(final File file){
  final DocumentBuilderFactory docBuilderFactory=DocumentBuilderFactory.newInstance();
  docBuilderFactory.setIgnoringComments(true);
  docBuilderFactory.setNamespaceAware(true);
  try {
    final DocumentBuilder builder=docBuilderFactory.newDocumentBuilder();
    Document doc=null;
    Element root=null;
    doc=builder.parse(file);
    if (doc == null) {
      LOG.warn(""String_Node_Str"");
      return;
    }
    root=doc.getDocumentElement();
    if (root == null) {
      LOG.warn(""String_Node_Str"");
      return;
    }
    if (!""String_Node_Str"".equals(root.getNodeName())) {
      LOG.warn(""String_Node_Str"" + root.getNodeName());
      return;
    }
    final NodeList props=root.getChildNodes();
    int propNumber=-1;
synchronized (this.confData) {
      for (int i=0; i < props.getLength(); i++) {
        final Node propNode=props.item(i);
        String key=null;
        String value=null;
        if (propNode instanceof Text) {
          continue;
        }
        if (!(propNode instanceof Element)) {
          LOG.warn(""String_Node_Str"" + propNode.getNodeName() + ""String_Node_Str"");
          continue;
        }
        Element property=(Element)propNode;
        if (!""String_Node_Str"".equals(property.getNodeName())) {
          LOG.warn(""String_Node_Str"" + property.getNodeName());
          continue;
        }
        propNumber++;
        final NodeList propChildren=property.getChildNodes();
        if (propChildren == null) {
          LOG.warn(""String_Node_Str"");
          continue;
        }
        for (int j=0; j < propChildren.getLength(); j++) {
          final Node propChild=propChildren.item(j);
          if (propChild instanceof Element) {
            if (""String_Node_Str"".equals(propChild.getNodeName())) {
              if (propChild.getChildNodes() != null && propChild.getChildNodes().getLength() == 1) {
                if (propChild.getChildNodes().item(0) instanceof Text) {
                  final Text t=(Text)propChild.getChildNodes().item(0);
                  key=t.getTextContent();
                }
              }
            }
            if (""String_Node_Str"".equals(propChild.getNodeName())) {
              if (propChild.getChildNodes() != null && propChild.getChildNodes().getLength() == 1) {
                if (propChild.getChildNodes().item(0) instanceof Text) {
                  final Text t=(Text)propChild.getChildNodes().item(0);
                  value=t.getTextContent();
                }
              }
            }
          }
        }
        if (key != null && value != null) {
          LOG.debug(""String_Node_Str"" + key + ""String_Node_Str""+ value);
          this.confData.put(key,value);
        }
 else {
          LOG.warn(""String_Node_Str"" + propNumber);
          continue;
        }
      }
    }
  }
 catch (  ParserConfigurationException e) {
    LOG.warn(""String_Node_Str"" + StringUtils.stringifyException(e));
  }
catch (  IOException e) {
    LOG.warn(""String_Node_Str"" + StringUtils.stringifyException(e));
  }
catch (  SAXException e) {
    LOG.warn(""String_Node_Str"" + StringUtils.stringifyException(e));
  }
}",0.8676783004552352
55279,"@Override public final boolean next(final T target) throws IOException, InterruptedException {
  while (true) {
    if (this.inputGates.isEmpty()) {
      return false;
    }
    if (this.nextInputGateToReadFrom == null) {
synchronized (this.availableInputGates) {
        while (this.availableInputGates.isEmpty()) {
          this.availableInputGates.wait();
        }
        this.nextInputGateToReadFrom=this.availableInputGates.pop();
      }
    }
    if (this.nextInputGateToReadFrom.hasRecordAvailable()) {
      final T record=this.nextInputGateToReadFrom.readRecord(target);
      if (record == null) {
        this.inputGates.remove(this.nextInputGateToReadFrom);
        this.nextInputGateToReadFrom=null;
      }
 else {
        return true;
      }
    }
 else {
      this.nextInputGateToReadFrom=null;
    }
  }
}","@Override public boolean next(final T target) throws IOException, InterruptedException {
  while (true) {
    if (this.inputGates.isEmpty()) {
      return false;
    }
    if (this.nextInputGateToReadFrom == null) {
synchronized (this.availableInputGates) {
        while (this.availableInputGates.isEmpty()) {
          this.availableInputGates.wait();
        }
        this.nextInputGateToReadFrom=this.availableInputGates.pop();
      }
    }
    if (this.nextInputGateToReadFrom.hasRecordAvailable()) {
      final T record=this.nextInputGateToReadFrom.readRecord(target);
      if (record == null) {
        this.inputGates.remove(this.nextInputGateToReadFrom);
        this.nextInputGateToReadFrom=null;
      }
 else {
        return true;
      }
    }
 else {
      this.nextInputGateToReadFrom=null;
    }
  }
}",0.99636803874092
55280,"/** 
 * Writes the JAR files of all vertices in array <code>jobVertices</code> to the specified output stream.
 * @param kryo the kryo object
 * @param out the output stream to write the JAR files to
 * @param jobVertices array of job vertices whose required JAR file are to be written to the output stream
 * @throws IOException thrown if an error occurs while writing to the stream
 */
private void writeRequiredJarFiles(final Kryo kryo,final Output out,final AbstractJobVertex[] jobVertices) throws IOException {
  final FileSystem fs=FileSystem.getLocalFileSystem();
  for (int i=0; i < this.userJars.size(); i++) {
    if (!fs.exists(this.userJars.get(i))) {
      throw new IOException(""String_Node_Str"" + this.userJars.get(i));
    }
  }
  out.writeInt(this.userJars.size());
  for (int i=0; i < this.userJars.size(); i++) {
    final Path jar=this.userJars.get(i);
    jar.write(kryo,out);
    final FileStatus file=fs.getFileStatus(jar);
    out.writeInt((int)file.getLen());
    final FSDataInputStream inStream=fs.open(this.userJars.get(i));
    final byte[] buf=new byte[BUFFERSIZE];
    int read=inStream.read(buf,0,buf.length);
    while (read > 0) {
      out.write(buf,0,read);
      read=inStream.read(buf,0,buf.length);
    }
  }
}","/** 
 * Writes the JAR files of all vertices in array <code>jobVertices</code> to the specified output stream.
 * @param kryo the kryo object
 * @param out the output stream to write the JAR files to
 * @throws IOException thrown if an error occurs while writing to the stream
 */
private void writeRequiredJarFiles(final Kryo kryo,final Output out) throws IOException {
  final FileSystem fs=FileSystem.getLocalFileSystem();
  for (int i=0; i < this.userJars.size(); i++) {
    if (!fs.exists(this.userJars.get(i))) {
      throw new IOException(""String_Node_Str"" + this.userJars.get(i));
    }
  }
  out.writeInt(this.userJars.size());
  for (int i=0; i < this.userJars.size(); i++) {
    final Path jar=this.userJars.get(i);
    jar.write(kryo,out);
    final FileStatus file=fs.getFileStatus(jar);
    out.writeInt((int)file.getLen());
    final FSDataInputStream inStream=fs.open(this.userJars.get(i));
    final byte[] buf=new byte[BUFFERSIZE];
    int read=inStream.read(buf,0,buf.length);
    while (read > 0) {
      out.write(buf,0,read);
      read=inStream.read(buf,0,buf.length);
    }
  }
}",0.9383765405864852
55281,"/** 
 * {@inheritDoc}
 */
@Override public void write(final Kryo kryo,final Output output){
  kryo.writeObject(output,this.jobID);
  output.writeString(this.jobName);
  final AbstractJobVertex[] allVertices=this.getAllJobVertices();
  try {
    writeRequiredJarFiles(kryo,output,allVertices);
  }
 catch (  IOException ioe) {
    throw new RuntimeException(ioe);
  }
  output.writeInt(allVertices.length);
  for (int i=0; i < allVertices.length; i++) {
    final String className=allVertices[i].getClass().getName();
    output.writeString(className);
    kryo.writeObject(output,allVertices[i].getID());
    output.writeString(allVertices[i].getName());
  }
  for (int i=0; i < allVertices.length; i++) {
    kryo.writeObject(output,allVertices[i].getID());
    allVertices[i].write(kryo,output);
  }
  this.jobConfiguration.write(kryo,output);
  this.taskManagerConfiguration.write(kryo,output);
}","/** 
 * {@inheritDoc}
 */
@Override public void write(final Kryo kryo,final Output output){
  kryo.writeObject(output,this.jobID);
  output.writeString(this.jobName);
  final AbstractJobVertex[] allVertices=this.getAllJobVertices();
  try {
    writeRequiredJarFiles(kryo,output);
  }
 catch (  IOException ioe) {
    throw new RuntimeException(ioe);
  }
  output.writeInt(allVertices.length);
  for (int i=0; i < allVertices.length; i++) {
    final String className=allVertices[i].getClass().getName();
    output.writeString(className);
    kryo.writeObject(output,allVertices[i].getID());
    output.writeString(allVertices[i].getName());
  }
  for (int i=0; i < allVertices.length; i++) {
    kryo.writeObject(output,allVertices[i].getID());
    allVertices[i].write(kryo,output);
  }
  this.jobConfiguration.write(kryo,output);
  this.taskManagerConfiguration.write(kryo,output);
}",0.9932810750279956
55282,"/** 
 * Checks if the job graph is acyclic.
 * @return <code>true</code> if the job graph is acyclic, <code>false</code> otherwise
 */
public boolean isAcyclic(){
  final AbstractJobVertex[] reachable=getAllReachableJobVertices();
  final HashMap<AbstractJobVertex,Integer> indexMap=new HashMap<AbstractJobVertex,Integer>();
  final HashMap<AbstractJobVertex,Integer> lowLinkMap=new HashMap<AbstractJobVertex,Integer>();
  final Stack<AbstractJobVertex> stack=new Stack<AbstractJobVertex>();
  final Integer index=Integer.valueOf(0);
  for (int i=0; i < reachable.length; i++) {
    if (!indexMap.containsKey(reachable[i])) {
      if (!tarjan(reachable[i],index,indexMap,lowLinkMap,stack)) {
        return false;
      }
    }
  }
  return true;
}","/** 
 * Checks if the job graph is acyclic.
 * @return <code>true</code> if the job graph is acyclic, <code>false</code> otherwise
 */
public boolean isAcyclic(){
  final AbstractJobVertex[] reachable=getAllReachableJobVertices();
  final HashMap<AbstractJobVertex,Integer> indexMap=new HashMap<AbstractJobVertex,Integer>();
  final HashMap<AbstractJobVertex,Integer> lowLinkMap=new HashMap<AbstractJobVertex,Integer>();
  final Stack<AbstractJobVertex> stack=new Stack<AbstractJobVertex>();
  final Integer index=Integer.valueOf(0);
  for (int i=0; i < reachable.length; i++) {
    if (!indexMap.containsKey(reachable[i]) && !tarjan(reachable[i],index,indexMap,lowLinkMap,stack)) {
      return false;
    }
  }
  return true;
}",0.9634641407307172
55283,"/** 
 * Auxiliary method implementing Tarjan's algorithm for strongly-connected components to determine whether the job graph is acyclic.
 */
private boolean tarjan(final AbstractJobVertex jv,Integer index,final HashMap<AbstractJobVertex,Integer> indexMap,final HashMap<AbstractJobVertex,Integer> lowLinkMap,final Stack<AbstractJobVertex> stack){
  indexMap.put(jv,index);
  lowLinkMap.put(jv,index);
  index=Integer.valueOf(index.intValue() + 1);
  stack.push(jv);
  for (int i=0; i < jv.getNumberOfForwardConnections(); i++) {
    final AbstractJobVertex jv2=jv.getForwardConnection(i).getConnectedVertex();
    if (!indexMap.containsKey(jv2) || stack.contains(jv2)) {
      if (!indexMap.containsKey(jv2)) {
        if (!tarjan(jv2,index,indexMap,lowLinkMap,stack)) {
          return false;
        }
      }
      if (lowLinkMap.get(jv) > lowLinkMap.get(jv2)) {
        lowLinkMap.put(jv,lowLinkMap.get(jv2));
      }
    }
  }
  if (lowLinkMap.get(jv).equals(indexMap.get(jv))) {
    int count=0;
    while (stack.size() > 0) {
      final AbstractJobVertex jv2=stack.pop();
      if (jv == jv2) {
        break;
      }
      count++;
    }
    if (count > 0) {
      return false;
    }
  }
  return true;
}","/** 
 * Auxiliary method implementing Tarjan's algorithm for strongly-connected components to determine whether the job graph is acyclic.
 */
private boolean tarjan(final AbstractJobVertex jv,Integer index,final HashMap<AbstractJobVertex,Integer> indexMap,final HashMap<AbstractJobVertex,Integer> lowLinkMap,final Stack<AbstractJobVertex> stack){
  indexMap.put(jv,index);
  lowLinkMap.put(jv,index);
  index=Integer.valueOf(index.intValue() + 1);
  stack.push(jv);
  for (int i=0; i < jv.getNumberOfForwardConnections(); i++) {
    final AbstractJobVertex jv2=jv.getForwardConnection(i).getConnectedVertex();
    if (!indexMap.containsKey(jv2) || stack.contains(jv2)) {
      if (!indexMap.containsKey(jv2) && !tarjan(jv2,index,indexMap,lowLinkMap,stack)) {
        return false;
      }
      if (lowLinkMap.get(jv) > lowLinkMap.get(jv2)) {
        lowLinkMap.put(jv,lowLinkMap.get(jv2));
      }
    }
  }
  if (lowLinkMap.get(jv).equals(indexMap.get(jv))) {
    int count=0;
    while (stack.size() > 0) {
      final AbstractJobVertex jv2=stack.pop();
      if (jv == jv2) {
        break;
      }
      count++;
    }
    if (count > 0) {
      return false;
    }
  }
  return true;
}",0.975893599334996
55284,"/** 
 * Creates a jar file which contains the previously added class. The content of the jar file is written to <code>outputFile</code> which has been provided to the constructor. If <code>outputFile</code> already exists, it is overwritten by this operation.
 * @throws IOException thrown if an error occurs while writing to the output file
 */
public synchronized void createJarFile() throws IOException {
  final byte[] buf=new byte[128];
  if (this.outputFile == null) {
    throw new IOException(""String_Node_Str"");
  }
  if (this.outputFile.exists()) {
    this.outputFile.delete();
  }
  final JarOutputStream jos=new JarOutputStream(new FileOutputStream(this.outputFile),new Manifest());
  final Iterator<Class<?>> it=this.classSet.iterator();
  while (it.hasNext()) {
    final Class<?> clazz=it.next();
    final String entry=clazz.getName().replace('.','/') + CLASS_EXTENSION;
    jos.putNextEntry(new JarEntry(entry));
    final InputStream classInputStream=clazz.getResourceAsStream(clazz.getSimpleName() + CLASS_EXTENSION);
    int num=classInputStream.read(buf);
    while (num != -1) {
      jos.write(buf,0,num);
      num=classInputStream.read(buf);
    }
    classInputStream.close();
    jos.closeEntry();
  }
  jos.close();
}","/** 
 * Creates a jar file which contains the previously added class. The content of the jar file is written to <code>outputFile</code> which has been provided to the constructor. If <code>outputFile</code> already exists, it is overwritten by this operation.
 * @throws IOException thrown if an error occurs while writing to the output file
 */
public synchronized void createJarFile() throws IOException {
  final byte[] buf=new byte[128];
  if (this.outputFile == null) {
    throw new IOException(""String_Node_Str"");
  }
  if (this.outputFile.exists()) {
    this.outputFile.delete();
  }
  final JarOutputStream jos=new JarOutputStream(new FileOutputStream(this.outputFile),new Manifest());
  final Iterator<Class<?>> it=this.classSet.iterator();
  while (it.hasNext()) {
    final Class<?> clazz=it.next();
    final String entry=clazz.getName().replace('.','/') + CLASS_EXTENSION;
    jos.putNextEntry(new JarEntry(entry));
    InputStream classInputStream=null;
    try {
      classInputStream=clazz.getResourceAsStream(clazz.getSimpleName() + CLASS_EXTENSION);
      int num=classInputStream.read(buf);
      while (num != -1) {
        jos.write(buf,0,num);
        num=classInputStream.read(buf);
      }
      classInputStream.close();
      jos.closeEntry();
    }
  finally {
      CloseableUtils.closeSilently(classInputStream);
    }
  }
  jos.close();
}",0.9476499808941536
55285,"@SuppressWarnings(""String_Node_Str"") private boolean readNotificationList(ReadableByteChannel readableByteChannel) throws IOException {
  if (!this.eventListExistanceDeserialized) {
    this.tempBuffer.position(0);
    this.tempBuffer.limit(1);
    readableByteChannel.read(this.tempBuffer);
    if (this.tempBuffer.hasRemaining()) {
      return true;
    }
    this.eventListExistanceDeserialized=true;
    final boolean eventListFollows=(this.tempBuffer.get(0) == (byte)1);
    this.tempBuffer.clear();
    if (!eventListFollows) {
      this.transferEnvelope=new TransferEnvelope(this.deserializedSequenceNumber,this.deserializedJobID,this.deserializedSourceID,this.deserializedEventList);
      this.deserializationState=DeserializationState.NOTIFICATIONSDESERIALIZED;
      return false;
    }
  }
  this.deserializedEventList=this.objectDeserializer.deserialize(readableByteChannel,List.class);
  if (this.deserializedEventList == null) {
    return true;
  }
 else {
    this.transferEnvelope=new TransferEnvelope(this.deserializedSequenceNumber,this.deserializedJobID,this.deserializedSourceID,this.deserializedEventList);
    this.deserializationState=DeserializationState.NOTIFICATIONSDESERIALIZED;
    return false;
  }
}","@SuppressWarnings(""String_Node_Str"") private boolean readNotificationList(ReadableByteChannel readableByteChannel) throws IOException {
  if (!this.eventListExistanceDeserialized) {
    this.tempBuffer.position(0);
    this.tempBuffer.limit(1);
    readableByteChannel.read(this.tempBuffer);
    if (this.tempBuffer.hasRemaining()) {
      return true;
    }
    this.eventListExistanceDeserialized=true;
    final boolean eventListFollows=(this.tempBuffer.get(0) == (byte)1);
    this.tempBuffer.clear();
    if (!eventListFollows) {
      this.transferEnvelope=new TransferEnvelope(this.deserializedSequenceNumber,this.deserializedJobID,this.deserializedSourceID,this.deserializedEventList);
      this.deserializationState=DeserializationState.NOTIFICATIONSDESERIALIZED;
      return false;
    }
  }
  this.deserializedEventList=this.objectDeserializer.deserialize(readableByteChannel,ArrayList.class);
  if (this.deserializedEventList == null) {
    return true;
  }
 else {
    this.transferEnvelope=new TransferEnvelope(this.deserializedSequenceNumber,this.deserializedJobID,this.deserializedSourceID,this.deserializedEventList);
    this.deserializationState=DeserializationState.NOTIFICATIONSDESERIALIZED;
    return false;
  }
}",0.9979765277215702
55286,"/** 
 * {@inheritDoc}
 */
@Override public <T extends Record>OutputGate<T> createAndRegisterOutputGate(final ChannelSelector<T> selector,final boolean isBroadcast){
  if (this.unboundOutputGates == null) {
    return new RuntimeOutputGate<T>(getJobID(),null,getNumberOfOutputGates(),ChannelType.NETWORK,CompressionLevel.NO_COMPRESSION,selector,isBroadcast,null);
  }
  final GateDeploymentDescriptor gdd=this.unboundOutputGates.poll();
  if (gdd == null) {
    throw new IllegalStateException(""String_Node_Str"");
  }
  RecordSerializerFactory<T> serializerFactory;
  if (gdd.spanningRecordsAllowed()) {
    serializerFactory=new SpanningRecordSerializerFactory<T>();
  }
 else {
    serializerFactory=new DefaultRecordSerializerFactory<T>();
  }
  return new RuntimeOutputGate<T>(getJobID(),gdd.getGateID(),getNumberOfInputGates(),gdd.getChannelType(),gdd.getCompressionLevel(),selector,isBroadcast,serializerFactory);
}","/** 
 * {@inheritDoc}
 */
@Override public <T extends Record>OutputGate<T> createAndRegisterOutputGate(final ChannelSelector<T> selector,final boolean isBroadcast){
  if (this.unboundOutputGates == null) {
    final RuntimeOutputGate<T> rog=new RuntimeOutputGate<T>(getJobID(),null,getNumberOfOutputGates(),ChannelType.NETWORK,CompressionLevel.NO_COMPRESSION,selector,isBroadcast,null);
    this.outputGates.add(rog);
    return rog;
  }
  final GateDeploymentDescriptor gdd=this.unboundOutputGates.poll();
  if (gdd == null) {
    throw new IllegalStateException(""String_Node_Str"");
  }
  RecordSerializerFactory<T> serializerFactory;
  if (gdd.spanningRecordsAllowed()) {
    serializerFactory=new SpanningRecordSerializerFactory<T>();
  }
 else {
    serializerFactory=new DefaultRecordSerializerFactory<T>();
  }
  final RuntimeOutputGate<T> rog=new RuntimeOutputGate<T>(getJobID(),gdd.getGateID(),getNumberOfInputGates(),gdd.getChannelType(),gdd.getCompressionLevel(),selector,isBroadcast,serializerFactory);
  this.outputGates.add(rog);
  return rog;
}",0.916076845298281
55287,"/** 
 * {@inheritDoc}
 */
@Override public void read(final Kryo kryo,final Input input){
  this.jobID=kryo.readObjectOrNull(input,JobID.class);
  this.jobName=input.readString();
  try {
    readRequiredJarFiles(kryo,input);
  }
 catch (  IOException ioe) {
    new RuntimeException(ioe);
  }
  final int numVertices=input.readInt();
  for (int i=0; i < numVertices; i++) {
    final String className=input.readString();
    final JobVertexID id=kryo.readObject(input,JobVertexID.class);
    final String vertexName=input.readString();
    Class<? extends Record> c;
    try {
      c=ClassUtils.getRecordByName(className);
    }
 catch (    ClassNotFoundException cnfe) {
      throw new RuntimeException(cnfe.toString());
    }
    Constructor<? extends Record> cst;
    try {
      cst=c.getConstructor(String.class,JobVertexID.class,JobGraph.class);
      cst.newInstance(vertexName,id,this);
    }
 catch (    Exception e) {
      throw new RuntimeException(e.toString());
    }
  }
  for (int i=0; i < numVertices; i++) {
    AbstractJobVertex jv;
    final JobVertexID tmpID=kryo.readObject(input,JobVertexID.class);
    if (inputVertices.containsKey(tmpID)) {
      jv=inputVertices.get(tmpID);
    }
 else {
      if (outputVertices.containsKey(tmpID)) {
        jv=outputVertices.get(tmpID);
      }
 else {
        if (taskVertices.containsKey(tmpID)) {
          jv=taskVertices.get(tmpID);
        }
 else {
          throw new IllegalStateException(""String_Node_Str"" + tmpID + ""String_Node_Str"");
        }
      }
    }
    jv.read(kryo,input);
  }
  ClassLoader cl=null;
  try {
    cl=LibraryCacheManager.getClassLoader(this.jobID);
  }
 catch (  IOException ioe) {
    throw new RuntimeException(""String_Node_Str"" + StringUtils.stringifyException(ioe));
  }
  this.jobConfiguration=new Configuration(cl);
  this.jobConfiguration.read(kryo,input);
  this.taskManagerConfiguration.read(kryo,input);
}","/** 
 * {@inheritDoc}
 */
@Override public void read(final Kryo kryo,final Input input){
  this.jobID=kryo.readObject(input,JobID.class);
  this.jobName=input.readString();
  try {
    readRequiredJarFiles(kryo,input);
  }
 catch (  IOException ioe) {
    new RuntimeException(ioe);
  }
  final int numVertices=input.readInt();
  for (int i=0; i < numVertices; i++) {
    final String className=input.readString();
    final JobVertexID id=kryo.readObject(input,JobVertexID.class);
    final String vertexName=input.readString();
    Class<? extends Record> c;
    try {
      c=ClassUtils.getRecordByName(className);
    }
 catch (    ClassNotFoundException cnfe) {
      throw new RuntimeException(cnfe.toString());
    }
    Constructor<? extends Record> cst;
    try {
      cst=c.getConstructor(String.class,JobVertexID.class,JobGraph.class);
      cst.newInstance(vertexName,id,this);
    }
 catch (    Exception e) {
      throw new RuntimeException(e.toString());
    }
  }
  for (int i=0; i < numVertices; i++) {
    AbstractJobVertex jv;
    final JobVertexID tmpID=kryo.readObject(input,JobVertexID.class);
    if (inputVertices.containsKey(tmpID)) {
      jv=inputVertices.get(tmpID);
    }
 else {
      if (outputVertices.containsKey(tmpID)) {
        jv=outputVertices.get(tmpID);
      }
 else {
        if (taskVertices.containsKey(tmpID)) {
          jv=taskVertices.get(tmpID);
        }
 else {
          throw new IllegalStateException(""String_Node_Str"" + tmpID + ""String_Node_Str"");
        }
      }
    }
    jv.read(kryo,input);
  }
  ClassLoader cl=null;
  try {
    cl=LibraryCacheManager.getClassLoader(this.jobID);
  }
 catch (  IOException ioe) {
    throw new RuntimeException(""String_Node_Str"" + StringUtils.stringifyException(ioe));
  }
  this.jobConfiguration=new Configuration(cl);
  this.jobConfiguration.read(kryo,input);
  this.taskManagerConfiguration.read(kryo,input);
}",0.9984317825405122
55288,"/** 
 * Serializes the record and writes it to an internal buffer. The buffer grows dynamically in case more memory is required to serialization.
 * @param object the object to be serialized
 * @throws IOException Thrown if data from a previous serialization process is still in the internal buffer and has not yet been transfered to a byte buffer
 */
void serialize(final Object object) throws IOException {
  if (dataLeftFromPreviousSerialization()) {
    throw new IOException(""String_Node_Str"" + leftInSerializationBuffer() + ""String_Node_Str"");
  }
  this.kryo.writeObject(this.output,object);
  this.lengthBuf.putInt(this.output.total());
}","/** 
 * Serializes the record and writes it to an internal buffer. The buffer grows dynamically in case more memory is required to serialization.
 * @param object the object to be serialized
 * @throws IOException Thrown if data from a previous serialization process is still in the internal buffer and has not yet been transfered to a byte buffer
 */
void serialize(final Object object) throws IOException {
  if (dataLeftFromPreviousSerialization()) {
    throw new IOException(""String_Node_Str"" + leftInSerializationBuffer() + ""String_Node_Str"");
  }
  this.kryo.writeObject(this.output,object);
  this.lengthBuf.putInt(this.output.total());
  this.lengthBuf.flip();
}",0.9810174639331816
55289,"/** 
 * {@inheritDoc}
 */
@Override public void write(final Kryo kryo,final Output output){
  output.writeString(this.instanceType);
  output.writeInt(this.numberOfSubtasks);
  output.writeInt(this.numberOfSubtasksPerInstance);
  output.writeInt(this.numberOfExecutionRetries);
  if (this.vertexToShareInstancesWith != null) {
    output.writeBoolean(true);
    kryo.writeObject(output,this.vertexToShareInstancesWith.getID());
  }
 else {
    output.writeBoolean(false);
  }
  this.configuration.write(kryo,output);
  output.writeInt(this.forwardEdges.size());
  for (int i=0; i < this.forwardEdges.size(); i++) {
    final JobEdge edge=this.forwardEdges.get(i);
    if (edge == null) {
      output.writeBoolean(false);
    }
 else {
      output.writeBoolean(true);
      kryo.writeObject(output,edge.getConnectedVertex().getID());
      EnumUtils.writeEnum(output,edge.getChannelType());
      EnumUtils.writeEnum(output,edge.getCompressionLevel());
      EnumUtils.writeEnum(output,edge.getDistributionPattern());
      output.writeInt(edge.getIndexOfInputGate());
    }
  }
  output.writeString(this.invokableClassName);
}","/** 
 * {@inheritDoc}
 */
@Override public void write(final Kryo kryo,final Output output){
  output.writeString(this.instanceType);
  output.writeInt(this.numberOfSubtasks);
  output.writeInt(this.numberOfSubtasksPerInstance);
  output.writeInt(this.numberOfExecutionRetries);
  if (this.vertexToShareInstancesWith != null) {
    output.writeBoolean(true);
    kryo.writeObject(output,this.vertexToShareInstancesWith.getID());
  }
 else {
    output.writeBoolean(false);
  }
  this.configuration.write(kryo,output);
  output.writeInt(this.forwardEdges.size());
  for (int i=0; i < this.forwardEdges.size(); i++) {
    final JobEdge edge=this.forwardEdges.get(i);
    if (edge == null) {
      output.writeBoolean(false);
    }
 else {
      output.writeBoolean(true);
      kryo.writeObject(output,edge.getConnectedVertex().getID());
      EnumUtils.writeEnum(output,edge.getChannelType());
      EnumUtils.writeEnum(output,edge.getCompressionLevel());
      EnumUtils.writeEnum(output,edge.getDistributionPattern());
      output.writeInt(edge.getIndexOfInputGate());
      output.writeBoolean(edge.spanningRecordsAllowed());
    }
  }
  output.writeString(this.invokableClassName);
}",0.9749351771823682
55290,"@Test public void testLargeSortAcrossMultipleWindows() throws Exception {
  try {
    final int NUM_RECORDS=1000000;
    final TestData.Generator generator=new TestData.Generator(SEED,KEY_MAX,VALUE_LENGTH,KeyMode.RANDOM,ValueMode.CONSTANT,VAL);
    final MutableObjectIterator<PactRecord> source=new TestData.GeneratorIterator(generator,NUM_RECORDS);
    LOG.debug(""String_Node_Str"");
    Sorter<PactRecord> sorter=new AsynchronousPartialSorter<PactRecord>(this.memoryManager,source,this.parentTask,this.serializer,this.comparator,32 * 1024 * 1024);
    runPartialSorter(sorter,NUM_RECORDS,28);
  }
 catch (  Exception t) {
    t.printStackTrace();
    Assert.fail(""String_Node_Str"" + t.getMessage());
  }
}","@Test public void testLargeSortAcrossMultipleWindows() throws Exception {
  try {
    final int NUM_RECORDS=1000000;
    final TestData.Generator generator=new TestData.Generator(SEED,KEY_MAX,VALUE_LENGTH,KeyMode.RANDOM,ValueMode.CONSTANT,VAL);
    final MutableObjectIterator<PactRecord> source=new TestData.GeneratorIterator(generator,NUM_RECORDS);
    LOG.debug(""String_Node_Str"");
    Sorter<PactRecord> sorter=new AsynchronousPartialSorter<PactRecord>(this.memoryManager,source,this.parentTask,this.serializer,this.comparator,10 * 1024 * 1024);
    runPartialSorter(sorter,NUM_RECORDS,25);
  }
 catch (  Exception t) {
    t.printStackTrace();
    Assert.fail(""String_Node_Str"" + t.getMessage());
  }
}",0.9957567185289956
55291,"@Test public void testLargeSortAcrossTwoWindows() throws Exception {
  try {
    final int NUM_RECORDS=100000;
    final TestData.Generator generator=new TestData.Generator(SEED,KEY_MAX,VALUE_LENGTH,KeyMode.RANDOM,ValueMode.CONSTANT,VAL);
    final MutableObjectIterator<PactRecord> source=new TestData.GeneratorIterator(generator,NUM_RECORDS);
    LOG.debug(""String_Node_Str"");
    Sorter<PactRecord> sorter=new AsynchronousPartialSorter<PactRecord>(this.memoryManager,source,this.parentTask,this.serializer,this.comparator,32 * 1024 * 1024);
    runPartialSorter(sorter,NUM_RECORDS,2);
  }
 catch (  Exception t) {
    t.printStackTrace();
    Assert.fail(""String_Node_Str"" + t.getMessage());
  }
}","@Test public void testLargeSortAcrossTwoWindows() throws Exception {
  try {
    final int NUM_RECORDS=100000;
    final TestData.Generator generator=new TestData.Generator(SEED,KEY_MAX,VALUE_LENGTH,KeyMode.RANDOM,ValueMode.CONSTANT,VAL);
    final MutableObjectIterator<PactRecord> source=new TestData.GeneratorIterator(generator,NUM_RECORDS);
    LOG.debug(""String_Node_Str"");
    Sorter<PactRecord> sorter=new AsynchronousPartialSorter<PactRecord>(this.memoryManager,source,this.parentTask,this.serializer,this.comparator,10 * 1024 * 1024);
    runPartialSorter(sorter,NUM_RECORDS,2);
  }
 catch (  Exception t) {
    t.printStackTrace();
    Assert.fail(""String_Node_Str"" + t.getMessage());
  }
}",0.9971428571428572
55292,"MultiPacketOutputStream(final int initialBufferSize){
  this.bufferSize=initialBufferSize - RPCMessage.METADATA_SIZE;
  this.buf=new byte[initialBufferSize];
}","MultiPacketOutputStream(final int initialBufferSize){
  this.buf=new byte[initialBufferSize];
}",0.7480314960629921
55293,"@Override public void write(final byte[] b,final int off,final int len) throws IOException {
  while (this.totalLen + len > this.bufferSize) {
    resizeBuffer();
  }
  int written=0;
  while (written < len) {
    if (this.lenInPacket == RPCMessage.MAXIMUM_MSG_SIZE) {
      this.lenInPacket=0;
      this.totalLen+=RPCMessage.METADATA_SIZE;
    }
    final int amountOfDataToWrite=Math.min((len - written),(RPCMessage.MAXIMUM_MSG_SIZE - this.lenInPacket));
    System.arraycopy(b,off + written,this.buf,this.totalLen,amountOfDataToWrite);
    this.lenInPacket+=amountOfDataToWrite;
    this.totalLen+=amountOfDataToWrite;
    written+=amountOfDataToWrite;
  }
}","@Override public void write(final byte[] b,final int off,final int len) throws IOException {
  final int lengthIncludingMetaData=getLengthIncludingMetaData(len);
  while (this.totalLen + lengthIncludingMetaData > this.buf.length) {
    resizeBuffer();
  }
  int written=0;
  while (written < len) {
    if (this.lenInPacket == RPCMessage.MAXIMUM_MSG_SIZE) {
      this.lenInPacket=0;
      this.totalLen+=RPCMessage.METADATA_SIZE;
    }
    final int amountOfDataToWrite=Math.min((len - written),(RPCMessage.MAXIMUM_MSG_SIZE - this.lenInPacket));
    System.arraycopy(b,off + written,this.buf,this.totalLen,amountOfDataToWrite);
    this.lenInPacket+=amountOfDataToWrite;
    this.totalLen+=amountOfDataToWrite;
    written+=amountOfDataToWrite;
  }
}",0.903043170559094
55294,"private void resizeBuffer(){
  final byte[] newBuf=new byte[this.buf.length * 2];
  System.arraycopy(this.buf,0,newBuf,0,this.totalLen);
  this.buf=newBuf;
  this.bufferSize=newBuf.length - RPCMessage.METADATA_SIZE;
}","private void resizeBuffer(){
  final byte[] newBuf=new byte[this.buf.length * 2];
  System.arraycopy(this.buf,0,newBuf,0,this.totalLen);
  this.buf=newBuf;
}",0.839572192513369
55295,"/** 
 * {@inheritDoc}
 */
@Override protected Kryo initialValue(){
  final Kryo kryo=new Kryo();
  if (kryoTypesToRegister != null) {
    kryo.setAutoReset(false);
    kryo.setRegistrationRequired(true);
    for (    final Class<?> kryoType : kryoTypesToRegister) {
      kryo.register(kryoType);
    }
  }
  return kryo;
}","/** 
 * {@inheritDoc}
 */
@Override protected Kryo initialValue(){
  final Kryo kryo=new Kryo();
  if (kryoTypesToRegister != null) {
    kryo.setAutoReset(false);
    kryo.setRegistrationRequired(true);
    kryo.setReferences(false);
    for (    final Class<?> kryoType : kryoTypesToRegister) {
      kryo.register(kryoType);
    }
  }
  return kryo;
}",0.9542097488921714
55296,"/** 
 * Reads library data from the given stream.
 * @param in the stream to read the library data from
 * @throws IOException throws if an error occurs while reading from the stream
 */
private void readLibraryFromStreamInternal(final DataInput in) throws IOException {
  final String libraryFileName=StringRecord.readString(in);
  if (libraryFileName == null) {
    throw new IOException(""String_Node_Str"");
  }
  final long length=in.readLong();
  if (length > (long)Integer.MAX_VALUE) {
    throw new IOException(""String_Node_Str"" + libraryFileName + ""String_Node_Str"");
  }
  final byte[] buf=new byte[(int)length];
  in.readFully(buf);
  final Path storePath=new Path(this.libraryCachePath + ""String_Node_Str"" + libraryFileName);
synchronized (this.fs) {
    if (!fs.exists(storePath)) {
      final FSDataOutputStream fos=fs.create(storePath,false);
      fos.write(buf,0,buf.length);
      fos.close();
    }
  }
}","/** 
 * Reads library data from the given stream.
 * @param input the stream to read the library data from
 * @throws IOException throws if an error occurs while reading from the stream
 */
private void readLibraryFromStreamInternal(final Input input) throws IOException {
  final String libraryFileName=input.readString();
  if (libraryFileName == null) {
    throw new IOException(""String_Node_Str"");
  }
  final long length=input.readLong();
  if (length > (long)Integer.MAX_VALUE) {
    throw new IOException(""String_Node_Str"" + libraryFileName + ""String_Node_Str"");
  }
  final byte[] buf=new byte[(int)length];
  input.readBytes(buf);
  final Path storePath=new Path(this.libraryCachePath + ""String_Node_Str"" + libraryFileName);
synchronized (this.fs) {
    if (!fs.exists(storePath)) {
      final FSDataOutputStream fos=fs.create(storePath,false);
      fos.write(buf,0,buf.length);
      fos.close();
    }
  }
}",0.9571351058057516
55297,"/** 
 * Writes data from the library with the given file name to the specified stream.
 * @param libraryFileName the name of the library
 * @param out the stream to write the data to
 * @throws IOException thrown if an error occurs while writing the data
 */
private void writeLibraryToStreamInternal(final String libraryFileName,final DataOutput out) throws IOException {
  if (libraryFileName == null) {
    throw new IOException(""String_Node_Str"");
  }
  final Path storePath=new Path(this.libraryCachePath + ""String_Node_Str"" + libraryFileName);
synchronized (this.fs) {
    if (!fs.exists(storePath)) {
      throw new IOException(storePath + ""String_Node_Str"");
    }
    final FileStatus status=fs.getFileStatus(storePath);
    StringRecord.writeString(out,libraryFileName);
    out.writeLong(status.getLen());
    final FSDataInputStream inStream=fs.open(storePath);
    final byte[] buf=new byte[8192];
    int read=inStream.read(buf,0,buf.length);
    while (read > 0) {
      out.write(buf,0,read);
      read=inStream.read(buf,0,buf.length);
    }
    inStream.close();
  }
}","/** 
 * Writes data from the library with the given file name to the specified stream.
 * @param libraryFileName the name of the library
 * @param output the stream to write the data to
 * @throws IOException thrown if an error occurs while writing the data
 */
private void writeLibraryToStreamInternal(final String libraryFileName,final Output output) throws IOException {
  if (libraryFileName == null) {
    throw new IOException(""String_Node_Str"");
  }
  final Path storePath=new Path(this.libraryCachePath + ""String_Node_Str"" + libraryFileName);
synchronized (this.fs) {
    if (!fs.exists(storePath)) {
      throw new IOException(storePath + ""String_Node_Str"");
    }
    final FileStatus status=fs.getFileStatus(storePath);
    output.writeString(libraryFileName);
    output.writeLong(status.getLen());
    final FSDataInputStream inStream=fs.open(storePath);
    final byte[] buf=new byte[8192];
    int read=inStream.read(buf,0,buf.length);
    while (read > 0) {
      output.writeBytes(buf,0,read);
      read=inStream.read(buf,0,buf.length);
    }
    inStream.close();
  }
}",0.9627928341754708
55298,"/** 
 * Writes data from the library with the given file name to the specified stream.
 * @param libraryFileName the name of the library
 * @param out the stream to write the data to
 * @throws IOException thrown if an error occurs while writing the data
 */
public static void writeLibraryToStream(final String libraryFileName,final DataOutput out) throws IOException {
  final LibraryCacheManager lib=get();
  lib.writeLibraryToStreamInternal(libraryFileName,out);
}","/** 
 * Writes data from the library with the given file name to the specified stream.
 * @param libraryFileName the name of the library
 * @param output the stream to write the data to
 * @throws IOException thrown if an error occurs while writing the data
 */
public static void writeLibraryToStream(final String libraryFileName,final Output output) throws IOException {
  final LibraryCacheManager lib=get();
  lib.writeLibraryToStreamInternal(libraryFileName,output);
}",0.9861849096705632
55299,"/** 
 * Reads library data from the given stream.
 * @param in the stream to read the library data from
 * @throws IOException throws if an error occurs while reading from the stream
 */
public static void readLibraryFromStream(final DataInput in) throws IOException {
  final LibraryCacheManager lib=get();
  lib.readLibraryFromStreamInternal(in);
}","/** 
 * Reads library data from the given stream.
 * @param in the stream to read the library data from
 * @throws IOException throws if an error occurs while reading from the stream
 */
public static void readLibraryFromStream(final Input input) throws IOException {
  final LibraryCacheManager lib=get();
  lib.readLibraryFromStreamInternal(input);
}",0.9857549857549858
55300,"/** 
 * {@inheritDoc}
 */
@Override public void read(final DataInput in) throws IOException {
  LibraryCacheManager.readLibraryFromStream(in);
}","/** 
 * {@inheritDoc}
 */
@Override public void read(final Kryo kryo,final Input input){
  try {
    LibraryCacheManager.readLibraryFromStream(input);
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}",0.4590163934426229
55301,"/** 
 * {@inheritDoc}
 */
@Override public void write(final DataOutput out) throws IOException {
  if (this.libraryFileName == null) {
    throw new IOException(""String_Node_Str"");
  }
  LibraryCacheManager.writeLibraryToStream(this.libraryFileName,out);
}","/** 
 * {@inheritDoc}
 */
@Override public void write(final Kryo kryo,final Output output){
  if (this.libraryFileName == null) {
    throw new IllegalStateException(""String_Node_Str"");
  }
  try {
    LibraryCacheManager.writeLibraryToStream(this.libraryFileName,output);
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}",0.3433333333333333
55302,"/** 
 * Returns a list of types frequently used by the RPC protocols of this package and its parent packages.
 * @return a list of types frequently used by the RPC protocols of this package
 */
public static List<Class<?>> getRPCTypesToRegister(){
  final ArrayList<Class<?>> types=new ArrayList<Class<?>>();
  types.add(AbstractJobResult.class);
  types.add(AbstractJobResult.ReturnCode.class);
  types.add(ChannelID.class);
  types.add(ChannelType.class);
  types.add(CompressionLevel.class);
  types.add(ExecutionState.class);
  types.add(GateID.class);
  types.add(HashMap.class);
  types.add(IntegerRecord.class);
  types.add(JobCancelResult.class);
  types.add(JobEvent.class);
  types.add(JobGraph.class);
  types.add(JobID.class);
  types.add(JobProgressResult.class);
  types.add(JobStatus.class);
  types.add(JobSubmissionResult.class);
  types.add(JobVertexID.class);
  types.add(LibraryCacheProfileRequest.class);
  types.add(LibraryCacheProfileResponse.class);
  types.add(Path.class);
  types.add(SerializableArrayList.class);
  types.add(SerializableHashMap.class);
  types.add(SerializableHashSet.class);
  types.add(Set.class);
  types.add(VertexEvent.class);
  return types;
}","/** 
 * Returns a list of types frequently used by the RPC protocols of this package and its parent packages.
 * @return a list of types frequently used by the RPC protocols of this package
 */
public static List<Class<?>> getRPCTypesToRegister(){
  final ArrayList<Class<?>> types=new ArrayList<Class<?>>();
  types.add(AbstractJobResult.class);
  types.add(AbstractJobResult.ReturnCode.class);
  types.add(ChannelID.class);
  types.add(ChannelType.class);
  types.add(CompressionLevel.class);
  types.add(ExecutionState.class);
  types.add(GateID.class);
  types.add(HashMap.class);
  types.add(IntegerRecord.class);
  types.add(JobCancelResult.class);
  types.add(JobEvent.class);
  types.add(JobGraph.class);
  types.add(JobID.class);
  types.add(JobProgressResult.class);
  types.add(JobStatus.class);
  types.add(JobSubmissionResult.class);
  types.add(JobVertexID.class);
  types.add(LibraryCacheProfileRequest.class);
  types.add(LibraryCacheProfileResponse.class);
  types.add(LibraryCacheUpdate.class);
  types.add(Path.class);
  types.add(SerializableArrayList.class);
  types.add(SerializableHashMap.class);
  types.add(SerializableHashSet.class);
  types.add(Set.class);
  types.add(VertexEvent.class);
  return types;
}",0.9839307787391842
55303,"/** 
 * Constructs a new job manager, starts its discovery service and its IPC service.
 */
public JobManager(final String configDir,final String executionMode){
  GlobalConfiguration.loadConfiguration(configDir);
  final String ipcAddressString=GlobalConfiguration.getString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY,null);
  InetAddress ipcAddress=null;
  if (ipcAddressString != null) {
    try {
      ipcAddress=InetAddress.getByName(ipcAddressString);
    }
 catch (    UnknownHostException e) {
      LOG.fatal(""String_Node_Str"" + ipcAddressString + ""String_Node_Str""+ StringUtils.stringifyException(e));
      System.exit(FAILURERETURNCODE);
    }
  }
  final int ipcPort=GlobalConfiguration.getInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY,ConfigConstants.DEFAULT_JOB_MANAGER_IPC_PORT);
  try {
    DiscoveryService.startDiscoveryService(ipcAddress,ipcPort);
  }
 catch (  DiscoveryException e) {
    LOG.fatal(""String_Node_Str"" + StringUtils.stringifyException(e));
    System.exit(FAILURERETURNCODE);
  }
  this.recommendedClientPollingInterval=GlobalConfiguration.getInteger(""String_Node_Str"",5);
  this.eventCollector=new EventCollector(this.recommendedClientPollingInterval);
  this.inputSplitManager=new InputSplitManager();
  final InetSocketAddress rpcServerAddress=new InetSocketAddress(ipcAddress,ipcPort);
  RPCService rpcService=null;
  try {
    final int handlerCount=GlobalConfiguration.getInteger(""String_Node_Str"",3);
    rpcService=new RPCService(rpcServerAddress.getPort(),handlerCount,ServerTypeUtils.getRPCTypesToRegister());
  }
 catch (  IOException ioe) {
    LOG.fatal(""String_Node_Str"" + StringUtils.stringifyException(ioe));
    System.exit(FAILURERETURNCODE);
  }
  this.rpcService=rpcService;
  this.rpcService.setProtocolCallbackHandler(ChannelLookupProtocol.class,this);
  this.rpcService.setProtocolCallbackHandler(ExtendedManagementProtocol.class,this);
  this.rpcService.setProtocolCallbackHandler(InputSplitProviderProtocol.class,this);
  this.rpcService.setProtocolCallbackHandler(JobManagementProtocol.class,this);
  this.rpcService.setProtocolCallbackHandler(JobManagerProtocol.class,this);
  LOG.info(""String_Node_Str"" + executionMode + ""String_Node_Str"");
  this.jobManagerPlugins=PluginManager.getJobManagerPlugins(this,configDir);
  if (""String_Node_Str"".equals(executionMode)) {
    try {
      this.instanceManager=new LocalInstanceManager(configDir,this.rpcService);
    }
 catch (    RuntimeException rte) {
      LOG.fatal(""String_Node_Str"" + StringUtils.stringifyException(rte));
      System.exit(FAILURERETURNCODE);
    }
  }
 else {
    final String instanceManagerClassName=JobManagerUtils.getInstanceManagerClassName(executionMode);
    LOG.info(""String_Node_Str"" + instanceManagerClassName + ""String_Node_Str"");
    this.instanceManager=JobManagerUtils.loadInstanceManager(instanceManagerClassName);
    if (this.instanceManager == null) {
      LOG.fatal(""String_Node_Str"" + instanceManagerClassName);
      System.exit(FAILURERETURNCODE);
    }
  }
  final String schedulerClassName=JobManagerUtils.getSchedulerClassName(executionMode);
  LOG.info(""String_Node_Str"" + schedulerClassName + ""String_Node_Str"");
  this.scheduler=JobManagerUtils.loadScheduler(schedulerClassName,this,this.instanceManager);
  if (this.scheduler == null) {
    LOG.fatal(""String_Node_Str"" + schedulerClassName);
    System.exit(FAILURERETURNCODE);
  }
  this.multicastManager=new MulticastManager(this.scheduler);
  if (GlobalConfiguration.getBoolean(ProfilingUtils.ENABLE_PROFILING_KEY,false)) {
    final String profilerClassName=GlobalConfiguration.getString(ProfilingUtils.JOBMANAGER_CLASSNAME_KEY,null);
    if (profilerClassName == null) {
      LOG.fatal(""String_Node_Str"");
      System.exit(FAILURERETURNCODE);
    }
    this.profiler=ProfilingUtils.loadJobManagerProfiler(profilerClassName,ipcAddress);
    if (this.profiler == null) {
      LOG.fatal(""String_Node_Str"");
      System.exit(FAILURERETURNCODE);
    }
  }
 else {
    this.profiler=null;
    LOG.debug(""String_Node_Str"");
  }
  Runtime.getRuntime().addShutdownHook(new JobManagerCleanUp(this));
}","/** 
 * Constructs a new job manager, starts its discovery service and its IPC service.
 */
public JobManager(final String configDir,final String executionMode){
  GlobalConfiguration.loadConfiguration(configDir);
  final String ipcAddressString=GlobalConfiguration.getString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY,null);
  InetAddress ipcAddress=null;
  if (ipcAddressString != null) {
    try {
      ipcAddress=InetAddress.getByName(ipcAddressString);
    }
 catch (    UnknownHostException e) {
      LOG.fatal(""String_Node_Str"" + ipcAddressString + ""String_Node_Str""+ StringUtils.stringifyException(e));
      System.exit(FAILURERETURNCODE);
    }
  }
  final int ipcPort=GlobalConfiguration.getInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY,ConfigConstants.DEFAULT_JOB_MANAGER_IPC_PORT);
  try {
    DiscoveryService.startDiscoveryService(ipcAddress,ipcPort);
  }
 catch (  DiscoveryException e) {
    LOG.fatal(""String_Node_Str"" + StringUtils.stringifyException(e));
    System.exit(FAILURERETURNCODE);
  }
  this.recommendedClientPollingInterval=GlobalConfiguration.getInteger(""String_Node_Str"",5);
  this.eventCollector=new EventCollector(this.recommendedClientPollingInterval);
  this.inputSplitManager=new InputSplitManager();
  final InetSocketAddress rpcServerAddress=new InetSocketAddress(ipcAddress,ipcPort);
  RPCService rpcService=null;
  try {
    final int handlerCount=GlobalConfiguration.getInteger(""String_Node_Str"",3);
    rpcService=new RPCService(rpcServerAddress.getPort(),handlerCount,ServerTypeUtils.getRPCTypesToRegister());
  }
 catch (  IOException ioe) {
    LOG.fatal(""String_Node_Str"" + StringUtils.stringifyException(ioe));
    System.exit(FAILURERETURNCODE);
  }
  this.rpcService=rpcService;
  this.rpcService.setProtocolCallbackHandler(ChannelLookupProtocol.class,this);
  this.rpcService.setProtocolCallbackHandler(ExtendedManagementProtocol.class,this);
  this.rpcService.setProtocolCallbackHandler(InputSplitProviderProtocol.class,this);
  this.rpcService.setProtocolCallbackHandler(JobManagementProtocol.class,this);
  this.rpcService.setProtocolCallbackHandler(JobManagerProtocol.class,this);
  LOG.info(""String_Node_Str"" + executionMode + ""String_Node_Str"");
  this.jobManagerPlugins=PluginManager.getJobManagerPlugins(this,configDir);
  if (""String_Node_Str"".equals(executionMode)) {
    try {
      this.instanceManager=new LocalInstanceManager(configDir,this.rpcService);
    }
 catch (    RuntimeException rte) {
      LOG.fatal(""String_Node_Str"" + StringUtils.stringifyException(rte));
      System.exit(FAILURERETURNCODE);
    }
  }
 else {
    final String instanceManagerClassName=JobManagerUtils.getInstanceManagerClassName(executionMode);
    LOG.info(""String_Node_Str"" + instanceManagerClassName + ""String_Node_Str"");
    this.instanceManager=JobManagerUtils.loadInstanceManager(instanceManagerClassName,this.rpcService);
    if (this.instanceManager == null) {
      LOG.fatal(""String_Node_Str"" + instanceManagerClassName);
      System.exit(FAILURERETURNCODE);
    }
  }
  final String schedulerClassName=JobManagerUtils.getSchedulerClassName(executionMode);
  LOG.info(""String_Node_Str"" + schedulerClassName + ""String_Node_Str"");
  this.scheduler=JobManagerUtils.loadScheduler(schedulerClassName,this,this.instanceManager);
  if (this.scheduler == null) {
    LOG.fatal(""String_Node_Str"" + schedulerClassName);
    System.exit(FAILURERETURNCODE);
  }
  this.multicastManager=new MulticastManager(this.scheduler);
  if (GlobalConfiguration.getBoolean(ProfilingUtils.ENABLE_PROFILING_KEY,false)) {
    final String profilerClassName=GlobalConfiguration.getString(ProfilingUtils.JOBMANAGER_CLASSNAME_KEY,null);
    if (profilerClassName == null) {
      LOG.fatal(""String_Node_Str"");
      System.exit(FAILURERETURNCODE);
    }
    this.profiler=ProfilingUtils.loadJobManagerProfiler(profilerClassName,ipcAddress);
    if (this.profiler == null) {
      LOG.fatal(""String_Node_Str"");
      System.exit(FAILURERETURNCODE);
    }
  }
 else {
    this.profiler=null;
    LOG.debug(""String_Node_Str"");
  }
  Runtime.getRuntime().addShutdownHook(new JobManagerCleanUp(this));
}",0.998061076102763
55304,"/** 
 * Tries to locate a class with given name and to instantiate a   {@link AbstractScheduler} object from it.
 * @param schedulerClassName the name of the class to instantiate the scheduler object from
 * @param deploymentManager the deployment manager which shall be passed on to the scheduler
 * @param instanceManager the instance manager which shall be passed on to the scheduler
 * @return the {@link AbstractScheduler} object instantiated from the class with the provided name
 */
@SuppressWarnings(""String_Node_Str"") static AbstractScheduler loadScheduler(final String schedulerClassName,final DeploymentManager deploymentManager,final InstanceManager instanceManager){
  Class<? extends AbstractScheduler> schedulerClass;
  try {
    schedulerClass=(Class<? extends AbstractScheduler>)Class.forName(schedulerClassName);
  }
 catch (  ClassNotFoundException e) {
    LOG.error(""String_Node_Str"" + schedulerClassName + ""String_Node_Str""+ StringUtils.stringifyException(e));
    return null;
  }
  Constructor<? extends AbstractScheduler> constructor;
  try {
    Class<?>[] constructorArgs={DeploymentManager.class,InstanceManager.class};
    constructor=schedulerClass.getConstructor(constructorArgs);
  }
 catch (  NoSuchMethodException e) {
    LOG.error(""String_Node_Str"" + StringUtils.stringifyException(e));
    return null;
  }
catch (  SecurityException e) {
    LOG.error(""String_Node_Str"" + StringUtils.stringifyException(e));
    return null;
  }
  AbstractScheduler scheduler;
  try {
    scheduler=constructor.newInstance(deploymentManager,instanceManager);
  }
 catch (  InstantiationException e) {
    LOG.error(""String_Node_Str"" + StringUtils.stringifyException(e));
    return null;
  }
catch (  IllegalAccessException e) {
    LOG.error(""String_Node_Str"" + StringUtils.stringifyException(e));
    return null;
  }
catch (  IllegalArgumentException e) {
    LOG.error(""String_Node_Str"" + StringUtils.stringifyException(e));
    return null;
  }
catch (  InvocationTargetException e) {
    LOG.error(""String_Node_Str"" + StringUtils.stringifyException(e));
    return null;
  }
  return scheduler;
}","/** 
 * Tries to locate a class with given name and to instantiate a   {@link AbstractScheduler} object from it.
 * @param schedulerClassName the name of the class to instantiate the scheduler object from
 * @param deploymentManager the deployment manager which shall be passed on to the scheduler
 * @param instanceManager the instance manager which shall be passed on to the scheduler
 * @return the {@link AbstractScheduler} object instantiated from the class with the provided name
 */
@SuppressWarnings(""String_Node_Str"") static AbstractScheduler loadScheduler(final String schedulerClassName,final DeploymentManager deploymentManager,final InstanceManager instanceManager){
  Class<? extends AbstractScheduler> schedulerClass;
  try {
    schedulerClass=(Class<? extends AbstractScheduler>)Class.forName(schedulerClassName);
  }
 catch (  ClassNotFoundException e) {
    LOG.error(""String_Node_Str"" + schedulerClassName + ""String_Node_Str""+ StringUtils.stringifyException(e));
    return null;
  }
  Constructor<? extends AbstractScheduler> constructor;
  try {
    Class<?>[] constructorArgs={DeploymentManager.class,InstanceManager.class};
    constructor=schedulerClass.getConstructor(constructorArgs);
  }
 catch (  Exception e) {
    LOG.error(""String_Node_Str"" + StringUtils.stringifyException(e));
    return null;
  }
  AbstractScheduler scheduler;
  try {
    scheduler=constructor.newInstance(deploymentManager,instanceManager);
  }
 catch (  Exception e) {
    LOG.error(""String_Node_Str"" + StringUtils.stringifyException(e));
    return null;
  }
  return scheduler;
}",0.7845780533836614
55305,"/** 
 * Tries to locate a class with given name and to instantiate a instance manager from it.
 * @param instanceManagerClassName the name of the class to instantiate the instance manager object from
 * @return the {@link InstanceManager} object instantiated from the class with the provided name
 */
@SuppressWarnings(""String_Node_Str"") static InstanceManager loadInstanceManager(final String instanceManagerClassName){
  Class<? extends InstanceManager> instanceManagerClass;
  try {
    instanceManagerClass=(Class<? extends InstanceManager>)Class.forName(instanceManagerClassName);
  }
 catch (  ClassNotFoundException e) {
    LOG.error(""String_Node_Str"" + instanceManagerClassName + ""String_Node_Str""+ StringUtils.stringifyException(e));
    return null;
  }
  InstanceManager instanceManager;
  try {
    instanceManager=instanceManagerClass.newInstance();
  }
 catch (  InstantiationException e) {
    LOG.error(""String_Node_Str"" + StringUtils.stringifyException(e));
    return null;
  }
catch (  IllegalAccessException e) {
    LOG.error(""String_Node_Str"" + StringUtils.stringifyException(e));
    return null;
  }
  return instanceManager;
}","/** 
 * Tries to locate a class with given name and to instantiate a instance manager from it.
 * @param instanceManagerClassName the name of the class to instantiate the instance manager object from
 * @return the {@link InstanceManager} object instantiated from the class with the provided name
 */
@SuppressWarnings(""String_Node_Str"") static InstanceManager loadInstanceManager(final String instanceManagerClassName,final RPCService rpcService){
  Class<? extends InstanceManager> instanceManagerClass;
  try {
    instanceManagerClass=(Class<? extends InstanceManager>)Class.forName(instanceManagerClassName);
  }
 catch (  ClassNotFoundException e) {
    LOG.error(""String_Node_Str"" + instanceManagerClassName + ""String_Node_Str""+ StringUtils.stringifyException(e));
    return null;
  }
  Constructor<? extends InstanceManager> constructor;
  try {
    constructor=instanceManagerClass.getConstructor(RPCService.class);
  }
 catch (  Exception e) {
    LOG.error(StringUtils.stringifyException(e));
    return null;
  }
  InstanceManager instanceManager;
  try {
    instanceManager=constructor.newInstance(rpcService);
  }
 catch (  Exception e) {
    LOG.error(""String_Node_Str"" + StringUtils.stringifyException(e));
    return null;
  }
  return instanceManager;
}",0.8783505154639175
55306,"/** 
 * Returns a list of types frequently used by the RPC protocols of this package and its parent packages.
 * @return a list of types frequently used by the RPC protocols of this package
 */
public static List<Class<?>> getRPCTypesToRegister(){
  final List<Class<?>> types=ManagementTypeUtils.getRPCTypesToRegister();
  types.add(AbstractTaskResult.ReturnCode.class);
  types.add(ChannelDeploymentDescriptor.class);
  types.add(CheckpointState.class);
  types.add(ConnectionInfoLookupResponse.class);
  types.add(ConnectionInfoLookupResponse.ReturnCode.class);
  types.add(ExecutionVertexID.class);
  types.add(FileInputSplit.class);
  types.add(GateDeploymentDescriptor.class);
  types.add(Inet4Address.class);
  types.add(InputSplitWrapper.class);
  types.add(InstanceConnectionInfo.class);
  types.add(LocalInstance.class);
  types.add(RemoteReceiver.class);
  types.add(TaskCancelResult.class);
  types.add(TaskCheckpointState.class);
  types.add(TaskDeploymentDescriptor.class);
  types.add(TaskExecutionState.class);
  types.add(TaskSubmissionResult.class);
  return types;
}","/** 
 * Returns a list of types frequently used by the RPC protocols of this package and its parent packages.
 * @return a list of types frequently used by the RPC protocols of this package
 */
public static List<Class<?>> getRPCTypesToRegister(){
  final List<Class<?>> types=ManagementTypeUtils.getRPCTypesToRegister();
  types.add(AbstractTaskResult.ReturnCode.class);
  types.add(ChannelDeploymentDescriptor.class);
  types.add(CheckpointState.class);
  types.add(ConnectionInfoLookupResponse.class);
  types.add(ConnectionInfoLookupResponse.ReturnCode.class);
  types.add(ExecutionVertexID.class);
  types.add(FileInputSplit.class);
  types.add(GateDeploymentDescriptor.class);
  types.add(Inet4Address.class);
  types.add(InetSocketAddress.class);
  types.add(InputSplitWrapper.class);
  types.add(InstanceConnectionInfo.class);
  types.add(LocalInstance.class);
  types.add(RemoteReceiver.class);
  types.add(TaskCancelResult.class);
  types.add(TaskCheckpointState.class);
  types.add(TaskDeploymentDescriptor.class);
  types.add(TaskExecutionState.class);
  types.add(TaskSubmissionResult.class);
  return types;
}",0.9827898550724636
55307,"@Test public void testLargeSortAcrossMultipleWindows() throws Exception {
  try {
    final int NUM_RECORDS=1000000;
    final TestData.Generator generator=new TestData.Generator(SEED,KEY_MAX,VALUE_LENGTH,KeyMode.RANDOM,ValueMode.CONSTANT,VAL);
    final MutableObjectIterator<PactRecord> source=new TestData.GeneratorIterator(generator,NUM_RECORDS);
    LOG.debug(""String_Node_Str"");
    Sorter<PactRecord> sorter=new AsynchronousPartialSorter<PactRecord>(this.memoryManager,source,this.parentTask,this.serializer,this.comparator,32 * 1024 * 1024);
    runPartialSorter(sorter,NUM_RECORDS,28);
  }
 catch (  Exception t) {
    t.printStackTrace();
    Assert.fail(""String_Node_Str"" + t.getMessage());
  }
}","@Test public void testLargeSortAcrossMultipleWindows() throws Exception {
  try {
    final int NUM_RECORDS=1000000;
    final TestData.Generator generator=new TestData.Generator(SEED,KEY_MAX,VALUE_LENGTH,KeyMode.RANDOM,ValueMode.CONSTANT,VAL);
    final MutableObjectIterator<PactRecord> source=new TestData.GeneratorIterator(generator,NUM_RECORDS);
    LOG.debug(""String_Node_Str"");
    Sorter<PactRecord> sorter=new AsynchronousPartialSorter<PactRecord>(this.memoryManager,source,this.parentTask,this.serializer,this.comparator,10 * 1024 * 1024);
    runPartialSorter(sorter,NUM_RECORDS,25);
  }
 catch (  Exception t) {
    t.printStackTrace();
    Assert.fail(""String_Node_Str"" + t.getMessage());
  }
}",0.9957567185289956
55308,"@Test public void testLargeSortAcrossTwoWindows() throws Exception {
  try {
    final int NUM_RECORDS=100000;
    final TestData.Generator generator=new TestData.Generator(SEED,KEY_MAX,VALUE_LENGTH,KeyMode.RANDOM,ValueMode.CONSTANT,VAL);
    final MutableObjectIterator<PactRecord> source=new TestData.GeneratorIterator(generator,NUM_RECORDS);
    LOG.debug(""String_Node_Str"");
    Sorter<PactRecord> sorter=new AsynchronousPartialSorter<PactRecord>(this.memoryManager,source,this.parentTask,this.serializer,this.comparator,32 * 1024 * 1024);
    runPartialSorter(sorter,NUM_RECORDS,2);
  }
 catch (  Exception t) {
    t.printStackTrace();
    Assert.fail(""String_Node_Str"" + t.getMessage());
  }
}","@Test public void testLargeSortAcrossTwoWindows() throws Exception {
  try {
    final int NUM_RECORDS=100000;
    final TestData.Generator generator=new TestData.Generator(SEED,KEY_MAX,VALUE_LENGTH,KeyMode.RANDOM,ValueMode.CONSTANT,VAL);
    final MutableObjectIterator<PactRecord> source=new TestData.GeneratorIterator(generator,NUM_RECORDS);
    LOG.debug(""String_Node_Str"");
    Sorter<PactRecord> sorter=new AsynchronousPartialSorter<PactRecord>(this.memoryManager,source,this.parentTask,this.serializer,this.comparator,10 * 1024 * 1024);
    runPartialSorter(sorter,NUM_RECORDS,2);
  }
 catch (  Exception t) {
    t.printStackTrace();
    Assert.fail(""String_Node_Str"" + t.getMessage());
  }
}",0.9971428571428572
55309,"/** 
 * Constructs a new job manager, starts its discovery service and its IPC service.
 */
public JobManager(final String configDir,final String executionMode){
  GlobalConfiguration.loadConfiguration(configDir);
  final String ipcAddressString=GlobalConfiguration.getString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY,null);
  InetAddress ipcAddress=null;
  if (ipcAddressString != null) {
    try {
      ipcAddress=InetAddress.getByName(ipcAddressString);
    }
 catch (    UnknownHostException e) {
      LOG.fatal(""String_Node_Str"" + ipcAddressString + ""String_Node_Str""+ StringUtils.stringifyException(e));
      System.exit(FAILURERETURNCODE);
    }
  }
  final int ipcPort=GlobalConfiguration.getInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY,ConfigConstants.DEFAULT_JOB_MANAGER_IPC_PORT);
  try {
    DiscoveryService.startDiscoveryService(ipcAddress,ipcPort);
  }
 catch (  DiscoveryException e) {
    LOG.fatal(""String_Node_Str"" + StringUtils.stringifyException(e));
    System.exit(FAILURERETURNCODE);
  }
  this.recommendedClientPollingInterval=GlobalConfiguration.getInteger(""String_Node_Str"",5);
  this.eventCollector=new EventCollector(this.recommendedClientPollingInterval);
  this.inputSplitManager=new InputSplitManager();
  final InetSocketAddress rpcServerAddress=new InetSocketAddress(ipcAddress,ipcPort);
  RPCService rpcService=null;
  try {
    rpcService=new RPCService(rpcServerAddress.getPort());
  }
 catch (  IOException ioe) {
    LOG.fatal(""String_Node_Str"" + StringUtils.stringifyException(ioe));
    System.exit(FAILURERETURNCODE);
  }
  this.rpcService=rpcService;
  this.rpcService.setProtocolCallbackHandler(JobManagerProtocol.class,this);
  this.rpcService.setProtocolCallbackHandler(JobManagementProtocol.class,this);
  this.rpcService.setProtocolCallbackHandler(ChannelLookupProtocol.class,this);
  LOG.info(""String_Node_Str"" + executionMode + ""String_Node_Str"");
  this.jobManagerPlugins=PluginManager.getJobManagerPlugins(this,configDir);
  if (""String_Node_Str"".equals(executionMode)) {
    try {
      this.instanceManager=new LocalInstanceManager(configDir,this.rpcService);
    }
 catch (    RuntimeException rte) {
      LOG.fatal(""String_Node_Str"" + StringUtils.stringifyException(rte));
      System.exit(FAILURERETURNCODE);
    }
  }
 else {
    final String instanceManagerClassName=JobManagerUtils.getInstanceManagerClassName(executionMode);
    LOG.info(""String_Node_Str"" + instanceManagerClassName + ""String_Node_Str"");
    this.instanceManager=JobManagerUtils.loadInstanceManager(instanceManagerClassName);
    if (this.instanceManager == null) {
      LOG.fatal(""String_Node_Str"" + instanceManagerClassName);
      System.exit(FAILURERETURNCODE);
    }
  }
  final String schedulerClassName=JobManagerUtils.getSchedulerClassName(executionMode);
  LOG.info(""String_Node_Str"" + schedulerClassName + ""String_Node_Str"");
  this.scheduler=JobManagerUtils.loadScheduler(schedulerClassName,this,this.instanceManager);
  if (this.scheduler == null) {
    LOG.fatal(""String_Node_Str"" + schedulerClassName);
    System.exit(FAILURERETURNCODE);
  }
  this.multicastManager=new MulticastManager(this.scheduler);
  if (GlobalConfiguration.getBoolean(ProfilingUtils.ENABLE_PROFILING_KEY,false)) {
    final String profilerClassName=GlobalConfiguration.getString(ProfilingUtils.JOBMANAGER_CLASSNAME_KEY,null);
    if (profilerClassName == null) {
      LOG.fatal(""String_Node_Str"");
      System.exit(FAILURERETURNCODE);
    }
    this.profiler=ProfilingUtils.loadJobManagerProfiler(profilerClassName,ipcAddress);
    if (this.profiler == null) {
      LOG.fatal(""String_Node_Str"");
      System.exit(FAILURERETURNCODE);
    }
  }
 else {
    this.profiler=null;
    LOG.debug(""String_Node_Str"");
  }
  Runtime.getRuntime().addShutdownHook(new JobManagerCleanUp(this));
}","/** 
 * Constructs a new job manager, starts its discovery service and its IPC service.
 */
public JobManager(final String configDir,final String executionMode){
  GlobalConfiguration.loadConfiguration(configDir);
  final String ipcAddressString=GlobalConfiguration.getString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY,null);
  InetAddress ipcAddress=null;
  if (ipcAddressString != null) {
    try {
      ipcAddress=InetAddress.getByName(ipcAddressString);
    }
 catch (    UnknownHostException e) {
      LOG.fatal(""String_Node_Str"" + ipcAddressString + ""String_Node_Str""+ StringUtils.stringifyException(e));
      System.exit(FAILURERETURNCODE);
    }
  }
  final int ipcPort=GlobalConfiguration.getInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY,ConfigConstants.DEFAULT_JOB_MANAGER_IPC_PORT);
  try {
    DiscoveryService.startDiscoveryService(ipcAddress,ipcPort);
  }
 catch (  DiscoveryException e) {
    LOG.fatal(""String_Node_Str"" + StringUtils.stringifyException(e));
    System.exit(FAILURERETURNCODE);
  }
  this.recommendedClientPollingInterval=GlobalConfiguration.getInteger(""String_Node_Str"",5);
  this.eventCollector=new EventCollector(this.recommendedClientPollingInterval);
  this.inputSplitManager=new InputSplitManager();
  final InetSocketAddress rpcServerAddress=new InetSocketAddress(ipcAddress,ipcPort);
  RPCService rpcService=null;
  try {
    rpcService=new RPCService(rpcServerAddress.getPort());
  }
 catch (  IOException ioe) {
    LOG.fatal(""String_Node_Str"" + StringUtils.stringifyException(ioe));
    System.exit(FAILURERETURNCODE);
  }
  this.rpcService=rpcService;
  this.rpcService.setProtocolCallbackHandler(ChannelLookupProtocol.class,this);
  this.rpcService.setProtocolCallbackHandler(ExtendedManagementProtocol.class,this);
  this.rpcService.setProtocolCallbackHandler(InputSplitProviderProtocol.class,this);
  this.rpcService.setProtocolCallbackHandler(JobManagementProtocol.class,this);
  this.rpcService.setProtocolCallbackHandler(JobManagerProtocol.class,this);
  LOG.info(""String_Node_Str"" + executionMode + ""String_Node_Str"");
  this.jobManagerPlugins=PluginManager.getJobManagerPlugins(this,configDir);
  if (""String_Node_Str"".equals(executionMode)) {
    try {
      this.instanceManager=new LocalInstanceManager(configDir,this.rpcService);
    }
 catch (    RuntimeException rte) {
      LOG.fatal(""String_Node_Str"" + StringUtils.stringifyException(rte));
      System.exit(FAILURERETURNCODE);
    }
  }
 else {
    final String instanceManagerClassName=JobManagerUtils.getInstanceManagerClassName(executionMode);
    LOG.info(""String_Node_Str"" + instanceManagerClassName + ""String_Node_Str"");
    this.instanceManager=JobManagerUtils.loadInstanceManager(instanceManagerClassName);
    if (this.instanceManager == null) {
      LOG.fatal(""String_Node_Str"" + instanceManagerClassName);
      System.exit(FAILURERETURNCODE);
    }
  }
  final String schedulerClassName=JobManagerUtils.getSchedulerClassName(executionMode);
  LOG.info(""String_Node_Str"" + schedulerClassName + ""String_Node_Str"");
  this.scheduler=JobManagerUtils.loadScheduler(schedulerClassName,this,this.instanceManager);
  if (this.scheduler == null) {
    LOG.fatal(""String_Node_Str"" + schedulerClassName);
    System.exit(FAILURERETURNCODE);
  }
  this.multicastManager=new MulticastManager(this.scheduler);
  if (GlobalConfiguration.getBoolean(ProfilingUtils.ENABLE_PROFILING_KEY,false)) {
    final String profilerClassName=GlobalConfiguration.getString(ProfilingUtils.JOBMANAGER_CLASSNAME_KEY,null);
    if (profilerClassName == null) {
      LOG.fatal(""String_Node_Str"");
      System.exit(FAILURERETURNCODE);
    }
    this.profiler=ProfilingUtils.loadJobManagerProfiler(profilerClassName,ipcAddress);
    if (this.profiler == null) {
      LOG.fatal(""String_Node_Str"");
      System.exit(FAILURERETURNCODE);
    }
  }
 else {
    this.profiler=null;
    LOG.debug(""String_Node_Str"");
  }
  Runtime.getRuntime().addShutdownHook(new JobManagerCleanUp(this));
}",0.9564102564102565
55310,"/** 
 * Returns the list of receivers for transfer envelopes produced by the channel with the given source channel ID.
 * @param jobID the ID of the job the given channel ID belongs to
 * @param sourceChannelID the source channel ID for which the receiver list shall be retrieved
 * @return the list of receivers or <code>null</code> if the receiver could not be determined
 * @throws IOException
 * @throws InterruptedExcption
 */
private TransferEnvelopeReceiverList getReceiverList(final JobID jobID,final ChannelID sourceChannelID) throws IOException, InterruptedException {
  TransferEnvelopeReceiverList receiverList=this.receiverCache.get(sourceChannelID);
  if (receiverList != null) {
    return receiverList;
  }
  while (true) {
    if (Thread.currentThread().isInterrupted()) {
      break;
    }
    ConnectionInfoLookupResponse lookupResponse;
synchronized (this.channelLookupService) {
      lookupResponse=this.channelLookupService.lookupConnectionInfo(this.localConnectionInfo,jobID,sourceChannelID);
    }
    if (lookupResponse.isJobAborting()) {
      break;
    }
    if (lookupResponse.receiverNotFound()) {
      LOG.error(""String_Node_Str"" + sourceChannelID);
      break;
    }
    if (lookupResponse.receiverNotReady()) {
      Thread.sleep(500);
      continue;
    }
    if (lookupResponse.receiverReady()) {
      receiverList=new TransferEnvelopeReceiverList(lookupResponse);
      break;
    }
  }
  if (receiverList != null) {
    this.receiverCache.put(sourceChannelID,receiverList);
    if (LOG.isDebugEnabled()) {
      final StringBuilder sb=new StringBuilder();
      sb.append(""String_Node_Str"" + sourceChannelID + ""String_Node_Str""+ this.localConnectionInfo+ ""String_Node_Str"");
      if (receiverList.hasLocalReceivers()) {
        sb.append(""String_Node_Str"");
        final Iterator<ChannelID> it=receiverList.getLocalReceivers().iterator();
        while (it.hasNext()) {
          sb.append(""String_Node_Str"" + it.next() + ""String_Node_Str"");
        }
      }
      if (receiverList.hasRemoteReceivers()) {
        sb.append(""String_Node_Str"");
        final Iterator<RemoteReceiver> it=receiverList.getRemoteReceivers().iterator();
        while (it.hasNext()) {
          sb.append(""String_Node_Str"" + it.next() + ""String_Node_Str"");
        }
      }
      LOG.debug(sb.toString());
    }
  }
  return receiverList;
}","/** 
 * Returns the list of receivers for transfer envelopes produced by the channel with the given source channel ID.
 * @param jobID the ID of the job the given channel ID belongs to
 * @param sourceChannelID the source channel ID for which the receiver list shall be retrieved
 * @return the list of receivers or <code>null</code> if the receiver could not be determined
 * @throws IOException
 * @throws InterruptedExcption
 */
private TransferEnvelopeReceiverList getReceiverList(final JobID jobID,final ChannelID sourceChannelID) throws IOException, InterruptedException {
  TransferEnvelopeReceiverList receiverList=this.receiverCache.get(sourceChannelID);
  if (receiverList != null) {
    return receiverList;
  }
  while (true) {
    if (Thread.currentThread().isInterrupted()) {
      break;
    }
    final ConnectionInfoLookupResponse lookupResponse=this.channelLookupService.lookupConnectionInfo(this.localConnectionInfo,jobID,sourceChannelID);
    if (lookupResponse.isJobAborting()) {
      break;
    }
    if (lookupResponse.receiverNotFound()) {
      LOG.error(""String_Node_Str"" + sourceChannelID);
      break;
    }
    if (lookupResponse.receiverNotReady()) {
      Thread.sleep(500);
      continue;
    }
    if (lookupResponse.receiverReady()) {
      receiverList=new TransferEnvelopeReceiverList(lookupResponse);
      break;
    }
  }
  if (receiverList != null) {
    this.receiverCache.put(sourceChannelID,receiverList);
    if (LOG.isDebugEnabled()) {
      final StringBuilder sb=new StringBuilder();
      sb.append(""String_Node_Str"" + sourceChannelID + ""String_Node_Str""+ this.localConnectionInfo+ ""String_Node_Str"");
      if (receiverList.hasLocalReceivers()) {
        sb.append(""String_Node_Str"");
        final Iterator<ChannelID> it=receiverList.getLocalReceivers().iterator();
        while (it.hasNext()) {
          sb.append(""String_Node_Str"" + it.next() + ""String_Node_Str"");
        }
      }
      if (receiverList.hasRemoteReceivers()) {
        sb.append(""String_Node_Str"");
        final Iterator<RemoteReceiver> it=receiverList.getRemoteReceivers().iterator();
        while (it.hasNext()) {
          sb.append(""String_Node_Str"" + it.next() + ""String_Node_Str"");
        }
      }
      LOG.debug(sb.toString());
    }
  }
  return receiverList;
}",0.9834941050375134
55311,"DatagramPacket[] createPackets(final InetSocketAddress remoteAddress,final int requestID){
  if (this.totalLen == 0) {
    return new DatagramPacket[0];
  }
  final int maximumPacketSize=RPCMessage.MAXIMUM_MSG_SIZE + RPCMessage.METADATA_SIZE;
  final short numberOfPackets=(short)(this.totalLen / maximumPacketSize + 1);
  final DatagramPacket[] packets=new DatagramPacket[numberOfPackets];
  for (short i=0; i < numberOfPackets; ++i) {
    final boolean lastPacket=(i == (numberOfPackets - 1));
    int offset;
    if (lastPacket) {
      offset=(numberOfPackets - 1) * maximumPacketSize + this.lenInPacket;
    }
 else {
      offset=(i + 1) * maximumPacketSize - RPCMessage.METADATA_SIZE;
    }
    shortToByteArray(i,this.buf,offset);
    shortToByteArray(numberOfPackets,this.buf,offset + 2);
    DatagramPacket packet;
    if (lastPacket) {
      packet=new DatagramPacket(this.buf,i * maximumPacketSize,this.lenInPacket + RPCMessage.METADATA_SIZE);
    }
 else {
      packet=new DatagramPacket(this.buf,i * maximumPacketSize,maximumPacketSize);
    }
    packet.setSocketAddress(remoteAddress);
    packets[i]=packet;
  }
  return packets;
}","DatagramPacket[] createPackets(final InetSocketAddress remoteAddress){
  if (this.totalLen == 0) {
    return new DatagramPacket[0];
  }
  final int maximumPacketSize=RPCMessage.MAXIMUM_MSG_SIZE + RPCMessage.METADATA_SIZE;
  final short numberOfPackets=(short)(this.totalLen / maximumPacketSize + 1);
  short fragmentationID=0;
  if (numberOfPackets > 1) {
    fragmentationID=(short)((double)Short.MIN_VALUE + (Math.random() * 2.0 * (double)Short.MAX_VALUE));
  }
  final DatagramPacket[] packets=new DatagramPacket[numberOfPackets];
  for (short i=0; i < numberOfPackets; ++i) {
    final boolean lastPacket=(i == (numberOfPackets - 1));
    int offset;
    if (lastPacket) {
      offset=(numberOfPackets - 1) * maximumPacketSize + this.lenInPacket;
    }
 else {
      offset=(i + 1) * maximumPacketSize - RPCMessage.METADATA_SIZE;
    }
    shortToByteArray(i,this.buf,offset);
    shortToByteArray(numberOfPackets,this.buf,offset + 2);
    shortToByteArray(fragmentationID,this.buf,offset + 4);
    DatagramPacket packet;
    if (lastPacket) {
      packet=new DatagramPacket(this.buf,i * maximumPacketSize,this.lenInPacket + RPCMessage.METADATA_SIZE);
    }
 else {
      packet=new DatagramPacket(this.buf,i * maximumPacketSize,maximumPacketSize);
    }
    packet.setSocketAddress(remoteAddress);
    packets[i]=packet;
  }
  return packets;
}",0.9028388644542183
55312,"private MultiPacketInputStreamKey(final SocketAddress socketAddress,final int requestID){
  this.socketAddress=socketAddress;
  this.requestID=requestID;
}","private MultiPacketInputStreamKey(final SocketAddress socketAddress,final short fragmentationID){
  this.socketAddress=socketAddress;
  this.fragmentationID=fragmentationID;
}",0.8424242424242424
55313,"@Override public Object invoke(final Object proxy,final Method method,final Object[] args) throws Throwable {
  final int requestID=Integer.MIN_VALUE + (int)(Math.random() * (double)Integer.MAX_VALUE * 2.0);
  final RPCRequest rpcRequest=new RPCRequest(requestID,this.interfaceName,method,args);
  return sendRPCRequest(this.remoteSocketAddress,rpcRequest);
}","@Override public Object invoke(final Object proxy,final Method method,final Object[] args) throws Throwable {
  final int requestID=(int)((double)Integer.MIN_VALUE + (Math.random() * (double)Integer.MAX_VALUE * 2.0));
  final RPCRequest rpcRequest=new RPCRequest(requestID,this.interfaceName,method,args);
  return sendRPCRequest(this.remoteSocketAddress,rpcRequest);
}",0.9725274725274724
55314,"void removeIncompleteInputStream(final SocketAddress socketAddress,final int requestID){
  this.incompleteInputStreams.remove(new MultiPacketInputStreamKey(socketAddress,requestID));
}","void removeIncompleteInputStream(final SocketAddress socketAddress,final short fragmentationID){
  this.incompleteInputStreams.remove(new MultiPacketInputStreamKey(socketAddress,fragmentationID));
}",0.900523560209424
55315,"@Override public int hashCode(){
  return this.socketAddress.hashCode() + this.requestID;
}","@Override public int hashCode(){
  return this.socketAddress.hashCode() + this.fragmentationID;
}",0.925531914893617
55316,"/** 
 * {@inheritDoc}
 */
@Override public boolean equals(final Object obj){
  if (!(obj instanceof MultiPacketInputStreamKey)) {
    return false;
  }
  final MultiPacketInputStreamKey mpisk=(MultiPacketInputStreamKey)obj;
  if (this.requestID != mpisk.requestID) {
    return false;
  }
  if (!this.socketAddress.equals(mpisk.socketAddress)) {
    return false;
  }
  return true;
}","/** 
 * {@inheritDoc}
 */
@Override public boolean equals(final Object obj){
  if (!(obj instanceof MultiPacketInputStreamKey)) {
    return false;
  }
  final MultiPacketInputStreamKey mpisk=(MultiPacketInputStreamKey)obj;
  if (this.fragmentationID != mpisk.fragmentationID) {
    return false;
  }
  if (!this.socketAddress.equals(mpisk.socketAddress)) {
    return false;
  }
  return true;
}",0.676923076923077
55317,"MultiPacketInputStream getIncompleteInputStream(final SocketAddress socketAddress,final int requestID,final short numberOfPackets){
  final MultiPacketInputStreamKey key=new MultiPacketInputStreamKey(socketAddress,requestID);
  MultiPacketInputStream mpis=this.incompleteInputStreams.get(key);
  if (mpis == null) {
    mpis=new MultiPacketInputStream(numberOfPackets);
    MultiPacketInputStream oldVal=this.incompleteInputStreams.putIfAbsent(key,mpis);
    if (oldVal != null) {
      mpis=oldVal;
    }
  }
  return mpis;
}","MultiPacketInputStream getIncompleteInputStream(final SocketAddress socketAddress,final short fragmentationID,final short numberOfPackets){
  final MultiPacketInputStreamKey key=new MultiPacketInputStreamKey(socketAddress,fragmentationID);
  MultiPacketInputStream mpis=this.incompleteInputStreams.get(key);
  if (mpis == null) {
    mpis=new MultiPacketInputStream(numberOfPackets);
    MultiPacketInputStream oldVal=this.incompleteInputStreams.putIfAbsent(key,mpis);
    if (oldVal != null) {
      mpis=oldVal;
    }
  }
  return mpis;
}",0.953095684803002
55318,"@Override public void run(){
  final Kryo kryo=RPCService.createKryoObject();
  byte[] buf=new byte[RPCMessage.MAXIMUM_MSG_SIZE + RPCMessage.METADATA_SIZE];
  DatagramPacket dp=new DatagramPacket(buf,buf.length);
  while (!this.shutdownRequested) {
    try {
      this.socket.receive(dp);
    }
 catch (    SocketException se) {
      if (this.shutdownRequested) {
        return;
      }
      Log.error(""String_Node_Str"",se);
      return;
    }
catch (    IOException ioe) {
      Log.error(""String_Node_Str"",ioe);
      return;
    }
    final InetSocketAddress remoteSocketAddress=(InetSocketAddress)dp.getSocketAddress();
    final int length=dp.getLength() - RPCMessage.METADATA_SIZE;
    final byte[] dbbuf=dp.getData();
    final short numberOfPackets=byteArrayToShort(dbbuf,length + 2);
    Input input=null;
    if (numberOfPackets == 1) {
      final SinglePacketInputStream spis=new SinglePacketInputStream(dbbuf,length);
      input=new Input(spis);
    }
 else {
      final MultiPacketInputStream mpis=this.rpcService.getIncompleteInputStream(remoteSocketAddress,0,numberOfPackets);
      mpis.addPacket(byteArrayToShort(dbbuf,length),dp);
      if (!mpis.isComplete()) {
        buf=new byte[RPCMessage.MAXIMUM_MSG_SIZE + RPCMessage.METADATA_SIZE];
        dp=new DatagramPacket(buf,buf.length);
        continue;
      }
      this.rpcService.removeIncompleteInputStream(remoteSocketAddress,0);
      input=new Input(mpis);
    }
    final RPCEnvelope envelope=kryo.readObject(input,RPCEnvelope.class);
    final RPCMessage msg=envelope.getRPCMessage();
    if (msg instanceof RPCRequest) {
      while (true) {
        try {
          this.rpcService.processIncomingRPCRequest(remoteSocketAddress,(RPCRequest)msg);
          break;
        }
 catch (        InterruptedException e) {
          if (this.shutdownRequested) {
            return;
          }
 else {
            continue;
          }
        }
      }
    }
 else     if (msg instanceof RPCResponse) {
      this.rpcService.processIncomingRPCResponse(remoteSocketAddress,(RPCResponse)msg);
    }
 else {
      this.rpcService.processIncomingRPCCleanup(remoteSocketAddress,(RPCCleanup)msg);
    }
  }
}","@Override public void run(){
  byte[] buf=new byte[RPCMessage.MAXIMUM_MSG_SIZE + RPCMessage.METADATA_SIZE];
  DatagramPacket dp=new DatagramPacket(buf,buf.length);
  while (!this.shutdownRequested) {
    try {
      this.socket.receive(dp);
    }
 catch (    SocketException se) {
      if (this.shutdownRequested) {
        return;
      }
      Log.error(""String_Node_Str"",se);
      return;
    }
catch (    IOException ioe) {
      Log.error(""String_Node_Str"",ioe);
      return;
    }
    final InetSocketAddress remoteSocketAddress=(InetSocketAddress)dp.getSocketAddress();
    final int length=dp.getLength() - RPCMessage.METADATA_SIZE;
    final byte[] dbbuf=dp.getData();
    final short packetIndex=byteArrayToShort(dbbuf,length);
    final short numberOfPackets=byteArrayToShort(dbbuf,length + 2);
    final short fragmentationID=byteArrayToShort(dbbuf,length + 4);
    Input input=null;
    if (numberOfPackets == 1) {
      final SinglePacketInputStream spis=new SinglePacketInputStream(dbbuf,length);
      input=new Input(spis);
    }
 else {
      final MultiPacketInputStream mpis=this.rpcService.getIncompleteInputStream(remoteSocketAddress,fragmentationID,numberOfPackets);
      mpis.addPacket(packetIndex,dp);
      if (!mpis.isComplete()) {
        buf=new byte[RPCMessage.MAXIMUM_MSG_SIZE + RPCMessage.METADATA_SIZE];
        dp=new DatagramPacket(buf,buf.length);
        continue;
      }
      this.rpcService.removeIncompleteInputStream(remoteSocketAddress,fragmentationID);
      input=new Input(mpis);
    }
    final Kryo kryo=RPCService.createKryoObject();
    final RPCEnvelope envelope=kryo.readObject(input,RPCEnvelope.class);
    final RPCMessage msg=envelope.getRPCMessage();
    if (msg instanceof RPCRequest) {
      while (true) {
        try {
          this.rpcService.processIncomingRPCRequest(remoteSocketAddress,(RPCRequest)msg);
          break;
        }
 catch (        InterruptedException e) {
          if (this.shutdownRequested) {
            return;
          }
 else {
            continue;
          }
        }
      }
    }
 else     if (msg instanceof RPCResponse) {
      this.rpcService.processIncomingRPCResponse(remoteSocketAddress,(RPCResponse)msg);
    }
 else {
      this.rpcService.processIncomingRPCCleanup(remoteSocketAddress,(RPCCleanup)msg);
    }
  }
}",0.9265912619206031
55319,"@Override public void run(){
  final Kryo kryo=RPCService.createKryoObject();
  final byte[] buf=new byte[SEND_BUFFER];
  final MultiPacketOutputStream mbos=new MultiPacketOutputStream(buf);
  while (!this.shutdownRequested) {
    SendingRequest sendingRequest=null;
    try {
      sendingRequest=this.msgQueue.take();
    }
 catch (    InterruptedException ie) {
      if (this.shutdownRequested) {
        return;
      }
 else {
        continue;
      }
    }
    mbos.reset();
    final Output output=new Output(mbos);
    kryo.writeObject(output,new RPCEnvelope(sendingRequest.rpcMessage));
    output.close();
    mbos.close();
    final DatagramPacket[] packets=mbos.createPackets(sendingRequest.remoteSocketAddress,sendingRequest.rpcMessage.getRequestID());
    try {
      for (int i=0; i < packets.length; ++i) {
        this.socket.send(packets[i]);
      }
    }
 catch (    IOException ioe) {
      Log.error(""String_Node_Str"",ioe);
      return;
    }
  }
}","@Override public void run(){
  final byte[] buf=new byte[SEND_BUFFER];
  final MultiPacketOutputStream mbos=new MultiPacketOutputStream(buf);
  while (!this.shutdownRequested) {
    SendingRequest sendingRequest=null;
    try {
      sendingRequest=this.msgQueue.take();
    }
 catch (    InterruptedException ie) {
      if (this.shutdownRequested) {
        return;
      }
 else {
        continue;
      }
    }
    mbos.reset();
    final Output output=new Output(mbos);
    final Kryo kryo=RPCService.createKryoObject();
    kryo.writeObject(output,new RPCEnvelope(sendingRequest.rpcMessage));
    output.close();
    mbos.close();
    final DatagramPacket[] packets=mbos.createPackets(sendingRequest.remoteSocketAddress);
    try {
      for (int i=0; i < packets.length; ++i) {
        this.socket.send(packets[i]);
      }
    }
 catch (    IOException ioe) {
      Log.error(""String_Node_Str"",ioe);
      return;
    }
  }
}",0.9260618772941792
55320,"@Test public void testMultiPacketSerialization(){
  final byte[] sourceBuf=new byte[1500];
  for (int i=0; i < sourceBuf.length; ++i) {
    sourceBuf[i]=(byte)(i % 23);
  }
  final byte[] targetBuf=new byte[8192];
  final MultiPacketOutputStream mpos=new MultiPacketOutputStream(targetBuf);
  try {
    mpos.write(sourceBuf);
  }
 catch (  IOException ioe) {
    fail(StringUtils.stringifyException(ioe));
  }
  final DatagramPacket[] packets=mpos.createPackets(TEST_REMOTE_ADDRESS,0);
  assertNotNull(packets);
  assertEquals(2,packets.length);
  int offset=packets[0].getOffset();
  int length=packets[0].getLength();
  assertEquals(0,offset);
  assertEquals(RPCMessage.MAXIMUM_MSG_SIZE + RPCMessage.METADATA_SIZE,length);
  byte[] packetBuf=packets[0].getData();
  byte lastByte=0;
  for (int i=offset; i < (offset + length - RPCMessage.METADATA_SIZE); ++i) {
    lastByte=packetBuf[i];
    assertEquals((byte)(i % 23),lastByte);
  }
  assertEquals(7,lastByte);
  System.out.println(""String_Node_Str"" + lastByte);
  assertEquals(0,packetBuf[offset + length - RPCMessage.METADATA_SIZE]);
  assertEquals(0,packetBuf[offset + length - RPCMessage.METADATA_SIZE + 1]);
  assertEquals(2,packetBuf[offset + length - RPCMessage.METADATA_SIZE + 2]);
  assertEquals(0,packetBuf[offset + length - RPCMessage.METADATA_SIZE + 3]);
  offset=packets[1].getOffset();
  length=packets[1].getLength();
  assertEquals(sourceBuf.length - RPCMessage.MAXIMUM_MSG_SIZE + RPCMessage.METADATA_SIZE,length);
  assertEquals(RPCMessage.MAXIMUM_MSG_SIZE + RPCMessage.METADATA_SIZE,offset);
  packetBuf=packets[1].getData();
  int j=lastByte + 1;
  for (int i=offset; i < (offset + length - RPCMessage.METADATA_SIZE); ++i) {
    assertEquals((byte)(j++ % 23),packetBuf[i]);
  }
}","@Test public void testMultiPacketSerialization(){
  final byte[] sourceBuf=new byte[1500];
  for (int i=0; i < sourceBuf.length; ++i) {
    sourceBuf[i]=(byte)(i % 23);
  }
  final byte[] targetBuf=new byte[8192];
  final MultiPacketOutputStream mpos=new MultiPacketOutputStream(targetBuf);
  try {
    mpos.write(sourceBuf);
  }
 catch (  IOException ioe) {
    fail(StringUtils.stringifyException(ioe));
  }
  final DatagramPacket[] packets=mpos.createPackets(TEST_REMOTE_ADDRESS);
  assertNotNull(packets);
  assertEquals(2,packets.length);
  int offset=packets[0].getOffset();
  int length=packets[0].getLength();
  assertEquals(0,offset);
  assertEquals(RPCMessage.MAXIMUM_MSG_SIZE + RPCMessage.METADATA_SIZE,length);
  byte[] packetBuf=packets[0].getData();
  byte lastByte=0;
  for (int i=offset; i < (offset + length - RPCMessage.METADATA_SIZE); ++i) {
    lastByte=packetBuf[i];
    assertEquals((byte)(i % 23),lastByte);
  }
  assertEquals(7,lastByte);
  System.out.println(""String_Node_Str"" + lastByte);
  assertEquals(0,packetBuf[offset + length - RPCMessage.METADATA_SIZE]);
  assertEquals(0,packetBuf[offset + length - RPCMessage.METADATA_SIZE + 1]);
  assertEquals(2,packetBuf[offset + length - RPCMessage.METADATA_SIZE + 2]);
  assertEquals(0,packetBuf[offset + length - RPCMessage.METADATA_SIZE + 3]);
  offset=packets[1].getOffset();
  length=packets[1].getLength();
  assertEquals(sourceBuf.length - RPCMessage.MAXIMUM_MSG_SIZE + RPCMessage.METADATA_SIZE,length);
  assertEquals(RPCMessage.MAXIMUM_MSG_SIZE + RPCMessage.METADATA_SIZE,offset);
  packetBuf=packets[1].getData();
  int j=lastByte + 1;
  for (int i=offset; i < (offset + length - RPCMessage.METADATA_SIZE); ++i) {
    assertEquals((byte)(j++ % 23),packetBuf[i]);
  }
}",0.9994288977727012
55321,"public void testSinglePacketSerialization(){
  final byte[] sourceBuf=new byte[512];
  for (int i=0; i < sourceBuf.length; ++i) {
    sourceBuf[i]=(byte)(i % 23);
  }
  final byte[] targetBuf=new byte[8192];
  final MultiPacketOutputStream mpos=new MultiPacketOutputStream(targetBuf);
  try {
    mpos.write(sourceBuf);
  }
 catch (  IOException ioe) {
    fail(StringUtils.stringifyException(ioe));
  }
  final DatagramPacket[] packets=mpos.createPackets(TEST_REMOTE_ADDRESS,0);
  assertNotNull(packets);
  assertEquals(1,packets.length);
  final int offset=packets[0].getOffset();
  final int length=packets[0].getLength();
  assertEquals(0,offset);
  assertEquals(sourceBuf.length + RPCMessage.METADATA_SIZE,length);
  final byte[] packetBuf=packets[0].getData();
  for (int i=offset; i < (offset + length - RPCMessage.METADATA_SIZE); ++i) {
    assertEquals((byte)(i % 23),packetBuf[i]);
  }
  assertEquals(0,packetBuf[offset + length - RPCMessage.METADATA_SIZE]);
  assertEquals(0,packetBuf[offset + length - RPCMessage.METADATA_SIZE + 1]);
  assertEquals(1,packetBuf[offset + length - RPCMessage.METADATA_SIZE + 2]);
  assertEquals(0,packetBuf[offset + length - RPCMessage.METADATA_SIZE + 3]);
}","@Test public void testSinglePacketSerialization(){
  final byte[] sourceBuf=new byte[512];
  for (int i=0; i < sourceBuf.length; ++i) {
    sourceBuf[i]=(byte)(i % 23);
  }
  final byte[] targetBuf=new byte[8192];
  final MultiPacketOutputStream mpos=new MultiPacketOutputStream(targetBuf);
  try {
    mpos.write(sourceBuf);
  }
 catch (  IOException ioe) {
    fail(StringUtils.stringifyException(ioe));
  }
  final DatagramPacket[] packets=mpos.createPackets(TEST_REMOTE_ADDRESS);
  assertNotNull(packets);
  assertEquals(1,packets.length);
  final int offset=packets[0].getOffset();
  final int length=packets[0].getLength();
  assertEquals(0,offset);
  assertEquals(sourceBuf.length + RPCMessage.METADATA_SIZE,length);
  final byte[] packetBuf=packets[0].getData();
  for (int i=offset; i < (offset + length - RPCMessage.METADATA_SIZE); ++i) {
    assertEquals((byte)(i % 23),packetBuf[i]);
  }
  assertEquals(0,packetBuf[offset + length - RPCMessage.METADATA_SIZE]);
  assertEquals(0,packetBuf[offset + length - RPCMessage.METADATA_SIZE + 1]);
  assertEquals(1,packetBuf[offset + length - RPCMessage.METADATA_SIZE + 2]);
  assertEquals(0,packetBuf[offset + length - RPCMessage.METADATA_SIZE + 3]);
}",0.99667497921862
55322,"@Override public int testMethod(final boolean par1,final int par2,final List<String> par3){
  assertEquals(true,par1);
  assertEquals(this.counter.getAndIncrement(),par2);
  assertEquals(NUMBER_OF_TEST_STRINGS,par3.size());
  for (int i=0; i < NUMBER_OF_TEST_STRINGS; ++i) {
    assertEquals(constructTestString(i),par3.get(i));
  }
  return par2;
}","@Override public int testMethod(final boolean par1,final int par2,final List<String> par3){
  if (par1) {
    assertEquals(this.counter.getAndIncrement(),par2);
  }
  assertEquals(NUMBER_OF_TEST_STRINGS,par3.size());
  for (int i=0; i < NUMBER_OF_TEST_STRINGS; ++i) {
    assertEquals(constructTestString(i),par3.get(i));
  }
  return par2;
}",0.9522431259044862
55323,"/** 
 * Constructs a new job manager, starts its discovery service and its IPC service.
 */
public JobManager(final String configDir,final String executionMode){
  GlobalConfiguration.loadConfiguration(configDir);
  final String ipcAddressString=GlobalConfiguration.getString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY,null);
  InetAddress ipcAddress=null;
  if (ipcAddressString != null) {
    try {
      ipcAddress=InetAddress.getByName(ipcAddressString);
    }
 catch (    UnknownHostException e) {
      LOG.fatal(""String_Node_Str"" + ipcAddressString + ""String_Node_Str""+ StringUtils.stringifyException(e));
      System.exit(FAILURERETURNCODE);
    }
  }
  final int ipcPort=GlobalConfiguration.getInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY,ConfigConstants.DEFAULT_JOB_MANAGER_IPC_PORT);
  try {
    DiscoveryService.startDiscoveryService(ipcAddress,ipcPort);
  }
 catch (  DiscoveryException e) {
    LOG.fatal(""String_Node_Str"" + StringUtils.stringifyException(e));
    System.exit(FAILURERETURNCODE);
  }
  this.recommendedClientPollingInterval=GlobalConfiguration.getInteger(""String_Node_Str"",5);
  this.eventCollector=new EventCollector(this.recommendedClientPollingInterval);
  this.inputSplitManager=new InputSplitManager();
  final InetSocketAddress rpcServerAddress=new InetSocketAddress(ipcAddress,ipcPort);
  RPCService rpcService=null;
  try {
    rpcService=new RPCService(rpcServerAddress.getPort());
  }
 catch (  IOException ioe) {
    LOG.fatal(""String_Node_Str"" + StringUtils.stringifyException(ioe));
    System.exit(FAILURERETURNCODE);
  }
  this.rpcService=rpcService;
  this.rpcService.setProtocolCallbackHandler(JobManagerProtocol.class,this);
  LOG.info(""String_Node_Str"" + executionMode + ""String_Node_Str"");
  this.jobManagerPlugins=PluginManager.getJobManagerPlugins(this,configDir);
  if (""String_Node_Str"".equals(executionMode)) {
    try {
      this.instanceManager=new LocalInstanceManager(configDir,this.rpcService);
    }
 catch (    RuntimeException rte) {
      LOG.fatal(""String_Node_Str"" + StringUtils.stringifyException(rte));
      System.exit(FAILURERETURNCODE);
    }
  }
 else {
    final String instanceManagerClassName=JobManagerUtils.getInstanceManagerClassName(executionMode);
    LOG.info(""String_Node_Str"" + instanceManagerClassName + ""String_Node_Str"");
    this.instanceManager=JobManagerUtils.loadInstanceManager(instanceManagerClassName);
    if (this.instanceManager == null) {
      LOG.fatal(""String_Node_Str"" + instanceManagerClassName);
      System.exit(FAILURERETURNCODE);
    }
  }
  final String schedulerClassName=JobManagerUtils.getSchedulerClassName(executionMode);
  LOG.info(""String_Node_Str"" + schedulerClassName + ""String_Node_Str"");
  this.scheduler=JobManagerUtils.loadScheduler(schedulerClassName,this,this.instanceManager);
  if (this.scheduler == null) {
    LOG.fatal(""String_Node_Str"" + schedulerClassName);
    System.exit(FAILURERETURNCODE);
  }
  this.multicastManager=new MulticastManager(this.scheduler);
  if (GlobalConfiguration.getBoolean(ProfilingUtils.ENABLE_PROFILING_KEY,false)) {
    final String profilerClassName=GlobalConfiguration.getString(ProfilingUtils.JOBMANAGER_CLASSNAME_KEY,null);
    if (profilerClassName == null) {
      LOG.fatal(""String_Node_Str"");
      System.exit(FAILURERETURNCODE);
    }
    this.profiler=ProfilingUtils.loadJobManagerProfiler(profilerClassName,ipcAddress);
    if (this.profiler == null) {
      LOG.fatal(""String_Node_Str"");
      System.exit(FAILURERETURNCODE);
    }
  }
 else {
    this.profiler=null;
    LOG.debug(""String_Node_Str"");
  }
  Runtime.getRuntime().addShutdownHook(new JobManagerCleanUp(this));
}","/** 
 * Constructs a new job manager, starts its discovery service and its IPC service.
 */
public JobManager(final String configDir,final String executionMode){
  GlobalConfiguration.loadConfiguration(configDir);
  final String ipcAddressString=GlobalConfiguration.getString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY,null);
  InetAddress ipcAddress=null;
  if (ipcAddressString != null) {
    try {
      ipcAddress=InetAddress.getByName(ipcAddressString);
    }
 catch (    UnknownHostException e) {
      LOG.fatal(""String_Node_Str"" + ipcAddressString + ""String_Node_Str""+ StringUtils.stringifyException(e));
      System.exit(FAILURERETURNCODE);
    }
  }
  final int ipcPort=GlobalConfiguration.getInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY,ConfigConstants.DEFAULT_JOB_MANAGER_IPC_PORT);
  try {
    DiscoveryService.startDiscoveryService(ipcAddress,ipcPort);
  }
 catch (  DiscoveryException e) {
    LOG.fatal(""String_Node_Str"" + StringUtils.stringifyException(e));
    System.exit(FAILURERETURNCODE);
  }
  this.recommendedClientPollingInterval=GlobalConfiguration.getInteger(""String_Node_Str"",5);
  this.eventCollector=new EventCollector(this.recommendedClientPollingInterval);
  this.inputSplitManager=new InputSplitManager();
  final InetSocketAddress rpcServerAddress=new InetSocketAddress(ipcAddress,ipcPort);
  RPCService rpcService=null;
  try {
    rpcService=new RPCService(rpcServerAddress.getPort());
  }
 catch (  IOException ioe) {
    LOG.fatal(""String_Node_Str"" + StringUtils.stringifyException(ioe));
    System.exit(FAILURERETURNCODE);
  }
  this.rpcService=rpcService;
  this.rpcService.setProtocolCallbackHandler(JobManagerProtocol.class,this);
  this.rpcService.setProtocolCallbackHandler(JobManagementProtocol.class,this);
  this.rpcService.setProtocolCallbackHandler(ChannelLookupProtocol.class,this);
  LOG.info(""String_Node_Str"" + executionMode + ""String_Node_Str"");
  this.jobManagerPlugins=PluginManager.getJobManagerPlugins(this,configDir);
  if (""String_Node_Str"".equals(executionMode)) {
    try {
      this.instanceManager=new LocalInstanceManager(configDir,this.rpcService);
    }
 catch (    RuntimeException rte) {
      LOG.fatal(""String_Node_Str"" + StringUtils.stringifyException(rte));
      System.exit(FAILURERETURNCODE);
    }
  }
 else {
    final String instanceManagerClassName=JobManagerUtils.getInstanceManagerClassName(executionMode);
    LOG.info(""String_Node_Str"" + instanceManagerClassName + ""String_Node_Str"");
    this.instanceManager=JobManagerUtils.loadInstanceManager(instanceManagerClassName);
    if (this.instanceManager == null) {
      LOG.fatal(""String_Node_Str"" + instanceManagerClassName);
      System.exit(FAILURERETURNCODE);
    }
  }
  final String schedulerClassName=JobManagerUtils.getSchedulerClassName(executionMode);
  LOG.info(""String_Node_Str"" + schedulerClassName + ""String_Node_Str"");
  this.scheduler=JobManagerUtils.loadScheduler(schedulerClassName,this,this.instanceManager);
  if (this.scheduler == null) {
    LOG.fatal(""String_Node_Str"" + schedulerClassName);
    System.exit(FAILURERETURNCODE);
  }
  this.multicastManager=new MulticastManager(this.scheduler);
  if (GlobalConfiguration.getBoolean(ProfilingUtils.ENABLE_PROFILING_KEY,false)) {
    final String profilerClassName=GlobalConfiguration.getString(ProfilingUtils.JOBMANAGER_CLASSNAME_KEY,null);
    if (profilerClassName == null) {
      LOG.fatal(""String_Node_Str"");
      System.exit(FAILURERETURNCODE);
    }
    this.profiler=ProfilingUtils.loadJobManagerProfiler(profilerClassName,ipcAddress);
    if (this.profiler == null) {
      LOG.fatal(""String_Node_Str"");
      System.exit(FAILURERETURNCODE);
    }
  }
 else {
    this.profiler=null;
    LOG.debug(""String_Node_Str"");
  }
  Runtime.getRuntime().addShutdownHook(new JobManagerCleanUp(this));
}",0.9785809906291834
55324,"/** 
 * Constructs a new task manager, starts its IPC service and attempts to discover the job manager to receive an initial configuration.
 * @param configDir the directory containing the configuration files for the task manager
 */
public TaskManager(String configDir) throws Exception {
  GlobalConfiguration.loadConfiguration(configDir);
  final String address=GlobalConfiguration.getString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY,null);
  InetSocketAddress jobManagerAddress=null;
  if (address == null) {
    LOG.info(""String_Node_Str"");
    try {
      jobManagerAddress=DiscoveryService.getJobManagerAddress();
    }
 catch (    DiscoveryException e) {
      throw new Exception(""String_Node_Str"" + e.getMessage(),e);
    }
  }
 else {
    LOG.info(""String_Node_Str"");
    final int port=GlobalConfiguration.getInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY,ConfigConstants.DEFAULT_JOB_MANAGER_IPC_PORT);
    try {
      final InetAddress tmpAddress=InetAddress.getByName(address);
      jobManagerAddress=new InetSocketAddress(tmpAddress,port);
    }
 catch (    UnknownHostException e) {
      throw new Exception(""String_Node_Str"" + e.getMessage(),e);
    }
  }
  LOG.info(""String_Node_Str"" + jobManagerAddress);
  final int ipcPort=GlobalConfiguration.getInteger(ConfigConstants.TASK_MANAGER_IPC_PORT_KEY,ConfigConstants.DEFAULT_TASK_MANAGER_IPC_PORT);
  final int dataPort=GlobalConfiguration.getInteger(ConfigConstants.TASK_MANAGER_DATA_PORT_KEY,ConfigConstants.DEFAULT_TASK_MANAGER_DATA_PORT);
  InetAddress taskManagerAddress=null;
  try {
    taskManagerAddress=DiscoveryService.getTaskManagerAddress(jobManagerAddress.getAddress());
  }
 catch (  DiscoveryException e) {
    throw new Exception(""String_Node_Str"" + e.getMessage(),e);
  }
  this.localInstanceConnectionInfo=new InstanceConnectionInfo(taskManagerAddress,ipcPort,dataPort);
  RPCService rpcService=null;
  try {
    rpcService=new RPCService(ipcPort);
  }
 catch (  IOException e) {
    LOG.error(StringUtils.stringifyException(e));
    throw new Exception(""String_Node_Str"" + e.getMessage(),e);
  }
  this.rpcService=rpcService;
  LOG.info(""String_Node_Str"" + this.localInstanceConnectionInfo + ""String_Node_Str"");
  JobManagerProtocol jobManager=null;
  try {
    jobManager=this.rpcService.getProxy(jobManagerAddress,JobManagerProtocol.class);
  }
 catch (  IOException e) {
    LOG.error(StringUtils.stringifyException(e));
    throw new Exception(""String_Node_Str"" + e.getMessage(),e);
  }
  this.jobManager=jobManager;
  InputSplitProviderProtocol globalInputSplitProvider=null;
  try {
    globalInputSplitProvider=this.rpcService.getProxy(jobManagerAddress,InputSplitProviderProtocol.class);
  }
 catch (  IOException e) {
    LOG.error(StringUtils.stringifyException(e));
    throw new Exception(""String_Node_Str"" + e.getMessage(),e);
  }
  this.globalInputSplitProvider=globalInputSplitProvider;
  ChannelLookupProtocol lookupService=null;
  try {
    lookupService=this.rpcService.getProxy(jobManagerAddress,ChannelLookupProtocol.class);
  }
 catch (  IOException e) {
    LOG.error(StringUtils.stringifyException(e));
    throw new Exception(""String_Node_Str"" + e.getMessage(),e);
  }
  this.lookupService=lookupService;
  PluginCommunicationProtocol pluginCommunicationService=null;
  try {
    pluginCommunicationService=this.rpcService.getProxy(jobManagerAddress,PluginCommunicationProtocol.class);
  }
 catch (  IOException e) {
    LOG.error(StringUtils.stringifyException(e));
    throw new Exception(""String_Node_Str"" + e.getMessage(),e);
  }
  this.pluginCommunicationService=pluginCommunicationService;
  if (GlobalConfiguration.getBoolean(ProfilingUtils.ENABLE_PROFILING_KEY,false)) {
    final String profilerClassName=GlobalConfiguration.getString(ProfilingUtils.TASKMANAGER_CLASSNAME_KEY,null);
    if (profilerClassName == null) {
      LOG.error(""String_Node_Str"");
      throw new Exception(""String_Node_Str"");
    }
    this.profiler=ProfilingUtils.loadTaskManagerProfiler(profilerClassName,jobManagerAddress.getAddress(),this.localInstanceConnectionInfo);
  }
 else {
    this.profiler=null;
    LOG.debug(""String_Node_Str"");
  }
  final String[] tmpDirPaths=GlobalConfiguration.getString(ConfigConstants.TASK_MANAGER_TMP_DIR_KEY,ConfigConstants.DEFAULT_TASK_MANAGER_TMP_PATH).split(File.pathSeparator);
  checkTempDirs(tmpDirPaths);
  ByteBufferedChannelManager byteBufferedChannelManager=null;
  try {
    byteBufferedChannelManager=new ByteBufferedChannelManager(this.lookupService,this.localInstanceConnectionInfo);
  }
 catch (  IOException ioe) {
    LOG.error(StringUtils.stringifyException(ioe));
    throw new Exception(""String_Node_Str"" + ioe.getMessage(),ioe);
  }
  this.byteBufferedChannelManager=byteBufferedChannelManager;
  HardwareDescription hardware=HardwareDescriptionFactory.extractFromSystem();
  if (hardware == null) {
    LOG.warn(""String_Node_Str"");
  }
  long memorySize=GlobalConfiguration.getInteger(ConfigConstants.MEMORY_MANAGER_AVAILABLE_MEMORY_SIZE_KEY,-1);
  if (memorySize > 0) {
    hardware=HardwareDescriptionFactory.construct(hardware.getNumberOfCPUCores(),hardware.getSizeOfPhysicalMemory(),memorySize * 1024L * 1024L);
  }
  this.hardwareDescription=hardware;
  LOG.info(""String_Node_Str"" + (hardware.getSizeOfFreeMemory() >>> 20) + ""String_Node_Str"");
  try {
    this.memoryManager=new DefaultMemoryManager(hardware.getSizeOfFreeMemory());
  }
 catch (  RuntimeException rte) {
    LOG.fatal(""String_Node_Str"" + (hardware.getSizeOfFreeMemory() >>> 20) + ""String_Node_Str"",rte);
    throw rte;
  }
  this.ioManager=new IOManager(tmpDirPaths);
  this.taskManagerPlugins=PluginManager.getTaskManagerPlugins(this,configDir);
  Runtime.getRuntime().addShutdownHook(new TaskManagerCleanUp(this));
}","/** 
 * Constructs a new task manager, starts its IPC service and attempts to discover the job manager to receive an initial configuration.
 * @param configDir the directory containing the configuration files for the task manager
 */
public TaskManager(String configDir) throws Exception {
  GlobalConfiguration.loadConfiguration(configDir);
  final String address=GlobalConfiguration.getString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY,null);
  InetSocketAddress jobManagerAddress=null;
  if (address == null) {
    LOG.info(""String_Node_Str"");
    try {
      jobManagerAddress=DiscoveryService.getJobManagerAddress();
    }
 catch (    DiscoveryException e) {
      throw new Exception(""String_Node_Str"" + e.getMessage(),e);
    }
  }
 else {
    LOG.info(""String_Node_Str"");
    final int port=GlobalConfiguration.getInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY,ConfigConstants.DEFAULT_JOB_MANAGER_IPC_PORT);
    try {
      final InetAddress tmpAddress=InetAddress.getByName(address);
      jobManagerAddress=new InetSocketAddress(tmpAddress,port);
    }
 catch (    UnknownHostException e) {
      throw new Exception(""String_Node_Str"" + e.getMessage(),e);
    }
  }
  LOG.info(""String_Node_Str"" + jobManagerAddress);
  final int ipcPort=GlobalConfiguration.getInteger(ConfigConstants.TASK_MANAGER_IPC_PORT_KEY,ConfigConstants.DEFAULT_TASK_MANAGER_IPC_PORT);
  final int dataPort=GlobalConfiguration.getInteger(ConfigConstants.TASK_MANAGER_DATA_PORT_KEY,ConfigConstants.DEFAULT_TASK_MANAGER_DATA_PORT);
  InetAddress taskManagerAddress=null;
  try {
    taskManagerAddress=DiscoveryService.getTaskManagerAddress(jobManagerAddress.getAddress());
  }
 catch (  DiscoveryException e) {
    throw new Exception(""String_Node_Str"" + e.getMessage(),e);
  }
  this.localInstanceConnectionInfo=new InstanceConnectionInfo(taskManagerAddress,ipcPort,dataPort);
  RPCService rpcService=null;
  try {
    rpcService=new RPCService(ipcPort);
  }
 catch (  IOException e) {
    LOG.error(StringUtils.stringifyException(e));
    throw new Exception(""String_Node_Str"" + e.getMessage(),e);
  }
  this.rpcService=rpcService;
  this.rpcService.setProtocolCallbackHandler(TaskOperationProtocol.class,this);
  LOG.info(""String_Node_Str"" + this.localInstanceConnectionInfo + ""String_Node_Str"");
  JobManagerProtocol jobManager=null;
  try {
    jobManager=this.rpcService.getProxy(jobManagerAddress,JobManagerProtocol.class);
  }
 catch (  IOException e) {
    LOG.error(StringUtils.stringifyException(e));
    throw new Exception(""String_Node_Str"" + e.getMessage(),e);
  }
  this.jobManager=jobManager;
  InputSplitProviderProtocol globalInputSplitProvider=null;
  try {
    globalInputSplitProvider=this.rpcService.getProxy(jobManagerAddress,InputSplitProviderProtocol.class);
  }
 catch (  IOException e) {
    LOG.error(StringUtils.stringifyException(e));
    throw new Exception(""String_Node_Str"" + e.getMessage(),e);
  }
  this.globalInputSplitProvider=globalInputSplitProvider;
  ChannelLookupProtocol lookupService=null;
  try {
    lookupService=this.rpcService.getProxy(jobManagerAddress,ChannelLookupProtocol.class);
  }
 catch (  IOException e) {
    LOG.error(StringUtils.stringifyException(e));
    throw new Exception(""String_Node_Str"" + e.getMessage(),e);
  }
  this.lookupService=lookupService;
  PluginCommunicationProtocol pluginCommunicationService=null;
  try {
    pluginCommunicationService=this.rpcService.getProxy(jobManagerAddress,PluginCommunicationProtocol.class);
  }
 catch (  IOException e) {
    LOG.error(StringUtils.stringifyException(e));
    throw new Exception(""String_Node_Str"" + e.getMessage(),e);
  }
  this.pluginCommunicationService=pluginCommunicationService;
  if (GlobalConfiguration.getBoolean(ProfilingUtils.ENABLE_PROFILING_KEY,false)) {
    final String profilerClassName=GlobalConfiguration.getString(ProfilingUtils.TASKMANAGER_CLASSNAME_KEY,null);
    if (profilerClassName == null) {
      LOG.error(""String_Node_Str"");
      throw new Exception(""String_Node_Str"");
    }
    this.profiler=ProfilingUtils.loadTaskManagerProfiler(profilerClassName,jobManagerAddress.getAddress(),this.localInstanceConnectionInfo);
  }
 else {
    this.profiler=null;
    LOG.debug(""String_Node_Str"");
  }
  final String[] tmpDirPaths=GlobalConfiguration.getString(ConfigConstants.TASK_MANAGER_TMP_DIR_KEY,ConfigConstants.DEFAULT_TASK_MANAGER_TMP_PATH).split(File.pathSeparator);
  checkTempDirs(tmpDirPaths);
  ByteBufferedChannelManager byteBufferedChannelManager=null;
  try {
    byteBufferedChannelManager=new ByteBufferedChannelManager(this.lookupService,this.localInstanceConnectionInfo);
  }
 catch (  IOException ioe) {
    LOG.error(StringUtils.stringifyException(ioe));
    throw new Exception(""String_Node_Str"" + ioe.getMessage(),ioe);
  }
  this.byteBufferedChannelManager=byteBufferedChannelManager;
  HardwareDescription hardware=HardwareDescriptionFactory.extractFromSystem();
  if (hardware == null) {
    LOG.warn(""String_Node_Str"");
  }
  long memorySize=GlobalConfiguration.getInteger(ConfigConstants.MEMORY_MANAGER_AVAILABLE_MEMORY_SIZE_KEY,-1);
  if (memorySize > 0) {
    hardware=HardwareDescriptionFactory.construct(hardware.getNumberOfCPUCores(),hardware.getSizeOfPhysicalMemory(),memorySize * 1024L * 1024L);
  }
  this.hardwareDescription=hardware;
  LOG.info(""String_Node_Str"" + (hardware.getSizeOfFreeMemory() >>> 20) + ""String_Node_Str"");
  try {
    this.memoryManager=new DefaultMemoryManager(hardware.getSizeOfFreeMemory());
  }
 catch (  RuntimeException rte) {
    LOG.fatal(""String_Node_Str"" + (hardware.getSizeOfFreeMemory() >>> 20) + ""String_Node_Str"",rte);
    throw rte;
  }
  this.ioManager=new IOManager(tmpDirPaths);
  this.taskManagerPlugins=PluginManager.getTaskManagerPlugins(this,configDir);
  Runtime.getRuntime().addShutdownHook(new TaskManagerCleanUp(this));
}",0.9930951147937166
55325,"/** 
 * {@inheritDoc}
 */
@Override public void run(){
  final RPCProtocol callbackHandler=callbackHandlers.get(rpcRequest.getInterfaceName());
  if (callbackHandler == null) {
    Log.error(""String_Node_Str"" + rpcRequest.getInterfaceName());
    return;
  }
  Method method=null;
  try {
    method=callbackHandler.getClass().getMethod(rpcRequest.getMethodName(),rpcRequest.getParameterTypes());
  }
 catch (  Exception e) {
    e.printStackTrace();
    Log.error(""String_Node_Str"",e);
    return;
  }
  RPCResponse rpcResponse=null;
  try {
    final Object retVal=method.invoke(callbackHandler,rpcRequest.getArgs());
    rpcResponse=new RPCReturnValue(rpcRequest.getMessageID(),retVal);
  }
 catch (  InvocationTargetException ite) {
    rpcResponse=new RPCThrowable(rpcRequest.getMessageID(),ite.getTargetException());
  }
catch (  Exception e) {
    e.printStackTrace();
    Log.error(""String_Node_Str"",e);
    return;
  }
  final DatagramPacket[] packets=messageToPackets(remoteSocketAddress,rpcResponse);
  cachedResponses.put(messageID,new CachedResponse(System.currentTimeMillis(),packets));
  try {
    sendPackets(packets);
  }
 catch (  IOException e) {
    Log.error(""String_Node_Str"",e);
  }
}","/** 
 * {@inheritDoc}
 */
@Override public void run(){
  final Kryo kryo=threadLocalKryo.get();
  kryo.reset();
  final RPCEnvelope envelope=kryo.readObject(input,RPCEnvelope.class);
  final RPCMessage msg=envelope.getRPCMessage();
  if (msg instanceof RPCRequest) {
    processIncomingRPCRequest(remoteSocketAddress,(RPCRequest)msg);
  }
 else   if (msg instanceof RPCResponse) {
    processIncomingRPCResponse(remoteSocketAddress,(RPCResponse)msg);
  }
 else {
    processIncomingRPCCleanup(remoteSocketAddress,(RPCCleanup)msg);
  }
}",0.1067125645438898
55326,"private void processIncomingRPCRequest(final InetSocketAddress remoteSocketAddress,final RPCRequest rpcRequest){
  final Integer messageID=Integer.valueOf(rpcRequest.getMessageID());
  final CachedResponse cachedResponse=this.cachedResponses.get(messageID);
  if (cachedResponse != null) {
    try {
      sendPackets(cachedResponse.packets);
    }
 catch (    IOException e) {
      Log.error(""String_Node_Str"",e);
    }
    return;
  }
  final Runnable runnable=new Runnable(){
    /** 
 * {@inheritDoc}
 */
    @Override public void run(){
      final RPCProtocol callbackHandler=callbackHandlers.get(rpcRequest.getInterfaceName());
      if (callbackHandler == null) {
        Log.error(""String_Node_Str"" + rpcRequest.getInterfaceName());
        return;
      }
      Method method=null;
      try {
        method=callbackHandler.getClass().getMethod(rpcRequest.getMethodName(),rpcRequest.getParameterTypes());
      }
 catch (      Exception e) {
        e.printStackTrace();
        Log.error(""String_Node_Str"",e);
        return;
      }
      RPCResponse rpcResponse=null;
      try {
        final Object retVal=method.invoke(callbackHandler,rpcRequest.getArgs());
        rpcResponse=new RPCReturnValue(rpcRequest.getMessageID(),retVal);
      }
 catch (      InvocationTargetException ite) {
        rpcResponse=new RPCThrowable(rpcRequest.getMessageID(),ite.getTargetException());
      }
catch (      Exception e) {
        e.printStackTrace();
        Log.error(""String_Node_Str"",e);
        return;
      }
      final DatagramPacket[] packets=messageToPackets(remoteSocketAddress,rpcResponse);
      cachedResponses.put(messageID,new CachedResponse(System.currentTimeMillis(),packets));
      try {
        sendPackets(packets);
      }
 catch (      IOException e) {
        Log.error(""String_Node_Str"",e);
      }
    }
  }
;
  this.rpcHandlers.execute(runnable);
}","private void processIncomingRPCRequest(final InetSocketAddress remoteSocketAddress,final RPCRequest rpcRequest){
  final Integer messageID=Integer.valueOf(rpcRequest.getMessageID());
  if (this.requestsBeingProcessed.putIfAbsent(messageID,rpcRequest) != null) {
    Log.debug(""String_Node_Str"" + rpcRequest.getMessageID() + ""String_Node_Str"");
    return;
  }
  final CachedResponse cachedResponse=this.cachedResponses.get(messageID);
  if (cachedResponse != null) {
    try {
      sendPackets(cachedResponse.packets);
    }
 catch (    IOException e) {
      Log.error(""String_Node_Str"",e);
    }
 finally {
      this.requestsBeingProcessed.remove(messageID);
    }
    return;
  }
  final RPCProtocol callbackHandler=callbackHandlers.get(rpcRequest.getInterfaceName());
  if (callbackHandler == null) {
    Log.error(""String_Node_Str"" + rpcRequest.getInterfaceName());
    this.requestsBeingProcessed.remove(messageID);
    return;
  }
  try {
    final Method method=callbackHandler.getClass().getMethod(rpcRequest.getMethodName(),rpcRequest.getParameterTypes());
    RPCResponse rpcResponse=null;
    try {
      final Object retVal=method.invoke(callbackHandler,rpcRequest.getArgs());
      rpcResponse=new RPCReturnValue(rpcRequest.getMessageID(),retVal);
    }
 catch (    InvocationTargetException ite) {
      rpcResponse=new RPCThrowable(rpcRequest.getMessageID(),ite.getTargetException());
    }
    final DatagramPacket[] packets=messageToPackets(remoteSocketAddress,rpcResponse);
    cachedResponses.put(messageID,new CachedResponse(System.currentTimeMillis(),packets));
    sendPackets(packets);
  }
 catch (  Exception e) {
    Log.error(""String_Node_Str"",e);
  }
 finally {
    this.requestsBeingProcessed.remove(messageID);
  }
}",0.63308560418387
55327,"/** 
 * Default constructor for serialization/deserialization.
 */
public ChannelDeploymentDescriptor(){
  this.outputChannelID=new ChannelID();
  this.inputChannelID=new ChannelID();
}","/** 
 * Default constructor required by kryo.
 */
@SuppressWarnings(""String_Node_Str"") private ChannelDeploymentDescriptor(){
  this.outputChannelID=null;
  this.inputChannelID=null;
}",0.6666666666666666
55328,"/** 
 * Default constructor for serialization/deserialization.
 */
public GateDeploymentDescriptor(){
  this.gateID=null;
  this.channelType=null;
  this.compressionLevel=null;
  this.channels=null;
}","/** 
 * Default constructor required by kryo.
 */
@SuppressWarnings(""String_Node_Str"") private GateDeploymentDescriptor(){
  this.gateID=null;
  this.channelType=null;
  this.compressionLevel=null;
  this.channels=null;
}",0.7505938242280285
55329,"/** 
 * Tests the execution of a job with a large degree of parallelism. In particular, the tests checks that the overall runtime of the test does not exceed a certain time limit.
 */
@Test public void testExecutionWithLargeDoP(){
  final int numberOfSubtasks=64;
  File inputFile1=null;
  File inputFile2=null;
  File outputFile=null;
  File jarFile=new File(ServerTestUtils.getTempDir() + File.separator + ""String_Node_Str"");
  JobClient jobClient=null;
  try {
    inputFile1=ServerTestUtils.createInputFile(0);
    inputFile2=ServerTestUtils.createInputFile(0);
    outputFile=new File(ServerTestUtils.getTempDir() + File.separator + ServerTestUtils.getRandomFilename());
    JarFileCreator jfc=new JarFileCreator(jarFile);
    jfc.addClass(UnionTask.class);
    jfc.createJarFile();
    final JobGraph jg=new JobGraph(""String_Node_Str"" + numberOfSubtasks + ""String_Node_Str"");
    final JobFileInputVertex i1=new JobFileInputVertex(""String_Node_Str"",jg);
    i1.setFileInputClass(FileLineReader.class);
    i1.setFilePath(new Path(inputFile1.toURI()));
    i1.setNumberOfSubtasks(numberOfSubtasks);
    i1.setNumberOfSubtasksPerInstance(numberOfSubtasks);
    final JobFileInputVertex i2=new JobFileInputVertex(""String_Node_Str"",jg);
    i2.setFileInputClass(FileLineReader.class);
    i2.setFilePath(new Path(inputFile2.toURI()));
    i2.setNumberOfSubtasks(numberOfSubtasks);
    i2.setNumberOfSubtasksPerInstance(numberOfSubtasks);
    final JobTaskVertex f1=new JobTaskVertex(""String_Node_Str"",jg);
    f1.setTaskClass(DoubleTargetTask.class);
    f1.setNumberOfSubtasks(numberOfSubtasks);
    f1.setNumberOfSubtasksPerInstance(numberOfSubtasks);
    JobFileOutputVertex o1=new JobFileOutputVertex(""String_Node_Str"",jg);
    o1.setFileOutputClass(FileLineWriter.class);
    o1.setFilePath(new Path(outputFile.toURI()));
    o1.setNumberOfSubtasks(numberOfSubtasks);
    o1.setNumberOfSubtasksPerInstance(numberOfSubtasks);
    i1.setVertexToShareInstancesWith(o1);
    i2.setVertexToShareInstancesWith(o1);
    f1.setVertexToShareInstancesWith(o1);
    i1.connectTo(f1,ChannelType.NETWORK,CompressionLevel.NO_COMPRESSION,DistributionPattern.BIPARTITE);
    i2.connectTo(f1,ChannelType.NETWORK,CompressionLevel.NO_COMPRESSION,DistributionPattern.BIPARTITE);
    f1.connectTo(o1,ChannelType.NETWORK,CompressionLevel.NO_COMPRESSION,DistributionPattern.BIPARTITE);
    jg.addJar(new Path(jarFile.toURI()));
    jobClient=new JobClient(jg,configuration);
    try {
      jobClient.submitJobAndWait();
    }
 catch (    JobExecutionException e) {
      return;
    }
    fail(""String_Node_Str"");
  }
 catch (  JobGraphDefinitionException jgde) {
    fail(jgde.getMessage());
  }
catch (  IOException ioe) {
    fail(ioe.getMessage());
  }
 finally {
    if (inputFile1 != null) {
      inputFile1.delete();
    }
    if (inputFile2 != null) {
      inputFile2.delete();
    }
    if (outputFile != null) {
      if (outputFile.isDirectory()) {
        final String[] files=outputFile.list();
        final String outputDir=outputFile.getAbsolutePath();
        for (        final String file : files) {
          new File(outputDir + File.separator + file).delete();
        }
      }
      outputFile.delete();
    }
    if (jarFile != null) {
      jarFile.delete();
    }
    if (jobClient != null) {
      jobClient.close();
    }
  }
}","/** 
 * Tests the execution of a job with a large degree of parallelism. In particular, the tests checks that the overall runtime of the test does not exceed a certain time limit.
 */
@Test public void testExecutionWithLargeDoP(){
  final int numberOfSubtasks=64;
  File inputFile1=null;
  File inputFile2=null;
  File outputFile=null;
  File jarFile=new File(ServerTestUtils.getTempDir() + File.separator + ""String_Node_Str"");
  JobClient jobClient=null;
  try {
    inputFile1=ServerTestUtils.createInputFile(0);
    inputFile2=ServerTestUtils.createInputFile(0);
    outputFile=new File(ServerTestUtils.getTempDir() + File.separator + ServerTestUtils.getRandomFilename());
    JarFileCreator jfc=new JarFileCreator(jarFile);
    jfc.addClass(UnionTask.class);
    jfc.createJarFile();
    final JobGraph jg=new JobGraph(""String_Node_Str"" + numberOfSubtasks + ""String_Node_Str"");
    final JobFileInputVertex i1=new JobFileInputVertex(""String_Node_Str"",jg);
    i1.setFileInputClass(FileLineReader.class);
    i1.setFilePath(new Path(inputFile1.toURI()));
    i1.setNumberOfSubtasks(numberOfSubtasks);
    i1.setNumberOfSubtasksPerInstance(numberOfSubtasks);
    i1.setNumberOfExecutionRetries(1);
    final JobFileInputVertex i2=new JobFileInputVertex(""String_Node_Str"",jg);
    i2.setFileInputClass(FileLineReader.class);
    i2.setFilePath(new Path(inputFile2.toURI()));
    i2.setNumberOfSubtasks(numberOfSubtasks);
    i2.setNumberOfSubtasksPerInstance(numberOfSubtasks);
    i2.setNumberOfExecutionRetries(1);
    final JobTaskVertex f1=new JobTaskVertex(""String_Node_Str"",jg);
    f1.setTaskClass(DoubleTargetTask.class);
    f1.setNumberOfSubtasks(numberOfSubtasks);
    f1.setNumberOfSubtasksPerInstance(numberOfSubtasks);
    f1.setNumberOfExecutionRetries(1);
    JobFileOutputVertex o1=new JobFileOutputVertex(""String_Node_Str"",jg);
    o1.setFileOutputClass(FileLineWriter.class);
    o1.setFilePath(new Path(outputFile.toURI()));
    o1.setNumberOfSubtasks(numberOfSubtasks);
    o1.setNumberOfSubtasksPerInstance(numberOfSubtasks);
    o1.setNumberOfExecutionRetries(1);
    i1.setVertexToShareInstancesWith(o1);
    i2.setVertexToShareInstancesWith(o1);
    f1.setVertexToShareInstancesWith(o1);
    i1.connectTo(f1,ChannelType.NETWORK,CompressionLevel.NO_COMPRESSION,DistributionPattern.BIPARTITE);
    i2.connectTo(f1,ChannelType.NETWORK,CompressionLevel.NO_COMPRESSION,DistributionPattern.BIPARTITE);
    f1.connectTo(o1,ChannelType.NETWORK,CompressionLevel.NO_COMPRESSION,DistributionPattern.BIPARTITE);
    jg.addJar(new Path(jarFile.toURI()));
    jobClient=new JobClient(jg,configuration);
    try {
      jobClient.submitJobAndWait();
    }
 catch (    JobExecutionException e) {
      return;
    }
    fail(""String_Node_Str"");
  }
 catch (  JobGraphDefinitionException jgde) {
    fail(jgde.getMessage());
  }
catch (  IOException ioe) {
    fail(ioe.getMessage());
  }
 finally {
    if (inputFile1 != null) {
      inputFile1.delete();
    }
    if (inputFile2 != null) {
      inputFile2.delete();
    }
    if (outputFile != null) {
      if (outputFile.isDirectory()) {
        final String[] files=outputFile.list();
        final String outputDir=outputFile.getAbsolutePath();
        for (        final String file : files) {
          new File(outputDir + File.separator + file).delete();
        }
      }
      outputFile.delete();
    }
    if (jarFile != null) {
      jarFile.delete();
    }
    if (jobClient != null) {
      jobClient.close();
    }
  }
}",0.9771996492253728
55330,"@Override public int read(final byte[] b,final int off,final int len){
  if (this.read == this.len) {
    return -1;
  }
  final int r=Math.min(len,this.len - this.read);
  System.arraycopy(this.buf,this.read,b,off,r);
  this.read+=r;
  return r;
}","@Override public int read(final byte[] b,final int off,final int len){
  if (!moreDataAvailable()) {
    System.out.println(""String_Node_Str"");
    return -1;
  }
  final int r=Math.min(len,this.currentLength - this.read);
  System.arraycopy(this.currentBuffer,this.read,b,off,r);
  this.read+=r;
  return r;
}",0.7921146953405018
55331,"@Override public int available(){
  return (this.len - this.read);
}","@Override public int available(){
  System.out.println(""String_Node_Str"");
  if (!isComplete()) {
    return 0;
  }
  int available=this.currentLength - this.read;
  for (int i=this.nextPacketToRead; i < this.packets.length; ++i) {
    available+=this.packets[i].getLength() - RPCMessage.METADATA_SIZE;
  }
  return available;
}",0.2474747474747475
55332,"@Override public long skip(long n){
  final int dataLeftInBuffer=this.len - this.read;
  if (n > dataLeftInBuffer) {
    this.read=this.len;
    return dataLeftInBuffer;
  }
  this.read+=(int)n;
  return n;
}","@Override public long skip(long n){
  if (!moreDataAvailable()) {
    return 0L;
  }
  final int dataLeftInBuffer=this.currentLength - this.read;
  if (n > dataLeftInBuffer) {
    this.read=this.currentLength;
    return dataLeftInBuffer;
  }
  this.read+=(int)n;
  return n;
}",0.8329896907216495
55333,"@Override public void write(final byte[] b,final int off,final int len) throws IOException {
  if (this.totalLen + len > this.bufferSize) {
    throw new IOException(""String_Node_Str"");
  }
  int written=0;
  while (written < len) {
    if (this.lenInPacket == RPCMessage.MAXIMUM_MSG_SIZE) {
      this.lenInPacket=0;
      this.totalLen+=RPCMessage.METADATA_SIZE;
    }
    final int amountOfDataToWrite=Math.min((len - written),(RPCMessage.MAXIMUM_MSG_SIZE - this.lenInPacket));
    System.arraycopy(b,off,this.buf,this.totalLen,amountOfDataToWrite);
    this.lenInPacket+=amountOfDataToWrite;
    this.totalLen+=amountOfDataToWrite;
    written+=amountOfDataToWrite;
  }
}","@Override public void write(final byte[] b,final int off,final int len) throws IOException {
  if (this.totalLen + len > this.bufferSize) {
    throw new IOException(""String_Node_Str"");
  }
  int written=0;
  while (written < len) {
    if (this.lenInPacket == RPCMessage.MAXIMUM_MSG_SIZE) {
      this.lenInPacket=0;
      this.totalLen+=RPCMessage.METADATA_SIZE;
    }
    final int amountOfDataToWrite=Math.min((len - written),(RPCMessage.MAXIMUM_MSG_SIZE - this.lenInPacket));
    System.arraycopy(b,off + written,this.buf,this.totalLen,amountOfDataToWrite);
    this.lenInPacket+=amountOfDataToWrite;
    this.totalLen+=amountOfDataToWrite;
    written+=amountOfDataToWrite;
  }
}",0.9926470588235294
55334,"@Override public void run(){
  final Kryo kryo=RPCService.createKryoObject();
  byte[] buf=new byte[RPCMessage.MAXIMUM_MSG_SIZE + RPCMessage.METADATA_SIZE];
  DatagramPacket dp=new DatagramPacket(buf,buf.length);
  while (!this.shutdownRequested) {
    try {
      this.socket.receive(dp);
    }
 catch (    SocketException se) {
      if (this.shutdownRequested) {
        return;
      }
      Log.error(""String_Node_Str"",se);
      return;
    }
catch (    IOException ioe) {
      Log.error(""String_Node_Str"",ioe);
      return;
    }
    final InetSocketAddress remoteSocketAddress=(InetSocketAddress)dp.getSocketAddress();
    final int length=dp.getLength() - RPCMessage.METADATA_SIZE;
    final byte[] dbbuf=dp.getData();
    final short numberOfPackets=byteArrayToShort(dbbuf,length + 2);
    Input input=null;
    if (numberOfPackets == 1) {
      final SinglePacketInputStream spis=new SinglePacketInputStream(dbbuf,length);
      input=new Input(spis);
    }
 else {
      final MultiPacketInputStream mpis=this.rpcService.getIncompleteInputStream(remoteSocketAddress,0,numberOfPackets);
      mpis.addPacket(byteArrayToShort(dbbuf,length),dp);
      if (!mpis.isComplete()) {
        buf=new byte[RPCMessage.MAXIMUM_MSG_SIZE + RPCMessage.METADATA_SIZE];
        dp=new DatagramPacket(buf,buf.length);
        continue;
      }
      this.rpcService.removeIncompleteInputStream(remoteSocketAddress,0);
      System.out.println(""String_Node_Str"");
      continue;
    }
    final RPCEnvelope envelope=kryo.readObject(input,RPCEnvelope.class);
    final RPCMessage msg=envelope.getRPCMessage();
    if (msg instanceof RPCRequest) {
      while (true) {
        try {
          this.rpcService.processIncomingRPCRequest(remoteSocketAddress,(RPCRequest)msg);
          break;
        }
 catch (        InterruptedException e) {
          if (this.shutdownRequested) {
            return;
          }
 else {
            continue;
          }
        }
      }
    }
 else     if (msg instanceof RPCResponse) {
      this.rpcService.processIncomingRPCResponse(remoteSocketAddress,(RPCResponse)msg);
    }
 else {
      this.rpcService.processIncomingRPCCleanup(remoteSocketAddress,(RPCCleanup)msg);
    }
  }
}","@Override public void run(){
  final Kryo kryo=RPCService.createKryoObject();
  byte[] buf=new byte[RPCMessage.MAXIMUM_MSG_SIZE + RPCMessage.METADATA_SIZE];
  DatagramPacket dp=new DatagramPacket(buf,buf.length);
  while (!this.shutdownRequested) {
    try {
      this.socket.receive(dp);
    }
 catch (    SocketException se) {
      if (this.shutdownRequested) {
        return;
      }
      Log.error(""String_Node_Str"",se);
      return;
    }
catch (    IOException ioe) {
      Log.error(""String_Node_Str"",ioe);
      return;
    }
    final InetSocketAddress remoteSocketAddress=(InetSocketAddress)dp.getSocketAddress();
    final int length=dp.getLength() - RPCMessage.METADATA_SIZE;
    final byte[] dbbuf=dp.getData();
    final short numberOfPackets=byteArrayToShort(dbbuf,length + 2);
    Input input=null;
    if (numberOfPackets == 1) {
      final SinglePacketInputStream spis=new SinglePacketInputStream(dbbuf,length);
      input=new Input(spis);
    }
 else {
      final MultiPacketInputStream mpis=this.rpcService.getIncompleteInputStream(remoteSocketAddress,0,numberOfPackets);
      mpis.addPacket(byteArrayToShort(dbbuf,length),dp);
      if (!mpis.isComplete()) {
        buf=new byte[RPCMessage.MAXIMUM_MSG_SIZE + RPCMessage.METADATA_SIZE];
        dp=new DatagramPacket(buf,buf.length);
        continue;
      }
      this.rpcService.removeIncompleteInputStream(remoteSocketAddress,0);
      input=new Input(mpis);
    }
    final RPCEnvelope envelope=kryo.readObject(input,RPCEnvelope.class);
    final RPCMessage msg=envelope.getRPCMessage();
    if (msg instanceof RPCRequest) {
      while (true) {
        try {
          this.rpcService.processIncomingRPCRequest(remoteSocketAddress,(RPCRequest)msg);
          break;
        }
 catch (        InterruptedException e) {
          if (this.shutdownRequested) {
            return;
          }
 else {
            continue;
          }
        }
      }
    }
 else     if (msg instanceof RPCResponse) {
      this.rpcService.processIncomingRPCResponse(remoteSocketAddress,(RPCResponse)msg);
    }
 else {
      this.rpcService.processIncomingRPCCleanup(remoteSocketAddress,(RPCCleanup)msg);
    }
  }
}",0.9831894593366652
55335,"@Override public void run(){
  final Kryo kryo=RPCService.createKryoObject();
  final byte[] buf=new byte[SEND_BUFFER];
  final MultiPacketOutputStream mbos=new MultiPacketOutputStream(buf);
  while (!this.shutdownRequested) {
    SendingRequest sendingRequest=null;
    try {
      sendingRequest=this.msgQueue.take();
    }
 catch (    InterruptedException ie) {
      if (this.shutdownRequested) {
        return;
      }
 else {
        continue;
      }
    }
    mbos.reset();
    final Output output=new Output(mbos);
    kryo.writeObject(output,new RPCEnvelope(sendingRequest.rpcMessage));
    output.close();
    mbos.close();
    try {
      mbos.sendPackets(this.socket,sendingRequest.remoteSocketAddress,sendingRequest.rpcMessage.getRequestID());
    }
 catch (    IOException ioe) {
      Log.error(""String_Node_Str"",ioe);
      return;
    }
  }
}","@Override public void run(){
  final Kryo kryo=RPCService.createKryoObject();
  final byte[] buf=new byte[SEND_BUFFER];
  final MultiPacketOutputStream mbos=new MultiPacketOutputStream(buf);
  while (!this.shutdownRequested) {
    SendingRequest sendingRequest=null;
    try {
      sendingRequest=this.msgQueue.take();
    }
 catch (    InterruptedException ie) {
      if (this.shutdownRequested) {
        return;
      }
 else {
        continue;
      }
    }
    mbos.reset();
    final Output output=new Output(mbos);
    kryo.writeObject(output,new RPCEnvelope(sendingRequest.rpcMessage));
    output.close();
    mbos.close();
    final DatagramPacket[] packets=mbos.createPackets(sendingRequest.remoteSocketAddress,sendingRequest.rpcMessage.getRequestID());
    try {
      for (int i=0; i < packets.length; ++i) {
        this.socket.send(packets[i]);
      }
    }
 catch (    IOException ioe) {
      Log.error(""String_Node_Str"",ioe);
      return;
    }
  }
}",0.9018538713195202
55336,"/** 
 * Construct a Path from a scheme, an authority and a path string.
 * @param scheme the scheme string
 * @param authority the authority string
 * @param path the path string
 */
public Path(String scheme,String authority,String path){
  checkPathArg(path);
  initialize(scheme,authority,path);
}","/** 
 * Construct a Path from a scheme, an authority and a path string.
 * @param scheme the scheme string
 * @param authority the authority string
 * @param path the path string
 */
public Path(final String scheme,final String authority,final String path){
  checkPathArg(path);
  initialize(scheme,authority,path);
}",0.970873786407767
55337,"public int compareTo(Object o){
  Path that=(Path)o;
  return this.uri.compareTo(that.uri);
}","public int compareTo(final Object o){
  final Path that=(Path)o;
  return this.uri.compareTo(that.uri);
}",0.9393939393939394
55338,"/** 
 * Adds a suffix to the final name in the path.
 * @param the suffix to be added
 * @return the new path including the suffix
 */
public Path suffix(String suffix){
  return new Path(getParent(),getName() + suffix);
}","/** 
 * Adds a suffix to the final name in the path.
 * @param the suffix to be added
 * @return the new path including the suffix
 */
public Path suffix(final String suffix){
  return new Path(getParent(),getName() + suffix);
}",0.9866666666666668
55339,"/** 
 * Checks if the provided path string contains a windows drive letter.
 * @param path the path to check
 * @param slashed <code>true</code> to indicate the first character of the string is a slash, <code>false</code> otherwise
 * @return <code>true</code> if the path string contains a windows drive letter, <code>false</code> otherwise
 */
private boolean hasWindowsDrive(String path,boolean slashed){
  if (!WINDOWS) {
    return false;
  }
  final int start=slashed ? 1 : 0;
  return path.length() >= start + 2 && (slashed ? path.charAt(0) == '/' : true) && path.charAt(start + 1) == ':' && ((path.charAt(start) >= 'A' && path.charAt(start) <= 'Z') || (path.charAt(start) >= 'a' && path.charAt(start) <= 'z'));
}","/** 
 * Checks if the provided path string contains a windows drive letter.
 * @param path the path to check
 * @param slashed <code>true</code> to indicate the first character of the string is a slash, <code>false</code> otherwise
 * @return <code>true</code> if the path string contains a windows drive letter, <code>false</code> otherwise
 */
private boolean hasWindowsDrive(final String path,final boolean slashed){
  if (!WINDOWS) {
    return false;
  }
  final int start=slashed ? 1 : 0;
  return path.length() >= start + 2 && (slashed ? path.charAt(0) == '/' : true) && path.charAt(start + 1) == ':' && ((path.charAt(start) >= 'A' && path.charAt(start) <= 'Z') || (path.charAt(start) >= 'a' && path.charAt(start) <= 'z'));
}",0.9917355371900828
55340,"/** 
 * {@inheritDoc}
 */
@Override public boolean equals(Object o){
  if (!(o instanceof Path)) {
    return false;
  }
  Path that=(Path)o;
  return this.uri.equals(that.uri);
}","/** 
 * {@inheritDoc}
 */
@Override public boolean equals(final Object o){
  if (!(o instanceof Path)) {
    return false;
  }
  final Path that=(Path)o;
  return this.uri.equals(that.uri);
}",0.9675675675675676
55341,"/** 
 * Returns a qualified path object.
 * @param fs the FileSystem that should be used to obtain the current working directory
 * @return the qualified path object
 */
public Path makeQualified(FileSystem fs){
  Path path=this;
  if (!isAbsolute()) {
    path=new Path(fs.getWorkingDirectory(),this);
  }
  final URI pathUri=path.toUri();
  final URI fsUri=fs.getUri();
  String scheme=pathUri.getScheme();
  String authority=pathUri.getAuthority();
  if (scheme != null && (authority != null || fsUri.getAuthority() == null))   return path;
  if (scheme == null) {
    scheme=fsUri.getScheme();
  }
  if (authority == null) {
    authority=fsUri.getAuthority();
    if (authority == null) {
      authority=""String_Node_Str"";
    }
  }
  return new Path(scheme + ""String_Node_Str"" + ""String_Node_Str""+ authority+ pathUri.getPath());
}","/** 
 * Returns a qualified path object.
 * @param fs the FileSystem that should be used to obtain the current working directory
 * @return the qualified path object
 */
public Path makeQualified(final FileSystem fs){
  Path path=this;
  if (!isAbsolute()) {
    path=new Path(fs.getWorkingDirectory(),this);
  }
  final URI pathUri=path.toUri();
  final URI fsUri=fs.getUri();
  String scheme=pathUri.getScheme();
  String authority=pathUri.getAuthority();
  if (scheme != null && (authority != null || fsUri.getAuthority() == null))   return path;
  if (scheme == null) {
    scheme=fsUri.getScheme();
  }
  if (authority == null) {
    authority=fsUri.getAuthority();
    if (authority == null) {
      authority=""String_Node_Str"";
    }
  }
  return new Path(scheme + ""String_Node_Str"" + ""String_Node_Str""+ authority+ pathUri.getPath());
}",0.9964285714285714
55342,"/** 
 * Initializes a path object given the scheme, authority and path string.
 * @param scheme the scheme string.
 * @param authority the authority string.
 * @param path the path string.
 */
private void initialize(String scheme,String authority,String path){
  try {
    this.uri=new URI(scheme,authority,normalizePath(path),null,null).normalize();
  }
 catch (  URISyntaxException e) {
    throw new IllegalArgumentException(e);
  }
}","/** 
 * Initializes a path object given the scheme, authority and path string.
 * @param scheme the scheme string.
 * @param authority the authority string.
 * @param path the path string.
 */
private void initialize(final String scheme,final String authority,final String path){
  try {
    this.uri=new URI(scheme,authority,normalizePath(path),null,null).normalize();
  }
 catch (  URISyntaxException e) {
    throw new IllegalArgumentException(e);
  }
}",0.9798657718120806
55343,"/** 
 * Checks if the provided path string is either null or has zero length and throws a   {@link IllegalArgumentException} if any of the two conditions apply.
 * @param path the path string to be checked
 */
private void checkPathArg(String path){
  if (path == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (path.length() == 0) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
}","/** 
 * Checks if the provided path string is either null or has zero length and throws a   {@link IllegalArgumentException} if any of the two conditions apply.
 * @param path the path string to be checked
 */
private void checkPathArg(final String path){
  if (path == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (path.length() == 0) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
}",0.9930232558139536
55344,"/** 
 * Writes the JAR files of all vertices in array <code>jobVertices</code> to the specified output stream.
 * @param kryo the kryo object
 * @param out the output stream to write the JAR files to
 * @param jobVertices array of job vertices whose required JAR file are to be written to the output stream
 * @throws IOException thrown if an error occurs while writing to the stream
 */
private void writeRequiredJarFiles(final Kryo kryo,final Output out,final AbstractJobVertex[] jobVertices) throws IOException {
  final FileSystem fs=FileSystem.getLocalFileSystem();
  for (int i=0; i < this.userJars.size(); i++) {
    if (!fs.exists(this.userJars.get(i))) {
      throw new IOException(""String_Node_Str"" + this.userJars.get(i));
    }
  }
  out.writeInt(this.userJars.size());
  for (int i=0; i < this.userJars.size(); i++) {
    final Path jar=this.userJars.get(i);
    kryo.writeObject(out,jar);
    final FileStatus file=fs.getFileStatus(jar);
    out.writeLong(file.getLen());
    final FSDataInputStream inStream=fs.open(this.userJars.get(i));
    final byte[] buf=new byte[BUFFERSIZE];
    int read=inStream.read(buf,0,buf.length);
    while (read > 0) {
      out.write(buf,0,read);
      read=inStream.read(buf,0,buf.length);
    }
  }
}","/** 
 * Writes the JAR files of all vertices in array <code>jobVertices</code> to the specified output stream.
 * @param kryo the kryo object
 * @param out the output stream to write the JAR files to
 * @param jobVertices array of job vertices whose required JAR file are to be written to the output stream
 * @throws IOException thrown if an error occurs while writing to the stream
 */
private void writeRequiredJarFiles(final Kryo kryo,final Output out,final AbstractJobVertex[] jobVertices) throws IOException {
  final FileSystem fs=FileSystem.getLocalFileSystem();
  for (int i=0; i < this.userJars.size(); i++) {
    if (!fs.exists(this.userJars.get(i))) {
      throw new IOException(""String_Node_Str"" + this.userJars.get(i));
    }
  }
  out.writeInt(this.userJars.size());
  for (int i=0; i < this.userJars.size(); i++) {
    final Path jar=this.userJars.get(i);
    jar.write(kryo,out);
    final FileStatus file=fs.getFileStatus(jar);
    out.writeInt((int)file.getLen());
    final FSDataInputStream inStream=fs.open(this.userJars.get(i));
    final byte[] buf=new byte[BUFFERSIZE];
    int read=inStream.read(buf,0,buf.length);
    while (read > 0) {
      out.write(buf,0,read);
      read=inStream.read(buf,0,buf.length);
    }
  }
}",0.9296
55345,"/** 
 * Reads required JAR files from an input stream and adds them to the library cache manager.
 * @param kryo the kryo object
 * @param input the data stream to read the JAR files from
 * @throws IOException thrown if an error occurs while reading the stream
 */
private void readRequiredJarFiles(final Kryo kryo,final Input input) throws IOException {
  final int numJars=input.readInt();
  if (numJars > 0) {
    for (int i=0; i < numJars; i++) {
      final Path p=kryo.readObject(input,Path.class);
      this.userJars.add(p);
      final int sizeOfJar=input.readInt();
      LibraryCacheManager.addLibrary(this.jobID,p,sizeOfJar,input);
    }
  }
  LibraryCacheManager.register(this.jobID,this.userJars.toArray(new Path[0]));
}","/** 
 * Reads required JAR files from an input stream and adds them to the library cache manager.
 * @param kryo the kryo object
 * @param input the data stream to read the JAR files from
 * @throws IOException thrown if an error occurs while reading the stream
 */
private void readRequiredJarFiles(final Kryo kryo,final Input input) throws IOException {
  final int numJars=input.readInt();
  if (numJars > 0) {
    for (int i=0; i < numJars; i++) {
      final Path p=new Path();
      p.read(kryo,input);
      this.userJars.add(p);
      final int sizeOfJar=input.readInt();
      LibraryCacheManager.addLibrary(this.jobID,p,sizeOfJar,input);
    }
  }
  LibraryCacheManager.register(this.jobID,this.userJars.toArray(new Path[0]));
}",0.9613034623217924
55346,"/** 
 * Creates a copy of the given object by an in-memory serialization and subsequent deserialization.
 * @param original the original object to be copied
 * @return the copy of original object created by the original object's serialization/deserialization methods
 * @throws IOException thrown if an error occurs while creating the copy of the object
 */
public static <T>T createCopy(final T original){
  final Kryo kryo=new Kryo();
  return (T)kryo.copy(original);
}","/** 
 * Creates a copy of the given object by an in-memory serialization and subsequent deserialization.
 * @param original the original object to be copied
 * @return the copy of original object created by the original object's serialization/deserialization methods
 * @throws IOException thrown if an error occurs while creating the copy of the object
 */
@SuppressWarnings(""String_Node_Str"") public static <T>T createCopy(final T original){
  final Kryo kryo=new Kryo();
  final byte[] buf=new byte[8192];
  final Output output=new Output(buf);
  kryo.writeObject(output,original);
  output.flush();
  final Input input=new Input(buf);
  return (T)kryo.readObject(input,original.getClass());
}",0.7849185946872322
55347,"/** 
 * Creates a copy of the given object by an in-memory serialization and subsequent deserialization.
 * @param original the original object to be copied
 * @return the copy of original object
 * @throws IOException thrown if an error occurs while creating the copy of the object
 */
@SuppressWarnings(""String_Node_Str"") public static <T>T createCopy(final T original){
  final Kryo kryo=new Kryo();
  final byte[] buf=new byte[8192];
  Output output=new Output(buf);
  kryo.writeObject(output,original);
  output.flush();
  Input input=new Input(buf);
  return (T)kryo.readObject(input,original.getClass());
}","/** 
 * Creates a copy of the given object by an in-memory serialization and subsequent deserialization.
 * @param original the original object to be copied
 * @return the copy of original object
 * @throws IOException thrown if an error occurs while creating the copy of the object
 */
@SuppressWarnings(""String_Node_Str"") public static <T>T createCopy(final T original){
  final Kryo kryo=new Kryo();
  final byte[] buf=new byte[8192];
  final Output output=new Output(buf);
  kryo.writeObject(output,original);
  output.flush();
  final Input input=new Input(buf);
  return (T)kryo.readObject(input,original.getClass());
}",0.9903069466882068
55348,"@Override public void configure(Configuration config){
  super.configure(config);
  numFields=config.getInteger(NUM_FIELDS_PARAMETER,-1);
  if (numFields < 1) {
    throw new IllegalArgumentException(""String_Node_Str"" + ""String_Node_Str"");
  }
  int[] textPosIdx=new int[numFields];
  boolean anyTextPosSet=false;
  boolean allTextPosSet=true;
  int maxTextPos=-1;
  for (int i=0; i < numFields; i++) {
    int pos=config.getInteger(TEXT_POSITION_PARAMETER_PREFIX + i,-1);
    if (pos == -1) {
      allTextPosSet=false;
      textPosIdx[i]=i;
      maxTextPos=i;
    }
 else {
      anyTextPosSet=true;
      textPosIdx[i]=pos;
      maxTextPos=pos > maxTextPos ? pos : maxTextPos;
    }
  }
  if (anyTextPosSet && !allTextPosSet) {
    throw new IllegalArgumentException(""String_Node_Str"" + ""String_Node_Str"");
  }
  int[] recPosIdx=new int[numFields];
  boolean anyRecPosSet=false;
  boolean allRecPosSet=true;
  for (int i=0; i < numFields; i++) {
    int pos=config.getInteger(RECORD_POSITION_PARAMETER_PREFIX + i,-1);
    if (pos == -1) {
      allRecPosSet=false;
      recPosIdx[i]=i;
    }
 else {
      anyRecPosSet=true;
      recPosIdx[i]=pos;
    }
  }
  if (anyRecPosSet && !allRecPosSet) {
    throw new IllegalArgumentException(""String_Node_Str"" + ""String_Node_Str"");
  }
  this.fieldParsers=new FieldParser[maxTextPos + 1];
  this.fieldValues=new Value[maxTextPos + 1];
  this.recordPositions=new int[maxTextPos + 1];
  for (int j=0; j < maxTextPos; j++) {
    fieldParsers[j]=null;
    fieldValues[j]=null;
    recordPositions[j]=-1;
  }
  for (int i=0; i < numFields; i++) {
    int pos=textPosIdx[i];
    recordPositions[pos]=recPosIdx[i];
    @SuppressWarnings(""String_Node_Str"") Class<? extends FieldParser<Value>> clazz=(Class<? extends FieldParser<Value>>)config.getClass(FIELD_PARSER_PARAMETER_PREFIX + i,null);
    if (clazz == null) {
      throw new IllegalArgumentException(""String_Node_Str"" + ""String_Node_Str"" + i);
    }
    try {
      fieldParsers[pos]=clazz.newInstance();
    }
 catch (    InstantiationException ie) {
      throw new IllegalArgumentException(""String_Node_Str"" + ""String_Node_Str"" + i);
    }
catch (    IllegalAccessException e) {
      throw new IllegalArgumentException(""String_Node_Str"" + ""String_Node_Str"" + i);
    }
    fieldValues[pos]=fieldParsers[pos].getValue();
  }
  final String fieldDelimStr=config.getString(FIELD_DELIMITER_PARAMETER,""String_Node_Str"");
  if (fieldDelimStr.length() != 1) {
    throw new IllegalArgumentException(""String_Node_Str"" + ""String_Node_Str"");
  }
  this.fieldDelim=fieldDelimStr.charAt(0);
}","@Override public void configure(Configuration config){
  super.configure(config);
  numFields=config.getInteger(NUM_FIELDS_PARAMETER,-1);
  if (numFields < 1) {
    throw new IllegalArgumentException(""String_Node_Str"" + ""String_Node_Str"");
  }
  int[] textPosIdx=new int[numFields];
  boolean anyTextPosSet=false;
  boolean allTextPosSet=true;
  int maxTextPos=-1;
  for (int i=0; i < numFields; i++) {
    int pos=config.getInteger(TEXT_POSITION_PARAMETER_PREFIX + i,-1);
    if (pos == -1) {
      allTextPosSet=false;
      textPosIdx[i]=i;
      maxTextPos=i;
    }
 else {
      anyTextPosSet=true;
      textPosIdx[i]=pos;
      maxTextPos=pos > maxTextPos ? pos : maxTextPos;
    }
  }
  if (anyTextPosSet && !allTextPosSet) {
    throw new IllegalArgumentException(""String_Node_Str"" + ""String_Node_Str"");
  }
  int[] recPosIdx=new int[numFields];
  boolean anyRecPosSet=false;
  boolean allRecPosSet=true;
  for (int i=0; i < numFields; i++) {
    int pos=config.getInteger(RECORD_POSITION_PARAMETER_PREFIX + i,-1);
    if (pos == -1) {
      allRecPosSet=false;
      recPosIdx[i]=i;
    }
 else {
      anyRecPosSet=true;
      recPosIdx[i]=pos;
    }
  }
  if (anyRecPosSet && !allRecPosSet) {
    throw new IllegalArgumentException(""String_Node_Str"" + ""String_Node_Str"");
  }
  this.fieldParsers=new FieldParser[maxTextPos + 1];
  this.fieldValues=new Value[maxTextPos + 1];
  this.recordPositions=new int[maxTextPos + 1];
  for (int j=0; j < maxTextPos; j++) {
    fieldParsers[j]=null;
    fieldValues[j]=null;
    recordPositions[j]=-1;
  }
  for (int i=0; i < numFields; i++) {
    int pos=textPosIdx[i];
    recordPositions[pos]=recPosIdx[i];
    @SuppressWarnings(""String_Node_Str"") Class<? extends FieldParser<Value>> clazz=(Class<? extends FieldParser<Value>>)config.getClass(FIELD_PARSER_PARAMETER_PREFIX + i,null);
    if (clazz == null) {
      throw new IllegalArgumentException(""String_Node_Str"" + ""String_Node_Str"" + i);
    }
    try {
      fieldParsers[pos]=clazz.newInstance();
      fieldParsers[pos].configure(config);
    }
 catch (    InstantiationException ie) {
      throw new IllegalArgumentException(""String_Node_Str"" + ""String_Node_Str"" + i);
    }
catch (    IllegalAccessException e) {
      throw new IllegalArgumentException(""String_Node_Str"" + ""String_Node_Str"" + i);
    }
    fieldValues[pos]=fieldParsers[pos].getValue();
  }
  final String fieldDelimStr=config.getString(FIELD_DELIMITER_PARAMETER,""String_Node_Str"");
  if (fieldDelimStr.length() != 1) {
    throw new IllegalArgumentException(""String_Node_Str"" + ""String_Node_Str"");
  }
  this.fieldDelim=fieldDelimStr.charAt(0);
}",0.9917577151619704
55349,"@Test public void testConfigure(){
  try {
    Configuration config=new Configuration();
    config.setString(RecordInputFormat.FILE_PARAMETER_KEY,""String_Node_Str"");
    boolean validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertFalse(validConfig);
    config.setInteger(RecordInputFormat.NUM_FIELDS_PARAMETER,2);
    validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertFalse(validConfig);
    config.setClass(RecordInputFormat.FIELD_PARSER_PARAMETER_PREFIX + 0,DecimalTextIntParser.class);
    config.setClass(RecordInputFormat.FIELD_PARSER_PARAMETER_PREFIX + 1,DecimalTextIntParser.class);
    validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertTrue(validConfig);
    config.setInteger(RecordInputFormat.NUM_FIELDS_PARAMETER,3);
    validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertFalse(validConfig);
    config.setClass(RecordInputFormat.FIELD_PARSER_PARAMETER_PREFIX + 2,DecimalTextIntParser.class);
    config.setString(RecordInputFormat.FIELD_DELIMITER_PARAMETER,""String_Node_Str"");
    validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertFalse(validConfig);
    config.setString(RecordInputFormat.FIELD_DELIMITER_PARAMETER,""String_Node_Str"");
    validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertTrue(validConfig);
    config.setInteger(RecordInputFormat.TEXT_POSITION_PARAMETER_PREFIX + 1,0);
    validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertFalse(validConfig);
    config.setInteger(RecordInputFormat.TEXT_POSITION_PARAMETER_PREFIX + 0,3);
    config.setInteger(RecordInputFormat.TEXT_POSITION_PARAMETER_PREFIX + 2,9);
    validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertTrue(validConfig);
    config.setInteger(RecordInputFormat.RECORD_POSITION_PARAMETER_PREFIX + 1,0);
    validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertFalse(validConfig);
    config.setInteger(RecordInputFormat.RECORD_POSITION_PARAMETER_PREFIX + 0,3);
    config.setInteger(RecordInputFormat.RECORD_POSITION_PARAMETER_PREFIX + 2,9);
    validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertTrue(validConfig);
  }
 catch (  Exception ex) {
    Assert.fail(""String_Node_Str"" + ex.getClass().getSimpleName() + ""String_Node_Str""+ ex.getMessage());
  }
}","@Test public void testConfigure(){
  try {
    Configuration config=new Configuration();
    config.setString(RecordInputFormat.FILE_PARAMETER_KEY,""String_Node_Str"");
    boolean validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertFalse(validConfig);
    config.setInteger(RecordInputFormat.NUM_FIELDS_PARAMETER,2);
    validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertFalse(validConfig);
    config.setClass(RecordInputFormat.FIELD_PARSER_PARAMETER_PREFIX + 0,DecimalTextIntParser.class);
    config.setClass(RecordInputFormat.FIELD_PARSER_PARAMETER_PREFIX + 1,DecimalTextIntParser.class);
    validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertTrue(validConfig);
    config.setInteger(RecordInputFormat.NUM_FIELDS_PARAMETER,3);
    validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertFalse(validConfig);
    config.setClass(RecordInputFormat.FIELD_PARSER_PARAMETER_PREFIX + 2,DecimalTextIntParser.class);
    config.setString(RecordInputFormat.FIELD_DELIMITER_PARAMETER,""String_Node_Str"");
    validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertFalse(validConfig);
    config.setString(RecordInputFormat.FIELD_DELIMITER_PARAMETER,""String_Node_Str"");
    validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertTrue(validConfig);
    config.setInteger(RecordInputFormat.TEXT_POSITION_PARAMETER_PREFIX + 1,0);
    validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertFalse(validConfig);
    config.setInteger(RecordInputFormat.TEXT_POSITION_PARAMETER_PREFIX + 0,3);
    config.setInteger(RecordInputFormat.TEXT_POSITION_PARAMETER_PREFIX + 2,9);
    validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertTrue(validConfig);
    config.setInteger(RecordInputFormat.RECORD_POSITION_PARAMETER_PREFIX + 1,0);
    validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertFalse(validConfig);
    config.setInteger(RecordInputFormat.RECORD_POSITION_PARAMETER_PREFIX + 0,3);
    config.setInteger(RecordInputFormat.RECORD_POSITION_PARAMETER_PREFIX + 2,9);
    validConfig=true;
    try {
      format.configure(config);
    }
 catch (    IllegalArgumentException iae) {
      validConfig=false;
    }
    assertTrue(validConfig);
    config=new Configuration();
    config.setString(RecordInputFormat.FILE_PARAMETER_KEY,""String_Node_Str"");
    config.setString(RecordInputFormat.FIELD_DELIMITER_PARAMETER,""String_Node_Str"");
    config.setInteger(RecordInputFormat.NUM_FIELDS_PARAMETER,2);
    config.setClass(RecordInputFormat.FIELD_PARSER_PARAMETER_PREFIX + 0,ConfigForwardCheckParser.class);
    config.setInteger(RecordInputFormat.TEXT_POSITION_PARAMETER_PREFIX + 0,0);
    config.setInteger(RecordInputFormat.RECORD_POSITION_PARAMETER_PREFIX + 0,0);
    config.setClass(RecordInputFormat.FIELD_PARSER_PARAMETER_PREFIX + 1,ConfigForwardCheckParser.class);
    config.setInteger(RecordInputFormat.TEXT_POSITION_PARAMETER_PREFIX + 1,1);
    config.setInteger(RecordInputFormat.RECORD_POSITION_PARAMETER_PREFIX + 1,1);
    config.setString(""String_Node_Str"",""String_Node_Str"");
    config.setInteger(""String_Node_Str"",42);
    new RecordInputFormat().configure(config);
  }
 catch (  Exception ex) {
    Assert.fail(""String_Node_Str"" + ex.getClass().getSimpleName() + ""String_Node_Str""+ ex.getMessage());
  }
}",0.8698298519850601
55350,"/** 
 * Returns the query.
 * @return the query
 */
public SopremoPlan getQuery(){
  if (this.query != null || this.planBuffer == null)   return this.query;
  final JobID dummId=new JobID();
  try {
    LibraryCacheManager.register(dummId,this.requiredPackages.toArray(new String[this.requiredPackages.size()]));
    this.query=SopremoUtil.byteArrayToSerializable(this.planBuffer,LibraryCacheManager.getClassLoader(dummId));
  }
 catch (  IOException e) {
    e.printStackTrace();
  }
 finally {
    try {
      LibraryCacheManager.unregister(dummId);
    }
 catch (    IOException e) {
    }
  }
  return this.query;
}","/** 
 * Returns the query.
 * @return the query
 */
public SopremoPlan getQuery(){
  if (this.query != null || this.planBuffer == null)   return this.query;
  final JobID dummId=new JobID();
  try {
    LibraryCacheManager.register(dummId,this.requiredPackages.toArray(new String[this.requiredPackages.size()]));
    this.query=SopremoUtil.byteArrayToSerializable(this.planBuffer,SopremoPlan.class,LibraryCacheManager.getClassLoader(dummId));
  }
 catch (  IOException e) {
    e.printStackTrace();
  }
 finally {
    try {
      LibraryCacheManager.unregister(dummId);
    }
 catch (    IOException e) {
    }
  }
  return this.query;
}",0.9856687898089171
55351,"@SuppressWarnings(""String_Node_Str"") public static <T extends Serializable>T byteArrayToSerializable(byte[] buffer,final ClassLoader classLoader) throws IOException {
  final ObjectInputStream ois=new ObjectInputStream(new ByteArrayInputStream(buffer)){
    @Override protected Class<?> resolveClass(    ObjectStreamClass desc) throws IOException, ClassNotFoundException {
      try {
        return classLoader.loadClass(desc.getName());
      }
 catch (      ClassNotFoundException e) {
        return super.resolveClass(desc);
      }
    }
  }
;
  try {
    return (T)ois.readObject();
  }
 catch (  ClassNotFoundException e) {
    throw new IllegalStateException(""String_Node_Str"",e);
  }
}","@SuppressWarnings(""String_Node_Str"") public static <T extends Serializable>T byteArrayToSerializable(byte[] buffer,Class<T> clazz,final ClassLoader classLoader) throws IOException {
  final ObjectInputStream ois=new ObjectInputStream(new ByteArrayInputStream(buffer)){
    @Override protected Class<?> resolveClass(    ObjectStreamClass desc) throws IOException, ClassNotFoundException {
      try {
        return classLoader.loadClass(desc.getName());
      }
 catch (      ClassNotFoundException e) {
        return super.resolveClass(desc);
      }
    }
  }
;
  try {
    return (T)ois.readObject();
  }
 catch (  ClassNotFoundException e) {
    throw new IllegalStateException(""String_Node_Str"",e);
  }
}",0.98932384341637
55352,"/** 
 * Deserializes an   {@link Serializable} from a {@link DataInput}.<br> Please note that this method is not very efficient.
 */
public static <T extends Serializable>T deserializeObject(DataInput in,Class<T> clazz) throws IOException {
  byte[] buffer=new byte[in.readInt()];
  in.readFully(buffer);
  return byteArrayToSerializable(buffer,clazz.getClassLoader());
}","/** 
 * Deserializes an   {@link Serializable} from a {@link DataInput}.<br> Please note that this method is not very efficient.
 */
public static <T extends Serializable>T deserializeObject(DataInput in,Class<T> clazz) throws IOException {
  byte[] buffer=new byte[in.readInt()];
  in.readFully(buffer);
  return byteArrayToSerializable(buffer,clazz,clazz.getClassLoader());
}",0.9919786096256684
55353,"/** 
 * Tests whether the job manager has been shut down completely.
 * @return <code>true</code> if the job manager has been shut down completely, <code>false</code> otherwise
 */
public boolean isShutDown(){
  return this.isShutDown.get();
}","/** 
 * Tests whether the job manager has been shut down completely.
 * @return <code>true</code> if the job manager has been shut down completely, <code>false</code> otherwise
 */
public boolean isShutDown(){
  return this.isShutDown;
}",0.9875
55354,"public void shutdown(){
  if (this.isShutDown.compareAndSet(false,true)) {
    return;
  }
  if (this.instanceManager != null) {
    this.instanceManager.shutdown();
  }
  DiscoveryService.stopDiscoveryService();
  if (this.profiler != null) {
    this.profiler.shutdown();
  }
  if (this.jobManagerServer != null) {
    this.jobManagerServer.stop();
  }
  if (this.executorService != null) {
    this.executorService.shutdown();
    try {
      this.executorService.awaitTermination(5000L,TimeUnit.MILLISECONDS);
    }
 catch (    InterruptedException e) {
      if (LOG.isDebugEnabled()) {
        LOG.debug(StringUtils.stringifyException(e));
      }
    }
  }
  final Iterator<JobManagerPlugin> it=this.jobManagerPlugins.values().iterator();
  while (it.hasNext()) {
    it.next().shutdown();
  }
  if (this.eventCollector != null) {
    this.eventCollector.shutdown();
  }
  if (this.scheduler != null) {
    this.scheduler.shutdown();
  }
  this.isShutDown.set(true);
  LOG.debug(""String_Node_Str"");
}","public void shutdown(){
  if (!this.isShutdownInProgress.compareAndSet(false,true)) {
    return;
  }
  if (this.instanceManager != null) {
    this.instanceManager.shutdown();
  }
  DiscoveryService.stopDiscoveryService();
  if (this.profiler != null) {
    this.profiler.shutdown();
  }
  if (this.jobManagerServer != null) {
    this.jobManagerServer.stop();
  }
  if (this.executorService != null) {
    this.executorService.shutdown();
    try {
      this.executorService.awaitTermination(5000L,TimeUnit.MILLISECONDS);
    }
 catch (    InterruptedException e) {
      if (LOG.isDebugEnabled()) {
        LOG.debug(StringUtils.stringifyException(e));
      }
    }
  }
  final Iterator<JobManagerPlugin> it=this.jobManagerPlugins.values().iterator();
  while (it.hasNext()) {
    it.next().shutdown();
  }
  if (this.eventCollector != null) {
    this.eventCollector.shutdown();
  }
  if (this.scheduler != null) {
    this.scheduler.shutdown();
  }
  this.isShutDown=true;
  LOG.debug(""String_Node_Str"");
}",0.9752475247524752
55355,"private void process(String[] args){
  CommandLine cmd=this.parseOptions(args);
  final SopremoPlan plan=this.parseScript(cmd);
  this.configureClient(cmd);
  this.sopremoClient.submit(plan,new StateListener(){
    @Override public void stateChanged(    ExecutionState executionState,    String detail){
switch (executionState) {
case ENQUEUED:
        System.out.print(""String_Node_Str"");
      break;
case RUNNING:
    System.out.print(""String_Node_Str"");
  break;
case FINISHED:
System.out.println(""String_Node_Str"" + detail);
break;
case ERROR:
System.err.println(""String_Node_Str"" + detail);
break;
}
}
@Override public void progressUpdate(ExecutionState status,String detail){
super.progressUpdate(status,detail);
System.out.print(""String_Node_Str"");
}
}
,cmd.hasOption(""String_Node_Str""));
this.sopremoClient.close();
}","private void process(String[] args){
  CommandLine cmd=this.parseOptions(args);
  final SopremoPlan plan=this.parseScript(cmd);
  this.configureClient(cmd);
  this.sopremoClient.submit(plan,new StateListener(){
    @Override public void stateChanged(    ExecutionState executionState,    String detail){
      System.out.println();
switch (executionState) {
case ENQUEUED:
        System.out.print(""String_Node_Str"");
      break;
case RUNNING:
    System.out.print(""String_Node_Str"");
  break;
case FINISHED:
System.out.print(detail);
break;
case ERROR:
System.out.print(detail);
break;
}
}
@Override protected void stateNotChanged(ExecutionState state,String detail){
System.out.print(""String_Node_Str"");
}
}
,cmd.hasOption(""String_Node_Str""));
this.sopremoClient.close();
}",0.7865168539325843
55356,"protected void dealWithError(Exception e,final String message){
  System.err.print(message);
  if (e != null) {
    System.err.print(""String_Node_Str"");
    System.err.print(e);
  }
  System.err.println();
  System.exit(1);
}","protected void dealWithError(Exception e,final String message,Object... args){
  System.err.print(String.format(message,args));
  if (e != null) {
    System.err.print(""String_Node_Str"");
    System.err.print(e);
  }
  System.err.println();
  System.exit(1);
}",0.8989690721649485
55357,"@Override public void stateChanged(ExecutionState executionState,String detail){
switch (executionState) {
case ENQUEUED:
    System.out.print(""String_Node_Str"");
  break;
case RUNNING:
System.out.print(""String_Node_Str"");
break;
case FINISHED:
System.out.println(""String_Node_Str"" + detail);
break;
case ERROR:
System.err.println(""String_Node_Str"" + detail);
break;
}
}","@Override public void stateChanged(ExecutionState executionState,String detail){
  System.out.println();
switch (executionState) {
case ENQUEUED:
    System.out.print(""String_Node_Str"");
  break;
case RUNNING:
System.out.print(""String_Node_Str"");
break;
case FINISHED:
System.out.print(detail);
break;
case ERROR:
System.out.print(detail);
break;
}
}",0.875
55358,"private SopremoPlan parseScript(CommandLine cmd){
  File file=new File(cmd.getOptionValue(""String_Node_Str""));
  if (!file.exists())   this.dealWithError(null,""String_Node_Str"");
  try {
    return new QueryParser().tryParse(new FileInputStream(file));
  }
 catch (  IOException e) {
    this.dealWithError(e,""String_Node_Str"");
    return null;
  }
}","private SopremoPlan parseScript(CommandLine cmd){
  File file=new File(cmd.getOptionValue(""String_Node_Str""));
  if (!file.exists())   this.dealWithError(null,""String_Node_Str"",file);
  try {
    return new QueryParser().tryParse(new FileInputStream(file));
  }
 catch (  IOException e) {
    this.dealWithError(e,""String_Node_Str"");
    return null;
  }
}",0.9929278642149928
55359,"private void configureClient(CommandLine cmd){
  String configDir=cmd.getOptionValue(""String_Node_Str"");
  GlobalConfiguration.loadConfiguration(configDir);
  this.sopremoClient=new DefaultClient();
  int updateTime=1000;
  if (cmd.hasOption(""String_Node_Str""))   updateTime=Integer.parseInt(cmd.getOptionValue(""String_Node_Str""));
  this.sopremoClient.setUpdateTime(updateTime);
  String address=cmd.getOptionValue(""String_Node_Str""), port=cmd.getOptionValue(""String_Node_Str"");
  if (address != null || port != null) {
    this.sopremoClient.setServerAddress(new InetSocketAddress(address == null ? ""String_Node_Str"" : address,port == null ? SopremoConstants.DEFAULT_SOPREMO_SERVER_IPC_PORT : Integer.parseInt(port)));
  }
  this.sopremoClient.setExecutionMode(ExecutionMode.RUN_WITH_STATISTICS);
}","private void configureClient(CommandLine cmd){
  String configDir=cmd.getOptionValue(""String_Node_Str"");
  GlobalConfiguration.loadConfiguration(configDir);
  this.sopremoClient=new DefaultClient(GlobalConfiguration.getConfiguration());
  int updateTime=1000;
  if (cmd.hasOption(""String_Node_Str""))   updateTime=Integer.parseInt(cmd.getOptionValue(""String_Node_Str""));
  this.sopremoClient.setUpdateTime(updateTime);
  String address=cmd.getOptionValue(""String_Node_Str""), port=cmd.getOptionValue(""String_Node_Str"");
  if (address != null || port != null) {
    this.sopremoClient.setServerAddress(new InetSocketAddress(address == null ? ""String_Node_Str"" : address,port == null ? SopremoConstants.DEFAULT_SOPREMO_SERVER_IPC_PORT : Integer.parseInt(port)));
  }
  this.sopremoClient.setExecutionMode(ExecutionMode.RUN_WITH_STATISTICS);
}",0.9768009768009768
55360,"/** 
 * Executes all operators. If expected values have been specified, the actual outputs values are compared to the expected values.
 */
public void run(){
  final SopremoPlan sopremoPlan=new SopremoPlan();
  sopremoPlan.setContext(this.evaluationContext);
  sopremoPlan.setSinks(this.getOutputOperators(0,this.expectedOutputs.length));
  final Collection<Contract> sinks=sopremoPlan.assemblePact();
  this.testPlan=new TestPlan(sinks);
  Schema schema=sopremoPlan.getSchema();
  for (  final Input input : this.inputs)   input.prepare(this.testPlan,schema);
  for (  final ExpectedOutput output : this.expectedOutputs)   output.prepare(this.testPlan,schema);
  if (this.trace)   SopremoUtil.trace();
  this.testPlan.run();
  if (this.trace)   SopremoUtil.untrace();
  for (  final ActualOutput output : this.actualOutputs)   output.load(this.testPlan);
}","/** 
 * Executes all operators. If expected values have been specified, the actual outputs values are compared to the expected values.
 */
public void run(){
  final SopremoPlan sopremoPlan=new SopremoPlan();
  sopremoPlan.setContext(this.evaluationContext);
  sopremoPlan.setSinks(this.getOutputOperators(0,this.expectedOutputs.length));
  final Collection<Contract> sinks=sopremoPlan.assemblePact();
  this.testPlan=new TestPlan(sinks);
  Schema schema=sopremoPlan.getSchema();
  for (  final Input input : this.inputs)   input.prepare(this.testPlan,schema);
  for (  final ExpectedOutput output : this.expectedOutputs)   output.prepare(this.testPlan,schema);
  if (this.dop > 0)   this.testPlan.setDegreeOfParallelism(this.dop);
  if (this.trace)   SopremoUtil.trace();
  this.testPlan.run();
  if (this.trace)   SopremoUtil.untrace();
  for (  final ActualOutput output : this.actualOutputs)   output.load(this.testPlan);
}",0.9607623318385652
55361,"/** 
 * Returns the degree of parallelism of the test plan.
 */
public void setDegreeOfParallelism(final int dop){
  if (dop < 1)   throw new IllegalArgumentException(""String_Node_Str"");
  this.testPlan.setDegreeOfParallelism(dop);
}","/** 
 * Returns the degree of parallelism of the test plan.
 */
public void setDegreeOfParallelism(final int dop){
  if (dop < 1)   throw new IllegalArgumentException(""String_Node_Str"");
  this.dop=dop;
}",0.9016018306636157
55362,"/** 
 * the iteration head prepares the backchannel: it allocates memory, instantiates a   {@link BlockingBackChannel} andhands it to the iteration tail via a  {@link Broker} singleton
 */
private BlockingBackChannel initBackChannel() throws Exception {
  TaskConfig taskConfig=getTaskConfig();
  long completeMemorySize=taskConfig.getMemorySize();
  long backChannelMemorySize=(long)(completeMemorySize * taskConfig.getBackChannelMemoryFraction());
  taskConfig.setMemorySize(completeMemorySize - backChannelMemorySize);
  List<MemorySegment> segments=Lists.newArrayList();
  int segmentSize=getMemoryManager().getPageSize();
  getMemoryManager().allocatePages(this,segments,backChannelMemorySize);
  BlockingBackChannel backChannel=new BlockingBackChannel(new SerializedUpdateBuffer(segments,segmentSize,getIOManager()));
  Broker<BlockingBackChannel> broker=BlockingBackChannelBroker.instance();
  broker.handIn(identifier(),backChannel);
  return backChannel;
}","/** 
 * the iteration head prepares the backchannel: it allocates memory, instantiates a   {@link BlockingBackChannel} andhands it to the iteration tail via a  {@link Broker} singleton
 */
private BlockingBackChannel initBackChannel() throws Exception {
  TaskConfig taskConfig=getTaskConfig();
  long completeMemorySize=taskConfig.getMemorySize();
  long backChannelMemorySize=(long)(completeMemorySize * taskConfig.getBackChannelMemoryFraction());
  taskConfig.setMemorySize(completeMemorySize - backChannelMemorySize);
  List<MemorySegment> segments=Lists.newArrayList();
  int segmentSize=getMemoryManager().getPageSize();
  getMemoryManager().allocatePages(this,segments,backChannelMemorySize);
  BlockingBackChannel backChannel=new BlockingBackChannel(new SerializedUpdateBuffer(segments,segmentSize,getIOManager()));
  Broker<BlockingBackChannel> broker=BlockingBackChannelBroker.instance();
  broker.handIn(brokerKey(),backChannel);
  return backChannel;
}",0.9901503369621566
55363,"private BlockingBackChannel retrieveBackChannel() throws Exception {
  Broker<BlockingBackChannel> broker=BlockingBackChannelBroker.instance();
  return broker.get(identifier());
}","private BlockingBackChannel retrieveBackChannel() throws Exception {
  Broker<BlockingBackChannel> broker=BlockingBackChannelBroker.instance();
  return broker.get(brokerKey());
}",0.958217270194986
55364,"@Override protected void fillArray(IJsonNode[] result){
  this.children.toArray(new IJsonNode[this.children.size()]);
}","@Override protected void fillArray(IJsonNode[] result){
  IJsonNode[] array=this.children.toArray(new IJsonNode[this.children.size()]);
  for (int i=0; i < this.children.size(); i++) {
    result[i]=array[i];
  }
}",0.5585585585585585
55365,"@Override protected void computeValidPlanAlternatives(List<? extends OptimizerNode> altSubPlans1,List<? extends OptimizerNode> altSubPlans2,CostEstimator estimator,List<OptimizerNode> outputPlans){
  for (  OptimizerNode subPlan1 : altSubPlans1) {
    for (    OptimizerNode subPlan2 : altSubPlans2) {
      if (!areBranchCompatible(subPlan1,subPlan2)) {
        continue;
      }
      ShipStrategy ss1=this.input1.getShipStrategy();
      ShipStrategy ss2=this.input2.getShipStrategy();
      GlobalProperties gp1;
      GlobalProperties gp2;
      if (ss1 == ShipStrategy.NONE) {
        gp1=subPlan1.getGlobalProperties();
        if (ss2 == ShipStrategy.NONE) {
          gp2=subPlan2.getGlobalProperties();
          if (partitioningIsOnRightFields(gp1,0) && gp1.getPartitioning().isComputablyPartitioned()) {
            ss1=ShipStrategy.FORWARD;
          }
          if (partitioningIsOnRightFields(gp2,1) && gp2.getPartitioning().isComputablyPartitioned()) {
            if (!partitioningIsOnRightFields(gp1,0) || !gp1.getPartitioning().isComputablyPartitioned()) {
              ss2=ShipStrategy.FORWARD;
            }
 else {
              if (gp1.getPartitioning() == gp2.getPartitioning() && partitioningIsOnSameSubkey(gp1.getPartitionedFields(),gp2.getPartitionedFields())) {
                ss2=ShipStrategy.FORWARD;
              }
 else {
                if (gp1.getPartitioning() == PartitionProperty.HASH_PARTITIONED && gp2.getPartitioning() == PartitionProperty.RANGE_PARTITIONED) {
                  createCoGroupAlternative(outputPlans,subPlan1,subPlan2,ShipStrategy.FORWARD,ShipStrategy.PARTITION_HASH,estimator);
                  createCoGroupAlternative(outputPlans,subPlan1,subPlan2,ShipStrategy.PARTITION_RANGE,ShipStrategy.FORWARD,estimator);
                }
 else                 if (gp1.getPartitioning() == PartitionProperty.RANGE_PARTITIONED && gp2.getPartitioning() == PartitionProperty.HASH_PARTITIONED) {
                  createCoGroupAlternative(outputPlans,subPlan1,subPlan2,ShipStrategy.FORWARD,ShipStrategy.PARTITION_RANGE,estimator);
                  createCoGroupAlternative(outputPlans,subPlan1,subPlan2,ShipStrategy.PARTITION_HASH,ShipStrategy.FORWARD,estimator);
                }
                continue;
              }
            }
          }
          if (ss1 == ShipStrategy.FORWARD) {
            if (ss2 == ShipStrategy.FORWARD) {
              createCoGroupAlternative(outputPlans,subPlan1,subPlan2,ss1,ss2,estimator);
              if (gp1.getPartitioning() != PartitionProperty.RANGE_PARTITIONED) {
              }
            }
 else {
              if (partitioningIsOnRightFields(gp1,0) && gp1.getPartitioning() == PartitionProperty.HASH_PARTITIONED) {
                createCoGroupAlternative(outputPlans,subPlan1,subPlan2,ss1,ShipStrategy.PARTITION_HASH,estimator);
              }
 else               if (partitioningIsOnRightFields(gp1,0) && gp1.getPartitioning() == PartitionProperty.RANGE_PARTITIONED) {
                createCoGroupAlternative(outputPlans,subPlan1,subPlan2,ss1,ShipStrategy.PARTITION_RANGE,estimator);
                createCoGroupAlternative(outputPlans,subPlan1,subPlan2,ShipStrategy.PARTITION_HASH,ShipStrategy.PARTITION_HASH,estimator);
              }
 else {
                throw new CompilerException(""String_Node_Str"" + getPactContract().getName() + ""String_Node_Str"");
              }
            }
          }
 else           if (ss2 == ShipStrategy.FORWARD) {
            if (partitioningIsOnRightFields(gp2,1) && gp2.getPartitioning() == PartitionProperty.HASH_PARTITIONED) {
              createCoGroupAlternative(outputPlans,subPlan1,subPlan2,ShipStrategy.PARTITION_HASH,ss2,estimator);
            }
 else             if (partitioningIsOnRightFields(gp2,1) && gp2.getPartitioning() == PartitionProperty.RANGE_PARTITIONED) {
              createCoGroupAlternative(outputPlans,subPlan1,subPlan2,ShipStrategy.PARTITION_RANGE,ss2,estimator);
              createCoGroupAlternative(outputPlans,subPlan1,subPlan2,ShipStrategy.PARTITION_HASH,ShipStrategy.PARTITION_HASH,estimator);
            }
 else {
              throw new CompilerException(""String_Node_Str"" + getPactContract().getName() + ""String_Node_Str"");
            }
          }
 else {
            createCoGroupAlternative(outputPlans,subPlan1,subPlan2,ShipStrategy.PARTITION_HASH,ShipStrategy.PARTITION_HASH,estimator);
          }
        }
 else {
          gp2=PactConnection.getGlobalPropertiesAfterConnection(subPlan1,this,ss2);
switch (ss2) {
case FORWARD:
            if (partitioningIsOnRightFields(gp2,1) && gp2.getPartitioning().isPartitioned()) {
              if (gp2.getPartitioning() == PartitionProperty.HASH_PARTITIONED) {
                ss1=ShipStrategy.PARTITION_HASH;
              }
 else               if (gp2.getPartitioning() == PartitionProperty.RANGE_PARTITIONED) {
                ss1=ShipStrategy.PARTITION_RANGE;
              }
 else {
                throw new CompilerException();
              }
            }
 else {
              continue;
            }
          break;
case PARTITION_HASH:
        ss1=(partitioningIsOnSameSubkey(gp1.getPartitionedFields(),this.keySet2) && gp1.getPartitioning() == PartitionProperty.HASH_PARTITIONED) ? ShipStrategy.FORWARD : ShipStrategy.PARTITION_HASH;
      break;
case PARTITION_RANGE:
    ss1=(partitioningIsOnRightFields(gp1,0) && gp1.getPartitioning() == PartitionProperty.RANGE_PARTITIONED) ? ShipStrategy.FORWARD : ShipStrategy.PARTITION_RANGE;
  break;
default :
throw new CompilerException(""String_Node_Str"" + ss2.name() + ""String_Node_Str""+ getPactContract().getName()+ ""String_Node_Str"");
}
createCoGroupAlternative(outputPlans,subPlan1,subPlan2,ss1,ss2,estimator);
}
}
 else if (ss2 == ShipStrategy.NONE) {
gp1=PactConnection.getGlobalPropertiesAfterConnection(subPlan1,this,ss1);
gp2=subPlan2.getGlobalProperties();
switch (ss1) {
case FORWARD:
if (partitioningIsOnRightFields(gp1,0) && gp1.getPartitioning().isPartitioned()) {
if (gp1.getPartitioning() == PartitionProperty.HASH_PARTITIONED) {
ss2=ShipStrategy.PARTITION_HASH;
}
 else if (gp1.getPartitioning() == PartitionProperty.RANGE_PARTITIONED) {
ss2=ShipStrategy.PARTITION_RANGE;
}
 else {
throw new CompilerException();
}
}
 else {
continue;
}
break;
case PARTITION_HASH:
ss2=(partitioningIsOnSameSubkey(this.keySet1,gp2.getPartitionedFields()) && gp2.getPartitioning() == PartitionProperty.HASH_PARTITIONED) ? ShipStrategy.FORWARD : ShipStrategy.PARTITION_HASH;
break;
case PARTITION_RANGE:
ss2=(partitioningIsOnRightFields(gp2,1) && gp2.getPartitioning() == PartitionProperty.RANGE_PARTITIONED) ? ShipStrategy.FORWARD : ShipStrategy.PARTITION_RANGE;
break;
default :
throw new CompilerException(""String_Node_Str"" + ss1.name() + ""String_Node_Str""+ getPactContract().getName()+ ""String_Node_Str"");
}
createCoGroupAlternative(outputPlans,subPlan1,subPlan2,ss1,ss2,estimator);
}
 else {
gp1=PactConnection.getGlobalPropertiesAfterConnection(subPlan1,this,ss1);
gp2=PactConnection.getGlobalPropertiesAfterConnection(subPlan2,this,ss2);
if (gp1.getPartitioning().isComputablyPartitioned() && gp1.getPartitioning() == gp2.getPartitioning() && partitioningIsOnSameSubkey(gp1.getPartitionedFields(),gp2.getPartitionedFields())) {
createCoGroupAlternative(outputPlans,subPlan1,subPlan2,ss1,ss2,estimator);
}
 else {
continue;
}
}
}
}
}","@Override protected void computeValidPlanAlternatives(List<? extends OptimizerNode> altSubPlans1,List<? extends OptimizerNode> altSubPlans2,CostEstimator estimator,List<OptimizerNode> outputPlans){
  for (  OptimizerNode subPlan1 : altSubPlans1) {
    for (    OptimizerNode subPlan2 : altSubPlans2) {
      if (!areBranchCompatible(subPlan1,subPlan2)) {
        continue;
      }
      ShipStrategy ss1=this.input1.getShipStrategy();
      ShipStrategy ss2=this.input2.getShipStrategy();
      GlobalProperties gp1;
      GlobalProperties gp2;
      if (ss1 == ShipStrategy.NONE) {
        gp1=subPlan1.getGlobalProperties();
        if (ss2 == ShipStrategy.NONE) {
          gp2=subPlan2.getGlobalProperties();
          if (partitioningIsOnRightFields(gp1,0) && gp1.getPartitioning().isComputablyPartitioned()) {
            ss1=ShipStrategy.FORWARD;
          }
          if (partitioningIsOnRightFields(gp2,1) && gp2.getPartitioning().isComputablyPartitioned()) {
            if (!partitioningIsOnRightFields(gp1,0) || !gp1.getPartitioning().isComputablyPartitioned()) {
              ss2=ShipStrategy.FORWARD;
            }
 else {
              if (gp1.getPartitioning() == gp2.getPartitioning() && partitioningIsOnSameSubkey(gp1.getPartitionedFields(),gp2.getPartitionedFields())) {
                ss2=ShipStrategy.FORWARD;
              }
 else {
                if (gp1.getPartitioning() == PartitionProperty.HASH_PARTITIONED && gp2.getPartitioning() == PartitionProperty.RANGE_PARTITIONED) {
                  createCoGroupAlternative(outputPlans,subPlan1,subPlan2,ShipStrategy.FORWARD,ShipStrategy.PARTITION_HASH,estimator);
                  createCoGroupAlternative(outputPlans,subPlan1,subPlan2,ShipStrategy.PARTITION_RANGE,ShipStrategy.FORWARD,estimator);
                }
 else                 if (gp1.getPartitioning() == PartitionProperty.RANGE_PARTITIONED && gp2.getPartitioning() == PartitionProperty.HASH_PARTITIONED) {
                  createCoGroupAlternative(outputPlans,subPlan1,subPlan2,ShipStrategy.FORWARD,ShipStrategy.PARTITION_RANGE,estimator);
                  createCoGroupAlternative(outputPlans,subPlan1,subPlan2,ShipStrategy.PARTITION_HASH,ShipStrategy.FORWARD,estimator);
                }
                continue;
              }
            }
          }
          if (ss1 == ShipStrategy.FORWARD) {
            if (ss2 == ShipStrategy.FORWARD) {
              createCoGroupAlternative(outputPlans,subPlan1,subPlan2,ss1,ss2,estimator);
              if (gp1.getPartitioning() != PartitionProperty.RANGE_PARTITIONED) {
              }
            }
 else {
              if (partitioningIsOnRightFields(gp1,0) && gp1.getPartitioning() == PartitionProperty.HASH_PARTITIONED) {
                createCoGroupAlternative(outputPlans,subPlan1,subPlan2,ss1,ShipStrategy.PARTITION_HASH,estimator);
              }
 else               if (partitioningIsOnRightFields(gp1,0) && gp1.getPartitioning() == PartitionProperty.RANGE_PARTITIONED) {
                createCoGroupAlternative(outputPlans,subPlan1,subPlan2,ss1,ShipStrategy.PARTITION_RANGE,estimator);
                createCoGroupAlternative(outputPlans,subPlan1,subPlan2,ShipStrategy.PARTITION_HASH,ShipStrategy.PARTITION_HASH,estimator);
              }
 else {
                throw new CompilerException(""String_Node_Str"" + getPactContract().getName() + ""String_Node_Str"");
              }
            }
          }
 else           if (ss2 == ShipStrategy.FORWARD) {
            if (partitioningIsOnRightFields(gp2,1) && gp2.getPartitioning() == PartitionProperty.HASH_PARTITIONED) {
              createCoGroupAlternative(outputPlans,subPlan1,subPlan2,ShipStrategy.PARTITION_HASH,ss2,estimator);
            }
 else             if (partitioningIsOnRightFields(gp2,1) && gp2.getPartitioning() == PartitionProperty.RANGE_PARTITIONED) {
              createCoGroupAlternative(outputPlans,subPlan1,subPlan2,ShipStrategy.PARTITION_RANGE,ss2,estimator);
              createCoGroupAlternative(outputPlans,subPlan1,subPlan2,ShipStrategy.PARTITION_HASH,ShipStrategy.PARTITION_HASH,estimator);
            }
 else {
              throw new CompilerException(""String_Node_Str"" + getPactContract().getName() + ""String_Node_Str"");
            }
          }
 else {
            createCoGroupAlternative(outputPlans,subPlan1,subPlan2,ShipStrategy.PARTITION_HASH,ShipStrategy.PARTITION_HASH,estimator);
          }
        }
 else {
          gp2=PactConnection.getGlobalPropertiesAfterConnection(subPlan2,this,1,ss2);
switch (ss2) {
case FORWARD:
            if (partitioningIsOnRightFields(gp2,1) && gp2.getPartitioning().isPartitioned()) {
              if (gp2.getPartitioning() == PartitionProperty.HASH_PARTITIONED) {
                ss1=ShipStrategy.PARTITION_HASH;
              }
 else               if (gp2.getPartitioning() == PartitionProperty.RANGE_PARTITIONED) {
                ss1=ShipStrategy.PARTITION_RANGE;
              }
 else {
                throw new CompilerException();
              }
            }
 else {
              continue;
            }
          break;
case PARTITION_HASH:
        ss1=(partitioningIsOnSameSubkey(gp1.getPartitionedFields(),this.keySet2) && gp1.getPartitioning() == PartitionProperty.HASH_PARTITIONED) ? ShipStrategy.FORWARD : ShipStrategy.PARTITION_HASH;
      break;
case PARTITION_RANGE:
    ss1=(partitioningIsOnRightFields(gp1,0) && gp1.getPartitioning() == PartitionProperty.RANGE_PARTITIONED) ? ShipStrategy.FORWARD : ShipStrategy.PARTITION_RANGE;
  break;
default :
throw new CompilerException(""String_Node_Str"" + ss2.name() + ""String_Node_Str""+ getPactContract().getName()+ ""String_Node_Str"");
}
createCoGroupAlternative(outputPlans,subPlan1,subPlan2,ss1,ss2,estimator);
}
}
 else if (ss2 == ShipStrategy.NONE) {
gp1=PactConnection.getGlobalPropertiesAfterConnection(subPlan1,this,0,ss1);
gp2=subPlan2.getGlobalProperties();
switch (ss1) {
case FORWARD:
if (partitioningIsOnRightFields(gp1,0) && gp1.getPartitioning().isPartitioned()) {
if (gp1.getPartitioning() == PartitionProperty.HASH_PARTITIONED) {
ss2=ShipStrategy.PARTITION_HASH;
}
 else if (gp1.getPartitioning() == PartitionProperty.RANGE_PARTITIONED) {
ss2=ShipStrategy.PARTITION_RANGE;
}
 else {
throw new CompilerException();
}
}
 else {
continue;
}
break;
case PARTITION_HASH:
ss2=(partitioningIsOnSameSubkey(this.keySet1,gp2.getPartitionedFields()) && gp2.getPartitioning() == PartitionProperty.HASH_PARTITIONED) ? ShipStrategy.FORWARD : ShipStrategy.PARTITION_HASH;
break;
case PARTITION_RANGE:
ss2=(partitioningIsOnRightFields(gp2,1) && gp2.getPartitioning() == PartitionProperty.RANGE_PARTITIONED) ? ShipStrategy.FORWARD : ShipStrategy.PARTITION_RANGE;
break;
default :
throw new CompilerException(""String_Node_Str"" + ss1.name() + ""String_Node_Str""+ getPactContract().getName()+ ""String_Node_Str"");
}
createCoGroupAlternative(outputPlans,subPlan1,subPlan2,ss1,ss2,estimator);
}
 else {
gp1=PactConnection.getGlobalPropertiesAfterConnection(subPlan1,this,0,ss1);
gp2=PactConnection.getGlobalPropertiesAfterConnection(subPlan2,this,1,ss2);
if (gp1.getPartitioning().isComputablyPartitioned() && gp1.getPartitioning() == gp2.getPartitioning() && partitioningIsOnSameSubkey(gp1.getPartitionedFields(),gp2.getPartitionedFields())) {
createCoGroupAlternative(outputPlans,subPlan1,subPlan2,ss1,ss2,estimator);
}
 else {
continue;
}
}
}
}
}",0.9993188010899182
55366,"/** 
 * Private utility method that generates the alternative CoGroup nodes, given fixed shipping strategies for the inputs.
 * @param target The list to put the alternatives in.
 * @param subPlan1 The subplan for the first input.
 * @param subPlan2 The subplan for the second input.
 * @param ss1 The shipping strategy for the first input.
 * @param ss2 The shipping strategy for the second input.
 * @param estimator The cost estimator.
 */
private void createCoGroupAlternative(List<OptimizerNode> target,OptimizerNode subPlan1,OptimizerNode subPlan2,ShipStrategy ss1,ShipStrategy ss2,CostEstimator estimator){
  GlobalProperties gp1, gp2;
  LocalProperties lp1, lp2;
  gp1=PactConnection.getGlobalPropertiesAfterConnection(subPlan1,this,ss1);
  lp1=PactConnection.getLocalPropertiesAfterConnection(subPlan1,this,ss1);
  gp2=PactConnection.getGlobalPropertiesAfterConnection(subPlan2,this,ss2);
  lp2=PactConnection.getLocalPropertiesAfterConnection(subPlan2,this,ss2);
  int[] scrambledKeyOrder1=null;
  int[] scrambledKeyOrder2=null;
  if (ss1 == ShipStrategy.FORWARD && ss2 == ShipStrategy.PARTITION_HASH) {
    scrambledKeyOrder1=getScrambledKeyOrder(this.keySet1,gp1.getPartitionedFields());
    if (scrambledKeyOrder1 != null) {
      FieldList scrambledKeys2=new FieldList();
      for (int i=0; i < scrambledKeyOrder1.length; i++) {
        scrambledKeys2.add(this.keySet2.get(scrambledKeyOrder1[i]));
      }
      gp2.setPartitioning(gp2.getPartitioning(),scrambledKeys2);
    }
  }
  if (ss2 == ShipStrategy.FORWARD && ss1 == ShipStrategy.PARTITION_HASH) {
    scrambledKeyOrder2=getScrambledKeyOrder(this.keySet2,gp2.getPartitionedFields());
    if (scrambledKeyOrder2 != null) {
      FieldList scrambledKeys1=new FieldList();
      for (int i=0; i < scrambledKeyOrder2.length; i++) {
        scrambledKeys1.add(this.keySet1.get(scrambledKeyOrder2[i]));
      }
      gp1.setPartitioning(gp1.getPartitioning(),scrambledKeys1);
    }
  }
  int[] keyColumns1=getPactContract().getKeyColumnNumbers(0);
  Ordering ordering1=new Ordering();
  for (  int keyColumn : keyColumns1) {
    ordering1.appendOrdering(keyColumn,null,Order.ASCENDING);
  }
  int[] keyColumns2=getPactContract().getKeyColumnNumbers(1);
  Ordering ordering2=new Ordering();
  for (  int keyColumn : keyColumns2) {
    ordering2.appendOrdering(keyColumn,null,Order.ASCENDING);
  }
  GlobalProperties outGp=new GlobalProperties();
  outGp.setPartitioning(gp1.getPartitioning(),gp1.getPartitionedFields());
  CoGroupNode n=new CoGroupNode(this,subPlan1,subPlan2,this.input1,this.input2,outGp,new LocalProperties());
  n.input1.setShipStrategy(ss1);
  n.input1.setScramblePartitionedFields(scrambledKeyOrder2);
  n.input2.setShipStrategy(ss2);
  n.input2.setScramblePartitionedFields(scrambledKeyOrder1);
  n.getLocalProperties().setOrdering(ordering1);
  n.getLocalProperties().setGrouped(true,new FieldSet(keyColumns1));
  if (n.getLocalStrategy() == LocalStrategy.NONE) {
    if (ordering1.isMetBy(lp1.getOrdering()) && ordering2.isMetBy(lp2.getOrdering())) {
      n.setLocalStrategy(LocalStrategy.MERGE);
    }
 else     if (!ordering1.isMetBy(lp1.getOrdering()) && ordering2.isMetBy(lp2.getOrdering())) {
      n.setLocalStrategy(LocalStrategy.SORT_FIRST_MERGE);
    }
 else     if (ordering1.isMetBy(lp1.getOrdering()) && !ordering2.isMetBy(lp2.getOrdering())) {
      n.setLocalStrategy(LocalStrategy.SORT_SECOND_MERGE);
    }
 else {
      n.setLocalStrategy(LocalStrategy.SORT_BOTH_MERGE);
    }
  }
  n.getGlobalProperties().filterByNodesConstantSet(this,0);
  n.getLocalProperties().filterByNodesConstantSet(this,0);
  estimator.costOperator(n);
  target.add(n);
  outGp=new GlobalProperties();
  outGp.setPartitioning(gp2.getPartitioning(),gp2.getPartitionedFields());
  n=new CoGroupNode(this,subPlan1,subPlan2,input1,input2,outGp,new LocalProperties());
  n.input1.setShipStrategy(ss1);
  n.input1.setScramblePartitionedFields(scrambledKeyOrder2);
  n.input2.setShipStrategy(ss2);
  n.input2.setScramblePartitionedFields(scrambledKeyOrder1);
  n.getLocalProperties().setOrdering(ordering2);
  n.getLocalProperties().setGrouped(true,new FieldSet(keyColumns2));
  if (n.getLocalStrategy() == LocalStrategy.NONE) {
    if (ordering1.isMetBy(lp1.getOrdering()) && ordering2.isMetBy(lp2.getOrdering())) {
      n.setLocalStrategy(LocalStrategy.MERGE);
    }
 else     if (!ordering1.isMetBy(lp1.getOrdering()) && ordering2.isMetBy(lp2.getOrdering())) {
      n.setLocalStrategy(LocalStrategy.SORT_FIRST_MERGE);
    }
 else     if (ordering1.isMetBy(lp1.getOrdering()) && !ordering2.isMetBy(lp2.getOrdering())) {
      n.setLocalStrategy(LocalStrategy.SORT_SECOND_MERGE);
    }
 else {
      n.setLocalStrategy(LocalStrategy.SORT_BOTH_MERGE);
    }
  }
  n.getGlobalProperties().filterByNodesConstantSet(this,1);
  n.getLocalProperties().filterByNodesConstantSet(this,1);
  estimator.costOperator(n);
  target.add(n);
}","/** 
 * Private utility method that generates the alternative CoGroup nodes, given fixed shipping strategies for the inputs.
 * @param target The list to put the alternatives in.
 * @param subPlan1 The subplan for the first input.
 * @param subPlan2 The subplan for the second input.
 * @param ss1 The shipping strategy for the first input.
 * @param ss2 The shipping strategy for the second input.
 * @param estimator The cost estimator.
 */
private void createCoGroupAlternative(List<OptimizerNode> target,OptimizerNode subPlan1,OptimizerNode subPlan2,ShipStrategy ss1,ShipStrategy ss2,CostEstimator estimator){
  GlobalProperties gp1, gp2;
  LocalProperties lp1, lp2;
  gp1=PactConnection.getGlobalPropertiesAfterConnection(subPlan1,this,0,ss1);
  lp1=PactConnection.getLocalPropertiesAfterConnection(subPlan1,this,ss1);
  gp2=PactConnection.getGlobalPropertiesAfterConnection(subPlan2,this,1,ss2);
  lp2=PactConnection.getLocalPropertiesAfterConnection(subPlan2,this,ss2);
  int[] scrambledKeyOrder1=null;
  int[] scrambledKeyOrder2=null;
  if (ss1 == ShipStrategy.FORWARD && ss2 == ShipStrategy.PARTITION_HASH) {
    scrambledKeyOrder1=getScrambledKeyOrder(this.keySet1,gp1.getPartitionedFields());
    if (scrambledKeyOrder1 != null) {
      FieldList scrambledKeys2=new FieldList();
      for (int i=0; i < scrambledKeyOrder1.length; i++) {
        scrambledKeys2.add(this.keySet2.get(scrambledKeyOrder1[i]));
      }
      gp2.setPartitioning(gp2.getPartitioning(),scrambledKeys2);
    }
  }
  if (ss2 == ShipStrategy.FORWARD && ss1 == ShipStrategy.PARTITION_HASH) {
    scrambledKeyOrder2=getScrambledKeyOrder(this.keySet2,gp2.getPartitionedFields());
    if (scrambledKeyOrder2 != null) {
      FieldList scrambledKeys1=new FieldList();
      for (int i=0; i < scrambledKeyOrder2.length; i++) {
        scrambledKeys1.add(this.keySet1.get(scrambledKeyOrder2[i]));
      }
      gp1.setPartitioning(gp1.getPartitioning(),scrambledKeys1);
    }
  }
  int[] keyColumns1=getPactContract().getKeyColumnNumbers(0);
  Ordering ordering1=new Ordering();
  for (  int keyColumn : keyColumns1) {
    ordering1.appendOrdering(keyColumn,null,Order.ASCENDING);
  }
  int[] keyColumns2=getPactContract().getKeyColumnNumbers(1);
  Ordering ordering2=new Ordering();
  for (  int keyColumn : keyColumns2) {
    ordering2.appendOrdering(keyColumn,null,Order.ASCENDING);
  }
  GlobalProperties outGp=new GlobalProperties();
  outGp.setPartitioning(gp1.getPartitioning(),gp1.getPartitionedFields());
  CoGroupNode n=new CoGroupNode(this,subPlan1,subPlan2,this.input1,this.input2,outGp,new LocalProperties());
  n.input1.setShipStrategy(ss1);
  n.input1.setScramblePartitionedFields(scrambledKeyOrder2);
  n.input2.setShipStrategy(ss2);
  n.input2.setScramblePartitionedFields(scrambledKeyOrder1);
  n.getLocalProperties().setOrdering(ordering1);
  n.getLocalProperties().setGrouped(true,new FieldSet(keyColumns1));
  if (n.getLocalStrategy() == LocalStrategy.NONE) {
    if (ordering1.isMetBy(lp1.getOrdering()) && ordering2.isMetBy(lp2.getOrdering())) {
      n.setLocalStrategy(LocalStrategy.MERGE);
    }
 else     if (!ordering1.isMetBy(lp1.getOrdering()) && ordering2.isMetBy(lp2.getOrdering())) {
      n.setLocalStrategy(LocalStrategy.SORT_FIRST_MERGE);
    }
 else     if (ordering1.isMetBy(lp1.getOrdering()) && !ordering2.isMetBy(lp2.getOrdering())) {
      n.setLocalStrategy(LocalStrategy.SORT_SECOND_MERGE);
    }
 else {
      n.setLocalStrategy(LocalStrategy.SORT_BOTH_MERGE);
    }
  }
  n.getGlobalProperties().filterByNodesConstantSet(this,0);
  n.getLocalProperties().filterByNodesConstantSet(this,0);
  estimator.costOperator(n);
  target.add(n);
  outGp=new GlobalProperties();
  outGp.setPartitioning(gp2.getPartitioning(),gp2.getPartitionedFields());
  n=new CoGroupNode(this,subPlan1,subPlan2,input1,input2,outGp,new LocalProperties());
  n.input1.setShipStrategy(ss1);
  n.input1.setScramblePartitionedFields(scrambledKeyOrder2);
  n.input2.setShipStrategy(ss2);
  n.input2.setScramblePartitionedFields(scrambledKeyOrder1);
  n.getLocalProperties().setOrdering(ordering2);
  n.getLocalProperties().setGrouped(true,new FieldSet(keyColumns2));
  if (n.getLocalStrategy() == LocalStrategy.NONE) {
    if (ordering1.isMetBy(lp1.getOrdering()) && ordering2.isMetBy(lp2.getOrdering())) {
      n.setLocalStrategy(LocalStrategy.MERGE);
    }
 else     if (!ordering1.isMetBy(lp1.getOrdering()) && ordering2.isMetBy(lp2.getOrdering())) {
      n.setLocalStrategy(LocalStrategy.SORT_FIRST_MERGE);
    }
 else     if (ordering1.isMetBy(lp1.getOrdering()) && !ordering2.isMetBy(lp2.getOrdering())) {
      n.setLocalStrategy(LocalStrategy.SORT_SECOND_MERGE);
    }
 else {
      n.setLocalStrategy(LocalStrategy.SORT_BOTH_MERGE);
    }
  }
  n.getGlobalProperties().filterByNodesConstantSet(this,1);
  n.getLocalProperties().filterByNodesConstantSet(this,1);
  estimator.costOperator(n);
  target.add(n);
}",0.9995925850478712
55367,"/** 
 * Private utility method that generates a candidate Cross node, given fixed shipping strategies and a fixed local strategy.
 * @param target The list to put the alternatives in.
 * @param subPlan1 The subPlan for the first input.
 * @param subPlan2 The subPlan for the second input.
 * @param ss1 The shipping strategy for the first input.
 * @param ss2 The shipping strategy for the second input.
 * @param ls The local strategy.
 * @param outGp The global properties of the data that goes to the user function.
 * @param outLp The local properties of the data that goes to the user function.
 * @param estimator The cost estimator.
 */
private void createCrossAlternative(List<OptimizerNode> target,OptimizerNode subPlan1,OptimizerNode subPlan2,ShipStrategy ss1,ShipStrategy ss2,LocalStrategy ls,boolean keepFirstOrder,boolean keepSecondOrder,CostEstimator estimator){
  GlobalProperties gp;
  LocalProperties lp;
  gp=PactConnection.getGlobalPropertiesAfterConnection(subPlan1,this,ss1);
  lp=PactConnection.getLocalPropertiesAfterConnection(subPlan1,this,ss1);
  if (keepFirstOrder == false) {
    gp.setOrdering(null);
    lp.setOrdering(null);
  }
  CrossNode n=new CrossNode(this,subPlan1,subPlan2,input1,input2,gp,lp);
  n.input1.setShipStrategy(ss1);
  n.input2.setShipStrategy(ss2);
  n.setLocalStrategy(ls);
  n.getGlobalProperties().filterByNodesConstantSet(this,0);
  n.getLocalProperties().filterByNodesConstantSet(this,0);
  estimator.costOperator(n);
  target.add(n);
  gp=PactConnection.getGlobalPropertiesAfterConnection(subPlan2,this,ss2);
  lp=PactConnection.getLocalPropertiesAfterConnection(subPlan2,this,ss2);
  if (keepSecondOrder == false) {
    gp.setOrdering(null);
    lp.setOrdering(null);
  }
  n=new CrossNode(this,subPlan1,subPlan2,input1,input2,gp,lp);
  n.input1.setShipStrategy(ss1);
  n.input2.setShipStrategy(ss2);
  n.setLocalStrategy(ls);
  n.getGlobalProperties().filterByNodesConstantSet(this,1);
  n.getLocalProperties().filterByNodesConstantSet(this,1);
  estimator.costOperator(n);
  target.add(n);
}","/** 
 * Private utility method that generates a candidate Cross node, given fixed shipping strategies and a fixed local strategy.
 * @param target The list to put the alternatives in.
 * @param subPlan1 The subPlan for the first input.
 * @param subPlan2 The subPlan for the second input.
 * @param ss1 The shipping strategy for the first input.
 * @param ss2 The shipping strategy for the second input.
 * @param ls The local strategy.
 * @param outGp The global properties of the data that goes to the user function.
 * @param outLp The local properties of the data that goes to the user function.
 * @param estimator The cost estimator.
 */
private void createCrossAlternative(List<OptimizerNode> target,OptimizerNode subPlan1,OptimizerNode subPlan2,ShipStrategy ss1,ShipStrategy ss2,LocalStrategy ls,boolean keepFirstOrder,boolean keepSecondOrder,CostEstimator estimator){
  GlobalProperties gp;
  LocalProperties lp;
  gp=PactConnection.getGlobalPropertiesAfterConnection(subPlan1,this,0,ss1);
  lp=PactConnection.getLocalPropertiesAfterConnection(subPlan1,this,ss1);
  if (keepFirstOrder == false) {
    gp.setOrdering(null);
    lp.setOrdering(null);
  }
  CrossNode n=new CrossNode(this,subPlan1,subPlan2,input1,input2,gp,lp);
  n.input1.setShipStrategy(ss1);
  n.input2.setShipStrategy(ss2);
  n.setLocalStrategy(ls);
  n.getGlobalProperties().filterByNodesConstantSet(this,0);
  n.getLocalProperties().filterByNodesConstantSet(this,0);
  estimator.costOperator(n);
  target.add(n);
  gp=PactConnection.getGlobalPropertiesAfterConnection(subPlan2,this,1,ss2);
  lp=PactConnection.getLocalPropertiesAfterConnection(subPlan2,this,ss2);
  if (keepSecondOrder == false) {
    gp.setOrdering(null);
    lp.setOrdering(null);
  }
  n=new CrossNode(this,subPlan1,subPlan2,input1,input2,gp,lp);
  n.input1.setShipStrategy(ss1);
  n.input2.setShipStrategy(ss2);
  n.setLocalStrategy(ls);
  n.getGlobalProperties().filterByNodesConstantSet(this,1);
  n.getLocalProperties().filterByNodesConstantSet(this,1);
  estimator.costOperator(n);
  target.add(n);
}",0.9990253411306044
55368,"@Override protected void computeValidPlanAlternatives(List<? extends OptimizerNode> altSubPlans,CostEstimator estimator,List<OptimizerNode> outputPlans){
  ShipStrategy ss=ShipStrategy.NONE;
  ShipStrategy hintSS=this.inConn.getShipStrategy();
  if (hintSS == ShipStrategy.BROADCAST || hintSS == ShipStrategy.SFR)   return;
 else   ss=hintSS;
  if (ss == ShipStrategy.NONE)   ss=ShipStrategy.FORWARD;
  for (  OptimizerNode subPlan : altSubPlans) {
    GlobalProperties gp=PactConnection.getGlobalPropertiesAfterConnection(subPlan,this,ss);
    LocalProperties lp=PactConnection.getLocalPropertiesAfterConnection(subPlan,this,ss);
    MapNode nMap=new MapNode(this,subPlan,this.inConn,gp,lp);
    nMap.inConn.setShipStrategy(ss);
    nMap.getGlobalProperties().filterByNodesConstantSet(this,0);
    nMap.getLocalProperties().filterByNodesConstantSet(this,0);
    estimator.costOperator(nMap);
    outputPlans.add(nMap);
  }
}","@Override protected void computeValidPlanAlternatives(List<? extends OptimizerNode> altSubPlans,CostEstimator estimator,List<OptimizerNode> outputPlans){
  ShipStrategy ss=ShipStrategy.NONE;
  ShipStrategy hintSS=this.inConn.getShipStrategy();
  if (hintSS == ShipStrategy.BROADCAST || hintSS == ShipStrategy.SFR)   return;
 else   ss=hintSS;
  if (ss == ShipStrategy.NONE)   ss=ShipStrategy.FORWARD;
  for (  OptimizerNode subPlan : altSubPlans) {
    GlobalProperties gp=PactConnection.getGlobalPropertiesAfterConnection(subPlan,this,0,ss);
    LocalProperties lp=PactConnection.getLocalPropertiesAfterConnection(subPlan,this,ss);
    MapNode nMap=new MapNode(this,subPlan,this.inConn,gp,lp);
    nMap.inConn.setShipStrategy(ss);
    nMap.getGlobalProperties().filterByNodesConstantSet(this,0);
    nMap.getLocalProperties().filterByNodesConstantSet(this,0);
    estimator.costOperator(nMap);
    outputPlans.add(nMap);
  }
}",0.9989200863930886
55369,"/** 
 * Private utility method that generates a candidate Match node, given fixed shipping strategies and a fixed local strategy.
 * @param target The list to put the alternatives in.
 * @param subPlan1 The predecessor node for the first input.
 * @param subPlan2 The predecessor node for the second input.
 * @param ss1 The shipping strategy for the first input.
 * @param ss2 The shipping strategy for the second input.
 * @param ls The local strategy.
 * @param outGp The global properties of the data that goes to the user function.
 * @param outLp The local properties of the data that goes to the user function.
 * @param estimator The cost estimator.
 */
private void createMatchAlternative(List<OptimizerNode> target,OptimizerNode subPlan1,OptimizerNode subPlan2,ShipStrategy ss1,ShipStrategy ss2,LocalStrategy ls,Order order,boolean grouped,LocalProperties outLpp,CostEstimator estimator){
  if (ls != LocalStrategy.SELF_NESTEDLOOP && ls != LocalStrategy.SORT_SELF_NESTEDLOOP) {
    GlobalProperties gp1=PactConnection.getGlobalPropertiesAfterConnection(subPlan1,this,ss1);
    GlobalProperties gp2=PactConnection.getGlobalPropertiesAfterConnection(subPlan2,this,ss2);
    int[] scrambledKeyOrder1=null;
    int[] scrambledKeyOrder2=null;
    if (ss1 == ShipStrategy.FORWARD && ss2 == ShipStrategy.PARTITION_HASH) {
      scrambledKeyOrder1=getScrambledKeyOrder(this.keySet1,gp1.getPartitionedFields());
      if (scrambledKeyOrder1 != null) {
        FieldList scrambledKeys2=new FieldList();
        for (int i=0; i < scrambledKeyOrder1.length; i++) {
          scrambledKeys2.add(this.keySet2.get(scrambledKeyOrder1[i]));
        }
        gp2.setPartitioning(gp2.getPartitioning(),scrambledKeys2);
      }
    }
    if (ss2 == ShipStrategy.FORWARD && ss1 == ShipStrategy.PARTITION_HASH) {
      scrambledKeyOrder2=getScrambledKeyOrder(this.keySet2,gp2.getPartitionedFields());
      if (scrambledKeyOrder2 != null) {
        FieldList scrambledKeys1=new FieldList();
        for (int i=0; i < scrambledKeyOrder2.length; i++) {
          scrambledKeys1.add(this.keySet1.get(scrambledKeyOrder2[i]));
        }
        gp1.setPartitioning(gp1.getPartitioning(),scrambledKeys1);
      }
    }
    LocalProperties outLp=outLpp;
    GlobalProperties outGp=new GlobalProperties();
    outGp.setPartitioning(gp1.getPartitioning(),gp1.getPartitionedFields());
    outGp.setOrdering(gp1.getOrdering());
    if (outLpp == null) {
      outLp=new LocalProperties();
      if (order != Order.NONE) {
        Ordering ordering=new Ordering();
        for (        int keyColumn : this.keySet1) {
          ordering.appendOrdering(keyColumn,null,order);
        }
        outLp.setOrdering(ordering);
      }
 else {
        outLp.setOrdering(null);
      }
      outLp.setGrouped(grouped,new FieldSet(this.keySet1));
    }
    MatchNode n=new MatchNode(this,subPlan1,subPlan2,this.input1,this.input2,outGp,outLp);
    n.input1.setShipStrategy(ss1);
    n.input1.setScramblePartitionedFields(scrambledKeyOrder2);
    n.input2.setShipStrategy(ss2);
    n.input2.setScramblePartitionedFields(scrambledKeyOrder1);
    n.setLocalStrategy(ls);
    n.getGlobalProperties().filterByNodesConstantSet(this,0);
    n.getLocalProperties().filterByNodesConstantSet(this,0);
    estimator.costOperator(n);
    target.add(n);
    outGp=new GlobalProperties();
    outGp.setPartitioning(gp2.getPartitioning(),gp2.getPartitionedFields());
    outGp.setOrdering(gp2.getOrdering());
    if (outLpp == null) {
      outLp=new LocalProperties();
      if (order != Order.NONE) {
        Ordering ordering=new Ordering();
        for (        int keyColumn : this.keySet2) {
          ordering.appendOrdering(keyColumn,null,order);
        }
        outLp.setOrdering(ordering);
      }
 else {
        outLp.setOrdering(null);
      }
      outLp.setGrouped(grouped,new FieldSet(this.keySet2));
    }
    n=new MatchNode(this,subPlan1,subPlan2,input1,input2,outGp,outLp);
    n.input1.setShipStrategy(ss1);
    n.input1.setScramblePartitionedFields(scrambledKeyOrder2);
    n.input2.setShipStrategy(ss2);
    n.input2.setScramblePartitionedFields(scrambledKeyOrder1);
    n.setLocalStrategy(ls);
    n.getGlobalProperties().filterByNodesConstantSet(this,1);
    n.getLocalProperties().filterByNodesConstantSet(this,1);
    estimator.costOperator(n);
    target.add(n);
  }
 else {
    GlobalProperties gp1=PactConnection.getGlobalPropertiesAfterConnection(subPlan1,this,ss1);
    GlobalProperties outGp=new GlobalProperties();
    outGp.setPartitioning(gp1.getPartitioning(),gp1.getPartitionedFields());
    outGp.setOrdering(gp1.getOrdering());
    LocalProperties outLp=null;
    if (outLpp == null) {
      outLp=new LocalProperties();
      if (order != Order.NONE) {
        Ordering ordering=new Ordering();
        for (        int keyColumn : this.keySet1) {
          ordering.appendOrdering(keyColumn,null,order);
        }
        outLp.setOrdering(ordering);
      }
 else {
        outLp.setOrdering(null);
      }
      outLp.setGrouped(grouped,new FieldSet(this.keySet1));
    }
    MatchNode n=new MatchNode(this,subPlan1,null,this.input1,null,outGp,outLp);
    n.input1.setShipStrategy(ss1);
    n.setLocalStrategy(ls);
    n.getGlobalProperties().filterByNodesConstantSet(this,0);
    n.getLocalProperties().filterByNodesConstantSet(this,0);
    estimator.costOperator(n);
    target.add(n);
  }
}","/** 
 * Private utility method that generates a candidate Match node, given fixed shipping strategies and a fixed local strategy.
 * @param target The list to put the alternatives in.
 * @param subPlan1 The predecessor node for the first input.
 * @param subPlan2 The predecessor node for the second input.
 * @param ss1 The shipping strategy for the first input.
 * @param ss2 The shipping strategy for the second input.
 * @param ls The local strategy.
 * @param outGp The global properties of the data that goes to the user function.
 * @param outLp The local properties of the data that goes to the user function.
 * @param estimator The cost estimator.
 */
private void createMatchAlternative(List<OptimizerNode> target,OptimizerNode subPlan1,OptimizerNode subPlan2,ShipStrategy ss1,ShipStrategy ss2,LocalStrategy ls,Order order,boolean grouped,LocalProperties outLpp,CostEstimator estimator){
  if (ls != LocalStrategy.SELF_NESTEDLOOP && ls != LocalStrategy.SORT_SELF_NESTEDLOOP) {
    GlobalProperties gp1=PactConnection.getGlobalPropertiesAfterConnection(subPlan1,this,0,ss1);
    GlobalProperties gp2=PactConnection.getGlobalPropertiesAfterConnection(subPlan2,this,1,ss2);
    int[] scrambledKeyOrder1=null;
    int[] scrambledKeyOrder2=null;
    if (ss1 == ShipStrategy.FORWARD && ss2 == ShipStrategy.PARTITION_HASH) {
      scrambledKeyOrder1=getScrambledKeyOrder(this.keySet1,gp1.getPartitionedFields());
      if (scrambledKeyOrder1 != null) {
        FieldList scrambledKeys2=new FieldList();
        for (int i=0; i < scrambledKeyOrder1.length; i++) {
          scrambledKeys2.add(this.keySet2.get(scrambledKeyOrder1[i]));
        }
        gp2.setPartitioning(gp2.getPartitioning(),scrambledKeys2);
      }
    }
    if (ss2 == ShipStrategy.FORWARD && ss1 == ShipStrategy.PARTITION_HASH) {
      scrambledKeyOrder2=getScrambledKeyOrder(this.keySet2,gp2.getPartitionedFields());
      if (scrambledKeyOrder2 != null) {
        FieldList scrambledKeys1=new FieldList();
        for (int i=0; i < scrambledKeyOrder2.length; i++) {
          scrambledKeys1.add(this.keySet1.get(scrambledKeyOrder2[i]));
        }
        gp1.setPartitioning(gp1.getPartitioning(),scrambledKeys1);
      }
    }
    LocalProperties outLp=outLpp;
    GlobalProperties outGp=new GlobalProperties();
    outGp.setPartitioning(gp1.getPartitioning(),gp1.getPartitionedFields());
    outGp.setOrdering(gp1.getOrdering());
    if (outLpp == null) {
      outLp=new LocalProperties();
      if (order != Order.NONE) {
        Ordering ordering=new Ordering();
        for (        int keyColumn : this.keySet1) {
          ordering.appendOrdering(keyColumn,null,order);
        }
        outLp.setOrdering(ordering);
      }
 else {
        outLp.setOrdering(null);
      }
      outLp.setGrouped(grouped,new FieldSet(this.keySet1));
    }
    MatchNode n=new MatchNode(this,subPlan1,subPlan2,this.input1,this.input2,outGp,outLp);
    n.input1.setShipStrategy(ss1);
    n.input1.setScramblePartitionedFields(scrambledKeyOrder2);
    n.input2.setShipStrategy(ss2);
    n.input2.setScramblePartitionedFields(scrambledKeyOrder1);
    n.setLocalStrategy(ls);
    n.getGlobalProperties().filterByNodesConstantSet(this,0);
    n.getLocalProperties().filterByNodesConstantSet(this,0);
    estimator.costOperator(n);
    target.add(n);
    outGp=new GlobalProperties();
    outGp.setPartitioning(gp2.getPartitioning(),gp2.getPartitionedFields());
    outGp.setOrdering(gp2.getOrdering());
    if (outLpp == null) {
      outLp=new LocalProperties();
      if (order != Order.NONE) {
        Ordering ordering=new Ordering();
        for (        int keyColumn : this.keySet2) {
          ordering.appendOrdering(keyColumn,null,order);
        }
        outLp.setOrdering(ordering);
      }
 else {
        outLp.setOrdering(null);
      }
      outLp.setGrouped(grouped,new FieldSet(this.keySet2));
    }
    n=new MatchNode(this,subPlan1,subPlan2,input1,input2,outGp,outLp);
    n.input1.setShipStrategy(ss1);
    n.input1.setScramblePartitionedFields(scrambledKeyOrder2);
    n.input2.setShipStrategy(ss2);
    n.input2.setScramblePartitionedFields(scrambledKeyOrder1);
    n.setLocalStrategy(ls);
    n.getGlobalProperties().filterByNodesConstantSet(this,1);
    n.getLocalProperties().filterByNodesConstantSet(this,1);
    estimator.costOperator(n);
    target.add(n);
  }
 else {
    GlobalProperties gp1=PactConnection.getGlobalPropertiesAfterConnection(subPlan1,this,0,ss1);
    GlobalProperties outGp=new GlobalProperties();
    outGp.setPartitioning(gp1.getPartitioning(),gp1.getPartitionedFields());
    outGp.setOrdering(gp1.getOrdering());
    LocalProperties outLp=null;
    if (outLpp == null) {
      outLp=new LocalProperties();
      if (order != Order.NONE) {
        Ordering ordering=new Ordering();
        for (        int keyColumn : this.keySet1) {
          ordering.appendOrdering(keyColumn,null,order);
        }
        outLp.setOrdering(ordering);
      }
 else {
        outLp.setOrdering(null);
      }
      outLp.setGrouped(grouped,new FieldSet(this.keySet1));
    }
    MatchNode n=new MatchNode(this,subPlan1,null,this.input1,null,outGp,outLp);
    n.input1.setShipStrategy(ss1);
    n.setLocalStrategy(ls);
    n.getGlobalProperties().filterByNodesConstantSet(this,0);
    n.getLocalProperties().filterByNodesConstantSet(this,0);
    estimator.costOperator(n);
    target.add(n);
  }
}",0.9994440326167532
55370,"@Override protected void computeValidPlanAlternatives(List<? extends OptimizerNode> altSubPlans1,List<? extends OptimizerNode> altSubPlans2,CostEstimator estimator,List<OptimizerNode> outputPlans){
  for (  OptimizerNode subPlan1 : altSubPlans1) {
    for (    OptimizerNode subPlan2 : altSubPlans2) {
      if (!areBranchCompatible(subPlan1,subPlan2)) {
        continue;
      }
      ShipStrategy ss1=this.input1.getShipStrategy();
      ShipStrategy ss2=this.input2.getShipStrategy();
      GlobalProperties gp1;
      GlobalProperties gp2;
      if (ss1 == ShipStrategy.NONE) {
        gp1=subPlan1.getGlobalProperties();
        if (ss2 == ShipStrategy.NONE) {
          gp2=subPlan2.getGlobalProperties();
          if (partitioningIsOnRightFields(gp1,0) && gp1.getPartitioning().isComputablyPartitioned()) {
            ss1=ShipStrategy.FORWARD;
          }
          if (partitioningIsOnRightFields(gp2,1) && gp2.getPartitioning().isComputablyPartitioned()) {
            if (!partitioningIsOnRightFields(gp1,0) || !gp1.getPartitioning().isComputablyPartitioned()) {
              ss2=ShipStrategy.FORWARD;
            }
 else {
              if (gp1.getPartitioning().isCompatibleWith(gp2.getPartitioning()) && partitioningIsOnSameSubkey(gp1.getPartitionedFields(),gp2.getPartitionedFields())) {
                ss2=ShipStrategy.FORWARD;
              }
 else {
                if (gp1.getPartitioning() == PartitionProperty.HASH_PARTITIONED) {
                  createLocalAlternatives(outputPlans,subPlan1,subPlan2,ShipStrategy.FORWARD,ShipStrategy.PARTITION_HASH,estimator);
                }
 else                 if (gp1.getPartitioning() == PartitionProperty.RANGE_PARTITIONED) {
                  createLocalAlternatives(outputPlans,subPlan1,subPlan2,ShipStrategy.FORWARD,ShipStrategy.PARTITION_RANGE,estimator);
                }
                if (gp2.getPartitioning() == PartitionProperty.HASH_PARTITIONED) {
                  createLocalAlternatives(outputPlans,subPlan1,subPlan2,ShipStrategy.PARTITION_HASH,ShipStrategy.FORWARD,estimator);
                }
 else                 if (gp2.getPartitioning() == PartitionProperty.RANGE_PARTITIONED) {
                  createLocalAlternatives(outputPlans,subPlan1,subPlan2,ShipStrategy.PARTITION_RANGE,ShipStrategy.FORWARD,estimator);
                }
                continue;
              }
            }
          }
          if (ss1 == ShipStrategy.FORWARD) {
            if (ss2 == ShipStrategy.FORWARD) {
              createLocalAlternatives(outputPlans,subPlan1,subPlan2,ss1,ss2,estimator);
              if (gp1.getPartitioning() != PartitionProperty.RANGE_PARTITIONED) {
                createLocalAlternatives(outputPlans,subPlan1,subPlan2,ShipStrategy.PARTITION_RANGE,ShipStrategy.PARTITION_RANGE,estimator);
              }
            }
 else {
              if (partitioningIsOnRightFields(gp1,0) && gp1.getPartitioning() == PartitionProperty.HASH_PARTITIONED) {
                createLocalAlternatives(outputPlans,subPlan1,subPlan2,ss1,ShipStrategy.PARTITION_HASH,estimator);
              }
 else               if (partitioningIsOnRightFields(gp1,0) && gp1.getPartitioning() == PartitionProperty.RANGE_PARTITIONED) {
                createLocalAlternatives(outputPlans,subPlan1,subPlan2,ss1,ShipStrategy.PARTITION_RANGE,estimator);
                createLocalAlternatives(outputPlans,subPlan1,subPlan2,ShipStrategy.PARTITION_HASH,ShipStrategy.PARTITION_HASH,estimator);
              }
 else {
                throw new CompilerException(""String_Node_Str"" + getPactContract().getName() + ""String_Node_Str"");
              }
            }
          }
 else           if (ss2 == ShipStrategy.FORWARD) {
            if (partitioningIsOnRightFields(gp2,1) && gp2.getPartitioning() == PartitionProperty.HASH_PARTITIONED) {
              createLocalAlternatives(outputPlans,subPlan1,subPlan2,ShipStrategy.PARTITION_HASH,ss2,estimator);
            }
 else             if (partitioningIsOnRightFields(gp2,1) && gp2.getPartitioning() == PartitionProperty.RANGE_PARTITIONED) {
              createLocalAlternatives(outputPlans,subPlan1,subPlan2,ShipStrategy.PARTITION_RANGE,ss2,estimator);
              createLocalAlternatives(outputPlans,subPlan1,subPlan2,ShipStrategy.PARTITION_HASH,ShipStrategy.PARTITION_HASH,estimator);
            }
 else {
              throw new CompilerException(""String_Node_Str"" + getPactContract().getName() + ""String_Node_Str"");
            }
          }
 else {
            createLocalAlternatives(outputPlans,subPlan1,subPlan2,ShipStrategy.PARTITION_HASH,ShipStrategy.PARTITION_HASH,estimator);
            if (haveValidOutputEstimates(subPlan1) && haveValidOutputEstimates(subPlan2)) {
              createLocalAlternatives(outputPlans,subPlan1,subPlan2,ShipStrategy.BROADCAST,ShipStrategy.FORWARD,estimator);
              createLocalAlternatives(outputPlans,subPlan1,subPlan2,ShipStrategy.FORWARD,ShipStrategy.BROADCAST,estimator);
            }
          }
        }
 else {
          gp2=PactConnection.getGlobalPropertiesAfterConnection(subPlan2,this,ss2);
switch (ss2) {
case BROADCAST:
            ss1=ShipStrategy.FORWARD;
          break;
case FORWARD:
        if (partitioningIsOnRightFields(gp2,1) && gp2.getPartitioning().isPartitioned()) {
          if (gp2.getPartitioning() == PartitionProperty.HASH_PARTITIONED) {
            ss1=ShipStrategy.PARTITION_HASH;
          }
 else           if (gp2.getPartitioning() == PartitionProperty.RANGE_PARTITIONED) {
            ss1=ShipStrategy.PARTITION_RANGE;
          }
 else {
            throw new CompilerException();
          }
        }
 else {
          ss1=ShipStrategy.BROADCAST;
        }
      break;
case PARTITION_HASH:
    ss1=(partitioningIsOnSameSubkey(gp1.getPartitionedFields(),this.keySet2) && gp1.getPartitioning() == PartitionProperty.HASH_PARTITIONED) ? ShipStrategy.FORWARD : ShipStrategy.PARTITION_HASH;
  break;
case PARTITION_RANGE:
ss1=(partitioningIsOnRightFields(gp1,0) && gp1.getPartitioning() == PartitionProperty.RANGE_PARTITIONED) ? ShipStrategy.FORWARD : ShipStrategy.PARTITION_RANGE;
break;
default :
throw new CompilerException(""String_Node_Str"" + ss2.name() + ""String_Node_Str""+ getPactContract().getName()+ ""String_Node_Str"");
}
createLocalAlternatives(outputPlans,subPlan1,subPlan2,ss1,ss2,estimator);
}
}
 else if (ss2 == ShipStrategy.NONE) {
gp1=PactConnection.getGlobalPropertiesAfterConnection(subPlan1,this,ss1);
gp2=subPlan2.getGlobalProperties();
switch (ss1) {
case BROADCAST:
ss2=ShipStrategy.FORWARD;
break;
case FORWARD:
if (partitioningIsOnRightFields(gp1,0) && gp1.getPartitioning().isPartitioned()) {
if (gp1.getPartitioning() == PartitionProperty.HASH_PARTITIONED) {
ss2=ShipStrategy.PARTITION_HASH;
}
 else if (gp1.getPartitioning() == PartitionProperty.RANGE_PARTITIONED) {
ss2=ShipStrategy.PARTITION_RANGE;
}
 else {
throw new CompilerException();
}
}
 else {
ss2=ShipStrategy.BROADCAST;
}
break;
case PARTITION_HASH:
ss2=(partitioningIsOnSameSubkey(this.keySet1,gp2.getPartitionedFields()) && partitioningIsOnRightFields(gp2,1) && gp2.getPartitioning() == PartitionProperty.HASH_PARTITIONED) ? ShipStrategy.FORWARD : ShipStrategy.PARTITION_HASH;
break;
case PARTITION_RANGE:
ss2=(partitioningIsOnRightFields(gp2,1) && gp2.getPartitioning() == PartitionProperty.RANGE_PARTITIONED) ? ShipStrategy.FORWARD : ShipStrategy.PARTITION_RANGE;
break;
default :
throw new CompilerException(""String_Node_Str"" + ss1.name() + ""String_Node_Str""+ getPactContract().getName()+ ""String_Node_Str"");
}
createLocalAlternatives(outputPlans,subPlan1,subPlan2,ss1,ss2,estimator);
}
 else {
if ((ss1 == ShipStrategy.BROADCAST && ss2 != ShipStrategy.BROADCAST) || (ss1 != ShipStrategy.BROADCAST && ss2 == ShipStrategy.BROADCAST)) {
createLocalAlternatives(outputPlans,subPlan1,subPlan2,ss1,ss2,estimator);
}
 else {
gp1=PactConnection.getGlobalPropertiesAfterConnection(subPlan1,this,ss1);
gp2=PactConnection.getGlobalPropertiesAfterConnection(subPlan2,this,ss2);
if (gp1.getPartitioning().isComputablyPartitioned() && gp1.getPartitioning() == gp2.getPartitioning() && partitioningIsOnSameSubkey(gp1.getPartitionedFields(),gp2.getPartitionedFields())) {
createLocalAlternatives(outputPlans,subPlan1,subPlan2,ss1,ss2,estimator);
}
 else {
continue;
}
}
}
}
}
}","@Override protected void computeValidPlanAlternatives(List<? extends OptimizerNode> altSubPlans1,List<? extends OptimizerNode> altSubPlans2,CostEstimator estimator,List<OptimizerNode> outputPlans){
  for (  OptimizerNode subPlan1 : altSubPlans1) {
    for (    OptimizerNode subPlan2 : altSubPlans2) {
      if (!areBranchCompatible(subPlan1,subPlan2)) {
        continue;
      }
      ShipStrategy ss1=this.input1.getShipStrategy();
      ShipStrategy ss2=this.input2.getShipStrategy();
      GlobalProperties gp1;
      GlobalProperties gp2;
      if (ss1 == ShipStrategy.NONE) {
        gp1=subPlan1.getGlobalProperties();
        if (ss2 == ShipStrategy.NONE) {
          gp2=subPlan2.getGlobalProperties();
          if (partitioningIsOnRightFields(gp1,0) && gp1.getPartitioning().isComputablyPartitioned()) {
            ss1=ShipStrategy.FORWARD;
          }
          if (partitioningIsOnRightFields(gp2,1) && gp2.getPartitioning().isComputablyPartitioned()) {
            if (!partitioningIsOnRightFields(gp1,0) || !gp1.getPartitioning().isComputablyPartitioned()) {
              ss2=ShipStrategy.FORWARD;
            }
 else {
              if (gp1.getPartitioning().isCompatibleWith(gp2.getPartitioning()) && partitioningIsOnSameSubkey(gp1.getPartitionedFields(),gp2.getPartitionedFields())) {
                ss2=ShipStrategy.FORWARD;
              }
 else {
                if (gp1.getPartitioning() == PartitionProperty.HASH_PARTITIONED) {
                  createLocalAlternatives(outputPlans,subPlan1,subPlan2,ShipStrategy.FORWARD,ShipStrategy.PARTITION_HASH,estimator);
                }
 else                 if (gp1.getPartitioning() == PartitionProperty.RANGE_PARTITIONED) {
                  createLocalAlternatives(outputPlans,subPlan1,subPlan2,ShipStrategy.FORWARD,ShipStrategy.PARTITION_RANGE,estimator);
                }
                if (gp2.getPartitioning() == PartitionProperty.HASH_PARTITIONED) {
                  createLocalAlternatives(outputPlans,subPlan1,subPlan2,ShipStrategy.PARTITION_HASH,ShipStrategy.FORWARD,estimator);
                }
 else                 if (gp2.getPartitioning() == PartitionProperty.RANGE_PARTITIONED) {
                  createLocalAlternatives(outputPlans,subPlan1,subPlan2,ShipStrategy.PARTITION_RANGE,ShipStrategy.FORWARD,estimator);
                }
                continue;
              }
            }
          }
          if (ss1 == ShipStrategy.FORWARD) {
            if (ss2 == ShipStrategy.FORWARD) {
              createLocalAlternatives(outputPlans,subPlan1,subPlan2,ss1,ss2,estimator);
              if (gp1.getPartitioning() != PartitionProperty.RANGE_PARTITIONED) {
                createLocalAlternatives(outputPlans,subPlan1,subPlan2,ShipStrategy.PARTITION_RANGE,ShipStrategy.PARTITION_RANGE,estimator);
              }
            }
 else {
              if (partitioningIsOnRightFields(gp1,0) && gp1.getPartitioning() == PartitionProperty.HASH_PARTITIONED) {
                createLocalAlternatives(outputPlans,subPlan1,subPlan2,ss1,ShipStrategy.PARTITION_HASH,estimator);
              }
 else               if (partitioningIsOnRightFields(gp1,0) && gp1.getPartitioning() == PartitionProperty.RANGE_PARTITIONED) {
                createLocalAlternatives(outputPlans,subPlan1,subPlan2,ss1,ShipStrategy.PARTITION_RANGE,estimator);
                createLocalAlternatives(outputPlans,subPlan1,subPlan2,ShipStrategy.PARTITION_HASH,ShipStrategy.PARTITION_HASH,estimator);
              }
 else {
                throw new CompilerException(""String_Node_Str"" + getPactContract().getName() + ""String_Node_Str"");
              }
            }
          }
 else           if (ss2 == ShipStrategy.FORWARD) {
            if (partitioningIsOnRightFields(gp2,1) && gp2.getPartitioning() == PartitionProperty.HASH_PARTITIONED) {
              createLocalAlternatives(outputPlans,subPlan1,subPlan2,ShipStrategy.PARTITION_HASH,ss2,estimator);
            }
 else             if (partitioningIsOnRightFields(gp2,1) && gp2.getPartitioning() == PartitionProperty.RANGE_PARTITIONED) {
              createLocalAlternatives(outputPlans,subPlan1,subPlan2,ShipStrategy.PARTITION_RANGE,ss2,estimator);
              createLocalAlternatives(outputPlans,subPlan1,subPlan2,ShipStrategy.PARTITION_HASH,ShipStrategy.PARTITION_HASH,estimator);
            }
 else {
              throw new CompilerException(""String_Node_Str"" + getPactContract().getName() + ""String_Node_Str"");
            }
          }
 else {
            createLocalAlternatives(outputPlans,subPlan1,subPlan2,ShipStrategy.PARTITION_HASH,ShipStrategy.PARTITION_HASH,estimator);
            if (haveValidOutputEstimates(subPlan1) && haveValidOutputEstimates(subPlan2)) {
              createLocalAlternatives(outputPlans,subPlan1,subPlan2,ShipStrategy.BROADCAST,ShipStrategy.FORWARD,estimator);
              createLocalAlternatives(outputPlans,subPlan1,subPlan2,ShipStrategy.FORWARD,ShipStrategy.BROADCAST,estimator);
            }
          }
        }
 else {
          gp2=PactConnection.getGlobalPropertiesAfterConnection(subPlan2,this,1,ss2);
switch (ss2) {
case BROADCAST:
            ss1=ShipStrategy.FORWARD;
          break;
case FORWARD:
        if (partitioningIsOnRightFields(gp2,1) && gp2.getPartitioning().isPartitioned()) {
          if (gp2.getPartitioning() == PartitionProperty.HASH_PARTITIONED) {
            ss1=ShipStrategy.PARTITION_HASH;
          }
 else           if (gp2.getPartitioning() == PartitionProperty.RANGE_PARTITIONED) {
            ss1=ShipStrategy.PARTITION_RANGE;
          }
 else {
            throw new CompilerException();
          }
        }
 else {
          ss1=ShipStrategy.BROADCAST;
        }
      break;
case PARTITION_HASH:
    ss1=(partitioningIsOnSameSubkey(gp1.getPartitionedFields(),this.keySet2) && gp1.getPartitioning() == PartitionProperty.HASH_PARTITIONED) ? ShipStrategy.FORWARD : ShipStrategy.PARTITION_HASH;
  break;
case PARTITION_RANGE:
ss1=(partitioningIsOnRightFields(gp1,0) && gp1.getPartitioning() == PartitionProperty.RANGE_PARTITIONED) ? ShipStrategy.FORWARD : ShipStrategy.PARTITION_RANGE;
break;
default :
throw new CompilerException(""String_Node_Str"" + ss2.name() + ""String_Node_Str""+ getPactContract().getName()+ ""String_Node_Str"");
}
createLocalAlternatives(outputPlans,subPlan1,subPlan2,ss1,ss2,estimator);
}
}
 else if (ss2 == ShipStrategy.NONE) {
gp1=PactConnection.getGlobalPropertiesAfterConnection(subPlan1,this,0,ss1);
gp2=subPlan2.getGlobalProperties();
switch (ss1) {
case BROADCAST:
ss2=ShipStrategy.FORWARD;
break;
case FORWARD:
if (partitioningIsOnRightFields(gp1,0) && gp1.getPartitioning().isPartitioned()) {
if (gp1.getPartitioning() == PartitionProperty.HASH_PARTITIONED) {
ss2=ShipStrategy.PARTITION_HASH;
}
 else if (gp1.getPartitioning() == PartitionProperty.RANGE_PARTITIONED) {
ss2=ShipStrategy.PARTITION_RANGE;
}
 else {
throw new CompilerException();
}
}
 else {
ss2=ShipStrategy.BROADCAST;
}
break;
case PARTITION_HASH:
ss2=(partitioningIsOnSameSubkey(this.keySet1,gp2.getPartitionedFields()) && partitioningIsOnRightFields(gp2,1) && gp2.getPartitioning() == PartitionProperty.HASH_PARTITIONED) ? ShipStrategy.FORWARD : ShipStrategy.PARTITION_HASH;
break;
case PARTITION_RANGE:
ss2=(partitioningIsOnRightFields(gp2,1) && gp2.getPartitioning() == PartitionProperty.RANGE_PARTITIONED) ? ShipStrategy.FORWARD : ShipStrategy.PARTITION_RANGE;
break;
default :
throw new CompilerException(""String_Node_Str"" + ss1.name() + ""String_Node_Str""+ getPactContract().getName()+ ""String_Node_Str"");
}
createLocalAlternatives(outputPlans,subPlan1,subPlan2,ss1,ss2,estimator);
}
 else {
if ((ss1 == ShipStrategy.BROADCAST && ss2 != ShipStrategy.BROADCAST) || (ss1 != ShipStrategy.BROADCAST && ss2 == ShipStrategy.BROADCAST)) {
createLocalAlternatives(outputPlans,subPlan1,subPlan2,ss1,ss2,estimator);
}
 else {
gp1=PactConnection.getGlobalPropertiesAfterConnection(subPlan1,this,0,ss1);
gp2=PactConnection.getGlobalPropertiesAfterConnection(subPlan2,this,1,ss2);
if (gp1.getPartitioning().isComputablyPartitioned() && gp1.getPartitioning() == gp2.getPartitioning() && partitioningIsOnSameSubkey(gp1.getPartitionedFields(),gp2.getPartitionedFields())) {
createLocalAlternatives(outputPlans,subPlan1,subPlan2,ss1,ss2,estimator);
}
 else {
continue;
}
}
}
}
}
}",0.9995163240628778
55371,"/** 
 * Gets the global properties of the source's output after it crossed a pact connection with the given shipping strategy. Global properties are maintained on <tt>FORWARD</tt> connections. If a partitioning happens, then a partitioning property exists afterwards. A <tt>BROADCAST</tt> connection destroys the key uniqueness. <p> If the shipping strategy has not yet been determined, the properties of the connections source are returned.
 * @return The properties of the data after this channel.
 */
public static GlobalProperties getGlobalPropertiesAfterConnection(OptimizerNode source,OptimizerNode target,ShipStrategy shipMode){
  GlobalProperties gp=source.getGlobalProperties().createCopy();
  FieldList keyFields=null;
  int inputNum=0;
  for (  PactConnection conn : target.getIncomingConnections()) {
    if (conn.getSourcePact().getId() == source.getId()) {
      if (conn.getScramblePartitionedFields() != null) {
        throw new CompilerException(""String_Node_Str"");
      }
 else       if (target.getPactContract() instanceof AbstractPact<?>) {
        keyFields=new FieldList(((AbstractPact<?>)target.getPactContract()).getKeyColumnNumbers(inputNum));
      }
      break;
    }
    inputNum++;
  }
switch (shipMode) {
case BROADCAST:
    gp.reset();
  break;
case PARTITION_RANGE:
gp.setPartitioning(PartitionProperty.RANGE_PARTITIONED,keyFields);
break;
case PARTITION_HASH:
gp.setPartitioning(PartitionProperty.HASH_PARTITIONED,keyFields);
gp.setOrdering(null);
break;
case FORWARD:
if (source.getDegreeOfParallelism() > target.getDegreeOfParallelism()) {
gp.setOrdering(null);
}
break;
case NONE:
throw new CompilerException(""String_Node_Str"");
case SFR:
default :
throw new CompilerException(""String_Node_Str"" + shipMode.name());
}
return gp;
}","/** 
 * Gets the global properties of the source's output after it crossed a pact connection with the given shipping strategy. Global properties are maintained on <tt>FORWARD</tt> connections. If a partitioning happens, then a partitioning property exists afterwards. A <tt>BROADCAST</tt> connection destroys the key uniqueness. <p> If the shipping strategy has not yet been determined, the properties of the connections source are returned.
 * @return The properties of the data after this channel.
 */
public static GlobalProperties getGlobalPropertiesAfterConnection(OptimizerNode source,OptimizerNode target,int targetInputNum,ShipStrategy shipMode){
  GlobalProperties gp=source.getGlobalProperties().createCopy();
  FieldList keyFields=null;
  PactConnection conn=target.getIncomingConnections().get(targetInputNum);
  if (conn.getScramblePartitionedFields() != null) {
    throw new CompilerException(""String_Node_Str"");
  }
 else   if (target.getPactContract() instanceof AbstractPact<?>) {
    keyFields=new FieldList(((AbstractPact<?>)target.getPactContract()).getKeyColumnNumbers(targetInputNum));
  }
switch (shipMode) {
case BROADCAST:
    gp.reset();
  break;
case PARTITION_RANGE:
gp.setPartitioning(PartitionProperty.RANGE_PARTITIONED,keyFields);
break;
case PARTITION_HASH:
gp.setPartitioning(PartitionProperty.HASH_PARTITIONED,keyFields);
gp.setOrdering(null);
break;
case FORWARD:
if (source.getDegreeOfParallelism() > target.getDegreeOfParallelism()) {
gp.setOrdering(null);
}
break;
case NONE:
throw new CompilerException(""String_Node_Str"");
case SFR:
default :
throw new CompilerException(""String_Node_Str"" + shipMode.name());
}
return gp;
}",0.9169338385310404
55372,"@Override protected void computeValidPlanAlternatives(List<? extends OptimizerNode> altSubPlans,CostEstimator estimator,List<OptimizerNode> outputPlans){
  FieldSet keySet=new FieldSet(getPactContract().getKeyColumnNumbers(0));
  ShipStrategy ss=ShipStrategy.NONE;
  ShipStrategy hintSS=this.inConn.getShipStrategy();
  if (hintSS == ShipStrategy.BROADCAST || hintSS == ShipStrategy.SFR)   return;
 else   ss=hintSS;
  for (  OptimizerNode subPlan : altSubPlans) {
    GlobalProperties gp;
    LocalProperties lp;
    if (ss == ShipStrategy.NONE) {
      gp=subPlan.getGlobalProperties();
      lp=subPlan.getLocalProperties();
      if ((partitioningIsOnRightFields(gp) && gp.getPartitioning().isPartitioned()) || isFieldSetUnique(keySet,0)) {
        ss=ShipStrategy.FORWARD;
      }
 else {
        ss=ShipStrategy.PARTITION_HASH;
      }
      gp=PactConnection.getGlobalPropertiesAfterConnection(subPlan,this,ss);
      lp=PactConnection.getLocalPropertiesAfterConnection(subPlan,this,ss);
    }
 else {
      gp=PactConnection.getGlobalPropertiesAfterConnection(subPlan,this,ss);
      lp=PactConnection.getLocalPropertiesAfterConnection(subPlan,this,ss);
      if (!((partitioningIsOnRightFields(gp) && gp.getPartitioning().isPartitioned()) || isFieldSetUnique(keySet,0))) {
        continue;
      }
    }
    boolean localStrategyNeeded=false;
    if (lp.getOrdering() == null || lp.getOrdering().groupsFieldSet(keySet) == false) {
      localStrategyNeeded=true;
    }
    if (localStrategyNeeded && lp.isGrouped() == true) {
      localStrategyNeeded=!lp.getGroupedFields().equals(keySet);
    }
    if (localStrategyNeeded) {
      localStrategyNeeded=!isFieldSetUnique(keySet,0);
    }
    LocalStrategy ls=getLocalStrategy();
    if (localStrategyNeeded) {
      if (ls != LocalStrategy.NONE) {
        if (ls != LocalStrategy.COMBININGSORT && ls != LocalStrategy.SORT) {
          continue;
        }
      }
 else {
        ls=isCombineable() ? LocalStrategy.COMBININGSORT : LocalStrategy.SORT;
      }
    }
    if (ls == LocalStrategy.COMBININGSORT || ls == LocalStrategy.SORT) {
      Ordering ordering=new Ordering();
      for (      Integer index : keySet) {
        ordering.appendOrdering(index,null,Order.ASCENDING);
      }
      lp.setOrdering(ordering);
      lp.setGrouped(true,keySet);
    }
    OptimizerNode reducePred=subPlan;
    if (isCombineable() && ss != ShipStrategy.FORWARD) {
      OptimizerNode combiner=new CombinerNode(getPactContract(),subPlan,this.combinerReducingFactor);
      combiner.setDegreeOfParallelism(subPlan.getDegreeOfParallelism());
      estimator.costOperator(combiner);
      reducePred=combiner;
    }
    ReduceNode n=new ReduceNode(this,reducePred,this.inConn,gp,lp);
    n.inConn.setShipStrategy(ss);
    n.setLocalStrategy(ls);
    n.getGlobalProperties().filterByNodesConstantSet(this,0);
    n.getLocalProperties().filterByNodesConstantSet(this,0);
    estimator.costOperator(n);
    outputPlans.add(n);
  }
}","@Override protected void computeValidPlanAlternatives(List<? extends OptimizerNode> altSubPlans,CostEstimator estimator,List<OptimizerNode> outputPlans){
  FieldSet keySet=new FieldSet(getPactContract().getKeyColumnNumbers(0));
  ShipStrategy ss=ShipStrategy.NONE;
  ShipStrategy hintSS=this.inConn.getShipStrategy();
  if (hintSS == ShipStrategy.BROADCAST || hintSS == ShipStrategy.SFR)   return;
 else   ss=hintSS;
  for (  OptimizerNode subPlan : altSubPlans) {
    GlobalProperties gp;
    LocalProperties lp;
    if (ss == ShipStrategy.NONE) {
      gp=subPlan.getGlobalProperties();
      lp=subPlan.getLocalProperties();
      if ((partitioningIsOnRightFields(gp) && gp.getPartitioning().isPartitioned()) || isFieldSetUnique(keySet,0)) {
        ss=ShipStrategy.FORWARD;
      }
 else {
        ss=ShipStrategy.PARTITION_HASH;
      }
      gp=PactConnection.getGlobalPropertiesAfterConnection(subPlan,this,0,ss);
      lp=PactConnection.getLocalPropertiesAfterConnection(subPlan,this,ss);
    }
 else {
      gp=PactConnection.getGlobalPropertiesAfterConnection(subPlan,this,0,ss);
      lp=PactConnection.getLocalPropertiesAfterConnection(subPlan,this,ss);
      if (!((partitioningIsOnRightFields(gp) && gp.getPartitioning().isPartitioned()) || isFieldSetUnique(keySet,0))) {
        continue;
      }
    }
    boolean localStrategyNeeded=false;
    if (lp.getOrdering() == null || lp.getOrdering().groupsFieldSet(keySet) == false) {
      localStrategyNeeded=true;
    }
    if (localStrategyNeeded && lp.isGrouped() == true) {
      localStrategyNeeded=!lp.getGroupedFields().equals(keySet);
    }
    if (localStrategyNeeded) {
      localStrategyNeeded=!isFieldSetUnique(keySet,0);
    }
    LocalStrategy ls=getLocalStrategy();
    if (localStrategyNeeded) {
      if (ls != LocalStrategy.NONE) {
        if (ls != LocalStrategy.COMBININGSORT && ls != LocalStrategy.SORT) {
          continue;
        }
      }
 else {
        ls=isCombineable() ? LocalStrategy.COMBININGSORT : LocalStrategy.SORT;
      }
    }
    if (ls == LocalStrategy.COMBININGSORT || ls == LocalStrategy.SORT) {
      Ordering ordering=new Ordering();
      for (      Integer index : keySet) {
        ordering.appendOrdering(index,null,Order.ASCENDING);
      }
      lp.setOrdering(ordering);
      lp.setGrouped(true,keySet);
    }
    OptimizerNode reducePred=subPlan;
    if (isCombineable() && ss != ShipStrategy.FORWARD) {
      OptimizerNode combiner=new CombinerNode(getPactContract(),subPlan,this.combinerReducingFactor);
      combiner.setDegreeOfParallelism(subPlan.getDegreeOfParallelism());
      estimator.costOperator(combiner);
      reducePred=combiner;
    }
    ReduceNode n=new ReduceNode(this,reducePred,this.inConn,gp,lp);
    n.inConn.setShipStrategy(ss);
    n.setLocalStrategy(ls);
    n.getGlobalProperties().filterByNodesConstantSet(this,0);
    n.getLocalProperties().filterByNodesConstantSet(this,0);
    estimator.costOperator(n);
    outputPlans.add(n);
  }
}",0.9993288590604028
55373,"public RandomAccessInputView(ArrayList<MemorySegment> segments,int segmentSize,int limitInLastSegment){
  super(segments.get(0),segmentSize,0);
  this.segments=segments;
  this.currentSegmentIndex=0;
  this.segmentSize=segmentSize;
  this.segmentSizeBits=MathUtils.log2strict(segmentSize);
  this.segmentSizeMask=segmentSize - 1;
  this.limitInLastSegment=limitInLastSegment;
}","public RandomAccessInputView(ArrayList<MemorySegment> segments,int segmentSize,int limitInLastSegment){
  super(segments.get(0),segments.size() > 1 ? segmentSize : limitInLastSegment,0);
  this.segments=segments;
  this.currentSegmentIndex=0;
  this.segmentSize=segmentSize;
  this.segmentSizeBits=MathUtils.log2strict(segmentSize);
  this.segmentSizeMask=segmentSize - 1;
  this.limitInLastSegment=limitInLastSegment;
}",0.9360100376411544
55374,"@Override public void setReadPosition(long position){
  final int bufferNum=(int)(position >>> this.segmentSizeBits);
  final int offset=(int)(position & this.segmentSizeMask);
  this.currentSegmentIndex=bufferNum;
  seekInput(this.segments.get(bufferNum),offset,this.segmentSize);
}","@Override public void setReadPosition(long position){
  final int bufferNum=(int)(position >>> this.segmentSizeBits);
  final int offset=(int)(position & this.segmentSizeMask);
  this.currentSegmentIndex=bufferNum;
  seekInput(this.segments.get(bufferNum),offset,bufferNum < this.segments.size() - 1 ? this.segmentSize : this.limitInLastSegment);
}",0.8557844690966719
55375,"/** 
 * Private utility method that generates the alternative CoGroup nodes, given fixed shipping strategies for the inputs.
 * @param target The list to put the alternatives in.
 * @param subPlan1 The subplan for the first input.
 * @param subPlan2 The subplan for the second input.
 * @param ss1 The shipping strategy for the first input.
 * @param ss2 The shipping strategy for the second input.
 * @param estimator The cost estimator.
 */
private void createCoGroupAlternative(List<OptimizerNode> target,OptimizerNode subPlan1,OptimizerNode subPlan2,ShipStrategy ss1,ShipStrategy ss2,CostEstimator estimator){
  GlobalProperties gp1, gp2;
  LocalProperties lp1, lp2;
  gp1=PactConnection.getGlobalPropertiesAfterConnection(subPlan1,this,ss1);
  lp1=PactConnection.getLocalPropertiesAfterConnection(subPlan1,this,ss1);
  gp2=PactConnection.getGlobalPropertiesAfterConnection(subPlan2,this,ss2);
  lp2=PactConnection.getLocalPropertiesAfterConnection(subPlan2,this,ss2);
  int[] scrambledKeyOrder1=null;
  int[] scrambledKeyOrder2=null;
  if (ss1 == ShipStrategy.FORWARD && ss2 == ShipStrategy.PARTITION_HASH) {
    scrambledKeyOrder1=getScrambledKeyOrder(this.keySet1,gp1.getPartitionedFields());
    if (scrambledKeyOrder1 != null) {
      FieldList scrambledKeys2=new FieldList();
      for (int i=0; i < scrambledKeyOrder1.length; i++) {
        scrambledKeys2.set(i,this.keySet2.get(scrambledKeyOrder1[i]));
      }
      gp2.setPartitioning(gp2.getPartitioning(),scrambledKeys2);
    }
  }
  if (ss2 == ShipStrategy.FORWARD && ss1 == ShipStrategy.PARTITION_HASH) {
    scrambledKeyOrder2=getScrambledKeyOrder(this.keySet2,gp2.getPartitionedFields());
    if (scrambledKeyOrder2 != null) {
      FieldList scrambledKeys1=new FieldList();
      for (int i=0; i < scrambledKeyOrder2.length; i++) {
        scrambledKeys1.set(i,this.keySet1.get(scrambledKeyOrder2[i]));
      }
      gp1.setPartitioning(gp1.getPartitioning(),scrambledKeys1);
    }
  }
  int[] keyColumns1=getPactContract().getKeyColumnNumbers(0);
  Ordering ordering1=new Ordering();
  for (  int keyColumn : keyColumns1) {
    ordering1.appendOrdering(keyColumn,null,Order.ASCENDING);
  }
  int[] keyColumns2=getPactContract().getKeyColumnNumbers(1);
  Ordering ordering2=new Ordering();
  for (  int keyColumn : keyColumns2) {
    ordering2.appendOrdering(keyColumn,null,Order.ASCENDING);
  }
  GlobalProperties outGp=new GlobalProperties();
  outGp.setPartitioning(gp1.getPartitioning(),gp1.getPartitionedFields());
  CoGroupNode n=new CoGroupNode(this,subPlan1,subPlan2,this.input1,this.input2,outGp,new LocalProperties());
  n.input1.setShipStrategy(ss1);
  n.input1.setScramblePartitionedFields(scrambledKeyOrder2);
  n.input2.setShipStrategy(ss2);
  n.input2.setScramblePartitionedFields(scrambledKeyOrder1);
  n.getLocalProperties().setOrdering(ordering1);
  n.getLocalProperties().setGrouped(true,new FieldSet(keyColumns1));
  if (n.getLocalStrategy() == LocalStrategy.NONE) {
    if (ordering1.isMetBy(lp1.getOrdering()) && ordering2.isMetBy(lp2.getOrdering())) {
      n.setLocalStrategy(LocalStrategy.MERGE);
    }
 else     if (!ordering1.isMetBy(lp1.getOrdering()) && ordering2.isMetBy(lp2.getOrdering())) {
      n.setLocalStrategy(LocalStrategy.SORT_FIRST_MERGE);
    }
 else     if (ordering1.isMetBy(lp1.getOrdering()) && !ordering2.isMetBy(lp2.getOrdering())) {
      n.setLocalStrategy(LocalStrategy.SORT_SECOND_MERGE);
    }
 else {
      n.setLocalStrategy(LocalStrategy.SORT_BOTH_MERGE);
    }
  }
  n.getGlobalProperties().filterByNodesConstantSet(this,0);
  n.getLocalProperties().filterByNodesConstantSet(this,0);
  estimator.costOperator(n);
  target.add(n);
  outGp=new GlobalProperties();
  outGp.setPartitioning(gp2.getPartitioning(),gp2.getPartitionedFields());
  n=new CoGroupNode(this,subPlan1,subPlan2,input1,input2,outGp,new LocalProperties());
  n.input1.setShipStrategy(ss1);
  n.input1.setScramblePartitionedFields(scrambledKeyOrder2);
  n.input2.setShipStrategy(ss2);
  n.input2.setScramblePartitionedFields(scrambledKeyOrder1);
  n.getLocalProperties().setOrdering(ordering2);
  n.getLocalProperties().setGrouped(true,new FieldSet(keyColumns2));
  if (n.getLocalStrategy() == LocalStrategy.NONE) {
    if (ordering1.isMetBy(lp1.getOrdering()) && ordering2.isMetBy(lp2.getOrdering())) {
      n.setLocalStrategy(LocalStrategy.MERGE);
    }
 else     if (!ordering1.isMetBy(lp1.getOrdering()) && ordering2.isMetBy(lp2.getOrdering())) {
      n.setLocalStrategy(LocalStrategy.SORT_FIRST_MERGE);
    }
 else     if (ordering1.isMetBy(lp1.getOrdering()) && !ordering2.isMetBy(lp2.getOrdering())) {
      n.setLocalStrategy(LocalStrategy.SORT_SECOND_MERGE);
    }
 else {
      n.setLocalStrategy(LocalStrategy.SORT_BOTH_MERGE);
    }
  }
  n.getGlobalProperties().filterByNodesConstantSet(this,1);
  n.getLocalProperties().filterByNodesConstantSet(this,1);
  estimator.costOperator(n);
  target.add(n);
}","/** 
 * Private utility method that generates the alternative CoGroup nodes, given fixed shipping strategies for the inputs.
 * @param target The list to put the alternatives in.
 * @param subPlan1 The subplan for the first input.
 * @param subPlan2 The subplan for the second input.
 * @param ss1 The shipping strategy for the first input.
 * @param ss2 The shipping strategy for the second input.
 * @param estimator The cost estimator.
 */
private void createCoGroupAlternative(List<OptimizerNode> target,OptimizerNode subPlan1,OptimizerNode subPlan2,ShipStrategy ss1,ShipStrategy ss2,CostEstimator estimator){
  GlobalProperties gp1, gp2;
  LocalProperties lp1, lp2;
  gp1=PactConnection.getGlobalPropertiesAfterConnection(subPlan1,this,ss1);
  lp1=PactConnection.getLocalPropertiesAfterConnection(subPlan1,this,ss1);
  gp2=PactConnection.getGlobalPropertiesAfterConnection(subPlan2,this,ss2);
  lp2=PactConnection.getLocalPropertiesAfterConnection(subPlan2,this,ss2);
  int[] scrambledKeyOrder1=null;
  int[] scrambledKeyOrder2=null;
  if (ss1 == ShipStrategy.FORWARD && ss2 == ShipStrategy.PARTITION_HASH) {
    scrambledKeyOrder1=getScrambledKeyOrder(this.keySet1,gp1.getPartitionedFields());
    if (scrambledKeyOrder1 != null) {
      FieldList scrambledKeys2=new FieldList();
      for (int i=0; i < scrambledKeyOrder1.length; i++) {
        scrambledKeys2.add(this.keySet2.get(scrambledKeyOrder1[i]));
      }
      gp2.setPartitioning(gp2.getPartitioning(),scrambledKeys2);
    }
  }
  if (ss2 == ShipStrategy.FORWARD && ss1 == ShipStrategy.PARTITION_HASH) {
    scrambledKeyOrder2=getScrambledKeyOrder(this.keySet2,gp2.getPartitionedFields());
    if (scrambledKeyOrder2 != null) {
      FieldList scrambledKeys1=new FieldList();
      for (int i=0; i < scrambledKeyOrder2.length; i++) {
        scrambledKeys1.add(this.keySet1.get(scrambledKeyOrder2[i]));
      }
      gp1.setPartitioning(gp1.getPartitioning(),scrambledKeys1);
    }
  }
  int[] keyColumns1=getPactContract().getKeyColumnNumbers(0);
  Ordering ordering1=new Ordering();
  for (  int keyColumn : keyColumns1) {
    ordering1.appendOrdering(keyColumn,null,Order.ASCENDING);
  }
  int[] keyColumns2=getPactContract().getKeyColumnNumbers(1);
  Ordering ordering2=new Ordering();
  for (  int keyColumn : keyColumns2) {
    ordering2.appendOrdering(keyColumn,null,Order.ASCENDING);
  }
  GlobalProperties outGp=new GlobalProperties();
  outGp.setPartitioning(gp1.getPartitioning(),gp1.getPartitionedFields());
  CoGroupNode n=new CoGroupNode(this,subPlan1,subPlan2,this.input1,this.input2,outGp,new LocalProperties());
  n.input1.setShipStrategy(ss1);
  n.input1.setScramblePartitionedFields(scrambledKeyOrder2);
  n.input2.setShipStrategy(ss2);
  n.input2.setScramblePartitionedFields(scrambledKeyOrder1);
  n.getLocalProperties().setOrdering(ordering1);
  n.getLocalProperties().setGrouped(true,new FieldSet(keyColumns1));
  if (n.getLocalStrategy() == LocalStrategy.NONE) {
    if (ordering1.isMetBy(lp1.getOrdering()) && ordering2.isMetBy(lp2.getOrdering())) {
      n.setLocalStrategy(LocalStrategy.MERGE);
    }
 else     if (!ordering1.isMetBy(lp1.getOrdering()) && ordering2.isMetBy(lp2.getOrdering())) {
      n.setLocalStrategy(LocalStrategy.SORT_FIRST_MERGE);
    }
 else     if (ordering1.isMetBy(lp1.getOrdering()) && !ordering2.isMetBy(lp2.getOrdering())) {
      n.setLocalStrategy(LocalStrategy.SORT_SECOND_MERGE);
    }
 else {
      n.setLocalStrategy(LocalStrategy.SORT_BOTH_MERGE);
    }
  }
  n.getGlobalProperties().filterByNodesConstantSet(this,0);
  n.getLocalProperties().filterByNodesConstantSet(this,0);
  estimator.costOperator(n);
  target.add(n);
  outGp=new GlobalProperties();
  outGp.setPartitioning(gp2.getPartitioning(),gp2.getPartitionedFields());
  n=new CoGroupNode(this,subPlan1,subPlan2,input1,input2,outGp,new LocalProperties());
  n.input1.setShipStrategy(ss1);
  n.input1.setScramblePartitionedFields(scrambledKeyOrder2);
  n.input2.setShipStrategy(ss2);
  n.input2.setScramblePartitionedFields(scrambledKeyOrder1);
  n.getLocalProperties().setOrdering(ordering2);
  n.getLocalProperties().setGrouped(true,new FieldSet(keyColumns2));
  if (n.getLocalStrategy() == LocalStrategy.NONE) {
    if (ordering1.isMetBy(lp1.getOrdering()) && ordering2.isMetBy(lp2.getOrdering())) {
      n.setLocalStrategy(LocalStrategy.MERGE);
    }
 else     if (!ordering1.isMetBy(lp1.getOrdering()) && ordering2.isMetBy(lp2.getOrdering())) {
      n.setLocalStrategy(LocalStrategy.SORT_FIRST_MERGE);
    }
 else     if (ordering1.isMetBy(lp1.getOrdering()) && !ordering2.isMetBy(lp2.getOrdering())) {
      n.setLocalStrategy(LocalStrategy.SORT_SECOND_MERGE);
    }
 else {
      n.setLocalStrategy(LocalStrategy.SORT_BOTH_MERGE);
    }
  }
  n.getGlobalProperties().filterByNodesConstantSet(this,1);
  n.getLocalProperties().filterByNodesConstantSet(this,1);
  estimator.costOperator(n);
  target.add(n);
}",0.9979629252393564
55376,"/** 
 * Private utility method that generates a candidate Match node, given fixed shipping strategies and a fixed local strategy.
 * @param target The list to put the alternatives in.
 * @param subPlan1 The predecessor node for the first input.
 * @param subPlan2 The predecessor node for the second input.
 * @param ss1 The shipping strategy for the first input.
 * @param ss2 The shipping strategy for the second input.
 * @param ls The local strategy.
 * @param outGp The global properties of the data that goes to the user function.
 * @param outLp The local properties of the data that goes to the user function.
 * @param estimator The cost estimator.
 */
private void createMatchAlternative(List<OptimizerNode> target,OptimizerNode subPlan1,OptimizerNode subPlan2,ShipStrategy ss1,ShipStrategy ss2,LocalStrategy ls,Order order,boolean grouped,LocalProperties outLpp,CostEstimator estimator){
  if (ls != LocalStrategy.SELF_NESTEDLOOP && ls != LocalStrategy.SORT_SELF_NESTEDLOOP) {
    GlobalProperties gp1=PactConnection.getGlobalPropertiesAfterConnection(subPlan1,this,ss1);
    GlobalProperties gp2=PactConnection.getGlobalPropertiesAfterConnection(subPlan2,this,ss2);
    int[] scrambledKeyOrder1=null;
    int[] scrambledKeyOrder2=null;
    if (ss1 == ShipStrategy.FORWARD && ss2 == ShipStrategy.PARTITION_HASH) {
      scrambledKeyOrder1=getScrambledKeyOrder(this.keySet1,gp1.getPartitionedFields());
      if (scrambledKeyOrder1 != null) {
        FieldList scrambledKeys2=new FieldList();
        for (int i=0; i < scrambledKeyOrder1.length; i++) {
          scrambledKeys2.set(i,this.keySet2.get(scrambledKeyOrder1[i]));
        }
        gp2.setPartitioning(gp2.getPartitioning(),scrambledKeys2);
      }
    }
    if (ss2 == ShipStrategy.FORWARD && ss1 == ShipStrategy.PARTITION_HASH) {
      scrambledKeyOrder2=getScrambledKeyOrder(this.keySet2,gp2.getPartitionedFields());
      if (scrambledKeyOrder2 != null) {
        FieldList scrambledKeys1=new FieldList();
        for (int i=0; i < scrambledKeyOrder2.length; i++) {
          scrambledKeys1.set(i,this.keySet1.get(scrambledKeyOrder2[i]));
        }
        gp1.setPartitioning(gp1.getPartitioning(),scrambledKeys1);
      }
    }
    LocalProperties outLp=outLpp;
    GlobalProperties outGp=new GlobalProperties();
    outGp.setPartitioning(gp1.getPartitioning(),gp1.getPartitionedFields());
    outGp.setOrdering(gp1.getOrdering());
    if (outLpp == null) {
      outLp=new LocalProperties();
      if (order != Order.NONE) {
        Ordering ordering=new Ordering();
        for (        int keyColumn : this.keySet1) {
          ordering.appendOrdering(keyColumn,null,order);
        }
        outLp.setOrdering(ordering);
      }
 else {
        outLp.setOrdering(null);
      }
      outLp.setGrouped(grouped,new FieldSet(this.keySet1));
    }
    MatchNode n=new MatchNode(this,subPlan1,subPlan2,this.input1,this.input2,outGp,outLp);
    n.input1.setShipStrategy(ss1);
    n.input1.setScramblePartitionedFields(scrambledKeyOrder2);
    n.input2.setShipStrategy(ss2);
    n.input2.setScramblePartitionedFields(scrambledKeyOrder1);
    n.setLocalStrategy(ls);
    n.getGlobalProperties().filterByNodesConstantSet(this,0);
    n.getLocalProperties().filterByNodesConstantSet(this,0);
    estimator.costOperator(n);
    target.add(n);
    outGp=new GlobalProperties();
    outGp.setPartitioning(gp2.getPartitioning(),gp2.getPartitionedFields());
    outGp.setOrdering(gp2.getOrdering());
    if (outLpp == null) {
      outLp=new LocalProperties();
      if (order != Order.NONE) {
        Ordering ordering=new Ordering();
        for (        int keyColumn : this.keySet2) {
          ordering.appendOrdering(keyColumn,null,order);
        }
        outLp.setOrdering(ordering);
      }
 else {
        outLp.setOrdering(null);
      }
      outLp.setGrouped(grouped,new FieldSet(this.keySet2));
    }
    n=new MatchNode(this,subPlan1,subPlan2,input1,input2,outGp,outLp);
    n.input1.setShipStrategy(ss1);
    n.input1.setScramblePartitionedFields(scrambledKeyOrder2);
    n.input2.setShipStrategy(ss2);
    n.input2.setScramblePartitionedFields(scrambledKeyOrder1);
    n.setLocalStrategy(ls);
    n.getGlobalProperties().filterByNodesConstantSet(this,1);
    n.getLocalProperties().filterByNodesConstantSet(this,1);
    estimator.costOperator(n);
    target.add(n);
  }
 else {
    GlobalProperties gp1=PactConnection.getGlobalPropertiesAfterConnection(subPlan1,this,ss1);
    GlobalProperties outGp=new GlobalProperties();
    outGp.setPartitioning(gp1.getPartitioning(),gp1.getPartitionedFields());
    outGp.setOrdering(gp1.getOrdering());
    LocalProperties outLp=null;
    if (outLpp == null) {
      outLp=new LocalProperties();
      if (order != Order.NONE) {
        Ordering ordering=new Ordering();
        for (        int keyColumn : this.keySet1) {
          ordering.appendOrdering(keyColumn,null,order);
        }
        outLp.setOrdering(ordering);
      }
 else {
        outLp.setOrdering(null);
      }
      outLp.setGrouped(grouped,new FieldSet(this.keySet1));
    }
    MatchNode n=new MatchNode(this,subPlan1,null,this.input1,null,outGp,outLp);
    n.input1.setShipStrategy(ss1);
    n.setLocalStrategy(ls);
    n.getGlobalProperties().filterByNodesConstantSet(this,0);
    n.getLocalProperties().filterByNodesConstantSet(this,0);
    estimator.costOperator(n);
    target.add(n);
  }
}","/** 
 * Private utility method that generates a candidate Match node, given fixed shipping strategies and a fixed local strategy.
 * @param target The list to put the alternatives in.
 * @param subPlan1 The predecessor node for the first input.
 * @param subPlan2 The predecessor node for the second input.
 * @param ss1 The shipping strategy for the first input.
 * @param ss2 The shipping strategy for the second input.
 * @param ls The local strategy.
 * @param outGp The global properties of the data that goes to the user function.
 * @param outLp The local properties of the data that goes to the user function.
 * @param estimator The cost estimator.
 */
private void createMatchAlternative(List<OptimizerNode> target,OptimizerNode subPlan1,OptimizerNode subPlan2,ShipStrategy ss1,ShipStrategy ss2,LocalStrategy ls,Order order,boolean grouped,LocalProperties outLpp,CostEstimator estimator){
  if (ls != LocalStrategy.SELF_NESTEDLOOP && ls != LocalStrategy.SORT_SELF_NESTEDLOOP) {
    GlobalProperties gp1=PactConnection.getGlobalPropertiesAfterConnection(subPlan1,this,ss1);
    GlobalProperties gp2=PactConnection.getGlobalPropertiesAfterConnection(subPlan2,this,ss2);
    int[] scrambledKeyOrder1=null;
    int[] scrambledKeyOrder2=null;
    if (ss1 == ShipStrategy.FORWARD && ss2 == ShipStrategy.PARTITION_HASH) {
      scrambledKeyOrder1=getScrambledKeyOrder(this.keySet1,gp1.getPartitionedFields());
      if (scrambledKeyOrder1 != null) {
        FieldList scrambledKeys2=new FieldList();
        for (int i=0; i < scrambledKeyOrder1.length; i++) {
          scrambledKeys2.add(this.keySet2.get(scrambledKeyOrder1[i]));
        }
        gp2.setPartitioning(gp2.getPartitioning(),scrambledKeys2);
      }
    }
    if (ss2 == ShipStrategy.FORWARD && ss1 == ShipStrategy.PARTITION_HASH) {
      scrambledKeyOrder2=getScrambledKeyOrder(this.keySet2,gp2.getPartitionedFields());
      if (scrambledKeyOrder2 != null) {
        FieldList scrambledKeys1=new FieldList();
        for (int i=0; i < scrambledKeyOrder2.length; i++) {
          scrambledKeys1.add(this.keySet1.get(scrambledKeyOrder2[i]));
        }
        gp1.setPartitioning(gp1.getPartitioning(),scrambledKeys1);
      }
    }
    LocalProperties outLp=outLpp;
    GlobalProperties outGp=new GlobalProperties();
    outGp.setPartitioning(gp1.getPartitioning(),gp1.getPartitionedFields());
    outGp.setOrdering(gp1.getOrdering());
    if (outLpp == null) {
      outLp=new LocalProperties();
      if (order != Order.NONE) {
        Ordering ordering=new Ordering();
        for (        int keyColumn : this.keySet1) {
          ordering.appendOrdering(keyColumn,null,order);
        }
        outLp.setOrdering(ordering);
      }
 else {
        outLp.setOrdering(null);
      }
      outLp.setGrouped(grouped,new FieldSet(this.keySet1));
    }
    MatchNode n=new MatchNode(this,subPlan1,subPlan2,this.input1,this.input2,outGp,outLp);
    n.input1.setShipStrategy(ss1);
    n.input1.setScramblePartitionedFields(scrambledKeyOrder2);
    n.input2.setShipStrategy(ss2);
    n.input2.setScramblePartitionedFields(scrambledKeyOrder1);
    n.setLocalStrategy(ls);
    n.getGlobalProperties().filterByNodesConstantSet(this,0);
    n.getLocalProperties().filterByNodesConstantSet(this,0);
    estimator.costOperator(n);
    target.add(n);
    outGp=new GlobalProperties();
    outGp.setPartitioning(gp2.getPartitioning(),gp2.getPartitionedFields());
    outGp.setOrdering(gp2.getOrdering());
    if (outLpp == null) {
      outLp=new LocalProperties();
      if (order != Order.NONE) {
        Ordering ordering=new Ordering();
        for (        int keyColumn : this.keySet2) {
          ordering.appendOrdering(keyColumn,null,order);
        }
        outLp.setOrdering(ordering);
      }
 else {
        outLp.setOrdering(null);
      }
      outLp.setGrouped(grouped,new FieldSet(this.keySet2));
    }
    n=new MatchNode(this,subPlan1,subPlan2,input1,input2,outGp,outLp);
    n.input1.setShipStrategy(ss1);
    n.input1.setScramblePartitionedFields(scrambledKeyOrder2);
    n.input2.setShipStrategy(ss2);
    n.input2.setScramblePartitionedFields(scrambledKeyOrder1);
    n.setLocalStrategy(ls);
    n.getGlobalProperties().filterByNodesConstantSet(this,1);
    n.getLocalProperties().filterByNodesConstantSet(this,1);
    estimator.costOperator(n);
    target.add(n);
  }
 else {
    GlobalProperties gp1=PactConnection.getGlobalPropertiesAfterConnection(subPlan1,this,ss1);
    GlobalProperties outGp=new GlobalProperties();
    outGp.setPartitioning(gp1.getPartitioning(),gp1.getPartitionedFields());
    outGp.setOrdering(gp1.getOrdering());
    LocalProperties outLp=null;
    if (outLpp == null) {
      outLp=new LocalProperties();
      if (order != Order.NONE) {
        Ordering ordering=new Ordering();
        for (        int keyColumn : this.keySet1) {
          ordering.appendOrdering(keyColumn,null,order);
        }
        outLp.setOrdering(ordering);
      }
 else {
        outLp.setOrdering(null);
      }
      outLp.setGrouped(grouped,new FieldSet(this.keySet1));
    }
    MatchNode n=new MatchNode(this,subPlan1,null,this.input1,null,outGp,outLp);
    n.input1.setShipStrategy(ss1);
    n.setLocalStrategy(ls);
    n.getGlobalProperties().filterByNodesConstantSet(this,0);
    n.getLocalProperties().filterByNodesConstantSet(this,0);
    estimator.costOperator(n);
    target.add(n);
  }
}",0.9981464318813716
55377,"private final void initFields(final byte[] data,final int begin,final int len){
  try {
    int pos=begin + len - 2;
    int numFields=data[begin + len - 1] & 0xFF;
    if (numFields >= MAX_BIT) {
      int shift=7;
      int curr;
      numFields=numFields & 0x7f;
      while ((curr=data[pos--]) >= MAX_BIT) {
        numFields|=(curr & 0x7f) << shift;
        shift+=7;
      }
      numFields|=curr << shift;
    }
    this.numFields=numFields;
    if (this.offsets == null || this.offsets.length < numFields) {
      this.offsets=new int[numFields];
    }
    if (this.lengths == null || this.lengths.length < numFields) {
      this.lengths=new int[numFields];
    }
    if (this.readFields == null || this.readFields.length < numFields) {
      this.readFields=new Value[numFields];
    }
    if (this.writeFields == null || this.writeFields.length < numFields) {
      this.writeFields=new Value[numFields];
    }
    final int beginMasks=pos;
    final int fieldsBy8=(numFields >>> 3) + ((numFields & 0x7) == 0 ? 0 : 1);
    pos=beginMasks - fieldsBy8;
    int lastNonNullField=-1;
    for (int field=0, chunk=0; chunk < fieldsBy8; chunk++) {
      int mask=data[beginMasks - chunk];
      for (int i=0; i < 8 && field < numFields; i++, field++) {
        if ((mask & 0x1) == 0x1) {
          if (lastNonNullField >= 0) {
            int start=data[pos--] & 0xff;
            if (start >= MAX_BIT) {
              int shift=7;
              int curr;
              start=start & 0x7f;
              while ((curr=data[pos--] & 0xff) >= MAX_BIT) {
                start|=(curr & 0x7f) << shift;
                shift+=7;
              }
              start|=curr << shift;
            }
            this.offsets[field]=start + begin;
            this.lengths[lastNonNullField]=start + begin - this.offsets[lastNonNullField];
          }
 else {
            this.offsets[field]=begin;
          }
          lastNonNullField=field;
        }
 else {
          this.offsets[field]=NULL_INDICATOR_OFFSET;
        }
        mask>>=1;
      }
    }
    if (lastNonNullField >= 0) {
      this.lengths[lastNonNullField]=pos - this.offsets[lastNonNullField] + 1;
    }
    this.firstModifiedPos=Integer.MAX_VALUE;
  }
 catch (  ArrayIndexOutOfBoundsException aioobex) {
    StringBuilder bld=new StringBuilder(len * 4 + 64);
    bld.append(""String_Node_Str"");
    for (int i=0; i < len; i++) {
      int num=data[i + begin] & 0xff;
      bld.append(num);
      if (i < len - 1) {
        bld.append(',');
      }
    }
    throw new RuntimeException(bld.toString(),aioobex);
  }
}","private final void initFields(final byte[] data,final int begin,final int len){
  try {
    int pos=begin + len - 2;
    int numFields=data[begin + len - 1] & 0xFF;
    if (numFields >= MAX_BIT) {
      int shift=7;
      int curr;
      numFields=numFields & 0x7f;
      while ((curr=data[pos--] & 0xff) >= MAX_BIT) {
        numFields|=(curr & 0x7f) << shift;
        shift+=7;
      }
      numFields|=curr << shift;
    }
    this.numFields=numFields;
    if (this.offsets == null || this.offsets.length < numFields) {
      this.offsets=new int[numFields];
    }
    if (this.lengths == null || this.lengths.length < numFields) {
      this.lengths=new int[numFields];
    }
    if (this.readFields == null || this.readFields.length < numFields) {
      this.readFields=new Value[numFields];
    }
    if (this.writeFields == null || this.writeFields.length < numFields) {
      this.writeFields=new Value[numFields];
    }
    final int beginMasks=pos;
    final int fieldsBy8=(numFields >>> 3) + ((numFields & 0x7) == 0 ? 0 : 1);
    pos=beginMasks - fieldsBy8;
    int lastNonNullField=-1;
    for (int field=0, chunk=0; chunk < fieldsBy8; chunk++) {
      int mask=data[beginMasks - chunk];
      for (int i=0; i < 8 && field < numFields; i++, field++) {
        if ((mask & 0x1) == 0x1) {
          if (lastNonNullField >= 0) {
            int start=data[pos--] & 0xff;
            if (start >= MAX_BIT) {
              int shift=7;
              int curr;
              start=start & 0x7f;
              while ((curr=data[pos--] & 0xff) >= MAX_BIT) {
                start|=(curr & 0x7f) << shift;
                shift+=7;
              }
              start|=curr << shift;
            }
            this.offsets[field]=start + begin;
            this.lengths[lastNonNullField]=start + begin - this.offsets[lastNonNullField];
          }
 else {
            this.offsets[field]=begin;
          }
          lastNonNullField=field;
        }
 else {
          this.offsets[field]=NULL_INDICATOR_OFFSET;
        }
        mask>>=1;
      }
    }
    if (lastNonNullField >= 0) {
      this.lengths[lastNonNullField]=pos - this.offsets[lastNonNullField] + 1;
    }
    this.firstModifiedPos=Integer.MAX_VALUE;
  }
 catch (  ArrayIndexOutOfBoundsException aioobex) {
    StringBuilder bld=new StringBuilder(len * 4 + 64);
    bld.append(""String_Node_Str"");
    for (int i=0; i < len; i++) {
      int num=data[i + begin] & 0xff;
      bld.append(num);
      if (i < len - 1) {
        bld.append(',');
      }
    }
    throw new RuntimeException(bld.toString(),aioobex);
  }
}",0.99864472410455
55378,"/** 
 * {@inheritDoc}
 */
@Override public void requestClose() throws IOException, InterruptedException {
  if (!this.closeRequested) {
    this.closeRequested=true;
    if (this.serializationBuffer.dataLeftFromPreviousSerialization()) {
      flush();
    }
    if (!isBroadcastChannel() || getChannelIndex() == 0) {
      transferEvent(new ByteBufferedChannelCloseEvent());
      flush();
    }
  }
}","/** 
 * {@inheritDoc}
 */
@Override public void requestClose() throws IOException, InterruptedException {
  if (!this.closeRequested) {
    this.closeRequested=true;
    if (this.serializationBuffer.dataLeftFromPreviousSerialization()) {
      flush();
    }
    if (getType() == ChannelType.INMEMORY || !isBroadcastChannel() || getChannelIndex() == 0) {
      transferEvent(new ByteBufferedChannelCloseEvent());
      flush();
    }
  }
}",0.906064209274673
55379,"public static void main(String[] args) throws Exception {
  int degreeOfParallelism=2;
  JobGraph jobGraph=new JobGraph(""String_Node_Str"");
  JobInputVertex pageWithRankInput=JobGraphUtils.createInput(PageWithRankInputFormat.class,""String_Node_Str"",""String_Node_Str"",jobGraph,degreeOfParallelism);
  JobInputVertex transitionMatrixInput=JobGraphUtils.createInput(TransitionMatrixInputFormat.class,""String_Node_Str"",""String_Node_Str"",jobGraph,degreeOfParallelism);
  TaskConfig transitionMatrixInputConfig=new TaskConfig(transitionMatrixInput.getConfiguration());
  transitionMatrixInputConfig.setComparatorFactoryForOutput(PactRecordComparatorFactory.class,0);
  PactRecordComparatorFactory.writeComparatorSetupToConfig(transitionMatrixInput.getConfiguration(),""String_Node_Str"",new int[]{1},new Class[]{PactLong.class});
  JobTaskVertex head=JobGraphUtils.createTask(BulkIterationHeadPactTask.class,""String_Node_Str"",jobGraph,degreeOfParallelism);
  TaskConfig headConfig=new TaskConfig(head.getConfiguration());
  headConfig.setDriver(MapDriver.class);
  headConfig.setStubClass(IdentityMap.class);
  headConfig.setMemorySize(3 * JobGraphUtils.MEGABYTE);
  headConfig.setBackChannelMemoryFraction(0.8f);
  headConfig.setNumberOfIterations(1);
  JobTaskVertex intermediate=JobGraphUtils.createTask(BulkIterationIntermediatePactTask.class,""String_Node_Str"",jobGraph,degreeOfParallelism);
  TaskConfig intermediateConfig=new TaskConfig(intermediate.getConfiguration());
  intermediateConfig.setDriver(MatchDriver.class);
  intermediateConfig.setStubClass(DotProductMatch.class);
  intermediateConfig.setLocalStrategy(TaskConfig.LocalStrategy.HYBRIDHASH_FIRST);
  PactRecordComparatorFactory.writeComparatorSetupToConfig(intermediateConfig.getConfiguration(),""String_Node_Str"",new int[]{0},new Class[]{PactLong.class});
  PactRecordComparatorFactory.writeComparatorSetupToConfig(intermediateConfig.getConfiguration(),""String_Node_Str"",new int[]{0},new Class[]{PactLong.class});
  intermediateConfig.setMemorySize(20 * JobGraphUtils.MEGABYTE);
  intermediateConfig.setGateCached(1);
  intermediateConfig.setInputGateCacheMemoryFraction(0.5f);
  JobTaskVertex tail=JobGraphUtils.createTask(BulkIterationTailPactTask.class,""String_Node_Str"",jobGraph,degreeOfParallelism);
  TaskConfig tailConfig=new TaskConfig(tail.getConfiguration());
  tailConfig.setLocalStrategy(TaskConfig.LocalStrategy.SORT);
  tailConfig.setDriver(ReduceDriver.class);
  tailConfig.setStubClass(DotProductReducer.class);
  PactRecordComparatorFactory.writeComparatorSetupToConfig(tail.getConfiguration(),""String_Node_Str"",new int[]{0},new Class[]{PactLong.class});
  tailConfig.setMemorySize(3 * JobGraphUtils.MEGABYTE);
  tailConfig.setNumFilehandles(2);
  JobTaskVertex sync=JobGraphUtils.createSingletonTask(BulkIterationSynchronizationPactTask.class,""String_Node_Str"",jobGraph);
  TaskConfig syncConfig=new TaskConfig(sync.getConfiguration());
  syncConfig.setDriver(MapDriver.class);
  syncConfig.setStubClass(EmptyMapStub.class);
  JobOutputVertex output=JobGraphUtils.createFileOutput(jobGraph,""String_Node_Str"",degreeOfParallelism);
  TaskConfig outputConfig=new TaskConfig(output.getConfiguration());
  outputConfig.setStubClass(PageWithRankOutFormat.class);
  outputConfig.setStubParameter(FileOutputFormat.FILE_PARAMETER_KEY,""String_Node_Str"");
  JobOutputVertex fakeTailOutput=JobGraphUtils.createFakeOutput(jobGraph,""String_Node_Str"",degreeOfParallelism);
  JobOutputVertex fakeSyncOutput=JobGraphUtils.createSingletonFakeOutput(jobGraph,""String_Node_Str"");
  JobGraphUtils.connectLocal(pageWithRankInput,head);
  JobGraphUtils.connectNetwork(head,intermediate,DistributionPattern.BIPARTITE,ShipStrategy.BROADCAST);
  JobGraphUtils.connectLocal(transitionMatrixInput,intermediate,DistributionPattern.BIPARTITE,ShipStrategy.PARTITION_HASH);
  intermediateConfig.setGateIterativeWithNumberOfEventsUntilInterrupt(0,degreeOfParallelism);
  JobGraphUtils.connectLocal(intermediate,tail,DistributionPattern.POINTWISE,ShipStrategy.FORWARD);
  tailConfig.setGateIterativeWithNumberOfEventsUntilInterrupt(0,1);
  JobGraphUtils.connectLocal(head,sync);
  syncConfig.setGateIterativeWithNumberOfEventsUntilInterrupt(0,degreeOfParallelism);
  JobGraphUtils.connectLocal(head,output);
  JobGraphUtils.connectLocal(tail,fakeTailOutput);
  JobGraphUtils.connectLocal(sync,fakeSyncOutput);
  fakeTailOutput.setVertexToShareInstancesWith(tail);
  tail.setVertexToShareInstancesWith(head);
  pageWithRankInput.setVertexToShareInstancesWith(head);
  transitionMatrixInput.setVertexToShareInstancesWith(head);
  intermediate.setVertexToShareInstancesWith(head);
  output.setVertexToShareInstancesWith(head);
  sync.setVertexToShareInstancesWith(head);
  fakeSyncOutput.setVertexToShareInstancesWith(sync);
  GlobalConfiguration.loadConfiguration(""String_Node_Str"");
  Configuration conf=GlobalConfiguration.getConfiguration();
  JobGraphUtils.submit(jobGraph,conf);
}","public static void main(String[] args) throws Exception {
  int degreeOfParallelism=2;
  JobGraph jobGraph=new JobGraph(""String_Node_Str"");
  JobInputVertex pageWithRankInput=JobGraphUtils.createInput(PageWithRankInputFormat.class,""String_Node_Str"",""String_Node_Str"",jobGraph,degreeOfParallelism);
  JobInputVertex transitionMatrixInput=JobGraphUtils.createInput(TransitionMatrixInputFormat.class,""String_Node_Str"",""String_Node_Str"",jobGraph,degreeOfParallelism);
  TaskConfig transitionMatrixInputConfig=new TaskConfig(transitionMatrixInput.getConfiguration());
  transitionMatrixInputConfig.setComparatorFactoryForOutput(PactRecordComparatorFactory.class,0);
  PactRecordComparatorFactory.writeComparatorSetupToConfig(transitionMatrixInput.getConfiguration(),""String_Node_Str"",new int[]{1},new Class[]{PactLong.class});
  JobTaskVertex head=JobGraphUtils.createTask(BulkIterationHeadPactTask.class,""String_Node_Str"",jobGraph,degreeOfParallelism);
  TaskConfig headConfig=new TaskConfig(head.getConfiguration());
  headConfig.setDriver(MapDriver.class);
  headConfig.setStubClass(IdentityMap.class);
  headConfig.setMemorySize(3 * JobGraphUtils.MEGABYTE);
  headConfig.setBackChannelMemoryFraction(0.8f);
  headConfig.setNumberOfIterations(1);
  JobTaskVertex intermediate=JobGraphUtils.createTask(BulkIterationIntermediatePactTask.class,""String_Node_Str"",jobGraph,degreeOfParallelism);
  TaskConfig intermediateConfig=new TaskConfig(intermediate.getConfiguration());
  intermediateConfig.setDriver(MatchDriver.class);
  intermediateConfig.setStubClass(DotProductMatch.class);
  intermediateConfig.setLocalStrategy(TaskConfig.LocalStrategy.HYBRIDHASH_FIRST);
  PactRecordComparatorFactory.writeComparatorSetupToConfig(intermediateConfig.getConfiguration(),""String_Node_Str"",new int[]{0},new Class[]{PactLong.class});
  PactRecordComparatorFactory.writeComparatorSetupToConfig(intermediateConfig.getConfiguration(),""String_Node_Str"",new int[]{0},new Class[]{PactLong.class});
  intermediateConfig.setMemorySize(20 * JobGraphUtils.MEGABYTE);
  intermediateConfig.setGateCached(1);
  intermediateConfig.setInputGateCacheMemoryFraction(0.5f);
  JobTaskVertex tail=JobGraphUtils.createTask(BulkIterationTailPactTask.class,""String_Node_Str"",jobGraph,degreeOfParallelism);
  TaskConfig tailConfig=new TaskConfig(tail.getConfiguration());
  tailConfig.setLocalStrategy(TaskConfig.LocalStrategy.SORT);
  tailConfig.setDriver(ReduceDriver.class);
  tailConfig.setStubClass(DotProductReducer.class);
  PactRecordComparatorFactory.writeComparatorSetupToConfig(tail.getConfiguration(),""String_Node_Str"",new int[]{0},new Class[]{PactLong.class});
  tailConfig.setMemorySize(3 * JobGraphUtils.MEGABYTE);
  tailConfig.setNumFilehandles(2);
  JobTaskVertex sync=JobGraphUtils.createSingletonTask(BulkIterationSynchronizationPactTask.class,""String_Node_Str"",jobGraph);
  TaskConfig syncConfig=new TaskConfig(sync.getConfiguration());
  syncConfig.setDriver(MapDriver.class);
  syncConfig.setStubClass(EmptyMapStub.class);
  JobOutputVertex output=JobGraphUtils.createFileOutput(jobGraph,""String_Node_Str"",degreeOfParallelism);
  TaskConfig outputConfig=new TaskConfig(output.getConfiguration());
  outputConfig.setStubClass(PageWithRankOutFormat.class);
  outputConfig.setStubParameter(FileOutputFormat.FILE_PARAMETER_KEY,""String_Node_Str"");
  JobOutputVertex fakeTailOutput=JobGraphUtils.createFakeOutput(jobGraph,""String_Node_Str"",degreeOfParallelism);
  JobOutputVertex fakeSyncOutput=JobGraphUtils.createSingletonFakeOutput(jobGraph,""String_Node_Str"");
  JobGraphUtils.connectLocal(pageWithRankInput,head);
  JobGraphUtils.connectLocal(head,intermediate,DistributionPattern.BIPARTITE,ShipStrategy.BROADCAST);
  JobGraphUtils.connectLocal(transitionMatrixInput,intermediate,DistributionPattern.BIPARTITE,ShipStrategy.PARTITION_HASH);
  intermediateConfig.setGateIterativeWithNumberOfEventsUntilInterrupt(0,degreeOfParallelism);
  JobGraphUtils.connectLocal(intermediate,tail,DistributionPattern.POINTWISE,ShipStrategy.FORWARD);
  tailConfig.setGateIterativeWithNumberOfEventsUntilInterrupt(0,1);
  JobGraphUtils.connectLocal(head,sync);
  syncConfig.setGateIterativeWithNumberOfEventsUntilInterrupt(0,degreeOfParallelism);
  JobGraphUtils.connectLocal(head,output);
  JobGraphUtils.connectLocal(tail,fakeTailOutput);
  JobGraphUtils.connectLocal(sync,fakeSyncOutput);
  fakeTailOutput.setVertexToShareInstancesWith(tail);
  tail.setVertexToShareInstancesWith(head);
  pageWithRankInput.setVertexToShareInstancesWith(head);
  transitionMatrixInput.setVertexToShareInstancesWith(head);
  intermediate.setVertexToShareInstancesWith(head);
  output.setVertexToShareInstancesWith(head);
  sync.setVertexToShareInstancesWith(head);
  fakeSyncOutput.setVertexToShareInstancesWith(sync);
  GlobalConfiguration.loadConfiguration(""String_Node_Str"");
  Configuration conf=GlobalConfiguration.getConfiguration();
  JobGraphUtils.submit(jobGraph,conf);
}",0.9987824675324676
55380,"/** 
 * Creates a new block location
 * @param blockLocation the original HDFS block location
 */
public DistributedBlockLocation(org.apache.hadoop.fs.BlockLocation blockLocation){
  this.blockLocation=blockLocation;
}","/** 
 * Creates a new block location
 * @param blockLocation the original HDFS block location
 */
public DistributedBlockLocation(final org.apache.hadoop.fs.BlockLocation blockLocation){
  this.blockLocation=blockLocation;
}",0.986425339366516
55381,"@Override public long getOffset(){
  return blockLocation.getOffset();
}","/** 
 * {@inheritDoc}
 */
@Override public long getOffset(){
  return this.blockLocation.getOffset();
}",0.8228571428571428
55382,"@Override public long getLength(){
  return blockLocation.getLength();
}","/** 
 * {@inheritDoc}
 */
@Override public long getLength(){
  return this.blockLocation.getLength();
}",0.8228571428571428
55383,"@Override public int compareTo(BlockLocation o){
  long diff=getOffset() - o.getOffset();
  return diff < 0 ? -1 : diff > 0 ? 1 : 0;
}","/** 
 * {@inheritDoc}
 */
@Override public int compareTo(final BlockLocation o){
  final long diff=getOffset() - o.getOffset();
  return diff < 0 ? -1 : diff > 0 ? 1 : 0;
}",0.8758169934640523
55384,"@Override public String[] getHosts() throws IOException {
  return blockLocation.getHosts();
}","/** 
 * {@inheritDoc}
 */
@Override public String[] getHosts() throws IOException {
  if (this.hostnames == null) {
    final String[] hadoopHostnames=blockLocation.getHosts();
    this.hostnames=new String[hadoopHostnames.length];
    for (int i=0; i < hadoopHostnames.length; ++i) {
      this.hostnames[i]=stripHostname(hadoopHostnames[i]);
    }
  }
  return this.hostnames;
}",0.3713080168776371
55385,"public String toString(){
  if (this.indexes.size() == 0) {
    return ""String_Node_Str"";
  }
  final StringBuffer buf=new StringBuffer();
  for (int i=0; i < indexes.size(); i++) {
    if (buf.length() == 0) {
      buf.append(""String_Node_Str"");
    }
 else {
      buf.append(""String_Node_Str"");
    }
    buf.append(this.indexes.get(i));
    buf.append(""String_Node_Str"");
    buf.append(this.types.get(i).getName());
    buf.append(""String_Node_Str"");
    buf.append(this.orders.get(i).name());
  }
  buf.append(""String_Node_Str"");
  return buf.toString();
}","public String toString(){
  if (this.indexes.size() == 0) {
    return ""String_Node_Str"";
  }
  final StringBuffer buf=new StringBuffer();
  for (int i=0; i < indexes.size(); i++) {
    if (buf.length() == 0) {
      buf.append(""String_Node_Str"");
    }
 else {
      buf.append(""String_Node_Str"");
    }
    buf.append(this.indexes.get(i));
    if (this.types.get(i) != null) {
      buf.append(""String_Node_Str"");
      buf.append(this.types.get(i).getName());
    }
    buf.append(""String_Node_Str"");
    buf.append(this.orders.get(i).name());
  }
  buf.append(""String_Node_Str"");
  return buf.toString();
}",0.9599317988064792
55386,"@Override public void postVisit(OptimizerNode visitable){
  this.jsonString.append(""String_Node_Str"");
  this.jsonString.append(""String_Node_Str"" + this.nodeIds.get(visitable));
  String type;
switch (visitable.getPactType()) {
case DataSink:
    type=""String_Node_Str"";
  break;
case DataSource:
type=""String_Node_Str"";
break;
default :
type=""String_Node_Str"";
break;
}
this.jsonString.append(""String_Node_Str"" + type + ""String_Node_Str"");
String contents;
switch (visitable.getPactType()) {
case DataSink:
contents=visitable.getPactContract().toString();
break;
case DataSource:
contents=visitable.getPactContract().toString();
break;
default :
jsonString.append(""String_Node_Str"" + visitable.getName() + ""String_Node_Str"");
contents=visitable.getPactContract().getName();
break;
}
this.jsonString.append(""String_Node_Str"" + contents + ""String_Node_Str"");
this.jsonString.append(""String_Node_Str"" + (visitable.getDegreeOfParallelism() >= 1 ? visitable.getDegreeOfParallelism() : ""String_Node_Str"") + ""String_Node_Str"");
List<PactConnection> inConns=visitable.getIncomingConnections();
String child1name=""String_Node_Str"", child2name=""String_Node_Str"";
if (inConns != null && inConns.size() > 0) {
this.jsonString.append(""String_Node_Str"");
int connCnt=0;
for (PactConnection conn : inConns) {
this.jsonString.append(connCnt == 0 ? ""String_Node_Str"" : ""String_Node_Str"");
if (connCnt == 0) {
child1name+=child1name.length() > 0 ? ""String_Node_Str"" : ""String_Node_Str"";
child1name+=conn.getSourcePact().getPactContract().getName();
}
 else if (connCnt == 1) {
child2name+=child2name.length() > 0 ? ""String_Node_Str"" : ""String_Node_Str"";
child2name=conn.getSourcePact().getPactContract().getName();
}
this.jsonString.append(""String_Node_Str"" + this.nodeIds.get(conn.getSourcePact()));
if (inConns.size() == 2) {
this.jsonString.append(""String_Node_Str"" + (connCnt == 0 ? ""String_Node_Str"" : ""String_Node_Str"") + ""String_Node_Str"");
}
String shipStrategy=null;
String channelType=null;
switch (conn.getShipStrategy()) {
case NONE:
break;
case FORWARD:
shipStrategy=""String_Node_Str"";
channelType=""String_Node_Str"";
break;
case BROADCAST:
shipStrategy=""String_Node_Str"";
channelType=""String_Node_Str"";
break;
case PARTITION_HASH:
shipStrategy=""String_Node_Str"";
channelType=""String_Node_Str"";
break;
case PARTITION_RANGE:
shipStrategy=""String_Node_Str"";
channelType=""String_Node_Str"";
break;
case PARTITION_LOCAL_HASH:
shipStrategy=""String_Node_Str"";
channelType=""String_Node_Str"";
case SFR:
shipStrategy=""String_Node_Str"";
channelType=""String_Node_Str"";
break;
default :
throw new CompilerException(""String_Node_Str"" + conn.getShipStrategy().name() + ""String_Node_Str"");
}
if (shipStrategy != null) {
this.jsonString.append(""String_Node_Str"" + shipStrategy + ""String_Node_Str"");
}
if (channelType != null) {
this.jsonString.append(""String_Node_Str"" + channelType + ""String_Node_Str"");
}
if (conn.getTempMode() != TempMode.NONE) {
String tempMode=conn.getTempMode().toString();
this.jsonString.append(""String_Node_Str"" + tempMode + ""String_Node_Str"");
}
this.jsonString.append('}');
connCnt++;
}
this.jsonString.append(""String_Node_Str"");
}
String locString=null;
if (visitable.getLocalStrategy() != null) {
switch (visitable.getLocalStrategy()) {
case NONE:
break;
case HYBRIDHASH_FIRST:
locString=""String_Node_Str"" + child1name + ""String_Node_Str"";
break;
case HYBRIDHASH_SECOND:
locString=""String_Node_Str"" + child2name + ""String_Node_Str"";
break;
case MMHASH_FIRST:
locString=""String_Node_Str"" + child1name + ""String_Node_Str"";
break;
case MMHASH_SECOND:
locString=""String_Node_Str"" + child2name + ""String_Node_Str"";
break;
case NESTEDLOOP_BLOCKED_OUTER_FIRST:
locString=""String_Node_Str"" + child1name + ""String_Node_Str"";
break;
case NESTEDLOOP_BLOCKED_OUTER_SECOND:
locString=""String_Node_Str"" + child2name + ""String_Node_Str"";
break;
case NESTEDLOOP_STREAMED_OUTER_FIRST:
locString=""String_Node_Str"" + child1name + ""String_Node_Str"";
break;
case NESTEDLOOP_STREAMED_OUTER_SECOND:
locString=""String_Node_Str"" + child2name + ""String_Node_Str"";
break;
case SORT_BOTH_MERGE:
locString=""String_Node_Str"";
break;
case SORT_FIRST_MERGE:
locString=""String_Node_Str"";
break;
case SORT_SECOND_MERGE:
locString=""String_Node_Str"";
break;
case MERGE:
locString=""String_Node_Str"";
break;
case SORT:
locString=""String_Node_Str"";
break;
case COMBININGSORT:
locString=""String_Node_Str"";
break;
case SORT_SELF_NESTEDLOOP:
locString=""String_Node_Str"";
break;
case SELF_NESTEDLOOP:
locString=""String_Node_Str"";
break;
default :
throw new CompilerException(""String_Node_Str"" + visitable.getLocalStrategy().name() + ""String_Node_Str"");
}
if (locString != null) {
this.jsonString.append(""String_Node_Str"");
this.jsonString.append(locString);
this.jsonString.append(""String_Node_Str"");
}
}
{
GlobalProperties gp=visitable.getGlobalProperties();
this.jsonString.append(""String_Node_Str"");
addProperty(jsonString,""String_Node_Str"",gp.getPartitioning().name(),true);
if (gp.getPartitioning() != PartitionProperty.NONE) {
addProperty(jsonString,""String_Node_Str"",gp.getPartitionedFields().toString(),false);
}
if (gp.getOrdering() != null) {
addProperty(jsonString,""String_Node_Str"",gp.getOrdering().toString(),false);
}
 else {
addProperty(jsonString,""String_Node_Str"",""String_Node_Str"",false);
}
if (visitable.getUniqueFields() == null || visitable.getUniqueFields().size() == 0) {
addProperty(jsonString,""String_Node_Str"",""String_Node_Str"",false);
}
 else {
addProperty(jsonString,""String_Node_Str"",visitable.getUniqueFields().toString(),false);
}
this.jsonString.append(""String_Node_Str"");
}
{
LocalProperties lp=visitable.getLocalProperties();
this.jsonString.append(""String_Node_Str"");
if (lp.getOrdering() != null) {
addProperty(jsonString,""String_Node_Str"",lp.getOrdering().toString(),true);
}
 else {
addProperty(jsonString,""String_Node_Str"",""String_Node_Str"",true);
}
if (visitable.getUniqueFields() == null || visitable.getUniqueFields().size() == 0) {
addProperty(jsonString,""String_Node_Str"",""String_Node_Str"",false);
}
 else {
addProperty(jsonString,""String_Node_Str"",visitable.getUniqueFields().toString(),false);
}
addProperty(jsonString,""String_Node_Str"",lp.isGrouped() ? ""String_Node_Str"" : ""String_Node_Str"",false);
if (lp.isGrouped()) {
addProperty(jsonString,""String_Node_Str"",lp.getGroupedFields().toString(),false);
}
this.jsonString.append(""String_Node_Str"");
}
this.jsonString.append(""String_Node_Str"");
addProperty(this.jsonString,""String_Node_Str"",visitable.getEstimatedNumRecords() == -1 ? ""String_Node_Str"" : formatNumber(visitable.getEstimatedNumRecords()),true);
String estCardinality=""String_Node_Str"";
if (visitable.getEstimatedCardinalities().size() > 0) {
estCardinality=""String_Node_Str"";
for (Entry<FieldSet,Long> entry : visitable.getEstimatedCardinalities().entrySet()) {
estCardinality+=""String_Node_Str"" + entry.getKey().toString() + ""String_Node_Str""+ entry.getValue()+ ""String_Node_Str"";
}
}
addProperty(jsonString,""String_Node_Str"",estCardinality,false);
addProperty(jsonString,""String_Node_Str"",visitable.getEstimatedOutputSize() == -1 ? ""String_Node_Str"" : formatNumber(visitable.getEstimatedOutputSize(),""String_Node_Str""),false);
this.jsonString.append(""String_Node_Str"");
if (visitable.getNodeCosts() != null) {
this.jsonString.append(""String_Node_Str"");
addProperty(this.jsonString,""String_Node_Str"",visitable.getNodeCosts().getNetworkCost() == -1 ? ""String_Node_Str"" : formatNumber(visitable.getNodeCosts().getNetworkCost(),""String_Node_Str""),true);
addProperty(this.jsonString,""String_Node_Str"",visitable.getNodeCosts().getSecondaryStorageCost() == -1 ? ""String_Node_Str"" : formatNumber(visitable.getNodeCosts().getSecondaryStorageCost(),""String_Node_Str""),false);
addProperty(this.jsonString,""String_Node_Str"",visitable.getCumulativeCosts().getNetworkCost() == -1 ? ""String_Node_Str"" : formatNumber(visitable.getCumulativeCosts().getNetworkCost(),""String_Node_Str""),false);
addProperty(this.jsonString,""String_Node_Str"",visitable.getCumulativeCosts().getSecondaryStorageCost() == -1 ? ""String_Node_Str"" : formatNumber(visitable.getCumulativeCosts().getSecondaryStorageCost(),""String_Node_Str""),false);
this.jsonString.append(""String_Node_Str"");
}
if (visitable.getPactContract().getCompilerHints() != null) {
CompilerHints hints=visitable.getPactContract().getCompilerHints();
CompilerHints defaults=new CompilerHints();
this.jsonString.append(""String_Node_Str"");
String hintCardinality=""String_Node_Str"";
if (hints.getDistinctCounts().size() > 0) {
hintCardinality=""String_Node_Str"";
for (Entry<FieldSet,Long> entry : visitable.getEstimatedCardinalities().entrySet()) {
hintCardinality+=""String_Node_Str"" + entry.getKey().toString() + ""String_Node_Str""+ entry.getValue()+ ""String_Node_Str"";
}
}
addProperty(jsonString,""String_Node_Str"",hintCardinality,true);
addProperty(jsonString,""String_Node_Str"",hints.getAvgRecordsEmittedPerStubCall() == defaults.getAvgRecordsEmittedPerStubCall() ? ""String_Node_Str"" : String.valueOf(hints.getAvgRecordsEmittedPerStubCall()),false);
String valuesKey=""String_Node_Str"";
if (hints.getAvgNumRecordsPerDistinctFields().size() > 0) {
valuesKey=""String_Node_Str"";
for (Entry<FieldSet,Float> entry : hints.getAvgNumRecordsPerDistinctFields().entrySet()) {
valuesKey+=""String_Node_Str"" + entry.getKey().toString() + ""String_Node_Str""+ entry.getValue()+ ""String_Node_Str"";
}
}
addProperty(jsonString,""String_Node_Str"",valuesKey,false);
addProperty(jsonString,""String_Node_Str"",hints.getAvgBytesPerRecord() == defaults.getAvgBytesPerRecord() ? ""String_Node_Str"" : String.valueOf(hints.getAvgBytesPerRecord()),false);
this.jsonString.append(""String_Node_Str"");
}
this.jsonString.append(""String_Node_Str"");
}","@Override public void postVisit(OptimizerNode visitable){
  this.jsonString.append(""String_Node_Str"");
  this.jsonString.append(""String_Node_Str"" + this.nodeIds.get(visitable));
  String type;
switch (visitable.getPactType()) {
case DataSink:
    type=""String_Node_Str"";
  break;
case DataSource:
type=""String_Node_Str"";
break;
default :
type=""String_Node_Str"";
break;
}
this.jsonString.append(""String_Node_Str"" + type + ""String_Node_Str"");
String contents;
switch (visitable.getPactType()) {
case DataSink:
contents=visitable.getPactContract().toString();
break;
case DataSource:
contents=visitable.getPactContract().toString();
break;
default :
jsonString.append(""String_Node_Str"" + visitable.getName() + ""String_Node_Str"");
contents=visitable.getPactContract().getName();
break;
}
this.jsonString.append(""String_Node_Str"" + contents + ""String_Node_Str"");
this.jsonString.append(""String_Node_Str"" + (visitable.getDegreeOfParallelism() >= 1 ? visitable.getDegreeOfParallelism() : ""String_Node_Str"") + ""String_Node_Str"");
List<PactConnection> inConns=visitable.getIncomingConnections();
String child1name=""String_Node_Str"", child2name=""String_Node_Str"";
if (inConns != null && inConns.size() > 0) {
this.jsonString.append(""String_Node_Str"");
int connCnt=0;
for (PactConnection conn : inConns) {
this.jsonString.append(connCnt == 0 ? ""String_Node_Str"" : ""String_Node_Str"");
if (connCnt == 0) {
child1name+=child1name.length() > 0 ? ""String_Node_Str"" : ""String_Node_Str"";
child1name+=conn.getSourcePact().getPactContract().getName();
}
 else if (connCnt == 1) {
child2name+=child2name.length() > 0 ? ""String_Node_Str"" : ""String_Node_Str"";
child2name=conn.getSourcePact().getPactContract().getName();
}
this.jsonString.append(""String_Node_Str"" + this.nodeIds.get(conn.getSourcePact()));
if (inConns.size() == 2) {
this.jsonString.append(""String_Node_Str"" + (connCnt == 0 ? ""String_Node_Str"" : ""String_Node_Str"") + ""String_Node_Str"");
}
String shipStrategy=null;
String channelType=null;
switch (conn.getShipStrategy()) {
case NONE:
break;
case FORWARD:
shipStrategy=""String_Node_Str"";
channelType=""String_Node_Str"";
break;
case BROADCAST:
shipStrategy=""String_Node_Str"";
channelType=""String_Node_Str"";
break;
case PARTITION_HASH:
shipStrategy=""String_Node_Str"";
channelType=""String_Node_Str"";
break;
case PARTITION_RANGE:
shipStrategy=""String_Node_Str"";
channelType=""String_Node_Str"";
break;
case PARTITION_LOCAL_HASH:
shipStrategy=""String_Node_Str"";
channelType=""String_Node_Str"";
break;
case SFR:
shipStrategy=""String_Node_Str"";
channelType=""String_Node_Str"";
break;
default :
throw new CompilerException(""String_Node_Str"" + conn.getShipStrategy().name() + ""String_Node_Str"");
}
if (shipStrategy != null) {
this.jsonString.append(""String_Node_Str"" + shipStrategy + ""String_Node_Str"");
}
if (channelType != null) {
this.jsonString.append(""String_Node_Str"" + channelType + ""String_Node_Str"");
}
if (conn.getTempMode() != TempMode.NONE) {
String tempMode=conn.getTempMode().toString();
this.jsonString.append(""String_Node_Str"" + tempMode + ""String_Node_Str"");
}
this.jsonString.append('}');
connCnt++;
}
this.jsonString.append(""String_Node_Str"");
}
String locString=null;
if (visitable.getLocalStrategy() != null) {
switch (visitable.getLocalStrategy()) {
case NONE:
break;
case HYBRIDHASH_FIRST:
locString=""String_Node_Str"" + child1name + ""String_Node_Str"";
break;
case HYBRIDHASH_SECOND:
locString=""String_Node_Str"" + child2name + ""String_Node_Str"";
break;
case MMHASH_FIRST:
locString=""String_Node_Str"" + child1name + ""String_Node_Str"";
break;
case MMHASH_SECOND:
locString=""String_Node_Str"" + child2name + ""String_Node_Str"";
break;
case NESTEDLOOP_BLOCKED_OUTER_FIRST:
locString=""String_Node_Str"" + child1name + ""String_Node_Str"";
break;
case NESTEDLOOP_BLOCKED_OUTER_SECOND:
locString=""String_Node_Str"" + child2name + ""String_Node_Str"";
break;
case NESTEDLOOP_STREAMED_OUTER_FIRST:
locString=""String_Node_Str"" + child1name + ""String_Node_Str"";
break;
case NESTEDLOOP_STREAMED_OUTER_SECOND:
locString=""String_Node_Str"" + child2name + ""String_Node_Str"";
break;
case SORT_BOTH_MERGE:
locString=""String_Node_Str"";
break;
case SORT_FIRST_MERGE:
locString=""String_Node_Str"";
break;
case SORT_SECOND_MERGE:
locString=""String_Node_Str"";
break;
case MERGE:
locString=""String_Node_Str"";
break;
case SORT:
locString=""String_Node_Str"";
break;
case COMBININGSORT:
locString=""String_Node_Str"";
break;
case SORT_SELF_NESTEDLOOP:
locString=""String_Node_Str"";
break;
case SELF_NESTEDLOOP:
locString=""String_Node_Str"";
break;
default :
throw new CompilerException(""String_Node_Str"" + visitable.getLocalStrategy().name() + ""String_Node_Str"");
}
if (locString != null) {
this.jsonString.append(""String_Node_Str"");
this.jsonString.append(locString);
this.jsonString.append(""String_Node_Str"");
}
}
{
GlobalProperties gp=visitable.getGlobalProperties();
this.jsonString.append(""String_Node_Str"");
addProperty(jsonString,""String_Node_Str"",gp.getPartitioning().name(),true);
if (gp.getPartitioning() != PartitionProperty.NONE) {
addProperty(jsonString,""String_Node_Str"",gp.getPartitionedFields().toString(),false);
}
if (gp.getOrdering() != null) {
addProperty(jsonString,""String_Node_Str"",gp.getOrdering().toString(),false);
}
 else {
addProperty(jsonString,""String_Node_Str"",""String_Node_Str"",false);
}
if (visitable.getUniqueFields() == null || visitable.getUniqueFields().size() == 0) {
addProperty(jsonString,""String_Node_Str"",""String_Node_Str"",false);
}
 else {
addProperty(jsonString,""String_Node_Str"",visitable.getUniqueFields().toString(),false);
}
this.jsonString.append(""String_Node_Str"");
}
{
LocalProperties lp=visitable.getLocalProperties();
this.jsonString.append(""String_Node_Str"");
if (lp.getOrdering() != null) {
addProperty(jsonString,""String_Node_Str"",lp.getOrdering().toString(),true);
}
 else {
addProperty(jsonString,""String_Node_Str"",""String_Node_Str"",true);
}
if (visitable.getUniqueFields() == null || visitable.getUniqueFields().size() == 0) {
addProperty(jsonString,""String_Node_Str"",""String_Node_Str"",false);
}
 else {
addProperty(jsonString,""String_Node_Str"",visitable.getUniqueFields().toString(),false);
}
addProperty(jsonString,""String_Node_Str"",lp.isGrouped() ? ""String_Node_Str"" : ""String_Node_Str"",false);
if (lp.isGrouped()) {
addProperty(jsonString,""String_Node_Str"",lp.getGroupedFields().toString(),false);
}
this.jsonString.append(""String_Node_Str"");
}
this.jsonString.append(""String_Node_Str"");
addProperty(this.jsonString,""String_Node_Str"",visitable.getEstimatedNumRecords() == -1 ? ""String_Node_Str"" : formatNumber(visitable.getEstimatedNumRecords()),true);
String estCardinality=""String_Node_Str"";
if (visitable.getEstimatedCardinalities().size() > 0) {
estCardinality=""String_Node_Str"";
for (Entry<FieldSet,Long> entry : visitable.getEstimatedCardinalities().entrySet()) {
estCardinality+=""String_Node_Str"" + entry.getKey().toString() + ""String_Node_Str""+ entry.getValue()+ ""String_Node_Str"";
}
}
addProperty(jsonString,""String_Node_Str"",estCardinality,false);
addProperty(jsonString,""String_Node_Str"",visitable.getEstimatedOutputSize() == -1 ? ""String_Node_Str"" : formatNumber(visitable.getEstimatedOutputSize(),""String_Node_Str""),false);
this.jsonString.append(""String_Node_Str"");
if (visitable.getNodeCosts() != null) {
this.jsonString.append(""String_Node_Str"");
addProperty(this.jsonString,""String_Node_Str"",visitable.getNodeCosts().getNetworkCost() == -1 ? ""String_Node_Str"" : formatNumber(visitable.getNodeCosts().getNetworkCost(),""String_Node_Str""),true);
addProperty(this.jsonString,""String_Node_Str"",visitable.getNodeCosts().getSecondaryStorageCost() == -1 ? ""String_Node_Str"" : formatNumber(visitable.getNodeCosts().getSecondaryStorageCost(),""String_Node_Str""),false);
addProperty(this.jsonString,""String_Node_Str"",visitable.getCumulativeCosts().getNetworkCost() == -1 ? ""String_Node_Str"" : formatNumber(visitable.getCumulativeCosts().getNetworkCost(),""String_Node_Str""),false);
addProperty(this.jsonString,""String_Node_Str"",visitable.getCumulativeCosts().getSecondaryStorageCost() == -1 ? ""String_Node_Str"" : formatNumber(visitable.getCumulativeCosts().getSecondaryStorageCost(),""String_Node_Str""),false);
this.jsonString.append(""String_Node_Str"");
}
if (visitable.getPactContract().getCompilerHints() != null) {
CompilerHints hints=visitable.getPactContract().getCompilerHints();
CompilerHints defaults=new CompilerHints();
this.jsonString.append(""String_Node_Str"");
String hintCardinality=""String_Node_Str"";
if (hints.getDistinctCounts().size() > 0) {
hintCardinality=""String_Node_Str"";
for (Entry<FieldSet,Long> entry : visitable.getEstimatedCardinalities().entrySet()) {
hintCardinality+=""String_Node_Str"" + entry.getKey().toString() + ""String_Node_Str""+ entry.getValue()+ ""String_Node_Str"";
}
}
addProperty(jsonString,""String_Node_Str"",hintCardinality,true);
addProperty(jsonString,""String_Node_Str"",hints.getAvgRecordsEmittedPerStubCall() == defaults.getAvgRecordsEmittedPerStubCall() ? ""String_Node_Str"" : String.valueOf(hints.getAvgRecordsEmittedPerStubCall()),false);
String valuesKey=""String_Node_Str"";
if (hints.getAvgNumRecordsPerDistinctFields().size() > 0) {
valuesKey=""String_Node_Str"";
for (Entry<FieldSet,Float> entry : hints.getAvgNumRecordsPerDistinctFields().entrySet()) {
valuesKey+=""String_Node_Str"" + entry.getKey().toString() + ""String_Node_Str""+ entry.getValue()+ ""String_Node_Str"";
}
}
addProperty(jsonString,""String_Node_Str"",valuesKey,false);
addProperty(jsonString,""String_Node_Str"",hints.getAvgBytesPerRecord() == defaults.getAvgBytesPerRecord() ? ""String_Node_Str"" : String.valueOf(hints.getAvgBytesPerRecord()),false);
this.jsonString.append(""String_Node_Str"");
}
this.jsonString.append(""String_Node_Str"");
}",0.999637999689714
55387,"/** 
 * Checks if another thread requested the vertex to cancel while it was in state STARTING. If so, the method clears the respective flag and repeats the cancel request.
 */
private void checkCancelRequestedFlag(){
  if (this.cancelRequested.compareAndSet(true,false)) {
    final TaskCancelResult tsr=cancelTask();
    if (tsr.getReturnCode() != AbstractTaskResult.ReturnCode.SUCCESS || tsr.getReturnCode() != AbstractTaskResult.ReturnCode.TASK_NOT_FOUND) {
      LOG.error(""String_Node_Str"" + this + ""String_Node_Str""+ tsr.getReturnCode().toString()+ ((tsr.getDescription() != null) ? (""String_Node_Str"" + tsr.getDescription() + ""String_Node_Str"") : ""String_Node_Str""));
    }
  }
}","/** 
 * Checks if another thread requested the vertex to cancel while it was in state STARTING. If so, the method clears the respective flag and repeats the cancel request.
 */
private void checkCancelRequestedFlag(){
  if (this.cancelRequested.compareAndSet(true,false)) {
    final TaskCancelResult tsr=cancelTask();
    if (tsr.getReturnCode() != AbstractTaskResult.ReturnCode.SUCCESS && tsr.getReturnCode() != AbstractTaskResult.ReturnCode.TASK_NOT_FOUND) {
      LOG.error(""String_Node_Str"" + this + ""String_Node_Str""+ tsr.getReturnCode().toString()+ ((tsr.getDescription() != null) ? (""String_Node_Str"" + tsr.getDescription() + ""String_Node_Str"") : ""String_Node_Str""));
    }
  }
}",0.9970887918486172
55388,"/** 
 * {@inheritDoc}
 */
@Override public void setCompressedDataBuffer(Buffer buffer){
  if (buffer == null) {
    this.compressedBuffer=null;
    this.compressedDataBuffer=null;
    this.compressedDataBufferLength=0;
  }
 else {
    this.compressedDataBuffer=getInternalByteBuffer(buffer);
    this.compressedBuffer=buffer;
    this.compressedDataBufferLength=bufferToInt(this.compressedDataBuffer,0);
    this.uncompressedDataBufferLength=bufferToInt(this.compressedDataBuffer,4);
  }
}","/** 
 * {@inheritDoc}
 */
@Override public void setCompressedDataBuffer(final MemoryBuffer buffer){
  if (buffer == null) {
    this.compressedBuffer=null;
    this.compressedDataBuffer=null;
    this.compressedDataBufferLength=0;
  }
 else {
    this.compressedDataBuffer=buffer.getByteBuffer();
    this.compressedBuffer=buffer;
    this.compressedDataBufferLength=bufferToInt(this.compressedDataBuffer,0);
    this.uncompressedDataBufferLength=bufferToInt(this.compressedDataBuffer,4);
  }
}",0.9664292980671414
55389,"/** 
 * Collects all vertices with checkpoints from the given execution graph and advices the corresponding task managers to remove those checkpoints.
 * @param executionGraph the execution graph from which the checkpoints shall be removed
 */
private void removeAllCheckpoints(final ExecutionGraph executionGraph){
  final Map<AbstractInstance,SerializableArrayList<ExecutionVertexID>> instanceMap=new HashMap<AbstractInstance,SerializableArrayList<ExecutionVertexID>>();
  final Iterator<ExecutionVertex> it=new ExecutionGraphIterator(executionGraph,true);
  while (it.hasNext()) {
    final ExecutionVertex vertex=it.next();
    final AllocatedResource allocatedResource=vertex.getAllocatedResource();
    if (allocatedResource == null) {
      continue;
    }
    final AbstractInstance abstractInstance=allocatedResource.getInstance();
    if (abstractInstance == null) {
      continue;
    }
    SerializableArrayList<ExecutionVertexID> vertexIDs=instanceMap.get(abstractInstance);
    if (vertexIDs == null) {
      vertexIDs=new SerializableArrayList<ExecutionVertexID>();
      instanceMap.put(abstractInstance,vertexIDs);
    }
    vertexIDs.add(vertex.getID());
  }
  final Iterator<Map.Entry<AbstractInstance,SerializableArrayList<ExecutionVertexID>>> it2=instanceMap.entrySet().iterator();
  while (it2.hasNext()) {
    final Map.Entry<AbstractInstance,SerializableArrayList<ExecutionVertexID>> entry=it2.next();
    final AbstractInstance abstractInstance=entry.getKey();
    if (abstractInstance == null) {
      LOG.error(""String_Node_Str"");
      continue;
    }
    final Runnable runnable=new Runnable(){
      @Override public void run(){
        try {
          abstractInstance.removeCheckpoints(entry.getValue());
        }
 catch (        IOException ioe) {
          LOG.error(StringUtils.stringifyException(ioe));
        }
      }
    }
;
    this.executorService.execute(runnable);
  }
}","/** 
 * Collects all vertices with checkpoints from the given execution graph and advices the corresponding task managers to remove those checkpoints.
 * @param executionGraph the execution graph from which the checkpoints shall be removed
 */
private void removeAllCheckpoints(final ExecutionGraph executionGraph){
  final Map<AbstractInstance,SerializableArrayList<ExecutionVertexID>> instanceMap=new HashMap<AbstractInstance,SerializableArrayList<ExecutionVertexID>>();
  final Iterator<ExecutionVertex> it=new ExecutionGraphIterator(executionGraph,true);
  while (it.hasNext()) {
    final ExecutionVertex vertex=it.next();
    final AllocatedResource allocatedResource=vertex.getAllocatedResource();
    if (allocatedResource == null) {
      continue;
    }
    final AbstractInstance abstractInstance=allocatedResource.getInstance();
    if (abstractInstance == null) {
      continue;
    }
    SerializableArrayList<ExecutionVertexID> vertexIDs=instanceMap.get(abstractInstance);
    if (vertexIDs == null) {
      vertexIDs=new SerializableArrayList<ExecutionVertexID>();
      instanceMap.put(abstractInstance,vertexIDs);
    }
    vertexIDs.add(vertex.getID());
  }
  final Iterator<Map.Entry<AbstractInstance,SerializableArrayList<ExecutionVertexID>>> it2=instanceMap.entrySet().iterator();
  while (it2.hasNext()) {
    final Map.Entry<AbstractInstance,SerializableArrayList<ExecutionVertexID>> entry=it2.next();
    final AbstractInstance abstractInstance=entry.getKey();
    if (abstractInstance == null) {
      LOG.error(""String_Node_Str"");
      continue;
    }
    if (abstractInstance instanceof DummyInstance) {
      continue;
    }
    final Runnable runnable=new Runnable(){
      @Override public void run(){
        try {
          abstractInstance.removeCheckpoints(entry.getValue());
        }
 catch (        IOException ioe) {
          LOG.error(StringUtils.stringifyException(ioe));
        }
      }
    }
;
    this.executorService.execute(runnable);
  }
}",0.9808036856923472
55390,"/** 
 * Creates a copy of the given   {@link IOReadableWritable} object by an in-memory serialization and subsequentdeserialization.
 * @param original the original object to be copied
 * @return the copy of original object created by the original object's serialization/deserialization methods
 * @throws IOException thrown if an error occurs while creating the copy of the object
 */
@SuppressWarnings(""String_Node_Str"") public static IOReadableWritable createCopy(IOReadableWritable original) throws IOException {
  final ByteArrayOutputStream baos=new ByteArrayOutputStream();
  final DataOutputStream dos=new DataOutputStream(baos);
  original.write(dos);
  final String className=original.getClass().getName();
  if (className == null) {
    fail(""String_Node_Str"");
  }
  Class<? extends IOReadableWritable> clazz=null;
  try {
    clazz=(Class<? extends IOReadableWritable>)Class.forName(className);
  }
 catch (  ClassNotFoundException e) {
    fail(e.getMessage());
  }
  if (clazz == null) {
    fail(""String_Node_Str"" + className);
  }
  IOReadableWritable copy=null;
  try {
    copy=clazz.newInstance();
  }
 catch (  InstantiationException e) {
    fail(e.getMessage());
  }
catch (  IllegalAccessException e) {
    fail(e.getMessage());
  }
  if (copy == null) {
    fail(""String_Node_Str"" + className + ""String_Node_Str"");
  }
  final ByteArrayInputStream bais=new ByteArrayInputStream(baos.toByteArray());
  final DataInputStream dis=new DataInputStream(bais);
  copy.read(dis);
  return copy;
}","/** 
 * Creates a copy of the given   {@link IOReadableWritable} object by an in-memory serialization and subsequentdeserialization.
 * @param original the original object to be copied
 * @return the copy of original object created by the original object's serialization/deserialization methods
 * @throws IOException thrown if an error occurs while creating the copy of the object
 */
@SuppressWarnings(""String_Node_Str"") public static <T extends IOReadableWritable>T createCopy(final T original) throws IOException {
  final ByteArrayOutputStream baos=new ByteArrayOutputStream();
  final DataOutputStream dos=new DataOutputStream(baos);
  original.write(dos);
  final String className=original.getClass().getName();
  if (className == null) {
    fail(""String_Node_Str"");
  }
  Class<T> clazz=null;
  try {
    clazz=(Class<T>)Class.forName(className);
  }
 catch (  ClassNotFoundException e) {
    fail(e.getMessage());
  }
  if (clazz == null) {
    fail(""String_Node_Str"" + className);
  }
  T copy=null;
  try {
    copy=clazz.newInstance();
  }
 catch (  InstantiationException e) {
    fail(e.getMessage());
  }
catch (  IllegalAccessException e) {
    fail(e.getMessage());
  }
  if (copy == null) {
    fail(""String_Node_Str"" + className + ""String_Node_Str"");
  }
  final ByteArrayInputStream bais=new ByteArrayInputStream(baos.toByteArray());
  final DataInputStream dis=new DataInputStream(bais);
  copy.read(dis);
  return copy;
}",0.9611092323300644
55391,"/** 
 * Unregisters the   {@link ExecutionListener} object for this vertex. This objectwill no longer be notified about particular events during the vertex's lifetime.
 * @param checkpointStateChangeListener the object to be unregistered
 */
public void unregisterExecutionListener(final ExecutionListener executionListener){
  this.executionListeners.remove(executionListener);
}","/** 
 * Unregisters the   {@link ExecutionListener} object for this vertex. This objectwill no longer be notified about particular events during the vertex's lifetime.
 * @param checkpointStateChangeListener the object to be unregistered
 */
public void unregisterExecutionListener(final ExecutionListener executionListener){
  this.executionListeners.remove(Integer.valueOf(executionListener.getPriority()));
}",0.9178255372945638
55392,"/** 
 * Cancels and removes the task represented by this vertex from the instance it is currently running on. If the task is not currently running, its execution state is simply updated to <code>CANCELLED</code>.
 * @return the result of the task cancel attempt
 */
public TaskCancelResult cancelTask(){
  while (true) {
    final ExecutionState previousState=this.executionState.get();
    if (previousState == ExecutionState.CANCELED) {
      return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
    }
    if (previousState == ExecutionState.FAILED) {
      return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
    }
    if (previousState == ExecutionState.FINISHED) {
      return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
    }
    if (previousState == ExecutionState.CANCELING) {
      return new TaskCancelResult(getID(),ReturnCode.SUCCESS);
    }
    if (previousState == ExecutionState.STARTING) {
      int retry=2000;
      while (this.executionState.get() == ExecutionState.STARTING) {
        if (--retry == 0) {
          return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.ILLEGAL_STATE);
        }
        try {
          Thread.sleep(1);
        }
 catch (        InterruptedException ie) {
          return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.ILLEGAL_STATE);
        }
      }
      continue;
    }
    if (compareAndUpdateExecutionState(previousState,ExecutionState.CANCELING)) {
      if (this.groupVertex.getStageNumber() != this.executionGraph.getIndexOfCurrentExecutionStage()) {
        updateExecutionState(ExecutionState.CANCELED,null);
        return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
      }
      if (previousState != ExecutionState.RUNNING && previousState != ExecutionState.FINISHING && previousState != ExecutionState.REPLAYING) {
        updateExecutionState(ExecutionState.CANCELED,null);
        return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
      }
      if (this.allocatedResource == null) {
        final TaskCancelResult result=new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.NO_INSTANCE);
        result.setDescription(""String_Node_Str"" + this.toString() + ""String_Node_Str"");
        return result;
      }
      try {
        return this.allocatedResource.getInstance().cancelTask(this.vertexID);
      }
 catch (      IOException e) {
        final TaskCancelResult result=new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.IPC_ERROR);
        result.setDescription(StringUtils.stringifyException(e));
        return result;
      }
    }
  }
}","/** 
 * Cancels and removes the task represented by this vertex from the instance it is currently running on. If the task is not currently running, its execution state is simply updated to <code>CANCELLED</code>.
 * @return the result of the task cancel attempt
 */
public TaskCancelResult cancelTask(){
  while (true) {
    final ExecutionState previousState=this.executionState.get();
    if (previousState == ExecutionState.CANCELED) {
      return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
    }
    if (previousState == ExecutionState.FAILED) {
      return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
    }
    if (previousState == ExecutionState.FINISHED) {
      return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
    }
    if (previousState == ExecutionState.CANCELING) {
      return new TaskCancelResult(getID(),ReturnCode.SUCCESS);
    }
    if (previousState == ExecutionState.STARTING) {
      this.cancelRequested.set(true);
      if (this.executionState.get() != ExecutionState.STARTING) {
        this.cancelRequested.set(false);
        continue;
      }
      return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
    }
    if (compareAndUpdateExecutionState(previousState,ExecutionState.CANCELING)) {
      if (this.groupVertex.getStageNumber() != this.executionGraph.getIndexOfCurrentExecutionStage()) {
        updateExecutionState(ExecutionState.CANCELED,null);
        return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
      }
      if (previousState != ExecutionState.RUNNING && previousState != ExecutionState.FINISHING && previousState != ExecutionState.REPLAYING) {
        updateExecutionState(ExecutionState.CANCELED,null);
        return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
      }
      if (this.allocatedResource == null) {
        final TaskCancelResult result=new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.NO_INSTANCE);
        result.setDescription(""String_Node_Str"" + this.toString() + ""String_Node_Str"");
        return result;
      }
      try {
        return this.allocatedResource.getInstance().cancelTask(this.vertexID);
      }
 catch (      IOException e) {
        final TaskCancelResult result=new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.IPC_ERROR);
        result.setDescription(StringUtils.stringifyException(e));
        return result;
      }
    }
  }
}",0.9242072699149264
55393,"public boolean compareAndUpdateExecutionState(final ExecutionState expected,final ExecutionState update){
  if (update == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (!this.executionState.compareAndSet(expected,update)) {
    return false;
  }
  ExecutionStateTransition.checkTransition(true,toString(),expected,update);
  final Iterator<ExecutionListener> it=this.executionListeners.values().iterator();
  while (it.hasNext()) {
    it.next().executionStateChanged(this.executionGraph.getJobID(),this.vertexID,update,null);
  }
  return true;
}","public boolean compareAndUpdateExecutionState(final ExecutionState expected,final ExecutionState update){
  if (update == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (!this.executionState.compareAndSet(expected,update)) {
    return false;
  }
  ExecutionStateTransition.checkTransition(true,toString(),expected,update);
  final Iterator<ExecutionListener> it=this.executionListeners.values().iterator();
  while (it.hasNext()) {
    it.next().executionStateChanged(this.executionGraph.getJobID(),this.vertexID,update,null);
  }
  checkCancelRequestedFlag();
  return true;
}",0.956081081081081
55394,"/** 
 * Updates the vertex's current execution state.
 * @param newExecutionState the new execution state
 * @param optionalMessage an optional message related to the state change
 */
public ExecutionState updateExecutionState(ExecutionState newExecutionState,final String optionalMessage){
  if (newExecutionState == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  final ExecutionState currentExecutionState=this.executionState.get();
  if (currentExecutionState == ExecutionState.CANCELING) {
    if (newExecutionState == ExecutionState.FINISHING) {
      return currentExecutionState;
    }
    if (newExecutionState == ExecutionState.FINISHED) {
      LOG.info(""String_Node_Str"" + toString() + ""String_Node_Str"");
      newExecutionState=ExecutionState.CANCELED;
    }
  }
  final ExecutionState previousState=this.executionState.getAndSet(newExecutionState);
  if (previousState == newExecutionState) {
    return previousState;
  }
  ExecutionStateTransition.checkTransition(true,toString(),previousState,newExecutionState);
  final Iterator<ExecutionListener> it=this.executionListeners.values().iterator();
  while (it.hasNext()) {
    it.next().executionStateChanged(this.executionGraph.getJobID(),this.vertexID,newExecutionState,optionalMessage);
  }
  return previousState;
}","/** 
 * Updates the vertex's current execution state.
 * @param newExecutionState the new execution state
 * @param optionalMessage an optional message related to the state change
 */
public ExecutionState updateExecutionState(ExecutionState newExecutionState,final String optionalMessage){
  if (newExecutionState == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  final ExecutionState currentExecutionState=this.executionState.get();
  if (currentExecutionState == ExecutionState.CANCELING) {
    if (newExecutionState == ExecutionState.FINISHING) {
      return currentExecutionState;
    }
    if (newExecutionState == ExecutionState.FINISHED) {
      LOG.info(""String_Node_Str"" + toString() + ""String_Node_Str"");
      newExecutionState=ExecutionState.CANCELED;
    }
  }
  final ExecutionState previousState=this.executionState.getAndSet(newExecutionState);
  if (previousState == newExecutionState) {
    return previousState;
  }
  ExecutionStateTransition.checkTransition(true,toString(),previousState,newExecutionState);
  final Iterator<ExecutionListener> it=this.executionListeners.values().iterator();
  while (it.hasNext()) {
    it.next().executionStateChanged(this.executionGraph.getJobID(),this.vertexID,newExecutionState,optionalMessage);
  }
  checkCancelRequestedFlag();
  return previousState;
}",0.98868778280543
55395,"public boolean readRecord(PactRecord target,byte[] bytes,int offset,int numBytes){
  PactString str=this.theString;
  if (this.ascii) {
    str.setValueAscii(bytes,offset,numBytes);
  }
 else {
    ByteBuffer byteWrapper=this.byteWrapper;
    if (bytes != byteWrapper.array()) {
      byteWrapper=ByteBuffer.wrap(bytes,0,bytes.length);
      this.byteWrapper=byteWrapper;
    }
    byteWrapper.position(offset);
    byteWrapper.limit(numBytes);
    try {
      CharBuffer result=this.decoder.decode(byteWrapper);
      str.setValue(result);
    }
 catch (    CharacterCodingException e) {
      byte[] copy=new byte[numBytes];
      System.arraycopy(bytes,offset,copy,0,numBytes);
      LOG.warn(""String_Node_Str"" + Arrays.toString(copy),e);
      return false;
    }
  }
  target.clear();
  target.addField(str);
  return true;
}","public boolean readRecord(PactRecord target,byte[] bytes,int offset,int numBytes){
  PactString str=this.theString;
  if (this.ascii) {
    str.setValueAscii(bytes,offset,numBytes);
  }
 else {
    ByteBuffer byteWrapper=this.byteWrapper;
    if (bytes != byteWrapper.array()) {
      byteWrapper=ByteBuffer.wrap(bytes,0,bytes.length);
      this.byteWrapper=byteWrapper;
    }
    byteWrapper.clear();
    byteWrapper.position(offset);
    byteWrapper.limit(offset + numBytes);
    try {
      CharBuffer result=this.decoder.decode(byteWrapper);
      str.setValue(result);
    }
 catch (    CharacterCodingException e) {
      byte[] copy=new byte[numBytes];
      System.arraycopy(bytes,offset,copy,0,numBytes);
      LOG.warn(""String_Node_Str"" + Arrays.toString(copy),e);
      return false;
    }
  }
  target.clear();
  target.addField(str);
  return true;
}",0.9799291617473436
55396,"/** 
 * Gets the type of the input splits that are processed by this input format.
 * @return The type of the input splits.
 */
public Class<T> getInputSplitType();","/** 
 * Gets the type of the input splits that are processed by this input format.
 * @return The type of the input splits.
 */
public Class<? extends T> getInputSplitType();",0.970414201183432
55397,"@Override public Class<GenericInputSplit> getInputSplitType(){
  return GenericInputSplit.class;
}","@Override public Class<? extends GenericInputSplit> getInputSplitType(){
  return GenericInputSplit.class;
}",0.9514563106796116
55398,"@Override public Class<InputSplit> getInputSplitType(){
  if (this.format == null) {
    throw new IllegalStateException(""String_Node_Str"");
  }
  return (Class<InputSplit>)this.format.getInputSplitType();
}","@SuppressWarnings(""String_Node_Str"") @Override public Class<InputSplit> getInputSplitType(){
  if (this.format == null) {
    throw new IllegalStateException(""String_Node_Str"");
  }
  return (Class<InputSplit>)this.format.getInputSplitType();
}",0.917960088691796
55399,"/** 
 * Cancels and removes the task represented by this vertex from the instance it is currently running on. If the task is not currently running, its execution state is simply updated to <code>CANCELLED</code>.
 * @return the result of the task cancel attempt
 */
public TaskCancelResult cancelTask(){
  final ExecutionState previousState=this.executionState.get();
  if (previousState == ExecutionState.CANCELED) {
    return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
  }
  if (previousState == ExecutionState.FAILED) {
    return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
  }
  if (previousState == ExecutionState.FINISHED) {
    return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
  }
  if (updateExecutionState(ExecutionState.CANCELING) != ExecutionState.CANCELING) {
    if (this.groupVertex.getStageNumber() != this.executionGraph.getIndexOfCurrentExecutionStage()) {
      updateExecutionState(ExecutionState.CANCELED,null);
      return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
    }
    if (previousState == ExecutionState.FINISHED || previousState == ExecutionState.FAILED) {
      return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
    }
    if (previousState != ExecutionState.RUNNING && previousState != ExecutionState.STARTING && previousState != ExecutionState.FINISHING && previousState != ExecutionState.REPLAYING) {
      updateExecutionState(ExecutionState.CANCELED,null);
      return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
    }
    if (this.allocatedResource == null) {
      final TaskCancelResult result=new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.NO_INSTANCE);
      result.setDescription(""String_Node_Str"" + this.toString() + ""String_Node_Str"");
      return result;
    }
    try {
      return this.allocatedResource.getInstance().cancelTask(this.vertexID);
    }
 catch (    IOException e) {
      final TaskCancelResult result=new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.IPC_ERROR);
      result.setDescription(StringUtils.stringifyException(e));
      return result;
    }
  }
  return new TaskCancelResult(getID(),ReturnCode.SUCCESS);
}","/** 
 * Cancels and removes the task represented by this vertex from the instance it is currently running on. If the task is not currently running, its execution state is simply updated to <code>CANCELLED</code>.
 * @return the result of the task cancel attempt
 */
public TaskCancelResult cancelTask(){
  ExecutionState previousState=this.executionState.get();
  int retry=1000;
  while (previousState == ExecutionState.STARTING) {
    if (--retry == 0) {
      return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.ILLEGAL_STATE);
    }
    try {
      Thread.sleep(1);
    }
 catch (    InterruptedException ie) {
      return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.ILLEGAL_STATE);
    }
    previousState=this.executionState.get();
  }
  if (previousState == ExecutionState.CANCELED) {
    return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
  }
  if (previousState == ExecutionState.FAILED) {
    return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
  }
  if (previousState == ExecutionState.FINISHED) {
    return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
  }
  if (updateExecutionState(ExecutionState.CANCELING) != ExecutionState.CANCELING) {
    if (this.groupVertex.getStageNumber() != this.executionGraph.getIndexOfCurrentExecutionStage()) {
      updateExecutionState(ExecutionState.CANCELED,null);
      return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
    }
    if (previousState == ExecutionState.FINISHED || previousState == ExecutionState.FAILED) {
      return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
    }
    if (previousState != ExecutionState.RUNNING && previousState != ExecutionState.STARTING && previousState != ExecutionState.FINISHING && previousState != ExecutionState.REPLAYING) {
      updateExecutionState(ExecutionState.CANCELED,null);
      return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
    }
    if (this.allocatedResource == null) {
      final TaskCancelResult result=new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.NO_INSTANCE);
      result.setDescription(""String_Node_Str"" + this.toString() + ""String_Node_Str"");
      return result;
    }
    try {
      return this.allocatedResource.getInstance().cancelTask(this.vertexID);
    }
 catch (    IOException e) {
      final TaskCancelResult result=new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.IPC_ERROR);
      result.setDescription(StringUtils.stringifyException(e));
      return result;
    }
  }
  return new TaskCancelResult(getID(),ReturnCode.SUCCESS);
}",0.9102720259845716
55400,"/** 
 * Copy constructor to create a copy of a node with a different predecessor. The predecessor is assumed to be of the same type and merely a copy with different strategies, as they are created in the process of the plan enumeration.
 * @param template The node to create a copy of.
 * @param predNode The new predecessor.
 * @param inConn The old connection to copy properties from.
 * @param globalProps The global properties of this copy.
 * @param localProps The local properties of this copy.
 */
protected SingleInputNode(SingleInputNode template,OptimizerNode predNode,PactConnection inConn,GlobalProperties globalProps,LocalProperties localProps){
  super(template,globalProps,localProps);
  this.constantSet=template.constantSet;
  this.keyList=template.keyList;
  this.inConn=new PactConnection(inConn,predNode,this);
  if (predNode.branchPlan != null && predNode.branchPlan.size() > 0) {
    this.branchPlan=new HashMap<OptimizerNode,OptimizerNode>(predNode.branchPlan);
  }
 else {
    this.branchPlan=null;
  }
}","/** 
 * Copy constructor to create a copy of a node with a different predecessor. The predecessor is assumed to be of the same type and merely a copy with different strategies, as they are created in the process of the plan enumeration.
 * @param template The node to create a copy of.
 * @param predNode The new predecessor.
 * @param inConn The old connection to copy properties from.
 * @param globalProps The global properties of this copy.
 * @param localProps The local properties of this copy.
 */
protected SingleInputNode(SingleInputNode template,OptimizerNode predNode,PactConnection inConn,GlobalProperties globalProps,LocalProperties localProps){
  super(template,globalProps,localProps);
  this.constantSet=template.constantSet;
  this.keyList=template.keyList;
  this.inConn=new PactConnection(inConn,predNode,this);
  if (this.branchPlan == null) {
    this.branchPlan=predNode.branchPlan;
  }
 else   if (predNode.branchPlan != null) {
    this.branchPlan.putAll(predNode.branchPlan);
  }
}",0.8997050147492626
55401,"@Override public void invoke() throws Exception {
  if (LOG.isInfoEnabled())   LOG.info(getLogString(""String_Node_Str""));
  boolean stubOpen=false;
  this.running=true;
  try {
    try {
      prepare();
    }
 catch (    Throwable t) {
      throw new Exception(""String_Node_Str"" + this.getEnvironment().getTaskName() + ""String_Node_Str""+ t.getMessage(),t);
    }
    AbstractPactTask.openChainedTasks(this.chainedTasks,this);
    try {
      Configuration stubConfig=this.config.getStubParameters();
      stubConfig.setInteger(""String_Node_Str"",this.getEnvironment().getIndexInSubtaskGroup());
      stubConfig.setInteger(""String_Node_Str"",this.getEnvironment().getCurrentNumberOfSubtasks());
      if (this.getEnvironment().getTaskName() != null) {
        stubConfig.setString(""String_Node_Str"",this.getEnvironment().getTaskName());
      }
      this.stub.open(stubConfig);
      stubOpen=true;
    }
 catch (    Throwable t) {
      throw new Exception(""String_Node_Str"" + t.getMessage(),t);
    }
    run();
    if (this.running) {
      this.stub.close();
      stubOpen=false;
    }
    this.output.close();
    AbstractPactTask.closeChainedTasks(this.chainedTasks,this);
  }
 catch (  Exception ex) {
    if (stubOpen) {
      try {
        this.stub.close();
      }
 catch (      Throwable t) {
      }
    }
    AbstractPactTask.cancelChainedTasks(this.chainedTasks);
    if (this.running) {
      AbstractPactTask.logAndThrowException(ex,this);
    }
  }
 finally {
    cleanup();
  }
  if (this.running) {
    if (LOG.isInfoEnabled())     LOG.info(getLogString(""String_Node_Str""));
  }
 else {
    if (LOG.isWarnEnabled())     LOG.warn(getLogString(""String_Node_Str""));
  }
}","@Override public void invoke() throws Exception {
  if (LOG.isInfoEnabled())   LOG.info(getLogString(""String_Node_Str""));
  boolean stubOpen=false;
  this.running=true;
  try {
    try {
      prepare();
    }
 catch (    Throwable t) {
      throw new Exception(""String_Node_Str"" + this.getEnvironment().getTaskName() + ""String_Node_Str""+ t.getMessage(),t);
    }
    if (!this.running) {
      return;
    }
    AbstractPactTask.openChainedTasks(this.chainedTasks,this);
    try {
      Configuration stubConfig=this.config.getStubParameters();
      stubConfig.setInteger(""String_Node_Str"",this.getEnvironment().getIndexInSubtaskGroup());
      stubConfig.setInteger(""String_Node_Str"",this.getEnvironment().getCurrentNumberOfSubtasks());
      if (this.getEnvironment().getTaskName() != null) {
        stubConfig.setString(""String_Node_Str"",this.getEnvironment().getTaskName());
      }
      this.stub.open(stubConfig);
      stubOpen=true;
    }
 catch (    Throwable t) {
      throw new Exception(""String_Node_Str"" + t.getMessage(),t);
    }
    run();
    if (this.running) {
      this.stub.close();
      stubOpen=false;
    }
    this.output.close();
    AbstractPactTask.closeChainedTasks(this.chainedTasks,this);
  }
 catch (  Exception ex) {
    if (stubOpen) {
      try {
        this.stub.close();
      }
 catch (      Throwable t) {
      }
    }
    AbstractPactTask.cancelChainedTasks(this.chainedTasks);
    if (this.running) {
      AbstractPactTask.logAndThrowException(ex,this);
    }
  }
 finally {
    cleanup();
  }
  if (this.running) {
    if (LOG.isInfoEnabled())     LOG.info(getLogString(""String_Node_Str""));
  }
 else {
    if (LOG.isWarnEnabled())     LOG.warn(getLogString(""String_Node_Str""));
  }
}",0.9868689816165742
55402,"@Override public void closeTask() throws Exception {
  while (!canceled && this.combinerThread.isAlive()) {
    try {
      this.combinerThread.join();
    }
 catch (    InterruptedException iex) {
    }
  }
  if (this.exception != null) {
    throw new ExceptionInChainedStubException(this.taskName,this.exception);
  }
  if (this.parent != null && this.combinerThread != null) {
    this.parent.userThreadFinished(this.combinerThread);
  }
  this.sorter.close();
  if (this.canceled)   return;
  AbstractPactTask.closeUserCode(this.combiner);
}","@Override public void closeTask() throws Exception {
  while (!this.canceled && this.combinerThread.isAlive()) {
    try {
      this.combinerThread.join();
    }
 catch (    InterruptedException iex) {
      cancelTask();
      throw iex;
    }
  }
  if (this.parent != null && this.combinerThread != null) {
    this.parent.userThreadFinished(this.combinerThread);
  }
  if (this.exception != null) {
    throw new ExceptionInChainedStubException(this.taskName,this.exception);
  }
  this.sorter.close();
  if (this.canceled)   return;
  AbstractPactTask.closeUserCode(this.combiner);
}",0.5943562610229277
55403,"@Override public void cancelTask(){
  this.canceled=true;
  this.exception=new Exception(""String_Node_Str"");
  this.combinerThread.cancel();
  this.inputCollector.close();
  this.sorter.close();
}","@Override public void cancelTask(){
  this.canceled=true;
  this.exception=new Exception(""String_Node_Str"");
  this.combinerThread.cancel();
  this.inputCollector.close();
  this.sorter.close();
  try {
    this.combinerThread.join();
  }
 catch (  InterruptedException iex) {
  }
 finally {
    if (this.parent != null && this.combinerThread != null) {
      this.parent.userThreadFinished(this.combinerThread);
    }
  }
}",0.632258064516129
55404,"/** 
 * Reads all stub annotations
 */
private void readStubAnnotations(){
  this.readConstantAnnotation();
  this.readUniqueFieldsAnnotation();
}","/** 
 * Reads all stub annotations
 */
private void readStubAnnotations(){
  this.readConstantAnnotation();
  this.readOutputCardBoundAnnotation();
  this.readUniqueFieldsAnnotation();
}",0.8795180722891566
55405,"/** 
 * Creates an instance that wraps the plan defined in the jar file using the given arguments. For generating the plan the class defined in the className parameter is used.
 * @param jarFile The jar file which contains the plan.
 * @param className Name of the class which generates the plan. Overrides the class defined in the jar file manifest
 * @param args Optional. The arguments used to create the pact plan, depend on implementation of the pact plan. See getDescription().
 * @throws ProgramInvocationException This invocation is thrown if the PlanAssembler can't be properly loaded. Causes may be a missing / wrong class or manifest files.
 */
public PactProgram(File jarFile,String className,String... args) throws ProgramInvocationException {
  this.jarFile=jarFile;
  this.args=args;
  this.assemblerClass=getPactAssemblerFromJar(jarFile,className);
}","/** 
 * Creates an instance that wraps the plan defined in the jar file using the given arguments. For generating the plan the class defined in the className parameter is used.
 * @param jarFile The jar file which contains the plan.
 * @param className Name of the class which generates the plan. Overrides the class defined in the jar file manifest
 * @param args Optional. The arguments used to create the pact plan, depend on implementation of the pact plan. See getDescription().
 * @throws ProgramInvocationException This invocation is thrown if the PlanAssembler can't be properly loaded. Causes may be a missing / wrong class or manifest files.
 */
public PactProgram(File jarFile,String className,String... args) throws ProgramInvocationException {
  this.jarFile=jarFile;
  this.args=args == null ? new String[0] : args;
  this.assemblerClass=getPactAssemblerFromJar(jarFile,className);
}",0.9824163357912647
55406,"@Override public void postVisit(OptimizerNode visitable){
  this.jsonString.append(""String_Node_Str"");
  this.jsonString.append(""String_Node_Str"" + this.nodeIds.get(visitable));
  String type;
switch (visitable.getPactType()) {
case DataSink:
    type=""String_Node_Str"";
  break;
case DataSource:
type=""String_Node_Str"";
break;
default :
type=""String_Node_Str"";
break;
}
this.jsonString.append(""String_Node_Str"" + type + ""String_Node_Str"");
String contents;
switch (visitable.getPactType()) {
case DataSink:
contents=visitable.getPactContract().toString();
break;
case DataSource:
contents=visitable.getPactContract().toString();
break;
default :
jsonString.append(""String_Node_Str"" + visitable.getName() + ""String_Node_Str"");
contents=visitable.getPactContract().getName();
break;
}
this.jsonString.append(""String_Node_Str"" + contents + ""String_Node_Str"");
this.jsonString.append(""String_Node_Str"" + (visitable.getDegreeOfParallelism() >= 1 ? visitable.getDegreeOfParallelism() : ""String_Node_Str"") + ""String_Node_Str"");
List<PactConnection> inConns=visitable.getIncomingConnections();
String child1name=""String_Node_Str"", child2name=""String_Node_Str"";
if (inConns != null && inConns.size() > 0) {
this.jsonString.append(""String_Node_Str"");
int connCnt=0;
for (PactConnection conn : inConns) {
this.jsonString.append(""String_Node_Str"");
if (connCnt == 0) {
child1name+=child1name.length() > 0 ? ""String_Node_Str"" : ""String_Node_Str"";
child1name+=conn.getSourcePact().getPactContract().getName();
}
 else if (connCnt == 1) {
child2name+=child2name.length() > 0 ? ""String_Node_Str"" : ""String_Node_Str"";
child2name=conn.getSourcePact().getPactContract().getName();
}
this.jsonString.append(""String_Node_Str"" + this.nodeIds.get(conn.getSourcePact()));
if (inConns.size() == 2) {
this.jsonString.append(""String_Node_Str"" + (connCnt == 0 ? ""String_Node_Str"" : ""String_Node_Str"") + ""String_Node_Str"");
}
String shipStrategy=null;
String channelType=null;
switch (conn.getShipStrategy()) {
case NONE:
break;
case FORWARD:
shipStrategy=""String_Node_Str"";
channelType=""String_Node_Str"";
break;
case BROADCAST:
shipStrategy=""String_Node_Str"";
channelType=""String_Node_Str"";
break;
case PARTITION_HASH:
shipStrategy=""String_Node_Str"";
channelType=""String_Node_Str"";
break;
case PARTITION_RANGE:
shipStrategy=""String_Node_Str"";
channelType=""String_Node_Str"";
break;
case PARTITION_LOCAL_HASH:
shipStrategy=""String_Node_Str"";
channelType=""String_Node_Str"";
case SFR:
shipStrategy=""String_Node_Str"";
channelType=""String_Node_Str"";
break;
default :
throw new CompilerException(""String_Node_Str"" + conn.getShipStrategy().name() + ""String_Node_Str"");
}
if (shipStrategy != null) {
this.jsonString.append(""String_Node_Str"" + shipStrategy + ""String_Node_Str"");
}
if (channelType != null) {
this.jsonString.append(""String_Node_Str"" + channelType + ""String_Node_Str"");
}
if (conn.getTempMode() != TempMode.NONE) {
String tempMode=conn.getTempMode().toString();
this.jsonString.append(""String_Node_Str"" + tempMode + ""String_Node_Str"");
}
this.jsonString.append('}');
connCnt++;
}
this.jsonString.append(""String_Node_Str"");
}
String locString=null;
if (visitable.getLocalStrategy() != null) {
switch (visitable.getLocalStrategy()) {
case NONE:
break;
case HYBRIDHASH_FIRST:
locString=""String_Node_Str"" + child1name + ""String_Node_Str"";
break;
case HYBRIDHASH_SECOND:
locString=""String_Node_Str"" + child2name + ""String_Node_Str"";
break;
case MMHASH_FIRST:
locString=""String_Node_Str"" + child1name + ""String_Node_Str"";
break;
case MMHASH_SECOND:
locString=""String_Node_Str"" + child2name + ""String_Node_Str"";
break;
case NESTEDLOOP_BLOCKED_OUTER_FIRST:
locString=""String_Node_Str"" + child1name + ""String_Node_Str"";
break;
case NESTEDLOOP_BLOCKED_OUTER_SECOND:
locString=""String_Node_Str"" + child2name + ""String_Node_Str"";
break;
case NESTEDLOOP_STREAMED_OUTER_FIRST:
locString=""String_Node_Str"" + child1name + ""String_Node_Str"";
break;
case NESTEDLOOP_STREAMED_OUTER_SECOND:
locString=""String_Node_Str"" + child2name + ""String_Node_Str"";
break;
case SORT_BOTH_MERGE:
locString=""String_Node_Str"";
break;
case SORT_FIRST_MERGE:
locString=""String_Node_Str"";
break;
case SORT_SECOND_MERGE:
locString=""String_Node_Str"";
break;
case MERGE:
locString=""String_Node_Str"";
break;
case SORT:
locString=""String_Node_Str"";
break;
case COMBININGSORT:
locString=""String_Node_Str"";
break;
case SORT_SELF_NESTEDLOOP:
locString=""String_Node_Str"";
break;
case SELF_NESTEDLOOP:
locString=""String_Node_Str"";
break;
default :
throw new CompilerException(""String_Node_Str"" + visitable.getLocalStrategy().name() + ""String_Node_Str"");
}
if (locString != null) {
this.jsonString.append(""String_Node_Str"");
this.jsonString.append(locString);
this.jsonString.append(""String_Node_Str"");
}
}
{
GlobalProperties gp=visitable.getGlobalProperties();
this.jsonString.append(""String_Node_Str"");
addProperty(jsonString,""String_Node_Str"",gp.getPartitioning().name(),true);
if (gp.getPartitioning() != PartitionProperty.NONE) {
addProperty(jsonString,""String_Node_Str"",gp.getPartitionedFields().toString(),false);
}
if (gp.getOrdering() != null) {
addProperty(jsonString,""String_Node_Str"",gp.getOrdering().toString(),false);
}
 else {
addProperty(jsonString,""String_Node_Str"",""String_Node_Str"",false);
}
if (visitable.getUniqueFields() == null || visitable.getUniqueFields().size() == 0) {
addProperty(jsonString,""String_Node_Str"",""String_Node_Str"",false);
}
 else {
addProperty(jsonString,""String_Node_Str"",visitable.getUniqueFields().toString(),false);
}
this.jsonString.append(""String_Node_Str"");
}
{
LocalProperties lp=visitable.getLocalProperties();
this.jsonString.append(""String_Node_Str"");
if (lp.getOrdering() != null) {
addProperty(jsonString,""String_Node_Str"",lp.getOrdering().toString(),true);
}
 else {
addProperty(jsonString,""String_Node_Str"",""String_Node_Str"",true);
}
if (visitable.getUniqueFields() == null || visitable.getUniqueFields().size() == 0) {
addProperty(jsonString,""String_Node_Str"",""String_Node_Str"",false);
}
 else {
addProperty(jsonString,""String_Node_Str"",visitable.getUniqueFields().toString(),false);
}
addProperty(jsonString,""String_Node_Str"",lp.isGrouped() ? ""String_Node_Str"" : ""String_Node_Str"",false);
if (lp.isGrouped()) {
addProperty(jsonString,""String_Node_Str"",lp.getGroupedFields().toString(),false);
}
this.jsonString.append(""String_Node_Str"");
}
this.jsonString.append(""String_Node_Str"");
addProperty(this.jsonString,""String_Node_Str"",visitable.getEstimatedNumRecords() == -1 ? ""String_Node_Str"" : formatNumber(visitable.getEstimatedNumRecords()),true);
String estCardinality=""String_Node_Str"";
if (visitable.getEstimatedCardinalities().size() > 0) {
estCardinality=""String_Node_Str"";
for (Entry<FieldSet,Long> entry : visitable.getEstimatedCardinalities().entrySet()) {
estCardinality+=""String_Node_Str"" + entry.getKey().toString() + ""String_Node_Str""+ entry.getValue()+ ""String_Node_Str"";
}
}
addProperty(jsonString,""String_Node_Str"",estCardinality,false);
addProperty(jsonString,""String_Node_Str"",visitable.getEstimatedOutputSize() == -1 ? ""String_Node_Str"" : formatNumber(visitable.getEstimatedOutputSize(),""String_Node_Str""),false);
this.jsonString.append(""String_Node_Str"");
if (visitable.getNodeCosts() != null) {
this.jsonString.append(""String_Node_Str"");
addProperty(this.jsonString,""String_Node_Str"",visitable.getNodeCosts().getNetworkCost() == -1 ? ""String_Node_Str"" : formatNumber(visitable.getNodeCosts().getNetworkCost(),""String_Node_Str""),true);
addProperty(this.jsonString,""String_Node_Str"",visitable.getNodeCosts().getSecondaryStorageCost() == -1 ? ""String_Node_Str"" : formatNumber(visitable.getNodeCosts().getSecondaryStorageCost(),""String_Node_Str""),false);
addProperty(this.jsonString,""String_Node_Str"",visitable.getCumulativeCosts().getNetworkCost() == -1 ? ""String_Node_Str"" : formatNumber(visitable.getCumulativeCosts().getNetworkCost(),""String_Node_Str""),false);
addProperty(this.jsonString,""String_Node_Str"",visitable.getCumulativeCosts().getSecondaryStorageCost() == -1 ? ""String_Node_Str"" : formatNumber(visitable.getCumulativeCosts().getSecondaryStorageCost(),""String_Node_Str""),false);
this.jsonString.append(""String_Node_Str"");
}
if (visitable.getPactContract().getCompilerHints() != null) {
CompilerHints hints=visitable.getPactContract().getCompilerHints();
CompilerHints defaults=new CompilerHints();
this.jsonString.append(""String_Node_Str"");
String hintCardinality=""String_Node_Str"";
if (hints.getDistinctCounts().size() > 0) {
hintCardinality=""String_Node_Str"";
for (Entry<FieldSet,Long> entry : visitable.getEstimatedCardinalities().entrySet()) {
hintCardinality+=""String_Node_Str"" + entry.getKey().toString() + ""String_Node_Str""+ entry.getValue()+ ""String_Node_Str"";
}
}
addProperty(jsonString,""String_Node_Str"",hintCardinality,true);
addProperty(jsonString,""String_Node_Str"",hints.getAvgRecordsEmittedPerStubCall() == defaults.getAvgRecordsEmittedPerStubCall() ? ""String_Node_Str"" : String.valueOf(hints.getAvgRecordsEmittedPerStubCall()),false);
String valuesKey=""String_Node_Str"";
if (hints.getAvgNumRecordsPerDistinctFields().size() > 0) {
valuesKey=""String_Node_Str"";
for (Entry<FieldSet,Float> entry : hints.getAvgNumRecordsPerDistinctFields().entrySet()) {
valuesKey+=""String_Node_Str"" + entry.getKey().toString() + ""String_Node_Str""+ entry.getValue()+ ""String_Node_Str"";
}
}
addProperty(jsonString,""String_Node_Str"",valuesKey,false);
addProperty(jsonString,""String_Node_Str"",hints.getAvgBytesPerRecord() == defaults.getAvgBytesPerRecord() ? ""String_Node_Str"" : String.valueOf(hints.getAvgBytesPerRecord()),false);
this.jsonString.append(""String_Node_Str"");
}
this.jsonString.append(""String_Node_Str"");
}","@Override public void postVisit(OptimizerNode visitable){
  this.jsonString.append(""String_Node_Str"");
  this.jsonString.append(""String_Node_Str"" + this.nodeIds.get(visitable));
  String type;
switch (visitable.getPactType()) {
case DataSink:
    type=""String_Node_Str"";
  break;
case DataSource:
type=""String_Node_Str"";
break;
default :
type=""String_Node_Str"";
break;
}
this.jsonString.append(""String_Node_Str"" + type + ""String_Node_Str"");
String contents;
switch (visitable.getPactType()) {
case DataSink:
contents=visitable.getPactContract().toString();
break;
case DataSource:
contents=visitable.getPactContract().toString();
break;
default :
jsonString.append(""String_Node_Str"" + visitable.getName() + ""String_Node_Str"");
contents=visitable.getPactContract().getName();
break;
}
this.jsonString.append(""String_Node_Str"" + contents + ""String_Node_Str"");
this.jsonString.append(""String_Node_Str"" + (visitable.getDegreeOfParallelism() >= 1 ? visitable.getDegreeOfParallelism() : ""String_Node_Str"") + ""String_Node_Str"");
List<PactConnection> inConns=visitable.getIncomingConnections();
String child1name=""String_Node_Str"", child2name=""String_Node_Str"";
if (inConns != null && inConns.size() > 0) {
this.jsonString.append(""String_Node_Str"");
int connCnt=0;
for (PactConnection conn : inConns) {
this.jsonString.append(connCnt == 0 ? ""String_Node_Str"" : ""String_Node_Str"");
if (connCnt == 0) {
child1name+=child1name.length() > 0 ? ""String_Node_Str"" : ""String_Node_Str"";
child1name+=conn.getSourcePact().getPactContract().getName();
}
 else if (connCnt == 1) {
child2name+=child2name.length() > 0 ? ""String_Node_Str"" : ""String_Node_Str"";
child2name=conn.getSourcePact().getPactContract().getName();
}
this.jsonString.append(""String_Node_Str"" + this.nodeIds.get(conn.getSourcePact()));
if (inConns.size() == 2) {
this.jsonString.append(""String_Node_Str"" + (connCnt == 0 ? ""String_Node_Str"" : ""String_Node_Str"") + ""String_Node_Str"");
}
String shipStrategy=null;
String channelType=null;
switch (conn.getShipStrategy()) {
case NONE:
break;
case FORWARD:
shipStrategy=""String_Node_Str"";
channelType=""String_Node_Str"";
break;
case BROADCAST:
shipStrategy=""String_Node_Str"";
channelType=""String_Node_Str"";
break;
case PARTITION_HASH:
shipStrategy=""String_Node_Str"";
channelType=""String_Node_Str"";
break;
case PARTITION_RANGE:
shipStrategy=""String_Node_Str"";
channelType=""String_Node_Str"";
break;
case PARTITION_LOCAL_HASH:
shipStrategy=""String_Node_Str"";
channelType=""String_Node_Str"";
case SFR:
shipStrategy=""String_Node_Str"";
channelType=""String_Node_Str"";
break;
default :
throw new CompilerException(""String_Node_Str"" + conn.getShipStrategy().name() + ""String_Node_Str"");
}
if (shipStrategy != null) {
this.jsonString.append(""String_Node_Str"" + shipStrategy + ""String_Node_Str"");
}
if (channelType != null) {
this.jsonString.append(""String_Node_Str"" + channelType + ""String_Node_Str"");
}
if (conn.getTempMode() != TempMode.NONE) {
String tempMode=conn.getTempMode().toString();
this.jsonString.append(""String_Node_Str"" + tempMode + ""String_Node_Str"");
}
this.jsonString.append('}');
connCnt++;
}
this.jsonString.append(""String_Node_Str"");
}
String locString=null;
if (visitable.getLocalStrategy() != null) {
switch (visitable.getLocalStrategy()) {
case NONE:
break;
case HYBRIDHASH_FIRST:
locString=""String_Node_Str"" + child1name + ""String_Node_Str"";
break;
case HYBRIDHASH_SECOND:
locString=""String_Node_Str"" + child2name + ""String_Node_Str"";
break;
case MMHASH_FIRST:
locString=""String_Node_Str"" + child1name + ""String_Node_Str"";
break;
case MMHASH_SECOND:
locString=""String_Node_Str"" + child2name + ""String_Node_Str"";
break;
case NESTEDLOOP_BLOCKED_OUTER_FIRST:
locString=""String_Node_Str"" + child1name + ""String_Node_Str"";
break;
case NESTEDLOOP_BLOCKED_OUTER_SECOND:
locString=""String_Node_Str"" + child2name + ""String_Node_Str"";
break;
case NESTEDLOOP_STREAMED_OUTER_FIRST:
locString=""String_Node_Str"" + child1name + ""String_Node_Str"";
break;
case NESTEDLOOP_STREAMED_OUTER_SECOND:
locString=""String_Node_Str"" + child2name + ""String_Node_Str"";
break;
case SORT_BOTH_MERGE:
locString=""String_Node_Str"";
break;
case SORT_FIRST_MERGE:
locString=""String_Node_Str"";
break;
case SORT_SECOND_MERGE:
locString=""String_Node_Str"";
break;
case MERGE:
locString=""String_Node_Str"";
break;
case SORT:
locString=""String_Node_Str"";
break;
case COMBININGSORT:
locString=""String_Node_Str"";
break;
case SORT_SELF_NESTEDLOOP:
locString=""String_Node_Str"";
break;
case SELF_NESTEDLOOP:
locString=""String_Node_Str"";
break;
default :
throw new CompilerException(""String_Node_Str"" + visitable.getLocalStrategy().name() + ""String_Node_Str"");
}
if (locString != null) {
this.jsonString.append(""String_Node_Str"");
this.jsonString.append(locString);
this.jsonString.append(""String_Node_Str"");
}
}
{
GlobalProperties gp=visitable.getGlobalProperties();
this.jsonString.append(""String_Node_Str"");
addProperty(jsonString,""String_Node_Str"",gp.getPartitioning().name(),true);
if (gp.getPartitioning() != PartitionProperty.NONE) {
addProperty(jsonString,""String_Node_Str"",gp.getPartitionedFields().toString(),false);
}
if (gp.getOrdering() != null) {
addProperty(jsonString,""String_Node_Str"",gp.getOrdering().toString(),false);
}
 else {
addProperty(jsonString,""String_Node_Str"",""String_Node_Str"",false);
}
if (visitable.getUniqueFields() == null || visitable.getUniqueFields().size() == 0) {
addProperty(jsonString,""String_Node_Str"",""String_Node_Str"",false);
}
 else {
addProperty(jsonString,""String_Node_Str"",visitable.getUniqueFields().toString(),false);
}
this.jsonString.append(""String_Node_Str"");
}
{
LocalProperties lp=visitable.getLocalProperties();
this.jsonString.append(""String_Node_Str"");
if (lp.getOrdering() != null) {
addProperty(jsonString,""String_Node_Str"",lp.getOrdering().toString(),true);
}
 else {
addProperty(jsonString,""String_Node_Str"",""String_Node_Str"",true);
}
if (visitable.getUniqueFields() == null || visitable.getUniqueFields().size() == 0) {
addProperty(jsonString,""String_Node_Str"",""String_Node_Str"",false);
}
 else {
addProperty(jsonString,""String_Node_Str"",visitable.getUniqueFields().toString(),false);
}
addProperty(jsonString,""String_Node_Str"",lp.isGrouped() ? ""String_Node_Str"" : ""String_Node_Str"",false);
if (lp.isGrouped()) {
addProperty(jsonString,""String_Node_Str"",lp.getGroupedFields().toString(),false);
}
this.jsonString.append(""String_Node_Str"");
}
this.jsonString.append(""String_Node_Str"");
addProperty(this.jsonString,""String_Node_Str"",visitable.getEstimatedNumRecords() == -1 ? ""String_Node_Str"" : formatNumber(visitable.getEstimatedNumRecords()),true);
String estCardinality=""String_Node_Str"";
if (visitable.getEstimatedCardinalities().size() > 0) {
estCardinality=""String_Node_Str"";
for (Entry<FieldSet,Long> entry : visitable.getEstimatedCardinalities().entrySet()) {
estCardinality+=""String_Node_Str"" + entry.getKey().toString() + ""String_Node_Str""+ entry.getValue()+ ""String_Node_Str"";
}
}
addProperty(jsonString,""String_Node_Str"",estCardinality,false);
addProperty(jsonString,""String_Node_Str"",visitable.getEstimatedOutputSize() == -1 ? ""String_Node_Str"" : formatNumber(visitable.getEstimatedOutputSize(),""String_Node_Str""),false);
this.jsonString.append(""String_Node_Str"");
if (visitable.getNodeCosts() != null) {
this.jsonString.append(""String_Node_Str"");
addProperty(this.jsonString,""String_Node_Str"",visitable.getNodeCosts().getNetworkCost() == -1 ? ""String_Node_Str"" : formatNumber(visitable.getNodeCosts().getNetworkCost(),""String_Node_Str""),true);
addProperty(this.jsonString,""String_Node_Str"",visitable.getNodeCosts().getSecondaryStorageCost() == -1 ? ""String_Node_Str"" : formatNumber(visitable.getNodeCosts().getSecondaryStorageCost(),""String_Node_Str""),false);
addProperty(this.jsonString,""String_Node_Str"",visitable.getCumulativeCosts().getNetworkCost() == -1 ? ""String_Node_Str"" : formatNumber(visitable.getCumulativeCosts().getNetworkCost(),""String_Node_Str""),false);
addProperty(this.jsonString,""String_Node_Str"",visitable.getCumulativeCosts().getSecondaryStorageCost() == -1 ? ""String_Node_Str"" : formatNumber(visitable.getCumulativeCosts().getSecondaryStorageCost(),""String_Node_Str""),false);
this.jsonString.append(""String_Node_Str"");
}
if (visitable.getPactContract().getCompilerHints() != null) {
CompilerHints hints=visitable.getPactContract().getCompilerHints();
CompilerHints defaults=new CompilerHints();
this.jsonString.append(""String_Node_Str"");
String hintCardinality=""String_Node_Str"";
if (hints.getDistinctCounts().size() > 0) {
hintCardinality=""String_Node_Str"";
for (Entry<FieldSet,Long> entry : visitable.getEstimatedCardinalities().entrySet()) {
hintCardinality+=""String_Node_Str"" + entry.getKey().toString() + ""String_Node_Str""+ entry.getValue()+ ""String_Node_Str"";
}
}
addProperty(jsonString,""String_Node_Str"",hintCardinality,true);
addProperty(jsonString,""String_Node_Str"",hints.getAvgRecordsEmittedPerStubCall() == defaults.getAvgRecordsEmittedPerStubCall() ? ""String_Node_Str"" : String.valueOf(hints.getAvgRecordsEmittedPerStubCall()),false);
String valuesKey=""String_Node_Str"";
if (hints.getAvgNumRecordsPerDistinctFields().size() > 0) {
valuesKey=""String_Node_Str"";
for (Entry<FieldSet,Float> entry : hints.getAvgNumRecordsPerDistinctFields().entrySet()) {
valuesKey+=""String_Node_Str"" + entry.getKey().toString() + ""String_Node_Str""+ entry.getValue()+ ""String_Node_Str"";
}
}
addProperty(jsonString,""String_Node_Str"",valuesKey,false);
addProperty(jsonString,""String_Node_Str"",hints.getAvgBytesPerRecord() == defaults.getAvgBytesPerRecord() ? ""String_Node_Str"" : String.valueOf(hints.getAvgBytesPerRecord()),false);
this.jsonString.append(""String_Node_Str"");
}
this.jsonString.append(""String_Node_Str"");
}",0.9981860585643948
55407,"@Override public boolean readRecord(PactRecord target,byte[] bytes,int offset,int numBytes){
  this.keyString.setValueAscii(bytes,0,1);
  this.valueString.setValueAscii(bytes,2,1);
  target.setField(0,keyString);
  target.setField(1,valueString);
  LOG.debug(""String_Node_Str"" + keyString.getValue() + ""String_Node_Str""+ valueString.getValue()+ ""String_Node_Str"");
  return true;
}","@Override public boolean readRecord(PactRecord target,byte[] bytes,int offset,int numBytes){
  this.keyString.setValueAscii(bytes,offset,1);
  this.valueString.setValueAscii(bytes,offset + 2,1);
  target.setField(0,keyString);
  target.setField(1,valueString);
  LOG.debug(""String_Node_Str"" + keyString.getValue() + ""String_Node_Str""+ valueString.getValue()+ ""String_Node_Str"");
  return true;
}",0.979381443298969
55408,"@Override public boolean readRecord(PactRecord target,byte[] bytes,int offset,int numBytes){
  this.keyString.setValueAscii(bytes,0,1);
  this.valueString.setValueAscii(bytes,2,1);
  target.setField(0,keyString);
  target.setField(1,valueString);
  LOG.debug(""String_Node_Str"" + keyString.getValue() + ""String_Node_Str""+ valueString.getValue()+ ""String_Node_Str"");
  return true;
}","@Override public boolean readRecord(PactRecord target,byte[] bytes,int offset,int numBytes){
  this.keyString.setValueAscii(bytes,offset,1);
  this.valueString.setValueAscii(bytes,offset + 2,1);
  target.setField(0,keyString);
  target.setField(1,valueString);
  LOG.debug(""String_Node_Str"" + keyString.getValue() + ""String_Node_Str""+ valueString.getValue()+ ""String_Node_Str"");
  return true;
}",0.979381443298969
55409,"@Override public boolean readRecord(PactRecord target,byte[] line,int offset,int numBytes){
  final int limit=offset + numBytes;
  int readPos=offset;
  short[] offsets=new short[MAX_COLUMNS];
  int col=1;
  int countInWrapBuffer=0;
  int startPos=readPos;
  while (readPos < limit) {
    if (line[readPos++] == DELIMITER) {
      offsets[col++]=(short)(countInWrapBuffer + readPos - startPos);
    }
  }
  Tuple value=new Tuple(line,offsets,col - 1);
  PactInteger key=new PactInteger((int)value.getLongValueAt(0));
  target.setField(0,key);
  target.setField(1,value);
  return true;
}","@Override public boolean readRecord(PactRecord target,byte[] line,int offset,int numBytes){
  final int limit=offset + numBytes;
  int readPos=offset;
  final short[] offsets=this.offsets;
  offsets[0]=(short)offset;
  int col=1;
  while (readPos < limit) {
    if (line[readPos++] == DELIMITER) {
      offsets[col++]=(short)(readPos);
    }
  }
  final Tuple value=new Tuple(line,offsets,col - 1);
  this.key.setValue((int)value.getLongValueAt(0));
  target.setField(0,this.key);
  target.setField(1,value);
  return true;
}",0.7151841868823001
55410,"@Override protected void map(final IJsonNode value,final JsonCollector out){
  System.out.println(""String_Node_Str"" + value);
  AnnotatorNodes.annotate(this.output,ANNOTATION_VALUE,value);
  System.out.println(this.output);
  out.collect(this.output);
}","@Override protected void map(final IJsonNode value,final JsonCollector out){
  AnnotatorNodes.annotate(this.output,ANNOTATION_VALUE,value);
  out.collect(this.output);
}",0.8009478672985783
55411,"@Override public void read(final IJsonNode node){
  if (node == null || !(node instanceof ObjectNode))   throw new IllegalArgumentException(""String_Node_Str"" + node);
  final ObjectNode objectNode=(ObjectNode)node;
  System.out.println(""String_Node_Str"" + node);
  this.key=PointNodes.getId(objectNode).getJavaValue();
  this.values=new ArrayList<String>();
  for (  final IJsonNode valuesNode : PointNodes.getValues(objectNode))   this.values.add(((TextNode)valuesNode).getTextValue());
  this.rowsum=PointNodes.getRowsum(objectNode).getIntValue();
}","@Override public void read(final IJsonNode node){
  if (node == null || !(node instanceof ObjectNode))   throw new IllegalArgumentException(""String_Node_Str"" + node);
  final ObjectNode objectNode=(ObjectNode)node;
  this.key=PointNodes.getId(objectNode).getJavaValue();
  this.values=new ArrayList<String>();
  for (  final IJsonNode valuesNode : PointNodes.getValues(objectNode))   this.values.add(((TextNode)valuesNode).getTextValue());
  this.rowsum=PointNodes.getRowsum(objectNode).getIntValue();
}",0.9544592030360532
55412,"@Override protected void reduce(final IArrayNode values,final JsonCollector out){
  System.out.println(""String_Node_Str"" + values);
  this.addPoints(values);
  this.cluster();
  this.emitClusters(out);
}","@Override protected void reduce(final IArrayNode values,final JsonCollector out){
  this.addPoints(values);
  this.cluster();
  this.emitClusters(out);
}",0.8595505617977528
55413,"public static IArrayNode getPoints(final ObjectNode clusterNode){
  return (IArrayNode)clusterNode.get(POINTS);
}","public static IArrayNode getPoints(final ObjectNode clusterNode){
  try {
    return (IArrayNode)clusterNode.get(POINTS);
  }
 catch (  ClassCastException e) {
    System.err.println(clusterNode);
    throw e;
  }
}",0.6890243902439024
55414,"@Override protected void map(final IJsonNode node,final JsonCollector out){
  System.out.println(""String_Node_Str"" + node);
  final ObjectNode clusterNode=(ObjectNode)node;
  final TextNode idNode=ClusterNodes.getId(clusterNode);
  final IArrayNode pointsNode=ClusterNodes.getPoints(clusterNode);
  for (  final IJsonNode pointNode : pointsNode) {
    this.outputNode.putAll((IObjectNode)pointNode);
    PointNodes.assignCluster(this.outputNode,idNode);
    out.collect(this.outputNode);
  }
}","@Override protected void map(final IJsonNode node,final JsonCollector out){
  final ObjectNode clusterNode=(ObjectNode)node;
  final TextNode idNode=ClusterNodes.getId(clusterNode);
  final IArrayNode pointsNode=ClusterNodes.getPoints(clusterNode);
  for (  final IJsonNode pointNode : pointsNode) {
    this.outputNode.putAll((IObjectNode)pointNode);
    PointNodes.assignCluster(this.outputNode,idNode);
    out.collect(this.outputNode);
  }
}",0.9488272921108742
55415,"@Override public ElementarySopremoModule asElementaryOperators(){
  final ElementarySopremoModule module=new ElementarySopremoModule(this.getName(),4,2);
  final Source initialClustersInput=module.getInput(0);
  final Source restPointsInput=module.getInput(1);
  final Source treeInput=module.getInput(2);
  final Source representationInput=module.getInput(3);
  final ClusterDisassemble disassemble=new ClusterDisassemble().withInputs(initialClustersInput);
  final PointMapper pointMapper=new PointMapper();
  pointMapper.setInput(PointMapper.POINT_INPUT_INDEX,restPointsInput);
  pointMapper.setInput(PointMapper.TREE_INPUT_INDEX,treeInput);
  final UnionAll pointUnionAll=new UnionAll().withInputs(disassemble,pointMapper);
  final RepresentationUpdate representationUpdate=new RepresentationUpdate().withInputs(representationInput,pointUnionAll);
  representationUpdate.setMaxClusterRadius(this.maxClusterRadius);
  representationUpdate.setMinPointCount(this.minPointCount);
  representationUpdate.setMaxClustroidShift(this.maxClustroidShift);
  representationUpdate.setRepresentationDetail(this.representationDetail);
  module.getOutput(0).setInputs(pointUnionAll);
  module.getOutput(1).setInputs(representationUpdate);
  return module;
}","@Override public ElementarySopremoModule asElementaryOperators(){
  final ElementarySopremoModule module=new ElementarySopremoModule(this.getName(),4,2);
  final Source initialClustersInput=module.getInput(0);
  final Source restPointsInput=module.getInput(1);
  final Source treeInput=module.getInput(2);
  final Source representationInput=module.getInput(3);
  final ClusterDisassemble disassemble=new ClusterDisassemble().withInputs(initialClustersInput);
  final PointMapper pointMapper=new PointMapper().withInputs(restPointsInput,treeInput);
  final UnionAll pointUnionAll=new UnionAll().withInputs(disassemble,pointMapper);
  final RepresentationUpdate representationUpdate=new RepresentationUpdate().withInputs(representationInput,pointUnionAll);
  representationUpdate.setMaxClusterRadius(this.maxClusterRadius);
  representationUpdate.setMinPointCount(this.minPointCount);
  representationUpdate.setMaxClustroidShift(this.maxClustroidShift);
  representationUpdate.setRepresentationDetail(this.representationDetail);
  module.getOutput(0).setInputs(pointUnionAll);
  module.getOutput(1).setInputs(representationUpdate);
  return module;
}",0.9410781445883828
55416,"@Override protected void cross(final IJsonNode pointNode,final IJsonNode treeNode,final JsonCollector out){
  System.out.println(""String_Node_Str"" + treeNode);
  System.out.println(""String_Node_Str"" + pointNode);
  final ClusterTree tree=new ClusterTree();
  tree.read(treeNode);
  final Point point=new Point();
  point.read(pointNode);
  final String clusterId=tree.findIdOfClusterNextTo(point);
  this.clusterIdNode.setValue(clusterId);
  PointNodes.assignCluster((ObjectNode)pointNode,this.clusterIdNode);
  System.out.println(pointNode);
  out.collect(pointNode);
}","@Override protected void cross(final IJsonNode pointNode,final IJsonNode treeNode,final JsonCollector out){
  final ClusterTree tree=new ClusterTree();
  tree.read(treeNode);
  final Point point=new Point();
  point.read(pointNode);
  final String clusterId=tree.findIdOfClusterNextTo(point);
  this.clusterIdNode.setValue(clusterId);
  PointNodes.assignCluster((ObjectNode)pointNode,this.clusterIdNode);
  out.collect(pointNode);
}",0.8622754491017964
55417,"@Override protected void coGroup(final IArrayNode representationsNode,final IArrayNode pointsNode,final JsonCollector out){
  if (representationsNode.size() != 1)   throw new IllegalStateException(""String_Node_Str"" + representationsNode.size());
  final ObjectNode representationNode=(ObjectNode)representationsNode.get(0);
  final String id=JsonUtil2.getField(representationNode,""String_Node_Str"",TextNode.class).getJavaValue();
  final Point oldClustroid=new Point();
  oldClustroid.read(representationNode.get(""String_Node_Str""));
  final ClusterRepresentation representation=new ClusterRepresentation(id,oldClustroid,this.representationDetail);
  for (  final IJsonNode memberNode : pointsNode) {
    final Point point=new Point();
    point.read(memberNode);
    representation.add(point);
  }
  this.emitRepresentation(representation,oldClustroid,out);
}","@Override protected void coGroup(final IArrayNode representationsNode,final IArrayNode pointsNode,final JsonCollector out){
  if (representationsNode.size() != 1)   throw new IllegalStateException(""String_Node_Str"" + representationsNode.size());
  final ObjectNode representationNode=(ObjectNode)representationsNode.get(0);
  final String id=JsonUtil2.getField(representationNode,RepresentationNodes.ID,TextNode.class).getJavaValue();
  final Point oldClustroid=new Point();
  oldClustroid.read(representationNode.get(RepresentationNodes.CLUSTROID));
  final ClusterRepresentation representation=new ClusterRepresentation(id,oldClustroid,this.representationDetail);
  for (  final IJsonNode memberNode : pointsNode) {
    final Point point=new Point();
    point.read(memberNode);
    representation.add(point);
  }
  this.emitRepresentation(representation,oldClustroid,out);
}",0.952216465169833
55418,"private void emit(final String id,final Point clustroid,final int flag,final String oldId,final JsonCollector collector){
  this.outputNode.clear();
  if (clustroid == null)   throw new IllegalArgumentException(""String_Node_Str"" + id);
  this.idNode.setValue(id);
  this.outputNode.put(""String_Node_Str"",this.idNode);
  this.outputNode.put(""String_Node_Str"",clustroid.write(this.pointNode));
  this.flagNode.setValue(flag);
  this.outputNode.put(""String_Node_Str"",this.flagNode);
  this.oldIdNode.setValue(oldId);
  this.outputNode.put(""String_Node_Str"",this.oldIdNode);
  collector.collect(this.outputNode);
}","private void emit(final String id,final Point clustroid,final int flag,final String oldId,final JsonCollector collector){
  this.outputNode.clear();
  if (clustroid == null)   throw new IllegalArgumentException(""String_Node_Str"" + id);
  this.idNode.setValue(id);
  this.flagNode.setValue(flag);
  this.oldIdNode.setValue(oldId);
  clustroid.write(this.pointNode);
  RepresentationNodes.write(outputNode,idNode,oldIdNode,pointNode);
  RepresentationNodes.setFlag(outputNode,flagNode);
  collector.collect(this.outputNode);
}",0.6296296296296297
55419,"@Override protected void coGroup(final IArrayNode representationNodes,final IArrayNode pointNodes,final JsonCollector out){
  if (representationNodes.size() != 2)   throw new IllegalArgumentException(""String_Node_Str"" + representationNodes.size());
  final ObjectNode representationNode1=(ObjectNode)representationNodes.get(0);
  final ObjectNode representationNode2=(ObjectNode)representationNodes.get(1);
  this.representation1=RepresentationNodes.read(representationNode1,this.representationDetail);
  this.representation2=RepresentationNodes.read(representationNode2,this.representationDetail);
  this.parentId=RepresentationNodes.getParentId(representationNode1).getTextValue();
  this.addAll(pointNodes);
  this.emitRepresentations(out);
}","@Override protected void coGroup(final IArrayNode representationNodes,final IArrayNode pointNodes,final JsonCollector out){
  final int representationCount=representationNodes.size();
  if (representationCount == 0)   return;
 else   if (representationCount != 2)   throw new IllegalArgumentException(""String_Node_Str"" + representationCount + ""String_Node_Str""+ pointNodes.size()+ ""String_Node_Str"");
  final ObjectNode representationNode1=(ObjectNode)representationNodes.get(0);
  final ObjectNode representationNode2=(ObjectNode)representationNodes.get(1);
  this.representation1=RepresentationNodes.read(representationNode1,this.representationDetail);
  this.representation2=RepresentationNodes.read(representationNode2,this.representationDetail);
  this.parentId=RepresentationNodes.getParentId(representationNode1).getTextValue();
  this.addAll(pointNodes);
  this.emitRepresentations(out);
}",0.9037758830694276
55420,"@Override public void read(final IJsonNode node){
  this.degree=JsonUtil2.getField(node,JSON_KEY_DEGREE,IntNode.class).getIntValue();
  this.root=this.createInnerNode();
  this.root.read(JsonUtil2.getField(node,JSON_KEY_ROOT,ObjectNode.class));
}","@Override public void read(final IJsonNode node){
  try {
    this.degree=JsonUtil2.getField(node,JSON_KEY_DEGREE,IntNode.class).getIntValue();
  }
 catch (  ClassCastException e) {
    System.out.println(""String_Node_Str"" + node);
    throw e;
  }
  this.root=this.createInnerNode();
  this.root.read(JsonUtil2.getField(node,JSON_KEY_ROOT,ObjectNode.class));
}",0.8105436573311368
55421,"@Override protected void map(final IJsonNode value,final JsonCollector out){
  System.out.println(""String_Node_Str"" + value);
  final ObjectNode clusterNode=(ObjectNode)value;
  final TextNode idNode=ClusterNodes.getId(clusterNode);
  final ObjectNode clustroidNode=ClusterNodes.getClustroid(clusterNode);
  RepresentationNodes.write(this.outputNode,idNode,clustroidNode);
  AnnotatorNodes.flatAnnotate(this.outputNode,DUMMY_ANNOTATION);
  out.collect(this.outputNode);
}","@Override protected void map(final IJsonNode value,final JsonCollector out){
  final ObjectNode clusterNode=(ObjectNode)value;
  final TextNode idNode=ClusterNodes.getId(clusterNode);
  final ObjectNode clustroidNode=ClusterNodes.getClustroid(clusterNode);
  RepresentationNodes.write(this.outputNode,idNode,clustroidNode);
  AnnotatorNodes.flatAnnotate(this.outputNode,DUMMY_ANNOTATION);
  out.collect(this.outputNode);
}",0.9451287793952968
55422,"@Override public ElementarySopremoModule asElementaryOperators(){
  final ElementarySopremoModule module=new ElementarySopremoModule(this.getName(),this.getInputs().size(),this.getOutputs().size());
  final Operator<Self> clone=this.clone();
  for (int index=0; index < this.getInputs().size(); index++)   clone.setInput(index,module.getInput(index));
  for (int index=0; index < this.getOutputs().size(); index++)   module.getOutput(index).setInput(index,clone.getOutput(index));
  return module;
}","@Override public ElementarySopremoModule asElementaryOperators(){
  final ElementarySopremoModule module=new ElementarySopremoModule(this.getName(),this.getInputs().size(),this.getOutputs().size());
  final Operator<Self> clone=this.clone();
  for (int index=0; index < this.getInputs().size(); index++)   clone.setInput(index,module.getInput(index));
  final List<JsonStream> outputs=clone.getOutputs();
  for (int index=0; index < outputs.size(); index++)   module.getOutput(index).setInput(index,outputs.get(index));
  return module;
}",0.9026036644165863
55423,"/** 
 * {@inheritDoc}
 */
@Override public void registerOutputGate(final OutputGate<? extends Record> outputGate){
  throw new IllegalStateException(""String_Node_Str"");
}","/** 
 * {@inheritDoc}
 */
@Override public void registerOutputGate(final OutputGate<? extends Record> outputGate){
}",0.8111888111888111
55424,"/** 
 * {@inheritDoc}
 */
@Override public void registerInputGate(final InputGate<? extends Record> inputGate){
  throw new IllegalStateException(""String_Node_Str"");
}","/** 
 * {@inheritDoc}
 */
@Override public void registerInputGate(final InputGate<? extends Record> inputGate){
}",0.8071428571428572
55425,"@SuppressWarnings(""String_Node_Str"") public List<? extends EvaluationExpression> getKeyExpressions(int inputIndex){
  if (inputIndex >= this.keyExpressions.size())   return Collections.EMPTY_LIST;
  final List<? extends EvaluationExpression> expressions=this.keyExpressions.get(inputIndex);
  if (expressions == null)   return Collections.EMPTY_LIST;
  return expressions;
}","/** 
 * Returns the key expressions of the given input.
 * @param inputIndex the index of the input
 * @return the key expressions of the given input
 */
@SuppressWarnings(""String_Node_Str"") public List<? extends EvaluationExpression> getKeyExpressions(int inputIndex){
  if (inputIndex >= this.keyExpressions.size())   return Collections.EMPTY_LIST;
  final List<? extends EvaluationExpression> expressions=this.keyExpressions.get(inputIndex);
  if (expressions == null)   return Collections.EMPTY_LIST;
  return expressions;
}",0.8292682926829268
55426,"/** 
 * Callback to add parameters to the stub configuration.<br> The default implementation adds the context and all non-transient, non-final, non-static fields.
 * @param contract the contract to configure
 * @param stubConfiguration the configuration of the stub
 * @param context the context in which the  {@link PactModule} is created and evaluated
 */
protected void configureContract(final Contract contract,final Configuration stubConfiguration,final EvaluationContext context){
  context.pushOperator(this);
  SopremoUtil.serialize(stubConfiguration,SopremoUtil.CONTEXT,context);
  context.popOperator();
  for (  final Field stubField : contract.getUserCodeClass().getDeclaredFields())   if ((stubField.getModifiers() & (Modifier.TRANSIENT | Modifier.FINAL | Modifier.STATIC)) == 0) {
    Field thisField;
    try {
      thisField=this.getClass().getDeclaredField(stubField.getName());
      thisField.setAccessible(true);
      SopremoUtil.serialize(stubConfiguration,stubField.getName(),(Serializable)thisField.get(this));
    }
 catch (    final NoSuchFieldException e) {
    }
catch (    final Exception e) {
      LOG.error(String.format(""String_Node_Str"",stubField.getName(),contract.getClass(),e));
    }
  }
}","/** 
 * Callback to add parameters to the stub configuration.<br> The default implementation adds the context and all non-transient, non-final, non-static fields.
 * @param contract the contract to configure
 * @param stubConfiguration the configuration of the stub
 * @param context the context in which the  {@link PactModule} is created and evaluated
 */
protected void configureContract(final Contract contract,final Configuration stubConfiguration,final EvaluationContext context){
  context.pushOperator(this);
  SopremoUtil.serialize(stubConfiguration,SopremoUtil.CONTEXT,context);
  context.popOperator();
  for (  final Field stubField : contract.getUserCodeClass().getDeclaredFields())   if ((stubField.getModifiers() & (Modifier.TRANSIENT | Modifier.FINAL | Modifier.STATIC)) == 0) {
    Class<?> clazz=this.getClass();
    do {
      Field thisField;
      try {
        thisField=clazz.getDeclaredField(stubField.getName());
        thisField.setAccessible(true);
        SopremoUtil.serialize(stubConfiguration,stubField.getName(),(Serializable)thisField.get(this));
      }
 catch (      final NoSuchFieldException e) {
      }
catch (      final Exception e) {
        LOG.error(String.format(""String_Node_Str"",stubField.getName(),contract.getClass(),e));
      }
    }
 while ((clazz=clazz.getSuperclass()) != ElementaryOperator.class);
  }
}",0.9261693080788558
55427,"/** 
 * Sets the keyExpressions to the specified value.
 * @param keyExpressions the keyExpressions to set
 */
public void setKeyExpressions(int index,EvaluationExpression... keyExpressions){
  if (keyExpressions.length == 0)   throw new IllegalArgumentException(""String_Node_Str"");
  setKeyExpressions(index,Arrays.asList(keyExpressions));
}","/** 
 * Sets the keyExpressions of the given input to the specified value.
 * @param keyExpressions the keyExpressions to set
 */
public void setKeyExpressions(int index,EvaluationExpression... keyExpressions){
  if (keyExpressions.length == 0)   throw new IllegalArgumentException(""String_Node_Str"");
  setKeyExpressions(index,Arrays.asList(keyExpressions));
}",0.972972972972973
55428,"/** 
 * Converts a long to a byte array.
 * @param l the long variable to be converted
 * @param ba the byte array to store the result the of the conversion
 * @param offset the offset indicating at what position inside the byte array the result of the conversion shall be stored
 */
private static void longToByteArray(final long l,final byte[] ba,final int offset){
  for (int i=0; i < Long.SIZE; ++i) {
    final int shift=i << 3;
    ba[offset + Long.SIZE - 1 - i]=(byte)((l & (0xffL << shift)) >>> shift);
  }
}","/** 
 * Converts a long to a byte array.
 * @param l the long variable to be converted
 * @param ba the byte array to store the result the of the conversion
 * @param offset the offset indicating at what position inside the byte array the result of the conversion shall be stored
 */
private static void longToByteArray(final long l,final byte[] ba,final int offset){
  for (int i=0; i < SIZE_OF_LONG; ++i) {
    final int shift=i << 3;
    ba[offset + SIZE_OF_LONG - 1 - i]=(byte)((l & (0xffL << shift)) >>> shift);
  }
}",0.97495183044316
55429,"/** 
 * Converts the given byte array to a long.
 * @param ba the byte array to be converted
 * @param offset the offset indicating at which byte inside the array the conversion shall begin
 * @return the long variable
 */
private static long byteArrayToLong(final byte[] ba,final int offset){
  long l=0;
  for (int i=0; i < Long.SIZE; ++i) {
    l|=(ba[offset + Long.SIZE - 1 - i] & 0xffL) << (i << 3);
  }
  return l;
}","/** 
 * Converts the given byte array to a long.
 * @param ba the byte array to be converted
 * @param offset the offset indicating at which byte inside the array the conversion shall begin
 * @return the long variable
 */
private static long byteArrayToLong(final byte[] ba,final int offset){
  long l=0;
  for (int i=0; i < SIZE_OF_LONG; ++i) {
    l|=(ba[offset + SIZE_OF_LONG - 1 - i] & 0xffL) << (i << 3);
  }
  return l;
}",0.9694117647058824
55430,"/** 
 * {@inheritDoc}
 */
@Override public String toString(){
  final byte[] ba=new byte[SIZE];
  longToByteArray(this.lowerPart,ba,0);
  longToByteArray(this.upperPart,ba,Long.SIZE);
  return StringUtils.byteToHexString(ba);
}","/** 
 * {@inheritDoc}
 */
@Override public String toString(){
  final byte[] ba=new byte[SIZE];
  longToByteArray(this.lowerPart,ba,0);
  longToByteArray(this.upperPart,ba,SIZE_OF_LONG);
  return StringUtils.byteToHexString(ba);
}",0.9715536105032824
55431,"@Override protected boolean readBufferData(final ReadableByteChannel readableByteChannel) throws IOException {
  final ByteBuffer tempBuffer=getTempBuffer();
  if (!this.bufferDataSerializationStarted) {
    tempBuffer.clear();
    this.bufferDataSerializationStarted=true;
  }
  readableByteChannel.read(tempBuffer);
  if (tempBuffer.hasRemaining()) {
    return true;
  }
  final long offset=byteBufferToLong(tempBuffer);
  final Buffer fileBuffer=BufferFactory.createFromCheckpoint(getSizeOfBuffer(),offset,this.ownerID,this.fileBufferManager,this.distributed);
  setBuffer(fileBuffer);
  this.bufferDataSerializationStarted=false;
  return false;
}","/** 
 * {@inheritDoc}
 */
@Override protected boolean readBufferData(final ReadableByteChannel readableByteChannel) throws IOException {
  final ByteBuffer tempBuffer=getTempBuffer();
  if (!this.bufferDataSerializationStarted) {
    tempBuffer.clear();
    this.bufferDataSerializationStarted=true;
  }
  readableByteChannel.read(tempBuffer);
  if (tempBuffer.hasRemaining()) {
    return true;
  }
  final long offset=byteBufferToLong(tempBuffer);
  final Buffer fileBuffer=BufferFactory.createFromCheckpoint(getSizeOfBuffer(),offset,this.ownerID,this.fileBufferManager,this.distributed);
  setBuffer(fileBuffer);
  this.bufferDataSerializationStarted=false;
  return false;
}",0.9804511278195488
55432,"private long byteBufferToLong(final ByteBuffer byteBuffer) throws IOException {
  long l=0;
  if (Long.SIZE > byteBuffer.limit()) {
    throw new IOException(""String_Node_Str"" + byteBuffer.limit() + ""String_Node_Str"");
  }
  for (int i=0; i < Long.SIZE; ++i) {
    l|=(byteBuffer.get((Long.SIZE - 1) - i) & 0xffL) << (i << 3);
  }
  return l;
}","private long byteBufferToLong(final ByteBuffer byteBuffer) throws IOException {
  long l=0;
  if (SIZE_OF_LONG > byteBuffer.limit()) {
    throw new IOException(""String_Node_Str"" + byteBuffer.limit() + ""String_Node_Str"");
  }
  for (int i=0; i < SIZE_OF_LONG; ++i) {
    l|=(byteBuffer.get((SIZE_OF_LONG - 1) - i) & 0xffL) << (i << 3);
  }
  return l;
}",0.9440459110473458
55433,"private void longToByteBuffer(long longToSerialize,ByteBuffer byteBuffer) throws IOException {
  if (Long.SIZE > byteBuffer.capacity()) {
    throw new IOException(""String_Node_Str"" + byteBuffer.limit() + ""String_Node_Str""+ Long.SIZE+ ""String_Node_Str"");
  }
  byteBuffer.limit(Long.SIZE);
  for (int i=0; i < Long.SIZE; ++i) {
    final int shift=i << 3;
    byteBuffer.put((Long.SIZE - 1) - i,(byte)((longToSerialize & (0xffL << shift)) >>> shift));
  }
}","private void longToByteBuffer(long longToSerialize,ByteBuffer byteBuffer) throws IOException {
  if (SIZE_OF_LONG > byteBuffer.capacity()) {
    throw new IOException(""String_Node_Str"" + byteBuffer.limit() + ""String_Node_Str""+ SIZE_OF_LONG+ ""String_Node_Str"");
  }
  byteBuffer.limit(SIZE_OF_LONG);
  for (int i=0; i < SIZE_OF_LONG; ++i) {
    final int shift=i << 3;
    byteBuffer.put((SIZE_OF_LONG - 1) - i,(byte)((longToSerialize & (0xffL << shift)) >>> shift));
  }
}",0.8266953713670614
55434,"/** 
 * Creates the initial edges between the group vertices
 * @param vertexMap the temporary vertex map
 * @throws GraphConversionException if the initial wiring cannot be created
 */
private void createInitialGroupEdges(final HashMap<AbstractJobVertex,ExecutionVertex> vertexMap) throws GraphConversionException {
  Iterator<Map.Entry<AbstractJobVertex,ExecutionVertex>> it=vertexMap.entrySet().iterator();
  while (it.hasNext()) {
    final Map.Entry<AbstractJobVertex,ExecutionVertex> entry=it.next();
    final AbstractJobVertex sjv=entry.getKey();
    final ExecutionVertex sev=entry.getValue();
    final ExecutionGroupVertex sgv=sev.getGroupVertex();
    if (sjv.getNumberOfForwardConnections() != sgv.getEnvironment().getNumberOfOutputGates()) {
      throw new GraphConversionException(""String_Node_Str"" + sjv.getName() + ""String_Node_Str"");
    }
    if (sjv.getNumberOfBackwardConnections() != sgv.getEnvironment().getNumberOfInputGates()) {
      throw new GraphConversionException(""String_Node_Str"" + sjv.getName() + ""String_Node_Str"");
    }
    for (int i=0; i < sjv.getNumberOfForwardConnections(); ++i) {
      final boolean isBroadcast=sgv.getEnvironment().getOutputGate(i).isBroadcast();
      final JobEdge edge=sjv.getForwardConnection(i);
      final AbstractJobVertex tjv=edge.getConnectedVertex();
      final ExecutionVertex tev=vertexMap.get(tjv);
      final ExecutionGroupVertex tgv=tev.getGroupVertex();
      final ChannelType channelType=edge.getChannelType();
      final CompressionLevel compressionLevel=edge.getCompressionLevel();
      final DistributionPattern distributionPattern=edge.getDistributionPattern();
      final boolean userDefinedChannelType=(channelType != null);
      final boolean userDefinedCompressionLevel=(compressionLevel != null);
      final ExecutionGroupEdge groupEdge=sgv.wireTo(tgv,edge.getIndexOfInputGate(),i,channelType,userDefinedChannelType,compressionLevel,userDefinedCompressionLevel,distributionPattern,isBroadcast);
      final ExecutionGate outputGate=new ExecutionGate(new GateID(),sev,groupEdge,false);
      sev.insertOutputGate(i,outputGate);
      final ExecutionGate inputGate=new ExecutionGate(new GateID(),tev,groupEdge,true);
      tev.insertInputGate(edge.getIndexOfInputGate(),inputGate);
    }
  }
}","/** 
 * Creates the initial edges between the group vertices
 * @param vertexMap the temporary vertex map
 * @throws GraphConversionException if the initial wiring cannot be created
 */
private void createInitialGroupEdges(final HashMap<AbstractJobVertex,ExecutionVertex> vertexMap) throws GraphConversionException {
  Iterator<Map.Entry<AbstractJobVertex,ExecutionVertex>> it=vertexMap.entrySet().iterator();
  while (it.hasNext()) {
    final Map.Entry<AbstractJobVertex,ExecutionVertex> entry=it.next();
    final AbstractJobVertex sjv=entry.getKey();
    final ExecutionVertex sev=entry.getValue();
    final ExecutionGroupVertex sgv=sev.getGroupVertex();
    if (sjv.getNumberOfForwardConnections() != sgv.getEnvironment().getNumberOfOutputGates()) {
      throw new GraphConversionException(""String_Node_Str"" + sjv.getName() + ""String_Node_Str"");
    }
    if (sjv.getNumberOfBackwardConnections() != sgv.getEnvironment().getNumberOfInputGates()) {
      throw new GraphConversionException(""String_Node_Str"" + sjv.getName() + ""String_Node_Str"");
    }
    for (int i=0; i < sjv.getNumberOfForwardConnections(); ++i) {
      final boolean isBroadcast=sgv.getEnvironment().getOutputGate(i).isBroadcast();
      final JobEdge edge=sjv.getForwardConnection(i);
      final AbstractJobVertex tjv=edge.getConnectedVertex();
      final ExecutionVertex tev=vertexMap.get(tjv);
      final ExecutionGroupVertex tgv=tev.getGroupVertex();
      ChannelType channelType=edge.getChannelType();
      boolean userDefinedChannelType=true;
      if (channelType == null) {
        userDefinedChannelType=false;
        channelType=ChannelType.NETWORK;
      }
      CompressionLevel compressionLevel=edge.getCompressionLevel();
      boolean userDefinedCompressionLevel=true;
      if (compressionLevel == null) {
        userDefinedCompressionLevel=false;
        compressionLevel=CompressionLevel.NO_COMPRESSION;
      }
      final DistributionPattern distributionPattern=edge.getDistributionPattern();
      final ExecutionGroupEdge groupEdge=sgv.wireTo(tgv,edge.getIndexOfInputGate(),i,channelType,userDefinedChannelType,compressionLevel,userDefinedCompressionLevel,distributionPattern,isBroadcast);
      final ExecutionGate outputGate=new ExecutionGate(new GateID(),sev,groupEdge,false);
      sev.insertOutputGate(i,outputGate);
      final ExecutionGate inputGate=new ExecutionGate(new GateID(),tev,groupEdge,true);
      tev.insertInputGate(edge.getIndexOfInputGate(),inputGate);
    }
  }
}",0.8150627615062761
55435,"public void logBufferUtilization(){
  System.out.println(""String_Node_Str"");
  final Iterator<Map.Entry<InetSocketAddress,OutgoingConnection>> it=this.outgoingConnections.entrySet().iterator();
  while (it.hasNext()) {
    final Map.Entry<InetSocketAddress,OutgoingConnection> entry=it.next();
    System.out.println(""String_Node_Str"" + entry.getKey() + ""String_Node_Str""+ entry.getValue().getNumberOfQueuedWriteBuffers());
  }
}","public void logBufferUtilization(){
  System.out.println(""String_Node_Str"");
  final Iterator<Map.Entry<RemoteReceiver,OutgoingConnection>> it=this.outgoingConnections.entrySet().iterator();
  while (it.hasNext()) {
    final Map.Entry<RemoteReceiver,OutgoingConnection> entry=it.next();
    System.out.println(""String_Node_Str"" + entry.getKey() + ""String_Node_Str""+ entry.getValue().getNumberOfQueuedWriteBuffers());
  }
}",0.9272300469483568
55436,"/** 
 * {@inheritDoc}
 */
@Override public void bufferAvailable(){
synchronized (this.pendingReadEventSubscribeRequests) {
    this.pendingReadEventSubscribeRequests.add(this.canceledKey);
  }
}","/** 
 * {@inheritDoc}
 */
@Override public void bufferAvailable(){
synchronized (this.pendingReadEventSubscribeRequests) {
    this.pendingReadEventSubscribeRequests.add(this.key);
  }
}",0.9736842105263158
55437,"private IncomingConnectionBufferAvailListener(final Queue<SelectionKey> pendingReadEventSubscribeRequests,final SelectionKey canceledKey){
  this.pendingReadEventSubscribeRequests=pendingReadEventSubscribeRequests;
  this.canceledKey=canceledKey;
}","private IncomingConnectionBufferAvailListener(final Queue<SelectionKey> pendingReadEventSubscribeRequests,final SelectionKey key){
  this.pendingReadEventSubscribeRequests=pendingReadEventSubscribeRequests;
  this.key=key;
}",0.9364406779661016
55438,"private void doRead(SelectionKey key){
  final IncomingConnection incomingConnection=(IncomingConnection)key.attachment();
  try {
    incomingConnection.read();
  }
 catch (  EOFException eof) {
    if (incomingConnection.isCloseUnexpected()) {
      final SocketChannel socketChannel=(SocketChannel)key.channel();
      LOG.error(""String_Node_Str"" + socketChannel.socket().getRemoteSocketAddress() + ""String_Node_Str"");
      incomingConnection.reportTransmissionProblem(key,eof);
    }
 else {
      incomingConnection.closeConnection(key);
    }
  }
catch (  IOException ioe) {
    incomingConnection.reportTransmissionProblem(key,ioe);
  }
catch (  InterruptedException e) {
  }
catch (  NoBufferAvailableException e) {
    key.cancel();
    final BufferAvailabilityListener bal=new IncomingConnectionBufferAvailListener(this.pendingReadEventSubscribeRequests,key);
    if (!e.getBufferProvider().registerBufferAvailabilityListener(bal)) {
      final SocketChannel socketChannel=(SocketChannel)key.channel();
      try {
        final SelectionKey newKey=socketChannel.register(this.selector,SelectionKey.OP_READ);
        newKey.attach(incomingConnection);
      }
 catch (      ClosedChannelException e1) {
        incomingConnection.reportTransmissionProblem(key,e1);
      }
    }
  }
}","private void doRead(SelectionKey key){
  final IncomingConnection incomingConnection=(IncomingConnection)key.attachment();
  try {
    incomingConnection.read();
  }
 catch (  EOFException eof) {
    if (incomingConnection.isCloseUnexpected()) {
      final SocketChannel socketChannel=(SocketChannel)key.channel();
      LOG.error(""String_Node_Str"" + socketChannel.socket().getRemoteSocketAddress() + ""String_Node_Str"");
      incomingConnection.reportTransmissionProblem(key,eof);
    }
 else {
      incomingConnection.closeConnection(key);
    }
  }
catch (  IOException ioe) {
    incomingConnection.reportTransmissionProblem(key,ioe);
  }
catch (  InterruptedException e) {
  }
catch (  NoBufferAvailableException e) {
    final SocketChannel socketChannel=(SocketChannel)key.channel();
    try {
      final SelectionKey newKey=socketChannel.register(this.selector,0);
      newKey.attach(incomingConnection);
    }
 catch (    ClosedChannelException e1) {
      incomingConnection.reportTransmissionProblem(key,e1);
    }
    final BufferAvailabilityListener bal=new IncomingConnectionBufferAvailListener(this.pendingReadEventSubscribeRequests,key);
    if (!e.getBufferProvider().registerBufferAvailabilityListener(bal)) {
      try {
        final SelectionKey newKey=socketChannel.register(this.selector,SelectionKey.OP_READ);
        newKey.attach(incomingConnection);
      }
 catch (      ClosedChannelException e1) {
        incomingConnection.reportTransmissionProblem(key,e1);
      }
    }
  }
}",0.8672125311498754
55439,"@Override public void run(){
  while (!this.isInterrupted()) {
synchronized (this.pendingReadEventSubscribeRequests) {
      while (!this.pendingReadEventSubscribeRequests.isEmpty()) {
        final SelectionKey canceledKey=this.pendingReadEventSubscribeRequests.poll();
        final IncomingConnection incomingConnection=(IncomingConnection)canceledKey.attachment();
        final SocketChannel socketChannel=(SocketChannel)canceledKey.channel();
        try {
          final SelectionKey newKey=socketChannel.register(this.selector,SelectionKey.OP_READ);
          newKey.attach(incomingConnection);
        }
 catch (        ClosedChannelException e) {
          incomingConnection.reportTransmissionProblem(canceledKey,e);
        }
      }
    }
    try {
      this.selector.select(500);
    }
 catch (    IOException e) {
      LOG.error(e);
    }
    final Iterator<SelectionKey> iter=this.selector.selectedKeys().iterator();
    while (iter.hasNext()) {
      final SelectionKey key=iter.next();
      iter.remove();
      if (key.isValid()) {
        if (key.isReadable()) {
          doRead(key);
        }
 else         if (key.isAcceptable()) {
          doAccept(key);
        }
 else {
          LOG.error(""String_Node_Str"" + key);
        }
      }
 else {
        LOG.error(""String_Node_Str"" + key);
      }
    }
  }
  if (this.listeningSocket != null) {
    try {
      this.listeningSocket.close();
    }
 catch (    IOException ioe) {
      LOG.debug(ioe);
    }
  }
  try {
    this.selector.close();
  }
 catch (  IOException ioe) {
    LOG.debug(StringUtils.stringifyException(ioe));
  }
}","@Override public void run(){
  while (!this.isInterrupted()) {
synchronized (this.pendingReadEventSubscribeRequests) {
      while (!this.pendingReadEventSubscribeRequests.isEmpty()) {
        final SelectionKey key=this.pendingReadEventSubscribeRequests.poll();
        final IncomingConnection incomingConnection=(IncomingConnection)key.attachment();
        final SocketChannel socketChannel=(SocketChannel)key.channel();
        try {
          final SelectionKey newKey=socketChannel.register(this.selector,SelectionKey.OP_READ);
          newKey.attach(incomingConnection);
        }
 catch (        ClosedChannelException e) {
          incomingConnection.reportTransmissionProblem(key,e);
        }
      }
    }
    try {
      this.selector.select(500);
    }
 catch (    IOException e) {
      LOG.error(e);
    }
    final Iterator<SelectionKey> iter=this.selector.selectedKeys().iterator();
    while (iter.hasNext()) {
      final SelectionKey key=iter.next();
      iter.remove();
      if (key.isValid()) {
        if (key.isReadable()) {
          doRead(key);
        }
 else         if (key.isAcceptable()) {
          doAccept(key);
        }
 else {
          LOG.error(""String_Node_Str"" + key);
        }
      }
 else {
        LOG.error(""String_Node_Str"" + key);
      }
    }
  }
  if (this.listeningSocket != null) {
    try {
      this.listeningSocket.close();
    }
 catch (    IOException ioe) {
      LOG.debug(ioe);
    }
  }
  try {
    this.selector.close();
  }
 catch (  IOException ioe) {
    LOG.debug(StringUtils.stringifyException(ioe));
  }
}",0.987492182614134
55440,"/** 
 * Removes the checkpoint of the vertex with the given ID. All files contained in the checkpoint are deleted.
 * @param vertexID the vertex whose checkpoint shall be removed
 */
public static void removeCheckpoint(final ExecutionVertexID vertexID){
  final Path localChPath=getLocalCheckpointPath();
  try {
    if (!removeCheckpointMetaData(new Path(localChPath + Path.SEPARATOR + METADATA_PREFIX+ ""String_Node_Str""+ vertexID))) {
      final Path distributedChPath=getDistributedCheckpointPath();
      if (distributedChPath != null) {
        removeCheckpointMetaData(new Path(distributedChPath + Path.SEPARATOR + METADATA_PREFIX+ ""String_Node_Str""+ vertexID));
      }
    }
    FileBufferManager.deleteFile(vertexID);
  }
 catch (  IOException e) {
    e.printStackTrace();
  }
}","/** 
 * Removes the checkpoint of the vertex with the given ID. All files contained in the checkpoint are deleted.
 * @param vertexID the vertex whose checkpoint shall be removed
 */
public static void removeCheckpoint(final ExecutionVertexID vertexID){
  final Path localChPath=getLocalCheckpointPath();
  try {
    if (!removeCheckpointMetaData(new Path(localChPath + Path.SEPARATOR + METADATA_PREFIX+ ""String_Node_Str""+ vertexID))) {
      final Path distributedChPath=getDistributedCheckpointPath();
      if (distributedChPath != null && allowDistributedCheckpoints()) {
        removeCheckpointMetaData(new Path(distributedChPath + Path.SEPARATOR + METADATA_PREFIX+ ""String_Node_Str""+ vertexID));
      }
    }
    FileBufferManager.deleteFile(vertexID);
  }
 catch (  IOException e) {
    e.printStackTrace();
  }
}",0.9795158286778398
55441,"private static boolean checkForCheckpoint(final ExecutionVertexID vertexID,final String suffix){
  try {
    final Path local=new Path(getLocalCheckpointPath() + Path.SEPARATOR + METADATA_PREFIX+ ""String_Node_Str""+ vertexID+ suffix);
    final FileSystem localFs=local.getFileSystem();
    if (localFs.exists(local)) {
      return true;
    }
    final Path distributedCheckpointPath=getDistributedCheckpointPath();
    if (distributedCheckpointPath == null) {
      return false;
    }
    final Path distributed=new Path(distributedCheckpointPath + Path.SEPARATOR + METADATA_PREFIX+ ""String_Node_Str""+ vertexID+ suffix);
    final FileSystem distFs=distributed.getFileSystem();
    return distFs.exists(distributed);
  }
 catch (  IOException ioe) {
    LOG.warn(StringUtils.stringifyException(ioe));
  }
  return false;
}","private static boolean checkForCheckpoint(final ExecutionVertexID vertexID,final String suffix){
  try {
    final Path local=new Path(getLocalCheckpointPath() + Path.SEPARATOR + METADATA_PREFIX+ ""String_Node_Str""+ vertexID+ suffix);
    final FileSystem localFs=local.getFileSystem();
    if (localFs.exists(local)) {
      return true;
    }
    if (!allowDistributedCheckpoints()) {
      return false;
    }
    final Path distributedCheckpointPath=getDistributedCheckpointPath();
    if (distributedCheckpointPath == null) {
      return false;
    }
    final Path distributed=new Path(distributedCheckpointPath + Path.SEPARATOR + METADATA_PREFIX+ ""String_Node_Str""+ vertexID+ suffix);
    final FileSystem distFs=distributed.getFileSystem();
    return distFs.exists(distributed);
  }
 catch (  IOException ioe) {
    LOG.warn(StringUtils.stringifyException(ioe));
  }
  return false;
}",0.960419091967404
55442,"WriteThread(final FileBufferManager fileBufferManager,final ExecutionVertexID vertexID,final int numberOfConnectedChannels){
  super(""String_Node_Str"" + vertexID);
  this.fileBufferManager=fileBufferManager;
  this.vertexID=vertexID;
  this.numberOfConnectedChannels=numberOfConnectedChannels;
  this.queuedEnvelopes=new ArrayBlockingQueue<TransferEnvelope>(256);
  final boolean dist=CheckpointUtils.createDistributedCheckpoint();
  if (dist) {
    final Path p=CheckpointUtils.getDistributedCheckpointPath();
    if (p == null) {
      LOG.error(""String_Node_Str"");
      this.checkpointPath=CheckpointUtils.getLocalCheckpointPath();
      this.distributed=false;
    }
 else {
      this.checkpointPath=p;
      this.distributed=true;
    }
  }
 else {
    this.checkpointPath=CheckpointUtils.getLocalCheckpointPath();
    this.distributed=false;
  }
}","WriteThread(final FileBufferManager fileBufferManager,final ExecutionVertexID vertexID,final int numberOfConnectedChannels){
  super(""String_Node_Str"" + vertexID);
  this.fileBufferManager=fileBufferManager;
  this.vertexID=vertexID;
  this.numberOfConnectedChannels=numberOfConnectedChannels;
  this.queuedEnvelopes=new ArrayBlockingQueue<TransferEnvelope>(256);
  final boolean dist=CheckpointUtils.allowDistributedCheckpoints();
  if (dist) {
    final Path p=CheckpointUtils.getDistributedCheckpointPath();
    if (p == null) {
      LOG.error(""String_Node_Str"");
      this.checkpointPath=CheckpointUtils.getLocalCheckpointPath();
      this.distributed=false;
    }
 else {
      this.checkpointPath=p;
      this.distributed=true;
    }
  }
 else {
    this.checkpointPath=CheckpointUtils.getLocalCheckpointPath();
    this.distributed=false;
  }
}",0.9929824561403509
55443,"public static boolean deleteFile(final AbstractID ownerID){
  final FileBufferManager fbm=getInstance();
  final File f=fbm.constructLocalFile(ownerID);
  if (f.exists()) {
    System.out.println(""String_Node_Str"" + f);
    f.delete();
    return true;
  }
  if (fbm.distributedTempPath != null) {
    final Path p=fbm.constructDistributedPath(ownerID);
    try {
      final FileSystem fs=p.getFileSystem();
      if (fs.exists(p)) {
        fs.delete(p,false);
        return true;
      }
    }
 catch (    IOException ioe) {
      if (LOG.isDebugEnabled()) {
        LOG.debug(StringUtils.stringifyException(ioe));
      }
    }
  }
  return false;
}","public static boolean deleteFile(final AbstractID ownerID){
  final FileBufferManager fbm=getInstance();
  final File f=fbm.constructLocalFile(ownerID);
  if (f.exists()) {
    f.delete();
    return true;
  }
  if (fbm.distributedTempPath != null) {
    final Path p=fbm.constructDistributedPath(ownerID);
    try {
      final FileSystem fs=p.getFileSystem();
      if (fs.exists(p)) {
        fs.delete(p,false);
        return true;
      }
    }
 catch (    IOException ioe) {
      if (LOG.isDebugEnabled()) {
        LOG.debug(StringUtils.stringifyException(ioe));
      }
    }
  }
  return false;
}",0.9627279936558288
55444,"/** 
 * Constructs a new file buffer manager object.
 */
private FileBufferManager(){
  this.tmpDirs=GlobalConfiguration.getString(ConfigConstants.TASK_MANAGER_TMP_DIR_KEY,ConfigConstants.DEFAULT_TASK_MANAGER_TMP_PATH).split(""String_Node_Str"");
  for (int i=0; i < this.tmpDirs.length; i++) {
    File f=new File(this.tmpDirs[i]);
    if (!(f.exists() && f.isDirectory() && f.canWrite())) {
      LOG.error(""String_Node_Str"" + f.getAbsolutePath() + ""String_Node_Str""+ ""String_Node_Str""+ ConfigConstants.DEFAULT_TASK_MANAGER_TMP_PATH);
      this.tmpDirs[i]=ConfigConstants.DEFAULT_TASK_MANAGER_TMP_PATH;
    }
    this.tmpDirs[i]=this.tmpDirs[i] + File.separator + FILE_BUFFER_PREFIX;
  }
  this.bufferSize=GlobalConfiguration.getInteger(""String_Node_Str"",64 * 1024);
  this.fileMap=new ConcurrentHashMap<AbstractID,ChannelWithAccessInfo>(2048,0.8f,64);
  this.distributedTempPath=CheckpointUtils.getDistributedCheckpointPath();
  FileSystem distFS=null;
  if (this.distributedTempPath != null) {
    try {
      distFS=this.distributedTempPath.getFileSystem();
      if (!distFS.exists(this.distributedTempPath)) {
        distFS.mkdirs(this.distributedTempPath);
      }
    }
 catch (    IOException e) {
      LOG.error(StringUtils.stringifyException(e));
    }
  }
  this.distributedFileSystem=distFS;
}","/** 
 * Constructs a new file buffer manager object.
 */
private FileBufferManager(){
  this.tmpDirs=GlobalConfiguration.getString(ConfigConstants.TASK_MANAGER_TMP_DIR_KEY,ConfigConstants.DEFAULT_TASK_MANAGER_TMP_PATH).split(""String_Node_Str"");
  for (int i=0; i < this.tmpDirs.length; i++) {
    File f=new File(this.tmpDirs[i]);
    if (!(f.exists() && f.isDirectory() && f.canWrite())) {
      LOG.error(""String_Node_Str"" + f.getAbsolutePath() + ""String_Node_Str""+ ""String_Node_Str""+ ConfigConstants.DEFAULT_TASK_MANAGER_TMP_PATH);
      this.tmpDirs[i]=ConfigConstants.DEFAULT_TASK_MANAGER_TMP_PATH;
    }
    this.tmpDirs[i]=this.tmpDirs[i] + File.separator + FILE_BUFFER_PREFIX;
  }
  this.bufferSize=GlobalConfiguration.getInteger(""String_Node_Str"",64 * 1024);
  this.fileMap=new ConcurrentHashMap<AbstractID,ChannelWithAccessInfo>(2048,0.8f,64);
  this.distributedTempPath=CheckpointUtils.getDistributedCheckpointPath();
  FileSystem distFS=null;
  if (this.distributedTempPath != null && CheckpointUtils.allowDistributedCheckpoints()) {
    try {
      distFS=this.distributedTempPath.getFileSystem();
      if (!distFS.exists(this.distributedTempPath)) {
        distFS.mkdirs(this.distributedTempPath);
      }
    }
 catch (    IOException e) {
      LOG.error(StringUtils.stringifyException(e));
    }
  }
  this.distributedFileSystem=distFS;
}",0.9816135084427768
55445,"@Override public void requestInstance(JobID jobID,Configuration conf,Map<InstanceType,Integer> instanceMap,List<String> splitAffinityList) throws InstanceException {
  this.instanceListener.resourceAllocated(jobID,this.allocatedResource);
}","@Override public void requestInstance(final JobID jobID,Configuration conf,Map<InstanceType,Integer> instanceMap,List<String> splitAffinityList) throws InstanceException {
  ConcurrentUtil.invokeLater(new Runnable(){
    @Override public void run(){
      MockInstanceManager.this.instanceListener.resourceAllocated(jobID,getAllocatedResource());
    }
  }
);
}",0.778702163061564
55446,"private void assignMemory(final TaskConfig config,final int memSize){
  config.setMemorySize(((long)memSize) * 1024L * 1024L);
  config.setNumFilehandles(DEFAUTL_MERGE_FACTOR);
}","private void assignMemory(final TaskConfig config,final int memSize){
  config.setMemorySize(memSize * 1024L * 1024L);
  config.setNumFilehandles(DEFAUTL_MERGE_FACTOR);
}",0.9770114942528736
55447,"/** 
 * {@inheritDoc}
 */
@Override public void write(final DataOutput out) throws IOException {
  final InetAddress ia=this.connectionAddress.getAddress();
  out.writeInt(ia.getAddress().length);
  out.write(ia.getAddress());
  out.write(this.connectionAddress.getPort());
  out.writeInt(this.connectionIndex);
}","/** 
 * {@inheritDoc}
 */
@Override public void write(final DataOutput out) throws IOException {
  final InetAddress ia=this.connectionAddress.getAddress();
  out.writeInt(ia.getAddress().length);
  out.write(ia.getAddress());
  out.writeInt(this.connectionAddress.getPort());
  out.writeInt(this.connectionIndex);
}",0.9952305246422892
55448,"ReplayTaskContext(final ReplayTask task,final TransferEnvelopeDispatcher transferEnvelopeDispatcher,final LocalBufferPoolOwner previousBufferPoolOwner,final int numberOfChannels){
  this.task=task;
  this.transferEnvelopeDispatcher=transferEnvelopeDispatcher;
  if (previousBufferPoolOwner == null) {
    this.localBufferPool=new LocalBufferPool(1,false,this);
  }
 else {
    if (!(previousBufferPoolOwner instanceof RuntimeTaskContext)) {
      throw new IllegalStateException(""String_Node_Str"");
    }
    final RuntimeTaskContext rtc=(RuntimeTaskContext)previousBufferPoolOwner;
    this.localBufferPool=rtc.getLocalBufferPool();
  }
  this.numberOfChannels=numberOfChannels;
}","ReplayTaskContext(final ReplayTask task,final TransferEnvelopeDispatcher transferEnvelopeDispatcher,final LocalBufferPoolOwner previousBufferPoolOwner,final int numberOfChannels){
  this.task=task;
  this.transferEnvelopeDispatcher=transferEnvelopeDispatcher;
  this.previousBufferPoolOwner=previousBufferPoolOwner;
  if (previousBufferPoolOwner == null) {
    this.localBufferPool=new LocalBufferPool(1,false,this);
  }
 else {
    if (!(previousBufferPoolOwner instanceof RuntimeTaskContext)) {
      throw new IllegalStateException(""String_Node_Str"");
    }
    final RuntimeTaskContext rtc=(RuntimeTaskContext)previousBufferPoolOwner;
    this.localBufferPool=rtc.getLocalBufferPool();
  }
  this.numberOfChannels=numberOfChannels;
}",0.9605077574047954
55449,"/** 
 * {@inheritDoc}
 */
@Override public void clearLocalBufferPool(){
  this.localBufferPool.destroy();
}","/** 
 * {@inheritDoc}
 */
@Override public void clearLocalBufferPool(){
  if (this.previousBufferPoolOwner != null) {
    this.previousBufferPoolOwner.clearLocalBufferPool();
  }
 else {
    this.localBufferPool.destroy();
  }
}",0.6328358208955224
55450,"@Override public String toString(){
  return ""String_Node_Str"" + this.cluster1 + ""String_Node_Str""+ this.cluster2+ ""String_Node_Str""+ this.distance+ ""String_Node_Str"";
}","@Override public String toString(){
  return ""String_Node_Str"" + clusters.size() + ""String_Node_Str""+ distancedPairs+ ""String_Node_Str"";
}",0.8078175895765473
55451,"private void cluster(){
  while (this.queue.getNumberOfClusters() > 1) {
    final ClusterPair pair=this.queue.getFirstElement();
    final HierarchicalCluster cluster1=pair.getCluster1();
    final HierarchicalCluster cluster2=pair.getCluster2();
    final HierarchicalCluster mergedCluster=new MergedCluster(cluster1,cluster2,this.createNewId());
    this.queue.removeCluster(cluster1);
    this.queue.removeCluster(cluster2);
    final boolean makeFinal=this.canBeFinal(mergedCluster);
    mergedCluster.makeFinal(makeFinal);
    if (makeFinal)     this.queue.add(mergedCluster);
 else     for (    final HierarchicalCluster child : mergedCluster.getChildren())     this.clusters.add(child);
  }
  this.clusters.addAll(this.queue.getClusters());
  this.queue=null;
}","private void cluster(){
  while (this.queue.getNumberOfClusters() > 1) {
    final ClusterPair pair=this.queue.getFirstElement();
    if (pair.getDistance() > maxRadius) {
      break;
    }
    final HierarchicalCluster cluster1=pair.getCluster1();
    final HierarchicalCluster cluster2=pair.getCluster2();
    final HierarchicalCluster mergedCluster=new MergedCluster(cluster1,cluster2,this.createNewId());
    this.queue.removeCluster(cluster1);
    this.queue.removeCluster(cluster2);
    final boolean makeFinal=this.canBeFinal(mergedCluster);
    mergedCluster.makeFinal(makeFinal);
    if (makeFinal)     this.queue.add(mergedCluster);
 else     for (    final HierarchicalCluster child : mergedCluster.getChildren())     this.clusters.add(child);
  }
  this.clusters.addAll(this.queue.getClusters());
  this.queue=null;
}",0.9618511569731082
55452,"private void emit(final HierarchicalCluster cluster,final JsonCollector out){
  if (cluster.isFinal()) {
    this.pointsNode.clear();
    for (    final Point point : cluster.getPoints())     this.pointsNode.add(point.write((IJsonNode)null));
    this.idNode.setValue(cluster.getId());
    JsonUtil2.copy(this.pointsNode,cluster.getPoints());
    ClusterNodes.write(this.outputNode,this.idNode,this.clustroidNode,this.pointsNode);
    out.collect(this.outputNode);
  }
 else   for (  final HierarchicalCluster child : cluster.getChildren())   this.emit(child,out);
}","private void emit(final HierarchicalCluster cluster,final JsonCollector out){
  if (cluster.isFinal()) {
    this.pointsNode.clear();
    for (    final Point point : cluster.getPoints())     this.pointsNode.add(point.write((IJsonNode)null));
    this.idNode.setValue(cluster.getId());
    cluster.getClustroid().write(this.clustroidNode);
    ClusterNodes.write(this.outputNode,this.idNode,this.clustroidNode,this.pointsNode);
    out.collect(this.outputNode);
  }
 else   for (  final HierarchicalCluster child : cluster.getChildren())   this.emit(child,out);
}",0.5473870682019486
55453,"public static void annotate(final ObjectNode node,final IntNode annotation,final IJsonNode annotatee){
  node.put(ANNOTATION,annotation);
  node.put(ANNOTATEE,annotatee);
}","public static void annotate(final ObjectNode node,String annotationKey,final IntNode annotation,String annotateeKey,final IJsonNode annotatee){
  node.put(annotationKey,annotation);
  node.put(annotateeKey,annotatee);
}",0.782608695652174
55454,"public static void copy(final IArrayNode array,final JsonSerializable... values){
  array.clear();
  for (  final JsonSerializable value : values)   array.add(value.write(null));
}","public static void copy(final IArrayNode array,final Iterable<JsonSerializable> values){
  array.clear();
  for (  final JsonSerializable value : values)   array.add(value.write(null));
}",0.9645776566757494
55455,"@Test public void testSequentialClustering(){
  final SequentialClustering clustering=new SequentialClustering();
  clustering.setMaxRadius(501);
  clustering.setMaxSize(50);
  final SopremoTestPlan plan=new SopremoTestPlan(clustering);
  final Point p1=new Point(""String_Node_Str"",Arrays.asList(""String_Node_Str"",""String_Node_Str"",""String_Node_Str""));
  final Point p2=new Point(""String_Node_Str"",Arrays.asList(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""));
  final Point p3=new Point(""String_Node_Str"",Arrays.asList(""String_Node_Str"",""String_Node_Str"",""String_Node_Str""));
  final Point p4=new Point(""String_Node_Str"",Arrays.asList(""String_Node_Str"",""String_Node_Str"",""String_Node_Str""));
  plan.getInput(0).add(this.createAnnotatedPoint(p1)).add(this.createAnnotatedPoint(p2)).add(this.createAnnotatedPoint(p3)).add(this.createAnnotatedPoint(p4));
  plan.run();
  int count=0;
  for (  final IJsonNode node : plan.getActualOutput(0)) {
    System.out.println(node);
    final ObjectNode cluster=(ObjectNode)node;
    Assert.assertEquals(2,((IArrayNode)cluster.get(""String_Node_Str"")).size());
    count++;
  }
  Assert.assertEquals(2,count);
}","@Test public void testSequentialClustering() throws IOException {
  final SequentialClustering clustering=new SequentialClustering();
  clustering.setMaxRadius(200);
  clustering.setMaxSize(200);
  final SopremoTestPlan plan=new SopremoTestPlan(clustering);
  String testPointsJsonString=""String_Node_Str"";
  JsonParser parser=new JsonParser(testPointsJsonString);
  while (!parser.checkEnd()) {
    plan.getInput(0).add(createAnnotatedPoint(parser.readValueAsTree()));
  }
  plan.run();
  int count=0;
  for (  final IJsonNode node : plan.getActualOutput(0)) {
    final ObjectNode cluster=(ObjectNode)node;
    System.out.println(cluster);
    count++;
  }
}",0.4667393675027262
55456,"private IJsonNode createAnnotatedPoint(final Point point){
  final ObjectNode annotatedValue=new ObjectNode();
  AnnotatorNodes.annotate(annotatedValue,Annotator.ANNOTATION_VALUE,point.write(null));
  return annotatedValue;
}","private IJsonNode createAnnotatedPoint(final IJsonNode pointNode){
  final ObjectNode annotatedValue=new ObjectNode();
  AnnotatorNodes.annotate(annotatedValue,Annotator.ANNOTATION_VALUE,pointNode);
  return annotatedValue;
}",0.9244444444444444
55457,"/** 
 * {@inheritDoc}
 */
@Override public Buffer requestEmptyBuffer(final int minimumSizeOfBuffer) throws IOException {
  throw new IllegalStateException(""String_Node_Str"");
}","/** 
 * {@inheritDoc}
 */
@Override public Buffer requestEmptyBuffer(final int minimumSizeOfBuffer) throws IOException {
  return this.inputGateContext.requestEmptyBuffer(minimumSizeOfBuffer);
}",0.7675675675675676
55458,"/** 
 * {@inheritDoc}
 */
@Override protected boolean readBufferData(final ReadableByteChannel readableByteChannel) throws IOException {
  if (getBuffer() == null) {
    try {
      if (!getDeserializedJobID().equals(this.lastDeserializedJobID) || !getDeserializedSourceID().equals(this.lastDeserializedSourceID)) {
        this.bufferProvider=this.bufferProviderBroker.getBufferProvider(getDeserializedJobID(),getDeserializedSourceID());
        this.lastDeserializedJobID=getDeserializedJobID();
        this.lastDeserializedSourceID=getDeserializedSourceID();
      }
      setBuffer(this.bufferProvider.requestEmptyBufferBlocking(getSizeOfBuffer()));
      if (getBuffer() == null) {
        Thread.sleep(100);
        return true;
      }
    }
 catch (    InterruptedException e) {
      return true;
    }
  }
 else {
    final Buffer buffer=getBuffer();
    final int bytesWritten=buffer.write(readableByteChannel);
    if (!buffer.hasRemaining()) {
      buffer.finishWritePhase();
      return false;
    }
 else {
      if (bytesWritten == -1) {
        throw new IOException(""String_Node_Str"" + buffer.remaining() + ""String_Node_Str"");
      }
    }
  }
  return true;
}","/** 
 * {@inheritDoc}
 */
@Override protected boolean readBufferData(final ReadableByteChannel readableByteChannel) throws IOException {
  if (getBuffer() == null) {
    try {
      if (!getDeserializedJobID().equals(this.lastDeserializedJobID) || !getDeserializedSourceID().equals(this.lastDeserializedSourceID)) {
        this.bufferProvider=this.bufferProviderBroker.getBufferProvider(getDeserializedJobID(),getDeserializedSourceID());
        this.lastDeserializedJobID=getDeserializedJobID();
        this.lastDeserializedSourceID=getDeserializedSourceID();
      }
      final Buffer buf=this.bufferProvider.requestEmptyBuffer(getSizeOfBuffer());
      if (buf == null) {
        Thread.sleep(1);
        return true;
      }
      setBuffer(buf);
    }
 catch (    InterruptedException e) {
      return true;
    }
  }
 else {
    final Buffer buffer=getBuffer();
    final int bytesWritten=buffer.write(readableByteChannel);
    if (!buffer.hasRemaining()) {
      buffer.finishWritePhase();
      return false;
    }
 else {
      if (bytesWritten == -1) {
        throw new IOException(""String_Node_Str"" + buffer.remaining() + ""String_Node_Str"");
      }
    }
  }
  return true;
}",0.9587194608256108
55459,"/** 
 * {@inheritDoc}
 */
@Override public void invoke() throws Exception {
  if (LOG.isInfoEnabled())   LOG.info(getLogString(""String_Node_Str""));
  try {
    AbstractPactTask.openChainedTasks(this.chainedTasks,this);
    final Iterator<InputSplit> splitIterator=getInputSplits();
    while (!this.taskCanceled && splitIterator.hasNext()) {
      final InputSplit split=splitIterator.next();
      if (LOG.isDebugEnabled())       LOG.debug(getLogString(""String_Node_Str"" + split.toString()));
      final InputFormat<OT,InputSplit> format=this.format;
      format.open(split);
      if (LOG.isDebugEnabled())       LOG.debug(getLogString(""String_Node_Str"" + split.toString()));
      final OT record=this.serializer.createInstance();
      if (record.getClass() == PactRecord.class) {
        final PactRecord pactRecord=(PactRecord)record;
        @SuppressWarnings(""String_Node_Str"") final InputFormat<PactRecord,InputSplit> inFormat=(InputFormat<PactRecord,InputSplit>)format;
        if (this.output instanceof PactRecordOutputCollector) {
          final PactRecordOutputCollector output=(PactRecordOutputCollector)this.output;
          while (!this.taskCanceled && !inFormat.reachedEnd()) {
            if (inFormat.nextRecord(pactRecord)) {
              output.collect(pactRecord);
            }
          }
        }
 else         if (this.output instanceof ChainedMapTask) {
          @SuppressWarnings(""String_Node_Str"") final ChainedMapTask<PactRecord,?> output=(ChainedMapTask<PactRecord,?>)this.output;
          while (!this.taskCanceled && !inFormat.reachedEnd()) {
            if (inFormat.nextRecord(pactRecord)) {
              output.collect(pactRecord);
            }
          }
        }
      }
 else {
        if (this.output instanceof OutputCollector) {
          final OutputCollector<OT> output=(OutputCollector<OT>)this.output;
          while (!this.taskCanceled && !format.reachedEnd()) {
            if (format.nextRecord(record)) {
              output.collect(record);
            }
          }
        }
 else         if (this.output instanceof ChainedMapTask) {
          @SuppressWarnings(""String_Node_Str"") final ChainedMapTask<OT,?> output=(ChainedMapTask<OT,?>)this.output;
          while (!this.taskCanceled && !format.reachedEnd()) {
            if (format.nextRecord(record)) {
              output.collect(record);
            }
          }
        }
 else {
          final Collector<OT> output=this.output;
          while (!this.taskCanceled && !format.reachedEnd()) {
            if (format.nextRecord(record)) {
              output.collect(record);
            }
          }
        }
      }
      if (!this.taskCanceled) {
        if (LOG.isDebugEnabled())         LOG.debug(getLogString(""String_Node_Str"" + split.toString()));
        format.close();
      }
    }
    this.output.close();
    AbstractPactTask.closeChainedTasks(this.chainedTasks,this);
  }
 catch (  Exception ex) {
    try {
      this.format.close();
    }
 catch (    Throwable t) {
    }
    AbstractPactTask.cancelChainedTasks(this.chainedTasks);
    if (!this.taskCanceled) {
      AbstractPactTask.logAndThrowException(ex,this);
    }
  }
  if (!this.taskCanceled) {
    if (LOG.isInfoEnabled())     LOG.info(getLogString(""String_Node_Str""));
  }
 else {
    if (LOG.isWarnEnabled())     LOG.warn(getLogString(""String_Node_Str""));
  }
}","/** 
 * {@inheritDoc}
 */
@Override public void invoke() throws Exception {
  if (LOG.isInfoEnabled())   LOG.info(getLogString(""String_Node_Str""));
  try {
    AbstractPactTask.openChainedTasks(this.chainedTasks,this);
    final Iterator<InputSplit> splitIterator=getInputSplits();
    while (!this.taskCanceled && splitIterator.hasNext()) {
      final InputSplit split=splitIterator.next();
      if (LOG.isDebugEnabled())       LOG.debug(getLogString(""String_Node_Str"" + split.toString()));
      final InputFormat<OT,InputSplit> format=this.format;
      format.open(split);
      if (LOG.isDebugEnabled())       LOG.debug(getLogString(""String_Node_Str"" + split.toString()));
      final OT record=this.serializer.createInstance();
      if (record.getClass() == PactRecord.class) {
        final PactRecord pactRecord=(PactRecord)record;
        @SuppressWarnings(""String_Node_Str"") final InputFormat<PactRecord,InputSplit> inFormat=(InputFormat<PactRecord,InputSplit>)format;
        if (this.output instanceof PactRecordOutputCollector) {
          final PactRecordOutputCollector output=(PactRecordOutputCollector)this.output;
          while (!this.taskCanceled && !inFormat.reachedEnd()) {
            if (inFormat.nextRecord(pactRecord)) {
              output.collect(pactRecord);
            }
          }
        }
 else         if (this.output instanceof ChainedMapTask) {
          @SuppressWarnings(""String_Node_Str"") final ChainedMapTask<PactRecord,?> output=(ChainedMapTask<PactRecord,?>)this.output;
          while (!this.taskCanceled && !inFormat.reachedEnd()) {
            if (inFormat.nextRecord(pactRecord)) {
              output.collect(pactRecord);
            }
          }
        }
 else {
          @SuppressWarnings(""String_Node_Str"") final Collector<PactRecord> output=(Collector<PactRecord>)this.output;
          while (!this.taskCanceled && !inFormat.reachedEnd()) {
            if (inFormat.nextRecord(pactRecord)) {
              output.collect(pactRecord);
            }
          }
        }
      }
 else {
        if (this.output instanceof OutputCollector) {
          final OutputCollector<OT> output=(OutputCollector<OT>)this.output;
          while (!this.taskCanceled && !format.reachedEnd()) {
            if (format.nextRecord(record)) {
              output.collect(record);
            }
          }
        }
 else         if (this.output instanceof ChainedMapTask) {
          @SuppressWarnings(""String_Node_Str"") final ChainedMapTask<OT,?> output=(ChainedMapTask<OT,?>)this.output;
          while (!this.taskCanceled && !format.reachedEnd()) {
            if (format.nextRecord(record)) {
              output.collect(record);
            }
          }
        }
 else {
          final Collector<OT> output=this.output;
          while (!this.taskCanceled && !format.reachedEnd()) {
            if (format.nextRecord(record)) {
              output.collect(record);
            }
          }
        }
      }
      if (!this.taskCanceled) {
        if (LOG.isDebugEnabled())         LOG.debug(getLogString(""String_Node_Str"" + split.toString()));
        format.close();
      }
    }
    this.output.close();
    AbstractPactTask.closeChainedTasks(this.chainedTasks,this);
  }
 catch (  Exception ex) {
    try {
      this.format.close();
    }
 catch (    Throwable t) {
    }
    AbstractPactTask.cancelChainedTasks(this.chainedTasks);
    if (!this.taskCanceled) {
      AbstractPactTask.logAndThrowException(ex,this);
    }
  }
  if (!this.taskCanceled) {
    if (LOG.isInfoEnabled())     LOG.info(getLogString(""String_Node_Str""));
  }
 else {
    if (LOG.isWarnEnabled())     LOG.warn(getLogString(""String_Node_Str""));
  }
}",0.9546613771606688
55460,"@Override public IArrayNode add(int index,IJsonNode element){
  if (element == null) {
    throw new NullPointerException();
  }
  if (element.isMissing()) {
    this.remove(index);
  }
  if (index < 0 || index > this.size()) {
    throw new IndexOutOfBoundsException();
  }
  if (index < this.schema.getTailSize()) {
    for (int i=this.schema.getTailSize() - 1; i >= index; i--) {
      if (!this.record.isNull(i)) {
        if (i == this.schema.getTailSize() - 1) {
          this.getOtherField().add(0,SopremoUtil.unwrap(this.record.getField(i,JsonNodeWrapper.class)));
        }
 else {
          this.record.setField(i + 1,this.record.getField(i,JsonNodeWrapper.class));
        }
      }
    }
    this.record.setField(index,SopremoUtil.wrap(element));
  }
  return this;
}","@Override public IArrayNode add(int index,IJsonNode element){
  if (element == null) {
    throw new NullPointerException();
  }
  if (element.isMissing()) {
    this.remove(index);
  }
  if (index < 0 || index > this.size()) {
    throw new IndexOutOfBoundsException();
  }
  int recordPosition=this.schema.getTailSize() - size() + index;
  if (recordPosition < 0) {
    this.getOtherField().add(index,element);
  }
 else {
    IJsonNode oldNode=SopremoUtil.unwrap(this.record.getField(recordPosition + 1,JsonNodeWrapper.class));
    IJsonNode tmpNode;
    this.record.setField(recordPosition + 1,SopremoUtil.wrap(element));
    for (int i=recordPosition + 1; i > 0; i--) {
      if (this.record.isNull(i)) {
        this.record.setField(i,SopremoUtil.wrap(oldNode));
        return this;
      }
 else {
        tmpNode=SopremoUtil.unwrap(this.record.getField(i,JsonNodeWrapper.class));
        if (oldNode != null) {
          this.record.setField(i,SopremoUtil.wrap(oldNode));
        }
        oldNode=tmpNode;
      }
    }
    if (oldNode != null) {
      this.getOtherField().add(oldNode);
    }
  }
  return this;
}",0.5241596638655462
55461,"@Override public IJsonNode set(int index,IJsonNode node){
  if (node == null) {
    throw new NullPointerException();
  }
  if (node.isMissing()) {
    return this.remove(index);
  }
  if (index < 0 || index >= this.size()) {
    if (index == this.size()) {
      this.add(node);
      return MissingNode.getInstance();
    }
 else {
      throw new IndexOutOfBoundsException();
    }
  }
  int pactRecordPosition=this.schema.getTailSize() - size() + index;
  if (pactRecordPosition < 0) {
    return this.getOtherField().set(index,node);
  }
 else {
    IJsonNode oldNode=SopremoUtil.unwrap(this.record.getField(pactRecordPosition + 1,JsonNodeWrapper.class));
    this.record.setField(pactRecordPosition + 1,node);
    return oldNode;
  }
}","@Override public IJsonNode set(int index,IJsonNode node){
  if (node == null) {
    throw new NullPointerException();
  }
  if (node.isMissing()) {
    return this.remove(index);
  }
  if (index < 0 || index >= this.size()) {
    if (index == this.size()) {
      this.add(node);
      return MissingNode.getInstance();
    }
 else {
      throw new IndexOutOfBoundsException();
    }
  }
  int recordPosition=this.schema.getTailSize() - size() + index;
  if (recordPosition < 0) {
    return this.getOtherField().set(index,node);
  }
 else {
    IJsonNode oldNode=SopremoUtil.unwrap(this.record.getField(recordPosition + 1,JsonNodeWrapper.class));
    this.record.setField(recordPosition + 1,node);
    return oldNode;
  }
}",0.9836289222373806
55462,"@Override public IJsonNode get(int index){
  int size=this.size();
  if (index < 0 || index >= size) {
    return MissingNode.getInstance();
  }
  if (size <= this.schema.getTailSize()) {
    return SopremoUtil.unwrap(this.record.getField(this.schema.getTailSize() - size + index + 1,JsonNodeWrapper.class));
  }
 else {
    return this.getOtherField().get(index);
  }
}","@Override public IJsonNode get(int index){
  int size=this.size();
  if (index < 0 || index >= size) {
    return MissingNode.getInstance();
  }
  int recordPosition=this.schema.getTailSize() - size + index;
  if (recordPosition >= 0) {
    return SopremoUtil.unwrap(this.record.getField(recordPosition + 1,JsonNodeWrapper.class));
  }
 else {
    return this.getOtherField().get(index);
  }
}",0.7339449541284404
55463,"@Override public void initArrayNode(){
  TailArraySchema schema=new TailArraySchema();
  schema.setTailSize(5);
  PactRecord record=schema.jsonToRecord(new ArrayNode(IntNode.valueOf(0),IntNode.valueOf(1),IntNode.valueOf(2)),null,null);
  this.node=new LazyTailArrayNode(record,schema);
}","@Override public void initArrayNode(){
}",0.2446483180428134
55464,"@Test public void shouldReturnTheCorrectNode(){
  this.node.add(0,TextNode.valueOf(""String_Node_Str""));
  Assert.assertEquals(TextNode.valueOf(""String_Node_Str""),this.node.get(0));
}","@Test public void shouldReturnTheCorrectNode(){
  this.node.add(0,TextNode.valueOf(""String_Node_Str""));
  this.node.add(0,TextNode.valueOf(""String_Node_Str""));
  Assert.assertEquals(TextNode.valueOf(""String_Node_Str""),this.node.get(0));
  Assert.assertEquals(TextNode.valueOf(""String_Node_Str""),this.node.get(1));
}",0.7323943661971831
55465,"/** 
 * Reconstructs the execution pipeline starting at the given vertex by conducting a depth-first search.
 * @param vertex the vertex to start the depth-first search from
 * @param forward <code>true</code> to traverse the graph according to the original direction of the edges or <code>false</code> for the opposite direction
 * @param alreadyVisited a set of vertices that have already been visited in the depth-first search
 */
private void reconstructExecutionPipeline(final ExecutionVertex vertex,final boolean forward,final Set<ExecutionVertex> alreadyVisited){
  ExecutionPipeline pipeline=vertex.getExecutionPipeline();
  if (pipeline == null) {
    pipeline=new ExecutionPipeline();
    vertex.setExecutionPipeline(pipeline);
  }
  alreadyVisited.add(vertex);
  final RuntimeEnvironment env=vertex.getEnvironment();
  if (forward) {
    final int numberOfOutputGates=env.getNumberOfOutputGates();
    for (int i=0; i < numberOfOutputGates; ++i) {
      final OutputGate<? extends Record> outputGate=env.getOutputGate(i);
      final ChannelType channelType=outputGate.getChannelType();
      final int numberOfOutputChannels=outputGate.getNumberOfOutputChannels();
      for (int j=0; j < numberOfOutputChannels; ++j) {
        final AbstractOutputChannel<? extends Record> outputChannel=outputGate.getOutputChannel(j);
        final ExecutionVertex connectedVertex=this.executionGraph.getVertexByChannelID(outputChannel.getConnectedChannelID());
        boolean recurse=false;
        if (!alreadyVisited.contains(connectedVertex)) {
          recurse=true;
        }
 else         if (channelType == ChannelType.INMEMORY && !pipeline.equals(connectedVertex.getExecutionPipeline())) {
          connectedVertex.setExecutionPipeline(pipeline);
          recurse=true;
        }
        if (recurse) {
          reconstructExecutionPipeline(connectedVertex,true,alreadyVisited);
        }
      }
    }
  }
 else {
    final int numberOfInputGates=env.getNumberOfInputGates();
    for (int i=0; i < numberOfInputGates; ++i) {
      final InputGate<? extends Record> inputGate=env.getInputGate(i);
      final ChannelType channelType=inputGate.getChannelType();
      final int numberOfInputChannels=inputGate.getNumberOfInputChannels();
      for (int j=0; j < numberOfInputChannels; ++j) {
        final AbstractInputChannel<? extends Record> inputChannel=inputGate.getInputChannel(j);
        final ExecutionVertex connectedVertex=this.executionGraph.getVertexByChannelID(inputChannel.getConnectedChannelID());
        boolean recurse=false;
        if (!alreadyVisited.contains(connectedVertex)) {
          recurse=true;
        }
 else         if (channelType == ChannelType.INMEMORY && !pipeline.equals(connectedVertex.getExecutionPipeline())) {
          connectedVertex.setExecutionPipeline(pipeline);
          recurse=true;
        }
        if (recurse) {
          reconstructExecutionPipeline(connectedVertex,false,alreadyVisited);
        }
      }
    }
  }
}","/** 
 * Reconstructs the execution pipeline starting at the given vertex by conducting a depth-first search.
 * @param vertex the vertex to start the depth-first search from
 * @param forward <code>true</code> to traverse the graph according to the original direction of the edges or <code>false</code> for the opposite direction
 * @param alreadyVisited a set of vertices that have already been visited in the depth-first search
 */
private void reconstructExecutionPipeline(final ExecutionVertex vertex,final boolean forward,final Set<ExecutionVertex> alreadyVisited){
  ExecutionPipeline pipeline=vertex.getExecutionPipeline();
  if (pipeline == null) {
    pipeline=new ExecutionPipeline();
    vertex.setExecutionPipeline(pipeline);
  }
  alreadyVisited.add(vertex);
  final RuntimeEnvironment env=vertex.getEnvironment();
  if (forward) {
    final int numberOfOutputGates=env.getNumberOfOutputGates();
    for (int i=0; i < numberOfOutputGates; ++i) {
      final OutputGate<? extends Record> outputGate=env.getOutputGate(i);
      final ChannelType channelType=outputGate.getChannelType();
      final int numberOfOutputChannels=outputGate.getNumberOfOutputChannels();
      for (int j=0; j < numberOfOutputChannels; ++j) {
        final AbstractOutputChannel<? extends Record> outputChannel=outputGate.getOutputChannel(j);
        final ExecutionVertex connectedVertex=this.executionGraph.getVertexByChannelID(outputChannel.getConnectedChannelID());
        boolean recurse=false;
        if (!alreadyVisited.contains(connectedVertex)) {
          recurse=true;
        }
        if (channelType == ChannelType.INMEMORY && !pipeline.equals(connectedVertex.getExecutionPipeline())) {
          connectedVertex.setExecutionPipeline(pipeline);
          recurse=true;
        }
        if (recurse) {
          reconstructExecutionPipeline(connectedVertex,true,alreadyVisited);
        }
      }
    }
  }
 else {
    final int numberOfInputGates=env.getNumberOfInputGates();
    for (int i=0; i < numberOfInputGates; ++i) {
      final InputGate<? extends Record> inputGate=env.getInputGate(i);
      final ChannelType channelType=inputGate.getChannelType();
      final int numberOfInputChannels=inputGate.getNumberOfInputChannels();
      for (int j=0; j < numberOfInputChannels; ++j) {
        final AbstractInputChannel<? extends Record> inputChannel=inputGate.getInputChannel(j);
        final ExecutionVertex connectedVertex=this.executionGraph.getVertexByChannelID(inputChannel.getConnectedChannelID());
        boolean recurse=false;
        if (!alreadyVisited.contains(connectedVertex)) {
          recurse=true;
        }
        if (channelType == ChannelType.INMEMORY && !pipeline.equals(connectedVertex.getExecutionPipeline())) {
          connectedVertex.setExecutionPipeline(pipeline);
          recurse=true;
        }
        if (recurse) {
          reconstructExecutionPipeline(connectedVertex,false,alreadyVisited);
        }
      }
    }
  }
}",0.9979859013091642
55466,"/** 
 * {@inheritDoc}
 */
@Override public void executionStateChanged(final JobID jobID,final ExecutionVertexID vertexID,final ExecutionState newExecutionState,final String optionalMessage){
  final ExecutionGraph eg=this.executionVertex.getExecutionGraph();
  if (newExecutionState == ExecutionState.FINISHING) {
    final ExecutionPipeline pipeline=this.executionVertex.getExecutionPipeline();
    if (!pipeline.isFinishing()) {
      return;
    }
    final ExecutionGroupVertex groupVertex=this.executionVertex.getGroupVertex();
    for (int i=0; i < groupVertex.getCurrentNumberOfGroupMembers(); ++i) {
      final ExecutionVertex groupMember=groupVertex.getGroupMember(i);
      if (groupMember.getExecutionState() == ExecutionState.SCHEDULED) {
        final ExecutionPipeline pipelineToBeDeployed=groupMember.getExecutionPipeline();
        pipelineToBeDeployed.setAllocatedResource(this.executionVertex.getAllocatedResource());
        pipelineToBeDeployed.updateExecutionState(ExecutionState.ASSIGNED);
        this.scheduler.deployAssignedVertices(groupMember);
        return;
      }
    }
  }
  if (newExecutionState == ExecutionState.CANCELED || newExecutionState == ExecutionState.FINISHED) {
synchronized (this.executionVertex.getExecutionGraph()) {
      if (this.scheduler.getVerticesToBeRestarted().remove(this.executionVertex.getID()) != null) {
        this.executionVertex.updateExecutionState(ExecutionState.ASSIGNED,""String_Node_Str"");
        this.scheduler.deployAssignedVertices(this.executionVertex);
        return;
      }
    }
  }
  if (newExecutionState == ExecutionState.FINISHED || newExecutionState == ExecutionState.CANCELED || newExecutionState == ExecutionState.FAILED) {
    this.scheduler.checkAndReleaseAllocatedResource(eg,this.executionVertex.getAllocatedResource());
  }
  if (newExecutionState == ExecutionState.FAILED) {
    if (this.executionVertex.decrementRetriesLeftAndCheck()) {
      final Set<ExecutionVertex> assignedVertices=new HashSet<ExecutionVertex>();
      if (RecoveryLogic.recover(this.executionVertex,this.scheduler.getVerticesToBeRestarted(),assignedVertices)) {
        if (RecoveryLogic.hasInstanceAssigned(this.executionVertex)) {
          this.scheduler.deployAssignedVertices(assignedVertices);
        }
      }
 else {
      }
    }
  }
}","/** 
 * {@inheritDoc}
 */
@Override public void executionStateChanged(final JobID jobID,final ExecutionVertexID vertexID,final ExecutionState newExecutionState,final String optionalMessage){
  final ExecutionGraph eg=this.executionVertex.getExecutionGraph();
  if (newExecutionState == ExecutionState.FINISHING) {
    final ExecutionPipeline pipeline=this.executionVertex.getExecutionPipeline();
    if (!pipeline.isFinishing()) {
      return;
    }
    final ExecutionGroupVertex groupVertex=this.executionVertex.getGroupVertex();
    for (int i=0; i < groupVertex.getCurrentNumberOfGroupMembers(); ++i) {
      final ExecutionVertex groupMember=groupVertex.getGroupMember(i);
      if (groupMember.compareAndUpdateExecutionState(ExecutionState.SCHEDULED,ExecutionState.ASSIGNED)) {
        final ExecutionPipeline pipelineToBeDeployed=groupMember.getExecutionPipeline();
        pipelineToBeDeployed.setAllocatedResource(this.executionVertex.getAllocatedResource());
        pipelineToBeDeployed.updateExecutionState(ExecutionState.ASSIGNED);
        this.scheduler.deployAssignedPipeline(pipelineToBeDeployed);
        return;
      }
    }
  }
  if (newExecutionState == ExecutionState.CANCELED || newExecutionState == ExecutionState.FINISHED) {
synchronized (this.executionVertex.getExecutionGraph()) {
      if (this.scheduler.getVerticesToBeRestarted().remove(this.executionVertex.getID()) != null) {
        this.executionVertex.updateExecutionState(ExecutionState.ASSIGNED,""String_Node_Str"");
        this.scheduler.deployAssignedVertices(this.executionVertex);
        return;
      }
    }
  }
  if (newExecutionState == ExecutionState.FINISHED || newExecutionState == ExecutionState.CANCELED || newExecutionState == ExecutionState.FAILED) {
    this.scheduler.checkAndReleaseAllocatedResource(eg,this.executionVertex.getAllocatedResource());
  }
  if (newExecutionState == ExecutionState.FAILED) {
    if (this.executionVertex.decrementRetriesLeftAndCheck()) {
      final Set<ExecutionVertex> assignedVertices=new HashSet<ExecutionVertex>();
      if (RecoveryLogic.recover(this.executionVertex,this.scheduler.getVerticesToBeRestarted(),assignedVertices)) {
        if (RecoveryLogic.hasInstanceAssigned(this.executionVertex)) {
          this.scheduler.deployAssignedVertices(assignedVertices);
        }
      }
 else {
      }
    }
  }
}",0.8701799485861182
55467,"@Override public JsonNode evaluate(final JsonNode node,final EvaluationContext context){
  return LongNode.valueOf((((LongNode)((ArrayNode)node).get(0)).getLongValue() << 48) + ((LongNode)((ArrayNode)node).get(1)).getLongValue());
}","@Override public IJsonNode evaluate(IJsonNode node,IJsonNode target,EvaluationContext context){
  return LongNode.valueOf((((LongNode)((ArrayNode)node).get(0)).getLongValue() << 48) + ((LongNode)((ArrayNode)node).get(1)).getLongValue());
}",0.9341825902335456
55468,"@Override public IJsonNode evaluate(IJsonNode node,EvaluationContext context){
  throw new EvaluationException(""String_Node_Str"");
}","@Override public IJsonNode evaluate(IJsonNode node,IJsonNode target,EvaluationContext context){
  throw new EvaluationException(""String_Node_Str"");
}",0.9395017793594306
55469,"public void collect(final IJsonNode value){
  if (SopremoUtil.LOG.isTraceEnabled())   SopremoUtil.LOG.trace(String.format(""String_Node_Str"",value));
  this.collector.collect(this.record=this.schema.jsonToRecord(value,null,this.record));
}","public void collect(final IJsonNode value){
  if (SopremoUtil.LOG.isTraceEnabled())   SopremoUtil.LOG.trace(String.format(""String_Node_Str"",value));
  this.collector.collect(this.record=this.schema.jsonToRecord(value,this.record,this.context));
}",0.9421487603305784
55470,"@Override public void coGroup(final Iterator<PactRecord> records1,final Iterator<PactRecord> records2,final Collector out){
  this.context.increaseInputCounter();
  this.collector.setCollector(out);
  this.cachedIterator1.setIterator(records1);
  this.cachedIterator2.setIterator(records2);
  Iterator<IJsonNode> values1=this.cachedIterator1;
  Iterator<IJsonNode> values2=this.cachedIterator2;
  if (SopremoUtil.LOG.isTraceEnabled()) {
    final ArrayList<IJsonNode> cached1=new ArrayList<IJsonNode>(), cached2=new ArrayList<IJsonNode>();
    while (values1.hasNext())     cached1.add(values1.next());
    while (values2.hasNext())     cached2.add(values2.next());
    SopremoUtil.LOG.trace(String.format(""String_Node_Str"",this.getContext().operatorTrace(),cached1,cached2));
    values1=cached1.iterator();
    values2=cached2.iterator();
  }
  final ArrayNode array1=JsonUtil.wrapWithNode(this.needsResettableIterator(0,values1),values1);
  final ArrayNode array2=JsonUtil.wrapWithNode(this.needsResettableIterator(0,values2),values2);
  try {
    this.coGroup(array1,array2,this.collector);
  }
 catch (  final RuntimeException e) {
    SopremoUtil.LOG.error(String.format(""String_Node_Str"",this.getContext().operatorTrace(),array1,array2,e));
    throw e;
  }
}","@Override public void coGroup(final Iterator<PactRecord> records1,final Iterator<PactRecord> records2,final Collector out){
  this.context.increaseInputCounter();
  this.collector.configure(out,this.context);
  this.cachedIterator1.setIterator(records1);
  this.cachedIterator2.setIterator(records2);
  Iterator<IJsonNode> values1=this.cachedIterator1;
  Iterator<IJsonNode> values2=this.cachedIterator2;
  if (SopremoUtil.LOG.isTraceEnabled()) {
    final ArrayList<IJsonNode> cached1=new ArrayList<IJsonNode>(), cached2=new ArrayList<IJsonNode>();
    while (values1.hasNext())     cached1.add(values1.next());
    while (values2.hasNext())     cached2.add(values2.next());
    SopremoUtil.LOG.trace(String.format(""String_Node_Str"",this.getContext().operatorTrace(),cached1,cached2));
    values1=cached1.iterator();
    values2=cached2.iterator();
  }
  final ArrayNode array1=JsonUtil.wrapWithNode(this.needsResettableIterator(0,values1),values1);
  final ArrayNode array2=JsonUtil.wrapWithNode(this.needsResettableIterator(0,values2),values2);
  try {
    this.coGroup(array1,array2,this.collector);
  }
 catch (  final RuntimeException e) {
    SopremoUtil.LOG.error(String.format(""String_Node_Str"",this.getContext().operatorTrace(),array1,array2,e));
    throw e;
  }
}",0.98426435877262
55471,"@Override public void cross(final PactRecord record1,final PactRecord record2,final Collector out){
  this.context.increaseInputCounter();
  this.collector.setCollector(out);
  final IJsonNode input1=this.inputSchema1.recordToJson(record1,this.cachedInput1);
  final IJsonNode input2=this.inputSchema2.recordToJson(record2,this.cachedInput2);
  if (SopremoUtil.LOG.isTraceEnabled())   SopremoUtil.LOG.trace(String.format(""String_Node_Str"",this.getContext().operatorTrace(),input1,input2));
  try {
    this.cross(input1,input2,this.collector);
  }
 catch (  final RuntimeException e) {
    SopremoUtil.LOG.error(String.format(""String_Node_Str"",this.getContext().operatorTrace(),input1,input2,e));
    throw e;
  }
}","@Override public void cross(final PactRecord record1,final PactRecord record2,final Collector out){
  this.context.increaseInputCounter();
  this.collector.configure(out,this.context);
  final IJsonNode input1=this.inputSchema1.recordToJson(record1,this.cachedInput1);
  final IJsonNode input2=this.inputSchema2.recordToJson(record2,this.cachedInput2);
  if (SopremoUtil.LOG.isTraceEnabled())   SopremoUtil.LOG.trace(String.format(""String_Node_Str"",this.getContext().operatorTrace(),input1,input2));
  try {
    this.cross(input1,input2,this.collector);
  }
 catch (  final RuntimeException e) {
    SopremoUtil.LOG.error(String.format(""String_Node_Str"",this.getContext().operatorTrace(),input1,input2,e));
    throw e;
  }
}",0.9722222222222222
55472,"@Override public void map(final PactRecord record,final Collector out) throws Exception {
  this.context.increaseInputCounter();
  this.collector.setCollector(out);
  final IJsonNode input=this.inputSchema.recordToJson(record,this.cachedInput);
  if (SopremoUtil.LOG.isTraceEnabled())   SopremoUtil.LOG.trace(String.format(""String_Node_Str"",this.getContext().operatorTrace(),input));
  try {
    this.map(input,this.collector);
  }
 catch (  final RuntimeException e) {
    SopremoUtil.LOG.error(String.format(""String_Node_Str"",this.getContext().operatorTrace(),this.cachedInput,e));
    throw e;
  }
}","@Override public void map(final PactRecord record,final Collector out) throws Exception {
  this.context.increaseInputCounter();
  this.collector.configure(out,this.context);
  final IJsonNode input=this.inputSchema.recordToJson(record,this.cachedInput);
  if (SopremoUtil.LOG.isTraceEnabled())   SopremoUtil.LOG.trace(String.format(""String_Node_Str"",this.getContext().operatorTrace(),input));
  try {
    this.map(input,this.collector);
  }
 catch (  final RuntimeException e) {
    SopremoUtil.LOG.error(String.format(""String_Node_Str"",this.getContext().operatorTrace(),this.cachedInput,e));
    throw e;
  }
}",0.9670510708401976
55473,"@Override public void match(final PactRecord record1,final PactRecord record2,final Collector out) throws Exception {
  this.context.increaseInputCounter();
  this.collector.setCollector(out);
  final IJsonNode input1=this.inputSchema1.recordToJson(record1,this.cachedInput1);
  final IJsonNode input2=this.inputSchema2.recordToJson(record2,this.cachedInput2);
  if (SopremoUtil.LOG.isTraceEnabled())   SopremoUtil.LOG.trace(String.format(""String_Node_Str"",this.getContext().operatorTrace(),input1,input2));
  try {
    this.match(input1,input2,this.collector);
  }
 catch (  final RuntimeException e) {
    SopremoUtil.LOG.error(String.format(""String_Node_Str"",this.getContext().operatorTrace(),input1,input2,e));
    throw e;
  }
}","@Override public void match(final PactRecord record1,final PactRecord record2,final Collector out) throws Exception {
  this.context.increaseInputCounter();
  this.collector.configure(out,this.context);
  final IJsonNode input1=this.inputSchema1.recordToJson(record1,this.cachedInput1);
  final IJsonNode input2=this.inputSchema2.recordToJson(record2,this.cachedInput2);
  if (SopremoUtil.LOG.isTraceEnabled())   SopremoUtil.LOG.trace(String.format(""String_Node_Str"",this.getContext().operatorTrace(),input1,input2));
  try {
    this.match(input1,input2,this.collector);
  }
 catch (  final RuntimeException e) {
    SopremoUtil.LOG.error(String.format(""String_Node_Str"",this.getContext().operatorTrace(),input1,input2,e));
    throw e;
  }
}",0.97289972899729
55474,"@Override public void reduce(final Iterator<PactRecord> records,final Collector out) throws Exception {
  this.context.increaseInputCounter();
  this.collector.setCollector(out);
  this.cachedIterator.setIterator(records);
  Iterator<IJsonNode> values=this.cachedIterator;
  if (SopremoUtil.LOG.isTraceEnabled()) {
    final ArrayList<IJsonNode> cached=new ArrayList<IJsonNode>();
    while (this.cachedIterator.hasNext())     cached.add(this.cachedIterator.next());
    values=cached.iterator();
    SopremoUtil.LOG.trace(String.format(""String_Node_Str"",this.getContext().operatorTrace(),cached));
  }
  final ArrayNode array=JsonUtil.wrapWithNode(this.needsResettableIterator(values),values);
  try {
    this.reduce(array,this.collector);
  }
 catch (  final RuntimeException e) {
    SopremoUtil.LOG.error(String.format(""String_Node_Str"",this.getContext().operatorTrace(),array,e));
    throw e;
  }
}","@Override public void reduce(final Iterator<PactRecord> records,final Collector out) throws Exception {
  this.context.increaseInputCounter();
  this.collector.configure(out,this.context);
  this.cachedIterator.setIterator(records);
  Iterator<IJsonNode> values=this.cachedIterator;
  if (SopremoUtil.LOG.isTraceEnabled()) {
    final ArrayList<IJsonNode> cached=new ArrayList<IJsonNode>();
    while (this.cachedIterator.hasNext())     cached.add(this.cachedIterator.next());
    values=cached.iterator();
    SopremoUtil.LOG.trace(String.format(""String_Node_Str"",this.getContext().operatorTrace(),cached));
  }
  final ArrayNode array=JsonUtil.wrapWithNode(this.needsResettableIterator(values),values);
  try {
    this.reduce(array,this.collector);
  }
 catch (  final RuntimeException e) {
    SopremoUtil.LOG.error(String.format(""String_Node_Str"",this.getContext().operatorTrace(),array,e));
    throw e;
  }
}",0.978021978021978
55475,"@Override public IJsonNode recordToJson(PactRecord record,IJsonNode target){
  if (this.getHeadSize() + 1 != record.getNumFields())   throw new IllegalStateException(""String_Node_Str"");
  if (target == null)   target=new ArrayNode();
}","@Override public IJsonNode recordToJson(PactRecord record,IJsonNode target){
  if (this.getHeadSize() + 1 != record.getNumFields())   throw new IllegalStateException(""String_Node_Str"");
  if (target == null)   target=new ArrayNode();
 else   ((IArrayNode)target).clear();
  for (int i=0; i < this.getHeadSize(); i++) {
    if (record.getField(i,JsonNodeWrapper.class) != null) {
      ((IArrayNode)target).add(SopremoUtil.unwrap(record.getField(i,JsonNodeWrapper.class)));
    }
  }
  ((IArrayNode)target).addAll((IArrayNode)SopremoUtil.unwrap(record.getField(this.getHeadSize(),JsonNodeWrapper.class)));
  return target;
}",0.5477855477855478
55476,"@Override public IJsonNode remove(int index){
}","@Override public IJsonNode remove(int index){
  if (index < 0 || index >= this.size())   return MissingNode.getInstance();
  if (index < this.schema.getHeadSize()) {
    IJsonNode oldNode=SopremoUtil.wrap(this.getOtherField().remove(0));
    IJsonNode buffer;
    for (int i=this.schema.getHeadSize() - 1; i >= index; i--) {
      buffer=this.record.getField(i,JsonNodeWrapper.class);
      if (buffer == null) {
        buffer=MissingNode.getInstance();
      }
      if (oldNode.isMissing())       this.record.setNull(i);
 else       this.record.setField(i,oldNode);
      oldNode=buffer;
    }
    return SopremoUtil.unwrap(oldNode);
  }
  return this.getOtherField().remove(index - this.schema.getHeadSize());
}",0.1233595800524934
55477,"@Override public PactRecord jsonToRecord(IJsonNode value,PactRecord target,EvaluationContext context){
}","@Override public PactRecord jsonToRecord(IJsonNode value,PactRecord target,EvaluationContext context){
  IObjectNode others;
  if (target == null) {
    target=new PactRecord(this.mappings.size() + 1);
    for (int i=0; i < this.mappings.size(); i++)     target.setField(i,new JsonNodeWrapper(MissingNode.getInstance()));
    target.setField(this.mappings.size(),new JsonNodeWrapper(others=new ObjectNode()));
  }
 else {
    JsonNodeWrapper wrappedField=target.getField(target.getNumFields() - 1,JsonNodeWrapper.class);
    others=wrappedField.getValue(IObjectNode.class);
    others.removeAll();
    target.setField(target.getNumFields() - 1,wrappedField);
  }
  IObjectNode object=(IObjectNode)value;
  for (int i=0; i < this.mappings.size(); i++) {
    IJsonNode node=object.get(this.mappings.get(i));
    JsonNodeWrapper wrappedField=target.getField(i,JsonNodeWrapper.class);
    wrappedField.setValue(node);
    target.setField(i,wrappedField);
  }
  for (  Entry<String,IJsonNode> entry : object.getEntries())   if (!this.mappings.contains(entry.getKey()))   others.put(entry.getKey(),entry.getValue());
  return target;
}",0.1686942416869424
55478,"private static void removeCheckpointMetaData(final Path pathPrefix) throws IOException {
  Path p=pathPrefix.suffix(COMPLETED_CHECKPOINT_SUFFIX);
  FileSystem fs=p.getFileSystem();
  if (fs.exists(p)) {
    fs.delete(p,false);
    return;
  }
  p=pathPrefix.suffix(""String_Node_Str"");
  if (fs.exists(p)) {
    fs.delete(p,false);
  }
  p=pathPrefix.suffix(""String_Node_Str"");
  if (fs.exists(p)) {
    fs.delete(p,false);
  }
}","private static boolean removeCheckpointMetaData(final Path pathPrefix) throws IOException {
  boolean removed=false;
  Path p=pathPrefix.suffix(""String_Node_Str"");
  FileSystem fs=p.getFileSystem();
  if (fs.exists(p)) {
    fs.delete(p,false);
    removed=true;
  }
  int suffix=0;
  while (true) {
    p=pathPrefix.suffix(""String_Node_Str"" + suffix++);
    if (fs.exists(p)) {
      fs.delete(p,false);
      removed=true;
    }
 else {
      break;
    }
  }
  p=pathPrefix.suffix(COMPLETED_CHECKPOINT_SUFFIX);
  if (fs.exists(p)) {
    fs.delete(p,false);
    removed=true;
  }
  return removed;
}",0.3867832847424684
55479,"/** 
 * Removes the checkpoint of the vertex with the given ID. All files contained in the checkpoint are deleted.
 * @param vertexID the vertex whose checkpoint shall be removed
 */
public static void removeCheckpoint(final ExecutionVertexID vertexID){
  final Path localChPath=getLocalCheckpointPath();
  try {
    removeCheckpointMetaData(new Path(localChPath + Path.SEPARATOR + METADATA_PREFIX));
    final Path distributedChPath=getDistributedCheckpointPath();
    if (distributedChPath != null) {
      removeCheckpointMetaData(new Path(distributedChPath + Path.SEPARATOR + METADATA_PREFIX));
    }
  }
 catch (  IOException e) {
  }
}","/** 
 * Removes the checkpoint of the vertex with the given ID. All files contained in the checkpoint are deleted.
 * @param vertexID the vertex whose checkpoint shall be removed
 */
public static void removeCheckpoint(final ExecutionVertexID vertexID){
  final Path localChPath=getLocalCheckpointPath();
  try {
    if (!removeCheckpointMetaData(new Path(localChPath + Path.SEPARATOR + METADATA_PREFIX+ ""String_Node_Str""+ vertexID))) {
      final Path distributedChPath=getDistributedCheckpointPath();
      if (distributedChPath != null) {
        removeCheckpointMetaData(new Path(distributedChPath + Path.SEPARATOR + METADATA_PREFIX+ ""String_Node_Str""+ vertexID));
      }
    }
    FileBufferManager.deleteFile(vertexID);
  }
 catch (  IOException e) {
    e.printStackTrace();
  }
}",0.8909090909090909
55480,"public synchronized void shutdown(){
  if (this.isShutDown) {
    return;
  }
  if (this.instanceManager != null) {
    this.instanceManager.shutdown();
  }
  DiscoveryService.stopDiscoveryService();
  if (this.profiler != null) {
    this.profiler.shutdown();
  }
  if (this.jobManagerServer != null) {
    this.jobManagerServer.stop();
  }
  if (this.executorService != null) {
    this.executorService.shutdown();
  }
  final Iterator<JobManagerPlugin> it=this.jobManagerPlugins.values().iterator();
  while (it.hasNext()) {
    it.next().shutdown();
  }
  if (this.eventCollector != null) {
    this.eventCollector.shutdown();
  }
  if (this.scheduler != null) {
    this.scheduler.shutdown();
  }
  this.isShutDown=true;
  LOG.debug(""String_Node_Str"");
}","public synchronized void shutdown(){
  if (this.isShutDown) {
    return;
  }
  if (this.instanceManager != null) {
    this.instanceManager.shutdown();
  }
  DiscoveryService.stopDiscoveryService();
  if (this.profiler != null) {
    this.profiler.shutdown();
  }
  if (this.jobManagerServer != null) {
    this.jobManagerServer.stop();
  }
  if (this.executorService != null) {
    this.executorService.shutdown();
    try {
      this.executorService.awaitTermination(5000L,TimeUnit.MILLISECONDS);
    }
 catch (    InterruptedException e) {
      if (LOG.isDebugEnabled()) {
        LOG.debug(StringUtils.stringifyException(e));
      }
    }
  }
  final Iterator<JobManagerPlugin> it=this.jobManagerPlugins.values().iterator();
  while (it.hasNext()) {
    it.next().shutdown();
  }
  if (this.eventCollector != null) {
    this.eventCollector.shutdown();
  }
  if (this.scheduler != null) {
    this.scheduler.shutdown();
  }
  this.isShutDown=true;
  LOG.debug(""String_Node_Str"");
}",0.5183066361556065
55481,"/** 
 * {@inheritDoc}
 */
@Override public TaskCancelResult cancelTask(final ExecutionVertexID id) throws IOException {
  final Task task=this.runningTasks.get(id);
  if (task == null) {
    final TaskCancelResult taskCancelResult=new TaskCancelResult(id,AbstractTaskResult.ReturnCode.TASK_NOT_FOUND);
    taskCancelResult.setDescription(""String_Node_Str"" + id + ""String_Node_Str"");
    return taskCancelResult;
  }
  final Thread tmpThread=new Thread(new Runnable(){
    @Override public void run(){
      task.cancelExecution();
    }
  }
);
  tmpThread.start();
  return new TaskCancelResult(id,AbstractTaskResult.ReturnCode.SUCCESS);
}","/** 
 * {@inheritDoc}
 */
@Override public TaskCancelResult cancelTask(final ExecutionVertexID id) throws IOException {
  final Task task=this.runningTasks.get(id);
  if (task == null) {
    final TaskCancelResult taskCancelResult=new TaskCancelResult(id,AbstractTaskResult.ReturnCode.TASK_NOT_FOUND);
    taskCancelResult.setDescription(""String_Node_Str"" + id + ""String_Node_Str"");
    return taskCancelResult;
  }
  final Runnable r=new Runnable(){
    @Override public void run(){
      task.cancelExecution();
    }
  }
;
  this.executorService.execute(r);
  return new TaskCancelResult(id,AbstractTaskResult.ReturnCode.SUCCESS);
}",0.9293563579277864
55482,"/** 
 * {@inheritDoc}
 */
@Override public void removeCheckpoints(final List<ExecutionVertexID> listOfVertexIDs) throws IOException {
  final Thread checkpointRemovalThread=new Thread(""String_Node_Str""){
    @Override public void run(){
      final Iterator<ExecutionVertexID> it=listOfVertexIDs.iterator();
      while (it.hasNext()) {
        final ExecutionVertexID vertexID=it.next();
        EnvelopeConsumptionLog.removeLog(vertexID);
        CheckpointUtils.removeCheckpoint(vertexID);
      }
    }
  }
;
  checkpointRemovalThread.start();
}","/** 
 * {@inheritDoc}
 */
@Override public void removeCheckpoints(final List<ExecutionVertexID> listOfVertexIDs) throws IOException {
  final List<ExecutionVertexID> threadSafeList=Collections.unmodifiableList(listOfVertexIDs);
  final Runnable r=new Runnable(){
    @Override public void run(){
      final Iterator<ExecutionVertexID> it=threadSafeList.iterator();
      while (it.hasNext()) {
        final ExecutionVertexID vertexID=it.next();
        EnvelopeConsumptionLog.removeLog(vertexID);
        CheckpointUtils.removeCheckpoint(vertexID);
      }
    }
  }
;
  this.executorService.execute(r);
}",0.4982698961937716
55483,"/** 
 * {@inheritDoc}
 */
@Override public TaskKillResult killTask(final ExecutionVertexID id) throws IOException {
  final Task task=this.runningTasks.get(id);
  if (task == null) {
    final TaskKillResult taskKillResult=new TaskKillResult(id,AbstractTaskResult.ReturnCode.TASK_NOT_FOUND);
    taskKillResult.setDescription(""String_Node_Str"" + id + ""String_Node_Str"");
    return taskKillResult;
  }
  final Thread tmpThread=new Thread(new Runnable(){
    @Override public void run(){
      task.killExecution();
    }
  }
);
  tmpThread.start();
  return new TaskKillResult(id,AbstractTaskResult.ReturnCode.SUCCESS);
}","/** 
 * {@inheritDoc}
 */
@Override public TaskKillResult killTask(final ExecutionVertexID id) throws IOException {
  final Task task=this.runningTasks.get(id);
  if (task == null) {
    final TaskKillResult taskKillResult=new TaskKillResult(id,AbstractTaskResult.ReturnCode.TASK_NOT_FOUND);
    taskKillResult.setDescription(""String_Node_Str"" + id + ""String_Node_Str"");
    return taskKillResult;
  }
  final Runnable r=new Runnable(){
    @Override public void run(){
      task.killExecution();
    }
  }
;
  this.executorService.execute(r);
  return new TaskKillResult(id,AbstractTaskResult.ReturnCode.SUCCESS);
}",0.9273021001615508
55484,"/** 
 * Shuts the task manager down.
 */
public synchronized void shutdown(){
  if (this.isShutDown) {
    return;
  }
  LOG.info(""String_Node_Str"");
  RPC.stopProxy(this.jobManager);
  this.taskManagerServer.stop();
  if (this.profiler != null) {
    this.profiler.shutdown();
  }
  this.byteBufferedChannelManager.shutdown();
  if (this.ioManager != null) {
    this.ioManager.shutdown();
  }
  if (this.memoryManager != null) {
    this.memoryManager.shutdown();
  }
  final Iterator<TaskManagerPlugin> it=this.taskManagerPlugins.values().iterator();
  while (it.hasNext()) {
    it.next().shutdown();
  }
  this.isShutDown=true;
}","/** 
 * Shuts the task manager down.
 */
public synchronized void shutdown(){
  if (this.isShutDown) {
    return;
  }
  LOG.info(""String_Node_Str"");
  RPC.stopProxy(this.jobManager);
  this.taskManagerServer.stop();
  if (this.profiler != null) {
    this.profiler.shutdown();
  }
  this.byteBufferedChannelManager.shutdown();
  if (this.ioManager != null) {
    this.ioManager.shutdown();
  }
  if (this.memoryManager != null) {
    this.memoryManager.shutdown();
  }
  if (this.executorService != null) {
    this.executorService.shutdown();
    try {
      this.executorService.awaitTermination(5000L,TimeUnit.MILLISECONDS);
    }
 catch (    InterruptedException e) {
      if (LOG.isDebugEnabled()) {
        LOG.debug(StringUtils.stringifyException(e));
      }
    }
  }
  final Iterator<TaskManagerPlugin> it=this.taskManagerPlugins.values().iterator();
  while (it.hasNext()) {
    it.next().shutdown();
  }
  this.isShutDown=true;
}",0.8040583386176284
55485,"/** 
 * {@inheritDoc}
 */
@Override public synchronized void requestInstance(final JobID jobID,final Configuration conf,final InstanceRequestMap instanceRequestMap,final List<String> splitAffinityList) throws InstanceException {
  final List<AllocatedResource> allocatedResources=new ArrayList<AllocatedResource>();
  final Iterator<Map.Entry<InstanceType,Integer>> it=instanceRequestMap.getMaximumIterator();
  while (it.hasNext()) {
    final Map.Entry<InstanceType,Integer> entry=it.next();
    final int maximumNumberOfInstances=entry.getValue().intValue();
    for (int i=0; i < maximumNumberOfInstances; i++) {
      LOG.info(""String_Node_Str"" + entry.getKey().getIdentifier());
      final AllocatedSlice slice=getSliceOfType(jobID,entry.getKey());
      if (slice == null) {
        if (i < instanceRequestMap.getMinimumNumberOfInstances(entry.getKey())) {
          removeAllSlicesOfJob(jobID);
          throw new InstanceException(""String_Node_Str"");
        }
 else {
          final int numberOfRemainingInstances=maximumNumberOfInstances - i;
          if (numberOfRemainingInstances > 0) {
            PendingRequestsMap pendingRequests=this.pendingRequestsOfJob.get(jobID);
            if (pendingRequests == null) {
              pendingRequests=new PendingRequestsMap();
              this.pendingRequestsOfJob.put(jobID,pendingRequests);
            }
            pendingRequests.addRequest(entry.getKey(),numberOfRemainingInstances);
          }
          break;
        }
      }
      List<AllocatedSlice> allocatedSlices=this.slicesOfJobs.get(jobID);
      if (allocatedSlices == null) {
        allocatedSlices=new ArrayList<AllocatedSlice>();
        this.slicesOfJobs.put(jobID,allocatedSlices);
      }
      allocatedSlices.add(slice);
      allocatedResources.add(new AllocatedResource(slice.getHostingInstance(),slice.getType(),slice.getAllocationID()));
    }
  }
  if (this.instanceListener != null) {
    final ClusterInstanceNotifier clusterInstanceNotifier=new ClusterInstanceNotifier(this.instanceListener,jobID,allocatedResources);
    clusterInstanceNotifier.start();
  }
}","/** 
 * {@inheritDoc}
 */
@Override public synchronized void requestInstance(final JobID jobID,final Configuration conf,final InstanceRequestMap instanceRequestMap,final List<String> splitAffinityList) throws InstanceException {
  final List<AllocatedSlice> newlyAllocatedSlicesOfJob=new ArrayList<AllocatedSlice>();
  final Map<InstanceType,Integer> pendingRequests=new HashMap<InstanceType,Integer>();
  for (final Iterator<Map.Entry<InstanceType,Integer>> it=instanceRequestMap.getMaximumIterator(); it.hasNext(); ) {
    final Map.Entry<InstanceType,Integer> entry=it.next();
    final int maximumNumberOfInstances=entry.getValue().intValue();
    for (int i=0; i < maximumNumberOfInstances; i++) {
      LOG.info(""String_Node_Str"" + entry.getKey().getIdentifier());
      final AllocatedSlice slice=getSliceOfType(jobID,entry.getKey());
      if (slice == null) {
        if (i < instanceRequestMap.getMinimumNumberOfInstances(entry.getKey())) {
          for (          final AllocatedSlice sliceToRelease : newlyAllocatedSlicesOfJob) {
            sliceToRelease.getHostingInstance().removeAllocatedSlice(sliceToRelease.getAllocationID());
          }
          throw new InstanceException(""String_Node_Str"");
        }
 else {
          final int numberOfRemainingInstances=maximumNumberOfInstances - i;
          if (numberOfRemainingInstances > 0) {
            Integer val=pendingRequests.get(entry.getKey());
            if (val == null) {
              val=Integer.valueOf(0);
            }
            val=Integer.valueOf(val.intValue() + numberOfRemainingInstances);
            pendingRequests.put(entry.getKey(),val);
          }
          break;
        }
      }
      newlyAllocatedSlicesOfJob.add(slice);
    }
  }
  List<AllocatedSlice> allAllocatedSlicesOfJob=this.slicesOfJobs.get(jobID);
  if (allAllocatedSlicesOfJob == null) {
    allAllocatedSlicesOfJob=new ArrayList<AllocatedSlice>();
    this.slicesOfJobs.put(jobID,allAllocatedSlicesOfJob);
  }
  allAllocatedSlicesOfJob.addAll(newlyAllocatedSlicesOfJob);
  PendingRequestsMap allPendingRequestsOfJob=this.pendingRequestsOfJob.get(jobID);
  if (allPendingRequestsOfJob == null) {
    allPendingRequestsOfJob=new PendingRequestsMap();
    this.pendingRequestsOfJob.put(jobID,allPendingRequestsOfJob);
  }
  for (final Iterator<Map.Entry<InstanceType,Integer>> it=pendingRequests.entrySet().iterator(); it.hasNext(); ) {
    final Map.Entry<InstanceType,Integer> entry=it.next();
    allPendingRequestsOfJob.addRequest(entry.getKey(),entry.getValue().intValue());
  }
  final List<AllocatedResource> allocatedResources=new ArrayList<AllocatedResource>();
  for (  final AllocatedSlice slice : newlyAllocatedSlicesOfJob) {
    allocatedResources.add(new AllocatedResource(slice.getHostingInstance(),slice.getType(),slice.getAllocationID()));
  }
  if (this.instanceListener != null) {
    final ClusterInstanceNotifier clusterInstanceNotifier=new ClusterInstanceNotifier(this.instanceListener,jobID,allocatedResources);
    clusterInstanceNotifier.start();
  }
}",0.5011645962732919
55486,"/** 
 * This test covers the matching of instances to instance types It addresses the automatic matching through the hardware description as well as user-defined instance type matching.
 */
@Test public void testInstanceMatching(){
  final String configDir=getConfigDir();
  if (configDir == null) {
    fail(""String_Node_Str"");
  }
  GlobalConfiguration.loadConfiguration(configDir);
  final TestInstanceListener testInstanceListener=new TestInstanceListener();
  final ClusterManager cm=new ClusterManager();
  cm.setInstanceListener(testInstanceListener);
  Map<InstanceType,InstanceTypeDescription> instanceTypeDescriptions=null;
  try {
    final int ipcPort=ConfigConstants.DEFAULT_TASK_MANAGER_IPC_PORT;
    final int dataPort=ConfigConstants.DEFAULT_TASK_MANAGER_DATA_PORT;
    HardwareDescription hardwareDescription=HardwareDescriptionFactory.construct(2,2L * 1024L * 1024L* 1024L,2L * 1024L * 1024L* 1024L);
    InstanceConnectionInfo ici=new InstanceConnectionInfo(InetAddress.getByName(""String_Node_Str""),ipcPort,dataPort);
    cm.reportHeartBeat(ici,hardwareDescription);
    instanceTypeDescriptions=cm.getMapOfAvailableInstanceTypes();
    assertEquals(3,instanceTypeDescriptions.size());
    Iterator<Map.Entry<InstanceType,InstanceTypeDescription>> it=instanceTypeDescriptions.entrySet().iterator();
    while (it.hasNext()) {
      final Map.Entry<InstanceType,InstanceTypeDescription> entry=it.next();
      if (LARGE_INSTANCE_TYPE_NAME.equals(entry.getKey().getIdentifier())) {
        assertEquals(1,entry.getValue().getMaximumNumberOfAvailableInstances());
      }
 else       if (MEDIUM_INSTANCE_TYPE_NAME.equals(entry.getKey().getIdentifier())) {
        assertEquals(2,entry.getValue().getMaximumNumberOfAvailableInstances());
      }
 else       if (SMALL_INSTANCE_TYPE_NAME.equals(entry.getKey().getIdentifier())) {
        assertEquals(4,entry.getValue().getMaximumNumberOfAvailableInstances());
      }
 else {
        fail(""String_Node_Str"" + entry.getKey());
      }
    }
    hardwareDescription=HardwareDescriptionFactory.construct(3,2L * 1024L * 1024L* 1024L,1024L * 1024L * 1024L);
    ici=new InstanceConnectionInfo(InetAddress.getByName(""String_Node_Str""),ipcPort,dataPort);
    cm.reportHeartBeat(ici,hardwareDescription);
    instanceTypeDescriptions=cm.getMapOfAvailableInstanceTypes();
    assertEquals(3,instanceTypeDescriptions.size());
    it=instanceTypeDescriptions.entrySet().iterator();
    while (it.hasNext()) {
      final Map.Entry<InstanceType,InstanceTypeDescription> entry=it.next();
      if (LARGE_INSTANCE_TYPE_NAME.equals(entry.getKey().getIdentifier())) {
        assertEquals(1,entry.getValue().getMaximumNumberOfAvailableInstances());
      }
 else       if (MEDIUM_INSTANCE_TYPE_NAME.equals(entry.getKey().getIdentifier())) {
        assertEquals(2,entry.getValue().getMaximumNumberOfAvailableInstances());
      }
 else       if (SMALL_INSTANCE_TYPE_NAME.equals(entry.getKey().getIdentifier())) {
        assertEquals(5,entry.getValue().getMaximumNumberOfAvailableInstances());
      }
 else {
        fail(""String_Node_Str"" + entry.getKey());
      }
    }
  }
 catch (  UnknownHostException e) {
    fail(e.getMessage());
  }
 finally {
    if (cm != null) {
      cm.shutdown();
    }
  }
}","/** 
 * This test covers the matching of instances to instance types It addresses the automatic matching through the hardware description as well as user-defined instance type matching.
 */
@Test public void testInstanceMatching(){
  final String configDir=getConfigDir();
  if (configDir == null) {
    fail(""String_Node_Str"");
  }
  GlobalConfiguration.loadConfiguration(configDir);
  final TestInstanceListener testInstanceListener=new TestInstanceListener();
  final ClusterManager cm=new ClusterManager();
  cm.setInstanceListener(testInstanceListener);
  Map<InstanceType,InstanceTypeDescription> instanceTypeDescriptions=null;
  try {
    final int ipcPort=ConfigConstants.DEFAULT_TASK_MANAGER_IPC_PORT;
    final int dataPort=ConfigConstants.DEFAULT_TASK_MANAGER_DATA_PORT;
    HardwareDescription hardwareDescription=HardwareDescriptionFactory.construct(2,2L * 1024L * 1024L* 1024L,2L * 1024L * 1024L* 1024L);
    String ipAddress=""String_Node_Str"";
    InstanceConnectionInfo ici=new InstanceConnectionInfo(InetAddress.getByName(ipAddress),ipAddress,null,ipcPort,dataPort);
    cm.reportHeartBeat(ici,hardwareDescription);
    instanceTypeDescriptions=cm.getMapOfAvailableInstanceTypes();
    assertEquals(3,instanceTypeDescriptions.size());
    Iterator<Map.Entry<InstanceType,InstanceTypeDescription>> it=instanceTypeDescriptions.entrySet().iterator();
    while (it.hasNext()) {
      final Map.Entry<InstanceType,InstanceTypeDescription> entry=it.next();
      if (LARGE_INSTANCE_TYPE_NAME.equals(entry.getKey().getIdentifier())) {
        assertEquals(1,entry.getValue().getMaximumNumberOfAvailableInstances());
      }
 else       if (MEDIUM_INSTANCE_TYPE_NAME.equals(entry.getKey().getIdentifier())) {
        assertEquals(2,entry.getValue().getMaximumNumberOfAvailableInstances());
      }
 else       if (SMALL_INSTANCE_TYPE_NAME.equals(entry.getKey().getIdentifier())) {
        assertEquals(4,entry.getValue().getMaximumNumberOfAvailableInstances());
      }
 else {
        fail(""String_Node_Str"" + entry.getKey());
      }
    }
    hardwareDescription=HardwareDescriptionFactory.construct(3,2L * 1024L * 1024L* 1024L,1024L * 1024L * 1024L);
    ipAddress=""String_Node_Str"";
    ici=new InstanceConnectionInfo(InetAddress.getByName(ipAddress),ipAddress,null,ipcPort,dataPort);
    cm.reportHeartBeat(ici,hardwareDescription);
    instanceTypeDescriptions=cm.getMapOfAvailableInstanceTypes();
    assertEquals(3,instanceTypeDescriptions.size());
    it=instanceTypeDescriptions.entrySet().iterator();
    while (it.hasNext()) {
      final Map.Entry<InstanceType,InstanceTypeDescription> entry=it.next();
      if (LARGE_INSTANCE_TYPE_NAME.equals(entry.getKey().getIdentifier())) {
        assertEquals(1,entry.getValue().getMaximumNumberOfAvailableInstances());
      }
 else       if (MEDIUM_INSTANCE_TYPE_NAME.equals(entry.getKey().getIdentifier())) {
        assertEquals(2,entry.getValue().getMaximumNumberOfAvailableInstances());
      }
 else       if (SMALL_INSTANCE_TYPE_NAME.equals(entry.getKey().getIdentifier())) {
        assertEquals(5,entry.getValue().getMaximumNumberOfAvailableInstances());
      }
 else {
        fail(""String_Node_Str"" + entry.getKey());
      }
    }
  }
 catch (  UnknownHostException e) {
    fail(e.getMessage());
  }
 finally {
    if (cm != null) {
      cm.shutdown();
    }
  }
}",0.9480539148871724
55487,"/** 
 * This test checks the clean-up routines of the cluster manager.
 */
@Test public void testCleanUp(){
  GlobalConfiguration.loadConfiguration(System.getProperty(USER_DIR_KEY) + CORRECT_CONF_DIR);
  final TestInstanceListener testInstanceListener=new TestInstanceListener();
  final ClusterManager cm=new ClusterManager();
  cm.setInstanceListener(testInstanceListener);
  try {
    final InstanceConnectionInfo instanceConnectionInfo=new InstanceConnectionInfo(InetAddress.getByName(""String_Node_Str""),1234,1235);
    final HardwareDescription hardwareDescription=HardwareDescriptionFactory.construct(8,8L * 1024L * 1024L* 1024L,8L * 1024L * 1024L* 1024L);
    cm.reportHeartBeat(instanceConnectionInfo,hardwareDescription);
    final JobID jobID=new JobID();
    final Configuration conf=new Configuration();
    try {
      InstanceRequestMap instancem=new InstanceRequestMap();
      instancem.setNumberOfInstances(cm.getInstanceTypeByName(LARGE_INSTANCE_TYPE_NAME),1);
      cm.requestInstance(jobID,conf,instancem,null);
    }
 catch (    InstanceException ie) {
      fail(ie.getMessage());
    }
    ClusterManagerTestUtils.waitForInstances(jobID,testInstanceListener,1,MAX_WAIT_TIME);
    assertEquals(1,testInstanceListener.getNumberOfAllocatedResourcesForJob(jobID));
    try {
      Thread.sleep(CLEAN_UP_INTERVAL);
    }
 catch (    InterruptedException ie) {
      fail(ie.getMessage());
    }
    ClusterManagerTestUtils.waitForInstances(jobID,testInstanceListener,0,MAX_WAIT_TIME);
    assertEquals(0,testInstanceListener.getNumberOfAllocatedResourcesForJob(jobID));
  }
 catch (  UnknownHostException e) {
    fail(e.getMessage());
  }
 finally {
    if (cm != null) {
      cm.shutdown();
    }
  }
}","/** 
 * This test checks the clean-up routines of the cluster manager.
 */
@Test public void testCleanUp(){
  GlobalConfiguration.loadConfiguration(System.getProperty(USER_DIR_KEY) + CORRECT_CONF_DIR);
  final TestInstanceListener testInstanceListener=new TestInstanceListener();
  final ClusterManager cm=new ClusterManager();
  cm.setInstanceListener(testInstanceListener);
  try {
    final String ipAddress=""String_Node_Str"";
    final InstanceConnectionInfo instanceConnectionInfo=new InstanceConnectionInfo(InetAddress.getByName(ipAddress),ipAddress,null,1234,1235);
    final HardwareDescription hardwareDescription=HardwareDescriptionFactory.construct(8,8L * 1024L * 1024L* 1024L,8L * 1024L * 1024L* 1024L);
    cm.reportHeartBeat(instanceConnectionInfo,hardwareDescription);
    final JobID jobID=new JobID();
    final Configuration conf=new Configuration();
    try {
      InstanceRequestMap instancem=new InstanceRequestMap();
      instancem.setNumberOfInstances(cm.getInstanceTypeByName(LARGE_INSTANCE_TYPE_NAME),1);
      cm.requestInstance(jobID,conf,instancem,null);
    }
 catch (    InstanceException ie) {
      fail(ie.getMessage());
    }
    ClusterManagerTestUtils.waitForInstances(jobID,testInstanceListener,1,MAX_WAIT_TIME);
    assertEquals(1,testInstanceListener.getNumberOfAllocatedResourcesForJob(jobID));
    try {
      Thread.sleep(CLEAN_UP_INTERVAL);
    }
 catch (    InterruptedException ie) {
      fail(ie.getMessage());
    }
    ClusterManagerTestUtils.waitForInstances(jobID,testInstanceListener,0,MAX_WAIT_TIME);
    assertEquals(0,testInstanceListener.getNumberOfAllocatedResourcesForJob(jobID));
  }
 catch (  UnknownHostException e) {
    fail(e.getMessage());
  }
 finally {
    if (cm != null) {
      cm.shutdown();
    }
  }
}",0.9745641611889112
55488,"/** 
 * This test checks the correctness of extracting instance types from the configuration, mapping IPs to instance types from the slave file, instance slicing and allocation/deallocation.
 */
@Test public void testAllocationDeallocation(){
  final String configDir=getConfigDir();
  if (configDir == null) {
    fail(""String_Node_Str"");
  }
  GlobalConfiguration.loadConfiguration(configDir);
  final TestInstanceListener testInstanceListener=new TestInstanceListener();
  final ClusterManager cm=new ClusterManager();
  cm.setInstanceListener(testInstanceListener);
  try {
    final InstanceConnectionInfo instanceConnectionInfo=new InstanceConnectionInfo(InetAddress.getByName(""String_Node_Str""),1234,1235);
    final HardwareDescription hardwareDescription=HardwareDescriptionFactory.construct(8,8L * 1024L * 1024L* 1024L,8L * 1024L * 1024L* 1024L);
    cm.reportHeartBeat(instanceConnectionInfo,hardwareDescription);
    final JobID jobID=new JobID();
    final Configuration conf=new Configuration();
    final InstanceRequestMap instanceRequestMap=new InstanceRequestMap();
    instanceRequestMap.setNumberOfInstances(cm.getInstanceTypeByName(SMALL_INSTANCE_TYPE_NAME),2);
    instanceRequestMap.setNumberOfInstances(cm.getInstanceTypeByName(MEDIUM_INSTANCE_TYPE_NAME),1);
    try {
      cm.requestInstance(jobID,conf,instanceRequestMap,null);
    }
 catch (    InstanceException ie) {
      fail(ie.getMessage());
    }
    ClusterManagerTestUtils.waitForInstances(jobID,testInstanceListener,3,MAX_WAIT_TIME);
    final List<AllocatedResource> allocatedResources=testInstanceListener.getAllocatedResourcesForJob(jobID);
    assertEquals(3,allocatedResources.size());
    Iterator<AllocatedResource> it=allocatedResources.iterator();
    final Set<AllocationID> allocationIDs=new HashSet<AllocationID>();
    while (it.hasNext()) {
      final AllocatedResource allocatedResource=it.next();
      if (!LARGE_INSTANCE_TYPE_NAME.equals(allocatedResource.getInstance().getType().getIdentifier())) {
        fail(""String_Node_Str"" + allocatedResource.getInstance().getType().getIdentifier());
      }
      if (allocationIDs.contains(allocatedResource.getAllocationID())) {
        fail(""String_Node_Str"" + allocatedResource.getAllocationID() + ""String_Node_Str"");
      }
 else {
        allocationIDs.add(allocatedResource.getAllocationID());
      }
    }
    try {
      InstanceRequestMap instancem=new InstanceRequestMap();
      instancem.setNumberOfInstances(cm.getInstanceTypeByName(MEDIUM_INSTANCE_TYPE_NAME),1);
      cm.requestInstance(jobID,conf,instancem,null);
      fail(""String_Node_Str"");
    }
 catch (    InstanceException ie) {
    }
    it=allocatedResources.iterator();
    try {
      while (it.hasNext()) {
        final AllocatedResource allocatedResource=it.next();
        cm.releaseAllocatedResource(jobID,conf,allocatedResource);
      }
    }
 catch (    InstanceException ie) {
      fail(ie.getMessage());
    }
    try {
      InstanceRequestMap instancem=new InstanceRequestMap();
      instancem.setNumberOfInstances(cm.getInstanceTypeByName(LARGE_INSTANCE_TYPE_NAME),1);
      cm.requestInstance(jobID,conf,instancem,null);
    }
 catch (    InstanceException ie) {
      fail(ie.getMessage());
    }
  }
 catch (  UnknownHostException e) {
    fail(e.getMessage());
  }
 finally {
    if (cm != null) {
      cm.shutdown();
    }
  }
}","/** 
 * This test checks the correctness of extracting instance types from the configuration, mapping IPs to instance types from the slave file, instance slicing and allocation/deallocation.
 */
@Test public void testAllocationDeallocation(){
  final String configDir=getConfigDir();
  if (configDir == null) {
    fail(""String_Node_Str"");
  }
  GlobalConfiguration.loadConfiguration(configDir);
  final TestInstanceListener testInstanceListener=new TestInstanceListener();
  final ClusterManager cm=new ClusterManager();
  cm.setInstanceListener(testInstanceListener);
  try {
    final String ipAddress=""String_Node_Str"";
    final InstanceConnectionInfo instanceConnectionInfo=new InstanceConnectionInfo(InetAddress.getByName(ipAddress),ipAddress,null,1234,1235);
    final HardwareDescription hardwareDescription=HardwareDescriptionFactory.construct(8,8L * 1024L * 1024L* 1024L,8L * 1024L * 1024L* 1024L);
    cm.reportHeartBeat(instanceConnectionInfo,hardwareDescription);
    final JobID jobID=new JobID();
    final Configuration conf=new Configuration();
    final InstanceRequestMap instanceRequestMap=new InstanceRequestMap();
    instanceRequestMap.setNumberOfInstances(cm.getInstanceTypeByName(SMALL_INSTANCE_TYPE_NAME),2);
    instanceRequestMap.setNumberOfInstances(cm.getInstanceTypeByName(MEDIUM_INSTANCE_TYPE_NAME),1);
    try {
      cm.requestInstance(jobID,conf,instanceRequestMap,null);
    }
 catch (    InstanceException ie) {
      fail(ie.getMessage());
    }
    ClusterManagerTestUtils.waitForInstances(jobID,testInstanceListener,3,MAX_WAIT_TIME);
    final List<AllocatedResource> allocatedResources=testInstanceListener.getAllocatedResourcesForJob(jobID);
    assertEquals(3,allocatedResources.size());
    Iterator<AllocatedResource> it=allocatedResources.iterator();
    final Set<AllocationID> allocationIDs=new HashSet<AllocationID>();
    while (it.hasNext()) {
      final AllocatedResource allocatedResource=it.next();
      if (!LARGE_INSTANCE_TYPE_NAME.equals(allocatedResource.getInstance().getType().getIdentifier())) {
        fail(""String_Node_Str"" + allocatedResource.getInstance().getType().getIdentifier());
      }
      if (allocationIDs.contains(allocatedResource.getAllocationID())) {
        fail(""String_Node_Str"" + allocatedResource.getAllocationID() + ""String_Node_Str"");
      }
 else {
        allocationIDs.add(allocatedResource.getAllocationID());
      }
    }
    try {
      InstanceRequestMap instancem=new InstanceRequestMap();
      instancem.setNumberOfInstances(cm.getInstanceTypeByName(MEDIUM_INSTANCE_TYPE_NAME),1);
      cm.requestInstance(jobID,conf,instancem,null);
      fail(""String_Node_Str"");
    }
 catch (    InstanceException ie) {
    }
    it=allocatedResources.iterator();
    try {
      while (it.hasNext()) {
        final AllocatedResource allocatedResource=it.next();
        cm.releaseAllocatedResource(jobID,conf,allocatedResource);
      }
    }
 catch (    InstanceException ie) {
      fail(ie.getMessage());
    }
    try {
      InstanceRequestMap instancem=new InstanceRequestMap();
      instancem.setNumberOfInstances(cm.getInstanceTypeByName(LARGE_INSTANCE_TYPE_NAME),1);
      cm.requestInstance(jobID,conf,instancem,null);
    }
 catch (    InstanceException ie) {
      fail(ie.getMessage());
    }
  }
 catch (  UnknownHostException e) {
    fail(e.getMessage());
  }
 finally {
    if (cm != null) {
      cm.shutdown();
    }
  }
}",0.9869367385879936
55489,"/** 
 * {@inheritDoc}
 */
@Override public void read(DataInput in) throws IOException {
  final int addr_length=in.readInt();
  byte[] address=new byte[addr_length];
  in.readFully(address);
  this.hostname=StringRecord.readString(in);
  this.domainname=StringRecord.readString(in);
  try {
    this.inetAddress=InetAddress.getByAddress(address);
  }
 catch (  UnknownHostException uhe) {
    throw new IOException(StringUtils.stringifyException(uhe));
  }
  this.ipcPort=in.readInt();
  this.dataPort=in.readInt();
}","/** 
 * {@inheritDoc}
 */
@Override public void read(final DataInput in) throws IOException {
  final int addr_length=in.readInt();
  byte[] address=new byte[addr_length];
  in.readFully(address);
  this.hostName=StringRecord.readString(in);
  this.domainName=StringRecord.readString(in);
  try {
    this.inetAddress=InetAddress.getByAddress(address);
  }
 catch (  UnknownHostException uhe) {
    throw new IOException(StringUtils.stringifyException(uhe));
  }
  this.ipcPort=in.readInt();
  this.dataPort=in.readInt();
}",0.9903846153846154
55490,"/** 
 * Returns the host name of the instance. If the host name could not be determined, the return value will be a textual representation of the instance's IP address.
 * @return the host name of the instance
 */
public String getHostName(){
  return this.hostname;
}","/** 
 * Returns the host name of the instance. If the host name could not be determined, the return value will be a textual representation of the instance's IP address.
 * @return the host name of the instance
 */
public String getHostName(){
  return this.hostName;
}",0.996268656716418
55491,"/** 
 * {@inheritDoc}
 */
@Override public boolean equals(Object obj){
  if (obj instanceof InstanceConnectionInfo) {
    InstanceConnectionInfo ici=(InstanceConnectionInfo)obj;
    if (!this.inetAddress.equals(ici.getAddress())) {
      return false;
    }
    if (this.ipcPort != ici.getIPCPort()) {
      return false;
    }
    if (this.dataPort != ici.getDataPort()) {
      return false;
    }
    return true;
  }
  return false;
}","/** 
 * {@inheritDoc}
 */
@Override public boolean equals(final Object obj){
  if (obj instanceof InstanceConnectionInfo) {
    InstanceConnectionInfo ici=(InstanceConnectionInfo)obj;
    if (!this.inetAddress.equals(ici.getAddress())) {
      return false;
    }
    if (this.ipcPort != ici.getIPCPort()) {
      return false;
    }
    if (this.dataPort != ici.getDataPort()) {
      return false;
    }
    return true;
  }
  return false;
}",0.9931972789115646
55492,"/** 
 * {@inheritDoc}
 */
@Override public String toString(){
  String iaString;
  if (this.hostname != null) {
    iaString=this.hostname;
  }
 else {
    iaString=inetAddress.toString();
    iaString=iaString.replace(""String_Node_Str"",""String_Node_Str"");
  }
  return iaString;
}","/** 
 * {@inheritDoc}
 */
@Override public String toString(){
  String iaString;
  if (this.hostName != null) {
    iaString=this.hostName;
  }
 else {
    iaString=inetAddress.toString();
    iaString=iaString.replace(""String_Node_Str"",""String_Node_Str"");
  }
  return iaString;
}",0.99288256227758
55493,"@Override public int compareTo(InstanceConnectionInfo o){
  return this.getAddress().getHostName().compareTo(((InstanceConnectionInfo)o).getAddress().getHostName());
}","/** 
 * {@inheritDoc}
 */
@Override public int compareTo(final InstanceConnectionInfo o){
  return this.getAddress().getHostName().compareTo(((InstanceConnectionInfo)o).getAddress().getHostName());
}",0.912568306010929
55494,"/** 
 * Returns the domain name of the instance.
 * @return the domain name of the instance or <code>null</code> if the domain name could not be determined
 */
public String getDomainName(){
  return this.domainname;
}","/** 
 * Returns the domain name of the instance.
 * @return the domain name of the instance or <code>null</code> if the domain name could not be determined
 */
public String getDomainName(){
  return this.domainName;
}",0.9954128440366972
55495,"/** 
 * {@inheritDoc}
 */
@Override public void write(DataOutput out) throws IOException {
  out.writeInt(this.inetAddress.getAddress().length);
  out.write(this.inetAddress.getAddress());
  StringRecord.writeString(out,this.hostname);
  StringRecord.writeString(out,this.domainname);
  out.writeInt(this.ipcPort);
  out.writeInt(this.dataPort);
}","/** 
 * {@inheritDoc}
 */
@Override public void write(final DataOutput out) throws IOException {
  out.writeInt(this.inetAddress.getAddress().length);
  out.write(this.inetAddress.getAddress());
  StringRecord.writeString(out,this.hostName);
  StringRecord.writeString(out,this.domainName);
  out.writeInt(this.ipcPort);
  out.writeInt(this.dataPort);
}",0.9857142857142858
55496,"/** 
 * {@inheritDoc}
 */
@Override public void queueTransferEnvelope(final TransferEnvelope transferEnvelope){
  final int sequenceNumber=transferEnvelope.getSequenceNumber();
  AbstractEvent eventToSend=null;
  if (ReceiverNotFoundEvent.isReceiverNotFoundEvent(transferEnvelope)) {
    return;
  }
synchronized (this.queuedEnvelopes) {
    if (this.destroyCalled) {
      final Buffer buffer=transferEnvelope.getBuffer();
      if (buffer != null) {
        buffer.recycleBuffer();
      }
      return;
    }
    final int expectedSequenceNumber=this.lastReceivedEnvelope + 1;
    if (sequenceNumber != expectedSequenceNumber) {
      if (sequenceNumber > expectedSequenceNumber) {
        if (expectedSequenceNumber > 2000) {
          this.byteBufferedInputChannel.reportIOException(new IOException(""String_Node_Str"" + expectedSequenceNumber + ""String_Node_Str""+ sequenceNumber));
          this.byteBufferedInputChannel.checkForNetworkEvents();
        }
      }
 else {
        eventToSend=lookForCloseEvent(transferEnvelope);
        if (eventToSend == null) {
          eventToSend=new UnexpectedEnvelopeEvent(expectedSequenceNumber - 1);
        }
      }
      LOG.warn(""String_Node_Str"" + getChannelName() + ""String_Node_Str""+ expectedSequenceNumber+ ""String_Node_Str""+ sequenceNumber);
      final Buffer buffer=transferEnvelope.getBuffer();
      if (buffer != null) {
        buffer.recycleBuffer();
      }
    }
 else {
      this.queuedEnvelopes.add(transferEnvelope);
      this.lastReceivedEnvelope=sequenceNumber;
      this.envelopeConsumptionLog.reportEnvelopeAvailability(this.byteBufferedInputChannel);
    }
  }
  if (eventToSend != null) {
    try {
      transferEventToOutputChannel(eventToSend);
    }
 catch (    Exception e) {
      LOG.error(StringUtils.stringifyException(e));
    }
  }
}","/** 
 * {@inheritDoc}
 */
@Override public void queueTransferEnvelope(final TransferEnvelope transferEnvelope){
  final int sequenceNumber=transferEnvelope.getSequenceNumber();
  AbstractEvent eventToSend=null;
  if (ReceiverNotFoundEvent.isReceiverNotFoundEvent(transferEnvelope)) {
    return;
  }
synchronized (this.queuedEnvelopes) {
    if (this.destroyCalled) {
      final Buffer buffer=transferEnvelope.getBuffer();
      if (buffer != null) {
        buffer.recycleBuffer();
      }
      return;
    }
    final int expectedSequenceNumber=this.lastReceivedEnvelope + 1;
    if (sequenceNumber != expectedSequenceNumber) {
      if (sequenceNumber > expectedSequenceNumber) {
        if (!this.isReexecuted) {
          this.byteBufferedInputChannel.reportIOException(new IOException(""String_Node_Str"" + expectedSequenceNumber + ""String_Node_Str""+ sequenceNumber));
          this.byteBufferedInputChannel.checkForNetworkEvents();
        }
      }
 else {
        eventToSend=lookForCloseEvent(transferEnvelope);
        if (eventToSend == null) {
          eventToSend=new UnexpectedEnvelopeEvent(expectedSequenceNumber - 1);
        }
      }
      LOG.warn(""String_Node_Str"" + getChannelName() + ""String_Node_Str""+ expectedSequenceNumber+ ""String_Node_Str""+ sequenceNumber);
      final Buffer buffer=transferEnvelope.getBuffer();
      if (buffer != null) {
        buffer.recycleBuffer();
      }
    }
 else {
      this.queuedEnvelopes.add(transferEnvelope);
      this.lastReceivedEnvelope=sequenceNumber;
      this.envelopeConsumptionLog.reportEnvelopeAvailability(this.byteBufferedInputChannel);
    }
  }
  if (eventToSend != null) {
    try {
      transferEventToOutputChannel(eventToSend);
    }
 catch (    Exception e) {
      LOG.error(StringUtils.stringifyException(e));
    }
  }
}",0.9881640517478668
55497,"RuntimeInputChannelContext(final RuntimeInputGateContext inputGateContext,final TransferEnvelopeDispatcher transferEnvelopeDispatcher,final AbstractByteBufferedInputChannel<?> byteBufferedInputChannel,final EnvelopeConsumptionLog envelopeConsumptionLog){
  this.inputGateContext=inputGateContext;
  this.transferEnvelopeDispatcher=transferEnvelopeDispatcher;
  this.byteBufferedInputChannel=byteBufferedInputChannel;
  this.byteBufferedInputChannel.setInputChannelBroker(this);
  this.envelopeConsumptionLog=envelopeConsumptionLog;
}","RuntimeInputChannelContext(final RuntimeInputGateContext inputGateContext,final TransferEnvelopeDispatcher transferEnvelopeDispatcher,final AbstractByteBufferedInputChannel<?> byteBufferedInputChannel,final EnvelopeConsumptionLog envelopeConsumptionLog){
  this.inputGateContext=inputGateContext;
  this.transferEnvelopeDispatcher=transferEnvelopeDispatcher;
  this.byteBufferedInputChannel=byteBufferedInputChannel;
  this.byteBufferedInputChannel.setInputChannelBroker(this);
  this.envelopeConsumptionLog=envelopeConsumptionLog;
  this.isReexecuted=(envelopeConsumptionLog.getNumberOfInitialLogEntries() > 0L);
}",0.9285714285714286
55498,"public ChannelReaderInputView(BlockChannelReader reader,List<MemorySegment> memory,int numBlocks,boolean waitForFirstBlock) throws IOException {
  super(ChannelWriterOutputView.HEADER_LENGTH);
  if (reader == null || memory == null)   throw new NullPointerException();
  if (memory.isEmpty())   throw new IllegalArgumentException(""String_Node_Str"");
  if (numBlocks < 1 && numBlocks != -1) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  this.reader=reader;
  this.numRequestsRemaining=numBlocks;
  this.numSegments=memory.size();
  for (int i=0; i < memory.size(); i++) {
    sendReadRequest(memory.get(i));
  }
  if (waitForFirstBlock) {
    advance();
  }
}","public ChannelReaderInputView(BlockChannelReader reader,List<MemorySegment> memory,int numBlocks,boolean waitForFirstBlock) throws IOException {
  super(ChannelWriterOutputView.HEADER_LENGTH);
  if (reader == null || memory == null)   throw new NullPointerException();
  if (memory.isEmpty())   throw new IllegalArgumentException(""String_Node_Str"");
  if (numBlocks < 1 && numBlocks != -1) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  this.reader=reader;
  this.numRequestsRemaining=numBlocks;
  this.numSegments=memory.size();
  this.freeMem=new ArrayList<MemorySegment>(this.numSegments);
  for (int i=0; i < memory.size(); i++) {
    sendReadRequest(memory.get(i));
  }
  if (waitForFirstBlock) {
    advance();
  }
}",0.955665024630542
55499,"/** 
 * Sends a new read requests, if further requests remain. Otherwise, this method adds the segment directly to the readers return queue.
 * @param seg The segment to use for the read request.
 * @throws IOException Thrown, if the reader is in error.
 */
private void sendReadRequest(MemorySegment seg) throws IOException {
  if (this.numRequestsRemaining != 0) {
    this.reader.readBlock(seg);
    if (this.numRequestsRemaining != -1) {
      this.numRequestsRemaining--;
    }
  }
 else {
    this.reader.getReturnQueue().add(seg);
  }
}","/** 
 * Sends a new read requests, if further requests remain. Otherwise, this method adds the segment directly to the readers return queue.
 * @param seg The segment to use for the read request.
 * @throws IOException Thrown, if the reader is in error.
 */
private void sendReadRequest(MemorySegment seg) throws IOException {
  if (this.numRequestsRemaining != 0) {
    this.reader.readBlock(seg);
    if (this.numRequestsRemaining != -1) {
      this.numRequestsRemaining--;
    }
  }
 else {
    this.freeMem.add(seg);
  }
}",0.97196261682243
55500,"/** 
 * Closes this InoutView, closing the underlying reader and returning all memory segments.
 * @return A list containing all memory segments originally supplied to this view.
 * @throws IOException Thrown, if the underlying reader could not be properly closed.
 */
public List<MemorySegment> close() throws IOException {
  if (this.closed) {
    throw new IllegalStateException(""String_Node_Str"");
  }
  this.closed=true;
  ArrayList<MemorySegment> list=new ArrayList<MemorySegment>(this.numSegments);
  final MemorySegment current=getCurrentSegment();
  if (current != null) {
    list.add(current);
  }
  clear();
  final LinkedBlockingQueue<MemorySegment> queue=this.reader.getReturnQueue();
  this.reader.close();
  while (list.size() < this.numSegments) {
    final MemorySegment m=queue.poll();
    if (m == null) {
      throw new RuntimeException(""String_Node_Str"");
    }
    list.add(m);
  }
  return list;
}","/** 
 * Closes this InputView, closing the underlying reader and returning all memory segments.
 * @return A list containing all memory segments originally supplied to this view.
 * @throws IOException Thrown, if the underlying reader could not be properly closed.
 */
public List<MemorySegment> close() throws IOException {
  if (this.closed) {
    throw new IllegalStateException(""String_Node_Str"");
  }
  this.closed=true;
  ArrayList<MemorySegment> list=this.freeMem;
  final MemorySegment current=getCurrentSegment();
  if (current != null) {
    list.add(current);
  }
  clear();
  final LinkedBlockingQueue<MemorySegment> queue=this.reader.getReturnQueue();
  this.reader.close();
  while (list.size() < this.numSegments) {
    final MemorySegment m=queue.poll();
    if (m == null) {
      throw new RuntimeException(""String_Node_Str"");
    }
    list.add(m);
  }
  return list;
}",0.8110497237569061
55501,"/** 
 * Creates an new ChannelWriterOutputView that writes to the given channel. It uses only a single memory segment for the buffering, which it takes from the writers return queue.
 * @param writer The writer to write to.
 * @param segmentSize The size of the memory segments.
 */
public ChannelWriterOutputView(BlockChannelWriter writer,int segmentSize){
  this(writer,null,segmentSize);
}","/** 
 * Creates an new ChannelWriterOutputView that writes to the given channel. It uses only a single memory segment for the buffering, which it takes from the writers return queue. Note that this variant locks if no buffers are contained in the return queue.
 * @param writer The writer to write to.
 * @param segmentSize The size of the memory segments.
 */
public ChannelWriterOutputView(BlockChannelWriter writer,int segmentSize){
  this(writer,null,segmentSize);
}",0.9095127610208816
55502,"/** 
 * {@inheritDoc}
 */
@Override public void processEvent(final AbstractEvent event){
  if (event instanceof ByteBufferedChannelCloseEvent) {
    LOG.info(""String_Node_Str"");
  }
 else   if (event instanceof UnexpectedEnvelopeEvent) {
    final UnexpectedEnvelopeEvent uee=(UnexpectedEnvelopeEvent)event;
    if (uee.getExpectedSequenceNumber() > this.nextEnvelopeToSend) {
      this.nextEnvelopeToSend=uee.getExpectedSequenceNumber();
    }
  }
 else   if (event instanceof ReceiverNotFoundEvent) {
    final ReceiverNotFoundEvent rnfe=(ReceiverNotFoundEvent)event;
    LOG.warn(""String_Node_Str"" + rnfe.getReceiverID() + ""String_Node_Str""+ rnfe.getSequenceNumber());
  }
 else {
    LOG.warn(""String_Node_Str"" + event);
  }
  getNext().processEvent(event);
}","/** 
 * {@inheritDoc}
 */
@Override public void processEvent(final AbstractEvent event){
  if (event instanceof ByteBufferedChannelCloseEvent) {
    LOG.info(""String_Node_Str"");
  }
 else   if (event instanceof UnexpectedEnvelopeEvent) {
    final UnexpectedEnvelopeEvent uee=(UnexpectedEnvelopeEvent)event;
    if (uee.getExpectedSequenceNumber() > this.nextEnvelopeToSend) {
      this.nextEnvelopeToSend=uee.getExpectedSequenceNumber();
    }
  }
 else   if (event instanceof ReceiverNotFoundEvent) {
    final ReceiverNotFoundEvent rnfe=(ReceiverNotFoundEvent)event;
    LOG.warn(""String_Node_Str"" + rnfe.getReceiverID() + ""String_Node_Str""+ rnfe.getSequenceNumber()+ ""String_Node_Str""+ this.nextEnvelopeToSend);
  }
 else {
    LOG.warn(""String_Node_Str"" + event);
  }
  getNext().processEvent(event);
}",0.9720101781170484
55503,"private void replayCheckpoint() throws Exception {
  final CheckpointDeserializer deserializer=new CheckpointDeserializer(this.vertexID,!this.isCheckpointLocal);
  final Path checkpointPath=this.isCheckpointLocal ? CheckpointUtils.getLocalCheckpointPath() : CheckpointUtils.getDistributedCheckpointPath();
  if (checkpointPath == null) {
    throw new IOException(""String_Node_Str"" + this.vertexID);
  }
  final FileSystem fileSystem=checkpointPath.getFileSystem();
  int metaDataIndex=0;
  Buffer firstDeserializedFileBuffer=null;
  FileChannel fileChannel=null;
  try {
    while (true) {
      if (this.restartRequested.compareAndSet(true,false)) {
        metaDataIndex=0;
      }
      final Path metaDataFile=checkpointPath.suffix(Path.SEPARATOR + CheckpointUtils.METADATA_PREFIX + ""String_Node_Str""+ this.vertexID+ ""String_Node_Str""+ metaDataIndex);
      while (!fileSystem.exists(metaDataFile)) {
        final Path finalMetaDataFile=checkpointPath.suffix(Path.SEPARATOR + CheckpointUtils.METADATA_PREFIX + ""String_Node_Str""+ this.vertexID+ ""String_Node_Str"");
        if (fileSystem.exists(finalMetaDataFile)) {
          return;
        }
        if (this.isCheckpointComplete) {
          throw new FileNotFoundException(""String_Node_Str"" + metaDataIndex + ""String_Node_Str""+ this.vertexID);
        }
        Thread.sleep(1000);
        if (this.executionObserver.isCanceled()) {
          return;
        }
      }
      fileChannel=getFileChannel(fileSystem,metaDataFile);
      while (true) {
        try {
          deserializer.read(fileChannel);
          final TransferEnvelope transferEnvelope=deserializer.getFullyDeserializedTransferEnvelope();
          if (transferEnvelope != null) {
            final ReplayOutputChannelBroker broker=this.outputBrokerMap.get(transferEnvelope.getSource());
            if (broker == null) {
              throw new IOException(""String_Node_Str"" + transferEnvelope.getSource());
            }
            final Buffer srcBuffer=transferEnvelope.getBuffer();
            if (srcBuffer != null) {
              if (firstDeserializedFileBuffer == null) {
                firstDeserializedFileBuffer=srcBuffer.duplicate();
              }
              if (transferEnvelope.getSequenceNumber() < broker.getNextEnvelopeToSend()) {
                srcBuffer.recycleBuffer();
                continue;
              }
              final Buffer destBuffer=broker.requestEmptyBufferBlocking(srcBuffer.size());
              srcBuffer.copyToBuffer(destBuffer);
              transferEnvelope.setBuffer(destBuffer);
              srcBuffer.recycleBuffer();
            }
            broker.outputEnvelope(transferEnvelope);
            if (this.executionObserver.isCanceled()) {
              return;
            }
          }
        }
 catch (        EOFException eof) {
          fileChannel.close();
          fileChannel=null;
          ++metaDataIndex;
          break;
        }
      }
    }
  }
  finally {
    if (firstDeserializedFileBuffer != null) {
      firstDeserializedFileBuffer.recycleBuffer();
      firstDeserializedFileBuffer=null;
    }
    if (fileChannel != null) {
      fileChannel.close();
      fileChannel=null;
    }
  }
}","private void replayCheckpoint() throws Exception {
  final CheckpointDeserializer deserializer=new CheckpointDeserializer(this.vertexID,!this.isCheckpointLocal);
  final Path checkpointPath=this.isCheckpointLocal ? CheckpointUtils.getLocalCheckpointPath() : CheckpointUtils.getDistributedCheckpointPath();
  if (checkpointPath == null) {
    throw new IOException(""String_Node_Str"" + this.vertexID);
  }
  final FileSystem fileSystem=checkpointPath.getFileSystem();
  int metaDataIndex=0;
  Buffer firstDeserializedFileBuffer=null;
  FileChannel fileChannel=null;
  try {
    while (true) {
      if (this.restartRequested.compareAndSet(true,false)) {
        metaDataIndex=0;
        resetAllOutputBroker();
      }
      final Path metaDataFile=checkpointPath.suffix(Path.SEPARATOR + CheckpointUtils.METADATA_PREFIX + ""String_Node_Str""+ this.vertexID+ ""String_Node_Str""+ metaDataIndex);
      while (!fileSystem.exists(metaDataFile)) {
        final Path finalMetaDataFile=checkpointPath.suffix(Path.SEPARATOR + CheckpointUtils.METADATA_PREFIX + ""String_Node_Str""+ this.vertexID+ ""String_Node_Str"");
        if (fileSystem.exists(finalMetaDataFile)) {
          return;
        }
        if (this.isCheckpointComplete) {
          throw new FileNotFoundException(""String_Node_Str"" + metaDataIndex + ""String_Node_Str""+ this.vertexID);
        }
        Thread.sleep(1000);
        if (this.executionObserver.isCanceled()) {
          return;
        }
      }
      fileChannel=getFileChannel(fileSystem,metaDataFile);
      while (true) {
        try {
          deserializer.read(fileChannel);
          final TransferEnvelope transferEnvelope=deserializer.getFullyDeserializedTransferEnvelope();
          if (transferEnvelope != null) {
            final ReplayOutputChannelBroker broker=this.outputBrokerMap.get(transferEnvelope.getSource());
            if (broker == null) {
              throw new IOException(""String_Node_Str"" + transferEnvelope.getSource());
            }
            final Buffer srcBuffer=transferEnvelope.getBuffer();
            if (srcBuffer != null) {
              if (firstDeserializedFileBuffer == null) {
                firstDeserializedFileBuffer=srcBuffer.duplicate();
              }
              if (transferEnvelope.getSequenceNumber() < broker.getNextEnvelopeToSend()) {
                srcBuffer.recycleBuffer();
                continue;
              }
              final Buffer destBuffer=broker.requestEmptyBufferBlocking(srcBuffer.size());
              srcBuffer.copyToBuffer(destBuffer);
              transferEnvelope.setBuffer(destBuffer);
              srcBuffer.recycleBuffer();
            }
            broker.outputEnvelope(transferEnvelope);
            if (this.executionObserver.isCanceled()) {
              return;
            }
          }
        }
 catch (        EOFException eof) {
          fileChannel.close();
          fileChannel=null;
          ++metaDataIndex;
          break;
        }
      }
    }
  }
  finally {
    if (firstDeserializedFileBuffer != null) {
      firstDeserializedFileBuffer.recycleBuffer();
      firstDeserializedFileBuffer=null;
    }
    if (fileChannel != null) {
      fileChannel.close();
      fileChannel=null;
    }
  }
}",0.99502796768179
55504,"/** 
 * {@inheritDoc}
 */
@Override public void run(){
  changeExecutionState(ExecutionState.REPLAYING,null);
  if (this.executionObserver.isCanceled()) {
    changeExecutionState(ExecutionState.CANCELED,null);
    return;
  }
  resetAllOutputBroker();
  try {
    replayCheckpoint();
    if (this.executionObserver.isCanceled()) {
      throw new InterruptedException();
    }
  }
 catch (  Exception e) {
    if (this.executionObserver.isCanceled()) {
      changeExecutionState(ExecutionState.CANCELED,null);
    }
 else {
      changeExecutionState(ExecutionState.FAILED,StringUtils.stringifyException(e));
    }
    return;
  }
  changeExecutionState(ExecutionState.FINISHING,null);
  try {
    waitForAllOutputBrokerToFinish();
  }
 catch (  Exception e) {
    if (this.executionObserver.isCanceled()) {
      changeExecutionState(ExecutionState.CANCELED,null);
    }
 else {
      changeExecutionState(ExecutionState.FAILED,StringUtils.stringifyException(e));
    }
    return;
  }
  changeExecutionState(ExecutionState.FINISHED,null);
}","/** 
 * {@inheritDoc}
 */
@Override public void run(){
  changeExecutionState(ExecutionState.REPLAYING,null);
  if (this.executionObserver.isCanceled()) {
    changeExecutionState(ExecutionState.CANCELED,null);
    return;
  }
  try {
    replayCheckpoint();
    if (this.executionObserver.isCanceled()) {
      throw new InterruptedException();
    }
  }
 catch (  Exception e) {
    if (this.executionObserver.isCanceled()) {
      changeExecutionState(ExecutionState.CANCELED,null);
    }
 else {
      changeExecutionState(ExecutionState.FAILED,StringUtils.stringifyException(e));
    }
    return;
  }
  changeExecutionState(ExecutionState.FINISHING,null);
  try {
    waitForAllOutputBrokerToFinish();
  }
 catch (  Exception e) {
    if (this.executionObserver.isCanceled()) {
      changeExecutionState(ExecutionState.CANCELED,null);
    }
 else {
      changeExecutionState(ExecutionState.FAILED,StringUtils.stringifyException(e));
    }
    return;
  }
  changeExecutionState(ExecutionState.FINISHED,null);
}",0.9873908826382152
55505,"void restart(){
  changeExecutionState(ExecutionState.STARTING,null);
  this.restartRequested.set(true);
  interrupt();
  this.interruptCalled.set(true);
}","void restart(){
  changeExecutionState(ExecutionState.STARTING,null);
  this.restartRequested.set(true);
  changeExecutionState(ExecutionState.REPLAYING,null);
}",0.7784810126582279
55506,"private void replayCheckpoint() throws Exception {
  final CheckpointDeserializer deserializer=new CheckpointDeserializer(this.vertexID,!this.isCheckpointLocal);
  final Path checkpointPath=this.isCheckpointLocal ? CheckpointUtils.getLocalCheckpointPath() : CheckpointUtils.getDistributedCheckpointPath();
  if (checkpointPath == null) {
    throw new IOException(""String_Node_Str"" + this.vertexID);
  }
  final FileSystem fileSystem=checkpointPath.getFileSystem();
  int metaDataIndex=0;
  Buffer firstDeserializedFileBuffer=null;
  FileChannel fileChannel=null;
  try {
    while (true) {
      final Path metaDataFile=checkpointPath.suffix(Path.SEPARATOR + CheckpointUtils.METADATA_PREFIX + ""String_Node_Str""+ this.vertexID+ ""String_Node_Str""+ metaDataIndex);
      while (!fileSystem.exists(metaDataFile)) {
        final Path finalMetaDataFile=checkpointPath.suffix(Path.SEPARATOR + CheckpointUtils.METADATA_PREFIX + ""String_Node_Str""+ this.vertexID+ ""String_Node_Str"");
        if (fileSystem.exists(finalMetaDataFile)) {
          return;
        }
        if (this.isCheckpointComplete) {
          throw new FileNotFoundException(""String_Node_Str"" + metaDataIndex + ""String_Node_Str""+ this.vertexID);
        }
        Thread.sleep(1000);
        if (this.executionObserver.isCanceled()) {
          return;
        }
      }
      fileChannel=getFileChannel(fileSystem,metaDataFile);
      while (true) {
        try {
          deserializer.read(fileChannel);
          final TransferEnvelope transferEnvelope=deserializer.getFullyDeserializedTransferEnvelope();
          if (transferEnvelope != null) {
            final ReplayOutputChannelBroker broker=this.outputBrokerMap.get(transferEnvelope.getSource());
            if (broker == null) {
              throw new IOException(""String_Node_Str"" + transferEnvelope.getSource());
            }
            final Buffer srcBuffer=transferEnvelope.getBuffer();
            if (srcBuffer != null) {
              if (firstDeserializedFileBuffer == null) {
                firstDeserializedFileBuffer=srcBuffer.duplicate();
              }
              if (transferEnvelope.getSequenceNumber() < broker.getNextEnvelopeToSend()) {
                srcBuffer.recycleBuffer();
                continue;
              }
              final Buffer destBuffer=broker.requestEmptyBufferBlocking(srcBuffer.size());
              srcBuffer.copyToBuffer(destBuffer);
              transferEnvelope.setBuffer(destBuffer);
              srcBuffer.recycleBuffer();
            }
            broker.outputEnvelope(transferEnvelope);
            if (this.executionObserver.isCanceled()) {
              return;
            }
            if (this.restartRequested.get()) {
              return;
            }
          }
        }
 catch (        EOFException eof) {
          fileChannel.close();
          fileChannel=null;
          ++metaDataIndex;
          break;
        }
      }
    }
  }
  finally {
    if (firstDeserializedFileBuffer != null) {
      firstDeserializedFileBuffer.recycleBuffer();
      firstDeserializedFileBuffer=null;
    }
    if (fileChannel != null) {
      fileChannel.close();
      fileChannel=null;
    }
  }
}","private void replayCheckpoint() throws Exception {
  final CheckpointDeserializer deserializer=new CheckpointDeserializer(this.vertexID,!this.isCheckpointLocal);
  final Path checkpointPath=this.isCheckpointLocal ? CheckpointUtils.getLocalCheckpointPath() : CheckpointUtils.getDistributedCheckpointPath();
  if (checkpointPath == null) {
    throw new IOException(""String_Node_Str"" + this.vertexID);
  }
  final FileSystem fileSystem=checkpointPath.getFileSystem();
  int metaDataIndex=0;
  Buffer firstDeserializedFileBuffer=null;
  FileChannel fileChannel=null;
  try {
    while (true) {
      if (this.restartRequested.compareAndSet(true,false)) {
        metaDataIndex=0;
      }
      final Path metaDataFile=checkpointPath.suffix(Path.SEPARATOR + CheckpointUtils.METADATA_PREFIX + ""String_Node_Str""+ this.vertexID+ ""String_Node_Str""+ metaDataIndex);
      while (!fileSystem.exists(metaDataFile)) {
        final Path finalMetaDataFile=checkpointPath.suffix(Path.SEPARATOR + CheckpointUtils.METADATA_PREFIX + ""String_Node_Str""+ this.vertexID+ ""String_Node_Str"");
        if (fileSystem.exists(finalMetaDataFile)) {
          return;
        }
        if (this.isCheckpointComplete) {
          throw new FileNotFoundException(""String_Node_Str"" + metaDataIndex + ""String_Node_Str""+ this.vertexID);
        }
        Thread.sleep(1000);
        if (this.executionObserver.isCanceled()) {
          return;
        }
      }
      fileChannel=getFileChannel(fileSystem,metaDataFile);
      while (true) {
        try {
          deserializer.read(fileChannel);
          final TransferEnvelope transferEnvelope=deserializer.getFullyDeserializedTransferEnvelope();
          if (transferEnvelope != null) {
            final ReplayOutputChannelBroker broker=this.outputBrokerMap.get(transferEnvelope.getSource());
            if (broker == null) {
              throw new IOException(""String_Node_Str"" + transferEnvelope.getSource());
            }
            final Buffer srcBuffer=transferEnvelope.getBuffer();
            if (srcBuffer != null) {
              if (firstDeserializedFileBuffer == null) {
                firstDeserializedFileBuffer=srcBuffer.duplicate();
              }
              if (transferEnvelope.getSequenceNumber() < broker.getNextEnvelopeToSend()) {
                srcBuffer.recycleBuffer();
                continue;
              }
              final Buffer destBuffer=broker.requestEmptyBufferBlocking(srcBuffer.size());
              srcBuffer.copyToBuffer(destBuffer);
              transferEnvelope.setBuffer(destBuffer);
              srcBuffer.recycleBuffer();
            }
            broker.outputEnvelope(transferEnvelope);
            if (this.executionObserver.isCanceled()) {
              return;
            }
          }
        }
 catch (        EOFException eof) {
          fileChannel.close();
          fileChannel=null;
          ++metaDataIndex;
          break;
        }
      }
    }
  }
  finally {
    if (firstDeserializedFileBuffer != null) {
      firstDeserializedFileBuffer.recycleBuffer();
      firstDeserializedFileBuffer=null;
    }
    if (fileChannel != null) {
      fileChannel.close();
      fileChannel=null;
    }
  }
}",0.9723134678554668
55507,"/** 
 * {@inheritDoc}
 */
@Override public void run(){
  while (true) {
    changeExecutionState(ExecutionState.REPLAYING,null);
    if (this.executionObserver.isCanceled()) {
      changeExecutionState(ExecutionState.CANCELED,null);
      return;
    }
    resetAllOutputBroker();
    try {
      replayCheckpoint();
      if (this.executionObserver.isCanceled()) {
        throw new InterruptedException();
      }
    }
 catch (    Exception e) {
      if (isRestartRequested()) {
        continue;
      }
      if (this.executionObserver.isCanceled()) {
        changeExecutionState(ExecutionState.CANCELED,null);
      }
 else {
        changeExecutionState(ExecutionState.FAILED,StringUtils.stringifyException(e));
      }
      return;
    }
    if (isRestartRequested()) {
      continue;
    }
    break;
  }
  changeExecutionState(ExecutionState.FINISHING,null);
  try {
    waitForAllOutputBrokerToFinish();
  }
 catch (  Exception e) {
    if (this.executionObserver.isCanceled()) {
      changeExecutionState(ExecutionState.CANCELED,null);
    }
 else {
      changeExecutionState(ExecutionState.FAILED,StringUtils.stringifyException(e));
    }
    return;
  }
  changeExecutionState(ExecutionState.FINISHED,null);
}","/** 
 * {@inheritDoc}
 */
@Override public void run(){
  changeExecutionState(ExecutionState.REPLAYING,null);
  if (this.executionObserver.isCanceled()) {
    changeExecutionState(ExecutionState.CANCELED,null);
    return;
  }
  resetAllOutputBroker();
  try {
    replayCheckpoint();
    if (this.executionObserver.isCanceled()) {
      throw new InterruptedException();
    }
  }
 catch (  Exception e) {
    if (this.executionObserver.isCanceled()) {
      changeExecutionState(ExecutionState.CANCELED,null);
    }
 else {
      changeExecutionState(ExecutionState.FAILED,StringUtils.stringifyException(e));
    }
    return;
  }
  changeExecutionState(ExecutionState.FINISHING,null);
  try {
    waitForAllOutputBrokerToFinish();
  }
 catch (  Exception e) {
    if (this.executionObserver.isCanceled()) {
      changeExecutionState(ExecutionState.CANCELED,null);
    }
 else {
      changeExecutionState(ExecutionState.FAILED,StringUtils.stringifyException(e));
    }
    return;
  }
  changeExecutionState(ExecutionState.FINISHED,null);
}",0.8759894459102903
55508,"boolean followsLog(){
  if (this.numberOfInitialLogEntries == 0) {
    return false;
  }
synchronized (this) {
    return this.announcedEnvelopesAsIntBuffer.hasRemaining();
  }
}","boolean followsLog(){
  if (this.numberOfInitialLogEntries == 0) {
    return false;
  }
synchronized (this) {
    return this.outstandingEnvelopesAsIntBuffer.hasRemaining();
  }
}",0.9608938547486032
55509,"@Override public Schema create(Iterable<EvaluationExpression> keyExpressions){
  List<ObjectAccess> objectAccesses=new ArrayList<ObjectAccess>();
  List<ArrayAccess> arrayAccesses=new ArrayList<ArrayAccess>();
  List<EvaluationExpression> mappings=new ArrayList<EvaluationExpression>();
  for (  EvaluationExpression evaluationExpression : keyExpressions) {
    mappings.add(evaluationExpression);
    if (evaluationExpression instanceof ObjectAccess) {
      objectAccesses.add((ObjectAccess)evaluationExpression);
    }
    if (evaluationExpression instanceof ArrayAccess) {
      arrayAccesses.add((ArrayAccess)evaluationExpression);
    }
  }
  if (mappings.isEmpty())   return new DirectSchema();
  if (objectAccesses.size() == mappings.size()) {
    ObjectSchema schema=new ObjectSchema();
    schema.setMappingsWithAccesses(objectAccesses);
    return schema;
  }
 else   if (arrayAccesses.size() == mappings.size()) {
    int startIndex=arrayAccesses.get(0).getStartIndex();
    int endIndex=arrayAccesses.get(arrayAccesses.size()).getEndIndex();
    if (startIndex == 0) {
      HeadArraySchema schema=new HeadArraySchema();
      schema.setHeadSize(endIndex + 1);
      return schema;
    }
 else {
      TailArraySchema schema=new TailArraySchema();
      schema.setTailSize(endIndex - startIndex + 1);
      return schema;
    }
  }
 else {
    return new GeneralSchema(mappings);
  }
}","@Override public Schema create(Iterable<EvaluationExpression> keyExpressions){
  List<ObjectAccess> objectAccesses=new ArrayList<ObjectAccess>();
  List<ArrayAccess> arrayAccesses=new ArrayList<ArrayAccess>();
  List<EvaluationExpression> mappings=new ArrayList<EvaluationExpression>();
  for (  EvaluationExpression evaluationExpression : keyExpressions) {
    mappings.add(evaluationExpression);
    if (evaluationExpression instanceof ObjectAccess) {
      objectAccesses.add((ObjectAccess)evaluationExpression);
    }
    if (evaluationExpression instanceof ArrayAccess) {
      arrayAccesses.add((ArrayAccess)evaluationExpression);
    }
  }
  if (mappings.isEmpty())   return new DirectSchema();
  if (objectAccesses.size() == mappings.size()) {
    ObjectSchema schema=new ObjectSchema();
    schema.setMappingsWithAccesses(objectAccesses);
    return schema;
  }
 else   if (arrayAccesses.size() == mappings.size()) {
    int startIndex=arrayAccesses.get(0).getStartIndex();
    int endIndex=arrayAccesses.get(arrayAccesses.size() - 1).getEndIndex();
    if (startIndex == 0) {
      HeadArraySchema schema=new HeadArraySchema();
      schema.setHeadSize(endIndex + 1);
      return schema;
    }
 else {
      TailArraySchema schema=new TailArraySchema();
      schema.setTailSize(endIndex - startIndex + 1);
      return schema;
    }
  }
 else {
    return new GeneralSchema(mappings);
  }
}",0.9985714285714286
55510,"/** 
 * Checks, if all target vertices for multicast transmisison are ready. If vertices are in state ASSIGNED, it will deploy those vertices.
 * @param caller
 * @param jobID
 * @param sourceChannelID
 * @return
 */
private boolean checkIfAllTargetVerticesReady(InstanceConnectionInfo caller,JobID jobID,ChannelID sourceChannelID){
  final ExecutionGraph eg=this.scheduler.getExecutionGraphByID(jobID);
  final AbstractOutputChannel<? extends Record> outputChannel=eg.getOutputChannelByID(sourceChannelID);
  final OutputGate<? extends Record> broadcastgate=outputChannel.getOutputGate();
  List<ExecutionVertex> verticesToDeploy=null;
  for (  AbstractOutputChannel<? extends Record> c : broadcastgate.getOutputChannels()) {
    if (c.isBroadcastChannel()) {
      ExecutionVertex targetVertex=eg.getVertexByChannelID(c.getConnectedChannelID());
      if (targetVertex.getExecutionState() == ExecutionState.ASSIGNED) {
        if (verticesToDeploy == null) {
          verticesToDeploy=new ArrayList<ExecutionVertex>();
        }
        verticesToDeploy.add(targetVertex);
      }
 else {
        if (targetVertex.getExecutionState() != ExecutionState.RUNNING && targetVertex.getExecutionState() != ExecutionState.FINISHING && targetVertex.getExecutionState() != ExecutionState.READY && targetVertex.getExecutionState() != ExecutionState.STARTING) {
          return false;
        }
      }
    }
  }
  if (verticesToDeploy != null) {
    this.scheduler.deployAssignedVertices(verticesToDeploy);
    return false;
  }
  return true;
}","/** 
 * Checks, if all target vertices for multicast transmisison are ready. If vertices are in state ASSIGNED, it will deploy those vertices.
 * @param caller
 * @param jobID
 * @param sourceChannelID
 * @return
 */
private boolean checkIfAllTargetVerticesReady(InstanceConnectionInfo caller,JobID jobID,ChannelID sourceChannelID){
  final ExecutionGraph eg=this.scheduler.getExecutionGraphByID(jobID);
  final AbstractOutputChannel<? extends Record> outputChannel=eg.getOutputChannelByID(sourceChannelID);
  final OutputGate<? extends Record> broadcastgate=outputChannel.getOutputGate();
  List<ExecutionVertex> verticesToDeploy=null;
  for (  AbstractOutputChannel<? extends Record> c : broadcastgate.getOutputChannels()) {
    if (c.isBroadcastChannel()) {
      ExecutionVertex targetVertex=eg.getVertexByChannelID(c.getConnectedChannelID());
      if (targetVertex.getExecutionState() == ExecutionState.ASSIGNED) {
        if (verticesToDeploy == null) {
          verticesToDeploy=new ArrayList<ExecutionVertex>();
        }
        verticesToDeploy.add(targetVertex);
      }
 else {
        if (targetVertex.getExecutionState() != ExecutionState.RUNNING && targetVertex.getExecutionState() != ExecutionState.FINISHING) {
          return false;
        }
      }
    }
  }
  if (verticesToDeploy != null) {
    this.scheduler.deployAssignedVertices(verticesToDeploy);
    return false;
  }
  return true;
}",0.9055198103623434
55511,"void wire(final ExecutionGroupVertex source,final int indexOfOutputGate,final ExecutionGroupVertex target,final int indexOfInputGate,final ChannelType channelType,final CompressionLevel compressionLevel) throws GraphConversionException {
  for (int i=0; i < source.getCurrentNumberOfGroupMembers(); i++) {
    final ExecutionVertex sourceVertex=source.getGroupMember(i);
    final OutputGate<? extends Record> outputGate=sourceVertex.getEnvironment().getOutputGate(indexOfOutputGate);
    if (outputGate == null) {
      throw new GraphConversionException(""String_Node_Str"" + sourceVertex.getName() + ""String_Node_Str""+ indexOfOutputGate);
    }
    if (outputGate.getNumberOfOutputChannels() > 0) {
      throw new GraphConversionException(""String_Node_Str"" + sourceVertex.getName() + ""String_Node_Str""+ i+ ""String_Node_Str""+ outputGate.getNumberOfOutputChannels()+ ""String_Node_Str"");
    }
    for (int j=0; j < target.getCurrentNumberOfGroupMembers(); j++) {
      final ExecutionVertex targetVertex=target.getGroupMember(j);
      final InputGate<? extends Record> inputGate=targetVertex.getEnvironment().getInputGate(indexOfInputGate);
      if (inputGate == null) {
        throw new GraphConversionException(""String_Node_Str"" + targetVertex.getName() + ""String_Node_Str""+ indexOfInputGate);
      }
      if (inputGate.getNumberOfInputChannels() > 0 && i == 0) {
        throw new GraphConversionException(""String_Node_Str"" + targetVertex.getName() + ""String_Node_Str""+ j+ ""String_Node_Str""+ inputGate.getNumberOfInputChannels()+ ""String_Node_Str"");
      }
      if (inputGate.getDistributionPattern().createWire(i,j,source.getCurrentNumberOfGroupMembers(),target.getCurrentNumberOfGroupMembers())) {
        createChannel(sourceVertex,outputGate,targetVertex,inputGate,channelType,compressionLevel);
      }
      inputGate.setChannelType(channelType);
    }
    outputGate.setChannelType(channelType);
  }
}","void wire(final ExecutionGroupVertex source,final int indexOfOutputGate,final ExecutionGroupVertex target,final int indexOfInputGate,final ChannelType channelType,final CompressionLevel compressionLevel) throws GraphConversionException {
  for (int i=0; i < source.getCurrentNumberOfGroupMembers(); i++) {
    final ExecutionVertex sourceVertex=source.getGroupMember(i);
    final OutputGate<? extends Record> outputGate=sourceVertex.getEnvironment().getOutputGate(indexOfOutputGate);
    if (outputGate == null) {
      throw new GraphConversionException(""String_Node_Str"" + sourceVertex.getName() + ""String_Node_Str""+ indexOfOutputGate);
    }
    if (outputGate.getNumberOfOutputChannels() > 0) {
      throw new GraphConversionException(""String_Node_Str"" + sourceVertex.getName() + ""String_Node_Str""+ i+ ""String_Node_Str""+ outputGate.getNumberOfOutputChannels()+ ""String_Node_Str"");
    }
    for (int j=0; j < target.getCurrentNumberOfGroupMembers(); j++) {
      final ExecutionVertex targetVertex=target.getGroupMember(j);
      final InputGate<? extends Record> inputGate=targetVertex.getEnvironment().getInputGate(indexOfInputGate);
      if (inputGate == null) {
        throw new GraphConversionException(""String_Node_Str"" + targetVertex.getName() + ""String_Node_Str""+ indexOfInputGate);
      }
      if (inputGate.getNumberOfInputChannels() > 0 && i == 0) {
        throw new GraphConversionException(""String_Node_Str"" + targetVertex.getName() + ""String_Node_Str""+ j+ ""String_Node_Str""+ inputGate.getNumberOfInputChannels()+ ""String_Node_Str"");
      }
      if (inputGate.getDistributionPattern().createWire(i,j,source.getCurrentNumberOfGroupMembers(),target.getCurrentNumberOfGroupMembers())) {
        createChannel(sourceVertex,outputGate,targetVertex,inputGate,channelType,compressionLevel);
      }
      inputGate.setChannelType(channelType);
    }
    outputGate.setChannelType(channelType);
    sourceVertex.checkInitialCheckpointState();
  }
}",0.9876416065911432
55512,"/** 
 * Private constructor used to duplicate execution vertices.
 * @param vertexID the ID of the new execution vertex.
 * @param invokableClass the task that is assigned to this execution vertex
 * @param executionGraph the execution graph the new vertex belongs to
 * @param groupVertex the group vertex the new vertex belongs to
 * @param environment the environment for the newly created vertex
 */
private ExecutionVertex(final ExecutionVertexID vertexID,final Class<? extends AbstractInvokable> invokableClass,final ExecutionGraph executionGraph,final ExecutionGroupVertex groupVertex,final RuntimeEnvironment environment){
  this.vertexID=vertexID;
  this.invokableClass=invokableClass;
  this.executionGraph=executionGraph;
  this.groupVertex=groupVertex;
  this.environment=environment;
  this.checkpointState=new AtomicEnum<CheckpointState>(groupVertex.getInitialCheckpointState());
  this.retriesLeft=new AtomicInteger(groupVertex.getNumberOfExecutionRetries());
  registerExecutionListener(this.executionGraph);
}","/** 
 * Private constructor used to duplicate execution vertices.
 * @param vertexID the ID of the new execution vertex.
 * @param invokableClass the task that is assigned to this execution vertex
 * @param executionGraph the execution graph the new vertex belongs to
 * @param groupVertex the group vertex the new vertex belongs to
 * @param environment the environment for the newly created vertex
 */
private ExecutionVertex(final ExecutionVertexID vertexID,final Class<? extends AbstractInvokable> invokableClass,final ExecutionGraph executionGraph,final ExecutionGroupVertex groupVertex,final RuntimeEnvironment environment){
  this.vertexID=vertexID;
  this.invokableClass=invokableClass;
  this.executionGraph=executionGraph;
  this.groupVertex=groupVertex;
  this.environment=environment;
  this.retriesLeft=new AtomicInteger(groupVertex.getNumberOfExecutionRetries());
  registerExecutionListener(this.executionGraph);
}",0.851150895140665
55513,"/** 
 * Returns a duplicate of this execution vertex.
 * @param preserveVertexID <code>true</code> to copy the vertex's ID to the duplicated vertex, <code>false</code> to create a new ID
 * @return a duplicate of this execution vertex
 * @throws Exception any exception that might be thrown by the user code during instantiation and registration of input and output channels
 */
public ExecutionVertex duplicateVertex(final boolean preserveVertexID) throws Exception {
  ExecutionVertexID newVertexID;
  if (preserveVertexID) {
    newVertexID=this.vertexID;
  }
 else {
    newVertexID=new ExecutionVertexID();
  }
  final RuntimeEnvironment duplicatedEnvironment=this.environment.duplicateEnvironment();
  final ExecutionVertex duplicatedVertex=new ExecutionVertex(newVertexID,this.invokableClass,this.executionGraph,this.groupVertex,duplicatedEnvironment);
  duplicatedVertex.setAllocatedResource(this.allocatedResource);
  return duplicatedVertex;
}","/** 
 * Returns a duplicate of this execution vertex.
 * @param preserveVertexID <code>true</code> to copy the vertex's ID to the duplicated vertex, <code>false</code> to create a new ID
 * @return a duplicate of this execution vertex
 * @throws Exception any exception that might be thrown by the user code during instantiation and registration of input and output channels
 */
public ExecutionVertex duplicateVertex(final boolean preserveVertexID) throws Exception {
  ExecutionVertexID newVertexID;
  if (preserveVertexID) {
    newVertexID=this.vertexID;
  }
 else {
    newVertexID=new ExecutionVertexID();
  }
  final RuntimeEnvironment duplicatedEnvironment=this.environment.duplicateEnvironment();
  final ExecutionVertex duplicatedVertex=new ExecutionVertex(newVertexID,this.invokableClass,this.executionGraph,this.groupVertex,duplicatedEnvironment);
  duplicatedVertex.checkpointState.set(this.checkpointState.get());
  duplicatedVertex.setAllocatedResource(this.allocatedResource);
  return duplicatedVertex;
}",0.9047619047619048
55514,"private void replayCheckpoint() throws Exception {
  final CheckpointDeserializer deserializer=new CheckpointDeserializer(this.vertexID,!this.isCheckpointLocal);
  final Path checkpointPath=this.isCheckpointLocal ? CheckpointUtils.getLocalCheckpointPath() : CheckpointUtils.getDistributedCheckpointPath();
  if (checkpointPath == null) {
    throw new IOException(""String_Node_Str"" + this.vertexID);
  }
  final FileSystem fileSystem=checkpointPath.getFileSystem();
  int metaDataIndex=0;
  Buffer firstDeserializedFileBuffer=null;
  FileChannel fileChannel=null;
  try {
    while (true) {
      final Path metaDataFile=checkpointPath.suffix(Path.SEPARATOR + CheckpointUtils.METADATA_PREFIX + ""String_Node_Str""+ this.vertexID+ ""String_Node_Str""+ metaDataIndex);
      while (!fileSystem.exists(metaDataFile)) {
        final Path finalMetaDataFile=checkpointPath.suffix(Path.SEPARATOR + CheckpointUtils.METADATA_PREFIX + ""String_Node_Str""+ this.vertexID+ ""String_Node_Str"");
        if (fileSystem.exists(finalMetaDataFile)) {
          return;
        }
        if (this.isCheckpointComplete) {
          throw new FileNotFoundException(""String_Node_Str"" + metaDataIndex + ""String_Node_Str""+ this.vertexID);
        }
        Thread.sleep(1000);
      }
      fileChannel=getFileChannel(fileSystem,metaDataFile);
      while (true) {
        try {
          deserializer.read(fileChannel);
          final TransferEnvelope transferEnvelope=deserializer.getFullyDeserializedTransferEnvelope();
          if (transferEnvelope != null) {
            final ReplayOutputChannelBroker broker=this.outputBrokerMap.get(transferEnvelope.getSource());
            if (broker == null) {
              throw new IOException(""String_Node_Str"" + transferEnvelope.getSource());
            }
            final Buffer srcBuffer=transferEnvelope.getBuffer();
            if (srcBuffer != null) {
              if (firstDeserializedFileBuffer == null) {
                firstDeserializedFileBuffer=srcBuffer.duplicate();
              }
              if (transferEnvelope.getSequenceNumber() < broker.getNextEnvelopeToSend()) {
                srcBuffer.recycleBuffer();
                continue;
              }
              final Buffer destBuffer=broker.requestEmptyBufferBlocking(srcBuffer.size());
              srcBuffer.copyToBuffer(destBuffer);
              transferEnvelope.setBuffer(destBuffer);
              srcBuffer.recycleBuffer();
            }
            broker.outputEnvelope(transferEnvelope);
            if (this.restartRequested.get()) {
              return;
            }
          }
        }
 catch (        EOFException eof) {
          fileChannel.close();
          fileChannel=null;
          ++metaDataIndex;
          break;
        }
      }
    }
  }
  finally {
    if (firstDeserializedFileBuffer != null) {
      firstDeserializedFileBuffer.recycleBuffer();
      firstDeserializedFileBuffer=null;
    }
    if (fileChannel != null) {
      fileChannel.close();
      fileChannel=null;
    }
  }
}","private void replayCheckpoint() throws Exception {
  final CheckpointDeserializer deserializer=new CheckpointDeserializer(this.vertexID,!this.isCheckpointLocal);
  final Path checkpointPath=this.isCheckpointLocal ? CheckpointUtils.getLocalCheckpointPath() : CheckpointUtils.getDistributedCheckpointPath();
  if (checkpointPath == null) {
    throw new IOException(""String_Node_Str"" + this.vertexID);
  }
  final FileSystem fileSystem=checkpointPath.getFileSystem();
  int metaDataIndex=0;
  Buffer firstDeserializedFileBuffer=null;
  FileChannel fileChannel=null;
  try {
    while (true) {
      final Path metaDataFile=checkpointPath.suffix(Path.SEPARATOR + CheckpointUtils.METADATA_PREFIX + ""String_Node_Str""+ this.vertexID+ ""String_Node_Str""+ metaDataIndex);
      while (!fileSystem.exists(metaDataFile)) {
        final Path finalMetaDataFile=checkpointPath.suffix(Path.SEPARATOR + CheckpointUtils.METADATA_PREFIX + ""String_Node_Str""+ this.vertexID+ ""String_Node_Str"");
        if (fileSystem.exists(finalMetaDataFile)) {
          return;
        }
        if (this.isCheckpointComplete) {
          throw new FileNotFoundException(""String_Node_Str"" + metaDataIndex + ""String_Node_Str""+ this.vertexID);
        }
        Thread.sleep(1000);
      }
      fileChannel=getFileChannel(fileSystem,metaDataFile);
      while (true) {
        try {
          deserializer.read(fileChannel);
          final TransferEnvelope transferEnvelope=deserializer.getFullyDeserializedTransferEnvelope();
          if (transferEnvelope != null) {
            final ReplayOutputChannelBroker broker=this.outputBrokerMap.get(transferEnvelope.getSource());
            if (broker == null) {
              throw new IOException(""String_Node_Str"" + transferEnvelope.getSource());
            }
            final Buffer srcBuffer=transferEnvelope.getBuffer();
            if (srcBuffer != null) {
              if (firstDeserializedFileBuffer == null) {
                firstDeserializedFileBuffer=srcBuffer.duplicate();
              }
              if (transferEnvelope.getSequenceNumber() < broker.getNextEnvelopeToSend()) {
                srcBuffer.recycleBuffer();
                continue;
              }
              final Buffer destBuffer=broker.requestEmptyBufferBlocking(srcBuffer.size());
              srcBuffer.copyToBuffer(destBuffer);
              transferEnvelope.setBuffer(destBuffer);
              srcBuffer.recycleBuffer();
            }
            broker.outputEnvelope(transferEnvelope);
            if (this.executionObserver.isCanceled()) {
              return;
            }
            if (this.restartRequested.get()) {
              return;
            }
          }
        }
 catch (        EOFException eof) {
          fileChannel.close();
          fileChannel=null;
          ++metaDataIndex;
          break;
        }
      }
    }
  }
  finally {
    if (firstDeserializedFileBuffer != null) {
      firstDeserializedFileBuffer.recycleBuffer();
      firstDeserializedFileBuffer=null;
    }
    if (fileChannel != null) {
      fileChannel.close();
      fileChannel=null;
    }
  }
}",0.985162237078102
55515,"private TransferEnvelopeReceiverList getReceiverList(final JobID jobID,final ChannelID sourceChannelID){
  TransferEnvelopeReceiverList receiverList=this.receiverCache.get(sourceChannelID);
  if (receiverList == null) {
    try {
      while (true) {
        ConnectionInfoLookupResponse lookupResponse;
synchronized (this.channelLookupService) {
          lookupResponse=this.channelLookupService.lookupConnectionInfo(this.localConnectionInfo,jobID,sourceChannelID);
        }
        if (lookupResponse.receiverNotFound()) {
          throw new IOException(""String_Node_Str"" + sourceChannelID);
        }
        if (lookupResponse.receiverNotReady()) {
          Thread.sleep(500);
          continue;
        }
        if (lookupResponse.receiverReady()) {
          receiverList=new TransferEnvelopeReceiverList(lookupResponse);
          break;
        }
      }
      if (receiverList != null) {
        this.receiverCache.put(sourceChannelID,receiverList);
        if (LOG.isDebugEnabled()) {
          final StringBuilder sb=new StringBuilder();
          sb.append(""String_Node_Str"" + sourceChannelID + ""String_Node_Str""+ this.localConnectionInfo+ ""String_Node_Str"");
          if (receiverList.hasLocalReceivers()) {
            sb.append(""String_Node_Str"");
            final Iterator<ChannelID> it=receiverList.getLocalReceivers().iterator();
            while (it.hasNext()) {
              sb.append(""String_Node_Str"" + it.next() + ""String_Node_Str"");
            }
          }
          if (receiverList.hasRemoteReceivers()) {
            sb.append(""String_Node_Str"");
            final Iterator<InetSocketAddress> it=receiverList.getRemoteReceivers().iterator();
            while (it.hasNext()) {
              sb.append(""String_Node_Str"" + it.next() + ""String_Node_Str"");
            }
          }
          LOG.debug(sb.toString());
        }
      }
    }
 catch (    InterruptedException ie) {
    }
catch (    IOException ioe) {
    }
  }
  return receiverList;
}","/** 
 * Returns the list of receivers for transfer envelopes produced by the channel with the given source channel ID.
 * @param jobID the ID of the job the given channel ID belongs to
 * @param sourceChannelID the source channel ID for which the receiver list shall be retrieved
 * @return the list of receivers or <code>null</code> if the list of receivers could not be retrieved or therequesting thread has been interrupted
 */
private TransferEnvelopeReceiverList getReceiverList(final JobID jobID,final ChannelID sourceChannelID){
  TransferEnvelopeReceiverList receiverList=this.receiverCache.get(sourceChannelID);
  if (receiverList == null) {
    try {
      while (true) {
        if (Thread.currentThread().isInterrupted()) {
          break;
        }
        ConnectionInfoLookupResponse lookupResponse;
synchronized (this.channelLookupService) {
          lookupResponse=this.channelLookupService.lookupConnectionInfo(this.localConnectionInfo,jobID,sourceChannelID);
        }
        if (lookupResponse.receiverNotFound()) {
          LOG.error(""String_Node_Str"" + sourceChannelID);
          break;
        }
        if (lookupResponse.receiverNotReady()) {
          Thread.sleep(500);
          continue;
        }
        if (lookupResponse.receiverReady()) {
          receiverList=new TransferEnvelopeReceiverList(lookupResponse);
          break;
        }
      }
    }
 catch (    Exception e) {
    }
  }
  if (receiverList != null) {
    this.receiverCache.put(sourceChannelID,receiverList);
    if (LOG.isDebugEnabled()) {
      final StringBuilder sb=new StringBuilder();
      sb.append(""String_Node_Str"" + sourceChannelID + ""String_Node_Str""+ this.localConnectionInfo+ ""String_Node_Str"");
      if (receiverList.hasLocalReceivers()) {
        sb.append(""String_Node_Str"");
        final Iterator<ChannelID> it=receiverList.getLocalReceivers().iterator();
        while (it.hasNext()) {
          sb.append(""String_Node_Str"" + it.next() + ""String_Node_Str"");
        }
      }
      if (receiverList.hasRemoteReceivers()) {
        sb.append(""String_Node_Str"");
        final Iterator<InetSocketAddress> it=receiverList.getRemoteReceivers().iterator();
        while (it.hasNext()) {
          sb.append(""String_Node_Str"" + it.next() + ""String_Node_Str"");
        }
      }
      LOG.debug(sb.toString());
    }
  }
  return receiverList;
}",0.8133180252583238
55516,"/** 
 * Sets up Nephele in local mode.
 */
@BeforeClass public static void startNephele(){
  if (jobManagerThread == null) {
    JobManager jobManager=null;
    try {
      Constructor<JobManager> c=JobManager.class.getDeclaredConstructor(new Class[]{String.class,String.class});
      c.setAccessible(true);
      jobManager=c.newInstance(new Object[]{ServerTestUtils.getConfigDir(),new String(""String_Node_Str"")});
    }
 catch (    SecurityException e) {
      fail(e.getMessage());
    }
catch (    NoSuchMethodException e) {
      fail(e.getMessage());
    }
catch (    IllegalArgumentException e) {
      fail(e.getMessage());
    }
catch (    InstantiationException e) {
      fail(e.getMessage());
    }
catch (    IllegalAccessException e) {
      fail(e.getMessage());
    }
catch (    InvocationTargetException e) {
      fail(e.getMessage());
    }
    configuration=GlobalConfiguration.getConfiguration(new String[]{ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY});
    if (jobManager != null) {
      jobManagerThread=new JobManagerThread(jobManager);
      jobManagerThread.start();
    }
    try {
      Thread.sleep(1000);
    }
 catch (    InterruptedException e) {
      e.printStackTrace();
    }
  }
}","/** 
 * Sets up Nephele in local mode.
 */
@BeforeClass public static void startNephele(){
  if (jobManagerThread == null) {
    JobManager jobManager=null;
    try {
      Constructor<JobManager> c=JobManager.class.getDeclaredConstructor(new Class[]{String.class,String.class});
      c.setAccessible(true);
      jobManager=c.newInstance(new Object[]{ServerTestUtils.getConfigDir(),new String(""String_Node_Str"")});
    }
 catch (    SecurityException e) {
      fail(e.getMessage());
    }
catch (    NoSuchMethodException e) {
      fail(e.getMessage());
    }
catch (    IllegalArgumentException e) {
      fail(e.getMessage());
    }
catch (    InstantiationException e) {
      fail(e.getMessage());
    }
catch (    IllegalAccessException e) {
      fail(e.getMessage());
    }
catch (    InvocationTargetException e) {
      fail(e.getMessage());
    }
    configuration=GlobalConfiguration.getConfiguration(new String[]{ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY});
    if (jobManager != null) {
      jobManagerThread=new JobManagerThread(jobManager);
      jobManagerThread.start();
    }
    try {
      Thread.sleep(10000);
    }
 catch (    InterruptedException e) {
      e.printStackTrace();
    }
  }
}",0.999589995899959
55517,"/** 
 * {@inheritDoc}
 */
@Override public boolean equals(final Object obj){
  if (!(obj instanceof AbstractJobResult)) {
    return false;
  }
  final AbstractJobResult ajr=(AbstractJobResult)obj;
  if (this.returnCode == null) {
    if (ajr.getReturnCode() != null) {
      return false;
    }
  }
 else {
    if (!this.returnCode.equals(ajr.getReturnCode())) {
      return false;
    }
  }
  if (this.description == null) {
    if (this.description != null) {
      return false;
    }
  }
 else {
    if (!this.description.equals(ajr.getDescription())) {
      return false;
    }
  }
  return true;
}","/** 
 * {@inheritDoc}
 */
@Override public boolean equals(final Object obj){
  if (!(obj instanceof AbstractJobResult)) {
    return false;
  }
  final AbstractJobResult ajr=(AbstractJobResult)obj;
  if (this.returnCode == null) {
    if (ajr.getReturnCode() != null) {
      return false;
    }
  }
 else {
    if (!this.returnCode.equals(ajr.getReturnCode())) {
      return false;
    }
  }
  if (this.description == null) {
  }
 else {
    if (!this.description.equals(ajr.getDescription())) {
      return false;
    }
  }
  return true;
}",0.8417391304347827
55518,"/** 
 * Returns the next code point at the current position in the buffer. The buffer's position will be incremented. Any mark set on this buffer will be changed by this method!
 */
public static int bytesToCodePoint(final ByteBuffer bytes){
  bytes.mark();
  final byte b=bytes.get();
  bytes.reset();
  final int extraBytesToRead=bytesFromUTF8[(b & 0xFF)];
  if (extraBytesToRead < 0) {
    return -1;
  }
  int ch=0;
switch (extraBytesToRead) {
case 5:
    ch+=(bytes.get() & 0xFF);
  ch<<=6;
case 4:
ch+=(bytes.get() & 0xFF);
ch<<=6;
case 3:
ch+=(bytes.get() & 0xFF);
ch<<=6;
case 2:
ch+=(bytes.get() & 0xFF);
ch<<=6;
case 1:
ch+=(bytes.get() & 0xFF);
ch<<=6;
case 0:
ch+=(bytes.get() & 0xFF);
}
ch-=offsetsFromUTF8[extraBytesToRead];
return ch;
}","/** 
 * Returns the next code point at the current position in the buffer. The buffer's position will be incremented. Any mark set on this buffer will be changed by this method!
 */
public static int bytesToCodePoint(final ByteBuffer bytes){
  bytes.mark();
  final byte b=bytes.get();
  bytes.reset();
  final int extraBytesToRead=bytesFromUTF8[(b & 0xFF)];
  if (extraBytesToRead < 0) {
    return -1;
  }
  int ch=0;
switch (extraBytesToRead) {
case 5:
    ch+=(bytes.get() & 0xFF);
  ch<<=6;
case 4:
ch+=(bytes.get() & 0xFF);
ch<<=6;
case 3:
ch+=(bytes.get() & 0xFF);
ch<<=6;
case 2:
ch+=(bytes.get() & 0xFF);
ch<<=6;
case 1:
ch+=(bytes.get() & 0xFF);
ch<<=6;
case 0:
ch+=(bytes.get() & 0xFF);
default :
break;
}
ch-=offsetsFromUTF8[extraBytesToRead];
return ch;
}",0.9888084265964452
55519,"/** 
 * Check to see if a byte array is valid utf-8
 * @param utf8 the array of bytes
 * @param start the offset of the first byte in the array
 * @param len the length of the byte sequence
 * @throws MalformedInputException if the byte array contains invalid bytes
 */
public static void validateUTF8(final byte[] utf8,final int start,final int len) throws MalformedInputException {
  int count=start;
  int leadByte=0;
  int length=0;
  int state=LEAD_BYTE;
  while (count < start + len) {
    final int aByte=((int)utf8[count] & 0xFF);
switch (state) {
case LEAD_BYTE:
      leadByte=aByte;
    length=bytesFromUTF8[aByte];
switch (length) {
case 0:
    if (leadByte > 0x7F) {
      throw new MalformedInputException(count);
    }
  break;
case 1:
if (leadByte < 0xC2 || leadByte > 0xDF) {
  throw new MalformedInputException(count);
}
state=TRAIL_BYTE_1;
break;
case 2:
if (leadByte < 0xE0 || leadByte > 0xEF) {
throw new MalformedInputException(count);
}
state=TRAIL_BYTE_1;
break;
case 3:
if (leadByte < 0xF0 || leadByte > 0xF4) {
throw new MalformedInputException(count);
}
state=TRAIL_BYTE_1;
break;
default :
throw new MalformedInputException(count);
}
break;
case TRAIL_BYTE_1:
if (leadByte == 0xF0 && aByte < 0x90) {
throw new MalformedInputException(count);
}
if (leadByte == 0xF4 && aByte > 0x8F) {
throw new MalformedInputException(count);
}
if (leadByte == 0xE0 && aByte < 0xA0) {
throw new MalformedInputException(count);
}
if (leadByte == 0xED && aByte > 0x9F) {
throw new MalformedInputException(count);
}
case TRAIL_BYTE:
if (aByte < 0x80 || aByte > 0xBF) {
throw new MalformedInputException(count);
}
if (--length == 0) {
state=LEAD_BYTE;
}
 else {
state=TRAIL_BYTE;
}
break;
}
count++;
}
}","/** 
 * Check to see if a byte array is valid utf-8
 * @param utf8 the array of bytes
 * @param start the offset of the first byte in the array
 * @param len the length of the byte sequence
 * @throws MalformedInputException if the byte array contains invalid bytes
 */
public static void validateUTF8(final byte[] utf8,final int start,final int len) throws MalformedInputException {
  int count=start;
  int leadByte=0;
  int length=0;
  int state=LEAD_BYTE;
  while (count < start + len) {
    final int aByte=((int)utf8[count] & 0xFF);
switch (state) {
case LEAD_BYTE:
      leadByte=aByte;
    length=bytesFromUTF8[aByte];
switch (length) {
case 0:
    if (leadByte > 0x7F) {
      throw new MalformedInputException(count);
    }
  break;
case 1:
if (leadByte < 0xC2 || leadByte > 0xDF) {
  throw new MalformedInputException(count);
}
state=TRAIL_BYTE_1;
break;
case 2:
if (leadByte < 0xE0 || leadByte > 0xEF) {
throw new MalformedInputException(count);
}
state=TRAIL_BYTE_1;
break;
case 3:
if (leadByte < 0xF0 || leadByte > 0xF4) {
throw new MalformedInputException(count);
}
state=TRAIL_BYTE_1;
break;
default :
throw new MalformedInputException(count);
}
break;
case TRAIL_BYTE_1:
if (leadByte == 0xF0 && aByte < 0x90) {
throw new MalformedInputException(count);
}
if (leadByte == 0xF4 && aByte > 0x8F) {
throw new MalformedInputException(count);
}
if (leadByte == 0xE0 && aByte < 0xA0) {
throw new MalformedInputException(count);
}
if (leadByte == 0xED && aByte > 0x9F) {
throw new MalformedInputException(count);
}
case TRAIL_BYTE:
if (aByte < 0x80 || aByte > 0xBF) {
throw new MalformedInputException(count);
}
if (--length == 0) {
state=LEAD_BYTE;
}
 else {
state=TRAIL_BYTE;
}
break;
default :
break;
}
count++;
}
}",0.9950538260110562
55520,"/** 
 * Reads a hard-coded tree topology from file and creates a tree according to the hard-coded topology from the file.
 * @param nodes
 * @return
 */
private MulticastForwardingTable createHardCodedTree(LinkedList<TreeNode> nodes){
  try {
    FileInputStream fstream=new FileInputStream(this.hardcodedtreefilepath);
    DataInputStream in=new DataInputStream(fstream);
    BufferedReader br=new BufferedReader(new InputStreamReader(in));
    String strLine;
    while ((strLine=br.readLine()) != null) {
      String[] values=strLine.split(""String_Node_Str"");
      String actualhostname=values[0];
      for (      TreeNode n : nodes) {
        if (n.toString().equals(actualhostname)) {
          for (int i=1; i < values.length; i++) {
            for (            TreeNode childnode : nodes) {
              if (childnode.toString().equals(values[i])) {
                n.addChild(childnode);
              }
            }
          }
        }
      }
    }
    return nodes.getFirst().createForwardingTable();
  }
 catch (  Exception e) {
    System.out.println(""String_Node_Str"" + e.getMessage());
    return null;
  }
}","/** 
 * Reads a hard-coded tree topology from file and creates a tree according to the hard-coded topology from the file.
 * @param nodes
 * @return
 */
private MulticastForwardingTable createHardCodedTree(LinkedList<TreeNode> nodes){
  try {
    FileInputStream fstream=new FileInputStream(this.hardcodedtreefilepath);
    DataInputStream in=new DataInputStream(fstream);
    BufferedReader br=new BufferedReader(new InputStreamReader(in));
    String strLine;
    while ((strLine=br.readLine()) != null) {
      String[] values=strLine.split(""String_Node_Str"");
      String actualhostname=values[0];
      for (      TreeNode n : nodes) {
        if (n.toString().equals(actualhostname)) {
          for (int i=1; i < values.length; i++) {
            for (            TreeNode childnode : nodes) {
              if (childnode.toString().equals(values[i])) {
                n.addChild(childnode);
              }
            }
          }
        }
      }
    }
    br.close();
    return nodes.getFirst().createForwardingTable();
  }
 catch (  Exception e) {
    System.out.println(""String_Node_Str"" + e.getMessage());
    return null;
  }
}",0.99297629499561
55521,"/** 
 * Auxiliary method that reads penalties for tree nodes from the given file. Expects penalties in format <HOSTNAME> <PENALTY_AS_INTEGER> and saves the penalty value in the corresponding TreeNode objects within the provided list.
 * @param f
 * @param nodes List with the nodes
 */
private void readPenalitesFromFile(File f,List<TreeNode> nodes){
  try {
    FileInputStream fstream=new FileInputStream(f);
    DataInputStream in=new DataInputStream(fstream);
    BufferedReader br=new BufferedReader(new InputStreamReader(in));
    String strLine;
    while ((strLine=br.readLine()) != null) {
      String[] values=strLine.split(""String_Node_Str"");
      String actualhostname=values[0];
      int actualpenalty=Integer.valueOf(values[1]);
      for (      TreeNode n : nodes) {
        if (n.toString().equals(actualhostname)) {
          System.out.println(""String_Node_Str"" + n.toString() + ""String_Node_Str""+ actualpenalty);
          n.setProperty(""String_Node_Str"",actualpenalty);
        }
      }
    }
    in.close();
  }
 catch (  Exception e) {
    System.err.println(""String_Node_Str"" + e.getMessage());
  }
}","/** 
 * Auxiliary method that reads penalties for tree nodes from the given file. Expects penalties in format <HOSTNAME> <PENALTY_AS_INTEGER> and saves the penalty value in the corresponding TreeNode objects within the provided list.
 * @param f
 * @param nodes List with the nodes
 */
private void readPenalitesFromFile(File f,List<TreeNode> nodes){
  try {
    FileInputStream fstream=new FileInputStream(f);
    DataInputStream in=new DataInputStream(fstream);
    BufferedReader br=new BufferedReader(new InputStreamReader(in));
    String strLine;
    while ((strLine=br.readLine()) != null) {
      String[] values=strLine.split(""String_Node_Str"");
      String actualhostname=values[0];
      int actualpenalty=Integer.valueOf(values[1]);
      for (      TreeNode n : nodes) {
        if (n.toString().equals(actualhostname)) {
          System.out.println(""String_Node_Str"" + n.toString() + ""String_Node_Str""+ actualpenalty);
          n.setProperty(""String_Node_Str"",actualpenalty);
        }
      }
    }
    br.close();
    in.close();
    fstream.close();
  }
 catch (  Exception e) {
    System.err.println(""String_Node_Str"" + e.getMessage());
  }
}",0.9821038847664776
55522,"private boolean isRestartRequested(){
  if (this.restartRequested.compareAndSet(true,false)) {
    if (!this.interruptCalled.compareAndSet(true,false)) {
      while (!Thread.currentThread().isInterrupted()) {
      }
      this.interruptCalled.set(false);
    }
    Thread.interrupted();
    return true;
  }
  return false;
}","private boolean isRestartRequested(){
  if (this.restartRequested.compareAndSet(true,false)) {
    if (!this.interruptCalled.compareAndSet(true,false)) {
      try {
        Thread.sleep(10L);
      }
 catch (      InterruptedException e) {
      }
      this.interruptCalled.set(false);
    }
    Thread.interrupted();
    return true;
  }
  return false;
}",0.5051094890510949
55523,"private void replayCheckpoint() throws Exception {
  final CheckpointDeserializer deserializer=new CheckpointDeserializer(this.vertexID,!this.isCheckpointLocal);
  final Path checkpointPath=this.isCheckpointLocal ? CheckpointUtils.getLocalCheckpointPath() : CheckpointUtils.getDistributedCheckpointPath();
  if (checkpointPath == null) {
    throw new IOException(""String_Node_Str"" + this.vertexID);
  }
  final FileSystem fileSystem=checkpointPath.getFileSystem();
  int metaDataIndex=0;
  Buffer firstDeserializedFileBuffer=null;
  FileChannel fileChannel=null;
  try {
    while (true) {
      final Path metaDataFile=checkpointPath.suffix(Path.SEPARATOR + CheckpointUtils.METADATA_PREFIX + ""String_Node_Str""+ this.vertexID+ ""String_Node_Str""+ metaDataIndex);
      while (!fileSystem.exists(metaDataFile)) {
        final Path finalMetaDataFile=checkpointPath.suffix(Path.SEPARATOR + CheckpointUtils.METADATA_PREFIX + ""String_Node_Str""+ this.vertexID+ ""String_Node_Str"");
        if (fileSystem.exists(finalMetaDataFile)) {
          return;
        }
        if (this.isCheckpointComplete) {
          throw new FileNotFoundException(""String_Node_Str"" + metaDataIndex + ""String_Node_Str""+ this.vertexID);
        }
        Thread.sleep(1000);
      }
      fileChannel=getFileChannel(fileSystem,metaDataFile);
      while (true) {
        try {
          deserializer.read(fileChannel);
          final TransferEnvelope transferEnvelope=deserializer.getFullyDeserializedTransferEnvelope();
          if (transferEnvelope != null) {
            final ReplayOutputChannelBroker broker=this.outputBrokerMap.get(transferEnvelope.getSource());
            if (broker == null) {
              throw new IOException(""String_Node_Str"" + transferEnvelope.getSource());
            }
            final Buffer srcBuffer=transferEnvelope.getBuffer();
            if (srcBuffer != null) {
              if (firstDeserializedFileBuffer == null) {
                firstDeserializedFileBuffer=srcBuffer.duplicate();
              }
              if (transferEnvelope.getSequenceNumber() < broker.getNextEnvelopeToSend()) {
                srcBuffer.recycleBuffer();
                continue;
              }
              final Buffer destBuffer=broker.requestEmptyBufferBlocking(srcBuffer.size());
              srcBuffer.copyToBuffer(destBuffer);
              transferEnvelope.setBuffer(destBuffer);
              srcBuffer.recycleBuffer();
            }
            broker.outputEnvelope(transferEnvelope);
            if (this.executionObserver.isCanceled()) {
              return;
            }
            if (this.restartRequested.get()) {
              return;
            }
          }
        }
 catch (        EOFException eof) {
          fileChannel.close();
          fileChannel=null;
          ++metaDataIndex;
          break;
        }
      }
    }
  }
  finally {
    if (firstDeserializedFileBuffer != null) {
      firstDeserializedFileBuffer.recycleBuffer();
      firstDeserializedFileBuffer=null;
    }
    if (fileChannel != null) {
      fileChannel.close();
      fileChannel=null;
    }
  }
}","private void replayCheckpoint() throws Exception {
  final CheckpointDeserializer deserializer=new CheckpointDeserializer(this.vertexID,!this.isCheckpointLocal);
  final Path checkpointPath=this.isCheckpointLocal ? CheckpointUtils.getLocalCheckpointPath() : CheckpointUtils.getDistributedCheckpointPath();
  if (checkpointPath == null) {
    throw new IOException(""String_Node_Str"" + this.vertexID);
  }
  final FileSystem fileSystem=checkpointPath.getFileSystem();
  int metaDataIndex=0;
  Buffer firstDeserializedFileBuffer=null;
  FileChannel fileChannel=null;
  try {
    while (true) {
      final Path metaDataFile=checkpointPath.suffix(Path.SEPARATOR + CheckpointUtils.METADATA_PREFIX + ""String_Node_Str""+ this.vertexID+ ""String_Node_Str""+ metaDataIndex);
      while (!fileSystem.exists(metaDataFile)) {
        final Path finalMetaDataFile=checkpointPath.suffix(Path.SEPARATOR + CheckpointUtils.METADATA_PREFIX + ""String_Node_Str""+ this.vertexID+ ""String_Node_Str"");
        if (fileSystem.exists(finalMetaDataFile)) {
          return;
        }
        if (this.isCheckpointComplete) {
          throw new FileNotFoundException(""String_Node_Str"" + metaDataIndex + ""String_Node_Str""+ this.vertexID);
        }
        Thread.sleep(1000);
        if (this.executionObserver.isCanceled()) {
          return;
        }
      }
      fileChannel=getFileChannel(fileSystem,metaDataFile);
      while (true) {
        try {
          deserializer.read(fileChannel);
          final TransferEnvelope transferEnvelope=deserializer.getFullyDeserializedTransferEnvelope();
          if (transferEnvelope != null) {
            final ReplayOutputChannelBroker broker=this.outputBrokerMap.get(transferEnvelope.getSource());
            if (broker == null) {
              throw new IOException(""String_Node_Str"" + transferEnvelope.getSource());
            }
            final Buffer srcBuffer=transferEnvelope.getBuffer();
            if (srcBuffer != null) {
              if (firstDeserializedFileBuffer == null) {
                firstDeserializedFileBuffer=srcBuffer.duplicate();
              }
              if (transferEnvelope.getSequenceNumber() < broker.getNextEnvelopeToSend()) {
                srcBuffer.recycleBuffer();
                continue;
              }
              final Buffer destBuffer=broker.requestEmptyBufferBlocking(srcBuffer.size());
              srcBuffer.copyToBuffer(destBuffer);
              transferEnvelope.setBuffer(destBuffer);
              srcBuffer.recycleBuffer();
            }
            broker.outputEnvelope(transferEnvelope);
            if (this.executionObserver.isCanceled()) {
              return;
            }
            if (this.restartRequested.get()) {
              return;
            }
          }
        }
 catch (        EOFException eof) {
          fileChannel.close();
          fileChannel=null;
          ++metaDataIndex;
          break;
        }
      }
    }
  }
  finally {
    if (firstDeserializedFileBuffer != null) {
      firstDeserializedFileBuffer.recycleBuffer();
      firstDeserializedFileBuffer=null;
    }
    if (fileChannel != null) {
      fileChannel.close();
      fileChannel=null;
    }
  }
}",0.9874662858956051
55524,"/** 
 * Sets up Nephele in local mode.
 */
@BeforeClass public static void startNephele(){
  if (jobManagerThread == null) {
    JobManager jobManager=null;
    try {
      final String userDir=System.getProperty(""String_Node_Str"");
      String configDir=userDir + File.separator + CONFIGURATION_DIRECTORY;
      if (!new File(configDir).exists()) {
        configDir=userDir + ""String_Node_Str"" + CONFIGURATION_DIRECTORY;
      }
      final Constructor<JobManager> c=JobManager.class.getDeclaredConstructor(new Class[]{String.class,String.class});
      c.setAccessible(true);
      jobManager=c.newInstance(new Object[]{configDir,new String(""String_Node_Str"")});
    }
 catch (    SecurityException e) {
      fail(e.getMessage());
    }
catch (    NoSuchMethodException e) {
      fail(e.getMessage());
    }
catch (    IllegalArgumentException e) {
      fail(e.getMessage());
    }
catch (    InstantiationException e) {
      fail(e.getMessage());
    }
catch (    IllegalAccessException e) {
      fail(e.getMessage());
    }
catch (    InvocationTargetException e) {
      fail(e.getMessage());
    }
    configuration=GlobalConfiguration.getConfiguration(new String[]{ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY});
    if (jobManager != null) {
      jobManagerThread=new JobManagerThread(jobManager);
      jobManagerThread.start();
    }
    try {
      Thread.sleep(1000);
    }
 catch (    InterruptedException e) {
      e.printStackTrace();
    }
  }
}","/** 
 * Sets up Nephele in local mode.
 */
@BeforeClass public static void startNephele(){
  if (jobManagerThread == null) {
    JobManager jobManager=null;
    try {
      final String userDir=System.getProperty(""String_Node_Str"");
      String configDir=userDir + File.separator + CONFIGURATION_DIRECTORY;
      if (!new File(configDir).exists()) {
        configDir=userDir + ""String_Node_Str"" + CONFIGURATION_DIRECTORY;
      }
      final Constructor<JobManager> c=JobManager.class.getDeclaredConstructor(new Class[]{String.class,String.class});
      c.setAccessible(true);
      jobManager=c.newInstance(new Object[]{configDir,new String(""String_Node_Str"")});
    }
 catch (    SecurityException e) {
      fail(e.getMessage());
    }
catch (    NoSuchMethodException e) {
      fail(e.getMessage());
    }
catch (    IllegalArgumentException e) {
      fail(e.getMessage());
    }
catch (    InstantiationException e) {
      fail(e.getMessage());
    }
catch (    IllegalAccessException e) {
      fail(e.getMessage());
    }
catch (    InvocationTargetException e) {
      fail(e.getMessage());
    }
    configuration=GlobalConfiguration.getConfiguration(new String[]{ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY});
    if (jobManager != null) {
      jobManagerThread=new JobManagerThread(jobManager);
      jobManagerThread.start();
    }
    try {
      ServerTestUtils.waitForJobManagerToBecomeReady(jobManager);
    }
 catch (    Exception e) {
      fail(StringUtils.stringifyException(e));
    }
  }
}",0.9407432206226984
55525,"/** 
 * Sets up Nephele in local mode.
 */
@BeforeClass public static void startNephele(){
  if (jobManagerThread == null) {
    JobManager jobManager=null;
    try {
      Constructor<JobManager> c=JobManager.class.getDeclaredConstructor(new Class[]{String.class,String.class});
      c.setAccessible(true);
      jobManager=c.newInstance(new Object[]{ServerTestUtils.getConfigDir(),new String(""String_Node_Str"")});
    }
 catch (    SecurityException e) {
      fail(e.getMessage());
    }
catch (    NoSuchMethodException e) {
      fail(e.getMessage());
    }
catch (    IllegalArgumentException e) {
      fail(e.getMessage());
    }
catch (    InstantiationException e) {
      fail(e.getMessage());
    }
catch (    IllegalAccessException e) {
      fail(e.getMessage());
    }
catch (    InvocationTargetException e) {
      fail(e.getMessage());
    }
    configuration=GlobalConfiguration.getConfiguration(new String[]{ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY});
    if (jobManager != null) {
      jobManagerThread=new JobManagerThread(jobManager);
      jobManagerThread.start();
    }
    try {
      Thread.sleep(10000);
    }
 catch (    InterruptedException e) {
      e.printStackTrace();
    }
  }
}","/** 
 * Sets up Nephele in local mode.
 */
@BeforeClass public static void startNephele(){
  if (jobManagerThread == null) {
    JobManager jobManager=null;
    try {
      Constructor<JobManager> c=JobManager.class.getDeclaredConstructor(new Class[]{String.class,String.class});
      c.setAccessible(true);
      jobManager=c.newInstance(new Object[]{ServerTestUtils.getConfigDir(),new String(""String_Node_Str"")});
    }
 catch (    SecurityException e) {
      fail(e.getMessage());
    }
catch (    NoSuchMethodException e) {
      fail(e.getMessage());
    }
catch (    IllegalArgumentException e) {
      fail(e.getMessage());
    }
catch (    InstantiationException e) {
      fail(e.getMessage());
    }
catch (    IllegalAccessException e) {
      fail(e.getMessage());
    }
catch (    InvocationTargetException e) {
      fail(e.getMessage());
    }
    configuration=GlobalConfiguration.getConfiguration(new String[]{ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY});
    if (jobManager != null) {
      jobManagerThread=new JobManagerThread(jobManager);
      jobManagerThread.start();
    }
    try {
      ServerTestUtils.waitForJobManagerToBecomeReady(jobManager);
    }
 catch (    Exception e) {
      fail(StringUtils.stringifyException(e));
    }
  }
}",0.9188102893890676
55526,"void restart(){
  changeExecutionState(ExecutionState.STARTING,null);
  this.restartRequested.set(true);
  interrupt();
}","void restart(){
  changeExecutionState(ExecutionState.STARTING,null);
  this.restartRequested.set(true);
  interrupt();
  this.interruptCalled.set(true);
}",0.8768115942028986
55527,"/** 
 * {@inheritDoc}
 */
@Override public void run(){
  while (true) {
    changeExecutionState(ExecutionState.REPLAYING,null);
    if (this.executionObserver.isCanceled()) {
      changeExecutionState(ExecutionState.CANCELED,null);
      return;
    }
    resetAllOutputBroker();
    try {
      replayCheckpoint();
      if (this.executionObserver.isCanceled()) {
        throw new InterruptedException();
      }
    }
 catch (    Exception e) {
      if (this.restartRequested.compareAndSet(true,false)) {
        while (!Thread.currentThread().isInterrupted()) {
        }
        Thread.interrupted();
        continue;
      }
      if (this.executionObserver.isCanceled()) {
        changeExecutionState(ExecutionState.CANCELED,null);
      }
 else {
        changeExecutionState(ExecutionState.FAILED,StringUtils.stringifyException(e));
      }
      return;
    }
    if (this.restartRequested.compareAndSet(true,false)) {
      while (!Thread.currentThread().isInterrupted()) {
      }
      Thread.interrupted();
      continue;
    }
    break;
  }
  changeExecutionState(ExecutionState.FINISHING,null);
  try {
    waitForAllOutputBrokerToFinish();
  }
 catch (  Exception e) {
    if (this.executionObserver.isCanceled()) {
      changeExecutionState(ExecutionState.CANCELED,null);
    }
 else {
      changeExecutionState(ExecutionState.FAILED,StringUtils.stringifyException(e));
    }
    return;
  }
  changeExecutionState(ExecutionState.FINISHED,null);
}","/** 
 * {@inheritDoc}
 */
@Override public void run(){
  while (true) {
    changeExecutionState(ExecutionState.REPLAYING,null);
    if (this.executionObserver.isCanceled()) {
      changeExecutionState(ExecutionState.CANCELED,null);
      return;
    }
    resetAllOutputBroker();
    try {
      replayCheckpoint();
      if (this.executionObserver.isCanceled()) {
        throw new InterruptedException();
      }
    }
 catch (    Exception e) {
      if (isRestartRequested()) {
        continue;
      }
      if (this.executionObserver.isCanceled()) {
        changeExecutionState(ExecutionState.CANCELED,null);
      }
 else {
        changeExecutionState(ExecutionState.FAILED,StringUtils.stringifyException(e));
      }
      return;
    }
    if (isRestartRequested()) {
      continue;
    }
    break;
  }
  changeExecutionState(ExecutionState.FINISHING,null);
  try {
    waitForAllOutputBrokerToFinish();
  }
 catch (  Exception e) {
    if (this.executionObserver.isCanceled()) {
      changeExecutionState(ExecutionState.CANCELED,null);
    }
 else {
      changeExecutionState(ExecutionState.FAILED,StringUtils.stringifyException(e));
    }
    return;
  }
  changeExecutionState(ExecutionState.FINISHED,null);
}",0.8890532544378699
55528,"void restart(){
  this.restartRequested.set(true);
}","void restart(){
  changeExecutionState(ExecutionState.STARTING,null);
  this.restartRequested.set(true);
  interrupt();
}",0.6011560693641619
55529,"private void replayCheckpoint() throws Exception {
  final CheckpointDeserializer deserializer=new CheckpointDeserializer(this.vertexID,!this.isCheckpointLocal);
  final Path checkpointPath=this.isCheckpointLocal ? CheckpointUtils.getLocalCheckpointPath() : CheckpointUtils.getDistributedCheckpointPath();
  if (checkpointPath == null) {
    throw new IOException(""String_Node_Str"" + this.vertexID);
  }
  final FileSystem fileSystem=checkpointPath.getFileSystem();
  int metaDataIndex=0;
  Buffer firstDeserializedFileBuffer=null;
  FileChannel fileChannel=null;
  try {
    while (true) {
      if (this.restartRequested.compareAndSet(true,false)) {
        metaDataIndex=0;
      }
      final Path metaDataFile=checkpointPath.suffix(Path.SEPARATOR + CheckpointUtils.METADATA_PREFIX + ""String_Node_Str""+ this.vertexID+ ""String_Node_Str""+ metaDataIndex);
      while (!fileSystem.exists(metaDataFile)) {
        final Path finalMetaDataFile=checkpointPath.suffix(Path.SEPARATOR + CheckpointUtils.METADATA_PREFIX + ""String_Node_Str""+ this.vertexID+ ""String_Node_Str"");
        if (fileSystem.exists(finalMetaDataFile)) {
          return;
        }
        if (this.isCheckpointComplete) {
          throw new FileNotFoundException(""String_Node_Str"" + metaDataIndex + ""String_Node_Str""+ this.vertexID);
        }
        Thread.sleep(1000);
      }
      fileChannel=getFileChannel(fileSystem,metaDataFile);
      while (true) {
        try {
          deserializer.read(fileChannel);
          final TransferEnvelope transferEnvelope=deserializer.getFullyDeserializedTransferEnvelope();
          if (transferEnvelope != null) {
            final ReplayOutputChannelBroker broker=this.outputBrokerMap.get(transferEnvelope.getSource());
            if (broker == null) {
              throw new IOException(""String_Node_Str"" + transferEnvelope.getSource());
            }
            final Buffer srcBuffer=transferEnvelope.getBuffer();
            if (srcBuffer != null) {
              if (firstDeserializedFileBuffer == null) {
                firstDeserializedFileBuffer=srcBuffer.duplicate();
              }
              if (transferEnvelope.getSequenceNumber() < broker.getNextEnvelopeToSend()) {
                srcBuffer.recycleBuffer();
                continue;
              }
              final Buffer destBuffer=broker.requestEmptyBufferBlocking(srcBuffer.size());
              srcBuffer.copyToBuffer(destBuffer);
              transferEnvelope.setBuffer(destBuffer);
              srcBuffer.recycleBuffer();
            }
            broker.outputEnvelope(transferEnvelope);
          }
        }
 catch (        EOFException eof) {
          fileChannel.close();
          fileChannel=null;
          ++metaDataIndex;
          break;
        }
      }
    }
  }
  finally {
    if (firstDeserializedFileBuffer != null) {
      firstDeserializedFileBuffer.recycleBuffer();
      firstDeserializedFileBuffer=null;
    }
    if (fileChannel != null) {
      fileChannel.close();
      fileChannel=null;
    }
  }
}","private void replayCheckpoint() throws Exception {
  final CheckpointDeserializer deserializer=new CheckpointDeserializer(this.vertexID,!this.isCheckpointLocal);
  final Path checkpointPath=this.isCheckpointLocal ? CheckpointUtils.getLocalCheckpointPath() : CheckpointUtils.getDistributedCheckpointPath();
  if (checkpointPath == null) {
    throw new IOException(""String_Node_Str"" + this.vertexID);
  }
  final FileSystem fileSystem=checkpointPath.getFileSystem();
  int metaDataIndex=0;
  Buffer firstDeserializedFileBuffer=null;
  FileChannel fileChannel=null;
  try {
    while (true) {
      final Path metaDataFile=checkpointPath.suffix(Path.SEPARATOR + CheckpointUtils.METADATA_PREFIX + ""String_Node_Str""+ this.vertexID+ ""String_Node_Str""+ metaDataIndex);
      while (!fileSystem.exists(metaDataFile)) {
        final Path finalMetaDataFile=checkpointPath.suffix(Path.SEPARATOR + CheckpointUtils.METADATA_PREFIX + ""String_Node_Str""+ this.vertexID+ ""String_Node_Str"");
        if (fileSystem.exists(finalMetaDataFile)) {
          return;
        }
        if (this.isCheckpointComplete) {
          throw new FileNotFoundException(""String_Node_Str"" + metaDataIndex + ""String_Node_Str""+ this.vertexID);
        }
        Thread.sleep(1000);
      }
      fileChannel=getFileChannel(fileSystem,metaDataFile);
      while (true) {
        try {
          deserializer.read(fileChannel);
          final TransferEnvelope transferEnvelope=deserializer.getFullyDeserializedTransferEnvelope();
          if (transferEnvelope != null) {
            final ReplayOutputChannelBroker broker=this.outputBrokerMap.get(transferEnvelope.getSource());
            if (broker == null) {
              throw new IOException(""String_Node_Str"" + transferEnvelope.getSource());
            }
            final Buffer srcBuffer=transferEnvelope.getBuffer();
            if (srcBuffer != null) {
              if (firstDeserializedFileBuffer == null) {
                firstDeserializedFileBuffer=srcBuffer.duplicate();
              }
              if (transferEnvelope.getSequenceNumber() < broker.getNextEnvelopeToSend()) {
                srcBuffer.recycleBuffer();
                continue;
              }
              final Buffer destBuffer=broker.requestEmptyBufferBlocking(srcBuffer.size());
              srcBuffer.copyToBuffer(destBuffer);
              transferEnvelope.setBuffer(destBuffer);
              srcBuffer.recycleBuffer();
            }
            broker.outputEnvelope(transferEnvelope);
            if (this.restartRequested.get()) {
              return;
            }
          }
        }
 catch (        EOFException eof) {
          fileChannel.close();
          fileChannel=null;
          ++metaDataIndex;
          break;
        }
      }
    }
  }
  finally {
    if (firstDeserializedFileBuffer != null) {
      firstDeserializedFileBuffer.recycleBuffer();
      firstDeserializedFileBuffer=null;
    }
    if (fileChannel != null) {
      fileChannel.close();
      fileChannel=null;
    }
  }
}",0.970758301668594
55530,"/** 
 * {@inheritDoc}
 */
@Override public void run(){
  changeExecutionState(ExecutionState.REPLAYING,null);
  if (this.executionObserver.isCanceled()) {
    changeExecutionState(ExecutionState.CANCELED,null);
    return;
  }
  try {
    replayCheckpoint();
    if (this.executionObserver.isCanceled()) {
      throw new InterruptedException();
    }
  }
 catch (  Exception e) {
    e.printStackTrace();
    if (this.executionObserver.isCanceled()) {
      changeExecutionState(ExecutionState.CANCELED,null);
    }
 else {
      changeExecutionState(ExecutionState.FAILED,StringUtils.stringifyException(e));
    }
    return;
  }
  changeExecutionState(ExecutionState.FINISHING,null);
  try {
    waitForAllOutputBrokerToFinish();
  }
 catch (  Exception e) {
    if (this.executionObserver.isCanceled()) {
      changeExecutionState(ExecutionState.CANCELED,null);
    }
 else {
      changeExecutionState(ExecutionState.FAILED,StringUtils.stringifyException(e));
    }
    return;
  }
  changeExecutionState(ExecutionState.FINISHED,null);
}","/** 
 * {@inheritDoc}
 */
@Override public void run(){
  while (true) {
    changeExecutionState(ExecutionState.REPLAYING,null);
    if (this.executionObserver.isCanceled()) {
      changeExecutionState(ExecutionState.CANCELED,null);
      return;
    }
    resetAllOutputBroker();
    try {
      replayCheckpoint();
      if (this.executionObserver.isCanceled()) {
        throw new InterruptedException();
      }
    }
 catch (    Exception e) {
      if (this.restartRequested.compareAndSet(true,false)) {
        while (!Thread.currentThread().isInterrupted()) {
        }
        Thread.interrupted();
        continue;
      }
      if (this.executionObserver.isCanceled()) {
        changeExecutionState(ExecutionState.CANCELED,null);
      }
 else {
        changeExecutionState(ExecutionState.FAILED,StringUtils.stringifyException(e));
      }
      return;
    }
    if (this.restartRequested.compareAndSet(true,false)) {
      while (!Thread.currentThread().isInterrupted()) {
      }
      Thread.interrupted();
      continue;
    }
    break;
  }
  changeExecutionState(ExecutionState.FINISHING,null);
  try {
    waitForAllOutputBrokerToFinish();
  }
 catch (  Exception e) {
    if (this.executionObserver.isCanceled()) {
      changeExecutionState(ExecutionState.CANCELED,null);
    }
 else {
      changeExecutionState(ExecutionState.FAILED,StringUtils.stringifyException(e));
    }
    return;
  }
  changeExecutionState(ExecutionState.FINISHED,null);
}",0.7580452920143027
55531,"/** 
 * Checks the transition of the execution state and outputs an error in case of an unexpected state transition.
 * @param jobManager <code>true</code> to indicate the method is called by the job manager, <code>false/<code> to indicate it is called by a task manager
 * @param taskName the name of the task whose execution has changed
 * @param oldState the old execution state
 * @param newState the new execution state
 */
public static void checkTransition(final boolean jobManager,final String taskName,final ExecutionState oldState,final ExecutionState newState){
  LOG.info((jobManager ? ""String_Node_Str"" : ""String_Node_Str"") + ""String_Node_Str"" + oldState+ ""String_Node_Str""+ newState+ ""String_Node_Str""+ taskName+ ""String_Node_Str""+ System.currentTimeMillis());
  boolean unexpectedStateChange=true;
  if (oldState == ExecutionState.CREATED && newState == ExecutionState.SCHEDULED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.SCHEDULED && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.ASSIGNED && newState == ExecutionState.READY) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.READY && newState == ExecutionState.STARTING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.STARTING && newState == ExecutionState.RUNNING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.RUNNING && newState == ExecutionState.FINISHING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FINISHING && newState == ExecutionState.FINISHED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FAILED && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FAILED && newState == ExecutionState.CREATED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FINISHED && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FINISHED && newState == ExecutionState.CREATED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.CANCELED && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.CANCELED && newState == ExecutionState.CREATED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.STARTING && newState == ExecutionState.REPLAYING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.REPLAYING && newState == ExecutionState.FINISHING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.CREATED && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.SCHEDULED && newState == ExecutionState.CANCELING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.ASSIGNED && newState == ExecutionState.CANCELING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.READY && newState == ExecutionState.CANCELING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.STARTING && newState == ExecutionState.FAILED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.RUNNING && newState == ExecutionState.FAILED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FINISHING && newState == ExecutionState.FAILED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.REPLAYING && newState == ExecutionState.FAILED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.RUNNING && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FINISHING && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.RUNNING && newState == ExecutionState.CANCELING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FINISHING && newState == ExecutionState.CANCELING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.CANCELING && newState == ExecutionState.CANCELED) {
    unexpectedStateChange=false;
  }
  if (unexpectedStateChange) {
    try {
      throw new IllegalStateException(""String_Node_Str"" + oldState + ""String_Node_Str""+ newState);
    }
 catch (    IllegalStateException e) {
      LOG.error(StringUtils.stringifyException(e));
    }
  }
}","/** 
 * Checks the transition of the execution state and outputs an error in case of an unexpected state transition.
 * @param jobManager <code>true</code> to indicate the method is called by the job manager, <code>false/<code> to indicate it is called by a task manager
 * @param taskName the name of the task whose execution has changed
 * @param oldState the old execution state
 * @param newState the new execution state
 */
public static void checkTransition(final boolean jobManager,final String taskName,final ExecutionState oldState,final ExecutionState newState){
  LOG.info((jobManager ? ""String_Node_Str"" : ""String_Node_Str"") + ""String_Node_Str"" + oldState+ ""String_Node_Str""+ newState+ ""String_Node_Str""+ taskName+ ""String_Node_Str""+ System.currentTimeMillis());
  boolean unexpectedStateChange=true;
  if (oldState == ExecutionState.CREATED && newState == ExecutionState.SCHEDULED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.SCHEDULED && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.ASSIGNED && newState == ExecutionState.READY) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.READY && newState == ExecutionState.STARTING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.STARTING && newState == ExecutionState.RUNNING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.RUNNING && newState == ExecutionState.FINISHING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FINISHING && newState == ExecutionState.FINISHED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FAILED && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FAILED && newState == ExecutionState.CREATED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FINISHED && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FINISHED && newState == ExecutionState.CREATED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.CANCELED && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.CANCELED && newState == ExecutionState.CREATED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.STARTING && newState == ExecutionState.REPLAYING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.REPLAYING && newState == ExecutionState.FINISHING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.CREATED && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.SCHEDULED && newState == ExecutionState.CANCELING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.ASSIGNED && newState == ExecutionState.CANCELING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.READY && newState == ExecutionState.CANCELING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.STARTING && newState == ExecutionState.FAILED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.RUNNING && newState == ExecutionState.FAILED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FINISHING && newState == ExecutionState.FAILED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.REPLAYING && newState == ExecutionState.FAILED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.RUNNING && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.REPLAYING && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FINISHING && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.RUNNING && newState == ExecutionState.CANCELING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FINISHING && newState == ExecutionState.CANCELING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.CANCELING && newState == ExecutionState.CANCELED) {
    unexpectedStateChange=false;
  }
  if (unexpectedStateChange) {
    try {
      throw new IllegalStateException(""String_Node_Str"" + oldState + ""String_Node_Str""+ newState);
    }
 catch (    IllegalStateException e) {
      LOG.error(StringUtils.stringifyException(e));
    }
  }
}",0.9864354013786968
55532,"/** 
 * Constructs a new ephemeral checkpoint.
 * @param task the task this checkpoint belongs to
 * @param ephemeral <code>true</code> if the checkpoint is initially ephemeral, <code>false</code> if the checkpoint shall be persistent from the beginning
 */
public EphemeralCheckpoint(final RuntimeTask task,final boolean ephemeral){
  this.task=task;
  int nooc=0;
  final RuntimeEnvironment environment=task.getRuntimeEnvironment();
  for (int i=0; i < environment.getNumberOfOutputGates(); ++i) {
    nooc+=environment.getOutputGate(i).getNumberOfOutputChannels();
  }
  this.numberOfConnectedChannels=nooc;
  this.checkpointingDecision=(ephemeral ? CheckpointingDecisionState.UNDECIDED : CheckpointingDecisionState.CHECKPOINTING);
  if (LOG.isDebugEnabled()) {
    LOG.debug(""String_Node_Str"" + task.getVertexID() + ""String_Node_Str""+ this.checkpointingDecision);
  }
  if (this.checkpointingDecision == CheckpointingDecisionState.CHECKPOINTING) {
    this.task.checkpointStateChanged(CheckpointState.PARTIAL);
    this.writeThread=new WriteThread(FileBufferManager.getInstance(),this.task.getVertexID(),this.numberOfConnectedChannels);
  }
}","/** 
 * Constructs a new ephemeral checkpoint.
 * @param task the task this checkpoint belongs to
 * @param ephemeral <code>true</code> if the checkpoint is initially ephemeral, <code>false</code> if the checkpoint shall be persistent from the beginning
 */
public EphemeralCheckpoint(final RuntimeTask task,final boolean ephemeral){
  this.task=task;
  int nooc=0;
  final RuntimeEnvironment environment=task.getRuntimeEnvironment();
  for (int i=0; i < environment.getNumberOfOutputGates(); ++i) {
    nooc+=environment.getOutputGate(i).getNumberOfOutputChannels();
  }
  this.numberOfConnectedChannels=nooc;
  this.checkpointingDecision=(ephemeral ? CheckpointingDecisionState.UNDECIDED : CheckpointingDecisionState.CHECKPOINTING);
  if (LOG.isDebugEnabled()) {
    LOG.debug(""String_Node_Str"" + task.getVertexID() + ""String_Node_Str""+ this.checkpointingDecision);
  }
  if (this.checkpointingDecision == CheckpointingDecisionState.CHECKPOINTING) {
    this.task.checkpointStateChanged(CheckpointState.PARTIAL);
    this.writeThread=new WriteThread(FileBufferManager.getInstance(),this.task.getVertexID(),this.numberOfConnectedChannels);
    this.writeThread.start();
  }
}",0.9870801033591732
55533,"public EphemeralCheckpointForwarder(final EphemeralCheckpoint ephemeralCheckpoint,final AbstractOutputChannelForwarder next){
  super(next);
  if (next == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  this.ephemeralCheckpoint=ephemeralCheckpoint;
}","public EphemeralCheckpointForwarder(final EphemeralCheckpoint ephemeralCheckpoint,final AbstractOutputChannelForwarder next){
  super(next);
  this.ephemeralCheckpoint=ephemeralCheckpoint;
}",0.8172043010752689
55534,"/** 
 * {@inheritDoc}
 */
@Override public boolean hasDataLeft() throws IOException, InterruptedException {
  if (this.ephemeralCheckpoint.hasDataLeft()) {
    return true;
  }
  return getNext().hasDataLeft();
}","/** 
 * {@inheritDoc}
 */
@Override public boolean hasDataLeft() throws IOException, InterruptedException {
  if (this.ephemeralCheckpoint.hasDataLeft()) {
    return true;
  }
  final AbstractOutputChannelForwarder next=getNext();
  if (next != null) {
    return getNext().hasDataLeft();
  }
  return false;
}",0.7839388145315488
55535,"/** 
 * {@inheritDoc}
 */
@Override public void push(final TransferEnvelope transferEnvelope) throws IOException, InterruptedException {
  this.ephemeralCheckpoint.forward(transferEnvelope);
  getNext().push(transferEnvelope);
}","/** 
 * {@inheritDoc}
 */
@Override public void push(final TransferEnvelope transferEnvelope) throws IOException, InterruptedException {
  this.ephemeralCheckpoint.forward(transferEnvelope);
  final AbstractOutputChannelForwarder next=getNext();
  if (next != null) {
    next.push(transferEnvelope);
  }
 else {
    recycleTransferEnvelope(transferEnvelope);
  }
}",0.7689713322091062
55536,"/** 
 * Constructs a new replay input channel context.
 * @param encapsulatedContext the encapsulated input channel context
 */
ReplayInputChannelContext(final InputChannelContext encapsulatedContext){
  this.encapsulatedContext=encapsulatedContext;
}","/** 
 * Constructs a new replay input channel context.
 * @param channelID the ID of the input channel this context belongs to
 * @param encapsulatedContext the encapsulated input channel context
 */
ReplayInputChannelContext(final ChannelID channelID,final InputChannelContext encapsulatedContext){
  this.channelID=channelID;
  this.encapsulatedContext=encapsulatedContext;
}",0.678343949044586
55537,"/** 
 * {@inheritDoc}
 */
@Override public ChannelID getChannelID(){
  return this.encapsulatedContext.getChannelID();
}","/** 
 * {@inheritDoc}
 */
@Override public ChannelID getChannelID(){
  return this.channelID;
}",0.8837209302325582
55538,"/** 
 * {@inheritDoc}
 */
@Override public void destroy(){
  this.encapsulatedContext.destroy();
}","/** 
 * {@inheritDoc}
 */
@Override public void destroy(){
  if (this.encapsulatedContext != null) {
    this.encapsulatedContext.destroy();
  }
}",0.8032786885245902
55539,"/** 
 * {@inheritDoc}
 */
@Override public InputChannelContext createInputChannelContext(ChannelID channelID,InputChannelContext previousContext){
  return new ReplayInputChannelContext(previousContext);
}","/** 
 * {@inheritDoc}
 */
@Override public InputChannelContext createInputChannelContext(final ChannelID channelID,final InputChannelContext previousContext){
  return new ReplayInputChannelContext(channelID,previousContext);
}",0.949074074074074
55540,"private static ExecutionState determineOverallExecutionState(final ExecutionState unchangedExecutionState,final ExecutionState changedExecutionState){
  if (changedExecutionState == null) {
    return changedExecutionState;
  }
  if (changedExecutionState == ExecutionState.REPLAYING) {
    if (unchangedExecutionState == ExecutionState.RUNNING || unchangedExecutionState == ExecutionState.FINISHING) {
      return ExecutionState.REPLAYING;
    }
 else {
      return unchangedExecutionState;
    }
  }
  if (changedExecutionState == ExecutionState.CANCELING) {
    return ExecutionState.CANCELING;
  }
  if (changedExecutionState == ExecutionState.CANCELED && unchangedExecutionState == ExecutionState.CANCELED) {
    return ExecutionState.CANCELED;
  }
  if (changedExecutionState == ExecutionState.FINISHING && (unchangedExecutionState == ExecutionState.FINISHING || unchangedExecutionState == ExecutionState.FINISHED)) {
    return ExecutionState.FINISHING;
  }
  if (changedExecutionState == ExecutionState.FINISHED && unchangedExecutionState == ExecutionState.FINISHED) {
    return ExecutionState.FINISHED;
  }
  if (changedExecutionState == ExecutionState.FAILED && unchangedExecutionState == ExecutionState.FAILED) {
    return ExecutionState.FAILED;
  }
  return null;
}","private static ExecutionState determineOverallExecutionState(final ExecutionState unchangedExecutionState,final ExecutionState changedExecutionState){
  if (unchangedExecutionState == null) {
    return changedExecutionState;
  }
  if (changedExecutionState == ExecutionState.REPLAYING) {
    if (unchangedExecutionState == ExecutionState.RUNNING || unchangedExecutionState == ExecutionState.FINISHING) {
      return ExecutionState.REPLAYING;
    }
 else {
      return unchangedExecutionState;
    }
  }
  if (changedExecutionState == ExecutionState.CANCELING) {
    return ExecutionState.CANCELING;
  }
  if (changedExecutionState == ExecutionState.CANCELED && unchangedExecutionState == ExecutionState.CANCELED) {
    return ExecutionState.CANCELED;
  }
  if (changedExecutionState == ExecutionState.FINISHING && (unchangedExecutionState == ExecutionState.FINISHING || unchangedExecutionState == ExecutionState.FINISHED)) {
    return ExecutionState.FINISHING;
  }
  if (changedExecutionState == ExecutionState.FINISHED && unchangedExecutionState == ExecutionState.FINISHED) {
    return ExecutionState.FINISHED;
  }
  if (changedExecutionState == ExecutionState.FAILED && unchangedExecutionState == ExecutionState.FAILED) {
    return ExecutionState.FAILED;
  }
  return null;
}",0.999219968798752
55541,"protected void replayCheckpointsFromPreviousStage(final ExecutionGraph executionGraph){
  final int currentStageIndex=executionGraph.getIndexOfCurrentExecutionStage();
  final ExecutionStage previousStage=executionGraph.getStage(currentStageIndex - 1);
  for (int i=0; i < previousStage.getNumberOfOutputExecutionVertices(); ++i) {
    final ExecutionVertex vertex=previousStage.getOutputExecutionVertex(i);
    vertex.updateExecutionState(ExecutionState.ASSIGNED);
  }
  deployAssignedInputVertices(executionGraph);
}","protected void replayCheckpointsFromPreviousStage(final ExecutionGraph executionGraph){
  final int currentStageIndex=executionGraph.getIndexOfCurrentExecutionStage();
  final ExecutionStage previousStage=executionGraph.getStage(currentStageIndex - 1);
  final List<ExecutionVertex> verticesToBeReplayed=new ArrayList<ExecutionVertex>();
  for (int i=0; i < previousStage.getNumberOfOutputExecutionVertices(); ++i) {
    final ExecutionVertex vertex=previousStage.getOutputExecutionVertex(i);
    vertex.updateExecutionState(ExecutionState.ASSIGNED);
    verticesToBeReplayed.add(vertex);
  }
  deployAssignedVertices(verticesToBeReplayed);
}",0.8603448275862069
55542,"/** 
 * Registers the given task with the byte buffered channel manager.
 * @param task the task to be registered
 * @param the set of output channels which are initially active
 */
public void register(final Task task,final Set<ChannelID> activeOutputChannels){
  final Environment environment=task.getEnvironment();
  final TaskContext taskContext=task.createTaskContext(this,this.localBufferPoolOwner.remove(task.getVertexID()));
  final Set<GateID> outputGateIDs=environment.getOutputGateIDs();
  for (final Iterator<GateID> gateIt=outputGateIDs.iterator(); gateIt.hasNext(); ) {
    final GateID gateID=gateIt.next();
    final OutputGateContext outputGateContext=taskContext.createOutputGateContext(gateID);
    final Set<ChannelID> outputChannelIDs=environment.getOutputChannelIDsOfGate(gateID);
    for (final Iterator<ChannelID> channelIt=outputChannelIDs.iterator(); channelIt.hasNext(); ) {
      final ChannelID channelID=channelIt.next();
      final OutputChannelContext previousContext=(OutputChannelContext)this.registeredChannels.get(channelID);
      final boolean isActive=activeOutputChannels.contains(channelID);
      final OutputChannelContext outputChannelContext=outputGateContext.createOutputChannelContext(channelID,previousContext,isActive,this.mergeSpilledBuffers);
      if (outputChannelContext.getType() == ChannelType.INMEMORY) {
        addReceiverListHint(outputChannelContext);
      }
      if (LOG.isDebugEnabled())       LOG.debug(""String_Node_Str"" + outputChannelContext.getChannelID() + ""String_Node_Str""+ (isActive ? ""String_Node_Str"" : ""String_Node_Str"")+ ""String_Node_Str"");
      this.registeredChannels.put(outputChannelContext.getChannelID(),outputChannelContext);
    }
  }
  final Set<GateID> inputGateIDs=environment.getInputGateIDs();
  for (final Iterator<GateID> gateIt=inputGateIDs.iterator(); gateIt.hasNext(); ) {
    final GateID gateID=gateIt.next();
    final InputGateContext inputGateContext=taskContext.createInputGateContext(gateID);
    final Set<ChannelID> inputChannelIDs=environment.getInputChannelIDsOfGate(gateID);
    for (final Iterator<ChannelID> channelIt=inputChannelIDs.iterator(); channelIt.hasNext(); ) {
      final ChannelID channelID=channelIt.next();
      final InputChannelContext previousContext=(InputChannelContext)this.registeredChannels.get(channelID);
      final InputChannelContext inputChannelContext=inputGateContext.createInputChannelContext(channelID,previousContext);
      if (inputChannelContext.getType() == ChannelType.INMEMORY) {
        addReceiverListHint(inputChannelContext);
      }
      final boolean isActive=activeOutputChannels.contains(inputChannelContext.getChannelID());
      if (LOG.isDebugEnabled())       LOG.debug(""String_Node_Str"" + inputChannelContext.getChannelID() + ""String_Node_Str""+ (isActive ? ""String_Node_Str"" : ""String_Node_Str"")+ ""String_Node_Str"");
      this.registeredChannels.put(inputChannelContext.getChannelID(),inputChannelContext);
    }
    final LocalBufferPoolOwner bufferPoolOwner=inputGateContext.getLocalBufferPoolOwner();
    if (bufferPoolOwner != null) {
      this.localBufferPoolOwner.put(inputGateContext.getGateID(),bufferPoolOwner);
    }
  }
  this.localBufferPoolOwner.put(task.getVertexID(),taskContext);
  redistributeGlobalBuffers();
}","/** 
 * Registers the given task with the byte buffered channel manager.
 * @param task the task to be registered
 * @param the set of output channels which are initially active
 */
public void register(final Task task,final Set<ChannelID> activeOutputChannels){
  final Environment environment=task.getEnvironment();
  final TaskContext taskContext=task.createTaskContext(this,this.localBufferPoolOwner.remove(task.getVertexID()));
  final Set<GateID> outputGateIDs=environment.getOutputGateIDs();
  for (final Iterator<GateID> gateIt=outputGateIDs.iterator(); gateIt.hasNext(); ) {
    final GateID gateID=gateIt.next();
    final OutputGateContext outputGateContext=taskContext.createOutputGateContext(gateID);
    final Set<ChannelID> outputChannelIDs=environment.getOutputChannelIDsOfGate(gateID);
    for (final Iterator<ChannelID> channelIt=outputChannelIDs.iterator(); channelIt.hasNext(); ) {
      final ChannelID channelID=channelIt.next();
      final OutputChannelContext previousContext=(OutputChannelContext)this.registeredChannels.get(channelID);
      final boolean isActive=activeOutputChannels.contains(channelID);
      final OutputChannelContext outputChannelContext=outputGateContext.createOutputChannelContext(channelID,previousContext,isActive,this.mergeSpilledBuffers);
      if (outputChannelContext.getType() == ChannelType.INMEMORY) {
        addReceiverListHint(outputChannelContext);
      }
      if (LOG.isDebugEnabled())       LOG.debug(""String_Node_Str"" + outputChannelContext.getChannelID() + ""String_Node_Str""+ (isActive ? ""String_Node_Str"" : ""String_Node_Str"")+ ""String_Node_Str"");
      this.registeredChannels.put(outputChannelContext.getChannelID(),outputChannelContext);
    }
  }
  final Set<GateID> inputGateIDs=environment.getInputGateIDs();
  for (final Iterator<GateID> gateIt=inputGateIDs.iterator(); gateIt.hasNext(); ) {
    final GateID gateID=gateIt.next();
    final InputGateContext inputGateContext=taskContext.createInputGateContext(gateID);
    final Set<ChannelID> inputChannelIDs=environment.getInputChannelIDsOfGate(gateID);
    for (final Iterator<ChannelID> channelIt=inputChannelIDs.iterator(); channelIt.hasNext(); ) {
      final ChannelID channelID=channelIt.next();
      final InputChannelContext previousContext=(InputChannelContext)this.registeredChannels.get(channelID);
      final InputChannelContext inputChannelContext=inputGateContext.createInputChannelContext(channelID,previousContext);
      if (inputChannelContext.getType() == ChannelType.INMEMORY) {
        addReceiverListHint(inputChannelContext);
      }
      this.registeredChannels.put(inputChannelContext.getChannelID(),inputChannelContext);
    }
    final LocalBufferPoolOwner bufferPoolOwner=inputGateContext.getLocalBufferPoolOwner();
    if (bufferPoolOwner != null) {
      this.localBufferPoolOwner.put(inputGateContext.getGateID(),bufferPoolOwner);
    }
  }
  this.localBufferPoolOwner.put(task.getVertexID(),taskContext);
  redistributeGlobalBuffers();
}",0.9536213468869124
55543,"/** 
 * {@inheritDoc}
 */
@Override public boolean hasDataLeft() throws IOException, InterruptedException {
  if (this.closeAcknowledgementReceived) {
    return getNext().hasDataLeft();
  }
  if ((this.lastSequenceNumberWithReceiverNotFound + 1) == this.sequenceNumber) {
    return getNext().hasDataLeft();
  }
  return true;
}","/** 
 * {@inheritDoc}
 */
@Override public boolean hasDataLeft() throws IOException, InterruptedException {
  if (this.byteBufferedOutputChannel.getType() == ChannelType.FILE) {
    return getNext().hasDataLeft();
  }
  if (this.closeAcknowledgmentReceived) {
    return getNext().hasDataLeft();
  }
  if ((this.lastSequenceNumberWithReceiverNotFound + 1) == this.sequenceNumber) {
    return getNext().hasDataLeft();
  }
  return true;
}",0.8552803129074316
55544,"/** 
 * {@inheritDoc}
 */
@Override public void processEvent(final AbstractEvent event){
  if (event instanceof ByteBufferedChannelCloseEvent) {
    this.closeAcknowledgementReceived=true;
  }
 else   if (event instanceof ReceiverNotFoundEvent) {
    this.lastSequenceNumberWithReceiverNotFound=((ReceiverNotFoundEvent)event).getSequenceNumber();
  }
 else   if (event instanceof AbstractTaskEvent) {
    this.byteBufferedOutputChannel.processEvent(event);
  }
  getNext().processEvent(event);
}","/** 
 * {@inheritDoc}
 */
@Override public void processEvent(final AbstractEvent event){
  if (event instanceof ByteBufferedChannelCloseEvent) {
    this.closeAcknowledgmentReceived=true;
  }
 else   if (event instanceof ReceiverNotFoundEvent) {
    this.lastSequenceNumberWithReceiverNotFound=((ReceiverNotFoundEvent)event).getSequenceNumber();
  }
 else   if (event instanceof AbstractTaskEvent) {
    this.byteBufferedOutputChannel.processEvent(event);
  }
  getNext().processEvent(event);
}",0.9989888776541962
55545,"/** 
 * {@inheritDoc}
 */
@Override public OutputChannelContext createOutputChannelContext(ChannelID channelID,OutputChannelContext previousContext,boolean isReceiverRunning,boolean mergeSpillBuffers){
  if (previousContext != null) {
    throw new IllegalStateException(""String_Node_Str"" + channelID);
  }
  AbstractOutputChannel<? extends Record> channel=null;
  for (int i=0; i < this.outputGate.getNumberOfOutputChannels(); ++i) {
    AbstractOutputChannel<? extends Record> candidateChannel=this.outputGate.getOutputChannel(i);
    if (candidateChannel.getID().equals(channelID)) {
      channel=candidateChannel;
      break;
    }
  }
  if (channel == null) {
    throw new IllegalArgumentException(""String_Node_Str"" + channelID);
  }
  if (!(channel instanceof AbstractByteBufferedOutputChannel)) {
    throw new IllegalStateException(""String_Node_Str"" + channelID + ""String_Node_Str"");
  }
  AbstractByteBufferedOutputChannel<? extends Record> outputChannel=(AbstractByteBufferedOutputChannel<? extends Record>)channel;
  final RuntimeDispatcher runtimeDispatcher=new RuntimeDispatcher(this.taskContext.getTransferEnvelopeDispatcher());
  final SpillingBarrier spillingBarrier=new SpillingBarrier(isReceiverRunning,mergeSpillBuffers,runtimeDispatcher);
  final ForwardingBarrier forwardingBarrier=new ForwardingBarrier(channelID,spillingBarrier);
  final EphemeralCheckpoint checkpoint=this.taskContext.getEphemeralCheckpoint();
  RuntimeOutputChannelBroker outputChannelBroker;
  if (checkpoint != null) {
    final EphemeralCheckpointForwarder checkpointForwarder=new EphemeralCheckpointForwarder(checkpoint,forwardingBarrier);
    outputChannelBroker=new RuntimeOutputChannelBroker(this,outputChannel,checkpointForwarder);
  }
 else {
    outputChannelBroker=new RuntimeOutputChannelBroker(this,outputChannel,forwardingBarrier);
  }
  final OutputChannelForwardingChain forwardingChain=new OutputChannelForwardingChain(outputChannelBroker,runtimeDispatcher);
  outputChannelBroker.setForwardingChain(forwardingChain);
  return new RuntimeOutputChannelContext(outputChannel,forwardingChain);
}","/** 
 * {@inheritDoc}
 */
@Override public OutputChannelContext createOutputChannelContext(ChannelID channelID,OutputChannelContext previousContext,boolean isReceiverRunning,boolean mergeSpillBuffers){
  if (previousContext != null) {
    throw new IllegalStateException(""String_Node_Str"" + channelID);
  }
  AbstractOutputChannel<? extends Record> channel=null;
  for (int i=0; i < this.outputGate.getNumberOfOutputChannels(); ++i) {
    AbstractOutputChannel<? extends Record> candidateChannel=this.outputGate.getOutputChannel(i);
    if (candidateChannel.getID().equals(channelID)) {
      channel=candidateChannel;
      break;
    }
  }
  if (channel == null) {
    throw new IllegalArgumentException(""String_Node_Str"" + channelID);
  }
  if (!(channel instanceof AbstractByteBufferedOutputChannel)) {
    throw new IllegalStateException(""String_Node_Str"" + channelID + ""String_Node_Str"");
  }
  final AbstractByteBufferedOutputChannel<? extends Record> outputChannel=(AbstractByteBufferedOutputChannel<? extends Record>)channel;
  RuntimeOutputChannelBroker outputChannelBroker;
  AbstractOutputChannelForwarder last;
  if (outputChannel.getType() == ChannelType.FILE) {
    final EphemeralCheckpoint checkpoint=this.taskContext.getEphemeralCheckpoint();
    if (checkpoint == null) {
      throw new IllegalStateException(""String_Node_Str"" + outputChannel.getID());
    }
    final EphemeralCheckpointForwarder checkpointForwarder=new EphemeralCheckpointForwarder(checkpoint,null);
    outputChannelBroker=new RuntimeOutputChannelBroker(this,outputChannel,checkpointForwarder);
    last=checkpointForwarder;
  }
 else {
    final RuntimeDispatcher runtimeDispatcher=new RuntimeDispatcher(this.taskContext.getTransferEnvelopeDispatcher());
    final SpillingBarrier spillingBarrier=new SpillingBarrier(isReceiverRunning,mergeSpillBuffers,runtimeDispatcher);
    final ForwardingBarrier forwardingBarrier=new ForwardingBarrier(channelID,spillingBarrier);
    final EphemeralCheckpoint checkpoint=this.taskContext.getEphemeralCheckpoint();
    if (checkpoint != null) {
      final EphemeralCheckpointForwarder checkpointForwarder=new EphemeralCheckpointForwarder(checkpoint,forwardingBarrier);
      outputChannelBroker=new RuntimeOutputChannelBroker(this,outputChannel,checkpointForwarder);
    }
 else {
      outputChannelBroker=new RuntimeOutputChannelBroker(this,outputChannel,forwardingBarrier);
    }
    last=runtimeDispatcher;
  }
  final OutputChannelForwardingChain forwardingChain=new OutputChannelForwardingChain(outputChannelBroker,last);
  outputChannelBroker.setForwardingChain(forwardingChain);
  return new RuntimeOutputChannelContext(outputChannel,forwardingChain);
}",0.8100104275286757
55546,"/** 
 * Sets up Nephele in local mode.
 */
@BeforeClass public static void startNephele(){
  if (jobManagerThread == null) {
    JobManager jobManager=null;
    try {
      Constructor<JobManager> c=JobManager.class.getDeclaredConstructor(new Class[]{String.class,String.class});
      c.setAccessible(true);
      jobManager=c.newInstance(new Object[]{new String(System.getProperty(""String_Node_Str"") + ""String_Node_Str""),new String(""String_Node_Str"")});
    }
 catch (    SecurityException e) {
      fail(e.getMessage());
    }
catch (    NoSuchMethodException e) {
      fail(e.getMessage());
    }
catch (    IllegalArgumentException e) {
      fail(e.getMessage());
    }
catch (    InstantiationException e) {
      fail(e.getMessage());
    }
catch (    IllegalAccessException e) {
      fail(e.getMessage());
    }
catch (    InvocationTargetException e) {
      fail(e.getMessage());
    }
    configuration=GlobalConfiguration.getConfiguration(new String[]{ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY});
    if (jobManager != null) {
      jobManagerThread=new JobManagerThread(jobManager);
      jobManagerThread.start();
    }
    try {
      Thread.sleep(1000);
    }
 catch (    InterruptedException e) {
      e.printStackTrace();
    }
  }
}","/** 
 * Sets up Nephele in local mode.
 */
@BeforeClass public static void startNephele(){
  if (jobManagerThread == null) {
    JobManager jobManager=null;
    try {
      Constructor<JobManager> c=JobManager.class.getDeclaredConstructor(new Class[]{String.class,String.class});
      c.setAccessible(true);
      jobManager=c.newInstance(new Object[]{ServerTestUtils.getConfigDir(),new String(""String_Node_Str"")});
    }
 catch (    SecurityException e) {
      fail(e.getMessage());
    }
catch (    NoSuchMethodException e) {
      fail(e.getMessage());
    }
catch (    IllegalArgumentException e) {
      fail(e.getMessage());
    }
catch (    InstantiationException e) {
      fail(e.getMessage());
    }
catch (    IllegalAccessException e) {
      fail(e.getMessage());
    }
catch (    InvocationTargetException e) {
      fail(e.getMessage());
    }
    configuration=GlobalConfiguration.getConfiguration(new String[]{ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY});
    if (jobManager != null) {
      jobManagerThread=new JobManagerThread(jobManager);
      jobManagerThread.start();
    }
    try {
      Thread.sleep(1000);
    }
 catch (    InterruptedException e) {
      e.printStackTrace();
    }
  }
}",0.9616471538150988
55547,"/** 
 * {@inheritDoc}
 */
@Override public void logQueuedEnvelopes(){
  this.encapsulatedContext.logQueuedEnvelopes();
}","/** 
 * {@inheritDoc}
 */
@Override public void logQueuedEnvelopes(){
  if (this.encapsulatedContext != null) {
    this.encapsulatedContext.logQueuedEnvelopes();
  }
}",0.8333333333333334
55548,"/** 
 * {@inheritDoc}
 */
@Override public void processEvent(final AbstractEvent event){
  if (event instanceof ByteBufferedChannelCloseEvent) {
    LOG.info(""String_Node_Str"");
  }
 else   if (event instanceof UnexpectedEnvelopeEvent) {
    final UnexpectedEnvelopeEvent uee=(UnexpectedEnvelopeEvent)event;
    if (uee.getExpectedSequenceNumber() > this.nextEnvelopeToSend) {
      this.nextEnvelopeToSend=uee.getExpectedSequenceNumber();
    }
  }
 else {
    LOG.warn(""String_Node_Str"" + event);
  }
  getNext().processEvent(event);
}","/** 
 * {@inheritDoc}
 */
@Override public void processEvent(final AbstractEvent event){
  if (event instanceof ByteBufferedChannelCloseEvent) {
    LOG.info(""String_Node_Str"");
  }
 else   if (event instanceof UnexpectedEnvelopeEvent) {
    final UnexpectedEnvelopeEvent uee=(UnexpectedEnvelopeEvent)event;
    if (uee.getExpectedSequenceNumber() > this.nextEnvelopeToSend) {
      this.nextEnvelopeToSend=uee.getExpectedSequenceNumber();
    }
  }
 else   if (event instanceof ReceiverNotFoundEvent) {
    final ReceiverNotFoundEvent rnfe=(ReceiverNotFoundEvent)event;
    LOG.warn(""String_Node_Str"" + rnfe.getReceiverID() + ""String_Node_Str""+ rnfe.getSequenceNumber());
  }
 else {
    LOG.warn(""String_Node_Str"" + event);
  }
  getNext().processEvent(event);
}",0.8178324365872406
55549,"/** 
 * Cancels and removes the task represented by this vertex from the instance it is currently running on. If the task is not currently running, its execution state is simply updated to <code>CANCELLED</code>.
 * @return the result of the task cancel attempt
 */
public TaskCancelResult cancelTask(){
  final ExecutionState previousState=this.executionState.get();
  if (previousState == ExecutionState.CANCELED) {
    return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
  }
  if (updateExecutionState(ExecutionState.CANCELING) != ExecutionState.CANCELING) {
    if (this.groupVertex.getStageNumber() != this.executionGraph.getIndexOfCurrentExecutionStage()) {
      updateExecutionState(ExecutionState.CANCELED,null);
      return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
    }
    if (previousState == ExecutionState.FINISHED || previousState == ExecutionState.FAILED) {
      return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
    }
    if (previousState != ExecutionState.RUNNING && previousState != ExecutionState.STARTING && previousState != ExecutionState.FINISHING && previousState != ExecutionState.REPLAYING) {
      updateExecutionState(ExecutionState.CANCELED,null);
      return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
    }
    if (this.allocatedResource == null) {
      final TaskCancelResult result=new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.NO_INSTANCE);
      result.setDescription(""String_Node_Str"" + this.toString() + ""String_Node_Str"");
      return result;
    }
    try {
      return this.allocatedResource.getInstance().cancelTask(this.vertexID);
    }
 catch (    IOException e) {
      final TaskCancelResult result=new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.IPC_ERROR);
      result.setDescription(StringUtils.stringifyException(e));
      return result;
    }
  }
  return new TaskCancelResult(getID(),ReturnCode.SUCCESS);
}","/** 
 * Cancels and removes the task represented by this vertex from the instance it is currently running on. If the task is not currently running, its execution state is simply updated to <code>CANCELLED</code>.
 * @return the result of the task cancel attempt
 */
public TaskCancelResult cancelTask(){
  final ExecutionState previousState=this.executionState.get();
  if (previousState == ExecutionState.CANCELED) {
    return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
  }
  if (previousState == ExecutionState.FAILED) {
    return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
  }
  if (previousState == ExecutionState.FINISHED) {
    return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
  }
  if (updateExecutionState(ExecutionState.CANCELING) != ExecutionState.CANCELING) {
    if (this.groupVertex.getStageNumber() != this.executionGraph.getIndexOfCurrentExecutionStage()) {
      updateExecutionState(ExecutionState.CANCELED,null);
      return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
    }
    if (previousState == ExecutionState.FINISHED || previousState == ExecutionState.FAILED) {
      return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
    }
    if (previousState != ExecutionState.RUNNING && previousState != ExecutionState.STARTING && previousState != ExecutionState.FINISHING && previousState != ExecutionState.REPLAYING) {
      updateExecutionState(ExecutionState.CANCELED,null);
      return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
    }
    if (this.allocatedResource == null) {
      final TaskCancelResult result=new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.NO_INSTANCE);
      result.setDescription(""String_Node_Str"" + this.toString() + ""String_Node_Str"");
      return result;
    }
    try {
      return this.allocatedResource.getInstance().cancelTask(this.vertexID);
    }
 catch (    IOException e) {
      final TaskCancelResult result=new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.IPC_ERROR);
      result.setDescription(StringUtils.stringifyException(e));
      return result;
    }
  }
  return new TaskCancelResult(getID(),ReturnCode.SUCCESS);
}",0.9375
55550,"/** 
 * Updates the vertex's current execution state.
 * @param newExecutionState the new execution state
 * @param optionalMessage an optional message related to the state change
 */
public ExecutionState updateExecutionState(ExecutionState newExecutionState,final String optionalMessage){
  if (newExecutionState == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (this.executionState.get() == ExecutionState.CANCELING && newExecutionState == ExecutionState.FINISHED) {
    LOG.info(""String_Node_Str"" + toString() + ""String_Node_Str"");
    newExecutionState=ExecutionState.CANCELED;
  }
  final ExecutionState previousState=this.executionState.getAndSet(newExecutionState);
  if (previousState == newExecutionState) {
    return previousState;
  }
  ExecutionStateTransition.checkTransition(true,toString(),previousState,newExecutionState);
  final Iterator<ExecutionListener> it=this.executionListeners.values().iterator();
  while (it.hasNext()) {
    it.next().executionStateChanged(this.executionGraph.getJobID(),this.vertexID,newExecutionState,optionalMessage);
  }
  return previousState;
}","/** 
 * Updates the vertex's current execution state.
 * @param newExecutionState the new execution state
 * @param optionalMessage an optional message related to the state change
 */
public ExecutionState updateExecutionState(ExecutionState newExecutionState,final String optionalMessage){
  if (newExecutionState == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  final ExecutionState currentExecutionState=this.executionState.get();
  if (currentExecutionState == ExecutionState.CANCELING) {
    if (newExecutionState == ExecutionState.FINISHING) {
      return currentExecutionState;
    }
    if (newExecutionState == ExecutionState.FINISHED) {
      LOG.info(""String_Node_Str"" + toString() + ""String_Node_Str"");
      newExecutionState=ExecutionState.CANCELED;
    }
  }
  final ExecutionState previousState=this.executionState.getAndSet(newExecutionState);
  if (previousState == newExecutionState) {
    return previousState;
  }
  ExecutionStateTransition.checkTransition(true,toString(),previousState,newExecutionState);
  final Iterator<ExecutionListener> it=this.executionListeners.values().iterator();
  while (it.hasNext()) {
    it.next().executionStateChanged(this.executionGraph.getJobID(),this.vertexID,newExecutionState,optionalMessage);
  }
  return previousState;
}",0.8978251949117768
55551,"/** 
 * Registers an newly incoming runtime task with the task manager.
 * @param id the ID of the task to register
 * @param jobConfiguration the job configuration that has been attached to the original job graph
 * @param environment the environment of the task to be registered
 * @param activeOutputChannels the set of initially active output channels
 * @return the task to be started or <code>null</code> if a task with the same ID was already running
 */
private Task createAndRegisterTask(final ExecutionVertexID id,final Configuration jobConfiguration,final RuntimeEnvironment environment,final Set<ChannelID> activeOutputChannels) throws IOException {
  if (id == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (environment == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  Task task=null;
synchronized (this) {
    final Task runningTask=this.runningTasks.get(id);
    boolean registerTask=true;
    if (runningTask == null) {
      if (CheckpointUtils.hasCompleteCheckpointAvailable(id)) {
        task=new ReplayTask(id,environment,this);
      }
 else {
        task=new RuntimeTask(id,environment,this);
      }
    }
 else {
      if (runningTask instanceof RuntimeTask) {
        if (CheckpointUtils.hasPartialCheckpointAvailable(id)) {
          task=new ReplayTask((RuntimeTask)runningTask,this);
        }
 else {
          return null;
        }
      }
 else {
        registerTask=false;
      }
    }
    final Environment ee=task.getEnvironment();
    if (registerTask) {
      task.registerMemoryManager(this.memoryManager);
      task.registerIOManager(this.ioManager);
      task.registerInputSplitProvider(new TaskInputSplitProvider(ee.getJobID(),id,this.globalInputSplitProvider));
      this.byteBufferedChannelManager.register(task,activeOutputChannels);
      boolean enableProfiling=false;
      if (this.profiler != null && jobConfiguration.getBoolean(ProfilingUtils.PROFILE_JOB_KEY,true)) {
        enableProfiling=true;
      }
      if (enableProfiling) {
        task.registerProfiler(this.profiler,jobConfiguration);
      }
      if (!this.taskManagerPlugins.isEmpty()) {
        final Iterator<TaskManagerPlugin> it=this.taskManagerPlugins.values().iterator();
        while (it.hasNext()) {
          it.next().registerTask(id,jobConfiguration,ee);
        }
      }
      this.runningTasks.put(id,task);
    }
  }
  return task;
}","/** 
 * Registers an newly incoming runtime task with the task manager.
 * @param id the ID of the task to register
 * @param jobConfiguration the job configuration that has been attached to the original job graph
 * @param environment the environment of the task to be registered
 * @param activeOutputChannels the set of initially active output channels
 * @return the task to be started or <code>null</code> if a task with the same ID was already running
 */
private Task createAndRegisterTask(final ExecutionVertexID id,final Configuration jobConfiguration,final RuntimeEnvironment environment,final Set<ChannelID> activeOutputChannels) throws IOException {
  if (id == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (environment == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  Task task=null;
synchronized (this) {
    final Task runningTask=this.runningTasks.get(id);
    boolean registerTask=true;
    if (runningTask == null) {
      if (CheckpointUtils.hasCompleteCheckpointAvailable(id)) {
        task=new ReplayTask(id,environment,this);
      }
 else {
        task=new RuntimeTask(id,environment,this);
      }
    }
 else {
      if (runningTask instanceof RuntimeTask) {
        if (CheckpointUtils.hasPartialCheckpointAvailable(id)) {
          task=new ReplayTask((RuntimeTask)runningTask,this);
        }
 else {
          return null;
        }
      }
 else {
        task=runningTask;
        registerTask=false;
      }
    }
    final Environment ee=task.getEnvironment();
    if (registerTask) {
      task.registerMemoryManager(this.memoryManager);
      task.registerIOManager(this.ioManager);
      task.registerInputSplitProvider(new TaskInputSplitProvider(ee.getJobID(),id,this.globalInputSplitProvider));
      this.byteBufferedChannelManager.register(task,activeOutputChannels);
      boolean enableProfiling=false;
      if (this.profiler != null && jobConfiguration.getBoolean(ProfilingUtils.PROFILE_JOB_KEY,true)) {
        enableProfiling=true;
      }
      if (enableProfiling) {
        task.registerProfiler(this.profiler,jobConfiguration);
      }
      if (!this.taskManagerPlugins.isEmpty()) {
        final Iterator<TaskManagerPlugin> it=this.taskManagerPlugins.values().iterator();
        while (it.hasNext()) {
          it.next().registerTask(id,jobConfiguration,ee);
        }
      }
      this.runningTasks.put(id,task);
    }
  }
  return task;
}",0.9946764946764948
55552,"public void executionStateChanged(final JobID jobID,final ExecutionVertexID id,final ExecutionState newExecutionState,final String optionalDescription){
  if (newExecutionState == ExecutionState.FINISHED || newExecutionState == ExecutionState.CANCELED || newExecutionState == ExecutionState.FAILED) {
    unregisterTask(id);
  }
synchronized (this.jobManager) {
    try {
      this.jobManager.updateTaskExecutionState(new TaskExecutionState(jobID,id,newExecutionState,optionalDescription));
    }
 catch (    IOException e) {
      LOG.error(StringUtils.stringifyException(e));
    }
  }
}","public void executionStateChanged(final JobID jobID,final ExecutionVertexID id,final ExecutionState newExecutionState,final String optionalDescription){
  if (newExecutionState == ExecutionState.CANCELING) {
    return;
  }
  if (newExecutionState == ExecutionState.FINISHED || newExecutionState == ExecutionState.CANCELED || newExecutionState == ExecutionState.FAILED) {
    unregisterTask(id);
  }
synchronized (this.jobManager) {
    try {
      this.jobManager.updateTaskExecutionState(new TaskExecutionState(jobID,id,newExecutionState,optionalDescription));
    }
 catch (    IOException e) {
      LOG.error(StringUtils.stringifyException(e));
    }
  }
}",0.8665067945643485
55553,"/** 
 * {@inheritDoc}
 */
@Override public boolean hasDataLeft(){
  return this.writeThread.hasDataLeft();
}","/** 
 * {@inheritDoc}
 */
@Override public boolean hasDataLeft() throws IOException, InterruptedException {
  if (isUndecided()) {
    setCheckpointDecisionSynchronously(true);
  }
  if (this.writeThread == null) {
    return false;
  }
  if (this.writeThread.hasDataLeft()) {
    return true;
  }
  if (!this.completeCheckpointAnnounced) {
    this.completeCheckpointAnnounced=true;
    this.task.checkpointStateChanged(CheckpointState.COMPLETE);
  }
  return false;
}",0.3084922010398613
55554,"boolean hasFinished(){
  this.incomingEventQueue.processQueuedEvents();
  return (!this.forwardingChain.anyForwarderHasDataLeft());
}","boolean hasFinished() throws IOException, InterruptedException {
  this.incomingEventQueue.processQueuedEvents();
  return (!this.forwardingChain.anyForwarderHasDataLeft());
}",0.8636363636363636
55555,"private void replayCheckpoint() throws Exception {
  final CheckpointDeserializer deserializer=new CheckpointDeserializer(this.vertexID);
  final Path checkpointPath=this.isCheckpointLocal ? CheckpointUtils.getLocalCheckpointPath() : CheckpointUtils.getDistributedCheckpointPath();
  if (checkpointPath == null) {
    throw new IOException(""String_Node_Str"" + this.vertexID);
  }
  final FileSystem fileSystem=checkpointPath.getFileSystem();
  int metaDataIndex=0;
  Buffer firstDeserializedFileBuffer=null;
  FileChannel fileChannel=null;
  try {
    while (true) {
      if (this.restartRequested.compareAndSet(true,false)) {
        metaDataIndex=0;
      }
      final Path metaDataFile=checkpointPath.suffix(Path.SEPARATOR + CheckpointUtils.METADATA_PREFIX + ""String_Node_Str""+ this.vertexID+ ""String_Node_Str""+ metaDataIndex);
      while (!fileSystem.exists(metaDataFile)) {
        final Path finalMetaDataFile=checkpointPath.suffix(Path.SEPARATOR + CheckpointUtils.METADATA_PREFIX + ""String_Node_Str""+ this.vertexID+ ""String_Node_Str"");
        if (fileSystem.exists(finalMetaDataFile)) {
          return;
        }
        if (this.isCheckpointComplete) {
          throw new FileNotFoundException(""String_Node_Str"" + metaDataIndex + ""String_Node_Str""+ this.vertexID);
        }
        Thread.sleep(1000);
      }
      fileChannel=getFileChannel(fileSystem,metaDataFile);
      while (true) {
        try {
          deserializer.read(fileChannel);
          final TransferEnvelope transferEnvelope=deserializer.getFullyDeserializedTransferEnvelope();
          if (transferEnvelope != null) {
            final ReplayOutputBroker broker=this.outputBrokerMap.get(transferEnvelope.getSource());
            if (broker == null) {
              throw new IOException(""String_Node_Str"" + transferEnvelope.getSource());
            }
            final Buffer srcBuffer=transferEnvelope.getBuffer();
            if (srcBuffer != null) {
              if (firstDeserializedFileBuffer == null) {
                firstDeserializedFileBuffer=srcBuffer.duplicate();
              }
              if (transferEnvelope.getSequenceNumber() < broker.getNextEnvelopeToSend()) {
                srcBuffer.recycleBuffer();
                continue;
              }
              final Buffer destBuffer=broker.requestEmptyBufferBlocking(srcBuffer.size());
              srcBuffer.copyToBuffer(destBuffer);
              transferEnvelope.setBuffer(destBuffer);
              srcBuffer.recycleBuffer();
            }
            broker.outputEnvelope(transferEnvelope);
          }
        }
 catch (        EOFException eof) {
          fileChannel.close();
          fileChannel=null;
          ++metaDataIndex;
          break;
        }
      }
    }
  }
  finally {
    if (firstDeserializedFileBuffer != null) {
      firstDeserializedFileBuffer.recycleBuffer();
      firstDeserializedFileBuffer=null;
    }
    if (fileChannel != null) {
      fileChannel.close();
      fileChannel=null;
    }
  }
}","private void replayCheckpoint() throws Exception {
  final CheckpointDeserializer deserializer=new CheckpointDeserializer(this.vertexID,!this.isCheckpointLocal);
  final Path checkpointPath=this.isCheckpointLocal ? CheckpointUtils.getLocalCheckpointPath() : CheckpointUtils.getDistributedCheckpointPath();
  if (checkpointPath == null) {
    throw new IOException(""String_Node_Str"" + this.vertexID);
  }
  final FileSystem fileSystem=checkpointPath.getFileSystem();
  int metaDataIndex=0;
  Buffer firstDeserializedFileBuffer=null;
  FileChannel fileChannel=null;
  try {
    while (true) {
      if (this.restartRequested.compareAndSet(true,false)) {
        metaDataIndex=0;
      }
      final Path metaDataFile=checkpointPath.suffix(Path.SEPARATOR + CheckpointUtils.METADATA_PREFIX + ""String_Node_Str""+ this.vertexID+ ""String_Node_Str""+ metaDataIndex);
      while (!fileSystem.exists(metaDataFile)) {
        final Path finalMetaDataFile=checkpointPath.suffix(Path.SEPARATOR + CheckpointUtils.METADATA_PREFIX + ""String_Node_Str""+ this.vertexID+ ""String_Node_Str"");
        if (fileSystem.exists(finalMetaDataFile)) {
          return;
        }
        if (this.isCheckpointComplete) {
          throw new FileNotFoundException(""String_Node_Str"" + metaDataIndex + ""String_Node_Str""+ this.vertexID);
        }
        Thread.sleep(1000);
      }
      fileChannel=getFileChannel(fileSystem,metaDataFile);
      while (true) {
        try {
          deserializer.read(fileChannel);
          final TransferEnvelope transferEnvelope=deserializer.getFullyDeserializedTransferEnvelope();
          if (transferEnvelope != null) {
            final ReplayOutputBroker broker=this.outputBrokerMap.get(transferEnvelope.getSource());
            if (broker == null) {
              throw new IOException(""String_Node_Str"" + transferEnvelope.getSource());
            }
            final Buffer srcBuffer=transferEnvelope.getBuffer();
            if (srcBuffer != null) {
              if (firstDeserializedFileBuffer == null) {
                firstDeserializedFileBuffer=srcBuffer.duplicate();
              }
              if (transferEnvelope.getSequenceNumber() < broker.getNextEnvelopeToSend()) {
                srcBuffer.recycleBuffer();
                continue;
              }
              final Buffer destBuffer=broker.requestEmptyBufferBlocking(srcBuffer.size());
              srcBuffer.copyToBuffer(destBuffer);
              transferEnvelope.setBuffer(destBuffer);
              srcBuffer.recycleBuffer();
            }
            broker.outputEnvelope(transferEnvelope);
          }
        }
 catch (        EOFException eof) {
          fileChannel.close();
          fileChannel=null;
          ++metaDataIndex;
          break;
        }
      }
    }
  }
  finally {
    if (firstDeserializedFileBuffer != null) {
      firstDeserializedFileBuffer.recycleBuffer();
      firstDeserializedFileBuffer=null;
    }
    if (fileChannel != null) {
      fileChannel.close();
      fileChannel=null;
    }
  }
}",0.9960172585462994
55556,boolean hasDataLeft();,"boolean hasDataLeft() throws IOException, InterruptedException ;",0.5116279069767442
55557,"public boolean anyForwarderHasDataLeft(){
  final Iterator<OutputChannelForwarder> it=this.forwardingChain.iterator();
  while (it.hasNext()) {
    if (it.next().hasDataLeft()) {
      return true;
    }
  }
  return false;
}","public boolean anyForwarderHasDataLeft() throws IOException, InterruptedException {
  final Iterator<OutputChannelForwarder> it=this.forwardingChain.iterator();
  while (it.hasNext()) {
    if (it.next().hasDataLeft()) {
      return true;
    }
  }
  return false;
}",0.9146341463414634
55558,"public CheckpointDeserializer(final AbstractID ownerID){
  this.ownerID=ownerID;
  this.fileBufferManager=FileBufferManager.getInstance();
}","public CheckpointDeserializer(final AbstractID ownerID,final boolean distributed){
  this.ownerID=ownerID;
  this.fileBufferManager=FileBufferManager.getInstance();
  this.distributed=distributed;
}",0.8284023668639053
55559,"@Override protected boolean readBufferData(final ReadableByteChannel readableByteChannel) throws IOException {
  final ByteBuffer tempBuffer=getTempBuffer();
  if (!this.bufferDataSerializationStarted) {
    tempBuffer.clear();
    this.bufferDataSerializationStarted=true;
  }
  readableByteChannel.read(tempBuffer);
  if (tempBuffer.hasRemaining()) {
    return true;
  }
  final long offset=byteBufferToLong(tempBuffer);
  final Buffer fileBuffer=BufferFactory.createFromCheckpoint(getSizeOfBuffer(),offset,this.ownerID,this.fileBufferManager,true);
  setBuffer(fileBuffer);
  this.bufferDataSerializationStarted=false;
  return false;
}","@Override protected boolean readBufferData(final ReadableByteChannel readableByteChannel) throws IOException {
  final ByteBuffer tempBuffer=getTempBuffer();
  if (!this.bufferDataSerializationStarted) {
    tempBuffer.clear();
    this.bufferDataSerializationStarted=true;
  }
  readableByteChannel.read(tempBuffer);
  if (tempBuffer.hasRemaining()) {
    return true;
  }
  final long offset=byteBufferToLong(tempBuffer);
  final Buffer fileBuffer=BufferFactory.createFromCheckpoint(getSizeOfBuffer(),offset,this.ownerID,this.fileBufferManager,this.distributed);
  setBuffer(fileBuffer);
  this.bufferDataSerializationStarted=false;
  return false;
}",0.9860681114551084
55560,"/** 
 * {@inheritDoc}
 */
@Override public void read(DataInput in) throws IOException {
  final int addr_length=in.readInt();
  byte[] address=new byte[addr_length];
  in.readFully(address);
  this.hostname=StringRecord.readString(in);
  try {
    this.inetAddress=InetAddress.getByAddress(address);
  }
 catch (  UnknownHostException uhe) {
    throw new IOException(StringUtils.stringifyException(uhe));
  }
  this.ipcPort=in.readInt();
  this.dataPort=in.readInt();
}","/** 
 * {@inheritDoc}
 */
@Override public void read(DataInput in) throws IOException {
  final int addr_length=in.readInt();
  byte[] address=new byte[addr_length];
  in.readFully(address);
  this.hostname=StringRecord.readString(in);
  this.domainname=StringRecord.readString(in);
  try {
    this.inetAddress=InetAddress.getByAddress(address);
  }
 catch (  UnknownHostException uhe) {
    throw new IOException(StringUtils.stringifyException(uhe));
  }
  this.ipcPort=in.readInt();
  this.dataPort=in.readInt();
}",0.9523809523809524
55561,"/** 
 * Returns the host name of the instance.
 * @return the host name of the instance
 */
public String getHostName(){
  return this.hostname;
}","/** 
 * Returns the host name of the instance. If the host name could not be determined, the return value will be a textual representation of the instance's IP address.
 * @return the host name of the instance
 */
public String getHostName(){
  return this.hostname;
}",0.7053140096618358
55562,"/** 
 * {@inheritDoc}
 */
@Override public void write(DataOutput out) throws IOException {
  out.writeInt(this.inetAddress.getAddress().length);
  out.write(this.inetAddress.getAddress());
  StringRecord.writeString(out,this.hostname);
  out.writeInt(this.ipcPort);
  out.writeInt(this.dataPort);
}","/** 
 * {@inheritDoc}
 */
@Override public void write(DataOutput out) throws IOException {
  out.writeInt(this.inetAddress.getAddress().length);
  out.write(this.inetAddress.getAddress());
  StringRecord.writeString(out,this.hostname);
  StringRecord.writeString(out,this.domainname);
  out.writeInt(this.ipcPort);
  out.writeInt(this.dataPort);
}",0.924031007751938
55563,"public long getDefaultBlockSize(){
  return 32 * 1024 * 1024;
}","/** 
 * Return the number of bytes that large input files should be optimally be split into to minimize I/O time.
 * @return the number of bytes that large input files should be optimally be split into to minimize I/O time
 */
public long getDefaultBlockSize(){
  return 32 * 1024 * 1024;
}",0.3569405099150141
55564,"/** 
 * {@inheritDoc}
 */
@Override public ChannelType getType(){
  return this.encapsulatedContext.getType();
}","/** 
 * {@inheritDoc}
 */
@Override public ChannelType getType(){
  return null;
}",0.8350515463917526
55565,"/** 
 * Creates an instance that wraps the plan defined in the jar file using the given arguments. For generating the plan the class defined in the className parameter is used.
 * @param jarFile The jar file which contains the plan.
 * @param className Name of the class which generates the plan. Overrides the class defined in the jar file manifest
 * @param args Optional. The arguments used to create the pact plan, depend on implementation of the pact plan. See getDescription().
 * @throws ProgramInvocationException This invocation is thrown if the PlanAssembler can't be properly loaded. Causes may be a missing / wrong class or manifest files.
 */
public PactProgram(File jarFile,String className,String... args) throws ProgramInvocationException {
  this.assemblerClass=getPactAssemblerFromJar(jarFile,className);
  this.jarFile=jarFile;
  this.args=args;
}","/** 
 * Creates an instance that wraps the plan defined in the jar file using the given arguments. For generating the plan the class defined in the className parameter is used.
 * @param jarFile The jar file which contains the plan.
 * @param className Name of the class which generates the plan. Overrides the class defined in the jar file manifest
 * @param args Optional. The arguments used to create the pact plan, depend on implementation of the pact plan. See getDescription().
 * @throws ProgramInvocationException This invocation is thrown if the PlanAssembler can't be properly loaded. Causes may be a missing / wrong class or manifest files.
 */
public PactProgram(File jarFile,String className,String... args) throws ProgramInvocationException {
  this.jarFile=jarFile;
  this.args=args;
  this.assemblerClass=getPactAssemblerFromJar(jarFile,className);
}",0.9515011547344112
55566,"/** 
 * Cancels or kills the task.
 * @param cancel <code>true/code> if the task shall be cancelled, <code>false</code> if it shall be killed
 */
private void cancelOrKillExecution(final boolean cancel){
  final Thread replayThread=this.environment.getExecutingThread();
  Thread encapsulatedThread=null;
  if (this.encapsulatedTask != null) {
    encapsulatedThread=this.encapsulatedTask.getRuntimeEnvironment().getExecutingThread();
  }
  if (replayThread == null && encapsulatedThread == null) {
    return;
  }
  if (cancel) {
    this.isCanceled=true;
    this.replayTaskExecutionState=ExecutionState.CANCELING;
    if (this.encapsulatedExecutionState != null) {
      this.encapsulatedExecutionState=ExecutionState.CANCELING;
    }
    reportExecutionStateChange(true,null);
  }
  if (this.encapsulatedTask != null) {
    try {
      final AbstractInvokable invokable=this.encapsulatedTask.getRuntimeEnvironment().getInvokable();
      if (invokable != null) {
        invokable.cancel();
      }
    }
 catch (    Throwable e) {
      LOG.error(StringUtils.stringifyException(e));
    }
  }
  while (true) {
    replayThread.interrupt();
    if (encapsulatedThread != null) {
      encapsulatedThread.interrupt();
    }
    if (cancel) {
      if (this.overallExecutionState.get() == ExecutionState.CANCELED) {
        break;
      }
    }
 else {
      if (this.overallExecutionState.get() == ExecutionState.FAILED) {
        break;
      }
    }
    try {
      Thread.sleep(100);
    }
 catch (    InterruptedException e) {
      break;
    }
  }
}","/** 
 * Cancels or kills the task.
 * @param cancel <code>true/code> if the task shall be cancelled, <code>false</code> if it shall be killed
 */
private void cancelOrKillExecution(final boolean cancel){
  final Thread replayThread=this.environment.getExecutingThread();
  Thread encapsulatedThread=null;
  if (this.encapsulatedTask != null) {
    encapsulatedThread=this.encapsulatedTask.getRuntimeEnvironment().getExecutingThread();
  }
  if (replayThread == null && encapsulatedThread == null) {
    return;
  }
  if (cancel) {
    this.isCanceled=true;
    this.replayTaskExecutionState=ExecutionState.CANCELING;
    if (this.encapsulatedExecutionState != null) {
      this.encapsulatedExecutionState=ExecutionState.CANCELING;
    }
    reportExecutionStateChange(true,null);
    if (this.encapsulatedTask != null) {
      try {
        final AbstractInvokable invokable=this.encapsulatedTask.getRuntimeEnvironment().getInvokable();
        if (invokable != null) {
          invokable.cancel();
        }
      }
 catch (      Throwable e) {
        LOG.error(StringUtils.stringifyException(e));
      }
    }
  }
  while (true) {
    replayThread.interrupt();
    if (encapsulatedThread != null) {
      encapsulatedThread.interrupt();
    }
    if (cancel) {
      if (this.overallExecutionState.get() == ExecutionState.CANCELED) {
        break;
      }
    }
 else {
      if (this.overallExecutionState.get() == ExecutionState.FAILED) {
        break;
      }
    }
    try {
      Thread.sleep(100);
    }
 catch (    InterruptedException e) {
      break;
    }
  }
}",0.9815168897386872
55567,"/** 
 * Cancels or kills the task.
 * @param cancel <code>true/code> if the task shall be canceled, <code>false</code> if it shall be killed
 */
private void cancelOrKillExecution(final boolean cancel){
  final Thread executingThread=this.environment.getExecutingThread();
  if (executingThread == null) {
    return;
  }
  if (this.executionState != ExecutionState.RUNNING && this.executionState != ExecutionState.REPLAYING && this.executionState != ExecutionState.FINISHING) {
    return;
  }
  LOG.info((cancel ? ""String_Node_Str"" : ""String_Node_Str"") + this.environment.getTaskNameWithIndex());
  if (cancel) {
    this.isCanceled=true;
    executionStateChanged(ExecutionState.CANCELING,null);
  }
  try {
    final AbstractInvokable invokable=this.environment.getInvokable();
    if (invokable != null) {
      invokable.cancel();
    }
  }
 catch (  Throwable e) {
    LOG.error(StringUtils.stringifyException(e));
  }
  while (true) {
    executingThread.interrupt();
    if (!executingThread.isAlive()) {
      break;
    }
    try {
      Thread.sleep(100);
    }
 catch (    InterruptedException e) {
      break;
    }
    LOG.info((cancel == true ? ""String_Node_Str"" : ""String_Node_Str"") + this.environment.getTaskName() + ""String_Node_Str""+ this.executionState);
  }
}","/** 
 * Cancels or kills the task.
 * @param cancel <code>true/code> if the task shall be canceled, <code>false</code> if it shall be killed
 */
private void cancelOrKillExecution(final boolean cancel){
  final Thread executingThread=this.environment.getExecutingThread();
  if (executingThread == null) {
    return;
  }
  if (this.executionState != ExecutionState.RUNNING && this.executionState != ExecutionState.REPLAYING && this.executionState != ExecutionState.FINISHING) {
    return;
  }
  LOG.info((cancel ? ""String_Node_Str"" : ""String_Node_Str"") + this.environment.getTaskNameWithIndex());
  if (cancel) {
    this.isCanceled=true;
    executionStateChanged(ExecutionState.CANCELING,null);
    try {
      final AbstractInvokable invokable=this.environment.getInvokable();
      if (invokable != null) {
        invokable.cancel();
      }
    }
 catch (    Throwable e) {
      LOG.error(StringUtils.stringifyException(e));
    }
  }
  while (true) {
    executingThread.interrupt();
    if (!executingThread.isAlive()) {
      break;
    }
    try {
      Thread.sleep(100);
    }
 catch (    InterruptedException e) {
      break;
    }
    LOG.info((cancel == true ? ""String_Node_Str"" : ""String_Node_Str"") + this.environment.getTaskName() + ""String_Node_Str""+ this.executionState);
  }
}",0.99147947327653
55568,"@Override protected Entry<String,IJsonNode> loadNext(){
  if (this.lastIndex >= LazyObjectNode.this.schema.getMappingSize()) {
    return noMoreElements();
  }
  String key=LazyObjectNode.this.schema.getMappings().get(this.lastIndex);
  IJsonNode value=SopremoUtil.unwrap(LazyObjectNode.this.record.getField(this.lastIndex,JsonNodeWrapper.class));
  this.lastIndex++;
  return new AbstractMap.SimpleEntry<String,IJsonNode>(key,value);
}","@Override protected Entry<String,IJsonNode> loadNext(){
  while (this.lastIndex < LazyObjectNode.this.schema.getMappingSize()) {
    String key=LazyObjectNode.this.schema.getMappings().get(this.lastIndex);
    if (!LazyObjectNode.this.record.isNull(lastIndex)) {
      IJsonNode value=SopremoUtil.unwrap(LazyObjectNode.this.record.getField(this.lastIndex,JsonNodeWrapper.class));
      this.lastIndex++;
      return new AbstractMap.SimpleEntry<String,IJsonNode>(key,value);
    }
    this.lastIndex++;
  }
  return noMoreElements();
}",0.7188465499485067
55569,"@Override public Iterator<Entry<String,IJsonNode>> iterator(){
  Iterator<Entry<String,IJsonNode>> iterator2=((IObjectNode)getOtherField()).iterator();
  Iterator<Entry<String,IJsonNode>> iterator1=new AbstractIterator<Map.Entry<String,IJsonNode>>(){
    int lastIndex=0;
    @Override protected Entry<String,IJsonNode> loadNext(){
      if (this.lastIndex >= LazyObjectNode.this.schema.getMappingSize()) {
        return noMoreElements();
      }
      String key=LazyObjectNode.this.schema.getMappings().get(this.lastIndex);
      IJsonNode value=SopremoUtil.unwrap(LazyObjectNode.this.record.getField(this.lastIndex,JsonNodeWrapper.class));
      this.lastIndex++;
      return new AbstractMap.SimpleEntry<String,IJsonNode>(key,value);
    }
  }
;
  return new ConcatenatingIterator<Map.Entry<String,IJsonNode>>(iterator1,iterator2);
}","@Override public Iterator<Entry<String,IJsonNode>> iterator(){
  Iterator<Entry<String,IJsonNode>> iterator2=((IObjectNode)getOtherField()).iterator();
  Iterator<Entry<String,IJsonNode>> iterator1=new AbstractIterator<Map.Entry<String,IJsonNode>>(){
    int lastIndex=0;
    @Override protected Entry<String,IJsonNode> loadNext(){
      while (this.lastIndex < LazyObjectNode.this.schema.getMappingSize()) {
        String key=LazyObjectNode.this.schema.getMappings().get(this.lastIndex);
        if (!LazyObjectNode.this.record.isNull(lastIndex)) {
          IJsonNode value=SopremoUtil.unwrap(LazyObjectNode.this.record.getField(this.lastIndex,JsonNodeWrapper.class));
          this.lastIndex++;
          return new AbstractMap.SimpleEntry<String,IJsonNode>(key,value);
        }
        this.lastIndex++;
      }
      return noMoreElements();
    }
  }
;
  return new ConcatenatingIterator<Map.Entry<String,IJsonNode>>(iterator1,iterator2);
}",0.8505875769445999
55570,"@Override public PactRecord jsonToRecord(IJsonNode value,PactRecord target){
  if (target == null) {
    target=new PactRecord(this.mapping.size() + 1);
  }
  for (int i=0; i < this.mapping.size(); i++) {
    target.setField(i,new JsonNodeWrapper(((IObjectNode)value).get(this.mapping.get(i))));
    ((IObjectNode)value).remove(this.mapping.get(i));
  }
  target.setField(this.mapping.size(),new JsonNodeWrapper(value));
  return target;
}","@Override public PactRecord jsonToRecord(IJsonNode value,PactRecord target){
  if (target == null) {
    target=new PactRecord(this.mapping.size() + 1);
  }
  for (int i=0; i < this.mapping.size(); i++) {
    target.setField(i,new JsonNodeWrapper(((IObjectNode)value).remove(this.mapping.get(i))));
  }
  target.setField(this.mapping.size(),new JsonNodeWrapper(value));
  return target;
}",0.7255139056831923
55571,"@Override public Class<? extends Value>[] getPactSchema(){
  Class<? extends Value>[] schema=new Class[this.mapping.size()];
  for (int i=0; i < this.mapping.size(); i++) {
    schema[i]=JsonNodeWrapper.class;
  }
  return schema;
}","@Override public Class<? extends Value>[] getPactSchema(){
  Class<? extends Value>[] schema=new Class[this.mapping.size() + 1];
  for (int i=0; i <= this.mapping.size(); i++) {
    schema[i]=JsonNodeWrapper.class;
  }
  return schema;
}",0.9893390191897654
55572,"@Test public void shouldUseRecordTarget(){
  this.schema.setMappings(""String_Node_Str"",""String_Node_Str"");
  ObjectNode object=new ObjectNode().put(""String_Node_Str"",TextNode.valueOf(""String_Node_Str"")).put(""String_Node_Str"",TextNode.valueOf(""String_Node_Str""));
  PactRecord target=new PactRecord();
  PactRecord result=this.schema.jsonToRecord(object,target);
  Assert.assertSame(target,result);
}","@Test public void shouldUseRecordTarget(){
  this.schema.setMappings(""String_Node_Str"",""String_Node_Str"");
  ObjectNode object=new ObjectNode().put(""String_Node_Str"",TextNode.valueOf(""String_Node_Str"")).put(""String_Node_Str"",TextNode.valueOf(""String_Node_Str""));
  PactRecord target=new PactRecord();
  target.setField(2,new JsonNodeWrapper(new ObjectNode()));
  PactRecord result=this.schema.jsonToRecord(object,target);
  Assert.assertSame(target,result);
}",0.93006993006993
55573,"@Test public void shouldConvertFromJsonToRecord(){
  this.schema.setMappings(""String_Node_Str"",""String_Node_Str"");
  ObjectNode object=new ObjectNode();
  object.put(""String_Node_Str"",TextNode.valueOf(""String_Node_Str"")).put(""String_Node_Str"",TextNode.valueOf(""String_Node_Str""));
  PactRecord result=this.schema.jsonToRecord(object,null);
  PactRecord expected=new PactRecord();
  expected.setField(0,new JsonNodeWrapper(TextNode.valueOf(""String_Node_Str"")));
  expected.setField(1,new JsonNodeWrapper(TextNode.valueOf(""String_Node_Str"")));
  Assert.assertTrue(PactRecordEqualer.recordsEqual(expected,result,this.schema.getPactSchema()));
}","@Test public void shouldConvertFromJsonToRecord(){
  this.schema.setMappings(""String_Node_Str"",""String_Node_Str"");
  ObjectNode object=new ObjectNode();
  object.put(""String_Node_Str"",TextNode.valueOf(""String_Node_Str"")).put(""String_Node_Str"",TextNode.valueOf(""String_Node_Str""));
  PactRecord result=this.schema.jsonToRecord(object,null);
  PactRecord expected=new PactRecord();
  expected.setField(0,new JsonNodeWrapper(TextNode.valueOf(""String_Node_Str"")));
  expected.setField(1,new JsonNodeWrapper(TextNode.valueOf(""String_Node_Str"")));
  expected.setField(2,new JsonNodeWrapper(new ObjectNode()));
  Assert.assertTrue(PactRecordEqualer.recordsEqual(expected,result,this.schema.getPactSchema()));
}",0.9538690476190476
55574,"/** 
 * {@inheritDoc}
 */
@Override protected void implCloseChannel() throws IOException {
  getOutputStream().close();
}","/** 
 * {@inheritDoc}
 */
@Override protected void implCloseChannel() throws IOException {
  getOutputStream().close();
  if (this.inputStream != null) {
    this.inputStream.close();
    this.inputStream=null;
  }
}",0.7181008902077152
55575,"private void writeTransferEnvelope(final TransferEnvelope transferEnvelope) throws IOException, InterruptedException {
  final Buffer buffer=transferEnvelope.getBuffer();
  if (buffer != null) {
    if (buffer.isBackedByMemory()) {
      final Buffer fileBuffer=BufferFactory.createFromFile(buffer.size(),this.task.getVertexID(),this.fileBufferManager,this.distributed);
      buffer.copyToBuffer(fileBuffer);
      transferEnvelope.setBuffer(fileBuffer);
      buffer.recycleBuffer();
    }
  }
  if (this.numberOfSerializedTransferEnvelopes % ENVELOPES_PER_META_DATA_FILE == 0) {
    if (this.fileSystem == null) {
      this.fileSystem=this.checkpointPath.getFileSystem();
    }
    if (this.metaDataFileChannel != null) {
      this.metaDataFileChannel.close();
      this.metaDataFileChannel=null;
      renameCheckpointPart();
      ++this.metaDataSuffix;
    }
  }
  if (this.metaDataFileChannel == null) {
    this.metaDataFileChannel=getMetaDataFileChannel(""String_Node_Str"");
  }
  this.transferEnvelopeSerializer.setTransferEnvelope(transferEnvelope);
  while (this.transferEnvelopeSerializer.write(this.metaDataFileChannel)) {
  }
  final EventList eventList=transferEnvelope.getEventList();
  if (eventList != null) {
    final Iterator<AbstractEvent> it=eventList.iterator();
    while (it.hasNext()) {
      if (it.next() instanceof ByteBufferedChannelCloseEvent) {
        ++this.numberOfClosedChannels;
      }
    }
  }
  ++this.numberOfSerializedTransferEnvelopes;
  if (this.numberOfClosedChannels == this.numberOfConnectedChannels) {
    if (this.metaDataFileChannel != null) {
      this.metaDataFileChannel.close();
      renameCheckpointPart();
    }
    getMetaDataFileChannel(CheckpointUtils.COMPLETED_CHECKPOINT_SUFFIX).close();
    LOG.info(""String_Node_Str"" + this.task.getVertexID());
    this.task.checkpointStateChanged(CheckpointState.COMPLETE);
  }
}","private void writeTransferEnvelope(final TransferEnvelope transferEnvelope) throws IOException, InterruptedException {
  Buffer buffer=transferEnvelope.getBuffer();
  if (buffer != null) {
    if (buffer.isBackedByMemory()) {
      final Buffer fileBuffer=BufferFactory.createFromFile(buffer.size(),this.task.getVertexID(),this.fileBufferManager,this.distributed);
      buffer.copyToBuffer(fileBuffer);
      transferEnvelope.setBuffer(fileBuffer);
      buffer.recycleBuffer();
    }
  }
  if (this.numberOfSerializedTransferEnvelopes % ENVELOPES_PER_META_DATA_FILE == 0) {
    if (this.fileSystem == null) {
      this.fileSystem=this.checkpointPath.getFileSystem();
    }
    if (this.metaDataFileChannel != null) {
      this.metaDataFileChannel.close();
      this.metaDataFileChannel=null;
      renameCheckpointPart();
      ++this.metaDataSuffix;
    }
  }
  if (this.metaDataFileChannel == null) {
    this.metaDataFileChannel=getMetaDataFileChannel(""String_Node_Str"");
  }
  this.transferEnvelopeSerializer.setTransferEnvelope(transferEnvelope);
  while (this.transferEnvelopeSerializer.write(this.metaDataFileChannel)) {
  }
  buffer=transferEnvelope.getBuffer();
  if (buffer != null) {
    if (this.firstSerializedFileBuffer == null) {
      this.firstSerializedFileBuffer=buffer;
    }
 else {
      buffer.recycleBuffer();
    }
  }
  final EventList eventList=transferEnvelope.getEventList();
  if (eventList != null) {
    final Iterator<AbstractEvent> it=eventList.iterator();
    while (it.hasNext()) {
      if (it.next() instanceof ByteBufferedChannelCloseEvent) {
        ++this.numberOfClosedChannels;
      }
    }
  }
  ++this.numberOfSerializedTransferEnvelopes;
  if (this.numberOfClosedChannels == this.numberOfConnectedChannels) {
    if (this.firstSerializedFileBuffer != null) {
      this.firstSerializedFileBuffer.recycleBuffer();
    }
    if (this.metaDataFileChannel != null) {
      this.metaDataFileChannel.close();
      renameCheckpointPart();
    }
    getMetaDataFileChannel(CheckpointUtils.COMPLETED_CHECKPOINT_SUFFIX).close();
    LOG.info(""String_Node_Str"" + this.task.getVertexID());
    this.task.checkpointStateChanged(CheckpointState.COMPLETE);
  }
}",0.919686581782566
55576,"private void replayCheckpoint() throws Exception {
  System.out.println(""String_Node_Str"" + this.vertexID);
  final CheckpointDeserializer deserializer=new CheckpointDeserializer(this.vertexID);
  final Path checkpointPath=this.isCheckpointLocal ? CheckpointUtils.getLocalCheckpointPath() : CheckpointUtils.getDistributedCheckpointPath();
  if (checkpointPath == null) {
    throw new IOException(""String_Node_Str"" + this.vertexID);
  }
  final FileSystem fileSystem=checkpointPath.getFileSystem();
  int metaDataIndex=0;
  while (true) {
    if (this.restartRequested.compareAndSet(true,false)) {
      metaDataIndex=0;
    }
    final Path metaDataFile=checkpointPath.suffix(Path.SEPARATOR + CheckpointUtils.METADATA_PREFIX + ""String_Node_Str""+ this.vertexID+ ""String_Node_Str""+ metaDataIndex);
    while (!fileSystem.exists(metaDataFile)) {
      final Path finalMetaDataFile=checkpointPath.suffix(Path.SEPARATOR + CheckpointUtils.METADATA_PREFIX + ""String_Node_Str""+ this.vertexID+ ""String_Node_Str"");
      if (fileSystem.exists(finalMetaDataFile)) {
        return;
      }
      if (this.isCheckpointComplete) {
        throw new FileNotFoundException(""String_Node_Str"" + metaDataIndex + ""String_Node_Str""+ this.vertexID);
      }
      Thread.sleep(100);
    }
    FileChannel fileChannel=null;
    try {
      fileChannel=getFileChannel(fileSystem,metaDataFile);
      while (true) {
        try {
          deserializer.read(fileChannel);
          final TransferEnvelope transferEnvelope=deserializer.getFullyDeserializedTransferEnvelope();
          if (transferEnvelope != null) {
            final ReplayOutputBroker broker=this.outputBrokerMap.get(transferEnvelope.getSource());
            if (broker == null) {
              throw new IOException(""String_Node_Str"" + transferEnvelope.getSource());
            }
            final Buffer srcBuffer=transferEnvelope.getBuffer();
            if (srcBuffer != null) {
              final Buffer destBuffer=broker.requestEmptyBufferBlocking(srcBuffer.size());
              srcBuffer.copyToBuffer(destBuffer);
              transferEnvelope.setBuffer(destBuffer);
              srcBuffer.recycleBuffer();
            }
            broker.outputEnvelope(transferEnvelope);
          }
        }
 catch (        EOFException eof) {
          fileChannel.close();
          ++metaDataIndex;
          break;
        }
      }
    }
  finally {
      if (fileChannel != null) {
        fileChannel.close();
      }
    }
  }
}","private void replayCheckpoint() throws Exception {
  final CheckpointDeserializer deserializer=new CheckpointDeserializer(this.vertexID);
  final Path checkpointPath=this.isCheckpointLocal ? CheckpointUtils.getLocalCheckpointPath() : CheckpointUtils.getDistributedCheckpointPath();
  if (checkpointPath == null) {
    throw new IOException(""String_Node_Str"" + this.vertexID);
  }
  final FileSystem fileSystem=checkpointPath.getFileSystem();
  int metaDataIndex=0;
  while (true) {
    if (this.restartRequested.compareAndSet(true,false)) {
      metaDataIndex=0;
    }
    final Path metaDataFile=checkpointPath.suffix(Path.SEPARATOR + CheckpointUtils.METADATA_PREFIX + ""String_Node_Str""+ this.vertexID+ ""String_Node_Str""+ metaDataIndex);
    while (!fileSystem.exists(metaDataFile)) {
      final Path finalMetaDataFile=checkpointPath.suffix(Path.SEPARATOR + CheckpointUtils.METADATA_PREFIX + ""String_Node_Str""+ this.vertexID+ ""String_Node_Str"");
      if (fileSystem.exists(finalMetaDataFile)) {
        return;
      }
      if (this.isCheckpointComplete) {
        throw new FileNotFoundException(""String_Node_Str"" + metaDataIndex + ""String_Node_Str""+ this.vertexID);
      }
      Thread.sleep(100);
    }
    FileChannel fileChannel=null;
    try {
      fileChannel=getFileChannel(fileSystem,metaDataFile);
      while (true) {
        try {
          deserializer.read(fileChannel);
          final TransferEnvelope transferEnvelope=deserializer.getFullyDeserializedTransferEnvelope();
          if (transferEnvelope != null) {
            final ReplayOutputBroker broker=this.outputBrokerMap.get(transferEnvelope.getSource());
            if (broker == null) {
              throw new IOException(""String_Node_Str"" + transferEnvelope.getSource());
            }
            final Buffer srcBuffer=transferEnvelope.getBuffer();
            if (srcBuffer != null) {
              final Buffer destBuffer=broker.requestEmptyBufferBlocking(srcBuffer.size());
              srcBuffer.copyToBuffer(destBuffer);
              transferEnvelope.setBuffer(destBuffer);
              srcBuffer.recycleBuffer();
            }
            broker.outputEnvelope(transferEnvelope);
          }
        }
 catch (        EOFException eof) {
          fileChannel.close();
          ++metaDataIndex;
          break;
        }
      }
    }
  finally {
      if (fileChannel != null) {
        fileChannel.close();
      }
    }
  }
}",0.9883934025656688
55577,"@Override public boolean equals(Object obj){
  if (this == obj) {
    return true;
  }
 else   if (obj == null) {
    return false;
  }
 else   if (getClass() != obj.getClass()) {
    return false;
  }
  GlobalProperties other=(GlobalProperties)obj;
  if ((ordering == other.getOrdering() || (ordering != null && ordering.equals(other.getOrdering()))) && partitioning == other.getPartitioning() && partitionedFields.equals(other.getPartitionedFields())) {
    return true;
  }
 else {
    return false;
  }
}","@Override public boolean equals(Object obj){
  if (this == obj) {
    return true;
  }
 else   if (obj == null) {
    return false;
  }
 else   if (getClass() != obj.getClass()) {
    return false;
  }
  GlobalProperties other=(GlobalProperties)obj;
  if ((ordering == other.getOrdering() || (ordering != null && ordering.equals(other.getOrdering()))) && partitioning == other.getPartitioning() && partitionedFields != null && partitionedFields.equals(other.getPartitionedFields())) {
    return true;
  }
 else {
    return false;
  }
}",0.9722488038277513
55578,"@Override public void run() throws Exception {
  final MutableObjectIterator<PactRecord> input=this.inputs[0];
  final MapStub stub=this.stub;
  final Collector output=this.output;
  final PactRecord record=new PactRecord();
  int count=0;
  long consumedPactRecordsInBytes=0L;
  final Environment env=getEnvironment();
  final OutputCollector oc=(OutputCollector)output;
  if (this.stub.getClass().isAnnotationPresent(ForceCheckpoint.class)) {
    env.isForced(this.stub.getClass().getAnnotation(ForceCheckpoint.class).checkpoint());
  }
  while (this.running && input.next(record)) {
    consumedPactRecordsInBytes=+record.getBinaryLength();
    stub.map(record,output);
    if (++count == 10) {
      env.reportPACTDataStatistics(consumedPactRecordsInBytes,oc.getCollectedPactRecordsInBytes());
      consumedPactRecordsInBytes=0L;
      count=0;
    }
  }
}","@Override public void run() throws Exception {
  final MutableObjectIterator<PactRecord> input=this.inputs[0];
  final MapStub stub=this.stub;
  final Collector output=this.output;
  final PactRecord record=new PactRecord();
  int count=0;
  long consumedPactRecordsInBytes=0L;
  final Environment env=getEnvironment();
  final OutputCollector oc=(OutputCollector)output;
  if (this.stub.getClass().isAnnotationPresent(ForceCheckpoint.class)) {
    env.isForced(this.stub.getClass().getAnnotation(ForceCheckpoint.class).checkpoint());
  }
  while (this.running && input.next(record)) {
    consumedPactRecordsInBytes+=record.getBinaryLength();
    stub.map(record,output);
    if (++count == 10) {
      env.reportPACTDataStatistics(consumedPactRecordsInBytes,oc.getCollectedPactRecordsInBytes());
      consumedPactRecordsInBytes=0L;
      count=0;
    }
  }
}",0.9988385598141696
55579,"/** 
 * Filters these properties by what can be preserved through the given output contract.
 * @param contract The output contract.
 * @return True, if any non-default value is preserved, false otherwise.
 */
public boolean filterByNodesConstantSet(OptimizerNode node,int input){
  if (ordering != null) {
    ArrayList<Integer> involvedIndexes=ordering.getInvolvedIndexes();
    for (int i=0; i < involvedIndexes.size(); i++) {
      if (node.isFieldKept(input,i) == false) {
        ordering=ordering.createNewOrderingUpToIndex(i);
        break;
      }
    }
  }
  if (this.groupedFields != null) {
    for (    Integer index : this.groupedFields) {
      if (node.isFieldKept(input,index) == false) {
        this.groupedFields=null;
        this.grouped=false;
        break;
      }
    }
  }
 else {
    this.grouped=false;
  }
  return !isTrivial();
}","/** 
 * Filters these properties by what can be preserved through the given output contract.
 * @param contract The output contract.
 * @return True, if any non-default value is preserved, false otherwise.
 */
public boolean filterByNodesConstantSet(OptimizerNode node,int input){
  if (ordering != null) {
    ArrayList<Integer> involvedIndexes=ordering.getInvolvedIndexes();
    for (int i=0; i < involvedIndexes.size(); i++) {
      if (node.isFieldKept(input,involvedIndexes.get(i)) == false) {
        ordering=ordering.createNewOrderingUpToIndex(i);
        break;
      }
    }
  }
  if (this.groupedFields != null) {
    for (    Integer index : this.groupedFields) {
      if (node.isFieldKept(input,index) == false) {
        this.groupedFields=null;
        this.grouped=false;
        break;
      }
    }
  }
 else {
    this.grouped=false;
  }
  return !isTrivial();
}",0.9879518072289156
55580,"private static boolean isNetworkTask(final RuntimeTask task){
  final RuntimeEnvironment environment=task.getRuntimeEnvironment();
  for (int i=0; i < environment.getNumberOfOutputGates(); ++i) {
    if (environment.getOutputGate(i).getChannelType() == ChannelType.NETWORK) {
      return true;
    }
  }
  return false;
}","private static boolean isNetworkTask(final RuntimeTask task){
  final RuntimeEnvironment environment=task.getRuntimeEnvironment();
  for (int i=0; i < environment.getNumberOfOutputGates(); ++i) {
    if (environment.getOutputGate(i).getChannelType() == ChannelType.NETWORK) {
      LOG.info(environment.getTaskNameWithIndex() + ""String_Node_Str"");
      return true;
    }
  }
  return false;
}",0.8994413407821229
55581,"public static CheckpointMode getCheckpointMode(){
  if (CHECKPOINT_MODE == null) {
    final String mode=GlobalConfiguration.getString(""String_Node_Str"",""String_Node_Str"").toLowerCase();
    if (""String_Node_Str"".equals(mode)) {
      CHECKPOINT_MODE=CheckpointMode.ALWAYS;
    }
 else     if (""String_Node_Str"".equals(mode)) {
      CHECKPOINT_MODE=CheckpointMode.NETWORK;
    }
 else     if (""String_Node_Str"".equals(mode)) {
      CHECKPOINT_MODE=CheckpointMode.DYNAMIC;
    }
 else {
      CHECKPOINT_MODE=CheckpointMode.NETWORK;
    }
  }
  return CHECKPOINT_MODE;
}","public static CheckpointMode getCheckpointMode(){
  if (CHECKPOINT_MODE == null) {
    final String mode=GlobalConfiguration.getString(""String_Node_Str"",""String_Node_Str"").toLowerCase();
    if (""String_Node_Str"".equals(mode)) {
      CHECKPOINT_MODE=CheckpointMode.ALWAYS;
    }
 else     if (""String_Node_Str"".equals(mode)) {
      CHECKPOINT_MODE=CheckpointMode.NETWORK;
    }
 else     if (""String_Node_Str"".equals(mode)) {
      CHECKPOINT_MODE=CheckpointMode.DYNAMIC;
    }
 else {
      CHECKPOINT_MODE=CheckpointMode.NEVER;
    }
  }
  return CHECKPOINT_MODE;
}",0.9947368421052633
55582,"void finish(){
synchronized (this) {
    writeAnnouncedEnvelopesBufferToDisk();
  }
}","void finish(){
synchronized (this) {
    if (this.announcedEnvelopesAsIntBuffer.position() == 0) {
      return;
    }
  }
  final EnvelopeConsumptionLog lock=this;
  final Thread finisherThread=new Thread(""String_Node_Str"" + this.environment.getTaskNameWithIndex()){
    /** 
 * {@inheritDoc}
 */
    @Override public void run(){
synchronized (lock) {
        writeAnnouncedEnvelopesBufferToDisk();
      }
    }
  }
;
  finisherThread.start();
  boolean regularExit=false;
  while (!regularExit) {
    try {
      finisherThread.join();
      regularExit=true;
    }
 catch (    InterruptedException ie) {
    }
  }
}",0.2329545454545454
55583,"/** 
 * {@inheritDoc}
 */
@Override public boolean isInputChannel(){
  return true;
}","/** 
 * {@inheritDoc}
 */
@Override public boolean isInputChannel(){
  return false;
}",0.95906432748538
55584,"/** 
 * {@inheritDoc}
 */
@Override public void killInstance(final StringRecord instanceName) throws IOException {
  final AbstractInstance instance=this.instanceManager.getInstanceByName(instanceName.toString());
  if (instance == null) {
    LOG.error(""String_Node_Str"" + instanceName + ""String_Node_Str"");
  }
  LOG.info(""String_Node_Str"" + instance);
  final Runnable runnable=new Runnable(){
    @Override public void run(){
      try {
        instance.killTaskManager();
      }
 catch (      IOException ioe) {
        LOG.error(StringUtils.stringifyException(ioe));
      }
    }
  }
;
  this.executorService.execute(runnable);
}","/** 
 * {@inheritDoc}
 */
@Override public void killInstance(final StringRecord instanceName) throws IOException {
  final AbstractInstance instance=this.instanceManager.getInstanceByName(instanceName.toString());
  if (instance == null) {
    LOG.error(""String_Node_Str"" + instanceName + ""String_Node_Str"");
    return;
  }
  LOG.info(""String_Node_Str"" + instance);
  final Runnable runnable=new Runnable(){
    @Override public void run(){
      try {
        instance.killTaskManager();
      }
 catch (      IOException ioe) {
        LOG.error(StringUtils.stringifyException(ioe));
      }
    }
  }
;
  this.executorService.execute(runnable);
}",0.9906832298136646
55585,"@Override public boolean callWithNextKey(MatchStub matchFunction,Collector collector) throws Exception {
  final OutputCollector oc=(OutputCollector)collector;
  if (this.hashJoin.nextRecord()) {
    final HashJoin.HashBucketIterator buildSideIterator=this.hashJoin.getBuildSideIterator();
    PactRecord probeRecord=this.hashJoin.getCurrentProbeRecord();
    PactRecord nextBuildSidePair=this.nextBuildSideObject;
    if (buildSideIterator.next(nextBuildSidePair)) {
      PactRecord tmpPair=new PactRecord();
      if (buildSideIterator.next(tmpPair)) {
        probeRecord.copyTo(this.probeCopy);
        long r1=nextBuildSidePair.getBinaryLength();
        long r2=probeRecord.getBinaryLength();
        matchFunction.match(nextBuildSidePair,probeRecord,collector);
        this.environment.reportPACTDataStatistics(r1 + r2,oc.getCollectedPactRecordsInBytes());
        probeRecord=new PactRecord();
        this.probeCopy.copyTo(probeRecord);
        r1=tmpPair.getBinaryLength();
        r2=probeRecord.getBinaryLength();
        matchFunction.match(tmpPair,probeRecord,collector);
        this.environment.reportPACTDataStatistics(r1 + r2,oc.getCollectedPactRecordsInBytes());
        tmpPair=new PactRecord();
        while (this.running && buildSideIterator.next(tmpPair)) {
          probeRecord=new PactRecord();
          this.probeCopy.copyTo(probeRecord);
          r1=tmpPair.getBinaryLength();
          r2=probeRecord.getBinaryLength();
          matchFunction.match(tmpPair,probeRecord,collector);
          this.environment.reportPACTDataStatistics(r1 + r2,oc.getCollectedPactRecordsInBytes());
          tmpPair=new PactRecord();
        }
        this.nextBuildSideObject=tmpPair;
      }
 else {
        this.nextBuildSideObject=tmpPair;
        final long r1=nextBuildSidePair.getBinaryLength();
        final long r2=probeRecord.getBinaryLength();
        matchFunction.match(nextBuildSidePair,probeRecord,collector);
        this.environment.reportPACTDataStatistics(r1 + r2,oc.getCollectedPactRecordsInBytes());
      }
    }
    return true;
  }
 else {
    return false;
  }
}","@Override public boolean callWithNextKey(MatchStub matchFunction,Collector collector) throws Exception {
  if (this.hashJoin.nextRecord()) {
    final HashJoin.HashBucketIterator buildSideIterator=this.hashJoin.getBuildSideIterator();
    PactRecord probeRecord=this.hashJoin.getCurrentProbeRecord();
    PactRecord nextBuildSidePair=this.nextBuildSideObject;
    if (buildSideIterator.next(nextBuildSidePair)) {
      PactRecord tmpPair=new PactRecord();
      if (buildSideIterator.next(tmpPair)) {
        probeRecord.copyTo(this.probeCopy);
        long r1=nextBuildSidePair.getBinaryLength();
        long r2=probeRecord.getBinaryLength();
        matchFunction.match(nextBuildSidePair,probeRecord,collector);
        this.environment.reportPACTDataStatistics(r1 + r2,collector.getCollectedPactRecordsInBytes());
        probeRecord=new PactRecord();
        this.probeCopy.copyTo(probeRecord);
        r1=tmpPair.getBinaryLength();
        r2=probeRecord.getBinaryLength();
        matchFunction.match(tmpPair,probeRecord,collector);
        this.environment.reportPACTDataStatistics(r1 + r2,collector.getCollectedPactRecordsInBytes());
        tmpPair=new PactRecord();
        while (this.running && buildSideIterator.next(tmpPair)) {
          probeRecord=new PactRecord();
          this.probeCopy.copyTo(probeRecord);
          r1=tmpPair.getBinaryLength();
          r2=probeRecord.getBinaryLength();
          matchFunction.match(tmpPair,probeRecord,collector);
          this.environment.reportPACTDataStatistics(r1 + r2,collector.getCollectedPactRecordsInBytes());
          tmpPair=new PactRecord();
        }
        this.nextBuildSideObject=tmpPair;
      }
 else {
        this.nextBuildSideObject=tmpPair;
        final long r1=nextBuildSidePair.getBinaryLength();
        final long r2=probeRecord.getBinaryLength();
        matchFunction.match(nextBuildSidePair,probeRecord,collector);
        this.environment.reportPACTDataStatistics(r1 + r2,collector.getCollectedPactRecordsInBytes());
      }
    }
    return true;
  }
 else {
    return false;
  }
}",0.9763214541975604
55586,"@Override public boolean callWithNextKey(MatchStub matchFunction,Collector collector) throws Exception {
  final Environment env=this.environment;
  final OutputCollector oc=(OutputCollector)collector;
  if (this.hashJoin.nextRecord()) {
    final HashJoin.HashBucketIterator buildSideIterator=this.hashJoin.getBuildSideIterator();
    PactRecord probeRecord=this.hashJoin.getCurrentProbeRecord();
    PactRecord nextBuildSidePair=this.nextBuildSideObject;
    if (buildSideIterator.next(nextBuildSidePair)) {
      PactRecord tmpPair=new PactRecord();
      if (buildSideIterator.next(tmpPair)) {
        probeRecord.copyTo(this.probeCopy);
        long r1=probeRecord.getBinaryLength();
        long r2=nextBuildSidePair.getBinaryLength();
        matchFunction.match(probeRecord,nextBuildSidePair,collector);
        env.reportPACTDataStatistics(r1 + r2,oc.getCollectedPactRecordsInBytes());
        probeRecord=new PactRecord();
        this.probeCopy.copyTo(probeRecord);
        r1=probeRecord.getBinaryLength();
        r2=tmpPair.getBinaryLength();
        matchFunction.match(probeRecord,tmpPair,collector);
        env.reportPACTDataStatistics(r1 + r2,oc.getCollectedPactRecordsInBytes());
        tmpPair=new PactRecord();
        while (this.running && buildSideIterator.next(tmpPair)) {
          probeRecord=new PactRecord();
          this.probeCopy.copyTo(probeRecord);
          r1=probeRecord.getBinaryLength();
          r2=tmpPair.getBinaryLength();
          matchFunction.match(probeRecord,tmpPair,collector);
          env.reportPACTDataStatistics(r1 + r2,oc.getCollectedPactRecordsInBytes());
          tmpPair=new PactRecord();
        }
        this.nextBuildSideObject=tmpPair;
      }
 else {
        this.nextBuildSideObject=tmpPair;
        final long r1=probeRecord.getBinaryLength();
        final long r2=nextBuildSidePair.getBinaryLength();
        matchFunction.match(probeRecord,nextBuildSidePair,collector);
        env.reportPACTDataStatistics(r1 + r2,oc.getCollectedPactRecordsInBytes());
      }
    }
    return true;
  }
 else {
    return false;
  }
}","@Override public boolean callWithNextKey(MatchStub matchFunction,Collector collector) throws Exception {
  final Environment env=this.environment;
  if (this.hashJoin.nextRecord()) {
    final HashJoin.HashBucketIterator buildSideIterator=this.hashJoin.getBuildSideIterator();
    PactRecord probeRecord=this.hashJoin.getCurrentProbeRecord();
    PactRecord nextBuildSidePair=this.nextBuildSideObject;
    if (buildSideIterator.next(nextBuildSidePair)) {
      PactRecord tmpPair=new PactRecord();
      if (buildSideIterator.next(tmpPair)) {
        probeRecord.copyTo(this.probeCopy);
        long r1=probeRecord.getBinaryLength();
        long r2=nextBuildSidePair.getBinaryLength();
        matchFunction.match(probeRecord,nextBuildSidePair,collector);
        env.reportPACTDataStatistics(r1 + r2,collector.getCollectedPactRecordsInBytes());
        probeRecord=new PactRecord();
        this.probeCopy.copyTo(probeRecord);
        r1=probeRecord.getBinaryLength();
        r2=tmpPair.getBinaryLength();
        matchFunction.match(probeRecord,tmpPair,collector);
        env.reportPACTDataStatistics(r1 + r2,collector.getCollectedPactRecordsInBytes());
        tmpPair=new PactRecord();
        while (this.running && buildSideIterator.next(tmpPair)) {
          probeRecord=new PactRecord();
          this.probeCopy.copyTo(probeRecord);
          r1=probeRecord.getBinaryLength();
          r2=tmpPair.getBinaryLength();
          matchFunction.match(probeRecord,tmpPair,collector);
          env.reportPACTDataStatistics(r1 + r2,collector.getCollectedPactRecordsInBytes());
          tmpPair=new PactRecord();
        }
        this.nextBuildSideObject=tmpPair;
      }
 else {
        this.nextBuildSideObject=tmpPair;
        final long r1=probeRecord.getBinaryLength();
        final long r2=nextBuildSidePair.getBinaryLength();
        matchFunction.match(probeRecord,nextBuildSidePair,collector);
        env.reportPACTDataStatistics(r1 + r2,collector.getCollectedPactRecordsInBytes());
      }
    }
    return true;
  }
 else {
    return false;
  }
}",0.9762076423936552
55587,"@Override public void collect(PactRecord record){
  this.list.add(record.createCopy());
}","@Override public void collect(PactRecord record){
  this.collectedPactRecordsInBytes+=record.getBinaryLength();
  this.list.add(record.createCopy());
}",0.7416666666666667
55588,"@Override public void collect(PactRecord record){
  try {
    if (this.spillingInThisBuffer) {
      if (this.currentBuffer.write(record)) {
        if (this.bytesUntilSpilling - this.currentBuffer.getOccupancy() <= 0) {
          this.bytesUntilSpilling=0;
          this.queues.sort.add(SPILLING_MARKER);
        }
        return;
      }
    }
 else {
      if (this.currentBuffer.write(record))       return;
    }
    if (this.bytesUntilSpilling > 0) {
      this.bytesUntilSpilling-=this.currentBuffer.getCapacity();
      if (this.bytesUntilSpilling <= 0) {
        this.bytesUntilSpilling=0;
        this.queues.sort.add(SPILLING_MARKER);
      }
    }
    if (LOG.isDebugEnabled()) {
      LOG.debug(""String_Node_Str"" + this.currentElement.id + ""String_Node_Str"");
    }
    this.queues.sort.add(this.currentElement);
    this.currentElement=null;
    while (this.running && this.currentElement == null) {
      try {
        this.currentElement=this.queues.empty.take();
      }
 catch (      InterruptedException iex) {
        if (this.running) {
          LOG.error(""String_Node_Str"" + ""String_Node_Str"");
        }
 else {
          return;
        }
      }
    }
    if (!this.running)     return;
    this.currentBuffer=this.currentElement.buffer;
    if (!this.currentBuffer.isEmpty()) {
      throw new RuntimeException(""String_Node_Str"");
    }
    if (LOG.isDebugEnabled()) {
      LOG.debug(""String_Node_Str"" + this.currentElement.id + ""String_Node_Str"");
    }
    if (!this.currentBuffer.write(record)) {
      throw new RuntimeException(""String_Node_Str"");
    }
  }
 catch (  IOException ioex) {
    throw new RuntimeException(""String_Node_Str"" + ioex.getMessage(),ioex);
  }
}","@Override public void collect(PactRecord record){
  this.collectedPactRecordsInBytes+=record.getBinaryLength();
  try {
    if (this.spillingInThisBuffer) {
      if (this.currentBuffer.write(record)) {
        if (this.bytesUntilSpilling - this.currentBuffer.getOccupancy() <= 0) {
          this.bytesUntilSpilling=0;
          this.queues.sort.add(SPILLING_MARKER);
        }
        return;
      }
    }
 else {
      if (this.currentBuffer.write(record))       return;
    }
    if (this.bytesUntilSpilling > 0) {
      this.bytesUntilSpilling-=this.currentBuffer.getCapacity();
      if (this.bytesUntilSpilling <= 0) {
        this.bytesUntilSpilling=0;
        this.queues.sort.add(SPILLING_MARKER);
      }
    }
    if (LOG.isDebugEnabled()) {
      LOG.debug(""String_Node_Str"" + this.currentElement.id + ""String_Node_Str"");
    }
    this.queues.sort.add(this.currentElement);
    this.currentElement=null;
    while (this.running && this.currentElement == null) {
      try {
        this.currentElement=this.queues.empty.take();
      }
 catch (      InterruptedException iex) {
        if (this.running) {
          LOG.error(""String_Node_Str"" + ""String_Node_Str"");
        }
 else {
          return;
        }
      }
    }
    if (!this.running)     return;
    this.currentBuffer=this.currentElement.buffer;
    if (!this.currentBuffer.isEmpty()) {
      throw new RuntimeException(""String_Node_Str"");
    }
    if (LOG.isDebugEnabled()) {
      LOG.debug(""String_Node_Str"" + this.currentElement.id + ""String_Node_Str"");
    }
    if (!this.currentBuffer.write(record)) {
      throw new RuntimeException(""String_Node_Str"");
    }
  }
 catch (  IOException ioex) {
    throw new RuntimeException(""String_Node_Str"" + ioex.getMessage(),ioex);
  }
}",0.9821222606689736
55589,"@Override public void collect(PactRecord record){
  if (this.exception != null)   throw new RuntimeException(""String_Node_Str"",this.exception.getCause() == null ? this.exception : this.exception.getCause());
  this.inputCollector.collect(record);
}","@Override public void collect(PactRecord record){
  this.collectedPactRecordsInBytes+=record.getBinaryLength();
  if (this.exception != null)   throw new RuntimeException(""String_Node_Str"",this.exception.getCause() == null ? this.exception : this.exception.getCause());
  this.inputCollector.collect(record);
}",0.8888888888888888
55590,"@Override public void collect(PactRecord record){
  try {
    this.consumedPactRecordsInBytes+=record.getBinaryLength();
    this.mapper.map(record,this.collector);
    if (++this.count == 10) {
      parent.getEnvironment().reportPACTDataStatistics(this.consumedPactRecordsInBytes,((OutputCollector)this.collector).getCollectedPactRecordsInBytes());
      this.consumedPactRecordsInBytes=0L;
      this.count=0;
    }
  }
 catch (  Exception ex) {
    throw new ExceptionInChainedStubException(this.taskName,ex);
  }
}","@Override public void collect(PactRecord record){
  final int recordLength=record.getBinaryLength();
  this.collectedPactRecordsInBytes+=recordLength;
  try {
    this.consumedPactRecordsInBytes+=recordLength;
    this.mapper.map(record,this.collector);
    if (++this.count == 10) {
      parent.getEnvironment().reportPACTDataStatistics(this.consumedPactRecordsInBytes,((OutputCollector)this.collector).getCollectedPactRecordsInBytes());
      this.consumedPactRecordsInBytes=0L;
      this.count=0;
    }
  }
 catch (  Exception ex) {
    throw new ExceptionInChainedStubException(this.taskName,ex);
  }
}",0.8713398402839396
55591,"private void processEnvelopeWithBuffer(final TransferEnvelope transferEnvelope,final TransferEnvelopeReceiverList receiverList,final boolean freeSourceBuffer){
  if (!freeSourceBuffer) {
    final List<ChannelID> localReceivers=receiverList.getLocalReceivers();
    if (localReceivers.size() != 1) {
      LOG.error(""String_Node_Str"");
    }
    final ChannelID localReceiver=localReceivers.get(0);
    final ChannelContext cc=this.registeredChannels.get(localReceiver);
    if (cc == null) {
      sendReceiverNotFoundEvent(transferEnvelope,localReceiver);
      recycleBuffer(transferEnvelope);
      return;
    }
    if (!cc.isInputChannel()) {
      LOG.error(""String_Node_Str"" + localReceiver + ""String_Node_Str"");
    }
    cc.queueTransferEnvelope(transferEnvelope);
    return;
  }
  final Buffer srcBuffer=transferEnvelope.getBuffer();
  if (receiverList.hasLocalReceivers()) {
    final List<ChannelID> localReceivers=receiverList.getLocalReceivers();
    for (    final ChannelID localReceiver : localReceivers) {
      final ChannelContext cc=this.registeredChannels.get(localReceiver);
      if (cc == null) {
        sendReceiverNotFoundEvent(transferEnvelope,localReceiver);
        continue;
      }
      if (!cc.isInputChannel()) {
        LOG.error(""String_Node_Str"" + localReceiver + ""String_Node_Str"");
        continue;
      }
      final InputChannelContext inputChannelContext=(InputChannelContext)cc;
      Buffer destBuffer=null;
      try {
        destBuffer=inputChannelContext.requestEmptyBufferBlocking(srcBuffer.size());
        srcBuffer.copyToBuffer(destBuffer);
      }
 catch (      Exception e) {
        LOG.error(StringUtils.stringifyException(e));
        if (destBuffer != null) {
          destBuffer.recycleBuffer();
        }
        continue;
      }
      final TransferEnvelope dup=transferEnvelope.duplicateWithoutBuffer();
      dup.setBuffer(destBuffer);
      inputChannelContext.queueTransferEnvelope(dup);
    }
  }
  if (receiverList.hasRemoteReceivers()) {
    final List<InetSocketAddress> remoteReceivers=receiverList.getRemoteReceivers();
    for (    final InetSocketAddress remoteReceiver : remoteReceivers) {
      TransferEnvelope dup=null;
      try {
        dup=transferEnvelope.duplicate();
      }
 catch (      Exception e) {
        LOG.error(StringUtils.stringifyException(e));
        if (dup != null) {
          recycleBuffer(dup);
          continue;
        }
      }
      this.networkConnectionManager.queueEnvelopeForTransfer(remoteReceiver,dup);
    }
  }
  srcBuffer.recycleBuffer();
}","private void processEnvelopeWithBuffer(final TransferEnvelope transferEnvelope,final TransferEnvelopeReceiverList receiverList,final boolean freeSourceBuffer){
  if (!freeSourceBuffer) {
    final List<ChannelID> localReceivers=receiverList.getLocalReceivers();
    if (localReceivers.size() != 1) {
      LOG.error(""String_Node_Str"");
    }
    final ChannelID localReceiver=localReceivers.get(0);
    final ChannelContext cc=this.registeredChannels.get(localReceiver);
    if (cc == null) {
      sendReceiverNotFoundEvent(transferEnvelope,localReceiver);
      recycleBuffer(transferEnvelope);
      return;
    }
    if (!cc.isInputChannel()) {
      LOG.error(""String_Node_Str"" + localReceiver + ""String_Node_Str"");
    }
    cc.queueTransferEnvelope(transferEnvelope);
    return;
  }
  final Buffer srcBuffer=transferEnvelope.getBuffer();
  if (receiverList.hasLocalReceivers()) {
    final List<ChannelID> localReceivers=receiverList.getLocalReceivers();
    for (    final ChannelID localReceiver : localReceivers) {
      final ChannelContext cc=this.registeredChannels.get(localReceiver);
      if (cc == null) {
        sendReceiverNotFoundEvent(transferEnvelope,localReceiver);
        continue;
      }
      if (!cc.isInputChannel()) {
        LOG.error(""String_Node_Str"" + localReceiver + ""String_Node_Str"");
        continue;
      }
      final InputChannelContext inputChannelContext=(InputChannelContext)cc;
      if (srcBuffer.isBackedByMemory()) {
        Buffer destBuffer=null;
        try {
          destBuffer=inputChannelContext.requestEmptyBufferBlocking(srcBuffer.size());
          srcBuffer.copyToBuffer(destBuffer);
        }
 catch (        Exception e) {
          LOG.error(StringUtils.stringifyException(e));
          if (destBuffer != null) {
            destBuffer.recycleBuffer();
          }
          continue;
        }
        final TransferEnvelope dup=transferEnvelope.duplicateWithoutBuffer();
        dup.setBuffer(destBuffer);
        inputChannelContext.queueTransferEnvelope(dup);
      }
 else {
        TransferEnvelope dup=null;
        try {
          dup=transferEnvelope.duplicate();
        }
 catch (        Exception e) {
          LOG.error(StringUtils.stringifyException(e));
          continue;
        }
        inputChannelContext.queueTransferEnvelope(dup);
      }
    }
  }
  if (receiverList.hasRemoteReceivers()) {
    final List<InetSocketAddress> remoteReceivers=receiverList.getRemoteReceivers();
    for (    final InetSocketAddress remoteReceiver : remoteReceivers) {
      TransferEnvelope dup=null;
      try {
        dup=transferEnvelope.duplicate();
      }
 catch (      Exception e) {
        LOG.error(StringUtils.stringifyException(e));
        if (dup != null) {
          recycleBuffer(dup);
          continue;
        }
      }
      this.networkConnectionManager.queueEnvelopeForTransfer(remoteReceiver,dup);
    }
  }
  srcBuffer.recycleBuffer();
}",0.8172902288412641
55592,"@Override public FileBaseStatistics getStatistics(BaseStatistics cachedStatistics){
  FileBaseStatistics stats=null;
  if (cachedStatistics != null && cachedStatistics instanceof FileBaseStatistics) {
    stats=(FileBaseStatistics)cachedStatistics;
  }
 else {
    stats=new FileBaseStatistics(-1,BaseStatistics.UNKNOWN,BaseStatistics.UNKNOWN);
  }
  try {
    final Path file=this.filePath;
    final URI uri=file.toUri();
    final FileSystem fs=FileSystem.get(uri);
    List<FileStatus> files=null;
{
      FileStatus status=fs.getFileStatus(file);
      if (status.isDir()) {
        FileStatus[] fss=fs.listStatus(file);
        files=new ArrayList<FileStatus>(fss.length);
        boolean unmodified=true;
        for (        FileStatus s : fss) {
          if (!s.isDir()) {
            files.add(s);
            if (s.getModificationTime() > stats.getLastModificationTime()) {
              stats.setFileModTime(s.getModificationTime());
              unmodified=false;
            }
          }
        }
        if (unmodified) {
          return stats;
        }
      }
 else {
        long modTime=status.getModificationTime();
        if (stats.getLastModificationTime() == modTime) {
          return stats;
        }
        stats.setFileModTime(modTime);
        files=new ArrayList<FileStatus>(1);
        files.add(status);
      }
    }
    stats.setAvgBytesPerRecord(-1.0f);
    stats.setFileSize(0);
    for (    FileStatus s : files) {
      stats.setFileSize(s.getLen());
    }
    if (stats.getTotalInputSize() <= 0) {
      stats.setFileSize(BaseStatistics.UNKNOWN);
      return stats;
    }
    final byte[] delimiter=getDelimiter();
    if (!((delimiter.length == 1 && delimiter[0] == '\n') || (delimiter.length == 2 && delimiter[0] == '\r' && delimiter[1] == '\n'))) {
      return stats;
    }
    int numSamples=Math.min(this.numLineSamples,(int)(stats.getTotalInputSize() / 1024));
    if (numSamples < 2) {
      numSamples=2;
    }
    long offset=0;
    long bytes=0;
    long stepSize=stats.getTotalInputSize() / numSamples;
    int fileNum=0;
    int samplesTaken=0;
    for (int sampleNum=0; sampleNum < numSamples && fileNum < files.size(); sampleNum++) {
      FileStatus currentFile=files.get(fileNum);
      FSDataInputStream inStream=null;
      try {
        inStream=fs.open(currentFile.getPath());
        LineReader lineReader=new LineReader(inStream,offset,currentFile.getLen() - offset,1024);
        byte[] line=lineReader.readLine();
        lineReader.close();
        if (line != null && line.length > 0) {
          samplesTaken++;
          bytes+=line.length + 1;
        }
      }
  finally {
        if (inStream != null) {
          try {
            inStream.close();
          }
 catch (          Throwable t) {
          }
        }
      }
      offset+=stepSize;
      while (fileNum < files.size() && offset >= (currentFile=files.get(fileNum)).getLen()) {
        offset-=currentFile.getLen();
        fileNum++;
      }
    }
    stats.setAvgBytesPerRecord(bytes / (float)samplesTaken);
  }
 catch (  IOException ioex) {
    if (LOG.isWarnEnabled())     LOG.warn(""String_Node_Str"" + filePath + ""String_Node_Str""+ ioex.getMessage());
  }
catch (  Throwable t) {
    if (LOG.isErrorEnabled())     LOG.error(""String_Node_Str"" + filePath + ""String_Node_Str""+ t.getMessage(),t);
  }
  return stats;
}","@Override public FileBaseStatistics getStatistics(BaseStatistics cachedStatistics){
  FileBaseStatistics stats=null;
  if (cachedStatistics != null && cachedStatistics instanceof FileBaseStatistics) {
    stats=(FileBaseStatistics)cachedStatistics;
  }
 else {
    stats=new FileBaseStatistics(-1,BaseStatistics.UNKNOWN,BaseStatistics.UNKNOWN);
  }
  try {
    final Path file=this.filePath;
    final URI uri=file.toUri();
    final FileSystem fs=FileSystem.get(uri);
    List<FileStatus> files=null;
{
      FileStatus status=fs.getFileStatus(file);
      if (status.isDir()) {
        FileStatus[] fss=fs.listStatus(file);
        files=new ArrayList<FileStatus>(fss.length);
        boolean unmodified=true;
        for (        FileStatus s : fss) {
          if (!s.isDir()) {
            files.add(s);
            if (s.getModificationTime() > stats.getLastModificationTime()) {
              stats.setFileModTime(s.getModificationTime());
              unmodified=false;
            }
          }
        }
        if (unmodified) {
          return stats;
        }
      }
 else {
        long modTime=status.getModificationTime();
        if (stats.getLastModificationTime() == modTime) {
          return stats;
        }
        stats.setFileModTime(modTime);
        files=new ArrayList<FileStatus>(1);
        files.add(status);
      }
    }
    stats.setAvgBytesPerRecord(-1.0f);
    stats.setFileSize(0);
    long totalInputSize=0;
    for (    FileStatus s : files) {
      totalInputSize+=s.getLen();
    }
    stats.setFileSize(totalInputSize);
    if (stats.getTotalInputSize() <= 0) {
      stats.setFileSize(BaseStatistics.UNKNOWN);
      return stats;
    }
    final byte[] delimiter=getDelimiter();
    if (!((delimiter.length == 1 && delimiter[0] == '\n') || (delimiter.length == 2 && delimiter[0] == '\r' && delimiter[1] == '\n'))) {
      return stats;
    }
    int numSamples=Math.min(this.numLineSamples,(int)(stats.getTotalInputSize() / 1024));
    if (numSamples < 2) {
      numSamples=2;
    }
    long offset=0;
    long bytes=0;
    long stepSize=stats.getTotalInputSize() / numSamples;
    int fileNum=0;
    int samplesTaken=0;
    for (int sampleNum=0; sampleNum < numSamples && fileNum < files.size(); sampleNum++) {
      FileStatus currentFile=files.get(fileNum);
      FSDataInputStream inStream=null;
      try {
        inStream=fs.open(currentFile.getPath());
        LineReader lineReader=new LineReader(inStream,offset,currentFile.getLen() - offset,1024);
        byte[] line=lineReader.readLine();
        lineReader.close();
        if (line != null && line.length > 0) {
          samplesTaken++;
          bytes+=line.length + 1;
        }
      }
  finally {
        if (inStream != null) {
          try {
            inStream.close();
          }
 catch (          Throwable t) {
          }
        }
      }
      offset+=stepSize;
      while (fileNum < files.size() && offset >= (currentFile=files.get(fileNum)).getLen()) {
        offset-=currentFile.getLen();
        fileNum++;
      }
    }
    stats.setAvgBytesPerRecord(bytes / (float)samplesTaken);
  }
 catch (  IOException ioex) {
    if (LOG.isWarnEnabled())     LOG.warn(""String_Node_Str"" + filePath + ""String_Node_Str""+ ioex.getMessage());
  }
catch (  Throwable t) {
    if (LOG.isErrorEnabled())     LOG.error(""String_Node_Str"" + filePath + ""String_Node_Str""+ t.getMessage(),t);
  }
  return stats;
}",0.9854175872735308
55593,"public boolean keepsUniqueProperty(FieldSet uniqueSet,int input){
  for (  Integer uniqueField : uniqueSet) {
    if (isFieldKept(uniqueField,input) == false) {
      return false;
    }
  }
  return true;
}","public boolean keepsUniqueProperty(FieldSet uniqueSet,int input){
  for (  Integer uniqueField : uniqueSet) {
    if (isFieldKept(input,uniqueField) == false) {
      return false;
    }
  }
  return true;
}",0.9227053140096618
55594,"private void recycleBuffer(final ByteBuffer byteBuffer){
synchronized (this.buffers) {
    if (this.isDestroyed) {
      this.globalBufferPool.releaseGlobalBuffer(this.buffers.poll());
      this.requestedNumberOfBuffers--;
      return;
    }
    this.buffers.add(byteBuffer);
    this.buffers.notify();
  }
}","private void recycleBuffer(final ByteBuffer byteBuffer){
synchronized (this.buffers) {
    if (this.isDestroyed) {
      this.globalBufferPool.releaseGlobalBuffer(byteBuffer);
      this.requestedNumberOfBuffers--;
      return;
    }
    this.buffers.add(byteBuffer);
    this.buffers.notify();
  }
}",0.9525368248772504
55595,"private void sendReceiverNotFoundEvent(final TransferEnvelope envelope,final ChannelID unknownReceiver){
  if (ChannelID.SYSTEM_ID.equals(envelope.getSource())) {
    LOG.error(""String_Node_Str"");
    return;
  }
  final JobID jobID=envelope.getJobID();
  final TransferEnvelope transferEnvelope=new TransferEnvelope(0,jobID,ChannelID.SYSTEM_ID);
  final ReceiverNotFoundEvent unknownReceiverEvent=new ReceiverNotFoundEvent(unknownReceiver,envelope.getSequenceNumber());
  transferEnvelope.addEvent(unknownReceiverEvent);
  final TransferEnvelopeReceiverList receiverList=getReceiverList(jobID,unknownReceiver);
  if (receiverList == null) {
    LOG.error(""String_Node_Str"" + unknownReceiver);
    return;
  }
  processEnvelopeEnvelopeWithoutBuffer(transferEnvelope,receiverList);
}","private void sendReceiverNotFoundEvent(final TransferEnvelope envelope,final ChannelID receiver){
  if (envelope.getBuffer() == null && envelope.getSequenceNumber() == 0) {
    final EventList eventList=envelope.getEventList();
    if (eventList.size() == 1) {
      final AbstractEvent event=eventList.get(0);
      if (event instanceof ReceiverNotFoundEvent) {
        LOG.info(""String_Node_Str"");
        return;
      }
    }
  }
  final JobID jobID=envelope.getJobID();
  final TransferEnvelope transferEnvelope=new TransferEnvelope(0,jobID,receiver);
  final ReceiverNotFoundEvent unknownReceiverEvent=new ReceiverNotFoundEvent(receiver,envelope.getSequenceNumber());
  transferEnvelope.addEvent(unknownReceiverEvent);
  final TransferEnvelopeReceiverList receiverList=getReceiverList(jobID,receiver);
  if (receiverList == null) {
    LOG.error(""String_Node_Str"" + receiver);
    return;
  }
  processEnvelopeEnvelopeWithoutBuffer(transferEnvelope,receiverList);
}",0.780376497432972
55596,"private TransferEnvelopeReceiverList getReceiverList(final JobID jobID,final ChannelID sourceChannelID){
  TransferEnvelopeReceiverList receiverList=this.receiverCache.get(sourceChannelID);
  if (receiverList == null) {
    try {
      while (true) {
        final ConnectionInfoLookupResponse lookupResponse=this.channelLookupService.lookupConnectionInfo(this.localConnectionInfo,jobID,sourceChannelID);
        if (lookupResponse.receiverNotFound()) {
          throw new IOException(""String_Node_Str"" + sourceChannelID);
        }
        if (lookupResponse.receiverNotReady()) {
          Thread.sleep(500);
          continue;
        }
        if (lookupResponse.receiverReady()) {
          receiverList=new TransferEnvelopeReceiverList(lookupResponse);
          break;
        }
      }
      if (receiverList != null) {
        this.receiverCache.put(sourceChannelID,receiverList);
        if (LOG.isDebugEnabled()) {
          final StringBuilder sb=new StringBuilder();
          sb.append(""String_Node_Str"" + sourceChannelID + ""String_Node_Str""+ this.localConnectionInfo+ ""String_Node_Str"");
          if (receiverList.hasLocalReceivers()) {
            sb.append(""String_Node_Str"");
            final Iterator<ChannelID> it=receiverList.getLocalReceivers().iterator();
            while (it.hasNext()) {
              sb.append(""String_Node_Str"" + it.next() + ""String_Node_Str"");
            }
          }
          if (receiverList.hasRemoteReceivers()) {
            sb.append(""String_Node_Str"");
            final Iterator<InetSocketAddress> it=receiverList.getRemoteReceivers().iterator();
            while (it.hasNext()) {
              sb.append(""String_Node_Str"" + it.next() + ""String_Node_Str"");
            }
          }
          LOG.debug(sb.toString());
        }
      }
    }
 catch (    InterruptedException ie) {
    }
catch (    IOException ioe) {
    }
  }
  return receiverList;
}","private TransferEnvelopeReceiverList getReceiverList(final JobID jobID,final ChannelID sourceChannelID){
  TransferEnvelopeReceiverList receiverList=this.receiverCache.get(sourceChannelID);
  if (receiverList == null) {
    try {
      while (true) {
        ConnectionInfoLookupResponse lookupResponse;
synchronized (this.channelLookupService) {
          lookupResponse=this.channelLookupService.lookupConnectionInfo(this.localConnectionInfo,jobID,sourceChannelID);
        }
        if (lookupResponse.receiverNotFound()) {
          throw new IOException(""String_Node_Str"" + sourceChannelID);
        }
        if (lookupResponse.receiverNotReady()) {
          Thread.sleep(500);
          continue;
        }
        if (lookupResponse.receiverReady()) {
          receiverList=new TransferEnvelopeReceiverList(lookupResponse);
          break;
        }
      }
      if (receiverList != null) {
        this.receiverCache.put(sourceChannelID,receiverList);
        if (LOG.isDebugEnabled()) {
          final StringBuilder sb=new StringBuilder();
          sb.append(""String_Node_Str"" + sourceChannelID + ""String_Node_Str""+ this.localConnectionInfo+ ""String_Node_Str"");
          if (receiverList.hasLocalReceivers()) {
            sb.append(""String_Node_Str"");
            final Iterator<ChannelID> it=receiverList.getLocalReceivers().iterator();
            while (it.hasNext()) {
              sb.append(""String_Node_Str"" + it.next() + ""String_Node_Str"");
            }
          }
          if (receiverList.hasRemoteReceivers()) {
            sb.append(""String_Node_Str"");
            final Iterator<InetSocketAddress> it=receiverList.getRemoteReceivers().iterator();
            while (it.hasNext()) {
              sb.append(""String_Node_Str"" + it.next() + ""String_Node_Str"");
            }
          }
          LOG.debug(sb.toString());
        }
      }
    }
 catch (    InterruptedException ie) {
    }
catch (    IOException ioe) {
    }
  }
  return receiverList;
}",0.972058446552166
55597,"@Override public BufferProvider getBufferProvider(final JobID jobID,final ChannelID sourceChannelID) throws IOException, InterruptedException {
  final TransferEnvelopeReceiverList receiverList=getReceiverList(jobID,sourceChannelID);
  if (receiverList.hasLocalReceivers() && !receiverList.hasRemoteReceivers()) {
    final List<ChannelID> localReceivers=receiverList.getLocalReceivers();
    if (localReceivers.size() == 1) {
      final ChannelID localReceiver=localReceivers.get(0);
      final ChannelContext cc=this.registeredChannels.get(localReceiver);
      if (cc == null) {
        return this.transitBufferPool;
      }
      if (!cc.isInputChannel()) {
        throw new IOException(""String_Node_Str"" + localReceiver + ""String_Node_Str"");
      }
      final InputChannelContext icc=(InputChannelContext)cc;
      return icc;
    }
  }
  return this.transitBufferPool;
}","/** 
 * {@inheritDoc}
 */
@Override public BufferProvider getBufferProvider(final JobID jobID,final ChannelID sourceChannelID) throws IOException, InterruptedException {
  final TransferEnvelopeReceiverList receiverList=getReceiverList(jobID,sourceChannelID);
  if (receiverList.hasLocalReceivers() && !receiverList.hasRemoteReceivers()) {
    final List<ChannelID> localReceivers=receiverList.getLocalReceivers();
    if (localReceivers.size() == 1) {
      final ChannelID localReceiver=localReceivers.get(0);
      final ChannelContext cc=this.registeredChannels.get(localReceiver);
      if (cc == null) {
        return this.transitBufferPool;
      }
      if (!cc.isInputChannel()) {
        throw new IOException(""String_Node_Str"" + localReceiver + ""String_Node_Str"");
      }
      final InputChannelContext icc=(InputChannelContext)cc;
      return icc;
    }
  }
  return this.transitBufferPool;
}",0.9854748603351956
55598,"/** 
 * Returns the key column numbers for the specific input if it is preserved by this node. Null, otherwise.
 * @param input
 * @return
 */
protected int[] getConstantKeySet(int input){
  int[] keyColumns=null;
  Contract contract=getPactContract();
  if (contract instanceof AbstractPact<?>) {
    AbstractPact<?> abstractPact=(AbstractPact<?>)contract;
    keyColumns=abstractPact.getKeyColumnNumbers(input);
    if (keyColumns != null) {
      for (      int keyColumn : keyColumns) {
        if (isFieldKept(input,keyColumn) == false) {
          keyColumns=null;
          break;
        }
      }
    }
  }
  return keyColumns;
}","/** 
 * Returns the key column numbers for the specific input if it is preserved by this node. Null, otherwise.
 * @param input
 * @return
 */
protected int[] getConstantKeySet(int input){
  int[] keyColumns=null;
  Contract contract=getPactContract();
  if (contract instanceof AbstractPact<?>) {
    AbstractPact<?> abstractPact=(AbstractPact<?>)contract;
    keyColumns=abstractPact.getKeyColumnNumbers(input);
    if (keyColumns != null) {
      if (keyColumns.length == 0) {
        return null;
      }
      for (      int keyColumn : keyColumns) {
        if (isFieldKept(input,keyColumn) == false) {
          return null;
        }
      }
    }
  }
  return keyColumns;
}",0.8651515151515151
55599,"/** 
 * Causes this node to compute its output estimates (such as number of rows, size in bytes) based on the inputs and the compiler hints. The compiler hints are instantiated with conservative default values which are used if no other values are provided. Nodes may access the statistics to determine relevant information.
 * @param statistics The statistics object which may be accessed to get statistical information. The parameter may be null, if no statistics are available.
 */
public void computeOutputEstimates(DataStatistics statistics){
  boolean allPredsAvailable=true;
  for (  List<PactConnection> incomingConnections : getIncomingConnections()) {
    if (allPredsAvailable) {
      for (      PactConnection incomingConnection : incomingConnections) {
        if (incomingConnection.getSourcePact() == null) {
          allPredsAvailable=false;
          break;
        }
      }
    }
 else {
      break;
    }
  }
  CompilerHints hints=getPactContract().getCompilerHints();
  computeUniqueFields();
  if (!allPredsAvailable) {
    this.estimatedCardinality.putAll(hints.getDistinctCounts());
    this.estimatedNumRecords=0;
    int count=0;
    for (    Entry<FieldSet,Long> cardinality : hints.getDistinctCounts().entrySet()) {
      float avgNumValues=hints.getAvgNumRecordsPerDistinctFields(cardinality.getKey());
      if (avgNumValues != -1) {
        this.estimatedNumRecords+=cardinality.getValue() * avgNumValues;
        count++;
      }
    }
    if (count > 0) {
      this.estimatedNumRecords=(this.estimatedNumRecords / count) >= 1 ? (this.estimatedNumRecords / count) : 1;
    }
 else {
      this.estimatedNumRecords=-1;
    }
    if (this.estimatedNumRecords != -1 && hints.getAvgBytesPerRecord() != -1) {
      this.estimatedOutputSize=(this.estimatedNumRecords * hints.getAvgBytesPerRecord() >= 1) ? (long)(this.estimatedNumRecords * hints.getAvgBytesPerRecord()) : 1;
    }
  }
 else {
    boolean outputCardEstimated=true;
    this.estimatedNumRecords=0;
    int count=0;
    for (    Entry<FieldSet,Long> cardinality : hints.getDistinctCounts().entrySet()) {
      float avgNumValues=hints.getAvgNumRecordsPerDistinctFields(cardinality.getKey());
      if (avgNumValues != -1) {
        this.estimatedNumRecords+=cardinality.getValue() * avgNumValues;
        count++;
      }
    }
    if (count > 0) {
      this.estimatedNumRecords=(this.estimatedNumRecords / count) >= 1 ? (this.estimatedNumRecords / count) : 1;
    }
 else {
      this.estimatedNumRecords=this.computeNumberOfStubCalls();
      if (hints.getAvgRecordsEmittedPerStubCall() != -1.0 && this.computeNumberOfStubCalls() != -1) {
        this.estimatedNumRecords=(this.computeNumberOfStubCalls() * hints.getAvgRecordsEmittedPerStubCall() >= 1) ? (long)(this.computeNumberOfStubCalls() * hints.getAvgRecordsEmittedPerStubCall()) : 1;
      }
 else {
        outputCardEstimated=false;
      }
    }
    this.estimatedCardinality.putAll(hints.getDistinctCounts());
    if (this.getUniqueFields() != null) {
      for (      FieldSet uniqueFieldSet : this.uniqueFields) {
        if (this.estimatedCardinality.get(uniqueFieldSet) == null) {
          this.estimatedCardinality.put(uniqueFieldSet,1L);
        }
      }
    }
    for (int input=0; input < getIncomingConnections().size(); input++) {
      int[] keyColumns;
      if ((keyColumns=getConstantKeySet(input)) != null) {
        long estimatedKeyCardinality;
        if (hints.getAvgRecordsEmittedPerStubCall() < 1.0) {
          double probToKeepKey=1.0 - Math.pow((1.0 - hints.getAvgRecordsEmittedPerStubCall()),this.computeStubCallsPerProcessedKey());
          estimatedKeyCardinality=(this.computeNumberOfProcessedKeys() * probToKeepKey >= 1) ? (long)(this.computeNumberOfProcessedKeys() * probToKeepKey) : 1;
        }
 else {
          estimatedKeyCardinality=this.computeNumberOfProcessedKeys();
        }
        FieldSet fieldSet=new FieldSet(keyColumns);
        if (estimatedCardinality.get(fieldSet) != null) {
          estimatedCardinality.put(fieldSet,estimatedKeyCardinality);
        }
      }
    }
    if (this.estimatedNumRecords != -1) {
      for (      Entry<FieldSet,Float> avgNumValues : hints.getAvgNumRecordsPerDistinctFields().entrySet()) {
        if (estimatedCardinality.get(avgNumValues.getKey()) == null) {
          long estimatedCard=(this.estimatedNumRecords / avgNumValues.getValue() >= 1) ? (long)(this.estimatedNumRecords / avgNumValues.getValue()) : 1;
          estimatedCardinality.put(avgNumValues.getKey(),estimatedCard);
        }
      }
    }
    if (!outputCardEstimated) {
      long newEstimatedNumRecords=0;
      count=0;
      for (      Entry<FieldSet,Long> cardinality : estimatedCardinality.entrySet()) {
        float avgNumValues=hints.getAvgNumRecordsPerDistinctFields(cardinality.getKey());
        if (avgNumValues != -1) {
          newEstimatedNumRecords+=cardinality.getValue() * avgNumValues;
          count++;
        }
      }
      if (count > 0) {
        newEstimatedNumRecords=(newEstimatedNumRecords / count) >= 1 ? (newEstimatedNumRecords / count) : 1;
      }
    }
    double estAvgRecordWidth=this.computeAverageRecordWidth();
    if (this.estimatedNumRecords != -1 && estAvgRecordWidth != -1) {
      this.estimatedOutputSize=(this.estimatedNumRecords * estAvgRecordWidth) >= 1 ? (long)(this.estimatedNumRecords * estAvgRecordWidth) : 1;
    }
    for (    Entry<FieldSet,Long> cardinality : this.estimatedCardinality.entrySet()) {
      if (cardinality.getValue() > this.estimatedNumRecords) {
        cardinality.setValue(this.estimatedNumRecords);
      }
    }
  }
}","/** 
 * Causes this node to compute its output estimates (such as number of rows, size in bytes) based on the inputs and the compiler hints. The compiler hints are instantiated with conservative default values which are used if no other values are provided. Nodes may access the statistics to determine relevant information.
 * @param statistics The statistics object which may be accessed to get statistical information. The parameter may be null, if no statistics are available.
 */
public void computeOutputEstimates(DataStatistics statistics){
  boolean allPredsAvailable=true;
  for (  List<PactConnection> incomingConnections : getIncomingConnections()) {
    if (allPredsAvailable) {
      for (      PactConnection incomingConnection : incomingConnections) {
        if (incomingConnection.getSourcePact() == null) {
          allPredsAvailable=false;
          break;
        }
      }
    }
 else {
      break;
    }
  }
  CompilerHints hints=getPactContract().getCompilerHints();
  computeUniqueFields();
  if (!allPredsAvailable) {
    this.estimatedCardinality.putAll(hints.getDistinctCounts());
    this.estimatedNumRecords=0;
    int count=0;
    for (    Entry<FieldSet,Long> cardinality : hints.getDistinctCounts().entrySet()) {
      float avgNumValues=hints.getAvgNumRecordsPerDistinctFields(cardinality.getKey());
      if (avgNumValues != -1) {
        this.estimatedNumRecords+=cardinality.getValue() * avgNumValues;
        count++;
      }
    }
    if (count > 0) {
      this.estimatedNumRecords=(this.estimatedNumRecords / count) >= 1 ? (this.estimatedNumRecords / count) : 1;
    }
 else {
      this.estimatedNumRecords=-1;
    }
    if (this.estimatedNumRecords != -1 && hints.getAvgBytesPerRecord() != -1) {
      this.estimatedOutputSize=(this.estimatedNumRecords * hints.getAvgBytesPerRecord() >= 1) ? (long)(this.estimatedNumRecords * hints.getAvgBytesPerRecord()) : 1;
    }
  }
 else {
    boolean outputCardEstimated=true;
    this.estimatedNumRecords=0;
    int count=0;
    for (    Entry<FieldSet,Long> cardinality : hints.getDistinctCounts().entrySet()) {
      float avgNumValues=hints.getAvgNumRecordsPerDistinctFields(cardinality.getKey());
      if (avgNumValues != -1) {
        this.estimatedNumRecords+=cardinality.getValue() * avgNumValues;
        count++;
      }
    }
    if (count > 0) {
      this.estimatedNumRecords=(this.estimatedNumRecords / count) >= 1 ? (this.estimatedNumRecords / count) : 1;
    }
 else {
      this.estimatedNumRecords=this.computeNumberOfStubCalls();
      if (hints.getAvgRecordsEmittedPerStubCall() != -1.0 && this.computeNumberOfStubCalls() != -1) {
        this.estimatedNumRecords=(this.computeNumberOfStubCalls() * hints.getAvgRecordsEmittedPerStubCall() >= 1) ? (long)(this.computeNumberOfStubCalls() * hints.getAvgRecordsEmittedPerStubCall()) : 1;
      }
 else {
        outputCardEstimated=false;
      }
    }
    this.estimatedCardinality.putAll(hints.getDistinctCounts());
    if (this.getUniqueFields() != null) {
      for (      FieldSet uniqueFieldSet : this.uniqueFields) {
        if (this.estimatedCardinality.get(uniqueFieldSet) == null) {
          this.estimatedCardinality.put(uniqueFieldSet,this.estimatedNumRecords);
        }
      }
    }
    for (int input=0; input < getIncomingConnections().size(); input++) {
      int[] keyColumns;
      if ((keyColumns=getConstantKeySet(input)) != null) {
        long estimatedKeyCardinality;
        if (hints.getAvgRecordsEmittedPerStubCall() < 1.0) {
          double probToKeepKey=1.0 - Math.pow((1.0 - hints.getAvgRecordsEmittedPerStubCall()),this.computeStubCallsPerProcessedKey());
          estimatedKeyCardinality=(this.computeNumberOfProcessedKeys() * probToKeepKey >= 1) ? (long)(this.computeNumberOfProcessedKeys() * probToKeepKey) : 1;
        }
 else {
          estimatedKeyCardinality=this.computeNumberOfProcessedKeys();
        }
        FieldSet fieldSet=new FieldSet(keyColumns);
        if (estimatedCardinality.get(fieldSet) == null) {
          estimatedCardinality.put(fieldSet,estimatedKeyCardinality);
        }
      }
    }
    if (this.estimatedNumRecords != -1) {
      for (      Entry<FieldSet,Float> avgNumValues : hints.getAvgNumRecordsPerDistinctFields().entrySet()) {
        if (estimatedCardinality.get(avgNumValues.getKey()) == null) {
          long estimatedCard=(this.estimatedNumRecords / avgNumValues.getValue() >= 1) ? (long)(this.estimatedNumRecords / avgNumValues.getValue()) : 1;
          estimatedCardinality.put(avgNumValues.getKey(),estimatedCard);
        }
      }
    }
    if (!outputCardEstimated) {
      long newEstimatedNumRecords=0;
      count=0;
      for (      Entry<FieldSet,Long> cardinality : estimatedCardinality.entrySet()) {
        float avgNumValues=hints.getAvgNumRecordsPerDistinctFields(cardinality.getKey());
        if (avgNumValues != -1) {
          newEstimatedNumRecords+=cardinality.getValue() * avgNumValues;
          count++;
        }
      }
      if (count > 0) {
        newEstimatedNumRecords=(newEstimatedNumRecords / count) >= 1 ? (newEstimatedNumRecords / count) : 1;
      }
    }
    double estAvgRecordWidth=this.computeAverageRecordWidth();
    if (this.estimatedNumRecords != -1 && estAvgRecordWidth != -1) {
      this.estimatedOutputSize=(this.estimatedNumRecords * estAvgRecordWidth) >= 1 ? (long)(this.estimatedNumRecords * estAvgRecordWidth) : 1;
    }
    for (    Entry<FieldSet,Long> cardinality : this.estimatedCardinality.entrySet()) {
      if (cardinality.getValue() > this.estimatedNumRecords) {
        cardinality.setValue(this.estimatedNumRecords);
      }
    }
  }
}",0.9975106685633002
55600,"/** 
 * Registers the spilling queue with this network connection. The network connection is then in charge of polling the elements from the queue.
 * @param spillingQueue the queue to register
 */
void registerSpillingQueue(final SpillingQueue spillingQueue){
synchronized (this.queuedEnvelopes) {
    checkConnection();
    this.queuedEnvelopes.registerSpillingQueue(spillingQueue);
  }
}","/** 
 * Registers the spilling queue with this network connection. The network connection is then in charge of polling the elements from the queue.
 * @param spillingQueue the queue to register
 */
void registerSpillingQueue(final SpillingQueue spillingQueue){
}",0.803680981595092
55601,"private void showOustandingEnvelopeLog(){
  int dataAvailableCounter=0;
  final int pos=this.outstandingEnvelopesAsIntBuffer.position();
  final int limit=this.outstandingEnvelopesAsIntBuffer.limit();
  for (int i=0; i < this.outstandingEnvelopesAsIntBuffer.capacity(); ++i) {
    if (i < pos) {
      System.out.print('_');
      continue;
    }
    if (i >= limit) {
      System.out.print('_');
      continue;
    }
    final int entry=this.outstandingEnvelopesAsIntBuffer.get(i);
    final int channelIndex=getInputChannel(entry);
    final boolean dataAvailable=getDataAvailability(entry);
    if (dataAvailable) {
      ++dataAvailableCounter;
    }
    char ch=(char)(((int)'A') + channelIndex + (dataAvailable ? 0 : 32));
    System.out.print(ch);
  }
  System.out.println(""String_Node_Str"");
  System.out.println(""String_Node_Str"" + dataAvailableCounter);
}","private void showOustandingEnvelopeLog(){
  int dataAvailableCounter=0;
  final int pos=this.outstandingEnvelopesAsIntBuffer.position();
  final int limit=this.outstandingEnvelopesAsIntBuffer.limit();
  final StringBuilder sb=new StringBuilder();
  for (int i=0; i < this.outstandingEnvelopesAsIntBuffer.capacity(); ++i) {
    if (i < pos) {
      sb.append('_');
      continue;
    }
    if (i >= limit) {
      sb.append('_');
      continue;
    }
    final int entry=this.outstandingEnvelopesAsIntBuffer.get(i);
    final int channelIndex=getInputChannel(entry);
    final boolean dataAvailable=getDataAvailability(entry);
    if (dataAvailable) {
      ++dataAvailableCounter;
    }
    char ch=(char)(((int)'A') + channelIndex + (dataAvailable ? 0 : 32));
    sb.append(ch);
  }
  LOG.debug(sb.toString());
}",0.8382877526753865
55602,"private void addOutstandingEnvelope(final int gateIndex,final int channelIndex){
  final int entryToTest=toEntry(gateIndex,channelIndex,false);
  boolean found=false;
  while (true) {
    for (int i=this.outstandingEnvelopesAsIntBuffer.position(); i < this.outstandingEnvelopesAsIntBuffer.limit(); ++i) {
      if (this.outstandingEnvelopesAsIntBuffer.get(i) == entryToTest) {
        this.outstandingEnvelopesAsIntBuffer.put(i,setDataAvailability(entryToTest,true));
        found=true;
        break;
      }
    }
    if (!found) {
      if (this.outstandingEnvelopesAsIntBuffer.limit() == this.outstandingEnvelopesAsIntBuffer.capacity()) {
        loadNextOutstandingEnvelopes();
        continue;
      }
      final int newEntry=setDataAvailability(entryToTest,true);
      final int limit=this.outstandingEnvelopesAsIntBuffer.limit();
      this.outstandingEnvelopesAsIntBuffer.limit(limit + 1);
      this.outstandingEnvelopesAsIntBuffer.put(limit,newEntry);
    }
    break;
  }
  int newPosition=this.outstandingEnvelopesAsIntBuffer.position();
  int count=0;
  for (int i=this.outstandingEnvelopesAsIntBuffer.position(); i < this.outstandingEnvelopesAsIntBuffer.limit(); ++i) {
    final int entry=this.outstandingEnvelopesAsIntBuffer.get(i);
    if (getDataAvailability(entry)) {
      announce(getInputGate(entry),getInputChannel(entry));
      newPosition=i + 1;
      ++count;
    }
 else {
      break;
    }
  }
  this.outstandingEnvelopesAsIntBuffer.position(Math.min(this.outstandingEnvelopesAsIntBuffer.limit(),newPosition));
  if (count > 0) {
    System.out.println(""String_Node_Str"" + count + ""String_Node_Str"");
    System.out.println(""String_Node_Str"" + this.numberOfInitialLogEntries + ""String_Node_Str""+ this.numberOfAnnouncedEnvelopes);
    System.out.println(""String_Node_Str"" + this.outstandingEnvelopesAsIntBuffer.remaining());
    showOustandingEnvelopeLog();
  }
  if (!this.outstandingEnvelopesAsIntBuffer.hasRemaining()) {
    loadNextOutstandingEnvelopes();
  }
}","private void addOutstandingEnvelope(final int gateIndex,final int channelIndex){
  final int entryToTest=toEntry(gateIndex,channelIndex,false);
  boolean found=false;
  while (true) {
    for (int i=this.outstandingEnvelopesAsIntBuffer.position(); i < this.outstandingEnvelopesAsIntBuffer.limit(); ++i) {
      if (this.outstandingEnvelopesAsIntBuffer.get(i) == entryToTest) {
        this.outstandingEnvelopesAsIntBuffer.put(i,setDataAvailability(entryToTest,true));
        found=true;
        break;
      }
    }
    if (!found) {
      if (this.outstandingEnvelopesAsIntBuffer.limit() == this.outstandingEnvelopesAsIntBuffer.capacity()) {
        loadNextOutstandingEnvelopes();
        continue;
      }
      final int newEntry=setDataAvailability(entryToTest,true);
      final int limit=this.outstandingEnvelopesAsIntBuffer.limit();
      this.outstandingEnvelopesAsIntBuffer.limit(limit + 1);
      this.outstandingEnvelopesAsIntBuffer.put(limit,newEntry);
    }
    break;
  }
  int newPosition=this.outstandingEnvelopesAsIntBuffer.position();
  int count=0;
  for (int i=this.outstandingEnvelopesAsIntBuffer.position(); i < this.outstandingEnvelopesAsIntBuffer.limit(); ++i) {
    final int entry=this.outstandingEnvelopesAsIntBuffer.get(i);
    if (getDataAvailability(entry)) {
      announce(getInputGate(entry),getInputChannel(entry));
      newPosition=i + 1;
      ++count;
    }
 else {
      break;
    }
  }
  this.outstandingEnvelopesAsIntBuffer.position(Math.min(this.outstandingEnvelopesAsIntBuffer.limit(),newPosition));
  if (count > 0 && LOG.isDebugEnabled()) {
    LOG.debug(""String_Node_Str"" + count + ""String_Node_Str"");
    LOG.debug(""String_Node_Str"" + this.numberOfInitialLogEntries + ""String_Node_Str""+ this.numberOfAnnouncedEnvelopes);
    LOG.debug(""String_Node_Str"" + this.outstandingEnvelopesAsIntBuffer.remaining());
    showOustandingEnvelopeLog();
  }
  if (!this.outstandingEnvelopesAsIntBuffer.hasRemaining()) {
    loadNextOutstandingEnvelopes();
  }
}",0.9737171464330412
55603,"/** 
 * {@inheritDoc}
 */
@Override public void queueTransferEnvelope(final TransferEnvelope transferEnvelope){
  final int sequenceNumber=transferEnvelope.getSequenceNumber();
  AbstractEvent eventToSend=null;
  if (ReceiverNotFoundEvent.isReceiverNotFoundEvent(transferEnvelope)) {
    return;
  }
synchronized (this.queuedEnvelopes) {
    if (this.destroyCalled) {
      final Buffer buffer=transferEnvelope.getBuffer();
      if (buffer != null) {
        buffer.recycleBuffer();
      }
      return;
    }
    final int expectedSequenceNumber=this.lastReceivedEnvelope + 1;
    if (sequenceNumber != expectedSequenceNumber) {
      if (sequenceNumber > expectedSequenceNumber) {
        if (expectedSequenceNumber > 0) {
          this.byteBufferedInputChannel.reportIOException(new IOException(""String_Node_Str"" + expectedSequenceNumber + ""String_Node_Str""+ sequenceNumber));
          this.envelopeConsumptionTracker.reportEnvelopeAvailability(this.byteBufferedInputChannel);
        }
      }
 else {
        eventToSend=lookForCloseEvent(transferEnvelope);
        if (eventToSend == null) {
          eventToSend=new UnexpectedEnvelopeEvent(expectedSequenceNumber - 1);
        }
      }
      LOG.warn(""String_Node_Str"" + getChannelID() + ""String_Node_Str""+ expectedSequenceNumber+ ""String_Node_Str""+ sequenceNumber);
      final Buffer buffer=transferEnvelope.getBuffer();
      if (buffer != null) {
        buffer.recycleBuffer();
      }
    }
 else {
      this.queuedEnvelopes.add(transferEnvelope);
      this.lastReceivedEnvelope=sequenceNumber;
    }
  }
  this.envelopeConsumptionTracker.reportEnvelopeAvailability(this.byteBufferedInputChannel);
  if (eventToSend != null) {
    try {
      transferEventToOutputChannel(eventToSend);
    }
 catch (    Exception e) {
      LOG.error(StringUtils.stringifyException(e));
    }
  }
}","/** 
 * {@inheritDoc}
 */
@Override public void queueTransferEnvelope(final TransferEnvelope transferEnvelope){
  final int sequenceNumber=transferEnvelope.getSequenceNumber();
  AbstractEvent eventToSend=null;
  if (ReceiverNotFoundEvent.isReceiverNotFoundEvent(transferEnvelope)) {
    return;
  }
synchronized (this.queuedEnvelopes) {
    if (this.destroyCalled) {
      final Buffer buffer=transferEnvelope.getBuffer();
      if (buffer != null) {
        buffer.recycleBuffer();
      }
      return;
    }
    final int expectedSequenceNumber=this.lastReceivedEnvelope + 1;
    if (sequenceNumber != expectedSequenceNumber) {
      if (sequenceNumber > expectedSequenceNumber) {
        if (expectedSequenceNumber > 0) {
          this.byteBufferedInputChannel.reportIOException(new IOException(""String_Node_Str"" + expectedSequenceNumber + ""String_Node_Str""+ sequenceNumber));
          this.byteBufferedInputChannel.checkForNetworkEvents();
        }
      }
 else {
        eventToSend=lookForCloseEvent(transferEnvelope);
        if (eventToSend == null) {
          eventToSend=new UnexpectedEnvelopeEvent(expectedSequenceNumber - 1);
        }
      }
      LOG.warn(""String_Node_Str"" + getChannelID() + ""String_Node_Str""+ expectedSequenceNumber+ ""String_Node_Str""+ sequenceNumber);
      final Buffer buffer=transferEnvelope.getBuffer();
      if (buffer != null) {
        buffer.recycleBuffer();
      }
    }
 else {
      this.queuedEnvelopes.add(transferEnvelope);
      this.lastReceivedEnvelope=sequenceNumber;
      this.envelopeConsumptionTracker.reportEnvelopeAvailability(this.byteBufferedInputChannel);
    }
  }
  if (eventToSend != null) {
    try {
      transferEventToOutputChannel(eventToSend);
    }
 catch (    Exception e) {
      LOG.error(StringUtils.stringifyException(e));
    }
  }
}",0.9733260751224824
55604,"RuntimeInputGateContext(final String taskName,final TransferEnvelopeDispatcher transferEnvelopeDispatcher,final InputGate<? extends Record> inputGate,final EnvelopeConsumptionTracker envelopeConsumptionTracker){
  this.taskName=taskName;
  this.localBufferPool=new LocalBufferPool(1,false);
  this.transferEnvelopeDispatcher=transferEnvelopeDispatcher;
  this.inputGate=inputGate;
  this.envelopeConsumptionTracker=envelopeConsumptionTracker;
}","RuntimeInputGateContext(final String taskName,final TransferEnvelopeDispatcher transferEnvelopeDispatcher,final InputGate<? extends Record> inputGate,final EnvelopeConsumptionTracker envelopeConsumptionTracker){
  this.taskName=taskName;
  this.localBufferPool=new LocalBufferPool(1,false);
  this.transferEnvelopeDispatcher=transferEnvelopeDispatcher;
  this.inputGate=inputGate;
  this.envelopeConsumptionTracker=envelopeConsumptionTracker;
  this.fileBufferManager=FileBufferManager.getInstance();
}",0.9386892177589852
55605,"/** 
 * {@inheritDoc}
 */
@Override public Buffer requestEmptyBufferBlocking(final int minimumSizeOfBuffer) throws IOException, InterruptedException {
  return this.localBufferPool.requestEmptyBufferBlocking(minimumSizeOfBuffer);
}","/** 
 * {@inheritDoc}
 */
@Override public Buffer requestEmptyBufferBlocking(final int minimumSizeOfBuffer) throws IOException, InterruptedException {
  final Buffer buffer=this.localBufferPool.requestEmptyBuffer(minimumSizeOfBuffer);
  if (buffer != null) {
    return buffer;
  }
  if (this.envelopeConsumptionTracker.followsLog()) {
    return BufferFactory.createFromFile(minimumSizeOfBuffer,this.inputGate.getGateID(),fileBufferManager);
  }
  return this.localBufferPool.requestEmptyBufferBlocking(minimumSizeOfBuffer);
}",0.5778364116094987
55606,"public static Buffer createFromMemory(final int bufferSize,final ByteBuffer byteBuffer,final Queue<ByteBuffer> queueForRecycledBuffers){
  final InternalBuffer internalBuffer=new MemoryBuffer(bufferSize,byteBuffer,queueForRecycledBuffers);
  return new Buffer(internalBuffer);
}","public static Buffer createFromMemory(final int bufferSize,final ByteBuffer byteBuffer,final MemoryBufferPoolConnector bufferPoolConnector){
  final InternalBuffer internalBuffer=new MemoryBuffer(bufferSize,byteBuffer,bufferPoolConnector);
  return new Buffer(internalBuffer);
}",0.7697841726618705
55607,"/** 
 * Increases the number of references to the physical buffer by one.
 */
synchronized void increaseReferenceCounter(){
  if (this.bufferAlreadyRecycled) {
    LOG.error(""String_Node_Str"");
  }
  ++this.referenceCounter;
}","/** 
 * Increases the number of references to the physical buffer by one.
 */
void increaseReferenceCounter(){
  if (this.referenceCounter.getAndIncrement() == 0) {
    LOG.error(""String_Node_Str"");
  }
}",0.5767441860465117
55608,"/** 
 * Constructs a new memory buffer recycler.
 * @param originalBuffer the original byte buffer
 * @param queueForRecycledBuffers the queue to append the buffer for recycling
 */
MemoryBufferRecycler(final ByteBuffer originalBuffer,final Queue<ByteBuffer> queueForRecycledBuffers){
  this.originalBuffer=originalBuffer;
  this.queueForRecycledBuffers=queueForRecycledBuffers;
}","/** 
 * Constructs a new memory buffer recycler.
 * @param originalBuffer the original byte buffer
 * @param bufferPoolConnector the connection to the pool from which the byte buffer has originally been taken
 */
MemoryBufferRecycler(final ByteBuffer originalBuffer,final MemoryBufferPoolConnector bufferPoolConnector){
  this.originalBuffer=originalBuffer;
  this.bufferPoolConnector=bufferPoolConnector;
}",0.4599745870393901
55609,"/** 
 * Decreases the number of references to the physical buffer by one. If the number of references becomes zero the physical buffer is recycled.
 */
synchronized void decreaseReferenceCounter(){
  if (this.bufferAlreadyRecycled) {
    LOG.error(""String_Node_Str"");
  }
  --this.referenceCounter;
  if (this.referenceCounter <= 0) {
    this.originalBuffer.clear();
synchronized (this.queueForRecycledBuffers) {
      this.queueForRecycledBuffers.add(this.originalBuffer);
      this.queueForRecycledBuffers.notify();
    }
    this.bufferAlreadyRecycled=true;
  }
}","/** 
 * Decreases the number of references to the physical buffer by one. If the number of references becomes zero the physical buffer is recycled.
 */
void decreaseReferenceCounter(){
  final int val=this.referenceCounter.decrementAndGet();
  if (val == 0) {
    this.originalBuffer.clear();
    this.bufferPoolConnector.recycle(this.originalBuffer);
  }
 else   if (val < 0) {
    LOG.error(""String_Node_Str"");
  }
}",0.3995943204868154
55610,"public LocalBufferPool(final String ownerName,final int designatedNumberOfBuffers,final boolean isShared){
  this(ownerName,designatedNumberOfBuffers,isShared,null);
}","public LocalBufferPool(final int designatedNumberOfBuffers,final boolean isShared){
  this(designatedNumberOfBuffers,isShared,null);
}",0.8903654485049833
55611,"private Buffer requestBufferInternal(final int minimumSizeOfBuffer,final boolean block) throws IOException, InterruptedException {
  if (minimumSizeOfBuffer > this.maximumBufferSize) {
    throw new IllegalArgumentException(""String_Node_Str"" + minimumSizeOfBuffer + ""String_Node_Str""+ this.maximumBufferSize);
  }
  while (true) {
    boolean async=false;
synchronized (this.buffers) {
      while (this.requestedNumberOfBuffers > this.designatedNumberOfBuffers) {
        final ByteBuffer buffer=this.buffers.poll();
        if (buffer == null) {
          break;
        }
        this.globalBufferPool.releaseGlobalBuffer(buffer);
        this.requestedNumberOfBuffers--;
      }
      while (this.buffers.isEmpty()) {
        if (this.requestedNumberOfBuffers < this.designatedNumberOfBuffers) {
          final ByteBuffer buffer=this.globalBufferPool.lockGlobalBuffer();
          if (buffer != null) {
            this.buffers.add(buffer);
            this.requestedNumberOfBuffers++;
            continue;
          }
        }
        if (this.asynchronousEventOccurred && block) {
          this.asynchronousEventOccurred=false;
          async=true;
          break;
        }
        if (block) {
          this.buffers.wait();
        }
 else {
          return null;
        }
      }
      if (!async) {
        final ByteBuffer byteBuffer=this.buffers.poll();
        return BufferFactory.createFromMemory(minimumSizeOfBuffer,byteBuffer,this.buffers);
      }
    }
    if (this.eventListener != null) {
      this.eventListener.asynchronousEventOccurred();
    }
  }
}","private Buffer requestBufferInternal(final int minimumSizeOfBuffer,final boolean block) throws IOException, InterruptedException {
  if (minimumSizeOfBuffer > this.maximumBufferSize) {
    throw new IllegalArgumentException(""String_Node_Str"" + minimumSizeOfBuffer + ""String_Node_Str""+ this.maximumBufferSize);
  }
  while (true) {
    boolean async=false;
synchronized (this.buffers) {
      while (this.requestedNumberOfBuffers > this.designatedNumberOfBuffers) {
        final ByteBuffer buffer=this.buffers.poll();
        if (buffer == null) {
          break;
        }
        this.globalBufferPool.releaseGlobalBuffer(buffer);
        this.requestedNumberOfBuffers--;
      }
      while (this.buffers.isEmpty()) {
        if (this.requestedNumberOfBuffers < this.designatedNumberOfBuffers) {
          final ByteBuffer buffer=this.globalBufferPool.lockGlobalBuffer();
          if (buffer != null) {
            this.buffers.add(buffer);
            this.requestedNumberOfBuffers++;
            continue;
          }
        }
        if (this.asynchronousEventOccurred && block) {
          this.asynchronousEventOccurred=false;
          async=true;
          break;
        }
        if (block) {
          this.buffers.wait();
        }
 else {
          return null;
        }
      }
      if (!async) {
        final ByteBuffer byteBuffer=this.buffers.poll();
        return BufferFactory.createFromMemory(minimumSizeOfBuffer,byteBuffer,this.bufferPoolConnector);
      }
    }
    if (this.eventListener != null) {
      this.eventListener.asynchronousEventOccurred();
    }
  }
}",0.9955974842767296
55612,"public ByteBufferedChannelManager(final ChannelLookupProtocol channelLookupService,final InstanceConnectionInfo localInstanceConnectionInfo) throws IOException {
  this.channelLookupService=channelLookupService;
  this.localConnectionInfo=localInstanceConnectionInfo;
  FileBufferManager.getInstance();
  GlobalBufferPool.getInstance();
  this.transitBufferPool=new LocalBufferPool(""String_Node_Str"",128,true);
  this.networkConnectionManager=new NetworkConnectionManager(this,localInstanceConnectionInfo.getAddress(),localInstanceConnectionInfo.getDataPort());
  this.allowSenderSideSpilling=GlobalConfiguration.getBoolean(""String_Node_Str"",DEFAULT_ALLOW_SENDER_SIDE_SPILLING);
  this.mergeSpilledBuffers=GlobalConfiguration.getBoolean(""String_Node_Str"",DEFAULT_MERGE_SPILLED_BUFFERS);
  LOG.info(""String_Node_Str"" + (this.allowSenderSideSpilling ? ""String_Node_Str"" : ""String_Node_Str"") + (this.mergeSpilledBuffers ? ""String_Node_Str"" : ""String_Node_Str""));
}","public ByteBufferedChannelManager(final ChannelLookupProtocol channelLookupService,final InstanceConnectionInfo localInstanceConnectionInfo) throws IOException {
  this.channelLookupService=channelLookupService;
  this.localConnectionInfo=localInstanceConnectionInfo;
  FileBufferManager.getInstance();
  GlobalBufferPool.getInstance();
  this.transitBufferPool=new LocalBufferPool(128,true);
  this.networkConnectionManager=new NetworkConnectionManager(this,localInstanceConnectionInfo.getAddress(),localInstanceConnectionInfo.getDataPort());
  this.allowSenderSideSpilling=GlobalConfiguration.getBoolean(""String_Node_Str"",DEFAULT_ALLOW_SENDER_SIDE_SPILLING);
  this.mergeSpilledBuffers=GlobalConfiguration.getBoolean(""String_Node_Str"",DEFAULT_MERGE_SPILLED_BUFFERS);
  LOG.info(""String_Node_Str"" + (this.allowSenderSideSpilling ? ""String_Node_Str"" : ""String_Node_Str"") + (this.mergeSpilledBuffers ? ""String_Node_Str"" : ""String_Node_Str""));
}",0.990546218487395
55613,"/** 
 * {@inheritDoc}
 */
@Override public void clearLocalBufferPool(){
  this.localBufferPool.clear();
}","/** 
 * {@inheritDoc}
 */
@Override public void clearLocalBufferPool(){
  this.localBufferPool.destroy();
}",0.9622641509433962
55614,"RuntimeInputGateContext(final String taskName,final TransferEnvelopeDispatcher transferEnvelopeDispatcher,final InputGate<? extends Record> inputGate){
  final String poolOwnerName=(taskName == null ? ""String_Node_Str"" : taskName + ""String_Node_Str"" + inputGate.getIndex()+ ""String_Node_Str"");
  this.localBufferPool=new LocalBufferPool(poolOwnerName,1,false);
  this.transferEnvelopeDispatcher=transferEnvelopeDispatcher;
  this.inputGate=inputGate;
}","RuntimeInputGateContext(final TransferEnvelopeDispatcher transferEnvelopeDispatcher,final InputGate<? extends Record> inputGate){
  this.localBufferPool=new LocalBufferPool(1,false);
  this.transferEnvelopeDispatcher=transferEnvelopeDispatcher;
  this.inputGate=inputGate;
}",0.4352617079889807
55615,"RuntimeTaskContext(final RuntimeTask task,final TransferEnvelopeDispatcher transferEnvelopeDispatcher,final Map<ExecutionVertexID,RuntimeTaskContext> tasksWithUndecidedCheckpoints){
  final String poolOwnerName=(task.getEnvironment().getTaskName() == null ? ""String_Node_Str"" : task.getEnvironment().getTaskName());
  this.localBufferPool=new LocalBufferPool(poolOwnerName,1,false,this);
  this.task=task;
  final RuntimeEnvironment environment=task.getRuntimeEnvironment();
  int nooc=0;
  boolean ephemeral=true;
  for (int i=0; i < environment.getNumberOfOutputGates(); ++i) {
    final OutputGate<? extends Record> outputGate=environment.getOutputGate(i);
    nooc+=outputGate.getNumberOfOutputChannels();
    if (outputGate.getChannelType() == ChannelType.FILE) {
      ephemeral=false;
    }
  }
  this.numberOfOutputChannels=nooc;
  this.ephemeralCheckpoint=new EphemeralCheckpoint(task,ephemeral);
  if (ephemeral) {
    tasksWithUndecidedCheckpoints.put(task.getVertexID(),this);
  }
  this.transferEnvelopeDispatcher=transferEnvelopeDispatcher;
  this.runtimeDispatcher=new RuntimeDispatcher(transferEnvelopeDispatcher);
}","RuntimeTaskContext(final RuntimeTask task,final TransferEnvelopeDispatcher transferEnvelopeDispatcher,final Map<ExecutionVertexID,RuntimeTaskContext> tasksWithUndecidedCheckpoints){
  this.localBufferPool=new LocalBufferPool(1,false,this);
  this.task=task;
  final RuntimeEnvironment environment=task.getRuntimeEnvironment();
  int nooc=0;
  boolean ephemeral=true;
  for (int i=0; i < environment.getNumberOfOutputGates(); ++i) {
    final OutputGate<? extends Record> outputGate=environment.getOutputGate(i);
    nooc+=outputGate.getNumberOfOutputChannels();
    if (outputGate.getChannelType() == ChannelType.FILE) {
      ephemeral=false;
    }
  }
  this.numberOfOutputChannels=nooc;
  this.ephemeralCheckpoint=new EphemeralCheckpoint(task,ephemeral);
  if (ephemeral) {
    tasksWithUndecidedCheckpoints.put(task.getVertexID(),this);
  }
  this.transferEnvelopeDispatcher=transferEnvelopeDispatcher;
  this.runtimeDispatcher=new RuntimeDispatcher(transferEnvelopeDispatcher);
}",0.9054820415879016
55616,"/** 
 * {@inheritDoc}
 */
@Override public void clearLocalBufferPool(){
  this.localBufferPool.clear();
}","/** 
 * {@inheritDoc}
 */
@Override public void clearLocalBufferPool(){
  this.localBufferPool.destroy();
}",0.9622641509433962
55617,"/** 
 * {@inheritDoc}
 */
@Override public InputGateContext createInputGateContext(final GateID gateID){
  if (gateID == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  InputGate<? extends Record> inputGate=null;
  final RuntimeEnvironment re=this.task.getRuntimeEnvironment();
  for (int i=0; i < re.getNumberOfInputGates(); ++i) {
    final InputGate<? extends Record> candidateGate=re.getInputGate(i);
    if (candidateGate.getGateID().equals(gateID)) {
      inputGate=candidateGate;
      break;
    }
  }
  if (inputGate == null) {
    throw new IllegalStateException(""String_Node_Str"" + gateID);
  }
  return new RuntimeInputGateContext(this.task.getEnvironment().getTaskName(),this.transferEnvelopeDispatcher,inputGate);
}","/** 
 * {@inheritDoc}
 */
@Override public InputGateContext createInputGateContext(final GateID gateID){
  if (gateID == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  InputGate<? extends Record> inputGate=null;
  final RuntimeEnvironment re=this.task.getRuntimeEnvironment();
  for (int i=0; i < re.getNumberOfInputGates(); ++i) {
    final InputGate<? extends Record> candidateGate=re.getInputGate(i);
    if (candidateGate.getGateID().equals(gateID)) {
      inputGate=candidateGate;
      break;
    }
  }
  if (inputGate == null) {
    throw new IllegalStateException(""String_Node_Str"" + gateID);
  }
  return new RuntimeInputGateContext(this.transferEnvelopeDispatcher,inputGate);
}",0.94213750850919
55618,"private static final boolean invalidateReceiverLookupCaches(final ExecutionVertex failedVertex,final Set<ExecutionVertex> verticesToBeCanceled){
  final Map<AbstractInstance,Set<ChannelID>> entriesToInvalidate=new HashMap<AbstractInstance,Set<ChannelID>>();
  final ExecutionGraph eg=failedVertex.getExecutionGraph();
  final RuntimeEnvironment env=failedVertex.getEnvironment();
  for (int i=0; i < env.getNumberOfOutputGates(); ++i) {
    final OutputGate<? extends Record> outputGate=env.getOutputGate(i);
    for (int j=0; j < outputGate.getNumberOfOutputChannels(); ++j) {
      final AbstractOutputChannel<? extends Record> outputChannel=outputGate.getOutputChannel(j);
      if (outputChannel.getType() == ChannelType.FILE) {
        continue;
      }
      final ChannelID connectedChannelID=outputChannel.getConnectedChannelID();
      final ExecutionVertex connectedVertex=eg.getVertexByChannelID(connectedChannelID);
      if (connectedVertex == null) {
        LOG.error(""String_Node_Str"");
        continue;
      }
      if (verticesToBeCanceled.contains(connectedVertex)) {
        continue;
      }
      final AbstractInstance instance=connectedVertex.getAllocatedResource().getInstance();
      Set<ChannelID> channelIDs=entriesToInvalidate.get(instance);
      if (channelIDs == null) {
        channelIDs=new SerializableHashSet<ChannelID>();
        entriesToInvalidate.put(instance,channelIDs);
      }
      channelIDs.add(connectedChannelID);
    }
  }
  for (int i=0; i < env.getNumberOfInputGates(); ++i) {
    final InputGate<? extends Record> inputGate=env.getInputGate(i);
    for (int j=0; j < inputGate.getNumberOfInputChannels(); ++j) {
      final AbstractInputChannel<? extends Record> inputChannel=inputGate.getInputChannel(j);
      if (inputChannel.getType() == ChannelType.FILE) {
        continue;
      }
      final ChannelID connectedChannelID=inputChannel.getConnectedChannelID();
      final ExecutionVertex connectedVertex=eg.getVertexByChannelID(connectedChannelID);
      if (connectedVertex == null) {
        LOG.error(""String_Node_Str"");
        continue;
      }
      if (verticesToBeCanceled.contains(connectedVertex)) {
        continue;
      }
      final AbstractInstance instance=connectedVertex.getAllocatedResource().getInstance();
      Set<ChannelID> channelIDs=entriesToInvalidate.get(instance);
      if (channelIDs == null) {
        channelIDs=new SerializableHashSet<ChannelID>();
        entriesToInvalidate.put(instance,channelIDs);
      }
      channelIDs.add(connectedChannelID);
    }
  }
  final Iterator<Map.Entry<AbstractInstance,Set<ChannelID>>> it=entriesToInvalidate.entrySet().iterator();
  while (it.hasNext()) {
    final Map.Entry<AbstractInstance,Set<ChannelID>> entry=it.next();
    final AbstractInstance instance=entry.getKey();
    try {
      instance.invalidateLookupCacheEntries(entry.getValue());
    }
 catch (    IOException ioe) {
      LOG.error(StringUtils.stringifyException(ioe));
      return false;
    }
  }
  return true;
}","private static final boolean invalidateReceiverLookupCaches(final ExecutionVertex failedVertex,final Set<ExecutionVertex> verticesToBeCanceled){
  final Map<AbstractInstance,Set<ChannelID>> entriesToInvalidate=new HashMap<AbstractInstance,Set<ChannelID>>();
  collectCacheEntriesToInvalidate(failedVertex,entriesToInvalidate);
  for (final Iterator<ExecutionVertex> it=verticesToBeCanceled.iterator(); it.hasNext(); ) {
    collectCacheEntriesToInvalidate(it.next(),entriesToInvalidate);
  }
  final Iterator<Map.Entry<AbstractInstance,Set<ChannelID>>> it=entriesToInvalidate.entrySet().iterator();
  while (it.hasNext()) {
    final Map.Entry<AbstractInstance,Set<ChannelID>> entry=it.next();
    final AbstractInstance instance=entry.getKey();
    try {
      instance.invalidateLookupCacheEntries(entry.getValue());
    }
 catch (    IOException ioe) {
      LOG.error(StringUtils.stringifyException(ioe));
      return false;
    }
  }
  return true;
}",0.3726770467101958
55619,"/** 
 * {@inheritDoc}
 */
@Override public boolean isCanceled(){
  if (this.encapsulatedTask != null) {
    if (this.encapsulatedTask.isCanceled()) {
      return true;
    }
  }
  return isCanceled;
}","/** 
 * {@inheritDoc}
 */
@Override public boolean isCanceled(){
  if (this.encapsulatedRuntimeTask != null) {
    if (this.encapsulatedRuntimeTask.isCanceled()) {
      return true;
    }
  }
  return isCanceled;
}",0.966346153846154
55620,"/** 
 * {@inheritDoc}
 */
@Override public boolean isTerminated(){
  if (this.encapsulatedTask != null) {
    if (this.encapsulatedTask.isTerminated()) {
      return true;
    }
  }
  final Thread executingThread=this.environment.getExecutingThread();
  if (executingThread.getState() == Thread.State.TERMINATED) {
    return true;
  }
  return false;
}","/** 
 * {@inheritDoc}
 */
@Override public boolean isTerminated(){
  if (this.encapsulatedTask != null) {
    if (this.encapsulatedTask.isTerminated()) {
      if (this.encapsulatedExecutionState != ExecutionState.FINISHED && this.encapsulatedExecutionState != ExecutionState.CANCELED && this.encapsulatedExecutionState != ExecutionState.FAILED) {
        return true;
      }
    }
  }
  final Thread executingThread=this.environment.getExecutingThread();
  if (executingThread.getState() == Thread.State.TERMINATED) {
    if (this.replayTaskExecutionState != ExecutionState.FINISHED && this.replayTaskExecutionState != ExecutionState.CANCELED && this.replayTaskExecutionState != ExecutionState.FAILED) {
      return true;
    }
  }
  return false;
}",0.6401446654611211
55621,"/** 
 * {@inheritDoc}
 */
@Override public void userThreadFinished(final Thread userThread){
  if (this.encapsulatedTask != null) {
    this.encapsulatedTask.userThreadFinished(userThread);
  }
 else {
    LOG.error(""String_Node_Str"");
  }
}","/** 
 * {@inheritDoc}
 */
@Override public void userThreadFinished(final Thread userThread){
  if (this.encapsulatedRuntimeTask != null) {
    this.encapsulatedRuntimeTask.userThreadFinished(userThread);
  }
 else {
    LOG.error(""String_Node_Str"");
  }
}",0.9717741935483872
55622,"/** 
 * {@inheritDoc}
 */
@Override public void markAsFailed(){
  this.replayTaskExecutionState=ExecutionState.FAILED;
  reportExecutionStateChange(true,""String_Node_Str"");
}","/** 
 * {@inheritDoc}
 */
@Override public void markAsFailed(){
  if (this.encapsulatedTask != null) {
    this.encapsulatedTask.killExecution();
  }
  this.replayTaskExecutionState=ExecutionState.FAILED;
  reportExecutionStateChange(true,""String_Node_Str"");
}",0.8018433179723502
55623,"private ReplayTaskExecutionObserver(final RuntimeTask encapsulatedTask){
  this.encapsulatedTask=encapsulatedTask;
}","private ReplayTaskExecutionObserver(final RuntimeTask encapsulatedRuntimeTask){
  this.encapsulatedRuntimeTask=encapsulatedRuntimeTask;
}",0.91699604743083
55624,"private static ExecutionState determineOverallExecutionState(final ExecutionState unchangedExecutionState,final ExecutionState changedExecutionState){
  if (changedExecutionState == null) {
    return changedExecutionState;
  }
  if (changedExecutionState == ExecutionState.REPLAYING) {
    if (unchangedExecutionState == ExecutionState.RUNNING) {
      return ExecutionState.REPLAYING;
    }
 else {
      return unchangedExecutionState;
    }
  }
  if (changedExecutionState == ExecutionState.CANCELING) {
    return ExecutionState.CANCELING;
  }
  if (changedExecutionState == ExecutionState.CANCELED && unchangedExecutionState == ExecutionState.CANCELED) {
    return ExecutionState.CANCELED;
  }
  if (changedExecutionState == ExecutionState.FINISHING && unchangedExecutionState == ExecutionState.FINISHING) {
    return ExecutionState.FINISHING;
  }
  if (changedExecutionState == ExecutionState.FINISHED && unchangedExecutionState == ExecutionState.FINISHED) {
    return ExecutionState.FINISHED;
  }
  return null;
}","private static ExecutionState determineOverallExecutionState(final ExecutionState unchangedExecutionState,final ExecutionState changedExecutionState){
  if (changedExecutionState == null) {
    return changedExecutionState;
  }
  if (changedExecutionState == ExecutionState.REPLAYING) {
    if (unchangedExecutionState == ExecutionState.RUNNING) {
      return ExecutionState.REPLAYING;
    }
 else {
      return unchangedExecutionState;
    }
  }
  if (changedExecutionState == ExecutionState.CANCELING) {
    return ExecutionState.CANCELING;
  }
  if (changedExecutionState == ExecutionState.CANCELED && unchangedExecutionState == ExecutionState.CANCELED) {
    return ExecutionState.CANCELED;
  }
  if (changedExecutionState == ExecutionState.FINISHING && unchangedExecutionState == ExecutionState.FINISHING) {
    return ExecutionState.FINISHING;
  }
  if (changedExecutionState == ExecutionState.FINISHED && unchangedExecutionState == ExecutionState.FINISHED) {
    return ExecutionState.FINISHED;
  }
  if (changedExecutionState == ExecutionState.FAILED && unchangedExecutionState == ExecutionState.FAILED) {
    return ExecutionState.FAILED;
  }
  return null;
}",0.9334548769371012
55625,"/** 
 * {@inheritDoc}
 */
@Override public void executionStateChanged(final ExecutionState newExecutionState,final String optionalMessage){
  if (this.encapsulatedTask == null) {
    replayTaskExecutionState=newExecutionState;
  }
 else {
    encapsulatedExecutionState=newExecutionState;
  }
  reportExecutionStateChange((this.encapsulatedTask == null),optionalMessage);
}","/** 
 * {@inheritDoc}
 */
@Override public void executionStateChanged(final ExecutionState newExecutionState,final String optionalMessage){
  if (this.encapsulatedRuntimeTask == null) {
    replayTaskExecutionState=newExecutionState;
    if (newExecutionState == ExecutionState.FAILED) {
      if (encapsulatedTask != null) {
        encapsulatedTask.killExecution();
      }
    }
  }
 else {
    encapsulatedExecutionState=newExecutionState;
    if (newExecutionState == ExecutionState.FAILED) {
      killExecution();
    }
  }
  reportExecutionStateChange((this.encapsulatedRuntimeTask == null),optionalMessage);
}",0.7527749747729566
55626,"/** 
 * {@inheritDoc}
 */
@Override public void userThreadStarted(final Thread userThread){
  if (this.encapsulatedTask != null) {
    this.encapsulatedTask.userThreadStarted(userThread);
  }
 else {
    LOG.error(""String_Node_Str"");
  }
}","/** 
 * {@inheritDoc}
 */
@Override public void userThreadStarted(final Thread userThread){
  if (this.encapsulatedRuntimeTask != null) {
    this.encapsulatedRuntimeTask.userThreadStarted(userThread);
  }
 else {
    LOG.error(""String_Node_Str"");
  }
}",0.9715447154471544
55627,"/** 
 * This method is periodically called by the framework to check the state of the task threads. If any task thread has unexpectedly switch to TERMINATED, this indicates that an   {@link Error} has occurredduring its execution.
 */
private void checkTaskExecution(){
  final List<Task> failedTasks=new ArrayList<Task>();
synchronized (this.runningTasks) {
    final Iterator<ExecutionVertexID> it=this.runningTasks.keySet().iterator();
    while (it.hasNext()) {
      final ExecutionVertexID executionVertexID=it.next();
      final Task task=this.runningTasks.get(executionVertexID);
      if (task.isTerminated()) {
        it.remove();
        failedTasks.add(task);
      }
    }
  }
  final Iterator<Task> it2=failedTasks.iterator();
  while (it2.hasNext()) {
    it2.next().markAsFailed();
  }
}","/** 
 * This method is periodically called by the framework to check the state of the task threads. If any task thread has unexpectedly switch to TERMINATED, this indicates that an   {@link Error} has occurredduring its execution.
 */
private void checkTaskExecution(){
  final Iterator<Task> it=this.runningTasks.values().iterator();
  while (it.hasNext()) {
    final Task task=it.next();
    if (task.isTerminated()) {
      task.markAsFailed();
    }
  }
}",0.4790513833992095
55628,"boolean hasFinished(){
  return (!this.forwardingChain.anyForwarderHasDataLeft());
}","boolean hasFinished(){
  this.incomingEventQueue.processQueuedEvents();
  return (!this.forwardingChain.anyForwarderHasDataLeft());
}",0.7741935483870968
55629,"/** 
 * {@inheritDoc}
 */
@Override public boolean hasDataLeft(){
  return (!this.closeAcknowledgementReceived);
}","/** 
 * {@inheritDoc}
 */
@Override public boolean hasDataLeft(){
  return false;
}",0.8223350253807107
55630,"/** 
 * {@inheritDoc}
 */
@Override public void processEvent(final AbstractEvent event){
  if (event instanceof ByteBufferedChannelCloseEvent) {
    this.closeAcknowledgementReceived=true;
  }
 else {
    System.out.println(""String_Node_Str"" + event);
  }
}","/** 
 * {@inheritDoc}
 */
@Override public void processEvent(final AbstractEvent event){
  if (event instanceof ByteBufferedChannelCloseEvent) {
    LOG.info(""String_Node_Str"");
  }
 else {
    LOG.warn(""String_Node_Str"" + event);
  }
}",0.640973630831643
55631,"private static ExecutionState determineOverallExecutionState(final ExecutionState unchangedExecutionState,final ExecutionState changedExecutionState){
  if (changedExecutionState == null) {
    return changedExecutionState;
  }
  if (changedExecutionState == ExecutionState.REPLAYING) {
    if (unchangedExecutionState == ExecutionState.RUNNING) {
      return ExecutionState.REPLAYING;
    }
 else {
      return unchangedExecutionState;
    }
  }
  if (changedExecutionState == ExecutionState.CANCELING) {
    return ExecutionState.CANCELING;
  }
  if (changedExecutionState == ExecutionState.CANCELED && unchangedExecutionState == ExecutionState.CANCELED) {
    return ExecutionState.CANCELED;
  }
  if (changedExecutionState == ExecutionState.FINISHING && unchangedExecutionState == ExecutionState.FINISHING) {
    return ExecutionState.FINISHING;
  }
  if (changedExecutionState == ExecutionState.FINISHED && unchangedExecutionState == ExecutionState.FINISHED) {
    return ExecutionState.FINISHED;
  }
  if (changedExecutionState == ExecutionState.FAILED && unchangedExecutionState == ExecutionState.FAILED) {
    return ExecutionState.FAILED;
  }
  return null;
}","private static ExecutionState determineOverallExecutionState(final ExecutionState unchangedExecutionState,final ExecutionState changedExecutionState){
  if (changedExecutionState == null) {
    return changedExecutionState;
  }
  if (changedExecutionState == ExecutionState.REPLAYING) {
    if (unchangedExecutionState == ExecutionState.RUNNING || unchangedExecutionState == ExecutionState.FINISHING) {
      return ExecutionState.REPLAYING;
    }
 else {
      return unchangedExecutionState;
    }
  }
  if (changedExecutionState == ExecutionState.CANCELING) {
    return ExecutionState.CANCELING;
  }
  if (changedExecutionState == ExecutionState.CANCELED && unchangedExecutionState == ExecutionState.CANCELED) {
    return ExecutionState.CANCELED;
  }
  if (changedExecutionState == ExecutionState.FINISHING && (unchangedExecutionState == ExecutionState.FINISHING || unchangedExecutionState == ExecutionState.FINISHED)) {
    return ExecutionState.FINISHING;
  }
  if (changedExecutionState == ExecutionState.FINISHED && unchangedExecutionState == ExecutionState.FINISHED) {
    return ExecutionState.FINISHED;
  }
  if (changedExecutionState == ExecutionState.FAILED && unchangedExecutionState == ExecutionState.FAILED) {
    return ExecutionState.FAILED;
  }
  return null;
}",0.9547123623011016
55632,"private void waitForAllOutputBrokerToFinish() throws IOException, InterruptedException {
  while (true) {
    boolean finished=true;
    final Iterator<ReplayOutputBroker> it=this.outputBrokerMap.values().iterator();
    while (it.hasNext()) {
      if (!it.next().hasFinished()) {
        finished=false;
      }
    }
    if (finished) {
      break;
    }
    Thread.sleep(SLEEPINTERVAL);
  }
}","private void waitForAllOutputBrokerToFinish() throws IOException, InterruptedException {
  while (!this.executionObserver.isCanceled()) {
    boolean finished=true;
    final Iterator<ReplayOutputBroker> it=this.outputBrokerMap.values().iterator();
    while (it.hasNext()) {
      if (!it.next().hasFinished()) {
        finished=false;
      }
    }
    if (finished) {
      break;
    }
    Thread.sleep(SLEEPINTERVAL);
  }
}",0.9515738498789348
55633,"/** 
 * {@inheritDoc}
 */
@Override public ConnectionInfoLookupResponse lookupConnectionInfo(final InstanceConnectionInfo caller,final JobID jobID,final ChannelID sourceChannelID){
  final ExecutionGraph eg=this.scheduler.getExecutionGraphByID(jobID);
  if (eg == null) {
    LOG.error(""String_Node_Str"" + jobID);
    return ConnectionInfoLookupResponse.createReceiverNotFound();
  }
  final AbstractOutputChannel<? extends Record> outputChannel=eg.getOutputChannelByID(sourceChannelID);
  if (outputChannel == null) {
    AbstractInputChannel<? extends Record> inputChannel=eg.getInputChannelByID(sourceChannelID);
    final ChannelID connectedChannelID=inputChannel.getConnectedChannelID();
    final ExecutionVertex connectedVertex=eg.getVertexByChannelID(connectedChannelID);
    final AbstractInstance assignedInstance=connectedVertex.getAllocatedResource().getInstance();
    if (assignedInstance == null) {
      LOG.error(""String_Node_Str"" + connectedChannelID + ""String_Node_Str"");
      return ConnectionInfoLookupResponse.createReceiverNotReady();
    }
    final ExecutionState executionState=connectedVertex.getExecutionState();
    if (executionState == ExecutionState.FINISHED) {
      return ConnectionInfoLookupResponse.createReceiverFoundAndReady();
    }
    if (executionState != ExecutionState.RUNNING && executionState != ExecutionState.REPLAYING && executionState != ExecutionState.FINISHING) {
      return ConnectionInfoLookupResponse.createReceiverNotReady();
    }
    if (assignedInstance.getInstanceConnectionInfo().equals(caller)) {
      return ConnectionInfoLookupResponse.createReceiverFoundAndReady(connectedChannelID);
    }
 else {
      return ConnectionInfoLookupResponse.createReceiverFoundAndReady(assignedInstance.getInstanceConnectionInfo());
    }
  }
  if (outputChannel.isBroadcastChannel()) {
    return multicastManager.lookupConnectionInfo(caller,jobID,sourceChannelID);
  }
 else {
    final ExecutionVertex targetVertex=eg.getVertexByChannelID(outputChannel.getConnectedChannelID());
    if (targetVertex == null) {
      LOG.error(""String_Node_Str"" + outputChannel.getConnectedChannelID());
      return ConnectionInfoLookupResponse.createReceiverNotFound();
    }
    final ExecutionState executionState=targetVertex.getExecutionState();
    if (executionState == ExecutionState.FINISHED) {
      return ConnectionInfoLookupResponse.createReceiverFinished();
    }
    if (executionState != ExecutionState.RUNNING && executionState != ExecutionState.REPLAYING && executionState != ExecutionState.FINISHING) {
      return ConnectionInfoLookupResponse.createReceiverNotReady();
    }
    final AbstractInstance assignedInstance=targetVertex.getAllocatedResource().getInstance();
    if (assignedInstance == null) {
      LOG.error(""String_Node_Str"" + outputChannel.getConnectedChannelID() + ""String_Node_Str"");
      return ConnectionInfoLookupResponse.createReceiverNotReady();
    }
    if (assignedInstance.getInstanceConnectionInfo().equals(caller)) {
      return ConnectionInfoLookupResponse.createReceiverFoundAndReady(outputChannel.getConnectedChannelID());
    }
 else {
      return ConnectionInfoLookupResponse.createReceiverFoundAndReady(assignedInstance.getInstanceConnectionInfo());
    }
  }
}","/** 
 * {@inheritDoc}
 */
@Override public ConnectionInfoLookupResponse lookupConnectionInfo(final InstanceConnectionInfo caller,final JobID jobID,final ChannelID sourceChannelID){
  final ExecutionGraph eg=this.scheduler.getExecutionGraphByID(jobID);
  if (eg == null) {
    LOG.error(""String_Node_Str"" + jobID);
    return ConnectionInfoLookupResponse.createReceiverNotFound();
  }
  final AbstractOutputChannel<? extends Record> outputChannel=eg.getOutputChannelByID(sourceChannelID);
  if (outputChannel == null) {
    AbstractInputChannel<? extends Record> inputChannel=eg.getInputChannelByID(sourceChannelID);
    final ChannelID connectedChannelID=inputChannel.getConnectedChannelID();
    final ExecutionVertex connectedVertex=eg.getVertexByChannelID(connectedChannelID);
    final AbstractInstance assignedInstance=connectedVertex.getAllocatedResource().getInstance();
    if (assignedInstance == null) {
      LOG.error(""String_Node_Str"" + connectedChannelID + ""String_Node_Str"");
      return ConnectionInfoLookupResponse.createReceiverNotReady();
    }
    final ExecutionState executionState=connectedVertex.getExecutionState();
    if (executionState == ExecutionState.FINISHED) {
      return ConnectionInfoLookupResponse.createReceiverFoundAndReady();
    }
    if (executionState != ExecutionState.RUNNING && executionState != ExecutionState.REPLAYING && executionState != ExecutionState.FINISHING) {
      return ConnectionInfoLookupResponse.createReceiverNotReady();
    }
    if (assignedInstance.getInstanceConnectionInfo().equals(caller)) {
      return ConnectionInfoLookupResponse.createReceiverFoundAndReady(connectedChannelID);
    }
 else {
      return ConnectionInfoLookupResponse.createReceiverFoundAndReady(assignedInstance.getInstanceConnectionInfo());
    }
  }
  if (outputChannel.isBroadcastChannel()) {
    return multicastManager.lookupConnectionInfo(caller,jobID,sourceChannelID);
  }
 else {
    final ExecutionVertex targetVertex=eg.getVertexByChannelID(outputChannel.getConnectedChannelID());
    if (targetVertex == null) {
      LOG.error(""String_Node_Str"" + outputChannel.getConnectedChannelID());
      return ConnectionInfoLookupResponse.createReceiverNotFound();
    }
    final ExecutionState executionState=targetVertex.getExecutionState();
    if (executionState != ExecutionState.RUNNING && executionState != ExecutionState.REPLAYING && executionState != ExecutionState.FINISHING && executionState != ExecutionState.FINISHED) {
      return ConnectionInfoLookupResponse.createReceiverNotReady();
    }
    final AbstractInstance assignedInstance=targetVertex.getAllocatedResource().getInstance();
    if (assignedInstance == null) {
      LOG.error(""String_Node_Str"" + outputChannel.getConnectedChannelID() + ""String_Node_Str"");
      return ConnectionInfoLookupResponse.createReceiverNotReady();
    }
    if (assignedInstance.getInstanceConnectionInfo().equals(caller)) {
      return ConnectionInfoLookupResponse.createReceiverFoundAndReady(outputChannel.getConnectedChannelID());
    }
 else {
      return ConnectionInfoLookupResponse.createReceiverFoundAndReady(assignedInstance.getInstanceConnectionInfo());
    }
  }
}",0.9732753262896208
55634,"public void runIOLoop(){
  long interval=GlobalConfiguration.getInteger(""String_Node_Str"",DEFAULTPERIODICTASKSINTERVAL);
  while (!Thread.interrupted()) {
    try {
      Thread.sleep(interval);
    }
 catch (    InterruptedException e1) {
      LOG.debug(""String_Node_Str"");
      break;
    }
    try {
      this.jobManager.sendHeartbeat(this.localInstanceConnectionInfo,this.hardwareDescription);
    }
 catch (    IOException e) {
      LOG.debug(""String_Node_Str"");
    }
    checkTaskExecution();
    this.byteBufferedChannelManager.cleanUpRecentlyRemovedChannelIDSet();
  }
  shutdown();
}","public void runIOLoop(){
  long interval=GlobalConfiguration.getInteger(""String_Node_Str"",DEFAULTPERIODICTASKSINTERVAL);
  while (!Thread.interrupted()) {
    try {
      Thread.sleep(interval);
    }
 catch (    InterruptedException e1) {
      LOG.debug(""String_Node_Str"");
      break;
    }
    try {
      this.jobManager.sendHeartbeat(this.localInstanceConnectionInfo,this.hardwareDescription);
    }
 catch (    IOException e) {
      LOG.debug(""String_Node_Str"");
    }
    checkTaskExecution();
  }
  shutdown();
}",0.9339285714285714
55635,"private void sendReceiverNotFoundEvent(final JobID jobID,final ChannelID unknownReceiver){
  if (ChannelID.SYSTEM_ID.equals(unknownReceiver)) {
    LOG.error(""String_Node_Str"");
    return;
  }
  final TransferEnvelope transferEnvelope=new TransferEnvelope(0,jobID,ChannelID.SYSTEM_ID);
  final UnknownReceiverEvent unknownReceiverEvent=new UnknownReceiverEvent(unknownReceiver);
  transferEnvelope.addEvent(unknownReceiverEvent);
  final TransferEnvelopeReceiverList receiverList=getReceiverList(jobID,unknownReceiver);
  if (receiverList == null) {
    LOG.error(""String_Node_Str"" + unknownReceiver);
    return;
  }
  processEnvelopeEnvelopeWithoutBuffer(transferEnvelope,receiverList);
}","private void sendReceiverNotFoundEvent(final TransferEnvelope envelope,final ChannelID unknownReceiver){
  if (ChannelID.SYSTEM_ID.equals(envelope.getSource())) {
    LOG.error(""String_Node_Str"");
    return;
  }
  final JobID jobID=envelope.getJobID();
  final TransferEnvelope transferEnvelope=new TransferEnvelope(0,jobID,ChannelID.SYSTEM_ID);
  final ReceiverNotFoundEvent unknownReceiverEvent=new ReceiverNotFoundEvent(unknownReceiver,envelope.getSequenceNumber());
  transferEnvelope.addEvent(unknownReceiverEvent);
  final TransferEnvelopeReceiverList receiverList=getReceiverList(jobID,unknownReceiver);
  if (receiverList == null) {
    LOG.error(""String_Node_Str"" + unknownReceiver);
    return;
  }
  processEnvelopeEnvelopeWithoutBuffer(transferEnvelope,receiverList);
}",0.8377460964019009
55636,"/** 
 * Unregisters the given task from the byte buffered channel manager.
 * @param vertexID the ID of the task to be unregistered
 * @param task the task to be unregistered
 */
public void unregister(final ExecutionVertexID vertexID,final Task task){
  final Environment environment=task.getEnvironment();
  this.recentlyRemovedChannelIDSet.add(environment);
  Iterator<ChannelID> channelIterator=environment.getOutputChannelIDs().iterator();
  while (channelIterator.hasNext()) {
    final ChannelID outputChannelID=channelIterator.next();
    final ChannelContext context=this.registeredChannels.remove(outputChannelID);
    if (context != null) {
      context.destroy();
    }
    this.receiverCache.remove(outputChannelID);
  }
  channelIterator=environment.getInputChannelIDs().iterator();
  while (channelIterator.hasNext()) {
    final ChannelID outputChannelID=channelIterator.next();
    final ChannelContext context=this.registeredChannels.remove(outputChannelID);
    if (context != null) {
      context.destroy();
    }
    this.receiverCache.remove(outputChannelID);
  }
  final Iterator<GateID> inputGateIterator=environment.getInputGateIDs().iterator();
  while (inputGateIterator.hasNext()) {
    final GateID inputGateID=inputGateIterator.next();
    final LocalBufferPoolOwner owner=this.localBufferPoolOwner.remove(inputGateID);
    if (owner != null) {
      owner.clearLocalBufferPool();
    }
  }
  final LocalBufferPoolOwner owner=this.localBufferPoolOwner.remove(vertexID);
  if (owner != null) {
    owner.clearLocalBufferPool();
  }
  redistributeGlobalBuffers();
}","/** 
 * Unregisters the given task from the byte buffered channel manager.
 * @param vertexID the ID of the task to be unregistered
 * @param task the task to be unregistered
 */
public void unregister(final ExecutionVertexID vertexID,final Task task){
  final Environment environment=task.getEnvironment();
  Iterator<ChannelID> channelIterator=environment.getOutputChannelIDs().iterator();
  while (channelIterator.hasNext()) {
    final ChannelID outputChannelID=channelIterator.next();
    final ChannelContext context=this.registeredChannels.remove(outputChannelID);
    if (context != null) {
      context.destroy();
    }
    this.receiverCache.remove(outputChannelID);
  }
  channelIterator=environment.getInputChannelIDs().iterator();
  while (channelIterator.hasNext()) {
    final ChannelID outputChannelID=channelIterator.next();
    final ChannelContext context=this.registeredChannels.remove(outputChannelID);
    if (context != null) {
      context.destroy();
    }
    this.receiverCache.remove(outputChannelID);
  }
  final Iterator<GateID> inputGateIterator=environment.getInputGateIDs().iterator();
  while (inputGateIterator.hasNext()) {
    final GateID inputGateID=inputGateIterator.next();
    final LocalBufferPoolOwner owner=this.localBufferPoolOwner.remove(inputGateID);
    if (owner != null) {
      owner.clearLocalBufferPool();
    }
  }
  final LocalBufferPoolOwner owner=this.localBufferPoolOwner.remove(vertexID);
  if (owner != null) {
    owner.clearLocalBufferPool();
  }
  redistributeGlobalBuffers();
}",0.9831048772712784
55637,"private TransferEnvelopeReceiverList getReceiverList(final JobID jobID,final ChannelID sourceChannelID){
  TransferEnvelopeReceiverList receiverList=this.receiverCache.get(sourceChannelID);
  if (receiverList == null) {
    try {
      while (true) {
        final ConnectionInfoLookupResponse lookupResponse=this.channelLookupService.lookupConnectionInfo(this.localConnectionInfo,jobID,sourceChannelID);
        if (lookupResponse.receiverNotFound()) {
          throw new IOException(""String_Node_Str"" + sourceChannelID);
        }
        if (lookupResponse.receiverNotReady()) {
          Thread.sleep(500);
          continue;
        }
        if (lookupResponse.receiverHasFinished()) {
          break;
        }
        if (lookupResponse.receiverReady()) {
          receiverList=new TransferEnvelopeReceiverList(lookupResponse);
          break;
        }
      }
      if (receiverList != null) {
        this.receiverCache.put(sourceChannelID,receiverList);
        if (LOG.isDebugEnabled()) {
          final StringBuilder sb=new StringBuilder();
          sb.append(""String_Node_Str"" + sourceChannelID + ""String_Node_Str""+ this.localConnectionInfo+ ""String_Node_Str"");
          if (receiverList.hasLocalReceivers()) {
            sb.append(""String_Node_Str"");
            final Iterator<ChannelID> it=receiverList.getLocalReceivers().iterator();
            while (it.hasNext()) {
              sb.append(""String_Node_Str"" + it.next() + ""String_Node_Str"");
            }
          }
          if (receiverList.hasRemoteReceivers()) {
            sb.append(""String_Node_Str"");
            final Iterator<InetSocketAddress> it=receiverList.getRemoteReceivers().iterator();
            while (it.hasNext()) {
              sb.append(""String_Node_Str"" + it.next() + ""String_Node_Str"");
            }
          }
          LOG.debug(sb.toString());
        }
      }
    }
 catch (    InterruptedException ie) {
    }
catch (    IOException ioe) {
    }
  }
  return receiverList;
}","private TransferEnvelopeReceiverList getReceiverList(final JobID jobID,final ChannelID sourceChannelID){
  TransferEnvelopeReceiverList receiverList=this.receiverCache.get(sourceChannelID);
  if (receiverList == null) {
    try {
      while (true) {
        final ConnectionInfoLookupResponse lookupResponse=this.channelLookupService.lookupConnectionInfo(this.localConnectionInfo,jobID,sourceChannelID);
        if (lookupResponse.receiverNotFound()) {
          throw new IOException(""String_Node_Str"" + sourceChannelID);
        }
        if (lookupResponse.receiverNotReady()) {
          Thread.sleep(500);
          continue;
        }
        if (lookupResponse.receiverReady()) {
          receiverList=new TransferEnvelopeReceiverList(lookupResponse);
          break;
        }
      }
      if (receiverList != null) {
        this.receiverCache.put(sourceChannelID,receiverList);
        if (LOG.isDebugEnabled()) {
          final StringBuilder sb=new StringBuilder();
          sb.append(""String_Node_Str"" + sourceChannelID + ""String_Node_Str""+ this.localConnectionInfo+ ""String_Node_Str"");
          if (receiverList.hasLocalReceivers()) {
            sb.append(""String_Node_Str"");
            final Iterator<ChannelID> it=receiverList.getLocalReceivers().iterator();
            while (it.hasNext()) {
              sb.append(""String_Node_Str"" + it.next() + ""String_Node_Str"");
            }
          }
          if (receiverList.hasRemoteReceivers()) {
            sb.append(""String_Node_Str"");
            final Iterator<InetSocketAddress> it=receiverList.getRemoteReceivers().iterator();
            while (it.hasNext()) {
              sb.append(""String_Node_Str"" + it.next() + ""String_Node_Str"");
            }
          }
          LOG.debug(sb.toString());
        }
      }
    }
 catch (    InterruptedException ie) {
    }
catch (    IOException ioe) {
    }
  }
  return receiverList;
}",0.9797798822626056
55638,"private void processEnvelopeWithBuffer(final TransferEnvelope transferEnvelope,final TransferEnvelopeReceiverList receiverList,final boolean freeSourceBuffer){
  if (!freeSourceBuffer) {
    final List<ChannelID> localReceivers=receiverList.getLocalReceivers();
    if (localReceivers.size() != 1) {
      LOG.error(""String_Node_Str"");
    }
    final ChannelID localReceiver=localReceivers.get(0);
    final ChannelContext cc=this.registeredChannels.get(localReceiver);
    if (cc == null) {
      if (!this.recentlyRemovedChannelIDSet.contains(localReceiver)) {
        sendReceiverNotFoundEvent(transferEnvelope.getJobID(),localReceiver);
      }
      recycleBuffer(transferEnvelope);
      return;
    }
    if (!cc.isInputChannel()) {
      LOG.error(""String_Node_Str"" + localReceiver + ""String_Node_Str"");
    }
    cc.queueTransferEnvelope(transferEnvelope);
    return;
  }
  final Buffer srcBuffer=transferEnvelope.getBuffer();
  if (receiverList.hasLocalReceivers()) {
    final List<ChannelID> localReceivers=receiverList.getLocalReceivers();
    for (    final ChannelID localReceiver : localReceivers) {
      final ChannelContext cc=this.registeredChannels.get(localReceiver);
      if (cc == null) {
        if (!this.recentlyRemovedChannelIDSet.contains(localReceiver)) {
          sendReceiverNotFoundEvent(transferEnvelope.getJobID(),localReceiver);
        }
        continue;
      }
      if (!cc.isInputChannel()) {
        LOG.error(""String_Node_Str"" + localReceiver + ""String_Node_Str"");
        continue;
      }
      final InputChannelContext inputChannelContext=(InputChannelContext)cc;
      Buffer destBuffer=null;
      try {
        destBuffer=inputChannelContext.requestEmptyBufferBlocking(srcBuffer.size());
        srcBuffer.copyToBuffer(destBuffer);
      }
 catch (      Exception e) {
        LOG.error(StringUtils.stringifyException(e));
        if (destBuffer != null) {
          destBuffer.recycleBuffer();
        }
        continue;
      }
      final TransferEnvelope dup=transferEnvelope.duplicateWithoutBuffer();
      dup.setBuffer(destBuffer);
      inputChannelContext.queueTransferEnvelope(dup);
    }
  }
  if (receiverList.hasRemoteReceivers()) {
    final List<InetSocketAddress> remoteReceivers=receiverList.getRemoteReceivers();
    for (    final InetSocketAddress remoteReceiver : remoteReceivers) {
      TransferEnvelope dup=null;
      try {
        dup=transferEnvelope.duplicate();
      }
 catch (      Exception e) {
        LOG.error(StringUtils.stringifyException(e));
        if (dup != null) {
          recycleBuffer(dup);
          continue;
        }
      }
      this.networkConnectionManager.queueEnvelopeForTransfer(remoteReceiver,dup);
    }
  }
  srcBuffer.recycleBuffer();
}","private void processEnvelopeWithBuffer(final TransferEnvelope transferEnvelope,final TransferEnvelopeReceiverList receiverList,final boolean freeSourceBuffer){
  if (!freeSourceBuffer) {
    final List<ChannelID> localReceivers=receiverList.getLocalReceivers();
    if (localReceivers.size() != 1) {
      LOG.error(""String_Node_Str"");
    }
    final ChannelID localReceiver=localReceivers.get(0);
    final ChannelContext cc=this.registeredChannels.get(localReceiver);
    if (cc == null) {
      sendReceiverNotFoundEvent(transferEnvelope,localReceiver);
      recycleBuffer(transferEnvelope);
      return;
    }
    if (!cc.isInputChannel()) {
      LOG.error(""String_Node_Str"" + localReceiver + ""String_Node_Str"");
    }
    cc.queueTransferEnvelope(transferEnvelope);
    return;
  }
  final Buffer srcBuffer=transferEnvelope.getBuffer();
  if (receiverList.hasLocalReceivers()) {
    final List<ChannelID> localReceivers=receiverList.getLocalReceivers();
    for (    final ChannelID localReceiver : localReceivers) {
      final ChannelContext cc=this.registeredChannels.get(localReceiver);
      if (cc == null) {
        sendReceiverNotFoundEvent(transferEnvelope,localReceiver);
        continue;
      }
      if (!cc.isInputChannel()) {
        LOG.error(""String_Node_Str"" + localReceiver + ""String_Node_Str"");
        continue;
      }
      final InputChannelContext inputChannelContext=(InputChannelContext)cc;
      Buffer destBuffer=null;
      try {
        destBuffer=inputChannelContext.requestEmptyBufferBlocking(srcBuffer.size());
        srcBuffer.copyToBuffer(destBuffer);
      }
 catch (      Exception e) {
        LOG.error(StringUtils.stringifyException(e));
        if (destBuffer != null) {
          destBuffer.recycleBuffer();
        }
        continue;
      }
      final TransferEnvelope dup=transferEnvelope.duplicateWithoutBuffer();
      dup.setBuffer(destBuffer);
      inputChannelContext.queueTransferEnvelope(dup);
    }
  }
  if (receiverList.hasRemoteReceivers()) {
    final List<InetSocketAddress> remoteReceivers=receiverList.getRemoteReceivers();
    for (    final InetSocketAddress remoteReceiver : remoteReceivers) {
      TransferEnvelope dup=null;
      try {
        dup=transferEnvelope.duplicate();
      }
 catch (      Exception e) {
        LOG.error(StringUtils.stringifyException(e));
        if (dup != null) {
          recycleBuffer(dup);
          continue;
        }
      }
      this.networkConnectionManager.queueEnvelopeForTransfer(remoteReceiver,dup);
    }
  }
  srcBuffer.recycleBuffer();
}",0.96467493423525
55639,"private boolean processEnvelopeEnvelopeWithoutBuffer(final TransferEnvelope transferEnvelope,final TransferEnvelopeReceiverList receiverList){
  final Iterator<ChannelID> localIt=receiverList.getLocalReceivers().iterator();
  while (localIt.hasNext()) {
    final ChannelID localReceiver=localIt.next();
    final ChannelContext channelContext=this.registeredChannels.get(localReceiver);
    if (channelContext == null) {
      if (LOG.isDebugEnabled()) {
        LOG.debug(""String_Node_Str"" + localReceiver + ""String_Node_Str""+ transferEnvelope.getJobID());
      }
      continue;
    }
    channelContext.queueTransferEnvelope(transferEnvelope);
  }
  final Iterator<InetSocketAddress> remoteIt=receiverList.getRemoteReceivers().iterator();
  while (remoteIt.hasNext()) {
    final InetSocketAddress remoteReceiver=remoteIt.next();
    this.networkConnectionManager.queueEnvelopeForTransfer(remoteReceiver,transferEnvelope);
  }
  return true;
}","private boolean processEnvelopeEnvelopeWithoutBuffer(final TransferEnvelope transferEnvelope,final TransferEnvelopeReceiverList receiverList){
  final Iterator<ChannelID> localIt=receiverList.getLocalReceivers().iterator();
  while (localIt.hasNext()) {
    final ChannelID localReceiver=localIt.next();
    final ChannelContext channelContext=this.registeredChannels.get(localReceiver);
    if (channelContext == null) {
      sendReceiverNotFoundEvent(transferEnvelope,localReceiver);
      continue;
    }
    channelContext.queueTransferEnvelope(transferEnvelope);
  }
  final Iterator<InetSocketAddress> remoteIt=receiverList.getRemoteReceivers().iterator();
  while (remoteIt.hasNext()) {
    final InetSocketAddress remoteReceiver=remoteIt.next();
    this.networkConnectionManager.queueEnvelopeForTransfer(remoteReceiver,transferEnvelope);
  }
  return true;
}",0.8942731277533039
55640,"@Override public BufferProvider getBufferProvider(final JobID jobID,final ChannelID sourceChannelID) throws IOException, InterruptedException {
  final TransferEnvelopeReceiverList receiverList=getReceiverList(jobID,sourceChannelID);
  if (receiverList.hasLocalReceivers() && !receiverList.hasRemoteReceivers()) {
    final List<ChannelID> localReceivers=receiverList.getLocalReceivers();
    if (localReceivers.size() == 1) {
      final ChannelID localReceiver=localReceivers.get(0);
      final ChannelContext cc=this.registeredChannels.get(localReceiver);
      if (cc == null) {
        if (this.recentlyRemovedChannelIDSet.contains(localReceiver)) {
          return this.transitBufferPool;
        }
 else {
          throw new IOException(""String_Node_Str"" + localReceiver);
        }
      }
      if (!cc.isInputChannel()) {
        throw new IOException(""String_Node_Str"" + localReceiver + ""String_Node_Str"");
      }
      final InputChannelContext icc=(InputChannelContext)cc;
      return icc;
    }
  }
  return this.transitBufferPool;
}","@Override public BufferProvider getBufferProvider(final JobID jobID,final ChannelID sourceChannelID) throws IOException, InterruptedException {
  final TransferEnvelopeReceiverList receiverList=getReceiverList(jobID,sourceChannelID);
  if (receiverList.hasLocalReceivers() && !receiverList.hasRemoteReceivers()) {
    final List<ChannelID> localReceivers=receiverList.getLocalReceivers();
    if (localReceivers.size() == 1) {
      final ChannelID localReceiver=localReceivers.get(0);
      final ChannelContext cc=this.registeredChannels.get(localReceiver);
      if (cc == null) {
        return this.transitBufferPool;
      }
      if (!cc.isInputChannel()) {
        throw new IOException(""String_Node_Str"" + localReceiver + ""String_Node_Str"");
      }
      final InputChannelContext icc=(InputChannelContext)cc;
      return icc;
    }
  }
  return this.transitBufferPool;
}",0.8386763185108583
55641,"/** 
 * {@inheritDoc}
 */
@Override public boolean hasDataLeft(){
  return (!this.closeAcknowledgementReceived);
}","/** 
 * {@inheritDoc}
 */
@Override public boolean hasDataLeft(){
  if (this.closeAcknowledgementReceived) {
    return false;
  }
  if ((this.lastSequenceNumberWithReceiverNotFound + 1) == this.sequenceNumber) {
    return false;
  }
  return true;
}",0.5698630136986301
55642,"/** 
 * {@inheritDoc}
 */
@Override public void processEvent(final AbstractEvent event){
  if (event instanceof ByteBufferedChannelCloseEvent) {
    this.closeAcknowledgementReceived=true;
  }
 else   if (event instanceof AbstractTaskEvent) {
    this.byteBufferedOutputChannel.processEvent(event);
  }
}","/** 
 * {@inheritDoc}
 */
@Override public void processEvent(final AbstractEvent event){
  if (event instanceof ByteBufferedChannelCloseEvent) {
    this.closeAcknowledgementReceived=true;
  }
 else   if (event instanceof ReceiverNotFoundEvent) {
    this.lastSequenceNumberWithReceiverNotFound=((ReceiverNotFoundEvent)event).getSequenceNumber();
  }
 else   if (event instanceof AbstractTaskEvent) {
    this.byteBufferedOutputChannel.processEvent(event);
  }
}",0.793733681462141
55643,"/** 
 * {@inheritDoc}
 */
@Override public List<TaskSubmissionResult> submitTasks(final List<TaskSubmissionWrapper> tasks) throws IOException {
  final List<TaskSubmissionResult> submissionResultList=new SerializableArrayList<TaskSubmissionResult>();
  final List<Task> tasksToStart=new ArrayList<Task>();
  for (  final TaskSubmissionWrapper tsw : tasks) {
    final RuntimeEnvironment re=tsw.getEnvironment();
    final ExecutionVertexID id=tsw.getVertexID();
    final Configuration jobConfiguration=tsw.getConfiguration();
    final Set<ChannelID> activeOutputChannels=tsw.getActiveOutputChannels();
    final Task task=createAndRegisterTask(id,jobConfiguration,re,activeOutputChannels);
    if (task == null) {
      final TaskSubmissionResult result=new TaskSubmissionResult(id,AbstractTaskResult.ReturnCode.TASK_NOT_FOUND);
      result.setDescription(""String_Node_Str"" + id + ""String_Node_Str"");
      LOG.error(result.getDescription());
      submissionResultList.add(result);
    }
 else {
      submissionResultList.add(new TaskSubmissionResult(id,AbstractTaskResult.ReturnCode.SUCCESS));
    }
    tasksToStart.add(task);
  }
  for (  final Task task : tasksToStart) {
    task.startExecution();
  }
  return submissionResultList;
}","/** 
 * {@inheritDoc}
 */
@Override public List<TaskSubmissionResult> submitTasks(final List<TaskSubmissionWrapper> tasks) throws IOException {
  final List<TaskSubmissionResult> submissionResultList=new SerializableArrayList<TaskSubmissionResult>();
  final List<Task> tasksToStart=new ArrayList<Task>();
  for (  final TaskSubmissionWrapper tsw : tasks) {
    final RuntimeEnvironment re=tsw.getEnvironment();
    final ExecutionVertexID id=tsw.getVertexID();
    final Configuration jobConfiguration=tsw.getConfiguration();
    final Set<ChannelID> activeOutputChannels=tsw.getActiveOutputChannels();
    final Task task=createAndRegisterTask(id,jobConfiguration,re,activeOutputChannels);
    if (task == null) {
      final TaskSubmissionResult result=new TaskSubmissionResult(id,AbstractTaskResult.ReturnCode.TASK_NOT_FOUND);
      result.setDescription(""String_Node_Str"" + re.getTaskNameWithIndex() + ""String_Node_Str""+ id+ ""String_Node_Str"");
      LOG.error(result.getDescription());
      submissionResultList.add(result);
    }
 else {
      submissionResultList.add(new TaskSubmissionResult(id,AbstractTaskResult.ReturnCode.SUCCESS));
      tasksToStart.add(task);
    }
  }
  for (  final Task task : tasksToStart) {
    task.startExecution();
  }
  return submissionResultList;
}",0.9566246056782336
55644,"private void waitForAllOutputBrokerToFinish() throws IOException, InterruptedException {
  while (true) {
    boolean finished=true;
    final Iterator<ReplayOutputBroker> it=this.outputBrokerMap.values().iterator();
    while (it.hasNext()) {
      if (it.next().hasFinished()) {
        finished=false;
      }
    }
    if (finished) {
      break;
    }
    Thread.sleep(SLEEPINTERVAL);
  }
}","private void waitForAllOutputBrokerToFinish() throws IOException, InterruptedException {
  while (true) {
    boolean finished=true;
    final Iterator<ReplayOutputBroker> it=this.outputBrokerMap.values().iterator();
    while (it.hasNext()) {
      if (!it.next().hasFinished()) {
        finished=false;
      }
    }
    if (finished) {
      break;
    }
    Thread.sleep(SLEEPINTERVAL);
  }
}",0.9987389659520808
55645,"/** 
 * This method computes the costs for an operator. It requires that all inputs are set and have a proper <tt>ShipStrategy</tt> set, which is not equal to <tt>NONE</tt>.
 * @param n The node to compute the costs for.
 */
public void costOperator(OptimizerNode n){
  if (n.getIncomingConnections() == null) {
    throw new CompilerException(""String_Node_Str"");
  }
  List<PactConnection> primConn=null;
  List<PactConnection> secConn=null;
{
    List<List<PactConnection>> conns=n.getIncomingConnections();
    if (conns.size() > 0) {
      primConn=conns.get(0);
    }
    if (conns.size() > 1) {
      secConn=conns.get(1);
    }
  }
  Costs globCost=new Costs();
  Costs locCost=new Costs();
  if (primConn != null && primConn.size() > 0) {
switch (primConn.get(0).getShipStrategy()) {
case NONE:
      throw new CompilerException(""String_Node_Str"");
case FORWARD:
case PARTITION_LOCAL_HASH:
    globCost.setNetworkCost(0);
  globCost.setSecondaryStorageCost(0);
break;
case PARTITION_HASH:
for (PactConnection c : primConn) getHashPartitioningCost(c,globCost);
break;
case PARTITION_RANGE:
getRangePartitionCost(primConn,globCost);
break;
case BROADCAST:
for (PactConnection c : primConn) getBroadcastCost(c,globCost);
break;
case SFR:
throw new CompilerException(""String_Node_Str"");
default :
throw new CompilerException(""String_Node_Str"" + primConn.get(0).getShipStrategy().name());
}
}
 else {
globCost.setNetworkCost(0);
globCost.setSecondaryStorageCost(0);
}
if (secConn != null) {
Costs secCost=new Costs();
switch (secConn.get(0).getShipStrategy()) {
case NONE:
throw new CompilerException(""String_Node_Str"");
case FORWARD:
case PARTITION_LOCAL_HASH:
secCost.setNetworkCost(0);
secCost.setSecondaryStorageCost(0);
break;
case PARTITION_HASH:
for (PactConnection c : secConn) getHashPartitioningCost(c,secCost);
break;
case PARTITION_RANGE:
getRangePartitionCost(secConn,secCost);
break;
case BROADCAST:
for (PactConnection c : secConn) getBroadcastCost(c,secCost);
break;
case SFR:
throw new CompilerException(""String_Node_Str"");
default :
throw new CompilerException(""String_Node_Str"" + secConn.get(0).getShipStrategy().name());
}
globCost.addCosts(secCost);
}
locCost.setNetworkCost(0);
switch (n.getLocalStrategy()) {
case NONE:
locCost.setNetworkCost(0);
locCost.setSecondaryStorageCost(0);
break;
case COMBININGSORT:
case SORT:
getLocalSortCost(n,primConn,locCost);
break;
case SORT_BOTH_MERGE:
getLocalDoubleSortMergeCost(n,primConn,secConn,locCost);
break;
case SORT_FIRST_MERGE:
getLocalSingleSortMergeCost(n,primConn,secConn,locCost);
break;
case SORT_SECOND_MERGE:
getLocalSingleSortMergeCost(n,secConn,primConn,locCost);
break;
case MERGE:
getLocalMergeCost(n,primConn,secConn,locCost);
break;
case SORT_SELF_NESTEDLOOP:
getLocalSortSelfNestedLoopCost(n,primConn,10,locCost);
break;
case SELF_NESTEDLOOP:
getLocalSelfNestedLoopCost(n,primConn,10,locCost);
break;
case HYBRIDHASH_FIRST:
getHybridHashCosts(n,primConn,secConn,locCost);
break;
case HYBRIDHASH_SECOND:
getHybridHashCosts(n,secConn,primConn,locCost);
break;
case MMHASH_FIRST:
getMainMemHashCosts(n,primConn,secConn,locCost);
break;
case MMHASH_SECOND:
getMainMemHashCosts(n,secConn,primConn,locCost);
break;
case NESTEDLOOP_BLOCKED_OUTER_FIRST:
getBlockNestedLoopsCosts(n,primConn,secConn,BlockResettableMutableObjectIterator.MIN_BUFFER_SIZE,locCost);
break;
case NESTEDLOOP_BLOCKED_OUTER_SECOND:
getBlockNestedLoopsCosts(n,secConn,primConn,BlockResettableMutableObjectIterator.MIN_BUFFER_SIZE,locCost);
break;
case NESTEDLOOP_STREAMED_OUTER_FIRST:
getStreamedNestedLoopsCosts(n,primConn,secConn,SpillingResettableIterator.MINIMUM_NUMBER_OF_BUFFERS * SpillingResettableIterator.MIN_BUFFER_SIZE,locCost);
break;
case NESTEDLOOP_STREAMED_OUTER_SECOND:
getStreamedNestedLoopsCosts(n,secConn,primConn,SpillingResettableIterator.MINIMUM_NUMBER_OF_BUFFERS * SpillingResettableIterator.MIN_BUFFER_SIZE,locCost);
break;
default :
throw new CompilerException(""String_Node_Str"" + n.getLocalStrategy().name());
}
globCost.addCosts(locCost);
n.setCosts(globCost);
}","/** 
 * This method computes the costs for an operator. It requires that all inputs are set and have a proper <tt>ShipStrategy</tt> set, which is not equal to <tt>NONE</tt>.
 * @param n The node to compute the costs for.
 */
public void costOperator(OptimizerNode n){
  if (n.getIncomingConnections() == null) {
    throw new CompilerException(""String_Node_Str"");
  }
  List<PactConnection> primConn=null;
  List<PactConnection> secConn=null;
{
    List<List<PactConnection>> conns=n.getIncomingConnections();
    if (conns.size() > 0) {
      primConn=conns.get(0);
    }
    if (conns.size() > 1) {
      secConn=conns.get(1);
    }
  }
  Costs globCost=new Costs();
  Costs locCost=new Costs();
  if (primConn != null && primConn.size() > 0) {
switch (primConn.get(0).getShipStrategy()) {
case NONE:
      throw new CompilerException(""String_Node_Str"");
case FORWARD:
case PARTITION_LOCAL_HASH:
    globCost.setNetworkCost(0);
  globCost.setSecondaryStorageCost(0);
break;
case PARTITION_HASH:
for (PactConnection c : primConn) getHashPartitioningCost(c,globCost);
break;
case PARTITION_RANGE:
getRangePartitionCost(primConn,globCost);
break;
case BROADCAST:
for (PactConnection c : primConn) getBroadcastCost(c,globCost);
break;
case SFR:
throw new CompilerException(""String_Node_Str"");
default :
throw new CompilerException(""String_Node_Str"" + primConn.get(0).getShipStrategy().name());
}
}
 else {
globCost.setNetworkCost(0);
globCost.setSecondaryStorageCost(0);
}
if (secConn != null && secConn.size() > 0) {
Costs secCost=new Costs();
switch (secConn.get(0).getShipStrategy()) {
case NONE:
throw new CompilerException(""String_Node_Str"");
case FORWARD:
case PARTITION_LOCAL_HASH:
secCost.setNetworkCost(0);
secCost.setSecondaryStorageCost(0);
break;
case PARTITION_HASH:
for (PactConnection c : secConn) getHashPartitioningCost(c,secCost);
break;
case PARTITION_RANGE:
getRangePartitionCost(secConn,secCost);
break;
case BROADCAST:
for (PactConnection c : secConn) getBroadcastCost(c,secCost);
break;
case SFR:
throw new CompilerException(""String_Node_Str"");
default :
throw new CompilerException(""String_Node_Str"" + secConn.get(0).getShipStrategy().name());
}
globCost.addCosts(secCost);
}
locCost.setNetworkCost(0);
switch (n.getLocalStrategy()) {
case NONE:
locCost.setNetworkCost(0);
locCost.setSecondaryStorageCost(0);
break;
case COMBININGSORT:
case SORT:
getLocalSortCost(n,primConn,locCost);
break;
case SORT_BOTH_MERGE:
getLocalDoubleSortMergeCost(n,primConn,secConn,locCost);
break;
case SORT_FIRST_MERGE:
getLocalSingleSortMergeCost(n,primConn,secConn,locCost);
break;
case SORT_SECOND_MERGE:
getLocalSingleSortMergeCost(n,secConn,primConn,locCost);
break;
case MERGE:
getLocalMergeCost(n,primConn,secConn,locCost);
break;
case SORT_SELF_NESTEDLOOP:
getLocalSortSelfNestedLoopCost(n,primConn,10,locCost);
break;
case SELF_NESTEDLOOP:
getLocalSelfNestedLoopCost(n,primConn,10,locCost);
break;
case HYBRIDHASH_FIRST:
getHybridHashCosts(n,primConn,secConn,locCost);
break;
case HYBRIDHASH_SECOND:
getHybridHashCosts(n,secConn,primConn,locCost);
break;
case MMHASH_FIRST:
getMainMemHashCosts(n,primConn,secConn,locCost);
break;
case MMHASH_SECOND:
getMainMemHashCosts(n,secConn,primConn,locCost);
break;
case NESTEDLOOP_BLOCKED_OUTER_FIRST:
getBlockNestedLoopsCosts(n,primConn,secConn,BlockResettableMutableObjectIterator.MIN_BUFFER_SIZE,locCost);
break;
case NESTEDLOOP_BLOCKED_OUTER_SECOND:
getBlockNestedLoopsCosts(n,secConn,primConn,BlockResettableMutableObjectIterator.MIN_BUFFER_SIZE,locCost);
break;
case NESTEDLOOP_STREAMED_OUTER_FIRST:
getStreamedNestedLoopsCosts(n,primConn,secConn,SpillingResettableIterator.MINIMUM_NUMBER_OF_BUFFERS * SpillingResettableIterator.MIN_BUFFER_SIZE,locCost);
break;
case NESTEDLOOP_STREAMED_OUTER_SECOND:
getStreamedNestedLoopsCosts(n,secConn,primConn,SpillingResettableIterator.MINIMUM_NUMBER_OF_BUFFERS * SpillingResettableIterator.MIN_BUFFER_SIZE,locCost);
break;
default :
throw new CompilerException(""String_Node_Str"" + n.getLocalStrategy().name());
}
globCost.addCosts(locCost);
n.setCosts(globCost);
}",0.9972852912142152
55646,"/** 
 * Private utility method that generates a candidate Match node, given fixed shipping strategies and a fixed local strategy.
 * @param target The list to put the alternatives in.
 * @param preds1 The predecessor node for the first input.
 * @param preds2 The predecessor node for the second input.
 * @param ss1 The shipping strategy for the first input.
 * @param ss2 The shipping strategy for the second input.
 * @param ls The local strategy.
 * @param outGp The global properties of the data that goes to the user function.
 * @param outLp The local properties of the data that goes to the user function.
 * @param estimator The cost estimator.
 */
private void createMatchAlternative(List<OptimizerNode> target,List<OptimizerNode> preds1,List<OptimizerNode> preds2,ShipStrategy ss1,ShipStrategy ss2,LocalStrategy ls,Order order,boolean grouped,LocalProperties outLpp,CostEstimator estimator){
  GlobalProperties gp1;
  GlobalProperties gp2;
  if (preds1.size() == 1) {
    gp1=PactConnection.getGlobalPropertiesAfterConnection(preds1.get(0),this,ss1);
  }
 else {
    gp1=new GlobalProperties();
  }
  if (preds2.size() == 1) {
    gp2=PactConnection.getGlobalPropertiesAfterConnection(preds2.get(0),this,ss2);
  }
 else {
    gp2=new GlobalProperties();
  }
  int[] keyPositions1=null;
  int[] keyPositions2=null;
  if (ss1 == ShipStrategy.FORWARD && ss2 == ShipStrategy.PARTITION_HASH) {
    keyPositions2=this.input1.get(0).getPartitionedFields();
  }
  if (ss2 == ShipStrategy.FORWARD && ss1 == ShipStrategy.PARTITION_HASH) {
    keyPositions1=this.input2.get(0).getPartitionedFields();
  }
  LocalProperties outLp=outLpp;
  GlobalProperties outGp=new GlobalProperties();
  outGp.setPartitioning(gp1.getPartitioning(),gp1.getPartitionedFields());
  outGp.setOrdering(gp1.getOrdering());
  if (outLpp == null) {
    int[] keyColumns=getPactContract().getKeyColumnNumbers(0);
    outLp=new LocalProperties();
    if (order != Order.NONE) {
      Ordering ordering=new Ordering();
      for (      int keyColumn : keyColumns) {
        ordering.appendOrdering(keyColumn,order);
      }
      outLp.setOrdering(ordering);
    }
 else {
      outLp.setOrdering(null);
    }
    outLp.setGrouped(grouped,new FieldSet(keyColumns));
  }
  MatchNode n=new MatchNode(this,preds1,preds2,this.input1,this.input2,outGp,outLp);
  for (  PactConnection c : n.input1) {
    c.setShipStrategy(ss1);
    c.setPartitionedFields(keyPositions1);
  }
  for (  PactConnection c : n.input2) {
    c.setShipStrategy(ss2);
    c.setPartitionedFields(keyPositions2);
  }
  n.setLocalStrategy(ls);
  n.getGlobalProperties().filterByNodesConstantSet(this,0);
  n.getLocalProperties().filterByNodesConstantSet(this,0);
  estimator.costOperator(n);
  target.add(n);
  outGp=new GlobalProperties();
  outGp.setPartitioning(gp2.getPartitioning(),gp2.getPartitionedFields());
  outGp.setOrdering(gp2.getOrdering());
  if (outLpp == null) {
    int[] keyColumns=getPactContract().getKeyColumnNumbers(1);
    outLp=new LocalProperties();
    if (order != Order.NONE) {
      Ordering ordering=new Ordering();
      for (      int keyColumn : keyColumns) {
        ordering.appendOrdering(keyColumn,order);
      }
      outLp.setOrdering(ordering);
    }
 else {
      outLp.setOrdering(null);
    }
    outLp.setGrouped(grouped,new FieldSet(keyColumns));
  }
  n=new MatchNode(this,preds1,preds2,input1,input2,outGp,outLp);
  for (  PactConnection c : n.input1) {
    c.setShipStrategy(ss1);
    c.setPartitionedFields(keyPositions1);
  }
  for (  PactConnection c : n.input2) {
    c.setShipStrategy(ss2);
    c.setPartitionedFields(keyPositions2);
  }
  n.setLocalStrategy(ls);
  n.getGlobalProperties().filterByNodesConstantSet(this,1);
  n.getLocalProperties().filterByNodesConstantSet(this,1);
  estimator.costOperator(n);
  target.add(n);
}","/** 
 * Private utility method that generates a candidate Match node, given fixed shipping strategies and a fixed local strategy.
 * @param target The list to put the alternatives in.
 * @param preds1 The predecessor node for the first input.
 * @param preds2 The predecessor node for the second input.
 * @param ss1 The shipping strategy for the first input.
 * @param ss2 The shipping strategy for the second input.
 * @param ls The local strategy.
 * @param outGp The global properties of the data that goes to the user function.
 * @param outLp The local properties of the data that goes to the user function.
 * @param estimator The cost estimator.
 */
private void createMatchAlternative(List<OptimizerNode> target,List<OptimizerNode> preds1,List<OptimizerNode> preds2,ShipStrategy ss1,ShipStrategy ss2,LocalStrategy ls,Order order,boolean grouped,LocalProperties outLpp,CostEstimator estimator){
  GlobalProperties gp1;
  GlobalProperties gp2;
  if (preds1.size() == 1) {
    gp1=PactConnection.getGlobalPropertiesAfterConnection(preds1.get(0),this,ss1);
  }
 else {
    gp1=new GlobalProperties();
  }
  if (preds2 != null && preds2.size() == 1) {
    gp2=PactConnection.getGlobalPropertiesAfterConnection(preds2.get(0),this,ss2);
  }
 else {
    gp2=new GlobalProperties();
  }
  int[] keyPositions1=null;
  int[] keyPositions2=null;
  if (ss1 == ShipStrategy.FORWARD && ss2 == ShipStrategy.PARTITION_HASH) {
    keyPositions2=this.input1.get(0).getPartitionedFields();
  }
  if (ss2 == ShipStrategy.FORWARD && ss1 == ShipStrategy.PARTITION_HASH) {
    keyPositions1=this.input2.get(0).getPartitionedFields();
  }
  LocalProperties outLp=outLpp;
  GlobalProperties outGp=new GlobalProperties();
  outGp.setPartitioning(gp1.getPartitioning(),gp1.getPartitionedFields());
  outGp.setOrdering(gp1.getOrdering());
  if (outLpp == null) {
    int[] keyColumns=getPactContract().getKeyColumnNumbers(0);
    outLp=new LocalProperties();
    if (order != Order.NONE) {
      Ordering ordering=new Ordering();
      for (      int keyColumn : keyColumns) {
        ordering.appendOrdering(keyColumn,order);
      }
      outLp.setOrdering(ordering);
    }
 else {
      outLp.setOrdering(null);
    }
    outLp.setGrouped(grouped,new FieldSet(keyColumns));
  }
  MatchNode n=new MatchNode(this,preds1,preds2,this.input1,this.input2,outGp,outLp);
  for (  PactConnection c : n.input1) {
    c.setShipStrategy(ss1);
    c.setPartitionedFields(keyPositions1);
  }
  for (  PactConnection c : n.input2) {
    c.setShipStrategy(ss2);
    c.setPartitionedFields(keyPositions2);
  }
  n.setLocalStrategy(ls);
  n.getGlobalProperties().filterByNodesConstantSet(this,0);
  n.getLocalProperties().filterByNodesConstantSet(this,0);
  estimator.costOperator(n);
  target.add(n);
  outGp=new GlobalProperties();
  outGp.setPartitioning(gp2.getPartitioning(),gp2.getPartitionedFields());
  outGp.setOrdering(gp2.getOrdering());
  if (outLpp == null) {
    int[] keyColumns=getPactContract().getKeyColumnNumbers(1);
    outLp=new LocalProperties();
    if (order != Order.NONE) {
      Ordering ordering=new Ordering();
      for (      int keyColumn : keyColumns) {
        ordering.appendOrdering(keyColumn,order);
      }
      outLp.setOrdering(ordering);
    }
 else {
      outLp.setOrdering(null);
    }
    outLp.setGrouped(grouped,new FieldSet(keyColumns));
  }
  n=new MatchNode(this,preds1,preds2,input1,input2,outGp,outLp);
  for (  PactConnection c : n.input1) {
    c.setShipStrategy(ss1);
    c.setPartitionedFields(keyPositions1);
  }
  for (  PactConnection c : n.input2) {
    c.setShipStrategy(ss2);
    c.setPartitionedFields(keyPositions2);
  }
  n.setLocalStrategy(ls);
  n.getGlobalProperties().filterByNodesConstantSet(this,1);
  n.getLocalProperties().filterByNodesConstantSet(this,1);
  estimator.costOperator(n);
  target.add(n);
}",0.9976525821596244
55647,"/** 
 * {@inheritDoc}
 */
@Override public void vertexAssignmentChanged(final ExecutionVertexID id,final AllocatedResource newAllocatedResource){
  final ManagementVertexID managementVertexID=id.toManagementVertexID();
  final long timestamp=System.currentTimeMillis();
  final AbstractInstance instance=newAllocatedResource.getInstance();
  VertexAssignmentEvent event;
  if (instance == null) {
    event=new VertexAssignmentEvent(timestamp,managementVertexID,""String_Node_Str"",""String_Node_Str"");
  }
 else {
    event=new VertexAssignmentEvent(timestamp,managementVertexID,instance.getName(),instance.getType().getIdentifier());
  }
  this.eventCollector.updateManagementGraph(jobID,event);
  this.eventCollector.addEvent(this.jobID,event);
}","/** 
 * {@inheritDoc}
 */
@Override public void vertexAssignmentChanged(final ExecutionVertexID id,final AllocatedResource newAllocatedResource){
  final ManagementVertexID managementVertexID=id.toManagementVertexID();
  final long timestamp=System.currentTimeMillis();
  final AbstractInstance instance=newAllocatedResource.getInstance();
  VertexAssignmentEvent event;
  if (instance == null) {
    event=new VertexAssignmentEvent(timestamp,managementVertexID,""String_Node_Str"",""String_Node_Str"");
  }
 else {
    String instanceName=null;
    if (instance.getInstanceConnectionInfo() != null) {
      instanceName=instance.getInstanceConnectionInfo().toString();
    }
 else {
      instanceName=instance.toString();
    }
    event=new VertexAssignmentEvent(timestamp,managementVertexID,instanceName,instance.getType().getIdentifier());
  }
  this.eventCollector.updateManagementGraph(jobID,event);
  this.eventCollector.addEvent(this.jobID,event);
}",0.8705882352941177
55648,"private static final boolean invalidateReceiverLookupCaches(final ExecutionVertex failedVertex,final Set<ExecutionVertex> verticesToBeCanceled){
  final Map<AbstractInstance,Set<ChannelID>> entriesToInvalidate=new HashMap<AbstractInstance,Set<ChannelID>>();
  final ExecutionGraph eg=failedVertex.getExecutionGraph();
  final Environment env=failedVertex.getEnvironment();
  for (int i=0; i < env.getNumberOfOutputGates(); ++i) {
    final OutputGate<? extends Record> outputGate=env.getOutputGate(i);
    for (int j=0; j < outputGate.getNumberOfOutputChannels(); ++j) {
      final AbstractOutputChannel<? extends Record> outputChannel=outputGate.getOutputChannel(j);
      if (outputChannel.getType() == ChannelType.FILE) {
        continue;
      }
      final ExecutionVertex connectedVertex=eg.getVertexByChannelID(outputChannel.getConnectedChannelID());
      if (connectedVertex == null) {
        LOG.error(""String_Node_Str"");
        continue;
      }
      if (verticesToBeCanceled.contains(connectedVertex)) {
        continue;
      }
      final AbstractInstance instance=connectedVertex.getAllocatedResource().getInstance();
      Set<ChannelID> channelIDs=entriesToInvalidate.get(instance);
      if (channelIDs == null) {
        channelIDs=new SerializableHashSet<ChannelID>();
        entriesToInvalidate.put(instance,channelIDs);
      }
      channelIDs.add(outputChannel.getID());
    }
  }
  for (int i=0; i < env.getNumberOfInputGates(); ++i) {
    final InputGate<? extends Record> inputGate=env.getInputGate(i);
    for (int j=0; j < inputGate.getNumberOfInputChannels(); ++j) {
      final AbstractInputChannel<? extends Record> inputChannel=inputGate.getInputChannel(j);
      if (inputChannel.getType() == ChannelType.FILE) {
        continue;
      }
      final ExecutionVertex connectedVertex=eg.getVertexByChannelID(inputChannel.getConnectedChannelID());
      if (connectedVertex == null) {
        LOG.error(""String_Node_Str"");
        continue;
      }
      if (verticesToBeCanceled.contains(connectedVertex)) {
        continue;
      }
      final AbstractInstance instance=connectedVertex.getAllocatedResource().getInstance();
      Set<ChannelID> channelIDs=entriesToInvalidate.get(instance);
      if (channelIDs == null) {
        channelIDs=new SerializableHashSet<ChannelID>();
        entriesToInvalidate.put(instance,channelIDs);
      }
      channelIDs.add(inputChannel.getID());
    }
  }
  final Iterator<Map.Entry<AbstractInstance,Set<ChannelID>>> it=entriesToInvalidate.entrySet().iterator();
  while (it.hasNext()) {
    final Map.Entry<AbstractInstance,Set<ChannelID>> entry=it.next();
    final AbstractInstance instance=entry.getKey();
    try {
      instance.invalidateLookupCacheEntries(entry.getValue());
    }
 catch (    IOException ioe) {
      LOG.error(StringUtils.stringifyException(ioe));
      return false;
    }
  }
  return true;
}","private static final boolean invalidateReceiverLookupCaches(final ExecutionVertex failedVertex,final Set<ExecutionVertex> verticesToBeCanceled){
  final Map<AbstractInstance,Set<ChannelID>> entriesToInvalidate=new HashMap<AbstractInstance,Set<ChannelID>>();
  final ExecutionGraph eg=failedVertex.getExecutionGraph();
  final Environment env=failedVertex.getEnvironment();
  for (int i=0; i < env.getNumberOfOutputGates(); ++i) {
    final OutputGate<? extends Record> outputGate=env.getOutputGate(i);
    for (int j=0; j < outputGate.getNumberOfOutputChannels(); ++j) {
      final AbstractOutputChannel<? extends Record> outputChannel=outputGate.getOutputChannel(j);
      if (outputChannel.getType() == ChannelType.FILE) {
        continue;
      }
      final ChannelID connectedChannelID=outputChannel.getConnectedChannelID();
      final ExecutionVertex connectedVertex=eg.getVertexByChannelID(connectedChannelID);
      if (connectedVertex == null) {
        LOG.error(""String_Node_Str"");
        continue;
      }
      if (verticesToBeCanceled.contains(connectedVertex)) {
        continue;
      }
      final AbstractInstance instance=connectedVertex.getAllocatedResource().getInstance();
      Set<ChannelID> channelIDs=entriesToInvalidate.get(instance);
      if (channelIDs == null) {
        channelIDs=new SerializableHashSet<ChannelID>();
        entriesToInvalidate.put(instance,channelIDs);
      }
      channelIDs.add(connectedChannelID);
    }
  }
  for (int i=0; i < env.getNumberOfInputGates(); ++i) {
    final InputGate<? extends Record> inputGate=env.getInputGate(i);
    for (int j=0; j < inputGate.getNumberOfInputChannels(); ++j) {
      final AbstractInputChannel<? extends Record> inputChannel=inputGate.getInputChannel(j);
      if (inputChannel.getType() == ChannelType.FILE) {
        continue;
      }
      final ChannelID connectedChannelID=inputChannel.getConnectedChannelID();
      final ExecutionVertex connectedVertex=eg.getVertexByChannelID(connectedChannelID);
      if (connectedVertex == null) {
        LOG.error(""String_Node_Str"");
        continue;
      }
      if (verticesToBeCanceled.contains(connectedVertex)) {
        continue;
      }
      final AbstractInstance instance=connectedVertex.getAllocatedResource().getInstance();
      Set<ChannelID> channelIDs=entriesToInvalidate.get(instance);
      if (channelIDs == null) {
        channelIDs=new SerializableHashSet<ChannelID>();
        entriesToInvalidate.put(instance,channelIDs);
      }
      channelIDs.add(connectedChannelID);
    }
  }
  final Iterator<Map.Entry<AbstractInstance,Set<ChannelID>>> it=entriesToInvalidate.entrySet().iterator();
  while (it.hasNext()) {
    final Map.Entry<AbstractInstance,Set<ChannelID>> entry=it.next();
    final AbstractInstance instance=entry.getKey();
    try {
      instance.invalidateLookupCacheEntries(entry.getValue());
    }
 catch (    IOException ioe) {
      LOG.error(StringUtils.stringifyException(ioe));
      return false;
    }
  }
  return true;
}",0.9545684850532004
55649,"/** 
 * Cancels all the tasks in the current and upper stages of the given execution graph.
 * @param eg the execution graph representing the job to cancel.
 * @return <code>null</code> no error occurred during the cancel attempt,otherwise the returned object will describe the error
 */
private TaskCancelResult cancelJob(final ExecutionGraph eg){
  TaskCancelResult errorResult=null;
  final Iterator<ExecutionVertex> it=new ExecutionGraphIterator(eg,eg.getIndexOfCurrentExecutionStage(),false,true);
  while (it.hasNext()) {
    final ExecutionVertex vertex=it.next();
    final TaskCancelResult result=vertex.cancelTask();
    if (result.getReturnCode() == AbstractTaskResult.ReturnCode.ERROR) {
      errorResult=result;
    }
  }
  return errorResult;
}","/** 
 * Cancels all the tasks in the current and upper stages of the given execution graph.
 * @param eg the execution graph representing the job to cancel.
 * @return <code>null</code> if no error occurred during the cancel attempt,otherwise the returned object will describe the error
 */
private TaskCancelResult cancelJob(final ExecutionGraph eg){
  TaskCancelResult errorResult=null;
  final Iterator<ExecutionVertex> it=new ExecutionGraphIterator(eg,eg.getIndexOfCurrentExecutionStage(),false,true);
  while (it.hasNext()) {
    final ExecutionVertex vertex=it.next();
    final TaskCancelResult result=vertex.cancelTask();
    if (result.getReturnCode() == AbstractTaskResult.ReturnCode.ERROR) {
      errorResult=result;
    }
  }
  return errorResult;
}",0.9980276134122288
55650,"/** 
 * Returns the associated   {@link Contract} type for the given {@link Stub} class.
 * @param stubClass the stub class
 * @return the associated Contract type
 */
@SuppressWarnings({""String_Node_Str""}) public static Class<? extends Contract> getContractClass(final Class<?> stubClass){
  final Class<?> contract=STUB_CONTRACTS.get(stubClass);
  if (contract == null && stubClass != null)   return getContractClass(stubClass.getSuperclass());
  return (Class<? extends Contract>)contract;
}","/** 
 * Returns the associated   {@link Contract} type for the given {@link Stub} class.
 * @param stubClass the stub class
 * @return the associated Contract type
 */
@SuppressWarnings({""String_Node_Str""}) public static Class<? extends Contract> getContractClass(final Class<?> stubClass){
  if (stubClass == null)   return null;
  final Class<?> contract=STUB_CONTRACTS.get(stubClass);
  if (contract != null)   return (Class<? extends Contract>)contract;
  Iterator<Entry<Class<?>,Class<? extends Contract>>> stubContracts=STUB_CONTRACTS.entrySet().iterator();
  while (stubContracts.hasNext()) {
    Map.Entry<Class<?>,Class<? extends Contract>> entry=stubContracts.next();
    if (entry.getKey().isAssignableFrom(stubClass))     return entry.getValue();
  }
  return null;
}",0.617439120188531
55651,"private void initAdhocInputs() throws IOException {
  for (  final FileDataSource source : this.sources) {
    final TestPairs input=this.getInput(source);
    if (input.isAdhoc())     input.saveToFile(source.getFilePath());
  }
}","private void initAdhocInputs() throws IOException {
  for (  final FileDataSource source : this.sources) {
    final TestRecords input=this.getInput(source);
    if (input.isAdhoc())     input.saveToFile(source.getFilePath());
  }
}",0.5670995670995671
55652,"/** 
 * Returns the input   {@link TestPairs} associated with the <i>i</i>th inputof the TestPlan. If multiple contracts are tested in the TestPlan, it is recommended to use the  {@link #getInput(GenericDataSource<?>)} method tounambiguously set the values.
 * @param number the number of the input.
 * @return the <i>i</i>th input of the TestPlan
 */
public TestPairs getInput(final int number){
  return this.getInput(this.getDataSources().get(number));
}","/** 
 * Returns the input   {@link TestPairs} associated with the <i>i</i>th inputof the TestPlan. If multiple contracts are tested in the TestPlan, it is recommended to use the  {@link #getInput(GenericDataSource<?>)} method tounambiguously set the values.
 * @param number the number of the input.
 * @return the <i>i</i>th input of the TestPlan
 */
public TestRecords getInput(final int number){
  return this.getInput(this.getDataSources().get(number));
}",0.9890829694323144
55653,"/** 
 * Returns the output   {@link TestPairs} associated with the <i>i</i>thoutput of the TestPlan. If multiple contracts are tested in the TestPlan, it is recommended to use the  {@link #getActualOutput(GenericDataSink)} method to unambiguously get thevalues.<br> The values are only meaningful after a  {@link #run()}.
 * @param number the number of the output.
 * @return the <i>i</i>th output of the TestPlan
 */
public TestPairs getActualOutput(final int number){
  return this.getActualOutput(this.getDataSinks().get(number));
}","/** 
 * Returns the output   {@link TestPairs} associated with the <i>i</i>thoutput of the TestPlan. If multiple contracts are tested in the TestPlan, it is recommended to use the  {@link #getActualOutput(GenericDataSink)} method to unambiguously get thevalues.<br> The values are only meaningful after a  {@link #run()}.
 * @param number the number of the output.
 * @return the <i>i</i>th output of the TestPlan
 */
public TestRecords getActualOutput(final int number){
  return this.getActualOutput(this.getDataSinks().get(number));
}",0.9906716417910448
55654,"/** 
 * Returns the expected output   {@link TestPairs} associated with the<i>i</i>th expected output of the TestPlan. If multiple contracts are tested in the TestPlan, it is recommended to use the  {@link #getExpectedOutput(GenericDataSink)} method tounambiguously set the values.
 * @param number the number of the expected output.
 * @return the <i>i</i>th expected output of the TestPlan
 */
public TestPairs getExpectedOutput(final int number,Class<? extends Value>[] schema){
  return this.getExpectedOutput(this.getDataSinks().get(number),schema);
}","/** 
 * Returns the expected output   {@link TestPairs} associated with the<i>i</i>th expected output of the TestPlan. If multiple contracts are tested in the TestPlan, it is recommended to use the  {@link #getExpectedOutput(GenericDataSink)} method tounambiguously set the values.
 * @param number the number of the expected output.
 * @return the <i>i</i>th expected output of the TestPlan
 */
public TestRecords getExpectedOutput(final int number,Class<? extends Value>[] schema){
  return this.getExpectedOutput(this.getDataSinks().get(number),schema);
}",0.9910233393177738
55655,"@Override public void close() throws IOException {
  ClosableManager closableManager=new ClosableManager();
  for (  TestPairs pairs : this.inputs.values())   closableManager.add(pairs);
  for (  TestPairs pairs : this.actualOutputs.values())   closableManager.add(pairs);
  for (  TestPairs pairs : this.expectedOutputs.values())   closableManager.add(pairs);
  closableManager.close();
}","@Override public void close() throws IOException {
  ClosableManager closableManager=new ClosableManager();
  for (  TestRecords pairs : this.inputs.values())   closableManager.add(pairs);
  for (  TestRecords pairs : this.actualOutputs.values())   closableManager.add(pairs);
  for (  TestRecords pairs : this.expectedOutputs.values())   closableManager.add(pairs);
  closableManager.close();
}",0.9617346938775512
55656,"/** 
 * Actually builds the plan but guarantees that the output can be read without additional knowledge. Currently the   {@link SequentialOutputFormat} is used for a guaranteeddeserializable output.<br> If a data source is not  {@link SequentialOutputFormat}, it is replaced by a   {@link SplittingOutputFormat}, with two outputs: the original one and one   {@link SequentialOutputFormat}.
 */
private Plan buildPlanWithReadableSinks(){
  final Collection<FileDataSink> existingSinks=this.getDataSinks();
  final Collection<GenericDataSink> wrappedSinks=new ArrayList<GenericDataSink>();
  for (  final FileDataSink fileSink : existingSinks)   if (!fileSink.getFormatClass().equals(SequentialOutputFormat.class)) {
    TestPairs expectedValues=this.expectedOutputs.get(fileSink);
    if (expectedValues == null)     continue;
    final FileDataSink safeSink=createDefaultSink(fileSink.getName());
    safeSink.setInputs(fileSink.getInputs());
    wrappedSinks.add(fileSink);
    wrappedSinks.add(safeSink);
    this.expectedOutputs.put(safeSink,expectedValues);
    this.actualOutputs.put(safeSink,this.getActualOutput(fileSink));
    this.getActualOutput(fileSink).fromFile(SequentialInputFormat.class,safeSink.getFilePath());
  }
 else {
    wrappedSinks.add(fileSink);
    this.getActualOutput(fileSink).fromFile(SequentialInputFormat.class,fileSink.getFilePath());
  }
  return new Plan(wrappedSinks);
}","/** 
 * Actually builds the plan but guarantees that the output can be read without additional knowledge. Currently the   {@link SequentialOutputFormat} is used for a guaranteeddeserializable output.<br> If a data source is not  {@link SequentialOutputFormat}, it is replaced by a   {@link SplittingOutputFormat}, with two outputs: the original one and one   {@link SequentialOutputFormat}.
 */
private Plan buildPlanWithReadableSinks(){
  final Collection<FileDataSink> existingSinks=this.getDataSinks();
  final Collection<GenericDataSink> wrappedSinks=new ArrayList<GenericDataSink>();
  for (  final FileDataSink fileSink : existingSinks)   if (!fileSink.getFormatClass().equals(SequentialOutputFormat.class)) {
    TestRecords expectedValues=this.expectedOutputs.get(fileSink);
    if (expectedValues == null)     continue;
    final FileDataSink safeSink=createDefaultSink(fileSink.getName());
    safeSink.setInputs(fileSink.getInputs());
    wrappedSinks.add(fileSink);
    wrappedSinks.add(safeSink);
    this.expectedOutputs.put(safeSink,expectedValues);
    this.actualOutputs.put(safeSink,this.getActualOutput(fileSink));
    this.getActualOutput(fileSink).fromFile(SequentialInputFormat.class,safeSink.getFilePath());
  }
 else {
    wrappedSinks.add(fileSink);
    this.getActualOutput(fileSink).fromFile(SequentialInputFormat.class,fileSink.getFilePath());
  }
  return new Plan(wrappedSinks);
}",0.9964513839602556
55657,"private void validateResults(){
  for (  final FileDataSink sinkContract : this.getDataSinks()) {
    TestPairs expectedValues=this.expectedOutputs.get(sinkContract);
    if (sinkContract.getFormatClass() == SequentialOutputFormat.class && expectedValues != null && expectedValues.isInitialized()) {
      final TestPairs actualValues=new TestPairs();
      actualValues.fromFile(SequentialInputFormat.class,sinkContract.getFilePath());
      FuzzyTestValueMatcher fuzzyMatcher=this.getFuzzyMatcher(sinkContract);
      FuzzyTestValueSimilarity fuzzySimilarity=this.getFuzzySimilarity(sinkContract);
      try {
        actualValues.assertEquals(expectedValues,fuzzyMatcher,fuzzySimilarity);
      }
 catch (      AssertionError e) {
        AssertionError assertionError=new AssertionError(sinkContract.getName() + ""String_Node_Str"" + e.getMessage());
        assertionError.initCause(e.getCause());
        throw assertionError;
      }
    }
  }
}","private void validateResults(){
  for (  final FileDataSink sinkContract : this.getDataSinks()) {
    TestRecords expectedValues=this.expectedOutputs.get(sinkContract);
    if (sinkContract.getFormatClass() == SequentialOutputFormat.class && expectedValues != null && expectedValues.isInitialized()) {
      final TestRecords actualValues=new TestRecords();
      actualValues.fromFile(SequentialInputFormat.class,sinkContract.getFilePath());
      FuzzyTestValueMatcher fuzzyMatcher=this.getFuzzyMatcher(sinkContract);
      FuzzyTestValueSimilarity fuzzySimilarity=this.getFuzzySimilarity(sinkContract);
      try {
        actualValues.assertEquals(expectedValues,fuzzyMatcher,fuzzySimilarity);
      }
 catch (      AssertionError e) {
        AssertionError assertionError=new AssertionError(sinkContract.getName() + ""String_Node_Str"" + e.getMessage());
        assertionError.initCause(e.getCause());
        throw assertionError;
      }
    }
  }
}",0.9842602308499476
55658,"/** 
 * Updates the binary representation of the data, such that it reflects the state of the currently stored fields. If the binary representation is already up to date, nothing happens. Otherwise, this function triggers the modified fields to serialize themselves into the records buffer and afterwards updates the offset table.
 */
public void updateBinaryRepresenation(){
  final int firstModified=this.firstModifiedPos < 0 ? 0 : this.firstModifiedPos;
  if (firstModified == Integer.MAX_VALUE)   return;
  final InternalDeSerializer serializer=this.serializer;
  final int[] offsets=this.offsets;
  final int numFields=this.numFields;
  if (numFields > 0) {
    int offset=0;
    if (firstModified > 0) {
      for (int i=firstModified - 1; i >= 0; i--) {
        if (this.offsets[i] != NULL_INDICATOR_OFFSET) {
          offset=this.offsets[i] + this.lengths[i];
          break;
        }
      }
    }
    serializer.memory=this.switchBuffer != null ? this.switchBuffer : new byte[numFields * 8];
    serializer.position=offset;
    if (offset > 0) {
      System.arraycopy(this.binaryData,0,serializer.memory,0,offset);
    }
    try {
      for (int i=firstModified; i < numFields; i++) {
        final int co=offsets[i];
        if (co == NULL_INDICATOR_OFFSET)         continue;
        offsets[i]=offset;
        if (co == MODIFIED_INDICATOR_OFFSET)         this.writeFields[i].write(serializer);
 else         serializer.write(this.binaryData,co,this.lengths[i]);
        this.lengths[i]=serializer.position - offset;
        offset=serializer.position;
      }
    }
 catch (    Exception e) {
      throw new RuntimeException(""String_Node_Str"" + e.getMessage(),e);
    }
    this.switchBuffer=this.binaryData;
    this.binaryData=serializer.memory;
  }
  try {
    int slp=serializer.position;
    if (numFields <= 8) {
      int mask=0;
      for (int i=numFields - 1; i > 0; i--) {
        if (offsets[i] != NULL_INDICATOR_OFFSET) {
          slp=serializer.position;
          serializer.writeValLenIntBackwards(offsets[i]);
          mask|=0x1;
        }
        mask<<=1;
      }
      if (offsets[0] != NULL_INDICATOR_OFFSET) {
        mask|=0x1;
      }
 else {
        serializer.position=slp;
      }
      serializer.writeByte(mask);
    }
 else {
      for (int i=numFields - 1; i > 0; i--) {
        if (offsets[i] != NULL_INDICATOR_OFFSET) {
          slp=serializer.position;
          serializer.writeValLenIntBackwards(offsets[i]);
        }
      }
      if (offsets[0] == NULL_INDICATOR_OFFSET) {
        serializer.position=slp;
      }
      int col=numFields - 1;
      int mask=0;
      for (int i=numFields & 0x7; i > 0; i--, col--) {
        mask<<=1;
        mask|=(offsets[col] != NULL_INDICATOR_OFFSET) ? 0x1 : 0x0;
      }
      serializer.writeByte(mask);
      for (int i=numFields >>> 3; i > 0; i--) {
        mask=0;
        for (int k=0; k < 8; k++, col--) {
          mask<<=1;
          mask|=(offsets[col] != NULL_INDICATOR_OFFSET) ? 0x1 : 0x0;
        }
        serializer.writeByte(mask);
      }
    }
    serializer.writeValLenIntBackwards(numFields);
  }
 catch (  Exception e) {
    throw new RuntimeException(""String_Node_Str"" + e.getMessage(),e);
  }
  this.binaryData=serializer.memory;
  this.binaryLen=serializer.position;
  this.firstModifiedPos=Integer.MAX_VALUE;
}","/** 
 * Updates the binary representation of the data, such that it reflects the state of the currently stored fields. If the binary representation is already up to date, nothing happens. Otherwise, this function triggers the modified fields to serialize themselves into the records buffer and afterwards updates the offset table.
 */
public void updateBinaryRepresenation(){
  final int firstModified=this.firstModifiedPos < 0 ? 0 : this.firstModifiedPos;
  if (firstModified == Integer.MAX_VALUE)   return;
  final InternalDeSerializer serializer=this.serializer;
  final int[] offsets=this.offsets;
  final int numFields=this.numFields;
  if (numFields > 0) {
    int offset=0;
    if (firstModified > 0) {
      for (int i=firstModified - 1; i >= 0; i--) {
        if (this.offsets[i] != NULL_INDICATOR_OFFSET) {
          offset=this.offsets[i] + this.lengths[i];
          break;
        }
      }
    }
    serializer.memory=this.switchBuffer != null ? this.switchBuffer : new byte[numFields * 8];
    serializer.position=offset;
    if (offset > 0) {
      System.arraycopy(this.binaryData,0,serializer.memory,0,offset);
    }
    try {
      for (int i=firstModified; i < numFields; i++) {
        final int co=offsets[i];
        if (co == NULL_INDICATOR_OFFSET)         continue;
        offsets[i]=offset;
        if (co == MODIFIED_INDICATOR_OFFSET)         this.writeFields[i].write(serializer);
 else         serializer.write(this.binaryData,co,this.lengths[i]);
        this.lengths[i]=serializer.position - offset;
        offset=serializer.position;
      }
    }
 catch (    Exception e) {
      throw new RuntimeException(""String_Node_Str"" + e.getMessage(),e);
    }
    this.switchBuffer=this.binaryData;
    this.binaryData=serializer.memory;
  }
  try {
    int slp=serializer.position;
    if (numFields <= 8) {
      int mask=0;
      for (int i=numFields - 1; i > 0; i--) {
        if (offsets[i] != NULL_INDICATOR_OFFSET) {
          slp=serializer.position;
          serializer.writeValLenIntBackwards(offsets[i]);
          mask|=0x1;
        }
        mask<<=1;
      }
      if (offsets[0] != NULL_INDICATOR_OFFSET) {
        mask|=0x1;
      }
 else {
        serializer.position=slp;
      }
      serializer.writeByte(mask);
    }
 else {
      for (int i=numFields - 1; i > 0; i--) {
        if (offsets[i] != NULL_INDICATOR_OFFSET) {
          slp=serializer.position;
          serializer.writeValLenIntBackwards(offsets[i]);
        }
      }
      if (offsets[0] == NULL_INDICATOR_OFFSET) {
        serializer.position=slp;
      }
      int col=numFields - 1;
      int mask=0;
      int i=numFields & 0x7;
      if (i > 0) {
        for (; i > 0; i--, col--) {
          mask<<=1;
          mask|=(offsets[col] != NULL_INDICATOR_OFFSET) ? 0x1 : 0x0;
        }
        serializer.writeByte(mask);
      }
      for (i=numFields >>> 3; i > 0; i--) {
        mask=0;
        for (int k=0; k < 8; k++, col--) {
          mask<<=1;
          mask|=(offsets[col] != NULL_INDICATOR_OFFSET) ? 0x1 : 0x0;
        }
        serializer.writeByte(mask);
      }
    }
    serializer.writeValLenIntBackwards(numFields);
  }
 catch (  Exception e) {
    throw new RuntimeException(""String_Node_Str"" + e.getMessage(),e);
  }
  this.binaryData=serializer.memory;
  this.binaryLen=serializer.position;
  this.firstModifiedPos=Integer.MAX_VALUE;
}",0.9897030293985972
55659,"/** 
 * Creates a new sorter that reads the data from a given reader and provides an iterator returning that data in a sorted manner. The memory is divided among sort buffers, write buffers and read buffers automatically. <p> WARNING: The given comparator is used simultaneously in multiple threads (the sorting thread and the merging thread). Make sure that the given comparator is stateless and does not make use of member variables.
 * @param memoryManager The memory manager from which to allocate the memory.
 * @param ioManager The I/O manager, which is used to write temporary files to disk.
 * @param totalMemory The total amount of memory dedicated to sorting, merging and I/O.
 * @param maxWriteMem The maximal amount of memory to be dedicated to writing sorted runs. Will be subtracted from the totalamount of memory (<code>totalMemory</code>).
 * @param numSortBuffers The number of distinct buffers to use creation of the initial runs.
 * @param maxNumFileHandles The maximum number of files to be merged at once.
 * @param keyComparators The comparator used to define the order among the keys.
 * @param keyPositions The logical positions of the keys in the records.
 * @param keyClasses The types of the keys.
 * @param input The input that is sorted by this sorter.
 * @param parentTask The parent task, which owns all resources used by this sorter.
 * @param startSpillingFraction The faction of the buffers that have to be filled before the spilling threadactually begins spilling data to disk.
 * @throws IOException Thrown, if an error occurs initializing the resources for external sorting.
 * @throws MemoryAllocationException Thrown, if not enough memory can be obtained from the memory manager toperform the sort.
 */
public UnilateralSortMerger(MemoryManager memoryManager,IOManager ioManager,long totalMemory,long maxWriteMem,int numSortBuffers,int maxNumFileHandles,Comparator<Key>[] keyComparators,int[] keyPositions,Class<? extends Key>[] keyClasses,MutableObjectIterator<PactRecord> input,AbstractInvokable parentTask,float startSpillingFraction) throws IOException, MemoryAllocationException {
  if (memoryManager == null | ioManager == null | keyComparators == null | keyPositions == null | keyClasses == null) {
    throw new NullPointerException();
  }
  if (parentTask == null) {
    throw new NullPointerException(""String_Node_Str"");
  }
  if (maxNumFileHandles < 2) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (keyComparators.length < 1) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (keyComparators.length != keyPositions.length || keyPositions.length != keyClasses.length) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (totalMemory < MIN_SORT_MEM + MIN_WRITE_MEM) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  this.maxNumFileHandles=maxNumFileHandles;
  this.memoryManager=memoryManager;
  this.ioManager=ioManager;
  this.keyComparators=keyComparators;
  this.keyPositions=keyPositions;
  this.keyClasses=keyClasses;
  this.parent=parentTask;
  this.memoryToReleaseAtShutdown=new ArrayList<List<MemorySegment>>();
  this.channelsToDeleteAtShutdown=new ArrayList<Channel.ID>();
  this.openChannels=new ArrayList<BlockChannelAccess<?,?>>();
  if (maxWriteMem != 0) {
    if (maxWriteMem != -1 && maxWriteMem < MIN_WRITE_MEM) {
      throw new IllegalArgumentException(""String_Node_Str"" + ""String_Node_Str"" + MIN_WRITE_MEM + ""String_Node_Str"");
    }
    final int minBuffers=NUM_WRITE_BUFFERS + maxNumFileHandles;
    final int desiredBuffers=NUM_WRITE_BUFFERS + 2 * maxNumFileHandles;
    int bufferSize=(int)(totalMemory / desiredBuffers);
    if (bufferSize < MIN_IO_BUFFER_SIZE) {
      bufferSize=MIN_IO_BUFFER_SIZE;
      if (totalMemory / minBuffers < MIN_IO_BUFFER_SIZE) {
        maxNumFileHandles=(int)(totalMemory / MIN_IO_BUFFER_SIZE) - NUM_WRITE_BUFFERS;
        if (LOG.isWarnEnabled())         LOG.warn(""String_Node_Str"" + maxNumFileHandles + ""String_Node_Str"");
      }
    }
 else {
      bufferSize=Math.min(MAX_IO_BUFFER_SIZE,MathUtils.roundDownToPowerOf2(bufferSize));
    }
    if (maxWriteMem < 0) {
      maxWriteMem=Math.max(totalMemory / 64,MIN_WRITE_MEM);
    }
    this.ioBufferSize=Math.min(bufferSize,MathUtils.roundDownToPowerOf2((int)(maxWriteMem / NUM_WRITE_BUFFERS)));
    maxWriteMem=NUM_WRITE_BUFFERS * this.ioBufferSize;
  }
 else {
    this.ioBufferSize=-1;
  }
  final long sortMem=totalMemory - maxWriteMem;
  final long numSortMemSegments=sortMem / SORT_MEM_SEGMENT_SIZE;
  if (numSortBuffers < 1) {
    if (sortMem > 96 * 1024 * 1024) {
      numSortBuffers=3;
    }
 else     if (numSortMemSegments >= 2 * MIN_NUM_SORT_MEM_SEGMENTS) {
      numSortBuffers=2;
    }
 else {
      numSortBuffers=1;
    }
  }
  final int numSegmentsPerSortBuffer=numSortMemSegments / numSortBuffers > Integer.MAX_VALUE ? Integer.MAX_VALUE : (int)(numSortMemSegments / numSortBuffers);
  if (LOG.isDebugEnabled()) {
    LOG.debug(""String_Node_Str"" + maxWriteMem + ""String_Node_Str""+ sortMem+ ""String_Node_Str""+ numSortBuffers+ ""String_Node_Str""+ numSegmentsPerSortBuffer+ ""String_Node_Str""+ SORT_MEM_SEGMENT_SIZE+ ""String_Node_Str""+ maxNumFileHandles+ ""String_Node_Str"");
  }
  final CircularQueues circularQueues=new CircularQueues();
  this.sortBuffers=new ArrayList<NormalizedKeySorter<?>>(numSortBuffers);
  final PactRecordAccessors accessors=new PactRecordAccessors(keyPositions,keyClasses);
  for (int i=0; i < numSortBuffers; i++) {
    final List<MemorySegment> sortSegments=memoryManager.allocateStrict(parentTask,numSegmentsPerSortBuffer,SORT_MEM_SEGMENT_SIZE);
    final NormalizedKeySorter<PactRecord> buffer=new NormalizedKeySorter<PactRecord>(accessors,sortSegments);
    this.sortBuffers.add(buffer);
    CircularElement element=new CircularElement(i,buffer);
    circularQueues.empty.add(element);
  }
  ExceptionHandler<IOException> exceptionHandler=new ExceptionHandler<IOException>(){
    public void handleException(    IOException exception){
      if (!closed) {
        setResultIteratorException(exception);
        close();
      }
    }
  }
;
  this.readThread=getReadingThread(exceptionHandler,input,circularQueues,parentTask,((long)(startSpillingFraction * sortMem)));
  this.sortThread=getSortingThread(exceptionHandler,circularQueues,parentTask);
  this.spillThread=getSpillingThread(exceptionHandler,circularQueues,memoryManager,ioManager,sortMem,parentTask);
  startThreads();
}","/** 
 * Creates a new sorter that reads the data from a given reader and provides an iterator returning that data in a sorted manner. The memory is divided among sort buffers, write buffers and read buffers automatically. <p> WARNING: The given comparator is used simultaneously in multiple threads (the sorting thread and the merging thread). Make sure that the given comparator is stateless and does not make use of member variables.
 * @param memoryManager The memory manager from which to allocate the memory.
 * @param ioManager The I/O manager, which is used to write temporary files to disk.
 * @param totalMemory The total amount of memory dedicated to sorting, merging and I/O.
 * @param maxWriteMem The maximal amount of memory to be dedicated to writing sorted runs. Will be subtracted from the totalamount of memory (<code>totalMemory</code>).
 * @param numSortBuffers The number of distinct buffers to use creation of the initial runs.
 * @param maxNumFileHandles The maximum number of files to be merged at once.
 * @param keyComparators The comparator used to define the order among the keys.
 * @param keyPositions The logical positions of the keys in the records.
 * @param keyClasses The types of the keys.
 * @param input The input that is sorted by this sorter.
 * @param parentTask The parent task, which owns all resources used by this sorter.
 * @param startSpillingFraction The faction of the buffers that have to be filled before the spilling threadactually begins spilling data to disk.
 * @throws IOException Thrown, if an error occurs initializing the resources for external sorting.
 * @throws MemoryAllocationException Thrown, if not enough memory can be obtained from the memory manager toperform the sort.
 */
public UnilateralSortMerger(MemoryManager memoryManager,IOManager ioManager,long totalMemory,long maxWriteMem,int numSortBuffers,int maxNumFileHandles,Comparator<Key>[] keyComparators,int[] keyPositions,Class<? extends Key>[] keyClasses,MutableObjectIterator<PactRecord> input,AbstractInvokable parentTask,float startSpillingFraction) throws IOException, MemoryAllocationException {
  if (memoryManager == null | ioManager == null | keyComparators == null | keyPositions == null | keyClasses == null) {
    throw new NullPointerException();
  }
  if (parentTask == null) {
    throw new NullPointerException(""String_Node_Str"");
  }
  if (maxNumFileHandles < 2) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (keyComparators.length < 1) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (keyComparators.length != keyPositions.length || keyPositions.length != keyClasses.length) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (totalMemory < MIN_SORT_MEM + MIN_WRITE_MEM) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  this.maxNumFileHandles=maxNumFileHandles;
  this.memoryManager=memoryManager;
  this.ioManager=ioManager;
  this.keyComparators=keyComparators;
  this.keyPositions=keyPositions;
  this.keyClasses=keyClasses;
  this.parent=parentTask;
  this.memoryToReleaseAtShutdown=new ArrayList<List<MemorySegment>>();
  this.channelsToDeleteAtShutdown=new ArrayList<Channel.ID>();
  this.openChannels=new ArrayList<BlockChannelAccess<?,?>>();
  if (maxWriteMem != 0) {
    if (maxWriteMem != -1 && maxWriteMem < MIN_WRITE_MEM) {
      throw new IllegalArgumentException(""String_Node_Str"" + ""String_Node_Str"" + MIN_WRITE_MEM + ""String_Node_Str"");
    }
    final int minBuffers=NUM_WRITE_BUFFERS + maxNumFileHandles;
    final int desiredBuffers=NUM_WRITE_BUFFERS + 2 * maxNumFileHandles;
    int bufferSize=(int)(totalMemory / desiredBuffers);
    if (bufferSize < MIN_IO_BUFFER_SIZE) {
      bufferSize=MIN_IO_BUFFER_SIZE;
      if (totalMemory / minBuffers < MIN_IO_BUFFER_SIZE) {
        maxNumFileHandles=(int)(totalMemory / MIN_IO_BUFFER_SIZE) - NUM_WRITE_BUFFERS;
        if (LOG.isWarnEnabled())         LOG.warn(""String_Node_Str"" + maxNumFileHandles + ""String_Node_Str"");
      }
    }
 else {
      bufferSize=Math.min(MAX_IO_BUFFER_SIZE,MathUtils.roundDownToPowerOf2(bufferSize));
    }
    if (maxWriteMem < 0) {
      maxWriteMem=Math.max(totalMemory / 64,MIN_WRITE_MEM);
    }
    this.ioBufferSize=Math.min(bufferSize,MathUtils.roundDownToPowerOf2((int)(maxWriteMem / NUM_WRITE_BUFFERS)));
    maxWriteMem=NUM_WRITE_BUFFERS * this.ioBufferSize;
  }
 else {
    this.ioBufferSize=-1;
  }
  final long sortMem=totalMemory - maxWriteMem;
  final long numSortMemSegments=sortMem / SORT_MEM_SEGMENT_SIZE;
  if (numSortBuffers < 1) {
    if (sortMem > 96 * 1024 * 1024) {
      numSortBuffers=3;
    }
 else     if (numSortMemSegments >= 2 * MIN_NUM_SORT_MEM_SEGMENTS) {
      numSortBuffers=2;
    }
 else {
      numSortBuffers=1;
    }
  }
  final int numSegmentsPerSortBuffer=numSortMemSegments / numSortBuffers > Integer.MAX_VALUE ? Integer.MAX_VALUE : (int)(numSortMemSegments / numSortBuffers);
  if (LOG.isDebugEnabled()) {
    LOG.debug(""String_Node_Str"" + maxWriteMem + ""String_Node_Str""+ sortMem+ ""String_Node_Str""+ numSortBuffers+ ""String_Node_Str""+ numSegmentsPerSortBuffer+ ""String_Node_Str""+ SORT_MEM_SEGMENT_SIZE+ ""String_Node_Str""+ maxNumFileHandles+ ""String_Node_Str"");
  }
  final CircularQueues circularQueues=new CircularQueues();
  this.sortBuffers=new ArrayList<NormalizedKeySorter<?>>(numSortBuffers);
  for (int i=0; i < numSortBuffers; i++) {
    final List<MemorySegment> sortSegments=memoryManager.allocateStrict(parentTask,numSegmentsPerSortBuffer,SORT_MEM_SEGMENT_SIZE);
    final PactRecordAccessors accessors=new PactRecordAccessors(keyPositions,keyClasses);
    final NormalizedKeySorter<PactRecord> buffer=new NormalizedKeySorter<PactRecord>(accessors,sortSegments);
    this.sortBuffers.add(buffer);
    CircularElement element=new CircularElement(i,buffer);
    circularQueues.empty.add(element);
  }
  ExceptionHandler<IOException> exceptionHandler=new ExceptionHandler<IOException>(){
    public void handleException(    IOException exception){
      if (!closed) {
        setResultIteratorException(exception);
        close();
      }
    }
  }
;
  this.readThread=getReadingThread(exceptionHandler,input,circularQueues,parentTask,((long)(startSpillingFraction * sortMem)));
  this.sortThread=getSortingThread(exceptionHandler,circularQueues,parentTask);
  this.spillThread=getSpillingThread(exceptionHandler,circularQueues,memoryManager,ioManager,sortMem,parentTask);
  startThreads();
}",0.9862378227926396
55660,"/** 
 * Checks, if this set of properties, as interesting properties, is met by the given properties.
 * @param other The properties for which to check whether they meet these properties.
 * @return True, if the properties are met, false otherwise.
 */
public boolean isMetBy(GlobalProperties other){
  if (this.partitioning != PartitionProperty.NONE) {
    if (this.partitioning == PartitionProperty.ANY) {
      if (other.partitioning == PartitionProperty.NONE) {
        return false;
      }
    }
 else     if (other.partitioning != this.partitioning) {
      return false;
    }
  }
  FieldSet otherPartitionedFields=other.getPartitionedFiels();
  if (this.partitionedFields != null) {
    if (other.partitionedFields == null) {
      return false;
    }
    if (this.partitionedFields.size() > otherPartitionedFields.size()) {
      return false;
    }
    for (    Integer fieldIndex : this.partitionedFields) {
      if (otherPartitionedFields.contains(fieldIndex) == false) {
        return false;
      }
    }
  }
  return this.ordering.isMetBy(other.getOrdering());
}","/** 
 * Checks, if this set of properties, as interesting properties, is met by the given properties.
 * @param other The properties for which to check whether they meet these properties.
 * @return True, if the properties are met, false otherwise.
 */
public boolean isMetBy(GlobalProperties other){
  if (this.partitioning != PartitionProperty.NONE) {
    if (this.partitioning == PartitionProperty.ANY) {
      if (other.partitioning == PartitionProperty.NONE) {
        return false;
      }
    }
 else     if (other.partitioning != this.partitioning) {
      return false;
    }
  }
  FieldSet otherPartitionedFields=other.getPartitionedFiels();
  if (this.partitionedFields != null) {
    if (other.partitionedFields == null) {
      return false;
    }
    if (this.partitionedFields.size() > otherPartitionedFields.size()) {
      return false;
    }
    for (    Integer fieldIndex : this.partitionedFields) {
      if (otherPartitionedFields.contains(fieldIndex) == false) {
        return false;
      }
    }
  }
  return (this.ordering == null || this.ordering.isMetBy(other.getOrdering()));
}",0.9876543209876544
55661,"/** 
 * Checks, if this set of properties, as interesting properties, is met by the given properties.
 * @param other The properties for which to check whether they meet these properties.
 * @return True, if the properties are met, false otherwise.
 */
public boolean isMetBy(LocalProperties other){
  boolean groupingFulfilled=false;
  if (this.grouped) {
    if (other.isGrouped()) {
      groupingFulfilled=this.groupedFields.equals(other.groupedFields);
    }
    if (!groupingFulfilled && other.getOrdering() != null) {
      ArrayList<Integer> otherIndexes=other.getOrdering().getInvolvedIndexes();
      if (groupedFields.size() > otherIndexes.size()) {
        return false;
      }
      for (int i=0; i < groupedFields.size(); i++) {
        if (groupedFields.contains(otherIndexes.get(i)) == false) {
          return false;
        }
      }
    }
  }
  if (groupingFulfilled == false) {
    return false;
  }
  return this.ordering.isMetBy(other.getOrdering());
}","/** 
 * Checks, if this set of properties, as interesting properties, is met by the given properties.
 * @param other The properties for which to check whether they meet these properties.
 * @return True, if the properties are met, false otherwise.
 */
public boolean isMetBy(LocalProperties other){
  boolean groupingFulfilled=false;
  if (this.grouped) {
    if (other.isGrouped()) {
      groupingFulfilled=this.groupedFields.equals(other.groupedFields);
    }
    if (!groupingFulfilled && other.getOrdering() != null) {
      ArrayList<Integer> otherIndexes=other.getOrdering().getInvolvedIndexes();
      if (groupedFields.size() > otherIndexes.size()) {
        return false;
      }
      for (int i=0; i < groupedFields.size(); i++) {
        if (groupedFields.contains(otherIndexes.get(i)) == false) {
          return false;
        }
      }
    }
  }
  if (groupingFulfilled == false) {
    return false;
  }
  return (this.ordering == null || this.ordering.isMetBy(other.getOrdering()));
}",0.986356745831228
55662,"/** 
 * Gets the global properties of the source's output after it crossed a pact connection with the given shipping strategy. Global properties are maintained on <tt>FORWARD</tt> connections. If a partitioning happens, then a partitioning property exists afterwards. A <tt>BROADCAST</tt> connection destroys the key uniqueness. <p> If the shipping strategy has not yet been determined, the properties of the connections source are returned.
 * @return The properties of the data after this channel.
 */
public static GlobalProperties getGlobalPropertiesAfterConnection(OptimizerNode source,OptimizerNode target,ShipStrategy shipMode){
  GlobalProperties gp=source.getGlobalProperties().createCopy();
  int inputNum=0;
  FieldSet keyFields=null;
  for (  List<PactConnection> connections : target.getIncomingConnections()) {
    boolean isThisConnection=false;
    for (    PactConnection connection : connections) {
      if (connection.getSourcePact().equals(source)) {
        if (target.getPactContract() instanceof AbstractPact<?>) {
          keyFields=new FieldSet(((AbstractPact<?>)target.getPactContract()).getKeyColumnNumbers(inputNum));
        }
        break;
      }
    }
    if (isThisConnection) {
      break;
    }
 else {
      inputNum++;
    }
  }
switch (shipMode) {
case BROADCAST:
    gp.reset();
  break;
case PARTITION_RANGE:
gp.setPartitioning(PartitionProperty.RANGE_PARTITIONED,keyFields);
break;
case PARTITION_HASH:
gp.setPartitioning(PartitionProperty.HASH_PARTITIONED,keyFields);
gp.setOrdering(null);
break;
case FORWARD:
if (source.getDegreeOfParallelism() > target.getDegreeOfParallelism()) {
gp.setOrdering(null);
}
break;
case NONE:
throw new CompilerException(""String_Node_Str"");
case SFR:
default :
throw new CompilerException(""String_Node_Str"" + shipMode.name());
}
return gp;
}","/** 
 * Gets the global properties of the source's output after it crossed a pact connection with the given shipping strategy. Global properties are maintained on <tt>FORWARD</tt> connections. If a partitioning happens, then a partitioning property exists afterwards. A <tt>BROADCAST</tt> connection destroys the key uniqueness. <p> If the shipping strategy has not yet been determined, the properties of the connections source are returned.
 * @return The properties of the data after this channel.
 */
public static GlobalProperties getGlobalPropertiesAfterConnection(OptimizerNode source,OptimizerNode target,ShipStrategy shipMode){
  GlobalProperties gp=source.getGlobalProperties().createCopy();
  int inputNum=0;
  FieldSet keyFields=null;
  for (  List<PactConnection> connections : target.getIncomingConnections()) {
    boolean isThisConnection=false;
    for (    PactConnection connection : connections) {
      if (connection.getSourcePact().getId() == source.getId()) {
        if (target.getPactContract() instanceof AbstractPact<?>) {
          keyFields=new FieldSet(((AbstractPact<?>)target.getPactContract()).getKeyColumnNumbers(inputNum));
        }
        break;
      }
    }
    if (isThisConnection) {
      break;
    }
 else {
      inputNum++;
    }
  }
switch (shipMode) {
case BROADCAST:
    gp.reset();
  break;
case PARTITION_RANGE:
gp.setPartitioning(PartitionProperty.RANGE_PARTITIONED,keyFields);
break;
case PARTITION_HASH:
gp.setPartitioning(PartitionProperty.HASH_PARTITIONED,keyFields);
gp.setOrdering(null);
break;
case FORWARD:
if (source.getDegreeOfParallelism() > target.getDegreeOfParallelism()) {
gp.setOrdering(null);
}
break;
case NONE:
throw new CompilerException(""String_Node_Str"");
case SFR:
default :
throw new CompilerException(""String_Node_Str"" + shipMode.name());
}
return gp;
}",0.9898657901944672
55663,"@Override public List<List<PactConnection>> getIncomingConnections(){
  return this.inputs;
}","@Override public List<List<PactConnection>> getIncomingConnections(){
  ArrayList<List<PactConnection>> inputs=new ArrayList<List<PactConnection>>(2);
  inputs.add(0,input1);
  inputs.add(1,input2);
  return inputs;
}",0.535483870967742
55664,"/** 
 * Copy constructor to create a copy of a node with different predecessors. The predecessors is assumed to be of the same type as in the template node and merely copies with different strategies, as they are created in the process of the plan enumeration.
 * @param template The node to create a copy of.
 * @param pred1 The new predecessor for the first input.
 * @param pred2 The new predecessor for the second input.
 * @param conn1 The old connection of the first input to copy properties from.
 * @param conn2 The old connection of the second input to copy properties from.
 * @param globalProps The global properties of this copy.
 * @param localProps The local properties of this copy.
 */
protected TwoInputNode(TwoInputNode template,List<OptimizerNode> pred1,List<OptimizerNode> pred2,List<PactConnection> conn1,List<PactConnection> conn2,GlobalProperties globalProps,LocalProperties localProps){
  super(template,globalProps,localProps);
  this.inputs=new ArrayList<List<PactConnection>>(2);
  int i=0;
  if (pred1 != null) {
    for (    PactConnection c : conn1) {
      PactConnection cc=new PactConnection(c,pred1.get(i++),this);
      this.input1.add(cc);
    }
    this.inputs.add(this.input1);
  }
  if (pred2 != null) {
    i=0;
    for (    PactConnection c : conn2) {
      PactConnection cc=new PactConnection(c,pred2.get(i++),this);
      this.input2.add(cc);
    }
    this.inputs.add(this.input2);
  }
  if (template.openBranches != null) {
    if (this.branchPlan == null) {
      this.branchPlan=new HashMap<OptimizerNode,OptimizerNode>(8);
    }
    for (    UnclosedBranchDescriptor uc : template.openBranches) {
      OptimizerNode brancher=uc.branchingNode;
      OptimizerNode selectedCandidate=null;
      if (pred1 != null) {
        Iterator<OptimizerNode> it1=pred1.iterator();
        while (it1.hasNext()) {
          OptimizerNode n=it1.next();
          if (n.branchPlan != null) {
            selectedCandidate=n.branchPlan.get(brancher);
            this.branchPlan.put(brancher,selectedCandidate);
          }
        }
      }
      if (selectedCandidate == null && pred2 != null) {
        Iterator<OptimizerNode> it2=pred2.iterator();
        while (it2.hasNext()) {
          OptimizerNode n=it2.next();
          if (n.branchPlan != null) {
            selectedCandidate=n.branchPlan.get(brancher);
            this.branchPlan.put(brancher,selectedCandidate);
          }
        }
      }
      if (selectedCandidate == null) {
        throw new CompilerException(""String_Node_Str"");
      }
    }
  }
}","/** 
 * Copy constructor to create a copy of a node with different predecessors. The predecessors is assumed to be of the same type as in the template node and merely copies with different strategies, as they are created in the process of the plan enumeration.
 * @param template The node to create a copy of.
 * @param pred1 The new predecessor for the first input.
 * @param pred2 The new predecessor for the second input.
 * @param conn1 The old connection of the first input to copy properties from.
 * @param conn2 The old connection of the second input to copy properties from.
 * @param globalProps The global properties of this copy.
 * @param localProps The local properties of this copy.
 */
protected TwoInputNode(TwoInputNode template,List<OptimizerNode> pred1,List<OptimizerNode> pred2,List<PactConnection> conn1,List<PactConnection> conn2,GlobalProperties globalProps,LocalProperties localProps){
  super(template,globalProps,localProps);
  int i=0;
  if (pred1 != null) {
    for (    PactConnection c : conn1) {
      PactConnection cc=new PactConnection(c,pred1.get(i++),this);
      this.input1.add(cc);
    }
  }
  if (pred2 != null) {
    i=0;
    for (    PactConnection c : conn2) {
      PactConnection cc=new PactConnection(c,pred2.get(i++),this);
      this.input2.add(cc);
    }
  }
  if (template.openBranches != null) {
    if (this.branchPlan == null) {
      this.branchPlan=new HashMap<OptimizerNode,OptimizerNode>(8);
    }
    for (    UnclosedBranchDescriptor uc : template.openBranches) {
      OptimizerNode brancher=uc.branchingNode;
      OptimizerNode selectedCandidate=null;
      if (pred1 != null) {
        Iterator<OptimizerNode> it1=pred1.iterator();
        while (it1.hasNext()) {
          OptimizerNode n=it1.next();
          if (n.branchPlan != null) {
            selectedCandidate=n.branchPlan.get(brancher);
            this.branchPlan.put(brancher,selectedCandidate);
          }
        }
      }
      if (selectedCandidate == null && pred2 != null) {
        Iterator<OptimizerNode> it2=pred2.iterator();
        while (it2.hasNext()) {
          OptimizerNode n=it2.next();
          if (n.branchPlan != null) {
            selectedCandidate=n.branchPlan.get(brancher);
            this.branchPlan.put(brancher,selectedCandidate);
          }
        }
      }
      if (selectedCandidate == null) {
        throw new CompilerException(""String_Node_Str"");
      }
    }
  }
}",0.9755511022044088
55665,"/** 
 * Updates the binary representation of the data, such that it reflects the state of the currently stored fields. If the binary representation is already up to date, nothing happens. Otherwise, this function triggers the modified fields to serialize themselves into the records buffer and afterwards updates the offset table.
 */
public void updateBinaryRepresenation(){
  final int firstModified=this.firstModifiedPos;
  if (firstModified == Integer.MAX_VALUE)   return;
  final InternalDeSerializer serializer=this.serializer;
  final int[] offsets=this.offsets;
  final int numFields=this.numFields;
  if (numFields > 0) {
    int offset=0;
    if (firstModified > 0) {
      for (int i=firstModified - 1; i >= 0; i--) {
        if (this.offsets[i] != NULL_INDICATOR_OFFSET) {
          offset=this.offsets[i] + this.lengths[i];
          break;
        }
      }
    }
    serializer.memory=this.switchBuffer != null ? this.switchBuffer : new byte[numFields * 8];
    serializer.position=offset;
    if (offset > 0) {
      System.arraycopy(this.binaryData,0,serializer.memory,0,offset);
    }
    try {
      for (int i=firstModified; i < numFields; i++) {
        final int co=offsets[i];
        if (co == NULL_INDICATOR_OFFSET)         continue;
        offsets[i]=offset;
        if (co == MODIFIED_INDICATOR_OFFSET)         this.writeFields[i].write(serializer);
 else         serializer.write(this.binaryData,co,this.lengths[i]);
        this.lengths[i]=serializer.position - offset;
        offset=serializer.position;
      }
    }
 catch (    Exception e) {
      throw new RuntimeException(""String_Node_Str"" + e.getMessage(),e);
    }
    this.switchBuffer=this.binaryData;
    this.binaryData=serializer.memory;
  }
  try {
    int slp=serializer.position;
    if (numFields <= 8) {
      int mask=0;
      for (int i=numFields - 1; i > 0; i--) {
        if (offsets[i] != NULL_INDICATOR_OFFSET) {
          slp=serializer.position;
          serializer.writeValLenIntBackwards(offsets[i]);
          mask|=0x1;
        }
        mask<<=1;
      }
      if (offsets[0] != NULL_INDICATOR_OFFSET) {
        mask|=0x1;
      }
 else {
        serializer.position=slp;
      }
      serializer.writeByte(mask);
    }
 else {
      for (int i=numFields - 1; i > 0; i--) {
        if (offsets[i] != NULL_INDICATOR_OFFSET) {
          slp=serializer.position;
          serializer.writeValLenIntBackwards(offsets[i]);
        }
      }
      if (offsets[0] == NULL_INDICATOR_OFFSET) {
        serializer.position=slp;
      }
      int col=numFields - 1;
      int mask=0;
      for (int i=numFields & 0x7; i > 0; i--, col--) {
        mask<<=1;
        mask|=(offsets[col] != NULL_INDICATOR_OFFSET) ? 0x1 : 0x0;
      }
      serializer.writeByte(mask);
      for (int i=numFields >>> 3; i > 0; i--) {
        mask=0;
        for (int k=0; k < 8; k++, col--) {
          mask<<=1;
          mask|=(offsets[col] != NULL_INDICATOR_OFFSET) ? 0x1 : 0x0;
        }
        serializer.writeByte(mask);
      }
    }
    serializer.writeValLenIntBackwards(numFields);
  }
 catch (  Exception e) {
    throw new RuntimeException(""String_Node_Str"" + e.getMessage(),e);
  }
  this.binaryData=serializer.memory;
  this.binaryLen=serializer.position;
  this.firstModifiedPos=Integer.MAX_VALUE;
}","/** 
 * Updates the binary representation of the data, such that it reflects the state of the currently stored fields. If the binary representation is already up to date, nothing happens. Otherwise, this function triggers the modified fields to serialize themselves into the records buffer and afterwards updates the offset table.
 */
public void updateBinaryRepresenation(){
  final int firstModified=this.firstModifiedPos < 0 ? 0 : this.firstModifiedPos;
  if (firstModified == Integer.MAX_VALUE)   return;
  final InternalDeSerializer serializer=this.serializer;
  final int[] offsets=this.offsets;
  final int numFields=this.numFields;
  if (numFields > 0) {
    int offset=0;
    if (firstModified > 0) {
      for (int i=firstModified - 1; i >= 0; i--) {
        if (this.offsets[i] != NULL_INDICATOR_OFFSET) {
          offset=this.offsets[i] + this.lengths[i];
          break;
        }
      }
    }
    serializer.memory=this.switchBuffer != null ? this.switchBuffer : new byte[numFields * 8];
    serializer.position=offset;
    if (offset > 0) {
      System.arraycopy(this.binaryData,0,serializer.memory,0,offset);
    }
    try {
      for (int i=firstModified; i < numFields; i++) {
        final int co=offsets[i];
        if (co == NULL_INDICATOR_OFFSET)         continue;
        offsets[i]=offset;
        if (co == MODIFIED_INDICATOR_OFFSET)         this.writeFields[i].write(serializer);
 else         serializer.write(this.binaryData,co,this.lengths[i]);
        this.lengths[i]=serializer.position - offset;
        offset=serializer.position;
      }
    }
 catch (    Exception e) {
      throw new RuntimeException(""String_Node_Str"" + e.getMessage(),e);
    }
    this.switchBuffer=this.binaryData;
    this.binaryData=serializer.memory;
  }
  try {
    int slp=serializer.position;
    if (numFields <= 8) {
      int mask=0;
      for (int i=numFields - 1; i > 0; i--) {
        if (offsets[i] != NULL_INDICATOR_OFFSET) {
          slp=serializer.position;
          serializer.writeValLenIntBackwards(offsets[i]);
          mask|=0x1;
        }
        mask<<=1;
      }
      if (offsets[0] != NULL_INDICATOR_OFFSET) {
        mask|=0x1;
      }
 else {
        serializer.position=slp;
      }
      serializer.writeByte(mask);
    }
 else {
      for (int i=numFields - 1; i > 0; i--) {
        if (offsets[i] != NULL_INDICATOR_OFFSET) {
          slp=serializer.position;
          serializer.writeValLenIntBackwards(offsets[i]);
        }
      }
      if (offsets[0] == NULL_INDICATOR_OFFSET) {
        serializer.position=slp;
      }
      int col=numFields - 1;
      int mask=0;
      for (int i=numFields & 0x7; i > 0; i--, col--) {
        mask<<=1;
        mask|=(offsets[col] != NULL_INDICATOR_OFFSET) ? 0x1 : 0x0;
      }
      serializer.writeByte(mask);
      for (int i=numFields >>> 3; i > 0; i--) {
        mask=0;
        for (int k=0; k < 8; k++, col--) {
          mask<<=1;
          mask|=(offsets[col] != NULL_INDICATOR_OFFSET) ? 0x1 : 0x0;
        }
        serializer.writeByte(mask);
      }
    }
    serializer.writeValLenIntBackwards(numFields);
  }
 catch (  Exception e) {
    throw new RuntimeException(""String_Node_Str"" + e.getMessage(),e);
  }
  this.binaryData=serializer.memory;
  this.binaryLen=serializer.position;
  this.firstModifiedPos=Integer.MAX_VALUE;
}",0.9951719975859988
55666,"/** 
 * Checks, if this set of properties, as interesting properties, is met by the given properties.
 * @param other The properties for which to check whether they meet these properties.
 * @return True, if the properties are met, false otherwise.
 */
public boolean isMetBy(GlobalProperties other){
  if (this.partitioning != PartitionProperty.NONE) {
    if (this.partitioning == PartitionProperty.ANY) {
      if (other.partitioning == PartitionProperty.NONE) {
        return false;
      }
    }
 else     if (other.partitioning != this.partitioning) {
      return false;
    }
  }
  FieldSet otherPartitionedFields=other.getPartitionedFiels();
  if (this.partitionedFields != null) {
    if (other.partitionedFields == null) {
      return false;
    }
    if (this.partitionedFields.size() > otherPartitionedFields.size()) {
      return false;
    }
    for (    Integer fieldIndex : this.partitionedFields) {
      if (otherPartitionedFields.contains(fieldIndex) == false) {
        return false;
      }
    }
  }
  return (this.ordering == null || this.ordering.isMetBy(other.getOrdering()));
}","/** 
 * Checks, if this set of properties, as interesting properties, is met by the given properties.
 * @param other The properties for which to check whether they meet these properties.
 * @return True, if the properties are met, false otherwise.
 */
public boolean isMetBy(GlobalProperties other){
  if (this.partitioning != PartitionProperty.NONE) {
    if (this.partitioning == PartitionProperty.ANY) {
      if (other.partitioning == PartitionProperty.NONE) {
        return false;
      }
    }
 else     if (other.partitioning != this.partitioning) {
      return false;
    }
  }
  FieldSet otherPartitionedFields=other.getPartitionedFiels();
  if (this.partitionedFields != null) {
    if (other.partitionedFields == null) {
      return false;
    }
    if (this.partitionedFields.size() < otherPartitionedFields.size()) {
      return false;
    }
    if (this.partitionedFields.containsAll(otherPartitionedFields) == false) {
      return false;
    }
  }
  return (this.ordering == null || this.ordering.isMetBy(other.getOrdering()));
}",0.9272137227630968
55667,"public GlobalProperties clone() throws CloneNotSupportedException {
  return (GlobalProperties)super.clone();
}","public GlobalProperties clone() throws CloneNotSupportedException {
  GlobalProperties newProps=(GlobalProperties)super.clone();
  if (this.ordering != null) {
    newProps.ordering=this.ordering.clone();
  }
  if (this.partitionedFields != null) {
    newProps.partitionedFields=(FieldSet)this.partitionedFields.clone();
  }
  return newProps;
}",0.4507658643326039
55668,"/** 
 * Checks, if this set of properties, as interesting properties, is met by the given properties.
 * @param other The properties for which to check whether they meet these properties.
 * @return True, if the properties are met, false otherwise.
 */
public boolean isMetBy(LocalProperties other){
  boolean groupingFulfilled=false;
  if (this.grouped) {
    if (other.isGrouped()) {
      groupingFulfilled=this.groupedFields.equals(other.groupedFields);
    }
    if (!groupingFulfilled && other.getOrdering() != null) {
      ArrayList<Integer> otherIndexes=other.getOrdering().getInvolvedIndexes();
      if (groupedFields.size() > otherIndexes.size()) {
        return false;
      }
      for (int i=0; i < groupedFields.size(); i++) {
        if (groupedFields.contains(otherIndexes.get(i)) == false) {
          return false;
        }
      }
    }
  }
  if (groupingFulfilled == false) {
    return false;
  }
  return (this.ordering == null || this.ordering.isMetBy(other.getOrdering()));
}","/** 
 * Checks, if this set of properties, as interesting properties, is met by the given properties.
 * @param other The properties for which to check whether they meet these properties.
 * @return True, if the properties are met, false otherwise.
 */
public boolean isMetBy(LocalProperties other){
  boolean groupingFulfilled=false;
  if (this.grouped) {
    if (other.isGrouped()) {
      groupingFulfilled=this.groupedFields.equals(other.groupedFields);
    }
    if (!groupingFulfilled && other.getOrdering() != null) {
      ArrayList<Integer> otherIndexes=other.getOrdering().getInvolvedIndexes();
      if (groupedFields.size() > otherIndexes.size()) {
        return false;
      }
      for (int i=0; i < groupedFields.size(); i++) {
        if (groupedFields.contains(otherIndexes.get(i)) == false) {
          return false;
        }
      }
      groupingFulfilled=true;
    }
    if (groupingFulfilled == false) {
      return false;
    }
  }
  return (this.ordering == null || this.ordering.isMetBy(other.getOrdering()));
}",0.9294809010773752
55669,"@Override public LocalProperties clone() throws CloneNotSupportedException {
  return (LocalProperties)super.clone();
}","@Override public LocalProperties clone() throws CloneNotSupportedException {
  LocalProperties newProps=(LocalProperties)super.clone();
  if (this.ordering != null) {
    newProps.ordering=this.ordering.clone();
  }
  if (this.groupedFields != null) {
    newProps.groupedFields=(FieldSet)this.groupedFields.clone();
  }
  return newProps;
}",0.4826086956521739
55670,"public static final List<InterestingProperties> filterByConstantSet(List<InterestingProperties> props,OptimizerNode node,int input){
  List<InterestingProperties> preserved=new ArrayList<InterestingProperties>();
  for (  InterestingProperties p : props) {
    boolean nonTrivial=p.getGlobalProperties().filterByNodesConstantSet(node,input);
    nonTrivial|=p.getLocalProperties().filterByNodesConstantSet(node,input);
    if (nonTrivial) {
      preserved.add(p);
    }
  }
  return preserved;
}","public static final List<InterestingProperties> filterByConstantSet(List<InterestingProperties> props,OptimizerNode node,int input){
  List<InterestingProperties> preserved=new ArrayList<InterestingProperties>();
  for (  InterestingProperties p : props) {
    GlobalProperties preservedGp=p.getGlobalProperties().createCopy();
    LocalProperties preservedLp=p.getLocalProperties().createCopy();
    boolean nonTrivial=preservedGp.filterByNodesConstantSet(node,input);
    nonTrivial|=preservedLp.filterByNodesConstantSet(node,input);
    if (nonTrivial) {
      try {
        preserved.add(new InterestingProperties(p.getMaximalCosts().clone(),preservedGp,preservedLp));
      }
 catch (      CloneNotSupportedException cnse) {
        throw new RuntimeException(cnse);
      }
    }
  }
  return preserved;
}",0.7008416220351951
55671,"public boolean isFieldKept(int input,int fieldNumber){
  if (input != 0) {
    throw new IndexOutOfBoundsException();
  }
switch (constantSetMode) {
case Constant:
    return (constantSet != null && Arrays.binarySearch(constantSet,fieldNumber) >= 0);
case Update:
  return (updateSet == null || Arrays.binarySearch(updateSet,fieldNumber) < 0);
default :
return false;
}
}","public boolean isFieldKept(int input,int fieldNumber){
  if (input != 0) {
    throw new IndexOutOfBoundsException();
  }
  if (constantSetMode == null) {
    return false;
  }
switch (constantSetMode) {
case Constant:
    return (constantSet != null && Arrays.binarySearch(constantSet,fieldNumber) >= 0);
case Update:
  return (updateSet == null || Arrays.binarySearch(updateSet,fieldNumber) < 0);
default :
return false;
}
}",0.93099121706399
55672,"public boolean isFieldKept(int input,int fieldNumber){
  ConstantSetMode constantSetMode;
  int[] constantSet;
  int[] updateSet;
switch (input) {
case 0:
    constantSetMode=constantSet1Mode;
  constantSet=constantSet1;
updateSet=updateSet1;
break;
case 1:
constantSetMode=constantSet2Mode;
constantSet=constantSet2;
updateSet=updateSet2;
break;
default :
throw new IndexOutOfBoundsException();
}
switch (constantSetMode) {
case Constant:
return (constantSet != null && Arrays.binarySearch(constantSet,fieldNumber) >= 0);
case Update:
return (updateSet == null || Arrays.binarySearch(updateSet,fieldNumber) < 0);
default :
return false;
}
}","public boolean isFieldKept(int input,int fieldNumber){
  ConstantSetMode constantSetMode;
  int[] constantSet;
  int[] updateSet;
switch (input) {
case 0:
    constantSetMode=constantSet1Mode;
  constantSet=constantSet1;
updateSet=updateSet1;
break;
case 1:
constantSetMode=constantSet2Mode;
constantSet=constantSet2;
updateSet=updateSet2;
break;
default :
throw new IndexOutOfBoundsException();
}
if (constantSetMode == null) {
return false;
}
switch (constantSetMode) {
case Constant:
return (constantSet != null && Arrays.binarySearch(constantSet,fieldNumber) >= 0);
case Update:
return (updateSet == null || Arrays.binarySearch(updateSet,fieldNumber) < 0);
default :
return false;
}
}",0.964635063957863
55673,"/** 
 * Updates the binary representation of the data, such that it reflects the state of the currently stored fields. If the binary representation is already up to date, nothing happens. Otherwise, this function triggers the modified fields to serialize themselves into the records buffer and afterwards updates the offset table.
 */
public void updateBinaryRepresenation(){
  if (!this.modified)   return;
  final int firstModified=this.firstModifiedPos;
  final int numFields=this.numFields;
  final int[] offsets=this.offsets;
  if (this.serializer == null) {
    this.serializer=new InternalDeSerializer();
  }
  final InternalDeSerializer serializer=this.serializer;
  if (numFields > 0) {
    int offset=firstModified <= 0 ? 0 : this.offsets[firstModified - 1] + this.lengths[firstModified - 1];
    serializer.position=offset;
    if (firstModified > 0) {
      serializer.memory=this.binaryData == null ? new byte[numFields * DEFAULT_FIELD_LEN] : this.binaryData;
      try {
        for (int i=firstModified; i < numFields; i++) {
          if (offsets[i] == NULL_INDICATOR_OFFSET)           continue;
          offsets[i]=offset;
          this.fields[i].write(serializer);
          int newOffset=serializer.position;
          this.lengths[i]=newOffset - offset;
          offset=newOffset;
        }
      }
 catch (      Exception e) {
        throw new RuntimeException(""String_Node_Str"" + e.getMessage());
      }
    }
 else {
      serializer.memory=this.serializationSwitchBuffer == null ? new byte[numFields * DEFAULT_FIELD_LEN] : this.serializationSwitchBuffer;
      if (offset > 0 & this.binaryData != null) {
        System.arraycopy(this.binaryData,0,serializer.memory,0,offset);
      }
      try {
        for (int i=firstModified; i < numFields; i++) {
          final int co=offsets[i];
          if (co == NULL_INDICATOR_OFFSET)           continue;
          offsets[i]=offset;
          if (co == MODIFIED_INDICATOR_OFFSET)           this.fields[i].write(serializer);
 else           serializer.write(this.binaryData,co,this.lengths[i]);
          this.lengths[i]=serializer.position - offset;
          offset=serializer.position;
        }
      }
 catch (      Exception e) {
        throw new RuntimeException(""String_Node_Str"" + e.getMessage());
      }
      this.serializationSwitchBuffer=this.binaryData;
      this.binaryData=serializer.memory;
    }
  }
  try {
    int slp=serializer.position;
    if (numFields <= 8) {
      int mask=0;
      for (int i=numFields - 1; i > 0; i--) {
        mask<<=1;
        if (offsets[i] != NULL_INDICATOR_OFFSET) {
          slp=serializer.position;
          serializer.writeValLenIntBackwards(offsets[i]);
          mask|=0x1;
        }
      }
      mask<<=1;
      if (offsets[0] != NULL_INDICATOR_OFFSET) {
        mask|=0x1;
      }
 else {
        serializer.position=slp;
      }
      serializer.writeByte(mask);
    }
 else {
      for (int i=numFields - 1; i > 0; i--) {
        if (offsets[i] != NULL_INDICATOR_OFFSET) {
          slp=serializer.position;
          serializer.writeValLenIntBackwards(offsets[i]);
        }
      }
      if (offsets[0] == NULL_INDICATOR_OFFSET) {
        serializer.position=slp;
      }
      int col=numFields - 1;
      int mask=0;
      for (int i=numFields & 0x7; i > 0; i--, col--) {
        mask<<=1;
        mask|=(offsets[col] != NULL_INDICATOR_OFFSET) ? 0x1 : 0x0;
      }
      serializer.writeByte(mask);
      for (int i=numFields >>> 3; i > 0; i--) {
        mask=0;
        for (int k=0; k < 8; k++, col--) {
          mask<<=1;
          mask|=(offsets[col] != NULL_INDICATOR_OFFSET) ? 0x1 : 0x0;
        }
        serializer.writeByte(mask);
      }
    }
    serializer.writeValLenIntBackwards(numFields);
  }
 catch (  Exception e) {
    throw new RuntimeException(""String_Node_Str"" + e.getMessage(),e);
  }
  this.binaryData=serializer.memory;
  this.binaryLen=serializer.position;
  this.firstModifiedPos=Integer.MAX_VALUE;
  this.modified=false;
}","/** 
 * Updates the binary representation of the data, such that it reflects the state of the currently stored fields. If the binary representation is already up to date, nothing happens. Otherwise, this function triggers the modified fields to serialize themselves into the records buffer and afterwards updates the offset table.
 */
public void updateBinaryRepresenation(){
  if (!this.modified)   return;
  final int firstModified=this.firstModifiedPos;
  final int numFields=this.numFields;
  final int[] offsets=this.offsets;
  if (this.serializer == null) {
    this.serializer=new InternalDeSerializer();
  }
  final InternalDeSerializer serializer=this.serializer;
  if (numFields > 0) {
    int offset=0;
    if (firstModified > 0) {
      for (int i=firstModified - 1; i >= 0; i--) {
        if (this.offsets[i] != NULL_INDICATOR_OFFSET) {
          offset=this.offsets[i] + this.lengths[i];
          break;
        }
      }
    }
    serializer.position=offset;
    if (firstModified > 0) {
      serializer.memory=this.binaryData == null ? new byte[numFields * DEFAULT_FIELD_LEN] : this.binaryData;
      try {
        for (int i=firstModified; i < numFields; i++) {
          if (offsets[i] == NULL_INDICATOR_OFFSET)           continue;
          offsets[i]=offset;
          this.fields[i].write(serializer);
          int newOffset=serializer.position;
          this.lengths[i]=newOffset - offset;
          offset=newOffset;
        }
      }
 catch (      Exception e) {
        throw new RuntimeException(""String_Node_Str"" + e.getMessage());
      }
    }
 else {
      serializer.memory=this.serializationSwitchBuffer == null ? new byte[numFields * DEFAULT_FIELD_LEN] : this.serializationSwitchBuffer;
      if (offset > 0 & this.binaryData != null) {
        System.arraycopy(this.binaryData,0,serializer.memory,0,offset);
      }
      try {
        for (int i=firstModified; i < numFields; i++) {
          final int co=offsets[i];
          if (co == NULL_INDICATOR_OFFSET)           continue;
          offsets[i]=offset;
          if (co == MODIFIED_INDICATOR_OFFSET)           this.fields[i].write(serializer);
 else           serializer.write(this.binaryData,co,this.lengths[i]);
          this.lengths[i]=serializer.position - offset;
          offset=serializer.position;
        }
      }
 catch (      Exception e) {
        throw new RuntimeException(""String_Node_Str"" + e.getMessage());
      }
      this.serializationSwitchBuffer=this.binaryData;
      this.binaryData=serializer.memory;
    }
  }
  try {
    int slp=serializer.position;
    if (numFields <= 8) {
      int mask=0;
      for (int i=numFields - 1; i > 0; i--) {
        mask<<=1;
        if (offsets[i] != NULL_INDICATOR_OFFSET) {
          slp=serializer.position;
          serializer.writeValLenIntBackwards(offsets[i]);
          mask|=0x1;
        }
      }
      mask<<=1;
      if (offsets[0] != NULL_INDICATOR_OFFSET) {
        mask|=0x1;
      }
 else {
        serializer.position=slp;
      }
      serializer.writeByte(mask);
    }
 else {
      for (int i=numFields - 1; i > 0; i--) {
        if (offsets[i] != NULL_INDICATOR_OFFSET) {
          slp=serializer.position;
          serializer.writeValLenIntBackwards(offsets[i]);
        }
      }
      if (offsets[0] == NULL_INDICATOR_OFFSET) {
        serializer.position=slp;
      }
      int col=numFields - 1;
      int mask=0;
      for (int i=numFields & 0x7; i > 0; i--, col--) {
        mask<<=1;
        mask|=(offsets[col] != NULL_INDICATOR_OFFSET) ? 0x1 : 0x0;
      }
      serializer.writeByte(mask);
      for (int i=numFields >>> 3; i > 0; i--) {
        mask=0;
        for (int k=0; k < 8; k++, col--) {
          mask<<=1;
          mask|=(offsets[col] != NULL_INDICATOR_OFFSET) ? 0x1 : 0x0;
        }
        serializer.writeByte(mask);
      }
    }
    serializer.writeValLenIntBackwards(numFields);
  }
 catch (  Exception e) {
    throw new RuntimeException(""String_Node_Str"" + e.getMessage(),e);
  }
  this.binaryData=serializer.memory;
  this.binaryLen=serializer.position;
  this.firstModifiedPos=Integer.MAX_VALUE;
  this.modified=false;
}",0.9727004426955238
55674,"/** 
 * Does the aggregation of the query.  sum(l_extendedprice) as revenue GROUP BY l_orderkey, o_shippriority; Output Schema: Key: ORDERKEY Value: 0:ORDERKEY, 1:SHIPPRIORITY, 2:EXTENDEDPRICESUM
 */
@Override public void reduce(Iterator<PactRecord> values,Collector out){
  PactRecord rec=null;
  double partExtendedPriceSum=0;
  while (values.hasNext()) {
    rec=values.next();
    partExtendedPriceSum+=rec.getField(2,PactDouble.class).getValue();
  }
  this.extendedPrice.setValue(partExtendedPriceSum);
  rec.setField(2,this.extendedPrice);
  out.collect(rec);
}","/** 
 * Does the aggregation of the query.  sum(l_extendedprice) as revenue GROUP BY l_orderkey, o_shippriority; Output Schema: Key: ORDERKEY Value: 0:ORDERKEY, 1:SHIPPRIORITY, 2:EXTENDEDPRICESUM
 */
@Override public void reduce(Iterator<PactRecord> values,Collector out){
  PactRecord rec=null;
  double partExtendedPriceSum=0;
  while (values.hasNext()) {
    rec=values.next();
    partExtendedPriceSum+=rec.getField(5,PactDouble.class).getValue();
  }
  this.extendedPrice.setValue(partExtendedPriceSum);
  rec.setField(2,this.extendedPrice);
  out.collect(rec);
}",0.7447183098591549
55675,"/** 
 * Implements the join between LineItem and Order table on the  order key. WHERE l_orderkey = o_orderkey Output Schema - 0:ORDERKEY, 1:SHIPPRIORITY, 2:EXTENDEDPRICE
 */
@Override public void match(PactRecord first,PactRecord second,Collector out){
  first.setField(2,second.getField(1,PactDouble.class));
  out.collect(first);
}","/** 
 * Implements the join between LineItem and Order table on the  order key. WHERE l_orderkey = o_orderkey Output Schema - 0:ORDERKEY, 1:SHIPPRIORITY, 2:EXTENDEDPRICE
 */
@Override public void match(PactRecord order,PactRecord lineitem,Collector out){
  order.setField(5,lineitem.getField(1,PactDouble.class));
  out.collect(order);
}",0.8686567164179104
55676,"/** 
 * Does the projection on the LineItem table  Output Schema - 0:ORDERKEY, 1:null, 2:EXTENDEDPRICE
 */
@Override public void map(PactRecord record,Collector out){
  final Tuple t=record.getField(0,Tuple.class);
  try {
    this.orderKey.setValue(t.getLongValueAt(0));
    this.extendedPrice.setValue(Double.parseDouble(t.getStringValueAt(5)));
    result.setField(0,this.orderKey);
    result.setField(1,this.extendedPrice);
    out.collect(result);
  }
 catch (  NumberFormatException nfe) {
    LOGGER.error(nfe);
  }
}","/** 
 * Filters the orders table by year, orderstatus and orderpriority. o_orderstatus = ""X""  AND YEAR(o_orderdate) > Y AND o_orderpriority LIKE ""Z"" Output Schema - 0:ORDERKEY, 1:SHIPPRIORITY
 */
@Override public void map(final PactRecord record,final Collector out){
  record.getFieldInto(2,orderStatus);
  record.getFieldInto(3,orderDate);
  record.getFieldInto(4,orderPrio);
  if (Integer.parseInt(orderDate.getValue().substring(0,4)) > this.yearFilter && orderStatus.getValue().equals(""String_Node_Str"") && orderPrio.getValue().startsWith(this.prioFilter)) {
    outRecord.setField(0,record.getField(0,PactLong.class));
    outRecord.setField(1,record.getField(1,PactInteger.class));
    out.collect(outRecord);
  }
}",0.2231139646869984
55677,"/** 
 * Creates partial sums on the price attribute for each data batch.
 */
@Override public void combine(Iterator<PactRecord> values,Collector out){
  reduce(values,out);
}","/** 
 * Creates partial sums on the price attribute for each data batch.
 */
@Override public void combine(Iterator<PactRecord> values,Collector out){
  PactRecord rec=null;
  double partExtendedPriceSum=0;
  while (values.hasNext()) {
    rec=values.next();
    partExtendedPriceSum+=rec.getField(5,PactDouble.class).getValue();
  }
  this.extendedPrice.setValue(partExtendedPriceSum);
  rec.setField(5,this.extendedPrice);
  out.collect(rec);
}",0.5225806451612903
55678,"@Override public void removeFailurePattern(final TreeItem selectedItem){
  final JobFailurePattern failurePattern=(JobFailurePattern)selectedItem.getData();
  if (failurePattern == null) {
    return;
  }
  final MessageBox messageBox=new MessageBox(this.shell,SWT.ICON_QUESTION | SWT.YES | SWT.NO);
  messageBox.setText(""String_Node_Str"");
  messageBox.setMessage(""String_Node_Str"" + failurePattern.getName() + ""String_Node_Str"");
  if (messageBox.open() != SWT.YES) {
    return;
  }
  selectedItem.dispose();
  this.loadedPatterns.remove(failurePattern.getName());
  if (this.jobTree.getItemCount() == 0) {
    jobFailurePatternSelected(null);
  }
 else {
    jobFailurePatternSelected(this.jobTree.getItem(0));
  }
}","@Override public void removeFailurePattern(final TreeItem selectedItem){
  final JobFailurePattern failurePattern=(JobFailurePattern)selectedItem.getData();
  if (failurePattern == null) {
    return;
  }
  final MessageBox messageBox=new MessageBox(this.shell,SWT.ICON_QUESTION | SWT.YES | SWT.NO);
  messageBox.setText(""String_Node_Str"");
  messageBox.setMessage(""String_Node_Str"" + failurePattern.getName() + ""String_Node_Str"");
  if (messageBox.open() != SWT.YES) {
    return;
  }
  selectedItem.dispose();
  this.loadedPatterns.remove(failurePattern.getName());
  if (this.jobTree.getItemCount() == 0) {
    jobFailurePatternSelected(null);
  }
 else {
    final TreeItem ti=this.jobTree.getItem(0);
    this.jobTree.setSelection(ti);
    jobFailurePatternSelected(ti);
  }
}",0.9300466355762824
55679,"public void addFailurePatternToTree(final JobFailurePattern failurePattern){
  final TreeItem jobFailureItem=new TreeItem(this.jobTree,SWT.NONE);
  jobFailureItem.setText(failurePattern.getName());
  jobFailureItem.setData(failurePattern);
}","public void addFailurePatternToTree(final JobFailurePattern failurePattern){
  final TreeItem jobFailureItem=new TreeItem(this.jobTree,SWT.NONE);
  jobFailureItem.setText(failurePattern.getName());
  jobFailureItem.setData(failurePattern);
  this.jobTree.setSelection(jobFailureItem);
}",0.9146110056925996
55680,"/** 
 * Returns the current status of the job represented by this execution graph.
 * @return the current status of the job
 */
public InternalJobStatus getJobStatus(){
  return this.jobStatus;
}","/** 
 * Returns the current status of the job represented by this execution graph.
 * @return the current status of the job
 */
public InternalJobStatus getJobStatus(){
  return this.jobStatus.get();
}",0.9848484848484848
55681,"/** 
 * {@inheritDoc}
 */
@Override public void executionStateChanged(final JobID jobID,final ExecutionVertexID vertexID,final ExecutionState newExecutionState,String optionalMessage){
  final InternalJobStatus oldStatus=this.jobStatus;
  if (newExecutionState == ExecutionState.RERUNNING) {
    this.recovering.remove(getVertexByID(vertexID));
  }
  checkAndUpdateJobStatus(newExecutionState);
  if (newExecutionState == ExecutionState.FINISHED) {
    if (this.isCurrentStageCompleted()) {
      ++this.indexToCurrentExecutionStage;
      if (this.indexToCurrentExecutionStage < this.stages.size()) {
        final Iterator<ExecutionStageListener> it=this.executionStageListeners.iterator();
        final ExecutionStage nextExecutionStage=getCurrentExecutionStage();
        while (it.hasNext()) {
          it.next().nextExecutionStageEntered(jobID,nextExecutionStage);
        }
      }
    }
  }
  if (newExecutionState == ExecutionState.FAILED && this.jobStatus == InternalJobStatus.RECOVERING) {
    LOG.info(""String_Node_Str"");
    if (!this.recovering.contains(vertexID)) {
      this.recovering.add(this.getVertexByID(vertexID));
    }
  }
  if (this.jobStatus != oldStatus) {
    if (this.jobStatus == InternalJobStatus.FAILING) {
      this.errorDescription=optionalMessage;
    }
    if (this.jobStatus == InternalJobStatus.FAILED) {
      optionalMessage=this.errorDescription;
    }
    final Iterator<JobStatusListener> it=this.jobStatusListeners.iterator();
    while (it.hasNext()) {
      it.next().jobStatusHasChanged(this,this.jobStatus,optionalMessage);
    }
  }
}","/** 
 * {@inheritDoc}
 */
@Override public void executionStateChanged(final JobID jobID,final ExecutionVertexID vertexID,final ExecutionState newExecutionState,String optionalMessage){
  if (newExecutionState == ExecutionState.RERUNNING) {
    this.recovering.remove(getVertexByID(vertexID));
  }
  final InternalJobStatus newJobStatus=determineNewJobStatus(this,newExecutionState);
  if (newExecutionState == ExecutionState.FINISHED) {
    if (this.isCurrentStageCompleted()) {
      ++this.indexToCurrentExecutionStage;
      if (this.indexToCurrentExecutionStage < this.stages.size()) {
        final Iterator<ExecutionStageListener> it=this.executionStageListeners.iterator();
        final ExecutionStage nextExecutionStage=getCurrentExecutionStage();
        while (it.hasNext()) {
          it.next().nextExecutionStageEntered(jobID,nextExecutionStage);
        }
      }
    }
  }
  if (newExecutionState == ExecutionState.FAILED && newJobStatus == InternalJobStatus.RECOVERING) {
    LOG.info(""String_Node_Str"");
    if (!this.recovering.contains(vertexID)) {
      this.recovering.add(this.getVertexByID(vertexID));
    }
  }
  updateJobStatus(newJobStatus,optionalMessage);
}",0.8034619545618463
55682,"/** 
 * {@inheritDoc}
 */
@Override public void deploy(final JobID jobID,final AbstractInstance instance,final List<ExecutionVertex> verticesToBeDeployed){
  if (verticesToBeDeployed.isEmpty()) {
    LOG.error(""String_Node_Str"");
    return;
  }
  final ExecutionGraph eg=verticesToBeDeployed.get(0).getExecutionGraph();
  for (  final ExecutionVertex vertex : verticesToBeDeployed) {
    if (vertex.getExecutionState() != ExecutionState.READY) {
      LOG.error(""String_Node_Str"" + vertex + ""String_Node_Str""+ vertex.getExecutionState());
    }
    vertex.updateExecutionState(ExecutionState.STARTING,null);
  }
  final Runnable deploymentRunnable=new Runnable(){
    /** 
 * {@inheritDoc}
 */
    @Override public void run(){
      try {
        instance.checkLibraryAvailability(jobID);
      }
 catch (      IOException ioe) {
        LOG.error(""String_Node_Str"" + StringUtils.stringifyException(ioe));
      }
      final List<TaskSubmissionWrapper> submissionList=new SerializableArrayList<TaskSubmissionWrapper>();
      for (      final ExecutionVertex vertex : verticesToBeDeployed) {
        submissionList.add(new TaskSubmissionWrapper(vertex.getID(),vertex.getEnvironment(),vertex.getExecutionGraph().getJobConfiguration(),vertex.constructInitialActiveOutputChannelsSet()));
        LOG.info(""String_Node_Str"" + vertex + ""String_Node_Str""+ vertex.getAllocatedResource().getInstance());
      }
      List<TaskSubmissionResult> submissionResultList=null;
      try {
        submissionResultList=instance.submitTasks(submissionList);
      }
 catch (      final IOException ioe) {
        final String errorMsg=StringUtils.stringifyException(ioe);
        for (        final ExecutionVertex vertex : verticesToBeDeployed) {
          vertex.updateExecutionState(ExecutionState.FAILED,errorMsg);
        }
      }
      if (verticesToBeDeployed.size() != submissionResultList.size()) {
        LOG.error(""String_Node_Str"");
      }
      int count=0;
      for (      final TaskSubmissionResult tsr : submissionResultList) {
        ExecutionVertex vertex=verticesToBeDeployed.get(count++);
        if (!vertex.getID().equals(tsr.getVertexID())) {
          LOG.error(""String_Node_Str"");
          vertex=null;
          for (          final ExecutionVertex candVertex : verticesToBeDeployed) {
            if (tsr.getVertexID().equals(candVertex.getID())) {
              vertex=candVertex;
              break;
            }
          }
          if (vertex == null) {
            LOG.error(""String_Node_Str"" + tsr.getVertexID());
            continue;
          }
        }
        if (tsr.getReturnCode() == AbstractTaskResult.ReturnCode.ERROR) {
          vertex.updateExecutionState(ExecutionState.FAILED,tsr.getDescription());
        }
      }
    }
  }
;
  this.executorService.execute(deploymentRunnable);
}","/** 
 * {@inheritDoc}
 */
@Override public void deploy(final JobID jobID,final AbstractInstance instance,final List<ExecutionVertex> verticesToBeDeployed){
  if (verticesToBeDeployed.isEmpty()) {
    LOG.error(""String_Node_Str"");
    return;
  }
  for (  final ExecutionVertex vertex : verticesToBeDeployed) {
    if (vertex.getExecutionState() != ExecutionState.READY) {
      LOG.error(""String_Node_Str"" + vertex + ""String_Node_Str""+ vertex.getExecutionState());
    }
    vertex.updateExecutionState(ExecutionState.STARTING,null);
  }
  final Runnable deploymentRunnable=new Runnable(){
    /** 
 * {@inheritDoc}
 */
    @Override public void run(){
      try {
        instance.checkLibraryAvailability(jobID);
      }
 catch (      IOException ioe) {
        LOG.error(""String_Node_Str"" + StringUtils.stringifyException(ioe));
      }
      final List<TaskSubmissionWrapper> submissionList=new SerializableArrayList<TaskSubmissionWrapper>();
      for (      final ExecutionVertex vertex : verticesToBeDeployed) {
        submissionList.add(new TaskSubmissionWrapper(vertex.getID(),vertex.getEnvironment(),vertex.getExecutionGraph().getJobConfiguration(),vertex.constructInitialActiveOutputChannelsSet()));
        LOG.info(""String_Node_Str"" + vertex + ""String_Node_Str""+ vertex.getAllocatedResource().getInstance());
      }
      List<TaskSubmissionResult> submissionResultList=null;
      try {
        submissionResultList=instance.submitTasks(submissionList);
      }
 catch (      final IOException ioe) {
        final String errorMsg=StringUtils.stringifyException(ioe);
        for (        final ExecutionVertex vertex : verticesToBeDeployed) {
          vertex.updateExecutionState(ExecutionState.FAILED,errorMsg);
        }
      }
      if (verticesToBeDeployed.size() != submissionResultList.size()) {
        LOG.error(""String_Node_Str"");
      }
      int count=0;
      for (      final TaskSubmissionResult tsr : submissionResultList) {
        ExecutionVertex vertex=verticesToBeDeployed.get(count++);
        if (!vertex.getID().equals(tsr.getVertexID())) {
          LOG.error(""String_Node_Str"");
          vertex=null;
          for (          final ExecutionVertex candVertex : verticesToBeDeployed) {
            if (tsr.getVertexID().equals(candVertex.getID())) {
              vertex=candVertex;
              break;
            }
          }
          if (vertex == null) {
            LOG.error(""String_Node_Str"" + tsr.getVertexID());
            continue;
          }
        }
        if (tsr.getReturnCode() == AbstractTaskResult.ReturnCode.ERROR) {
          vertex.updateExecutionState(ExecutionState.FAILED,tsr.getDescription());
        }
      }
    }
  }
;
  this.executorService.execute(deploymentRunnable);
}",0.9865567305968812
55683,"@Override public SopremoModule asElementaryOperators(){
  final SopremoModule sopremoModule=new SopremoModule(this.getName(),2,1);
  JsonStream input=sopremoModule.getInput(0);
  JsonStream nullInput=sopremoModule.getInput(1);
  int n=3;
  Partitioning partitioning=new Partitioning().withInputs(input);
  Grouping group=new Grouping().withInputs(partitioning).withGroupingKey(EvaluationExpression.KEY).withResetKey(false);
  final GenerateBinarySparseMatrix genMatrix=new GenerateBinarySparseMatrix().withInputs(group);
  final GenerateEmptyMatrix emptyMatrix=new GenerateEmptyMatrix().withInputs(nullInput);
  emptyMatrix.setN(n);
  final FillMatrix filledMatrix=new FillMatrix().withInputs(genMatrix,emptyMatrix);
  sopremoModule.getOutput(0).setInput(0,filledMatrix);
  return sopremoModule;
}","@Override public SopremoModule asElementaryOperators(){
  final SopremoModule sopremoModule=new SopremoModule(this.getName(),2,1);
  JsonStream input=sopremoModule.getInput(0);
  JsonStream nullInput=sopremoModule.getInput(1);
  int n=this.numberOfPartitions;
  Partitioning partitioning=new Partitioning().withInputs(input);
  partitioning.setNumberOfPartitions(n);
  Grouping group=new Grouping().withInputs(partitioning).withGroupingKey(EvaluationExpression.KEY).withResetKey(false);
  final GenerateBinarySparseMatrix genMatrix=new GenerateBinarySparseMatrix().withInputs(group);
  final GenerateEmptyMatrix emptyMatrix=new GenerateEmptyMatrix().withInputs(nullInput);
  emptyMatrix.setN(n);
  final FillMatrix filledMatrix=new FillMatrix().withInputs(genMatrix,emptyMatrix);
  sopremoModule.getOutput(0).setInput(0,filledMatrix);
  return sopremoModule;
}",0.955944477972239
55684,"@Override protected void map(JsonNode key,JsonNode value,JsonCollector out){
  for (int i=1; i <= n; i++) {
    for (int j=1; j <= i; j++) {
      out.collect(new ArrayNode(new IntNode(j),new IntNode(i)),new BinarySparseMatrix());
    }
  }
}","@Override protected void map(JsonNode key,JsonNode value,JsonCollector out){
  for (int i=0; i < n; i++) {
    for (int j=0; j <= i; j++) {
      out.collect(new ArrayNode(new IntNode(j),new IntNode(i)),new BinarySparseMatrix());
    }
  }
}",0.8861283643892339
55685,"@Override public SopremoModule asElementaryOperators(){
  final SopremoModule sopremoModule=new SopremoModule(this.getName(),2,1);
  JsonStream phase1=sopremoModule.getInput(0);
  JsonStream matrix=sopremoModule.getInput(1);
  final TransformDiagonal transDia=new TransformDiagonal().withInputs(phase1);
  final GenerateRows rows=new GenerateRows().withInputs(matrix);
  final ComputeBlockTuples computeRows=new ComputeBlockTuples().withInputs(transDia,rows);
  final GenerateColumns columns=new GenerateColumns().withInputs(computeRows);
  final ComputeBlockTuples computeTuples=new ComputeBlockTuples().withInputs(transDia,columns);
  sopremoModule.getOutput(0).setInput(0,computeTuples);
  return sopremoModule;
}","@Override public SopremoModule asElementaryOperators(){
  final SopremoModule sopremoModule=new SopremoModule(this.getName(),2,1);
  JsonStream phase1=sopremoModule.getInput(0);
  JsonStream matrix=sopremoModule.getInput(1);
  final TransformDiagonal transDia=new TransformDiagonal().withInputs(phase1);
  final GenerateRows rows=new GenerateRows().withInputs(matrix);
  final ComputeBlockTuples computeRows=new ComputeBlockTuples().withInputs(transDia,rows);
  final GenerateColumns columns=new GenerateColumns().withInputs(computeRows);
  final ComputeBlockTuples computeTuples=new ComputeBlockTuples().withInputs(transDia,columns);
  GenerateFullMatrix fullMatrix=new GenerateFullMatrix().withInputs(computeTuples);
  sopremoModule.getOutput(0).setInput(0,fullMatrix);
  return sopremoModule;
}",0.929279576999339
55686,"@Override protected void match(JsonNode key,JsonNode value1,JsonNode value2,JsonCollector out){
  JsonNode oldKeyPrimary=key;
  JsonNode oldKeyCurrent=((ArrayNode)value2).get(0);
  BinarySparseMatrix current=(BinarySparseMatrix)((ArrayNode)value2).get(1);
  if (oldKeyPrimary.equals(((ArrayNode)oldKeyCurrent).get(1))) {
    current=current.transpose();
  }
  TransitiveClosure.warshall((BinarySparseMatrix)value1,current);
  if (oldKeyPrimary.equals(((ArrayNode)oldKeyCurrent).get(1))) {
    current=current.transpose();
  }
  out.collect(oldKeyCurrent,current);
}","@Override protected void match(JsonNode key,JsonNode value1,JsonNode value2,JsonCollector out){
  JsonNode oldKeyPrimary=key;
  JsonNode oldKeyCurrent=((ArrayNode)value2).get(0);
  BinarySparseMatrix current=(BinarySparseMatrix)((ArrayNode)value2).get(1);
  if (oldKeyPrimary.equals(((ArrayNode)oldKeyCurrent).get(1))) {
    TransitiveClosure.warshall(current,(BinarySparseMatrix)value1,current);
  }
 else {
    TransitiveClosure.warshall((BinarySparseMatrix)value1,current,current);
  }
  out.collect(oldKeyCurrent,current);
}",0.7483989021043
55687,"@Override protected void map(JsonNode key,JsonNode value,JsonCollector out){
  if (((ArrayNode)key).get(0).compareTo(((ArrayNode)key).get(1)) > 0) {
    out.collect(new ArrayNode(((ArrayNode)key).get(1),((ArrayNode)key).get(0)),value);
  }
}","@Override protected void map(JsonNode key,JsonNode value,JsonCollector out){
  if (!((ArrayNode)key).get(0).equals(((ArrayNode)key).get(1))) {
    out.collect(new ArrayNode(((ArrayNode)key).get(1),((ArrayNode)key).get(0)),((BinarySparseMatrix)value).transpose());
  }
  out.collect(key,value);
}",0.5298507462686567
55688,"@Override public SopremoModule asElementaryOperators(){
  final SopremoModule sopremoModule=new SopremoModule(this.getName(),1,1);
  JsonStream input=sopremoModule.getInput(0);
  GenerateFullMatrix fullMatrix=new GenerateFullMatrix().withInputs(input);
  int itCount=3;
  ExtractRelatingBlocks xBlocks[]=new ExtractRelatingBlocks[itCount];
  ExtractNonRelatingBlocks abBlocks[]=new ExtractNonRelatingBlocks[itCount];
  TransformAKey[] a=new TransformAKey[itCount];
  TransformBKey[] b=new TransformBKey[itCount];
  TransformXKey[] x=new TransformXKey[itCount];
  BAndXMatch[] xb=new BAndXMatch[itCount];
  AMatch axb[]=new AMatch[itCount];
  UnionAll itOutput[]=new UnionAll[itCount];
  for (int i=0; i < itCount; i++) {
    JsonStream inputStream=i == 0 ? fullMatrix : itOutput[i - 1];
    xBlocks[i]=new ExtractRelatingBlocks().withInputs(inputStream);
    xBlocks[i].setIterationStep(i + 1);
    abBlocks[i]=new ExtractNonRelatingBlocks().withInputs(inputStream);
    abBlocks[i].setIterationStep(i + 1);
    a[i]=new TransformAKey().withInputs(abBlocks[i]);
    a[i].setIterationStep(i + 1);
    b[i]=new TransformBKey().withInputs(abBlocks[i]);
    b[i].setIterationStep(i + 1);
    x[i]=new TransformXKey().withInputs(xBlocks[i]);
    xb[i]=new BAndXMatch().withInputs(b[i],x[i]);
    axb[i]=new AMatch().withInputs(a[i],xb[i]);
    itOutput[i]=new UnionAll().withInputs(abBlocks[i],axb[i]);
  }
  sopremoModule.getOutput(0).setInput(0,itOutput[itCount - 1]);
  return sopremoModule;
}","@Override public SopremoModule asElementaryOperators(){
  final SopremoModule sopremoModule=new SopremoModule(this.getName(),1,1);
  JsonStream input=sopremoModule.getInput(0);
  int itCount=this.numberOfPartitions;
  ExtractRelatingBlocks xBlocks[]=new ExtractRelatingBlocks[itCount];
  ExtractNonRelatingBlocks abBlocks[]=new ExtractNonRelatingBlocks[itCount];
  TransformAKey[] a=new TransformAKey[itCount];
  TransformBKey[] b=new TransformBKey[itCount];
  TransformXKey[] x=new TransformXKey[itCount];
  BAndXMatch[] xb=new BAndXMatch[itCount];
  AMatch axb[]=new AMatch[itCount];
  UnionAll itOutput[]=new UnionAll[itCount];
  for (int i=0; i < itCount; i++) {
    JsonStream inputStream=i == 0 ? input : itOutput[i - 1];
    xBlocks[i]=new ExtractRelatingBlocks().withInputs(inputStream);
    xBlocks[i].setIterationStep(i);
    abBlocks[i]=new ExtractNonRelatingBlocks().withInputs(inputStream);
    abBlocks[i].setIterationStep(i);
    a[i]=new TransformAKey().withInputs(abBlocks[i]);
    a[i].setIterationStep(i);
    b[i]=new TransformBKey().withInputs(abBlocks[i]);
    b[i].setIterationStep(i);
    x[i]=new TransformXKey().withInputs(xBlocks[i]);
    xb[i]=new BAndXMatch().withInputs(b[i],x[i]);
    axb[i]=new AMatch().withInputs(a[i],xb[i]);
    itOutput[i]=new UnionAll().withInputs(abBlocks[i],axb[i]);
  }
  sopremoModule.getOutput(0).setInput(0,itOutput[itCount - 1]);
  return sopremoModule;
}",0.9473684210526316
55689,"@Override public SopremoModule asElementaryOperators(){
  final SopremoModule sopremoModule=new SopremoModule(this.getName(),2,1);
  JsonStream input=sopremoModule.getInput(0);
  JsonStream nullInput=sopremoModule.getInput(1);
  final GenerateMatrix filledMatrix=new GenerateMatrix().withInputs(input,nullInput);
  final Phase1 phase1=new Phase1().withInputs(filledMatrix);
  final Phase2 phase2=new Phase2().withInputs(phase1,filledMatrix);
  final Phase3 phase3=new Phase3().withInputs(new UnionAll().withInputs(phase1,phase2));
  final EmitMatrix result=new EmitMatrix().withInputs(phase3);
  sopremoModule.getOutput(0).setInput(0,result);
  return sopremoModule;
}","@Override public SopremoModule asElementaryOperators(){
  final SopremoModule sopremoModule=new SopremoModule(this.getName(),2,1);
  JsonStream input=sopremoModule.getInput(0);
  JsonStream nullInput=sopremoModule.getInput(1);
  final GenerateMatrix filledMatrix=new GenerateMatrix().withInputs(input,nullInput);
  filledMatrix.setNumberOfPartitions(this.numberOfPartitions);
  final Phase1 phase1=new Phase1().withInputs(filledMatrix);
  final Phase2 phase2=new Phase2().withInputs(phase1,filledMatrix);
  final Phase3 phase3=new Phase3().withInputs(new UnionAll().withInputs(phase1,phase2));
  phase3.setNumberOfPartitions(this.numberOfPartitions);
  final EmitMatrix result=new EmitMatrix().withInputs(phase3);
  sopremoModule.getOutput(0).setInput(0,result);
  return sopremoModule;
}",0.9175824175824177
55690,"/** 
 * Prints an error message and throws the given exception. If the exception is of the type  {@link ExceptionInChainedStubException} then the chain of contained exceptions is followeduntil an exception of a different type is found.
 * @param ex The exception to be thrown.
 * @param parent The parent task, whose information is included in the log message.
 * @throws Exception Always thrown.
 */
public static void logAndThrowException(Exception ex,AbstractInvokable parent) throws Exception {
  String taskName;
  if (ex instanceof ExceptionInChainedStubException) {
    do {
      ExceptionInChainedStubException cex=(ExceptionInChainedStubException)ex;
      taskName=cex.getTaskName();
      ex=cex.getWrappedException();
    }
 while (ex instanceof ExceptionInChainedStubException);
  }
 else {
    taskName=parent.getEnvironment().getTaskName();
  }
  if (LOG.isErrorEnabled())   LOG.error(constructLogString(""String_Node_Str"",taskName,parent));
  throw ex;
}","/** 
 * Prints an error message and throws the given exception. If the exception is of the type  {@link ExceptionInChainedStubException} then the chain of contained exceptions is followeduntil an exception of a different type is found.
 * @param ex The exception to be thrown.
 * @param parent The parent task, whose information is included in the log message.
 * @throws Exception Always thrown.
 */
public static void logAndThrowException(Exception ex,AbstractInvokable parent) throws Exception {
  String taskName;
  if (ex instanceof ExceptionInChainedStubException) {
    do {
      ExceptionInChainedStubException cex=(ExceptionInChainedStubException)ex;
      taskName=cex.getTaskName();
      ex=cex.getWrappedException();
    }
 while (ex instanceof ExceptionInChainedStubException);
  }
 else {
    taskName=parent.getEnvironment().getTaskName();
  }
  if (LOG.isErrorEnabled()) {
    LOG.error(constructLogString(""String_Node_Str"",taskName,parent));
    LOG.error(ex,ex);
  }
  throw ex;
}",0.9847715736040608
55691,"/** 
 * {@inheritDoc}
 */
@Override public void accept(Visitor<Contract> visitor){
  boolean descend=visitor.preVisit(this);
  if (descend) {
    if (visitor.preVisit(this)) {
      for (      Contract c : this.input1) {
        c.accept(visitor);
      }
      for (      Contract c : this.input2) {
        c.accept(visitor);
      }
    }
    visitor.postVisit(this);
  }
}","/** 
 * {@inheritDoc}
 */
@Override public void accept(Visitor<Contract> visitor){
  boolean descend=visitor.preVisit(this);
  if (descend) {
    for (    Contract c : this.input1) {
      c.accept(visitor);
    }
    for (    Contract c : this.input2) {
      c.accept(visitor);
    }
    visitor.postVisit(this);
  }
}",0.4655172413793103
55692,"/** 
 * Constructs a new auto-completion combo box.
 * @param parent the parent composite
 * @param style the style of the combo box
 * @param suggestions a list of suggestions for the auto-completion
 */
public AutoCompletionCombo(final Composite parent,final int style,final List<String> suggestions){
  super(parent,style);
  this.suggestions=new ArrayList<String>(suggestions);
  Collections.sort(this.suggestions);
  setLayout(new FillLayout());
  this.combo=new Combo(this,style);
  this.combo.addKeyListener(this);
  for (  final String suggestion : this.suggestions) {
    this.combo.add(suggestion);
  }
}","/** 
 * Constructs a new auto-completion combo box.
 * @param parent the parent composite
 * @param style the style of the combo box
 * @param suggestions a list of suggestions for the auto-completion
 */
public AutoCompletionCombo(final Composite parent,final int style,final List<String> suggestions){
  super(parent,style);
  this.suggestions=new ArrayList<String>(suggestions);
  Collections.sort(this.suggestions);
  setLayout(new FillLayout());
  this.combo=new Combo(this,style);
  this.combo.addKeyListener(this);
  this.combo.addSelectionListener(this);
  for (  final String suggestion : this.suggestions) {
    this.combo.add(suggestion);
  }
}",0.8778565799842396
55693,"@Override public SopremoModule asElementaryOperators(){
  final SopremoModule sopremoModule=new SopremoModule(this.getName(),2,1);
  JsonStream phase1=sopremoModule.getInput(0);
  JsonStream matrix=sopremoModule.getInput(1);
  final TransformDiagonal transDia=new TransformDiagonal().withInputs(phase1);
  final GenerateRows rows=new GenerateRows().withInputs(matrix);
  final ComputeBlockTuples computeRows=new ComputeBlockTuples().withInputs(transDia,rows);
  final ExtractMirroredMatrix mirroredMatrix=new ExtractMirroredMatrix().withInputs(computeRows);
  final FillMatrix fillMatrix=new FillMatrix().withInputs(computeRows,mirroredMatrix);
  sopremoModule.getOutput(0).setInput(0,fillMatrix);
  return sopremoModule;
}","@Override public SopremoModule asElementaryOperators(){
  final SopremoModule sopremoModule=new SopremoModule(this.getName(),2,1);
  JsonStream phase1=sopremoModule.getInput(0);
  JsonStream matrix=sopremoModule.getInput(1);
  final TransformDiagonal transDia=new TransformDiagonal().withInputs(phase1);
  final GenerateRows rows=new GenerateRows().withInputs(matrix);
  final ComputeBlockTuples computeRows=new ComputeBlockTuples().withInputs(transDia,rows);
  final GenerateColumns columns=new GenerateColumns().withInputs(computeRows);
  final ComputeBlockTuples computeTuples=new ComputeBlockTuples().withInputs(transDia,columns);
  sopremoModule.getOutput(0).setInput(0,computeTuples);
  return sopremoModule;
}",0.8075052119527449
55694,"@Override protected void match(JsonNode key,JsonNode value1,JsonNode value2,JsonCollector out){
  JsonNode oldKey=((ArrayNode)value2).get(0);
  TransitiveClosure.warshall((BinarySparseMatrix)value1,(BinarySparseMatrix)((ArrayNode)value2).get(1));
  out.collect(oldKey,((ArrayNode)value2).get(1));
}","@Override protected void match(JsonNode key,JsonNode value1,JsonNode value2,JsonCollector out){
  JsonNode oldKeyPrimary=key;
  JsonNode oldKeyCurrent=((ArrayNode)value2).get(0);
  BinarySparseMatrix current=(BinarySparseMatrix)((ArrayNode)value2).get(1);
  if (oldKeyPrimary.equals(((ArrayNode)oldKeyCurrent).get(1))) {
    current=current.transpose();
  }
  TransitiveClosure.warshall((BinarySparseMatrix)value1,current);
  if (oldKeyPrimary.equals(((ArrayNode)oldKeyCurrent).get(1))) {
    current=current.transpose();
  }
  out.collect(oldKeyCurrent,current);
}",0.4078794901506373
55695,"@Override public SopremoModule asElementaryOperators(){
  final SopremoModule sopremoModule=new SopremoModule(this.getName(),1,1);
  JsonStream input=sopremoModule.getInput(0);
  int itCount=3;
  TransformAKey[] a=new TransformAKey[itCount];
  TransformBKey[] b=new TransformBKey[itCount];
  TransformXKey[] x=new TransformXKey[itCount];
  BAndXMatch[] xb=new BAndXMatch[itCount];
  AMatch axb[]=new AMatch[itCount];
  for (int i=0; i < itCount; i++) {
    a[i]=new TransformAKey().withInputs(i == 0 ? input : axb[i - 1]);
    a[i].setIterationStep(i + 1);
    b[i]=new TransformBKey().withInputs(i == 0 ? input : axb[i - 1]);
    b[i].setIterationStep(i + 1);
    x[i]=new TransformXKey().withInputs(i == 0 ? input : axb[i - 1]);
    xb[i]=new BAndXMatch().withInputs(b[i],x[i]);
    axb[i]=new AMatch().withInputs(a[i],xb[i]);
  }
  sopremoModule.getOutput(0).setInput(0,axb[itCount - 1]);
  return sopremoModule;
}","@Override public SopremoModule asElementaryOperators(){
  final SopremoModule sopremoModule=new SopremoModule(this.getName(),1,1);
  JsonStream input=sopremoModule.getInput(0);
  int itCount=3;
  ExtractNonRelatingBlocks otherBlocks[]=new ExtractNonRelatingBlocks[itCount];
  TransformAKey[] a=new TransformAKey[itCount];
  TransformBKey[] b=new TransformBKey[itCount];
  TransformXKey[] x=new TransformXKey[itCount];
  BAndXMatch[] xb=new BAndXMatch[itCount];
  AMatch axb[]=new AMatch[itCount];
  UnionAll itOutput[]=new UnionAll[itCount];
  for (int i=0; i < itCount; i++) {
    JsonStream inputStream=i == 0 ? input : itOutput[i - 1];
    otherBlocks[i]=new ExtractNonRelatingBlocks().withInputs(inputStream);
    otherBlocks[i].setIterationStep(i + 1);
    a[i]=new TransformAKey().withInputs(inputStream);
    a[i].setIterationStep(i + 1);
    b[i]=new TransformBKey().withInputs(inputStream);
    b[i].setIterationStep(i + 1);
    x[i]=new TransformXKey().withInputs(inputStream);
    xb[i]=new BAndXMatch().withInputs(b[i],x[i]);
    axb[i]=new AMatch().withInputs(a[i],xb[i]);
    itOutput[i]=new UnionAll().withInputs(axb[i],otherBlocks[i]);
  }
  sopremoModule.getOutput(0).setInput(0,itOutput[itCount - 1]);
  return sopremoModule;
}",0.7733580018501388
55696,"@Override public SopremoModule asElementaryOperators(){
  final SopremoModule sopremoModule=new SopremoModule(this.getName(),2,1);
  JsonStream input=sopremoModule.getInput(0);
  JsonStream nullInput=sopremoModule.getInput(1);
  int n=3;
  Partitioning partitioning=new Partitioning().withInputs(input);
  Grouping group=new Grouping().withInputs(partitioning).withGroupingKey(EvaluationExpression.KEY).withResetKey(false);
  final GenerateMatrix genMatrix=new GenerateMatrix().withInputs(group);
  final GenerateEmptyMatrix emptyMatrix=new GenerateEmptyMatrix().withInputs(nullInput);
  emptyMatrix.setN(n);
  final FillMatrix filledMatrix=new FillMatrix().withInputs(genMatrix,emptyMatrix);
  final Phase1 phase1=new Phase1().withInputs(filledMatrix);
  final Phase2 phase2=new Phase2().withInputs(phase1,genMatrix);
  final Phase3 phase3=new Phase3().withInputs(new UnionAll().withInputs(phase1,phase2));
  final EmitMatrix result=new EmitMatrix().withInputs(new UnionAll().withInputs(phase1,phase2));
  sopremoModule.getOutput(0).setInput(0,result);
  return sopremoModule;
}","@Override public SopremoModule asElementaryOperators(){
  final SopremoModule sopremoModule=new SopremoModule(this.getName(),2,1);
  JsonStream input=sopremoModule.getInput(0);
  JsonStream nullInput=sopremoModule.getInput(1);
  int n=3;
  Partitioning partitioning=new Partitioning().withInputs(input);
  Grouping group=new Grouping().withInputs(partitioning).withGroupingKey(EvaluationExpression.KEY).withResetKey(false);
  final GenerateMatrix genMatrix=new GenerateMatrix().withInputs(group);
  final GenerateEmptyMatrix emptyMatrix=new GenerateEmptyMatrix().withInputs(nullInput);
  emptyMatrix.setN(n);
  final FillMatrix filledMatrix=new FillMatrix().withInputs(genMatrix,emptyMatrix);
  final Phase1 phase1=new Phase1().withInputs(filledMatrix);
  final Phase2 phase2=new Phase2().withInputs(phase1,filledMatrix);
  final Phase3 phase3=new Phase3().withInputs(new UnionAll().withInputs(phase1,phase2));
  final EmitMatrix result=new EmitMatrix().withInputs(phase3);
  sopremoModule.getOutput(0).setInput(0,result);
  return sopremoModule;
}",0.9741419840150448
55697,"/** 
 * Creates the record readers for the number of inputs as defined by   {@link #getNumberOfInputs()}.
 */
protected void initInputs(){
  int numInputs=getNumberOfInputs();
  @SuppressWarnings(""String_Node_Str"") final MutableObjectIterator<PactRecord>[] inputs=new MutableObjectIterator[numInputs];
  for (int i=0; i < numInputs; i++) {
    final ShipStrategy shipStrategy=this.config.getInputShipStrategy(i);
    DistributionPattern dp=null;
switch (shipStrategy) {
case FORWARD:
case PARTITION_LOCAL_HASH:
case PARTITION_LOCAL_RANGE:
      dp=new PointwiseDistributionPattern();
    break;
case PARTITION_HASH:
case PARTITION_RANGE:
case BROADCAST:
case SFR:
  dp=new BipartiteDistributionPattern();
break;
default :
throw new RuntimeException(""String_Node_Str"" + i + ""String_Node_Str""+ shipStrategy.name());
}
final int groupSize=this.config.getGroupSize(i + 1);
if (groupSize == 1) {
inputs[i]=new NepheleReaderIterator(new MutableRecordReader<PactRecord>(this,dp));
}
 else {
@SuppressWarnings(""String_Node_Str"") MutableRecordReader<PactRecord>[] readers=new MutableRecordReader[groupSize];
for (int j=0; j < groupSize; ++j) {
readers[j]=new MutableRecordReader<PactRecord>(this,dp);
}
inputs[i]=new NepheleReaderIterator(new MutableUnionRecordReader<PactRecord>(readers));
}
}
this.inputs=inputs;
}","/** 
 * Creates the record readers for the number of inputs as defined by   {@link #getNumberOfInputs()}.
 */
protected void initInputs(){
  int numInputs=getNumberOfInputs();
  @SuppressWarnings(""String_Node_Str"") final MutableObjectIterator<PactRecord>[] inputs=new MutableObjectIterator[numInputs];
  for (int i=0; i < numInputs; i++) {
    final ShipStrategy shipStrategy=this.config.getInputShipStrategy(i);
    DistributionPattern dp=null;
switch (shipStrategy) {
case FORWARD:
case PARTITION_LOCAL_HASH:
case PARTITION_LOCAL_RANGE:
      dp=new PointwiseDistributionPattern();
    break;
case PARTITION_HASH:
case PARTITION_RANGE:
case BROADCAST:
case SFR:
  dp=new BipartiteDistributionPattern();
break;
default :
throw new RuntimeException(""String_Node_Str"" + i + ""String_Node_Str""+ shipStrategy.name());
}
final int groupSize=this.config.getGroupSize(i + 1);
if (groupSize < 2) {
inputs[i]=new NepheleReaderIterator(new MutableRecordReader<PactRecord>(this,dp));
}
 else {
@SuppressWarnings(""String_Node_Str"") MutableRecordReader<PactRecord>[] readers=new MutableRecordReader[groupSize];
for (int j=0; j < groupSize; ++j) {
readers[j]=new MutableRecordReader<PactRecord>(this,dp);
}
inputs[i]=new NepheleReaderIterator(new MutableUnionRecordReader<PactRecord>(readers));
}
}
this.inputs=inputs;
}",0.9973210868733255
55698,"/** 
 * {@inheritDoc}
 */
@Override public void transferEvent(AbstractEvent event) throws IOException, InterruptedException {
  this.outputChannelBroker.transferEventToInputChannel(event);
  flush();
}","/** 
 * {@inheritDoc}
 */
@Override public void transferEvent(AbstractEvent event) throws IOException, InterruptedException {
  flush();
  this.outputChannelBroker.transferEventToInputChannel(event);
}",0.6865671641791045
55699,"/** 
 * {@inheritDoc}
 */
@Override public void requestClose() throws IOException, InterruptedException {
  if (!this.closeRequested) {
    this.closeRequested=true;
    flush();
    transferEvent(new ByteBufferedChannelCloseEvent());
  }
}","/** 
 * {@inheritDoc}
 */
@Override public void requestClose() throws IOException, InterruptedException {
  if (!this.closeRequested) {
    this.closeRequested=true;
    transferEvent(new ByteBufferedChannelCloseEvent());
    flush();
  }
}",0.9458333333333332
55700,"@Override public BufferPairResponse getReadBufferToConsume(){
  TransferEnvelope transferEnvelope=null;
synchronized (this.queuedEnvelopes) {
    if (this.queuedEnvelopes.isEmpty()) {
      return null;
    }
    transferEnvelope=this.queuedEnvelopes.peek();
    if (transferEnvelope.getBuffer() == null) {
      this.queuedEnvelopes.poll();
    }
  }
  if (transferEnvelope.getBuffer() == null) {
    final EventList eventList=transferEnvelope.getEventList();
    if (!eventList.isEmpty()) {
      final Iterator<AbstractEvent> it=eventList.iterator();
      while (it.hasNext()) {
        this.byteBufferedInputChannel.processEvent(it.next());
      }
    }
    return null;
  }
  BufferPairResponse response;
  if (this.byteBufferedInputChannel.getCompressionLevel() == CompressionLevel.NO_COMPRESSION) {
    response=new BufferPairResponse(null,transferEnvelope.getBuffer());
  }
 else {
    final int maximumBufferSize=this.byteBufferedChannelManager.getMaximumBufferSize();
    final BufferPairRequest request=new BufferPairRequest(transferEnvelope.getBuffer().isBackedByMemory() ? -1 : transferEnvelope.getBuffer().size(),maximumBufferSize,true);
    try {
      response=this.byteBufferedChannelManager.requestEmptyReadBuffers(request);
    }
 catch (    InterruptedException e) {
      this.byteBufferedInputChannel.checkForNetworkEvents();
      return null;
    }
    if (transferEnvelope.getBuffer().isBackedByMemory()) {
      response=new BufferPairResponse(transferEnvelope.getBuffer(),response.getUncompressedDataBuffer());
    }
 else {
      final Buffer oldBuffer=transferEnvelope.getBuffer();
      try {
        oldBuffer.copyToMemoryBackedBuffer(response.getCompressedDataBuffer());
        transferEnvelope.setBuffer(response.getCompressedDataBuffer());
      }
 catch (      IOException ioe) {
        LOG.error(ioe);
        this.byteBufferedInputChannel.reportIOException(ioe);
        return null;
      }
      oldBuffer.recycleBuffer();
    }
    this.uncompressedDataBuffer=response.getUncompressedDataBuffer();
  }
  final EventList eventList=transferEnvelope.getEventList();
  if (!eventList.isEmpty()) {
    final Iterator<AbstractEvent> it=eventList.iterator();
    while (it.hasNext()) {
      this.byteBufferedInputChannel.processEvent(it.next());
    }
  }
  return response;
}","@Override public BufferPairResponse getReadBufferToConsume(){
  TransferEnvelope transferEnvelope=null;
synchronized (this.queuedEnvelopes) {
    if (this.queuedEnvelopes.isEmpty()) {
      return null;
    }
    transferEnvelope=this.queuedEnvelopes.peek();
    if (transferEnvelope.getBuffer() == null) {
      this.queuedEnvelopes.poll();
    }
  }
  if (transferEnvelope.getBuffer() == null) {
    final EventList eventList=transferEnvelope.getEventList();
    if (!eventList.isEmpty()) {
      final Iterator<AbstractEvent> it=eventList.iterator();
      while (it.hasNext()) {
        this.byteBufferedInputChannel.processEvent(it.next());
      }
    }
    return null;
  }
  BufferPairResponse response;
  if (this.byteBufferedInputChannel.getCompressionLevel() == CompressionLevel.NO_COMPRESSION) {
    response=new BufferPairResponse(null,transferEnvelope.getBuffer());
  }
 else {
    final int maximumBufferSize=this.byteBufferedChannelManager.getMaximumBufferSize();
    final BufferPairRequest request=new BufferPairRequest(transferEnvelope.getBuffer().isBackedByMemory() ? -1 : transferEnvelope.getBuffer().size(),maximumBufferSize,true);
    try {
      response=this.byteBufferedChannelManager.requestEmptyReadBuffers(request);
    }
 catch (    InterruptedException e) {
      this.byteBufferedInputChannel.checkForNetworkEvents();
      return null;
    }
    if (transferEnvelope.getBuffer().isBackedByMemory()) {
      response=new BufferPairResponse(transferEnvelope.getBuffer(),response.getUncompressedDataBuffer());
    }
 else {
      final Buffer oldBuffer=transferEnvelope.getBuffer();
      try {
        oldBuffer.copyToMemoryBackedBuffer(response.getCompressedDataBuffer());
        transferEnvelope.setBuffer(response.getCompressedDataBuffer());
      }
 catch (      IOException ioe) {
        LOG.error(ioe);
        this.byteBufferedInputChannel.reportIOException(ioe);
        return null;
      }
      oldBuffer.recycleBuffer();
    }
    this.uncompressedDataBuffer=response.getUncompressedDataBuffer();
  }
  return response;
}",0.9356164383561644
55701,"@Override public void releaseConsumedReadBuffer(){
  TransferEnvelope transferEnvelope=null;
synchronized (this.queuedEnvelopes) {
    if (this.queuedEnvelopes.isEmpty()) {
      LOG.error(""String_Node_Str"");
      return;
    }
    transferEnvelope=this.queuedEnvelopes.poll();
    if (transferEnvelope.getBuffer() != null) {
      if (transferEnvelope.getBuffer().isBackedByMemory()) {
        --this.numberOfMemoryBuffers;
      }
 else {
        --this.numberOfFileBuffers;
      }
    }
  }
  final Buffer consumedBuffer=transferEnvelope.getBuffer();
  if (consumedBuffer == null) {
    LOG.error(""String_Node_Str"");
    return;
  }
  if (consumedBuffer.remaining() > 0) {
    LOG.error(""String_Node_Str"" + consumedBuffer.remaining() + ""String_Node_Str"");
  }
  consumedBuffer.recycleBuffer();
  if (this.uncompressedDataBuffer != null) {
    this.uncompressedDataBuffer.recycleBuffer();
    this.uncompressedDataBuffer=null;
  }
}","@Override public void releaseConsumedReadBuffer(){
  TransferEnvelope transferEnvelope=null;
synchronized (this.queuedEnvelopes) {
    if (this.queuedEnvelopes.isEmpty()) {
      LOG.error(""String_Node_Str"");
      return;
    }
    transferEnvelope=this.queuedEnvelopes.poll();
    if (transferEnvelope.getBuffer() != null) {
      if (transferEnvelope.getBuffer().isBackedByMemory()) {
        --this.numberOfMemoryBuffers;
      }
 else {
        --this.numberOfFileBuffers;
      }
    }
  }
  final EventList eventList=transferEnvelope.getEventList();
  if (!eventList.isEmpty()) {
    final Iterator<AbstractEvent> it=eventList.iterator();
    while (it.hasNext()) {
      this.byteBufferedInputChannel.processEvent(it.next());
    }
  }
  final Buffer consumedBuffer=transferEnvelope.getBuffer();
  if (consumedBuffer == null) {
    LOG.error(""String_Node_Str"");
    return;
  }
  if (consumedBuffer.remaining() > 0) {
    LOG.error(""String_Node_Str"" + consumedBuffer.remaining() + ""String_Node_Str"");
  }
  consumedBuffer.recycleBuffer();
  if (this.uncompressedDataBuffer != null) {
    this.uncompressedDataBuffer.recycleBuffer();
    this.uncompressedDataBuffer=null;
  }
}",0.8830188679245283
55702,"/** 
 * Registers a new job represented by its   {@link ExecutionGraph} with the input split manager.
 * @param executionGraph the job to be registered
 */
public void registerJob(final ExecutionGraph executionGraph){
  final Iterator<ExecutionGroupVertex> it=new ExecutionGroupVertexIterator(executionGraph,true,-1);
  while (it.hasNext()) {
    final ExecutionGroupVertex groupVertex=it.next();
    final InputSplit[] inputSplits=groupVertex.getInputSplits();
    if (inputSplits == null) {
      continue;
    }
    if (inputSplits.length == 0) {
      continue;
    }
    final AbstractInvokable invokable=groupVertex.getGroupMember(0).getEnvironment().getInvokable();
    if (!(invokable instanceof AbstractInputTask)) {
      LOG.error(groupVertex.getName() + ""String_Node_Str"" + inputSplits.length+ ""String_Node_Str"");
      continue;
    }
    @SuppressWarnings(""String_Node_Str"") final AbstractInputTask<? extends InputSplit> inputTask=(AbstractInputTask<? extends InputSplit>)invokable;
    final Class<? extends InputSplit> splitType=inputTask.getInputSplitType();
    final InputSplitAssigner assigner=getAssignerByType(splitType,true,executionGraph.getJobID());
    this.assignerCache.put(groupVertex,assigner);
    assigner.registerGroupVertex(groupVertex);
  }
}","/** 
 * Registers a new job represented by its   {@link ExecutionGraph} with the input split manager.
 * @param executionGraph the job to be registered
 */
public void registerJob(final ExecutionGraph executionGraph){
  final Iterator<ExecutionGroupVertex> it=new ExecutionGroupVertexIterator(executionGraph,true,-1);
  while (it.hasNext()) {
    final ExecutionGroupVertex groupVertex=it.next();
    final InputSplit[] inputSplits=groupVertex.getInputSplits();
    if (inputSplits == null) {
      continue;
    }
    if (inputSplits.length == 0) {
      continue;
    }
    final AbstractInvokable invokable=groupVertex.getGroupMember(0).getEnvironment().getInvokable();
    if (!(invokable instanceof AbstractInputTask)) {
      LOG.error(groupVertex.getName() + ""String_Node_Str"" + inputSplits.length+ ""String_Node_Str"");
      continue;
    }
    @SuppressWarnings(""String_Node_Str"") final AbstractInputTask<? extends InputSplit> inputTask=(AbstractInputTask<? extends InputSplit>)invokable;
    final Class<? extends InputSplit> splitType=inputTask.getInputSplitType();
    final InputSplitAssigner assigner=getAssignerByType(splitType,true);
    this.assignerCache.put(groupVertex,assigner);
    assigner.registerGroupVertex(groupVertex);
  }
}",0.9153481012658228
55703,"/** 
 * Attempts to find the responsible type of   {@link InputSplitAssigner} for the given type of input split from theconfiguration and instantiate an object for it.
 * @param inputSplitType the type of input split to load the  {@link InputSplitAssigner} for
 * @return the newly loaded {@link InputSplitAssigner} object or <code>null</code> if no such object could belocated or loaded
 */
@SuppressWarnings(""String_Node_Str"") private InputSplitAssigner loadInputSplitAssigner(final Class<? extends InputSplit> inputSplitType,JobID jid){
  final String typeClassName=inputSplitType.getSimpleName();
  final String assignerKey=INPUT_SPLIT_CONFIG_KEY_PREFIX + typeClassName;
  LOG.info(""String_Node_Str"" + typeClassName);
  String assignerClassName=GlobalConfiguration.getString(assignerKey,null);
  if (assignerClassName == null) {
    if (FileInputSplit.class.getSimpleName().equals(typeClassName)) {
      assignerClassName=FileInputSplitAssigner.class.getName();
    }
 else {
      return null;
    }
  }
  try {
    Class<? extends InputSplitAssigner> assignerClass;
    boolean useUserJar=GlobalConfiguration.getBoolean(INPUT_SPLIT_CONFIG_KEY_PREFIX + ""String_Node_Str"",false);
    if (useUserJar) {
      final ClassLoader cl=LibraryCacheManager.getClassLoader(jid);
      assignerClass=(Class<? extends InputSplitAssigner>)Class.forName(assignerClassName,true,cl);
    }
 else {
      assignerClass=(Class<? extends InputSplitAssigner>)Class.forName(assignerClassName);
    }
    return assignerClass.newInstance();
  }
 catch (  Exception e) {
    LOG.error(StringUtils.stringifyException(e));
  }
  return null;
}","/** 
 * Attempts to find the responsible type of   {@link InputSplitAssigner} for the given type of input split from theconfiguration and instantiate an object for it.
 * @param inputSplitType the type of input split to load the  {@link InputSplitAssigner} for
 * @return the newly loaded {@link InputSplitAssigner} object or <code>null</code> if no such object could belocated or loaded
 */
private InputSplitAssigner loadInputSplitAssigner(final Class<? extends InputSplit> inputSplitType){
  final String typeClassName=inputSplitType.getSimpleName();
  final String assignerKey=INPUT_SPLIT_CONFIG_KEY_PREFIX + typeClassName;
  LOG.info(""String_Node_Str"" + typeClassName);
  String assignerClassName=GlobalConfiguration.getString(assignerKey,null);
  if (assignerClassName == null) {
    if (FileInputSplit.class.getSimpleName().equals(typeClassName)) {
      assignerClassName=FileInputSplitAssigner.class.getName();
    }
 else {
      return null;
    }
  }
  try {
    @SuppressWarnings(""String_Node_Str"") final Class<? extends InputSplitAssigner> assignerClass=(Class<? extends InputSplitAssigner>)Class.forName(assignerClassName);
    return assignerClass.newInstance();
  }
 catch (  Exception e) {
    LOG.error(StringUtils.stringifyException(e));
  }
  return null;
}",0.8511371467953136
55704,"/** 
 * Returns the   {@link InputSplitAssigner} which is defined for the given type of input split.
 * @param inputSplitType the type of input split to find the corresponding  {@link InputSplitAssigner} for
 * @param allowLoading <code>true</code> to indicate that the input split assigner is allowed to load additional classes if necessary, <code>false</code> otherwise
 * @return the {@link InputSplitAssigner} responsible for the given type of input split
 */
private InputSplitAssigner getAssignerByType(final Class<? extends InputSplit> inputSplitType,final boolean allowLoading,JobID jid){
synchronized (this.loadedAssigners) {
    InputSplitAssigner assigner=this.loadedAssigners.get(inputSplitType);
    if (assigner == null && allowLoading) {
      assigner=loadInputSplitAssigner(inputSplitType,jid);
      if (assigner != null) {
        this.loadedAssigners.put(inputSplitType,assigner);
      }
    }
    if (assigner != null) {
      return assigner;
    }
  }
  LOG.warn(""String_Node_Str"" + inputSplitType.getName() + ""String_Node_Str"");
  return this.defaultAssigner;
}","/** 
 * Returns the   {@link InputSplitAssigner} which is defined for the given type of input split.
 * @param inputSplitType the type of input split to find the corresponding  {@link InputSplitAssigner} for
 * @param allowLoading <code>true</code> to indicate that the input split assigner is allowed to load additional classes if necessary, <code>false</code> otherwise
 * @return the {@link InputSplitAssigner} responsible for the given type of input split
 */
private InputSplitAssigner getAssignerByType(final Class<? extends InputSplit> inputSplitType,final boolean allowLoading){
synchronized (this.loadedAssigners) {
    InputSplitAssigner assigner=this.loadedAssigners.get(inputSplitType);
    if (assigner == null && allowLoading) {
      assigner=loadInputSplitAssigner(inputSplitType);
      if (assigner != null) {
        this.loadedAssigners.put(inputSplitType,assigner);
      }
    }
    if (assigner != null) {
      return assigner;
    }
  }
  LOG.warn(""String_Node_Str"" + inputSplitType.getName() + ""String_Node_Str"");
  return this.defaultAssigner;
}",0.9935125115848008
55705,"/** 
 * {@inheritDoc}
 */
@Override public void accept(Visitor<Contract> visitor){
  boolean descend=visitor.preVisit(this);
  if (descend) {
    for (    Contract c : this.input1) {
      c.accept(visitor);
    }
    for (    Contract c : this.input2) {
      c.accept(visitor);
    }
    visitor.postVisit(this);
  }
}","/** 
 * {@inheritDoc}
 */
@Override public void accept(Visitor<Contract> visitor){
  boolean descend=visitor.preVisit(this);
  if (descend) {
    if (visitor.preVisit(this)) {
      for (      Contract c : this.input1) {
        c.accept(visitor);
      }
      for (      Contract c : this.input2) {
        c.accept(visitor);
      }
    }
    visitor.postVisit(this);
  }
}",0.9022988505747126
55706,"/** 
 * Retrieves the index of the <tt>BlockLocation</tt> that contains the part of the file described by the given offset.
 * @param blocks The different blocks of the file. Must be ordered by their offset.
 * @param offset The offset of the position in the file.
 * @param startIndex The earliest index to look at.
 * @return The index of the block containing the given position.
 */
protected final int getBlockIndexForPosition(BlockLocation[] blocks,long offset,long halfSplitSize,int startIndex){
  for (int i=startIndex; i < blocks.length; i++) {
    long blockStart=blocks[i].getOffset();
    long blockEnd=blockStart + blocks[i].getLength();
    if (offset >= blockStart && offset < blockEnd) {
      if (i < blocks.length - 1 && blockEnd - offset < halfSplitSize) {
        return i + 1;
      }
 else {
        return i;
      }
    }
  }
  throw new IllegalArgumentException(""String_Node_Str"");
}","/** 
 * Retrieves the index of the <tt>BlockLocation</tt> that contains the part of the file described by the given offset.
 * @param blocks The different blocks of the file. Must be ordered by their offset.
 * @param offset The offset of the position in the file.
 * @param startIndex The earliest index to look at.
 * @return The index of the block containing the given position.
 */
private final int getBlockIndexForPosition(BlockLocation[] blocks,long offset,long halfSplitSize,int startIndex){
  for (int i=startIndex; i < blocks.length; i++) {
    long blockStart=blocks[i].getOffset();
    long blockEnd=blockStart + blocks[i].getLength();
    if (offset >= blockStart && offset < blockEnd) {
      if (i < blocks.length - 1 && blockEnd - offset < halfSplitSize) {
        return i + 1;
      }
 else {
        return i;
      }
    }
  }
  throw new IllegalArgumentException(""String_Node_Str"");
}",0.9933774834437086
55707,"/** 
 * Opens an input stream to the file defined in the input format. The stream is positioned at the beginning of the given split. <p> The stream is actually opened in an asynchronous thread to make sure any interruptions to the thread  working on the input format do not reach the file system.
 * @see eu.stratosphere.pact.common.io.InputFormat#open(eu.stratosphere.nephele.template.InputSplit)
 */
@Override public void open(FileInputSplit split) throws IOException {
  if (!(split instanceof FileInputSplit)) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  final FileInputSplit fileSplit=(FileInputSplit)split;
  fileNumber=Integer.parseInt(split.getPath().getName());
  this.start=fileSplit.getStart();
  this.length=fileSplit.getLength();
  if (LOG.isDebugEnabled())   LOG.debug(""String_Node_Str"" + fileSplit.getPath() + ""String_Node_Str""+ start+ ""String_Node_Str""+ length+ ""String_Node_Str"");
  final InputSplitOpenThread isot=new InputSplitOpenThread(fileSplit,OPEN_TIMEOUT_MILLIES);
  isot.start();
  try {
    isot.waitForCompletion();
  }
 catch (  Throwable t) {
    throw new IOException(""String_Node_Str"" + fileSplit.getPath() + ""String_Node_Str""+ start+ ""String_Node_Str""+ length+ ""String_Node_Str""+ t.getMessage(),t);
  }
  this.stream=isot.getFSDataInputStream();
  this.stream.seek(this.start);
}","/** 
 * Opens an input stream to the file defined in the input format. The stream is positioned at the beginning of the given split. <p> The stream is actually opened in an asynchronous thread to make sure any interruptions to the thread  working on the input format do not reach the file system.
 * @see eu.stratosphere.pact.common.io.InputFormat#open(eu.stratosphere.nephele.template.InputSplit)
 */
@Override public void open(FileInputSplit split) throws IOException {
  if (!(split instanceof FileInputSplit)) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  final FileInputSplit fileSplit=(FileInputSplit)split;
  this.start=fileSplit.getStart();
  this.length=fileSplit.getLength();
  if (LOG.isDebugEnabled())   LOG.debug(""String_Node_Str"" + fileSplit.getPath() + ""String_Node_Str""+ start+ ""String_Node_Str""+ length+ ""String_Node_Str"");
  final InputSplitOpenThread isot=new InputSplitOpenThread(fileSplit,OPEN_TIMEOUT_MILLIES);
  isot.start();
  try {
    isot.waitForCompletion();
  }
 catch (  Throwable t) {
    throw new IOException(""String_Node_Str"" + fileSplit.getPath() + ""String_Node_Str""+ start+ ""String_Node_Str""+ length+ ""String_Node_Str""+ t.getMessage(),t);
  }
  this.stream=isot.getFSDataInputStream();
  this.stream.seek(this.start);
}",0.9777777777777776
55708,"/** 
 * Registers a new job represented by its   {@link ExecutionGraph} with the input split manager.
 * @param executionGraph the job to be registered
 */
public void registerJob(final ExecutionGraph executionGraph){
  final Iterator<ExecutionGroupVertex> it=new ExecutionGroupVertexIterator(executionGraph,true,-1);
  while (it.hasNext()) {
    final ExecutionGroupVertex groupVertex=it.next();
    final InputSplit[] inputSplits=groupVertex.getInputSplits();
    if (inputSplits == null) {
      continue;
    }
    if (inputSplits.length == 0) {
      continue;
    }
    final AbstractInvokable invokable=groupVertex.getGroupMember(0).getEnvironment().getInvokable();
    if (!(invokable instanceof AbstractInputTask)) {
      LOG.error(groupVertex.getName() + ""String_Node_Str"" + inputSplits.length+ ""String_Node_Str"");
      continue;
    }
    @SuppressWarnings(""String_Node_Str"") final AbstractInputTask<? extends InputSplit> inputTask=(AbstractInputTask<? extends InputSplit>)invokable;
    final Class<? extends InputSplit> splitType=inputTask.getInputSplitType();
    final InputSplitAssigner assigner=getAssignerByType(splitType,true);
    this.assignerCache.put(groupVertex,assigner);
    assigner.registerGroupVertex(groupVertex);
  }
}","/** 
 * Registers a new job represented by its   {@link ExecutionGraph} with the input split manager.
 * @param executionGraph the job to be registered
 */
public void registerJob(final ExecutionGraph executionGraph){
  final Iterator<ExecutionGroupVertex> it=new ExecutionGroupVertexIterator(executionGraph,true,-1);
  while (it.hasNext()) {
    final ExecutionGroupVertex groupVertex=it.next();
    final InputSplit[] inputSplits=groupVertex.getInputSplits();
    if (inputSplits == null) {
      continue;
    }
    if (inputSplits.length == 0) {
      continue;
    }
    final AbstractInvokable invokable=groupVertex.getGroupMember(0).getEnvironment().getInvokable();
    if (!(invokable instanceof AbstractInputTask)) {
      LOG.error(groupVertex.getName() + ""String_Node_Str"" + inputSplits.length+ ""String_Node_Str"");
      continue;
    }
    @SuppressWarnings(""String_Node_Str"") final AbstractInputTask<? extends InputSplit> inputTask=(AbstractInputTask<? extends InputSplit>)invokable;
    final Class<? extends InputSplit> splitType=inputTask.getInputSplitType();
    final InputSplitAssigner assigner=getAssignerByType(splitType,true,executionGraph.getJobID());
    this.assignerCache.put(groupVertex,assigner);
    assigner.registerGroupVertex(groupVertex);
  }
}",0.9897151898734176
55709,"/** 
 * Attempts to find the responsible type of   {@link InputSplitAssigner} for the given type of input split from theconfiguration and instantiate an object for it.
 * @param inputSplitType the type of input split to load the  {@link InputSplitAssigner} for
 * @return the newly loaded {@link InputSplitAssigner} object or <code>null</code> if no such object could belocated or loaded
 */
private InputSplitAssigner loadInputSplitAssigner(final Class<? extends InputSplit> inputSplitType){
  final String typeClassName=inputSplitType.getSimpleName();
  final String assignerKey=INPUT_SPLIT_CONFIG_KEY_PREFIX + typeClassName;
  LOG.info(""String_Node_Str"" + typeClassName);
  String assignerClassName=GlobalConfiguration.getString(assignerKey,null);
  if (assignerClassName == null) {
    if (FileInputSplit.class.getSimpleName().equals(typeClassName)) {
      assignerClassName=FileInputSplitAssigner.class.getName();
    }
 else {
      return null;
    }
  }
  try {
    @SuppressWarnings(""String_Node_Str"") final Class<? extends InputSplitAssigner> assignerClass=(Class<? extends InputSplitAssigner>)Class.forName(assignerClassName);
    return assignerClass.newInstance();
  }
 catch (  Exception e) {
    LOG.error(StringUtils.stringifyException(e));
  }
  return null;
}","/** 
 * Attempts to find the responsible type of   {@link InputSplitAssigner} for the given type of input split from theconfiguration and instantiate an object for it.
 * @param inputSplitType the type of input split to load the  {@link InputSplitAssigner} for
 * @return the newly loaded {@link InputSplitAssigner} object or <code>null</code> if no such object could belocated or loaded
 */
@SuppressWarnings(""String_Node_Str"") private InputSplitAssigner loadInputSplitAssigner(final Class<? extends InputSplit> inputSplitType,JobID jid){
  final String typeClassName=inputSplitType.getSimpleName();
  final String assignerKey=INPUT_SPLIT_CONFIG_KEY_PREFIX + typeClassName;
  LOG.info(""String_Node_Str"" + typeClassName);
  String assignerClassName=GlobalConfiguration.getString(assignerKey,null);
  if (assignerClassName == null) {
    if (FileInputSplit.class.getSimpleName().equals(typeClassName)) {
      assignerClassName=FileInputSplitAssigner.class.getName();
    }
 else {
      return null;
    }
  }
  try {
    Class<? extends InputSplitAssigner> assignerClass;
    boolean useUserJar=GlobalConfiguration.getBoolean(INPUT_SPLIT_CONFIG_KEY_PREFIX + ""String_Node_Str"",false);
    if (useUserJar) {
      final ClassLoader cl=LibraryCacheManager.getClassLoader(jid);
      assignerClass=(Class<? extends InputSplitAssigner>)Class.forName(assignerClassName,true,cl);
    }
 else {
      assignerClass=(Class<? extends InputSplitAssigner>)Class.forName(assignerClassName);
    }
    return assignerClass.newInstance();
  }
 catch (  Exception e) {
    LOG.error(StringUtils.stringifyException(e));
  }
  return null;
}",0.8511371467953136
55710,"/** 
 * Returns the   {@link InputSplitAssigner} which is defined for the given type of input split.
 * @param inputSplitType the type of input split to find the corresponding  {@link InputSplitAssigner} for
 * @param allowLoading <code>true</code> to indicate that the input split assigner is allowed to load additional classes if necessary, <code>false</code> otherwise
 * @return the {@link InputSplitAssigner} responsible for the given type of input split
 */
private InputSplitAssigner getAssignerByType(final Class<? extends InputSplit> inputSplitType,final boolean allowLoading){
synchronized (this.loadedAssigners) {
    InputSplitAssigner assigner=this.loadedAssigners.get(inputSplitType);
    if (assigner == null && allowLoading) {
      assigner=loadInputSplitAssigner(inputSplitType);
      if (assigner != null) {
        this.loadedAssigners.put(inputSplitType,assigner);
      }
    }
    if (assigner != null) {
      return assigner;
    }
  }
  LOG.warn(""String_Node_Str"" + inputSplitType.getName() + ""String_Node_Str"");
  return this.defaultAssigner;
}","/** 
 * Returns the   {@link InputSplitAssigner} which is defined for the given type of input split.
 * @param inputSplitType the type of input split to find the corresponding  {@link InputSplitAssigner} for
 * @param allowLoading <code>true</code> to indicate that the input split assigner is allowed to load additional classes if necessary, <code>false</code> otherwise
 * @return the {@link InputSplitAssigner} responsible for the given type of input split
 */
private InputSplitAssigner getAssignerByType(final Class<? extends InputSplit> inputSplitType,final boolean allowLoading,JobID jid){
synchronized (this.loadedAssigners) {
    InputSplitAssigner assigner=this.loadedAssigners.get(inputSplitType);
    if (assigner == null && allowLoading) {
      assigner=loadInputSplitAssigner(inputSplitType,jid);
      if (assigner != null) {
        this.loadedAssigners.put(inputSplitType,assigner);
      }
    }
    if (assigner != null) {
      return assigner;
    }
  }
  LOG.warn(""String_Node_Str"" + inputSplitType.getName() + ""String_Node_Str"");
  return this.defaultAssigner;
}",0.9935125115848008
55711,"/** 
 * {@inheritDoc}
 */
@Override public void accept(Visitor<Contract> visitor){
  boolean descend=visitor.preVisit(this);
  if (descend) {
    if (visitor.preVisit(this)) {
      for (      Contract c : this.input1) {
        c.accept(visitor);
      }
      for (      Contract c : this.input2) {
        c.accept(visitor);
      }
    }
    visitor.postVisit(this);
  }
}","/** 
 * {@inheritDoc}
 */
@Override public void accept(Visitor<Contract> visitor){
  boolean descend=visitor.preVisit(this);
  if (descend) {
    for (    Contract c : this.input1) {
      c.accept(visitor);
    }
    for (    Contract c : this.input2) {
      c.accept(visitor);
    }
    visitor.postVisit(this);
  }
}",0.4655172413793103
55712,"/** 
 * Retrieves the index of the <tt>BlockLocation</tt> that contains the part of the file described by the given offset.
 * @param blocks The different blocks of the file. Must be ordered by their offset.
 * @param offset The offset of the position in the file.
 * @param startIndex The earliest index to look at.
 * @return The index of the block containing the given position.
 */
private final int getBlockIndexForPosition(BlockLocation[] blocks,long offset,long halfSplitSize,int startIndex){
  for (int i=startIndex; i < blocks.length; i++) {
    long blockStart=blocks[i].getOffset();
    long blockEnd=blockStart + blocks[i].getLength();
    if (offset >= blockStart && offset < blockEnd) {
      if (i < blocks.length - 1 && blockEnd - offset < halfSplitSize) {
        return i + 1;
      }
 else {
        return i;
      }
    }
  }
  throw new IllegalArgumentException(""String_Node_Str"");
}","/** 
 * Retrieves the index of the <tt>BlockLocation</tt> that contains the part of the file described by the given offset.
 * @param blocks The different blocks of the file. Must be ordered by their offset.
 * @param offset The offset of the position in the file.
 * @param startIndex The earliest index to look at.
 * @return The index of the block containing the given position.
 */
protected final int getBlockIndexForPosition(BlockLocation[] blocks,long offset,long halfSplitSize,int startIndex){
  for (int i=startIndex; i < blocks.length; i++) {
    long blockStart=blocks[i].getOffset();
    long blockEnd=blockStart + blocks[i].getLength();
    if (offset >= blockStart && offset < blockEnd) {
      if (i < blocks.length - 1 && blockEnd - offset < halfSplitSize) {
        return i + 1;
      }
 else {
        return i;
      }
    }
  }
  throw new IllegalArgumentException(""String_Node_Str"");
}",0.9933774834437086
55713,"/** 
 * Opens an input stream to the file defined in the input format. The stream is positioned at the beginning of the given split. <p> The stream is actually opened in an asynchronous thread to make sure any interruptions to the thread  working on the input format do not reach the file system.
 * @see eu.stratosphere.pact.common.io.InputFormat#open(eu.stratosphere.nephele.template.InputSplit)
 */
@Override public void open(FileInputSplit split) throws IOException {
  if (!(split instanceof FileInputSplit)) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  final FileInputSplit fileSplit=(FileInputSplit)split;
  this.start=fileSplit.getStart();
  this.length=fileSplit.getLength();
  if (LOG.isDebugEnabled())   LOG.debug(""String_Node_Str"" + fileSplit.getPath() + ""String_Node_Str""+ start+ ""String_Node_Str""+ length+ ""String_Node_Str"");
  final InputSplitOpenThread isot=new InputSplitOpenThread(fileSplit,OPEN_TIMEOUT_MILLIES);
  isot.start();
  try {
    isot.waitForCompletion();
  }
 catch (  Throwable t) {
    throw new IOException(""String_Node_Str"" + fileSplit.getPath() + ""String_Node_Str""+ start+ ""String_Node_Str""+ length+ ""String_Node_Str""+ t.getMessage(),t);
  }
  this.stream=isot.getFSDataInputStream();
  this.stream.seek(this.start);
}","/** 
 * Opens an input stream to the file defined in the input format. The stream is positioned at the beginning of the given split. <p> The stream is actually opened in an asynchronous thread to make sure any interruptions to the thread  working on the input format do not reach the file system.
 * @see eu.stratosphere.pact.common.io.InputFormat#open(eu.stratosphere.nephele.template.InputSplit)
 */
@Override public void open(FileInputSplit split) throws IOException {
  if (!(split instanceof FileInputSplit)) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  final FileInputSplit fileSplit=(FileInputSplit)split;
  fileNumber=Integer.parseInt(split.getPath().getName());
  this.start=fileSplit.getStart();
  this.length=fileSplit.getLength();
  if (LOG.isDebugEnabled())   LOG.debug(""String_Node_Str"" + fileSplit.getPath() + ""String_Node_Str""+ start+ ""String_Node_Str""+ length+ ""String_Node_Str"");
  final InputSplitOpenThread isot=new InputSplitOpenThread(fileSplit,OPEN_TIMEOUT_MILLIES);
  isot.start();
  try {
    isot.waitForCompletion();
  }
 catch (  Throwable t) {
    throw new IOException(""String_Node_Str"" + fileSplit.getPath() + ""String_Node_Str""+ start+ ""String_Node_Str""+ length+ ""String_Node_Str""+ t.getMessage(),t);
  }
  this.stream=isot.getFSDataInputStream();
  this.stream.seek(this.start);
}",0.9777777777777776
55714,"/** 
 * {@inheritDoc}
 */
@Override public T readRecord(final T target) throws IOException, InterruptedException {
  T record=null;
  if (this.executingThread == null) {
    this.executingThread=Thread.currentThread();
  }
  if (this.executingThread.isInterrupted()) {
    throw new InterruptedException();
  }
  while (true) {
    if (this.channelToReadFrom == -1) {
      this.availableChannelRetVal=waitForAnyChannelToBecomeAvailable();
      this.channelToReadFrom=this.availableChannelRetVal;
    }
    try {
      record=this.getInputChannel(this.channelToReadFrom).readRecord(target);
    }
 catch (    EOFException e) {
      if (this.isClosed()) {
        return null;
      }
    }
    if (++this.channelToReadFrom == getNumberOfInputChannels()) {
      this.channelToReadFrom=0;
    }
    if (record != null) {
      break;
    }
 else {
      if (this.channelToReadFrom == this.availableChannelRetVal) {
        this.channelToReadFrom=-1;
      }
    }
  }
  this.streamListener.recordReceived(record);
  return record;
}","/** 
 * {@inheritDoc}
 */
@Override public T readRecord(final T target) throws IOException, InterruptedException {
  T record=null;
  if (this.executingThread == null) {
    this.executingThread=Thread.currentThread();
  }
  if (this.executingThread.isInterrupted()) {
    throw new InterruptedException();
  }
  final int numberOfInputChannels=getNumberOfInputChannels();
  while (true) {
    if (this.channelToReadFrom == -1) {
      this.availableChannelRetVal=waitForAnyChannelToBecomeAvailable();
      this.channelToReadFrom=this.availableChannelRetVal;
    }
    try {
      record=this.getInputChannel(this.channelToReadFrom).readRecord(target);
    }
 catch (    EOFException e) {
      if (this.isClosed()) {
        return null;
      }
    }
    if (record == null && this.channelToReadFrom == this.availableChannelRetVal) {
      this.channelToReadFrom=-1;
      continue;
    }
    if (++this.channelToReadFrom == numberOfInputChannels) {
      this.channelToReadFrom=0;
    }
    if (record != null) {
      break;
    }
  }
  this.streamListener.recordReceived(record);
  return record;
}",0.8451099672437997
55715,"private void initBufferSizes(){
  int bufferSize=GlobalConfiguration.getInteger(""String_Node_Str"",GlobalBufferPool.DEFAULT_BUFFER_SIZE_IN_BYTES);
  long now=System.currentTimeMillis();
  for (  ProfilingPath path : profilingModel.getProfilingSubgraph().getProfilingPaths()) {
    for (    ManagementAttachment pathElement : path.getPathElements()) {
      if (pathElement instanceof ManagementEdge) {
        ManagementEdge edge=(ManagementEdge)pathElement;
        BufferSizeHistory bufferSizeHistory=new BufferSizeHistory(edge,2);
        bufferSizeHistory.addToHistory(now,bufferSize);
        bufferSizes.put(edge,bufferSizeHistory);
      }
    }
  }
}","private void initBufferSizes(){
  int bufferSize=GlobalConfiguration.getInteger(""String_Node_Str"",GlobalBufferPool.DEFAULT_BUFFER_SIZE_IN_BYTES);
  this.maximumBufferSize=bufferSize;
  long now=System.currentTimeMillis();
  for (  ProfilingPath path : profilingModel.getProfilingSubgraph().getProfilingPaths()) {
    for (    ManagementAttachment pathElement : path.getPathElements()) {
      if (pathElement instanceof ManagementEdge) {
        ManagementEdge edge=(ManagementEdge)pathElement;
        BufferSizeHistory bufferSizeHistory=new BufferSizeHistory(edge,2);
        bufferSizeHistory.addToHistory(now,bufferSize);
        bufferSizes.put(edge,bufferSizeHistory);
      }
    }
  }
}",0.9726128793486306
55716,"private void increaseBufferSize(ManagementEdge edge,HashMap<ManagementEdge,Integer> edgesToAdjust){
  int oldBufferSize=bufferSizes.get(edge).getLastEntry().getBufferSize();
  int newBufferSize=proposedIncreasedBufferSize(oldBufferSize);
  edgesToAdjust.put(edge,newBufferSize);
}","private void increaseBufferSize(ManagementEdge edge,HashMap<ManagementEdge,Integer> edgesToAdjust){
  int oldBufferSize=bufferSizes.get(edge).getLastEntry().getBufferSize();
  int newBufferSize=Math.min(proposedIncreasedBufferSize(oldBufferSize),this.maximumBufferSize);
  if (isRelevantIncrease(oldBufferSize,newBufferSize)) {
    edgesToAdjust.put(edge,newBufferSize);
  }
}",0.8536585365853658
55717,"public void refreshEdgeLatency(long timestamp,ChannelLatency channelLatency){
  ManagementEdgeID sourceEdgeID=profilingSubgraph.getEdgeByReceiverVertexID(channelLatency.getSinkVertexID().toManagementVertexID());
  EdgeCharacteristics edgeCharacteristics=profilingSubgraph.getEdgeCharacteristicsBySourceEdgeID(sourceEdgeID);
  edgeCharacteristics.addLatencyMeasurement(timestamp,channelLatency.getChannelLatency());
}","public void refreshEdgeLatency(long timestamp,ChannelLatency channelLatency){
  if (Double.isInfinite(channelLatency.getChannelLatency()) || Double.isNaN(channelLatency.getChannelLatency())) {
    return;
  }
  if (!channelLatency.getSourceVertexID().equals(channelLatency.getSinkVertexID())) {
    XoredVertexID xored=new XoredVertexID(channelLatency.getSourceVertexID().toManagementVertexID(),channelLatency.getSinkVertexID().toManagementVertexID());
    ManagementEdgeID sourceEdgeID=profilingSubgraph.getSourceEdgeIDByXoredVertexID(xored);
    if (sourceEdgeID == null) {
      ExecutionVertex source=executionGraph.getVertexByID(channelLatency.getSourceVertexID());
      ExecutionVertex sink=executionGraph.getVertexByID(channelLatency.getSinkVertexID());
      throw new RuntimeException(""String_Node_Str"" + getName(source) + ""String_Node_Str""+ getName(sink)+ ""String_Node_Str""+ xored.toString());
    }
    EdgeCharacteristics edgeCharacteristics=profilingSubgraph.getEdgeCharacteristicsBySourceEdgeID(sourceEdgeID);
    edgeCharacteristics.addLatencyMeasurement(timestamp,channelLatency.getChannelLatency());
  }
}",0.4548408057179987
55718,"public void refreshChannelThroughput(long timestamp,ChannelThroughput channelThroughput){
  ManagementEdgeID edgeID=new ManagementEdgeID(channelThroughput.getSourceChannelID());
  EdgeCharacteristics edgeCharaceristics=profilingSubgraph.getEdgeCharacteristicsBySourceEdgeID(edgeID);
  edgeCharaceristics.addThroughputMeasurement(timestamp,channelThroughput.getThroughput());
}","public void refreshChannelThroughput(long timestamp,ChannelThroughput channelThroughput){
  if (Double.isInfinite(channelThroughput.getThroughput()) || Double.isNaN(channelThroughput.getThroughput())) {
    return;
  }
  ManagementEdgeID edgeID=new ManagementEdgeID(channelThroughput.getSourceChannelID());
  EdgeCharacteristics edgeCharaceristics=profilingSubgraph.getEdgeCharacteristicsBySourceEdgeID(edgeID);
  edgeCharaceristics.addThroughputMeasurement(timestamp,channelThroughput.getThroughput());
}",0.8535754824063564
55719,"public void refreshTaskLatency(long timestamp,TaskLatency taskLatency){
  VertexLatency vertexLatency=profilingSubgraph.getVertexLatency(taskLatency.getVertexID().toManagementVertexID());
  vertexLatency.addLatencyMeasurement(timestamp,taskLatency.getTaskLatency());
}","public void refreshTaskLatency(long timestamp,TaskLatency taskLatency){
  if (Double.isInfinite(taskLatency.getTaskLatency()) || Double.isNaN(taskLatency.getTaskLatency())) {
    return;
  }
  VertexLatency vertexLatency=profilingSubgraph.getVertexLatency(taskLatency.getVertexID().toManagementVertexID());
  vertexLatency.addLatencyMeasurement(timestamp,taskLatency.getTaskLatency());
}",0.8183206106870229
55720,"private void initReceiverVertexToSourceEdgeIDMap(final ManagementGraph managementGraph){
  final Iterator<ManagementVertex> it=new ManagementGraphIterator(managementGraph,true);
  while (it.hasNext()) {
    final ManagementVertex source=it.next();
    final int numberOfOutputGates=source.getNumberOfOutputGates();
    for (int i=0; i < numberOfOutputGates; ++i) {
      final ManagementGate outputGate=source.getOutputGate(i);
      final int numberOfOutgoingEdges=outputGate.getNumberOfForwardEdges();
      for (int j=0; j < numberOfOutgoingEdges; ++j) {
        final ManagementEdge edge=outputGate.getForwardEdge(j);
        final ManagementVertex receiver=edge.getTarget().getVertex();
        this.receiverVertexToSourceEdgeIDMap.put(receiver.getID(),edge.getSourceEdgeID());
      }
    }
  }
}","private void initReceiverVertexToSourceEdgeIDMap(final ManagementGraph managementGraph){
  final Iterator<ManagementVertex> it=new ManagementGraphIterator(managementGraph,true);
  while (it.hasNext()) {
    final ManagementVertex source=it.next();
    final int numberOfOutputGates=source.getNumberOfOutputGates();
    for (int i=0; i < numberOfOutputGates; ++i) {
      final ManagementGate outputGate=source.getOutputGate(i);
      final int numberOfOutgoingEdges=outputGate.getNumberOfForwardEdges();
      for (int j=0; j < numberOfOutgoingEdges; ++j) {
        final ManagementEdge edge=outputGate.getForwardEdge(j);
        final ManagementVertex receiver=edge.getTarget().getVertex();
        XoredVertexID xored=new XoredVertexID(source.getID(),receiver.getID());
        System.out.println(""String_Node_Str"" + getName(source) + ""String_Node_Str""+ getName(receiver)+ ""String_Node_Str""+ xored.toString());
        this.xoredVertexToSourceEdgeIDMap.put(xored,edge.getSourceEdgeID());
      }
    }
  }
}",0.8382109331860851
55721,"@Override public StringBuilder toString(StringBuilder sb){
  for (  final JsonNode row : this.getRows())   sb.append(""String_Node_Str"").append(row).append(""String_Node_Str"").append(this.get(row)).append(""String_Node_Str"");
  return sb.append(""String_Node_Str"");
}","@Override public StringBuilder toString(StringBuilder sb){
  for (  final JsonNode row : this.getRows())   sb.append(""String_Node_Str"").append(row).append(""String_Node_Str"").append(this.get(row)).append(""String_Node_Str"");
  return sb;
}",0.948
55722,"@Override public SopremoModule asElementaryOperators(){
  final SopremoModule sopremoModule=new SopremoModule(this.getName(),2,1);
  JsonStream phase1=sopremoModule.getInput(0);
  JsonStream matrix=sopremoModule.getInput(1);
  final TransformDiagonal transDia=new TransformDiagonal().withInputs(phase1);
  final GenerateRows rows=new GenerateRows().withInputs(matrix);
  final ComputeBlockTuples computeRows=new ComputeBlockTuples().withInputs(transDia,rows);
  sopremoModule.getOutput(0).setInput(0,computeRows);
  return sopremoModule;
}","@Override public SopremoModule asElementaryOperators(){
  final SopremoModule sopremoModule=new SopremoModule(this.getName(),2,1);
  JsonStream phase1=sopremoModule.getInput(0);
  JsonStream matrix=sopremoModule.getInput(1);
  final TransformDiagonal transDia=new TransformDiagonal().withInputs(phase1);
  final GenerateRows rows=new GenerateRows().withInputs(matrix);
  final ComputeBlockTuples computeRows=new ComputeBlockTuples().withInputs(transDia,rows);
  final ExtractMirroredMatrix mirroredMatrix=new ExtractMirroredMatrix().withInputs(computeRows);
  final FillMatrix fillMatrix=new FillMatrix().withInputs(computeRows,mirroredMatrix);
  sopremoModule.getOutput(0).setInput(0,fillMatrix);
  return sopremoModule;
}",0.8367670364500792
55723,"@Override protected void map(JsonNode key,JsonNode value,JsonCollector out){
  ArrayNode castedKey=(ArrayNode)key;
  if (!castedKey.get(0).equals(castedKey.get(1))) {
    out.collect(castedKey.get(1),new ArrayNode(key,value));
  }
}","@Override protected void map(JsonNode key,JsonNode value,JsonCollector out){
  if (((ArrayNode)key).get(0).compareTo(((ArrayNode)key).get(1)) > 0) {
    out.collect(new ArrayNode(((ArrayNode)key).get(1),((ArrayNode)key).get(0)),value);
  }
}",0.5708245243128964
55724,"@Override protected void coGroup(JsonNode key,ArrayNode values1,ArrayNode values2,JsonCollector out){
  if (!key.isArray()) {
    for (    JsonNode array : values2) {
      out.collect(((ArrayNode)array).get(0),((ArrayNode)array).get(1));
    }
  }
 else {
    for (    JsonNode value2 : values2) {
      BinarySparseMatrix matrixB=(BinarySparseMatrix)((ArrayNode)(((ArrayNode)value2).get(0))).get(1);
      BinarySparseMatrix matrixX=(BinarySparseMatrix)((ArrayNode)(((ArrayNode)value2).get(1))).get(1);
      JsonNode oldKeyX=((ArrayNode)(((ArrayNode)value2).get(1))).get(0);
      if (!values1.isEmpty()) {
      }
 else {
        JsonNode oldKeyB=((ArrayNode)(((ArrayNode)value2).get(0))).get(0);
        out.collect(oldKeyB,matrixB);
      }
      out.collect(oldKeyX,matrixX);
    }
  }
}","@Override protected void coGroup(JsonNode key,ArrayNode values1,ArrayNode values2,JsonCollector out){
  if (!key.isArray()) {
    for (    JsonNode array : values2) {
      out.collect(((ArrayNode)array).get(0),((ArrayNode)array).get(1));
    }
  }
 else {
    if (values2.isEmpty()) {
      out.collect(key,values1.get(0));
    }
 else {
      for (      JsonNode value2 : values2) {
        BinarySparseMatrix matrixB=(BinarySparseMatrix)((ArrayNode)(((ArrayNode)value2).get(0))).get(1);
        BinarySparseMatrix matrixX=(BinarySparseMatrix)((ArrayNode)(((ArrayNode)value2).get(1))).get(1);
        JsonNode oldKeyX=((ArrayNode)(((ArrayNode)value2).get(1))).get(0);
        if (!values1.isEmpty()) {
        }
        out.collect(oldKeyX,matrixX);
      }
    }
  }
}",0.8460063897763578
55725,"@Override public SopremoModule asElementaryOperators(){
  final SopremoModule sopremoModule=new SopremoModule(this.getName(),1,1);
  JsonStream input=sopremoModule.getInput(0);
  int itCount=2;
  TransformAKey[] a=new TransformAKey[itCount];
  TransformBKey[] b=new TransformBKey[itCount];
  TransformXKey[] x=new TransformXKey[itCount];
  BAndXCoGroup[] xb=new BAndXCoGroup[itCount];
  ACoGroup axb[]=new ACoGroup[itCount];
  for (int i=0; i < itCount; i++) {
    a[i]=new TransformAKey().withInputs(i == 0 ? input : axb[i - 1]);
    a[i].setIterationStep(i + 1);
    b[i]=new TransformBKey().withInputs(i == 0 ? input : axb[i - 1]);
    b[i].setIterationStep(i + 1);
    x[i]=new TransformXKey().withInputs(i == 0 ? input : axb[i - 1]);
    xb[i]=new BAndXCoGroup().withInputs(b[i],x[i]);
    axb[i]=new ACoGroup().withInputs(a[i],xb[i]);
  }
  sopremoModule.getOutput(0).setInput(0,axb[itCount - 1]);
  return sopremoModule;
}","@Override public SopremoModule asElementaryOperators(){
  final SopremoModule sopremoModule=new SopremoModule(this.getName(),1,1);
  JsonStream input=sopremoModule.getInput(0);
  int itCount=3;
  TransformAKey[] a=new TransformAKey[itCount];
  TransformBKey[] b=new TransformBKey[itCount];
  TransformXKey[] x=new TransformXKey[itCount];
  BAndXCoGroup[] xb=new BAndXCoGroup[itCount];
  ACoGroup axb[]=new ACoGroup[itCount];
  for (int i=0; i < itCount; i++) {
    a[i]=new TransformAKey().withInputs(i == 0 ? input : axb[i - 1]);
    a[i].setIterationStep(i + 1);
    b[i]=new TransformBKey().withInputs(i == 0 ? input : axb[i - 1]);
    b[i].setIterationStep(i + 1);
    x[i]=new TransformXKey().withInputs(i == 0 ? input : axb[i - 1]);
    xb[i]=new BAndXCoGroup().withInputs(b[i],x[i]);
    axb[i]=new ACoGroup().withInputs(a[i],xb[i]);
  }
  sopremoModule.getOutput(0).setInput(0,axb[itCount - 1]);
  return sopremoModule;
}",0.9989235737351992
55726,"/** 
 * {@inheritDoc}
 */
@Override public void read(final DataInput in) throws IOException {
  this.sourceChannelID.read(in);
  this.bufferSize=in.readInt();
}","/** 
 * {@inheritDoc}
 */
@Override public void read(final DataInput in) throws IOException {
  super.read(in);
  this.sourceChannelID.read(in);
  this.bufferSize=in.readInt();
}",0.9467455621301776
55727,"/** 
 * {@inheritDoc}
 */
@Override public void write(final DataOutput out) throws IOException {
  this.sourceChannelID.write(out);
  out.writeInt(this.bufferSize);
}","/** 
 * {@inheritDoc}
 */
@Override public void write(final DataOutput out) throws IOException {
  super.write(out);
  this.sourceChannelID.write(out);
  out.writeInt(this.bufferSize);
}",0.9431818181818182
55728,"@Override public void close(){
  this.running=false;
  if (this.currentBuffer.isEmpty()) {
    this.queues.empty.add(this.currentElement);
  }
 else {
    this.queues.sort.add(this.currentElement);
    if (LOG.isDebugEnabled()) {
      LOG.debug(""String_Node_Str"" + this.currentElement.id + ""String_Node_Str"");
    }
  }
  this.currentBuffer=null;
  this.currentElement=null;
  this.queues.sort.add(SENTINEL);
  if (LOG.isDebugEnabled())   LOG.debug(""String_Node_Str"");
}","@Override public void close(){
  if (this.running) {
    this.running=false;
    if (this.currentBuffer != null && this.currentElement != null) {
      if (this.currentBuffer.isEmpty()) {
        this.queues.empty.add(this.currentElement);
      }
 else {
        this.queues.sort.add(this.currentElement);
        if (LOG.isDebugEnabled()) {
          LOG.debug(""String_Node_Str"" + this.currentElement.id + ""String_Node_Str"");
        }
      }
    }
    this.currentBuffer=null;
    this.currentElement=null;
    this.queues.sort.add(SENTINEL);
  }
}",0.8074291300097751
55729,"public static PluginID fromByteArray(final byte[] byteArray){
  if (byteArray == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (byteArray.length != SIZE) {
    throw new IllegalArgumentException(""String_Node_Str"" + SIZE);
  }
  return new PluginID(byteArray);
}","/** 
 * Constructs a new plugin ID from the given byte array.
 * @param byteArray the byte array to construct the plugin ID from
 */
public static PluginID fromByteArray(final byte[] byteArray){
  if (byteArray == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (byteArray.length != SIZE) {
    throw new IllegalArgumentException(""String_Node_Str"" + SIZE);
  }
  return new PluginID(byteArray);
}",0.813986013986014
55730,"private PluginID(final byte[] byteArray){
  super(byteArray);
}","/** 
 * Default constructor required for the deserialization.
 */
public PluginID(){
  super();
}",0.3625
55731,"public ProfilingValue(double value,long timestamp){
  this.value=value;
  this.timestamp=timestamp;
}","public ProfilingValue(double value,long timestamp){
  this.value=value;
  this.timestamp=timestamp;
  this.id=nextFreeId++;
}",0.8938053097345132
55732,"/** 
 * Sorts first by value and then by timestamp.
 */
@Override public int compareTo(ProfilingValue other){
  if (this.value > other.value) {
    return 1;
  }
 else   if (this.value < other.value) {
    return -1;
  }
 else {
    if (this.timestamp > other.timestamp) {
      return 1;
    }
 else     if (this.timestamp < other.timestamp) {
      return -1;
    }
 else {
      return 0;
    }
  }
}","/** 
 * Sorts first by value and then by id.
 */
@Override public int compareTo(ProfilingValue other){
  if (this.value > other.value) {
    return 1;
  }
 else   if (this.value < other.value) {
    return -1;
  }
 else {
    if (this.id > other.id) {
      return 1;
    }
 else     if (this.id < other.id) {
      return -1;
    }
 else {
      return 0;
    }
  }
}",0.8534370946822308
55733,"public ProfilingValueStatistic(int valueSetSize){
  this.sortedByTimestamp=new LinkedList<ProfilingValue>();
  this.sortedByValue=new ArrayList<ProfilingValue>();
  this.valueArraySize=valueSetSize;
  this.noOfStoredValues=0;
  this.sumOfValues=0;
}","public ProfilingValueStatistic(int statisticWindowSize){
  this.sortedById=new LinkedList<ProfilingValue>();
  this.sortedByValue=new ArrayList<ProfilingValue>();
  this.statisticWindowSize=statisticWindowSize;
  this.noOfStoredValues=0;
  this.sumOfValues=0;
}",0.8392156862745098
55734,"private ProfilingValue insertIntoSortedByTimestamp(ProfilingValue value){
  if (!sortedByTimestamp.isEmpty() && sortedByTimestamp.getLast().getTimestamp() > value.getTimestamp()) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  sortedByTimestamp.add(value);
  if (noOfStoredValues >= valueArraySize) {
    return sortedByTimestamp.removeFirst();
  }
 else {
    return null;
  }
}","private ProfilingValue insertIntoSortedByTimestamp(ProfilingValue value){
  if (!sortedById.isEmpty() && sortedById.getLast().getId() >= value.getId()) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  sortedById.add(value);
  if (noOfStoredValues >= statisticWindowSize) {
    return sortedById.removeFirst();
  }
 else {
    return null;
  }
}",0.8526315789473684
55735,"public void refreshEdgeLatency(PathLatency pathLatency){
}","public void refreshEdgeLatency(PathLatency pathLatency){
  LOG.info(""String_Node_Str"" + pathLatency);
}",0.7204968944099379
55736,"public LatencyOptimizerThread(ExecutionGraph executionGraph){
  this.latencyModel=new LatencyModel(executionGraph);
  this.streamingDataQueue=new LinkedBlockingQueue<AbstractStreamingData>();
}","public LatencyOptimizerThread(ExecutionGraph executionGraph){
  this.executionGraph=executionGraph;
  this.latencyModel=new LatencyModel(executionGraph);
  this.streamingDataQueue=new LinkedBlockingQueue<AbstractStreamingData>();
}",0.910377358490566
55737,"public void run(){
  try {
    while (!interrupted()) {
      AbstractStreamingData streamingData=streamingDataQueue.take();
      if (streamingData instanceof PathLatency) {
        latencyModel.refreshEdgeLatency((PathLatency)streamingData);
      }
    }
  }
 catch (  InterruptedException e) {
  }
}","public void run(){
  LOG.info(""String_Node_Str"" + executionGraph.getJobName());
  try {
    while (!interrupted()) {
      AbstractStreamingData streamingData=streamingDataQueue.take();
      if (streamingData instanceof PathLatency) {
        latencyModel.refreshEdgeLatency((PathLatency)streamingData);
      }
    }
  }
 catch (  InterruptedException e) {
  }
  LOG.info(""String_Node_Str"" + executionGraph.getJobName());
}",0.8324175824175825
55738,"public ManagementVertex getEnd(){
  return pathVertices.getFirst();
}","public ManagementVertex getEnd(){
  return pathVertices.getLast();
}",0.9635036496350364
55739,"/** 
 * Creates a new file input channel and assigns it to the input gate.
 * @param channelID the channel ID to assign to the new channel, <code>null</code> to generate a new ID
 * @param compressionLevel the level of compression to be used for this channel
 * @return the new file input channel
 */
FileInputChannel<T> createFileInputChannel(ChannelID channelID,CompressionLevel compressionLevel);","/** 
 * Creates a new file input channel and assigns it to the given input gate.
 * @param inputGate the input gate the channel shall be assigned to
 * @param channelID the channel ID to assign to the new channel, <code>null</code> to generate a new ID
 * @param compressionLevel the level of compression to be used for this channel
 * @return the new file input channel
 */
FileInputChannel<T> createFileInputChannel(InputGate<T> inputGate,ChannelID channelID,CompressionLevel compressionLevel);",0.8916201117318435
55740,"/** 
 * Creates a new in-memory input channel and assigns it to the input gate.
 * @param channelID the channel ID to assign to the new channel, <code>null</code> to generate a new ID
 * @param compressionLevel the level of compression to be used for this channel
 * @return the new in-memory input channel
 */
InMemoryInputChannel<T> createInMemoryInputChannel(ChannelID channelID,CompressionLevel compressionLevel);","/** 
 * Creates a new in-memory input channel and assigns it to the given input gate.
 * @param inputGate the input gate the channel shall be assigned to
 * @param channelID the channel ID to assign to the new channel, <code>null</code> to generate a new ID
 * @param compressionLevel the level of compression to be used for this channel
 * @return the new in-memory input channel
 */
InMemoryInputChannel<T> createInMemoryInputChannel(InputGate<T> inputGate,ChannelID channelID,CompressionLevel compressionLevel);",0.8958109559613319
55741,"/** 
 * Creates a new network input channel and assigns it to the input gate.
 * @param channelID the channel ID to assign to the new channel, <code>null</code> to generate a new ID
 * @param compressionLevel the level of compression to be used for this channel
 * @return the new network input channel
 */
NetworkInputChannel<T> createNetworkInputChannel(ChannelID channelID,CompressionLevel compressionLevel);","/** 
 * Creates a new network input channel and assigns it to the given input gate.
 * @param inputGate the input gate the channel shall be assigned to
 * @param channelID the channel ID to assign to the new channel, <code>null</code> to generate a new ID
 * @param compressionLevel the level of compression to be used for this channel
 * @return the new network input channel
 */
NetworkInputChannel<T> createNetworkInputChannel(InputGate<T> inputGate,ChannelID channelID,CompressionLevel compressionLevel);",0.8944504896626768
55742,"/** 
 * Creates a new in-memory output channel and assigns it to the output gate.
 * @param channelID the channel ID to assign to the new channel, <code>null</code> to generate a new ID
 * @param compressionLevel the level of compression to be used for this channel
 * @return the new in-memory output channel
 */
InMemoryOutputChannel<T> createInMemoryOutputChannel(ChannelID channelID,CompressionLevel compressionLevel);","/** 
 * Creates a new in-memory output channel and assigns it to the given output gate.
 * @param outputGate the output gate the channel shall be assigned to
 * @param channelID the channel ID to assign to the new channel, <code>null</code> to generate a new ID
 * @param compressionLevel the level of compression to be used for this channel
 * @return the new in-memory output channel
 */
InMemoryOutputChannel<T> createInMemoryOutputChannel(OutputGate<T> outputGate,ChannelID channelID,CompressionLevel compressionLevel);",0.8931216931216931
55743,"/** 
 * Creates a new network output channel and assigns it to the output gate.
 * @param channelID the channel ID to assign to the new channel, <code>null</code> to generate a new ID
 * @param compressionLevel the level of compression to be used for this channel
 * @return the new network output channel
 */
NetworkOutputChannel<T> createNetworkOutputChannel(ChannelID channelID,CompressionLevel compressionLevel);","/** 
 * Creates a new network output channel and assigns it to the given output gate.
 * @param outputGate the output gate the channel shall be assigned to
 * @param channelID the channel ID to assign to the new channel, <code>null</code> to generate a new ID
 * @param compressionLevel the level of compression to be used for this channel
 * @return the new network output channel
 */
NetworkOutputChannel<T> createNetworkOutputChannel(OutputGate<T> outputGate,ChannelID channelID,CompressionLevel compressionLevel);",0.8917470525187567
55744,"/** 
 * Creates a new file output channel and assigns it to the output gate.
 * @param channelID the channel ID to assign to the new channel, <code>null</code> to generate a new ID
 * @param compressionLevel the level of compression to be used for this channel
 * @return the new file output channel
 */
FileOutputChannel<T> createFileOutputChannel(ChannelID channelID,CompressionLevel compressionLevel);","/** 
 * Creates a new file output channel and assigns it to the given output gate.
 * @param outputGate the output gate the channel shall be assigned to
 * @param channelID the channel ID to assign to the new channel, <code>null</code> to generate a new ID
 * @param compressionLevel the level of compression to be used for this channel
 * @return the new file output channel
 */
FileOutputChannel<T> createFileOutputChannel(OutputGate<T> outputGate,ChannelID channelID,CompressionLevel compressionLevel);",0.8888888888888888
55745,"/** 
 * {@inheritDoc}
 */
@SuppressWarnings(""String_Node_Str"") @Override public void read(final DataInput in) throws IOException {
  this.jobID=new JobID();
  this.jobID.read(in);
  this.taskName=StringRecord.readString(in);
  final String[] requiredJarFiles=new String[in.readInt()];
  for (int i=0; i < requiredJarFiles.length; i++) {
    requiredJarFiles[i]=StringRecord.readString(in);
  }
  LibraryCacheManager.register(this.jobID,requiredJarFiles);
  final ClassLoader cl=LibraryCacheManager.getClassLoader(this.jobID);
  final String invokableClassName=StringRecord.readString(in);
  if (invokableClassName == null) {
    throw new IOException(""String_Node_Str"");
  }
  try {
    this.invokableClass=(Class<? extends AbstractInvokable>)Class.forName(invokableClassName,true,cl);
  }
 catch (  ClassNotFoundException cnfe) {
    throw new IOException(""String_Node_Str"" + invokableClassName + ""String_Node_Str""+ StringUtils.stringifyException(cnfe));
  }
  final int numOuputGates=in.readInt();
  for (int i=0; i < numOuputGates; i++) {
    final GateID gateID=new GateID();
    gateID.read(in);
    this.unboundOutputGateIDs.add(gateID);
  }
  final int numInputGates=in.readInt();
  for (int i=0; i < numInputGates; i++) {
    final GateID gateID=new GateID();
    gateID.read(in);
    this.unboundInputGateIDs.add(gateID);
  }
  this.taskConfiguration=new Configuration();
  this.taskConfiguration.read(in);
  this.jobConfiguration=new Configuration();
  this.jobConfiguration.read(in);
  this.currentNumberOfSubtasks=in.readInt();
  this.indexInSubtaskGroup=in.readInt();
  try {
    instantiateInvokable();
  }
 catch (  Exception e) {
    throw new IOException(StringUtils.stringifyException(e));
  }
  for (int i=0; i < numOuputGates; ++i) {
    final OutputGate<? extends Record> outputGate=this.outputGates.get(i);
    final int numberOfOutputChannels=in.readInt();
    for (int j=0; j < numberOfOutputChannels; ++j) {
      final ChannelID channelID=new ChannelID();
      channelID.read(in);
      final ChannelID connectedChannelID=new ChannelID();
      connectedChannelID.read(in);
      final ChannelType channelType=EnumUtils.readEnum(in,ChannelType.class);
      final CompressionLevel compressionLevel=EnumUtils.readEnum(in,CompressionLevel.class);
      AbstractOutputChannel<? extends Record> outputChannel=null;
switch (channelType) {
case INMEMORY:
        outputChannel=outputGate.createInMemoryOutputChannel(channelID,compressionLevel);
      break;
case NETWORK:
    outputChannel=outputGate.createNetworkOutputChannel(channelID,compressionLevel);
  break;
case FILE:
outputChannel=outputGate.createFileOutputChannel(channelID,compressionLevel);
break;
}
if (outputChannel == null) {
throw new IOException(""String_Node_Str"" + channelID);
}
outputChannel.setConnectedChannelID(connectedChannelID);
}
}
for (int i=0; i < numInputGates; ++i) {
final InputGate<? extends Record> inputGate=this.inputGates.get(i);
final int numberOfInputChannels=in.readInt();
for (int j=0; j < numberOfInputChannels; ++j) {
final ChannelID channelID=new ChannelID();
channelID.read(in);
final ChannelID connectedChannelID=new ChannelID();
connectedChannelID.read(in);
final ChannelType channelType=EnumUtils.readEnum(in,ChannelType.class);
final CompressionLevel compressionLevel=EnumUtils.readEnum(in,CompressionLevel.class);
AbstractInputChannel<? extends Record> inputChannel=null;
switch (channelType) {
case INMEMORY:
inputChannel=inputGate.createInMemoryInputChannel(channelID,compressionLevel);
break;
case NETWORK:
inputChannel=inputGate.createNetworkInputChannel(channelID,compressionLevel);
break;
case FILE:
inputChannel=inputGate.createFileInputChannel(channelID,compressionLevel);
break;
}
if (inputChannel == null) {
throw new IOException(""String_Node_Str"" + channelID);
}
inputChannel.setConnectedChannelID(connectedChannelID);
}
}
}","/** 
 * {@inheritDoc}
 */
@SuppressWarnings({""String_Node_Str"",""String_Node_Str""}) @Override public void read(final DataInput in) throws IOException {
  this.jobID=new JobID();
  this.jobID.read(in);
  this.taskName=StringRecord.readString(in);
  final String[] requiredJarFiles=new String[in.readInt()];
  for (int i=0; i < requiredJarFiles.length; i++) {
    requiredJarFiles[i]=StringRecord.readString(in);
  }
  LibraryCacheManager.register(this.jobID,requiredJarFiles);
  final ClassLoader cl=LibraryCacheManager.getClassLoader(this.jobID);
  final String invokableClassName=StringRecord.readString(in);
  if (invokableClassName == null) {
    throw new IOException(""String_Node_Str"");
  }
  try {
    this.invokableClass=(Class<? extends AbstractInvokable>)Class.forName(invokableClassName,true,cl);
  }
 catch (  ClassNotFoundException cnfe) {
    throw new IOException(""String_Node_Str"" + invokableClassName + ""String_Node_Str""+ StringUtils.stringifyException(cnfe));
  }
  final int numOuputGates=in.readInt();
  for (int i=0; i < numOuputGates; i++) {
    final GateID gateID=new GateID();
    gateID.read(in);
    this.unboundOutputGateIDs.add(gateID);
  }
  final int numInputGates=in.readInt();
  for (int i=0; i < numInputGates; i++) {
    final GateID gateID=new GateID();
    gateID.read(in);
    this.unboundInputGateIDs.add(gateID);
  }
  this.taskConfiguration=new Configuration();
  this.taskConfiguration.read(in);
  this.jobConfiguration=new Configuration();
  this.jobConfiguration.read(in);
  this.currentNumberOfSubtasks=in.readInt();
  this.indexInSubtaskGroup=in.readInt();
  try {
    instantiateInvokable();
  }
 catch (  Exception e) {
    throw new IOException(StringUtils.stringifyException(e));
  }
  for (int i=0; i < numOuputGates; ++i) {
    final OutputGate<? extends Record> outputGate=this.outputGates.get(i);
    final int numberOfOutputChannels=in.readInt();
    for (int j=0; j < numberOfOutputChannels; ++j) {
      final ChannelID channelID=new ChannelID();
      channelID.read(in);
      final ChannelID connectedChannelID=new ChannelID();
      connectedChannelID.read(in);
      final ChannelType channelType=EnumUtils.readEnum(in,ChannelType.class);
      final CompressionLevel compressionLevel=EnumUtils.readEnum(in,CompressionLevel.class);
      AbstractOutputChannel<? extends Record> outputChannel=null;
switch (channelType) {
case INMEMORY:
        outputChannel=outputGate.createInMemoryOutputChannel((OutputGate)outputGate,channelID,compressionLevel);
      break;
case NETWORK:
    outputChannel=outputGate.createNetworkOutputChannel((OutputGate)outputGate,channelID,compressionLevel);
  break;
case FILE:
outputChannel=outputGate.createFileOutputChannel((OutputGate)outputGate,channelID,compressionLevel);
break;
}
if (outputChannel == null) {
throw new IOException(""String_Node_Str"" + channelID);
}
outputChannel.setConnectedChannelID(connectedChannelID);
}
}
for (int i=0; i < numInputGates; ++i) {
final InputGate<? extends Record> inputGate=this.inputGates.get(i);
final int numberOfInputChannels=in.readInt();
for (int j=0; j < numberOfInputChannels; ++j) {
final ChannelID channelID=new ChannelID();
channelID.read(in);
final ChannelID connectedChannelID=new ChannelID();
connectedChannelID.read(in);
final ChannelType channelType=EnumUtils.readEnum(in,ChannelType.class);
final CompressionLevel compressionLevel=EnumUtils.readEnum(in,CompressionLevel.class);
AbstractInputChannel<? extends Record> inputChannel=null;
switch (channelType) {
case INMEMORY:
inputChannel=inputGate.createInMemoryInputChannel((InputGate)inputGate,channelID,compressionLevel);
break;
case NETWORK:
inputChannel=inputGate.createNetworkInputChannel((InputGate)inputGate,channelID,compressionLevel);
break;
case FILE:
inputChannel=inputGate.createFileInputChannel((InputGate)inputGate,channelID,compressionLevel);
break;
}
if (inputChannel == null) {
throw new IOException(""String_Node_Str"" + channelID);
}
inputChannel.setConnectedChannelID(connectedChannelID);
}
}
}",0.9806763285024156
55746,"private void createChannel(final ExecutionVertex source,final OutputGate<? extends Record> outputGate,final ExecutionVertex target,final InputGate<? extends Record> inputGate,final ChannelType channelType,final CompressionLevel compressionLevel) throws GraphConversionException {
  AbstractOutputChannel<? extends Record> outputChannel;
  AbstractInputChannel<? extends Record> inputChannel;
switch (channelType) {
case NETWORK:
    outputChannel=outputGate.createNetworkOutputChannel(null,compressionLevel);
  inputChannel=inputGate.createNetworkInputChannel(null,compressionLevel);
break;
case INMEMORY:
outputChannel=outputGate.createInMemoryOutputChannel(null,compressionLevel);
inputChannel=inputGate.createInMemoryInputChannel(null,compressionLevel);
break;
case FILE:
outputChannel=outputGate.createFileOutputChannel(null,compressionLevel);
inputChannel=inputGate.createFileInputChannel(null,compressionLevel);
break;
default :
throw new GraphConversionException(""String_Node_Str"");
}
inputChannel.setConnectedChannelID(outputChannel.getID());
outputChannel.setConnectedChannelID(inputChannel.getID());
this.outputChannelMap.put(outputChannel.getID(),outputChannel);
this.inputChannelMap.put(inputChannel.getID(),inputChannel);
this.channelToVertexMap.put(outputChannel.getID(),source);
this.channelToVertexMap.put(inputChannel.getID(),target);
}","@SuppressWarnings({""String_Node_Str"",""String_Node_Str""}) private void createChannel(final ExecutionVertex source,final OutputGate<? extends Record> outputGate,final ExecutionVertex target,final InputGate<? extends Record> inputGate,final ChannelType channelType,final CompressionLevel compressionLevel) throws GraphConversionException {
  AbstractOutputChannel<? extends Record> outputChannel;
  AbstractInputChannel<? extends Record> inputChannel;
switch (channelType) {
case NETWORK:
    outputChannel=outputGate.createNetworkOutputChannel((OutputGate)outputGate,null,compressionLevel);
  inputChannel=inputGate.createNetworkInputChannel((InputGate)inputGate,null,compressionLevel);
break;
case INMEMORY:
outputChannel=outputGate.createInMemoryOutputChannel((OutputGate)outputGate,null,compressionLevel);
inputChannel=inputGate.createInMemoryInputChannel((InputGate)inputGate,null,compressionLevel);
break;
case FILE:
outputChannel=outputGate.createFileOutputChannel((OutputGate)outputGate,null,compressionLevel);
inputChannel=inputGate.createFileInputChannel((InputGate)inputGate,null,compressionLevel);
break;
default :
throw new GraphConversionException(""String_Node_Str"");
}
inputChannel.setConnectedChannelID(outputChannel.getID());
outputChannel.setConnectedChannelID(inputChannel.getID());
this.outputChannelMap.put(outputChannel.getID(),outputChannel);
this.inputChannelMap.put(inputChannel.getID(),inputChannel);
this.channelToVertexMap.put(outputChannel.getID(),source);
this.channelToVertexMap.put(inputChannel.getID(),target);
}",0.9347150259067356
55747,"private static void addExecutionVertices(Map<ExecutionGroupVertex,ManagementGroupVertex> groupMap,ExecutionGraph executionGraph){
  ExecutionGraphIterator iterator=new ExecutionGraphIterator(executionGraph,true);
  final Map<ExecutionVertex,ManagementVertex> vertexMap=new HashMap<ExecutionVertex,ManagementVertex>();
  final Map<Gate<? extends Record>,ManagementGate> gateMap=new HashMap<Gate<? extends Record>,ManagementGate>();
  while (iterator.hasNext()) {
    final ExecutionVertex ev=iterator.next();
    final ManagementGroupVertex parent=groupMap.get(ev.getGroupVertex());
    final ManagementVertex managementVertex=new ManagementVertex(parent,ev.getID().toManagementVertexID(),(ev.getAllocatedResource().getInstance().getInstanceConnectionInfo() != null) ? ev.getAllocatedResource().getInstance().getInstanceConnectionInfo().toString() : ev.getAllocatedResource().getInstance().toString(),ev.getAllocatedResource().getInstance().getType().toString(),ev.getCheckpointState().toString(),ev.getEnvironment().getIndexInSubtaskGroup());
    managementVertex.setExecutionState(ev.getExecutionState());
    vertexMap.put(ev,managementVertex);
    for (int i=0; i < ev.getEnvironment().getNumberOfOutputGates(); i++) {
      final OutputGate<? extends Record> outputGate=ev.getEnvironment().getOutputGate(i);
      final ManagementGate managementGate=new ManagementGate(managementVertex,new ManagementGateID(),i,false,outputGate.getType().toString());
      gateMap.put(outputGate,managementGate);
    }
    for (int i=0; i < ev.getEnvironment().getNumberOfInputGates(); i++) {
      final InputGate<? extends Record> inputGate=ev.getEnvironment().getInputGate(i);
      final ManagementGate managementGate=new ManagementGate(managementVertex,new ManagementGateID(),i,true,""String_Node_Str"");
      gateMap.put(inputGate,managementGate);
    }
  }
  iterator=new ExecutionGraphIterator(executionGraph,true);
  while (iterator.hasNext()) {
    final ExecutionVertex source=iterator.next();
    for (int i=0; i < source.getEnvironment().getNumberOfOutputGates(); i++) {
      final RuntimeOutputGate<? extends Record> outputGate=(RuntimeOutputGate<? extends Record>)source.getEnvironment().getOutputGate(i);
      final ManagementGate manangementOutputGate=gateMap.get(outputGate);
      for (int j=0; j < outputGate.getNumberOfOutputChannels(); j++) {
        final AbstractOutputChannel<? extends Record> outputChannel=outputGate.getOutputChannel(j);
        final ChannelID inputChannelID=outputChannel.getConnectedChannelID();
        final AbstractInputChannel<? extends Record> inputChannel=executionGraph.getInputChannelByID(inputChannelID);
        final ManagementGate managementInputGate=gateMap.get(inputChannel.getInputGate());
        final ManagementEdgeID managementEdgeID=new ManagementEdgeID(manangementOutputGate.getVertex().getID(),managementInputGate.getVertex().getID());
        new ManagementEdge(managementEdgeID,manangementOutputGate,j,managementInputGate,inputChannel.getChannelIndex(),inputChannel.getType(),inputChannel.getCompressionLevel());
      }
    }
  }
}","private static void addExecutionVertices(Map<ExecutionGroupVertex,ManagementGroupVertex> groupMap,ExecutionGraph executionGraph){
  ExecutionGraphIterator iterator=new ExecutionGraphIterator(executionGraph,true);
  final Map<ExecutionVertex,ManagementVertex> vertexMap=new HashMap<ExecutionVertex,ManagementVertex>();
  final Map<Gate<? extends Record>,ManagementGate> gateMap=new HashMap<Gate<? extends Record>,ManagementGate>();
  while (iterator.hasNext()) {
    final ExecutionVertex ev=iterator.next();
    final ManagementGroupVertex parent=groupMap.get(ev.getGroupVertex());
    final ManagementVertex managementVertex=new ManagementVertex(parent,ev.getID().toManagementVertexID(),(ev.getAllocatedResource().getInstance().getInstanceConnectionInfo() != null) ? ev.getAllocatedResource().getInstance().getInstanceConnectionInfo().toString() : ev.getAllocatedResource().getInstance().toString(),ev.getAllocatedResource().getInstance().getType().toString(),ev.getCheckpointState().toString(),ev.getEnvironment().getIndexInSubtaskGroup());
    managementVertex.setExecutionState(ev.getExecutionState());
    vertexMap.put(ev,managementVertex);
    for (int i=0; i < ev.getEnvironment().getNumberOfOutputGates(); i++) {
      final OutputGate<? extends Record> outputGate=ev.getEnvironment().getOutputGate(i);
      final ManagementGate managementGate=new ManagementGate(managementVertex,new ManagementGateID(),i,false,outputGate.getType().toString());
      gateMap.put(outputGate,managementGate);
    }
    for (int i=0; i < ev.getEnvironment().getNumberOfInputGates(); i++) {
      final InputGate<? extends Record> inputGate=ev.getEnvironment().getInputGate(i);
      final ManagementGate managementGate=new ManagementGate(managementVertex,new ManagementGateID(),i,true,""String_Node_Str"");
      gateMap.put(inputGate,managementGate);
    }
  }
  iterator=new ExecutionGraphIterator(executionGraph,true);
  while (iterator.hasNext()) {
    final ExecutionVertex source=iterator.next();
    for (int i=0; i < source.getEnvironment().getNumberOfOutputGates(); i++) {
      final OutputGate<? extends Record> outputGate=source.getEnvironment().getOutputGate(i);
      final ManagementGate manangementOutputGate=gateMap.get(outputGate);
      for (int j=0; j < outputGate.getNumberOfOutputChannels(); j++) {
        final AbstractOutputChannel<? extends Record> outputChannel=outputGate.getOutputChannel(j);
        final ChannelID inputChannelID=outputChannel.getConnectedChannelID();
        final AbstractInputChannel<? extends Record> inputChannel=executionGraph.getInputChannelByID(inputChannelID);
        final ManagementGate managementInputGate=gateMap.get(inputChannel.getInputGate());
        final ManagementEdgeID managementEdgeID=new ManagementEdgeID(manangementOutputGate.getVertex().getID(),managementInputGate.getVertex().getID());
        new ManagementEdge(managementEdgeID,manangementOutputGate,j,managementInputGate,inputChannel.getChannelIndex(),inputChannel.getType(),inputChannel.getCompressionLevel());
      }
    }
  }
}",0.9928338762214984
55748,"/** 
 * {@inheritDoc}
 */
@Override public InMemoryInputChannel<T> createInMemoryInputChannel(final ChannelID channelID,final CompressionLevel compressionLevel){
  final InMemoryInputChannel<T> eimic=new InMemoryInputChannel<T>(this,this.inputChannels.size(),deserializer,channelID,compressionLevel);
  addInputChannel(eimic);
  return eimic;
}","/** 
 * {@inheritDoc}
 */
@Override public InMemoryInputChannel<T> createInMemoryInputChannel(final InputGate<T> inputGate,final ChannelID channelID,final CompressionLevel compressionLevel){
  final InMemoryInputChannel<T> eimic=new InMemoryInputChannel<T>(inputGate,this.inputChannels.size(),this.deserializer,channelID,compressionLevel);
  addInputChannel(eimic);
  return eimic;
}",0.9353507565337
55749,"/** 
 * {@inheritDoc}
 */
@Override public FileInputChannel<T> createFileInputChannel(final ChannelID channelID,final CompressionLevel compressionLevel){
  final FileInputChannel<T> efic=new FileInputChannel<T>(this,this.inputChannels.size(),deserializer,channelID,compressionLevel);
  addInputChannel(efic);
  return efic;
}","/** 
 * {@inheritDoc}
 */
@Override public FileInputChannel<T> createFileInputChannel(final InputGate<T> inputGate,final ChannelID channelID,final CompressionLevel compressionLevel){
  final FileInputChannel<T> efic=new FileInputChannel<T>(inputGate,this.inputChannels.size(),this.deserializer,channelID,compressionLevel);
  addInputChannel(efic);
  return efic;
}",0.9317851959361392
55750,"/** 
 * {@inheritDoc}
 */
@Override public NetworkInputChannel<T> createNetworkInputChannel(final ChannelID channelID,final CompressionLevel compressionLevel){
  final NetworkInputChannel<T> enic=new NetworkInputChannel<T>(this,this.inputChannels.size(),deserializer,channelID,compressionLevel);
  addInputChannel(enic);
  return enic;
}","/** 
 * {@inheritDoc}
 */
@Override public NetworkInputChannel<T> createNetworkInputChannel(final InputGate<T> inputGate,final ChannelID channelID,final CompressionLevel compressionLevel){
  final NetworkInputChannel<T> enic=new NetworkInputChannel<T>(inputGate,this.inputChannels.size(),this.deserializer,channelID,compressionLevel);
  addInputChannel(enic);
  return enic;
}",0.9340813464235624
55751,"/** 
 * {@inheritDoc}
 */
@Override public InMemoryOutputChannel<T> createInMemoryOutputChannel(final ChannelID channelID,final CompressionLevel compressionLevel){
  final InMemoryOutputChannel<T> einoc=new InMemoryOutputChannel<T>(this,this.outputChannels.size(),channelID,compressionLevel);
  addOutputChannel(einoc);
  return einoc;
}","/** 
 * {@inheritDoc}
 */
@Override public InMemoryOutputChannel<T> createInMemoryOutputChannel(final OutputGate<T> outputGate,final ChannelID channelID,final CompressionLevel compressionLevel){
  final InMemoryOutputChannel<T> einoc=new InMemoryOutputChannel<T>(outputGate,this.outputChannels.size(),channelID,compressionLevel);
  addOutputChannel(einoc);
  return einoc;
}",0.9367088607594936
55752,"/** 
 * {@inheritDoc}
 */
@Override public NetworkOutputChannel<T> createNetworkOutputChannel(final ChannelID channelID,final CompressionLevel compressionLevel){
  final NetworkOutputChannel<T> enoc=new NetworkOutputChannel<T>(this,this.outputChannels.size(),channelID,compressionLevel);
  addOutputChannel(enoc);
  return enoc;
}","/** 
 * {@inheritDoc}
 */
@Override public NetworkOutputChannel<T> createNetworkOutputChannel(final OutputGate<T> outputGate,final ChannelID channelID,final CompressionLevel compressionLevel){
  final NetworkOutputChannel<T> enoc=new NetworkOutputChannel<T>(outputGate,this.outputChannels.size(),channelID,compressionLevel);
  addOutputChannel(enoc);
  return enoc;
}",0.9354375896700144
55753,"/** 
 * {@inheritDoc}
 */
@Override public FileOutputChannel<T> createFileOutputChannel(final ChannelID channelID,final CompressionLevel compressionLevel){
  final FileOutputChannel<T> efoc=new FileOutputChannel<T>(this,this.outputChannels.size(),channelID,compressionLevel);
  addOutputChannel(efoc);
  return efoc;
}","/** 
 * {@inheritDoc}
 */
@Override public FileOutputChannel<T> createFileOutputChannel(final OutputGate<T> outputGate,final ChannelID channelID,final CompressionLevel compressionLevel){
  final FileOutputChannel<T> efoc=new FileOutputChannel<T>(outputGate,this.outputChannels.size(),channelID,compressionLevel);
  addOutputChannel(efoc);
  return efoc;
}",0.9331352154531948
55754,"/** 
 * {@inheritDoc}
 */
@Override public NetworkInputChannel<T> createNetworkInputChannel(final ChannelID channelID,final CompressionLevel compressionLevel){
  return this.wrappedInputGate.createNetworkInputChannel(channelID,compressionLevel);
}","/** 
 * {@inheritDoc}
 */
@Override public NetworkInputChannel<T> createNetworkInputChannel(final InputGate<T> inputGate,final ChannelID channelID,final CompressionLevel compressionLevel){
  return this.wrappedInputGate.createNetworkInputChannel(inputGate,channelID,compressionLevel);
}",0.926829268292683
55755,"/** 
 * {@inheritDoc}
 */
@Override public InMemoryInputChannel<T> createInMemoryInputChannel(final ChannelID channelID,final CompressionLevel compressionLevel){
  return this.wrappedInputGate.createInMemoryInputChannel(channelID,compressionLevel);
}","/** 
 * {@inheritDoc}
 */
@Override public InMemoryInputChannel<T> createInMemoryInputChannel(final InputGate<T> inputGate,final ChannelID channelID,final CompressionLevel compressionLevel){
  return this.wrappedInputGate.createInMemoryInputChannel(inputGate,channelID,compressionLevel);
}",0.927643784786642
55756,"/** 
 * {@inheritDoc}
 */
@Override public FileInputChannel<T> createFileInputChannel(final ChannelID channelID,final CompressionLevel compressionLevel){
  return this.wrappedInputGate.createFileInputChannel(channelID,compressionLevel);
}","/** 
 * {@inheritDoc}
 */
@Override public FileInputChannel<T> createFileInputChannel(final InputGate<T> inputGate,final ChannelID channelID,final CompressionLevel compressionLevel){
  return this.wrappedInputGate.createFileInputChannel(inputGate,channelID,compressionLevel);
}",0.9242718446601942
55757,"/** 
 * {@inheritDoc}
 */
@Override public InMemoryOutputChannel<T> createInMemoryOutputChannel(final ChannelID channelID,final CompressionLevel compressionLevel){
  return this.wrappedOutputGate.createInMemoryOutputChannel(channelID,compressionLevel);
}","/** 
 * {@inheritDoc}
 */
@Override public InMemoryOutputChannel<T> createInMemoryOutputChannel(final OutputGate<T> outputGate,final ChannelID channelID,final CompressionLevel compressionLevel){
  return this.wrappedOutputGate.createInMemoryOutputChannel(outputGate,channelID,compressionLevel);
}",0.9236363636363636
55758,"/** 
 * {@inheritDoc}
 */
@Override public NetworkOutputChannel<T> createNetworkOutputChannel(final ChannelID channelID,final CompressionLevel compressionLevel){
  return this.wrappedOutputGate.createNetworkOutputChannel(channelID,compressionLevel);
}","/** 
 * {@inheritDoc}
 */
@Override public NetworkOutputChannel<T> createNetworkOutputChannel(final OutputGate<T> outputGate,final ChannelID channelID,final CompressionLevel compressionLevel){
  return this.wrappedOutputGate.createNetworkOutputChannel(outputGate,channelID,compressionLevel);
}",0.9227941176470588
55759,"/** 
 * {@inheritDoc}
 */
@Override public FileOutputChannel<T> createFileOutputChannel(final ChannelID channelID,final CompressionLevel compressionLevel){
  return this.wrappedOutputGate.createFileOutputChannel(channelID,compressionLevel);
}","/** 
 * {@inheritDoc}
 */
@Override public FileOutputChannel<T> createFileOutputChannel(final OutputGate<T> outputGate,final ChannelID channelID,final CompressionLevel compressionLevel){
  return this.wrappedOutputGate.createFileOutputChannel(outputGate,channelID,compressionLevel);
}",0.9201520912547528
55760,"/** 
 * Output Schema: Key: C_MKTSEGMENT Value: 0:PARTIAL_COUNT=1
 */
@Override public void match(PactRecord value1,PactRecord value2,Collector out) throws Exception {
  value2.getField(1,mktSeg);
  value2.setField(0,mktSeg);
  value2.setField(1,oneInteger);
  out.collect(value2);
}","/** 
 * Output Schema: Key: C_MKTSEGMENT Value: 0:PARTIAL_COUNT=1
 */
@Override public void match(PactRecord value1,PactRecord value2,Collector out) throws Exception {
  mktSeg=value2.getField(1,mktSeg);
  value2.setField(0,mktSeg);
  value2.setField(1,oneInteger);
  out.collect(value2);
}",0.987783595113438
55761,"/** 
 * Output Schema: Key: CUSTOMERKEY Value: 0:MKTSEGMENT
 */
@Override public void map(PactRecord record,Collector out) throws Exception {
  record.getField(1,value);
  PactString mktSegment=new PactString(value.getStringValueAt(6));
  record.setField(1,mktSegment);
  out.collect(record);
}","/** 
 * Output Schema: Key: CUSTOMERKEY Value: 0:MKTSEGMENT
 */
@Override public void map(PactRecord record,Collector out) throws Exception {
  value=record.getField(1,value);
  PactString mktSegment=new PactString(value.getStringValueAt(6));
  record.setField(1,mktSegment);
  out.collect(record);
}",0.98989898989899
55762,"@Override public void coGroup(Iterator<PactRecord> records1,Iterator<PactRecord> records2,Collector out){
  int sum=0;
  LOG.debug(""String_Node_Str"");
  while (records1.hasNext()) {
    record=records1.next();
    record.getField(0,keyString);
    record.getField(1,valueString);
    sum+=Integer.parseInt(valueString.getValue());
    LOG.debug(""String_Node_Str"" + keyString.getValue() + ""String_Node_Str""+ valueString.getValue()+ ""String_Node_Str"");
  }
  LOG.debug(""String_Node_Str"");
  while (records2.hasNext()) {
    record=records2.next();
    record.getField(0,keyString);
    record.getField(1,valueString);
    sum-=Integer.parseInt(valueString.getValue());
    LOG.debug(""String_Node_Str"" + keyString.getValue() + ""String_Node_Str""+ valueString.getValue()+ ""String_Node_Str"");
  }
  record.setField(1,new PactInteger(sum));
  LOG.debug(""String_Node_Str"");
  out.collect(record);
}","@Override public void coGroup(Iterator<PactRecord> records1,Iterator<PactRecord> records2,Collector out){
  int sum=0;
  LOG.debug(""String_Node_Str"");
  while (records1.hasNext()) {
    record=records1.next();
    keyString=record.getField(0,keyString);
    valueString=record.getField(1,valueString);
    sum+=Integer.parseInt(valueString.getValue());
    LOG.debug(""String_Node_Str"" + keyString.getValue() + ""String_Node_Str""+ valueString.getValue()+ ""String_Node_Str"");
  }
  LOG.debug(""String_Node_Str"");
  while (records2.hasNext()) {
    record=records2.next();
    keyString=record.getField(0,keyString);
    valueString=record.getField(1,valueString);
    sum-=Integer.parseInt(valueString.getValue());
    LOG.debug(""String_Node_Str"" + keyString.getValue() + ""String_Node_Str""+ valueString.getValue()+ ""String_Node_Str"");
  }
  record.setField(1,new PactInteger(sum));
  LOG.debug(""String_Node_Str"");
  out.collect(record);
}",0.975877192982456
55763,"@Override public void cross(PactRecord record1,PactRecord record2,Collector out){
  record1.getField(1,string);
  int val1=Integer.parseInt(string.toString());
  record2.getField(1,string);
  int val2=Integer.parseInt(string.toString());
  record1.getField(0,string);
  int key1=Integer.parseInt(string.toString());
  record2.getField(0,string);
  int key2=Integer.parseInt(string.toString());
  LOG.debug(""String_Node_Str"" + key1 + ""String_Node_Str""+ val1+ ""String_Node_Str""+ key2+ ""String_Node_Str""+ val2+ ""String_Node_Str"");
  if (val1 + val2 <= 6) {
    string.setValue((key1 + key2 + 2) + ""String_Node_Str"");
    integer.setValue(val2 - val1 + 1);
    record1.setField(0,string);
    record1.setField(1,integer);
    out.collect(record1);
  }
}","@Override public void cross(PactRecord record1,PactRecord record2,Collector out){
  string=record1.getField(1,string);
  int val1=Integer.parseInt(string.toString());
  string=record2.getField(1,string);
  int val2=Integer.parseInt(string.toString());
  string=record1.getField(0,string);
  int key1=Integer.parseInt(string.toString());
  string=record2.getField(0,string);
  int key2=Integer.parseInt(string.toString());
  LOG.debug(""String_Node_Str"" + key1 + ""String_Node_Str""+ val1+ ""String_Node_Str""+ key2+ ""String_Node_Str""+ val2+ ""String_Node_Str"");
  if (val1 + val2 <= 6) {
    string.setValue((key1 + key2 + 2) + ""String_Node_Str"");
    integer.setValue(val2 - val1 + 1);
    record1.setField(0,string);
    record1.setField(1,integer);
    out.collect(record1);
  }
}",0.981651376146789
55764,"@Override public void map(PactRecord record,Collector out) throws Exception {
  record.getField(0,keyString);
  record.getField(1,valueString);
  LOG.debug(""String_Node_Str"" + keyString.toString() + ""String_Node_Str""+ valueString.getValue()+ ""String_Node_Str"");
  if (Integer.parseInt(keyString.toString()) + Integer.parseInt(valueString.toString()) < 10) {
    record.setField(0,valueString);
    record.setField(1,new PactInteger(Integer.parseInt(keyString.toString()) + 10));
    out.collect(record);
  }
}","@Override public void map(PactRecord record,Collector out) throws Exception {
  keyString=record.getField(0,keyString);
  valueString=record.getField(1,valueString);
  LOG.debug(""String_Node_Str"" + keyString.toString() + ""String_Node_Str""+ valueString.getValue()+ ""String_Node_Str"");
  if (Integer.parseInt(keyString.toString()) + Integer.parseInt(valueString.toString()) < 10) {
    record.setField(0,valueString);
    record.setField(1,new PactInteger(Integer.parseInt(keyString.toString()) + 10));
    out.collect(record);
  }
}",0.9788461538461538
55765,"@Override public void match(PactRecord value1,PactRecord value2,Collector out) throws Exception {
  value1.getField(0,keyString);
  keyString.setValue(""String_Node_Str"" + (Integer.parseInt(keyString.getValue()) + 1));
  value1.setField(0,keyString);
  value1.getField(1,valueString);
  int val1=Integer.parseInt(valueString.getValue()) + 2;
  value2.getField(1,valueString);
  int val2=Integer.parseInt(valueString.getValue()) + 1;
  value1.setField(1,new PactInteger(val1 - val2));
  out.collect(value1);
  LOG.debug(""String_Node_Str"" + keyString.toString() + ""String_Node_Str""+ val1+ ""String_Node_Str""+ ""String_Node_Str""+ keyString.toString()+ ""String_Node_Str""+ val2+ ""String_Node_Str"");
}","@Override public void match(PactRecord value1,PactRecord value2,Collector out) throws Exception {
  keyString=value1.getField(0,keyString);
  keyString.setValue(""String_Node_Str"" + (Integer.parseInt(keyString.getValue()) + 1));
  value1.setField(0,keyString);
  valueString=value1.getField(1,valueString);
  int val1=Integer.parseInt(valueString.getValue()) + 2;
  valueString=value2.getField(1,valueString);
  int val2=Integer.parseInt(valueString.getValue()) + 1;
  value1.setField(1,new PactInteger(val1 - val2));
  out.collect(value1);
  LOG.debug(""String_Node_Str"" + keyString.toString() + ""String_Node_Str""+ val1+ ""String_Node_Str""+ ""String_Node_Str""+ keyString.toString()+ ""String_Node_Str""+ val2+ ""String_Node_Str"");
}",0.9760225669957688
55766,"@Override public void reduce(Iterator<PactRecord> records,Collector out) throws Exception {
  int sum=0;
  PactRecord record=new PactRecord();
  while (records.hasNext()) {
    record=records.next();
    record.getField(1,reduceValue);
    sum+=Integer.parseInt(reduceValue.toString());
    LOG.debug(""String_Node_Str"" + record.getField(0,PactString.class).toString() + ""String_Node_Str""+ reduceValue.toString()+ ""String_Node_Str"");
  }
  record.setField(1,new PactInteger(sum));
  out.collect(record);
}","@Override public void reduce(Iterator<PactRecord> records,Collector out) throws Exception {
  int sum=0;
  PactRecord record=new PactRecord();
  while (records.hasNext()) {
    record=records.next();
    reduceValue=record.getField(1,reduceValue);
    sum+=Integer.parseInt(reduceValue.toString());
    LOG.debug(""String_Node_Str"" + record.getField(0,PactString.class).toString() + ""String_Node_Str""+ reduceValue.toString()+ ""String_Node_Str"");
  }
  record.setField(1,new PactInteger(sum));
  out.collect(record);
}",0.9882352941176472
55767,"@Override public void combine(Iterator<PactRecord> records,Collector out) throws Exception {
  int sum=0;
  PactRecord record=new PactRecord();
  while (records.hasNext()) {
    record=records.next();
    record.getField(1,combineValue);
    sum+=Integer.parseInt(combineValue.toString());
    LOG.debug(""String_Node_Str"" + record.getField(0,PactString.class).toString() + ""String_Node_Str""+ combineValue.toString()+ ""String_Node_Str"");
  }
  combineValue.setValue(sum + ""String_Node_Str"");
  record.setField(1,combineValue);
  out.collect(record);
}","@Override public void combine(Iterator<PactRecord> records,Collector out) throws Exception {
  int sum=0;
  PactRecord record=new PactRecord();
  while (records.hasNext()) {
    record=records.next();
    combineValue=record.getField(1,combineValue);
    sum+=Integer.parseInt(combineValue.toString());
    LOG.debug(""String_Node_Str"" + record.getField(0,PactString.class).toString() + ""String_Node_Str""+ combineValue.toString()+ ""String_Node_Str"");
  }
  combineValue.setValue(sum + ""String_Node_Str"");
  record.setField(1,combineValue);
  out.collect(record);
}",0.9883198562443846
55768,"@Override public void reduce(Iterator<PactRecord> records,Collector out) throws Exception {
  double sum=0;
  while (records.hasNext()) {
    record=records.next();
    record.getField(0,key);
    record.getField(1,v);
    if (v.getNumberOfColumns() > 1) {
      long val=Math.round(Double.parseDouble(v.getStringValueAt(0)) * (1 - Double.parseDouble(v.getStringValueAt(1))) * 10000);
      sum+=(((double)val) / 10000d);
    }
 else {
      sum+=Double.parseDouble(v.getStringValueAt(0));
    }
  }
  Tuple summed=new Tuple();
  summed.addAttribute(FORMATTER.format(sum));
  LOGGER.info(""String_Node_Str"" + key);
  record.setField(1,summed);
  out.collect(record);
}","@Override public void reduce(Iterator<PactRecord> records,Collector out) throws Exception {
  double sum=0;
  while (records.hasNext()) {
    record=records.next();
    key=record.getField(0,key);
    v=record.getField(1,v);
    if (v.getNumberOfColumns() > 1) {
      long val=Math.round(Double.parseDouble(v.getStringValueAt(0)) * (1 - Double.parseDouble(v.getStringValueAt(1))) * 10000);
      sum+=(((double)val) / 10000d);
    }
 else {
      sum+=Double.parseDouble(v.getStringValueAt(0));
    }
  }
  Tuple summed=new Tuple();
  summed.addAttribute(FORMATTER.format(sum));
  LOGGER.info(""String_Node_Str"" + key);
  record.setField(1,summed);
  out.collect(record);
}",0.9955223880597016
55769,"@Override public void map(PactRecord record,Collector out) throws Exception {
  record.getField(1,tuple);
  tuple.project(2);
  record.setField(1,tuple);
  out.collect(record);
}","@Override public void map(PactRecord record,Collector out) throws Exception {
  tuple=record.getField(1,tuple);
  tuple.project(2);
  record.setField(1,tuple);
  out.collect(record);
}",0.9834254143646408
55770,"/** 
 * Project ""partsupp"". Output Schema: Key: partkey Value: (suppkey, supplycost)
 */
@Override public void map(PactRecord record,Collector out) throws Exception {
  record.getField(1,inputTuple);
  inputTuple.project((0 << 0) | (1 << 1) | (0 << 2)| (1 << 3)| (0 << 4));
  record.setField(1,inputTuple);
  out.collect(record);
}","/** 
 * Project ""partsupp"". Output Schema: Key: partkey Value: (suppkey, supplycost)
 */
@Override public void map(PactRecord record,Collector out) throws Exception {
  inputTuple=record.getField(1,inputTuple);
  inputTuple.project((0 << 0) | (1 << 1) | (0 << 2)| (1 << 3)| (0 << 4));
  record.setField(1,inputTuple);
  out.collect(record);
}",0.9836552748885586
55771,"@Override public void writeRecord(PactRecord record) throws IOException {
  record.getField(0,key);
  record.getField(1,value);
  this.buffer.setLength(0);
  this.buffer.append(key.getFirst().toString());
  this.buffer.append('|');
  this.buffer.append(key.getSecond().toString());
  this.buffer.append('|');
  this.buffer.append(value.toString());
  this.buffer.append('\n');
  byte[] bytes=this.buffer.toString().getBytes();
  this.stream.write(bytes);
}","@Override public void writeRecord(PactRecord record) throws IOException {
  key=record.getField(0,key);
  value=record.getField(1,value);
  this.buffer.setLength(0);
  this.buffer.append(key.getFirst().toString());
  this.buffer.append('|');
  this.buffer.append(key.getSecond().toString());
  this.buffer.append('|');
  this.buffer.append(value.toString());
  this.buffer.append('\n');
  byte[] bytes=this.buffer.toString().getBytes();
  this.stream.write(bytes);
}",0.9891540130151844
55772,"/** 
 * Project ""supplier"". Output Schema: Key: nationkey Value: suppkey
 */
@Override public void map(PactRecord record,Collector out) throws Exception {
  record.getField(0,suppKey);
  record.getField(1,inputTuple);
  PactInteger nationKey=new PactInteger(Integer.parseInt(inputTuple.getStringValueAt(3)));
  record.setField(0,nationKey);
  record.setField(1,suppKey);
  out.collect(record);
}","/** 
 * Project ""supplier"". Output Schema: Key: nationkey Value: suppkey
 */
@Override public void map(PactRecord record,Collector out) throws Exception {
  suppKey=record.getField(0,suppKey);
  inputTuple=record.getField(1,inputTuple);
  PactInteger nationKey=new PactInteger(Integer.parseInt(inputTuple.getStringValueAt(3)));
  record.setField(0,nationKey);
  record.setField(1,suppKey);
  out.collect(record);
}",0.976514215080346
55773,"/** 
 * Join ""nation"" and ""supplier"" by ""nationkey"". Output Schema: Key: suppkey Value: ""nation"" (name of the nation)
 */
@Override public void match(PactRecord value1,PactRecord value2,Collector out) throws Exception {
  value1.getField(1,suppKey);
  value2.getField(1,nationVal);
  PactString nationName=new PactString(nationVal.getStringValueAt(1));
  value1.setField(0,suppKey);
  value1.setField(1,nationName);
  out.collect(value1);
}","/** 
 * Join ""nation"" and ""supplier"" by ""nationkey"". Output Schema: Key: suppkey Value: ""nation"" (name of the nation)
 */
@Override public void match(PactRecord value1,PactRecord value2,Collector out) throws Exception {
  suppKey=value1.getField(1,suppKey);
  nationVal=value2.getField(1,nationVal);
  PactString nationName=new PactString(nationVal.getStringValueAt(1));
  value1.setField(0,suppKey);
  value1.setField(1,nationName);
  out.collect(value1);
}",0.979955456570156
55774,"/** 
 * Compute the new position (coordinate vector) of a cluster center.
 */
@Override public void reduce(Iterator<PactRecord> dataPoints,Collector out){
  PactRecord next=null;
  this.coordinates.setCoordinates(null);
  double[] coordinateSum=null;
  int count=0;
  while (dataPoints.hasNext()) {
    next=dataPoints.next();
    double[] thisCoords=next.getField(1,CoordVector.class).getCoordinates();
    int thisCount=next.getField(2,PactInteger.class).getValue();
    if (coordinateSum == null) {
      if (this.coordinates.getCoordinates() != null) {
        coordinateSum=this.coordinates.getCoordinates();
      }
 else {
        coordinateSum=new double[thisCoords.length];
      }
    }
    addToCoordVector(coordinateSum,thisCoords);
    count+=thisCount;
  }
  for (int i=0; i < coordinateSum.length; i++) {
    coordinateSum[i]/=count;
  }
  this.coordinates.setCoordinates(coordinateSum);
  next.setField(1,this.coordinates);
  out.collect(next);
}","/** 
 * Compute the new position (coordinate vector) of a cluster center.
 */
@Override public void reduce(Iterator<PactRecord> dataPoints,Collector out){
  PactRecord next=null;
  CoordVector coordinates=new CoordVector();
  double[] coordinateSum=null;
  int count=0;
  while (dataPoints.hasNext()) {
    next=dataPoints.next();
    double[] thisCoords=next.getField(1,CoordVector.class).getCoordinates();
    int thisCount=next.getField(2,PactInteger.class).getValue();
    if (coordinateSum == null) {
      if (coordinates.getCoordinates() != null) {
        coordinateSum=coordinates.getCoordinates();
      }
 else {
        coordinateSum=new double[thisCoords.length];
      }
    }
    addToCoordVector(coordinateSum,thisCoords);
    count+=thisCount;
  }
  for (int i=0; i < coordinateSum.length; i++) {
    coordinateSum[i]/=count;
  }
  coordinates.setCoordinates(coordinateSum);
  next.setField(1,coordinates);
  out.collect(next);
}",0.949685534591195
55775,"/** 
 * Computes a pre-aggregated average value of a coordinate vector.
 */
@Override public void combine(Iterator<PactRecord> dataPoints,Collector out){
  PactRecord next=null;
  this.coordinates.setCoordinates(null);
  double[] coordinateSum=null;
  int count=0;
  while (dataPoints.hasNext()) {
    next=dataPoints.next();
    double[] thisCoords=next.getField(1,CoordVector.class).getCoordinates();
    int thisCount=next.getField(2,PactInteger.class).getValue();
    if (coordinateSum == null) {
      if (this.coordinates.getCoordinates() != null) {
        coordinateSum=this.coordinates.getCoordinates();
      }
 else {
        coordinateSum=new double[thisCoords.length];
      }
    }
    addToCoordVector(coordinateSum,thisCoords);
    count+=thisCount;
  }
  this.coordinates.setCoordinates(coordinateSum);
  this.count.setValue(count);
  next.setField(1,this.coordinates);
  next.setField(2,this.count);
  out.collect(next);
}","/** 
 * Computes a pre-aggregated average value of a coordinate vector.
 */
@Override public void combine(Iterator<PactRecord> dataPoints,Collector out){
  PactRecord next=null;
  CoordVector coordinates=new CoordVector();
  double[] coordinateSum=null;
  int count=0;
  while (dataPoints.hasNext()) {
    next=dataPoints.next();
    double[] thisCoords=next.getField(1,CoordVector.class).getCoordinates();
    int thisCount=next.getField(2,PactInteger.class).getValue();
    if (coordinateSum == null) {
      if (coordinates.getCoordinates() != null) {
        coordinateSum=coordinates.getCoordinates();
      }
 else {
        coordinateSum=new double[thisCoords.length];
      }
    }
    addToCoordVector(coordinateSum,thisCoords);
    count+=thisCount;
  }
  coordinates.setCoordinates(coordinateSum);
  this.count.setValue(count);
  next.setField(1,coordinates);
  next.setField(2,this.count);
  out.collect(next);
}",0.9484978540772532
55776,"/** 
 * Compute the new position (coordinate vector) of a cluster center.
 */
@Override public void reduce(Iterator<PactRecord> dataPoints,Collector out){
  this.coordinates.setCoordinates(null);
  double[] coordinateSum=null;
  int count=0;
  while (dataPoints.hasNext()) {
    PactRecord next=dataPoints.next();
    next.getField(0,cid);
    double[] thisCoords=next.getField(1,CoordVector.class).getCoordinates();
    int thisCount=next.getField(2,PactInteger.class).getValue();
    if (coordinateSum == null) {
      if (this.coordinates.getCoordinates() != null) {
        coordinateSum=this.coordinates.getCoordinates();
      }
 else {
        coordinateSum=new double[thisCoords.length];
      }
    }
    addToCoordVector(coordinateSum,thisCoords);
    count+=thisCount;
  }
  for (int i=0; i < coordinateSum.length; i++) {
    coordinateSum[i]/=count;
  }
  this.coordinates.setCoordinates(coordinateSum);
  result.setField(0,cid);
  result.setField(1,this.coordinates);
  out.collect(result);
}","/** 
 * Compute the new position (coordinate vector) of a cluster center.
 */
@Override public void reduce(Iterator<PactRecord> dataPoints,Collector out){
  PactRecord next=null;
  this.coordinates.setCoordinates(null);
  double[] coordinateSum=null;
  int count=0;
  while (dataPoints.hasNext()) {
    next=dataPoints.next();
    double[] thisCoords=next.getField(1,CoordVector.class).getCoordinates();
    int thisCount=next.getField(2,PactInteger.class).getValue();
    if (coordinateSum == null) {
      if (this.coordinates.getCoordinates() != null) {
        coordinateSum=this.coordinates.getCoordinates();
      }
 else {
        coordinateSum=new double[thisCoords.length];
      }
    }
    addToCoordVector(coordinateSum,thisCoords);
    count+=thisCount;
  }
  for (int i=0; i < coordinateSum.length; i++) {
    coordinateSum[i]/=count;
  }
  this.coordinates.setCoordinates(coordinateSum);
  next.setField(1,this.coordinates);
  out.collect(next);
}",0.931367564819522
55777,"/** 
 * Computes the distance of one data point to one cluster center and emits a key-value-pair where the id of the data point is the key and a Distance object is the value.
 */
@Override public void cross(PactRecord dataPointRecord,PactRecord clusterCenterRecord,Collector out){
  dataPointRecord.getField(1,dataPoint);
  clusterCenterRecord.getField(0,clusterCenterId);
  clusterCenterRecord.getField(1,clusterPoint);
  this.distance.setValue(dataPoint.computeEuclidianDistance(clusterPoint));
  dataPointRecord.setField(2,clusterCenterId);
  dataPointRecord.setField(3,this.distance);
  out.collect(dataPointRecord);
}","/** 
 * Computes the distance of one data point to one cluster center and emits a key-value-pair where the id of the data point is the key and a Distance object is the value.
 */
@Override public void cross(PactRecord dataPointRecord,PactRecord clusterCenterRecord,Collector out){
  CoordVector dataPoint=dataPointRecord.getField(1,CoordVector.class);
  PactInteger clusterCenterId=clusterCenterRecord.getField(0,PactInteger.class);
  CoordVector clusterPoint=clusterCenterRecord.getField(1,CoordVector.class);
  this.distance.setValue(dataPoint.computeEuclidianDistance(clusterPoint));
  dataPointRecord.setField(2,clusterCenterId);
  dataPointRecord.setField(3,this.distance);
  out.collect(dataPointRecord);
}",0.8800599700149925
55778,"@Override public int serializeRecord(PactRecord record,byte[] target){
  record.getField(0,this.centerId);
  record.getField(1,this.centerPos);
  StringBuilder line=new StringBuilder();
  line.append(this.centerId.getValue());
  for (  double coord : this.centerPos.getCoordinates()) {
    line.append('|');
    line.append(df.format(coord));
  }
  line.append('|');
  byte[] byteString=line.toString().getBytes();
  if (byteString.length <= target.length) {
    System.arraycopy(byteString,0,target,0,byteString.length);
    return byteString.length;
  }
 else {
    return -1 * byteString.length;
  }
}","@Override public int serializeRecord(PactRecord record,byte[] target){
  line.setLength(0);
  PactInteger centerId=record.getField(0,PactInteger.class);
  CoordVector centerPos=record.getField(1,CoordVector.class);
  line.append(centerId.getValue());
  for (  double coord : centerPos.getCoordinates()) {
    line.append('|');
    line.append(df.format(coord));
  }
  line.append('|');
  byte[] byteString=line.toString().getBytes();
  if (byteString.length <= target.length) {
    System.arraycopy(byteString,0,target,0,byteString.length);
    return byteString.length;
  }
 else {
    return -byteString.length;
  }
}",0.7653311529026983
55779,"/** 
 * Computes a pre-aggregated average value of a coordinate vector.
 */
@Override public void combine(Iterator<PactRecord> dataPoints,Collector out){
  this.coordinates.setCoordinates(null);
  double[] coordinateSum=null;
  int count=0;
  while (dataPoints.hasNext()) {
    PactRecord next=dataPoints.next();
    next.getField(0,cid);
    double[] thisCoords=next.getField(1,CoordVector.class).getCoordinates();
    int thisCount=next.getField(2,PactInteger.class).getValue();
    if (coordinateSum == null) {
      if (this.coordinates.getCoordinates() != null) {
        coordinateSum=this.coordinates.getCoordinates();
      }
 else {
        coordinateSum=new double[thisCoords.length];
      }
    }
    addToCoordVector(coordinateSum,thisCoords);
    count+=thisCount;
  }
  this.coordinates.setCoordinates(coordinateSum);
  this.count.setValue(count);
  result.setField(0,cid);
  result.setField(1,this.coordinates);
  result.setField(2,this.count);
  out.collect(result);
}","/** 
 * Computes a pre-aggregated average value of a coordinate vector.
 */
@Override public void combine(Iterator<PactRecord> dataPoints,Collector out){
  PactRecord next=null;
  this.coordinates.setCoordinates(null);
  double[] coordinateSum=null;
  int count=0;
  while (dataPoints.hasNext()) {
    next=dataPoints.next();
    double[] thisCoords=next.getField(1,CoordVector.class).getCoordinates();
    int thisCount=next.getField(2,PactInteger.class).getValue();
    if (coordinateSum == null) {
      if (this.coordinates.getCoordinates() != null) {
        coordinateSum=this.coordinates.getCoordinates();
      }
 else {
        coordinateSum=new double[thisCoords.length];
      }
    }
    addToCoordVector(coordinateSum,thisCoords);
    count+=thisCount;
  }
  this.coordinates.setCoordinates(coordinateSum);
  this.count.setValue(count);
  next.setField(1,this.coordinates);
  next.setField(2,this.count);
  out.collect(next);
}",0.9257142857142856
55780,"/** 
 * Aggregate ""amount"": sum(amount) GROUP BY nation, year Output Schema: Key: (nation, year) Value: amount
 */
@Override public void reduce(Iterator<PactRecord> records,Collector out) throws Exception {
  float amount=0;
  while (records.hasNext()) {
    record=records.next();
    record.getField(1,value);
    amount+=Float.parseFloat(value.toString());
  }
  if (value != null) {
    value.setValue(""String_Node_Str"" + amount);
    record.setField(1,value);
    out.collect(record);
  }
}","/** 
 * Aggregate ""amount"": sum(amount) GROUP BY nation, year Output Schema: Key: (nation, year) Value: amount
 */
@Override public void reduce(Iterator<PactRecord> records,Collector out) throws Exception {
  PactRecord record=null;
  float amount=0;
  while (records.hasNext()) {
    record=records.next();
    PactString value=record.getField(1,PactString.class);
    amount+=Float.parseFloat(value.toString());
  }
  value.setValue(String.valueOf(amount));
  record.setField(1,value);
  out.collect(record);
}",0.7805362462760675
55781,"/** 
 * Join together parts and orderedParts by matching partkey and suppkey. Output Schema: Key: suppkey Value: (amount, year)
 */
@Override public void match(PactRecord value1,PactRecord value2,Collector out) throws Exception {
  value1.getField(0,partAndSupplierKey);
  value1.getField(1,supplyCostStr);
  value2.getField(1,ordersValue);
  PactInteger year=new PactInteger(Integer.parseInt(ordersValue.getStringValueAt(0)));
  float quantity=Float.parseFloat(ordersValue.getStringValueAt(1));
  float price=Float.parseFloat(ordersValue.getStringValueAt(2));
  float supplyCost=Float.parseFloat(supplyCostStr.toString());
  float amount=price - supplyCost * quantity;
  value1.setField(0,partAndSupplierKey.getSecond());
  value1.setField(1,new StringIntPair(new PactString(""String_Node_Str"" + amount),year));
  out.collect(value1);
}","/** 
 * Join together parts and orderedParts by matching partkey and suppkey. Output Schema: Key: suppkey Value: (amount, year)
 */
@Override public void match(PactRecord value1,PactRecord value2,Collector out) throws Exception {
  IntPair partAndSupplierKey=value1.getField(0,this.partAndSupplierKey);
  PactString supplyCostStr=value1.getField(1,this.supplyCostStr);
  Tuple ordersValue=value2.getField(1,this.ordersValue);
  PactInteger year=new PactInteger(Integer.parseInt(ordersValue.getStringValueAt(0)));
  float quantity=Float.parseFloat(ordersValue.getStringValueAt(1));
  float price=Float.parseFloat(ordersValue.getStringValueAt(2));
  float supplyCost=Float.parseFloat(supplyCostStr.toString());
  float amount=price - supplyCost * quantity;
  value1.setField(0,partAndSupplierKey.getSecond());
  value1.setField(1,new StringIntPair(new PactString(""String_Node_Str"" + amount),year));
  out.collect(value1);
}",0.9516220830961868
55782,"/** 
 * Filter ""lineitem"". Output Schema: Key: orderkey Value: (partkey, suppkey, quantity, price)
 */
@Override public void map(PactRecord record,Collector out) throws Exception {
  record.getField(1,inputTuple);
  float price=Float.parseFloat(inputTuple.getStringValueAt(5)) * (1 - Float.parseFloat(inputTuple.getStringValueAt(6)));
  inputTuple.project((0 << 0) | (1 << 1) | (1 << 2)| (0 << 3)| (1 << 4));
  inputTuple.addAttribute(""String_Node_Str"" + price);
  record.setField(1,inputTuple);
  out.collect(record);
}","/** 
 * Filter ""lineitem"". Output Schema: Key: orderkey Value: (partkey, suppkey, quantity, price)
 */
@Override public void map(PactRecord record,Collector out) throws Exception {
  Tuple inputTuple=record.getField(1,Tuple.class);
  float price=Float.parseFloat(inputTuple.getStringValueAt(5)) * (1 - Float.parseFloat(inputTuple.getStringValueAt(6)));
  inputTuple.project((0 << 0) | (1 << 1) | (1 << 2)| (0 << 3)| (1 << 4));
  inputTuple.addAttribute(""String_Node_Str"" + price);
  record.setField(1,inputTuple);
  out.collect(record);
}",0.9640831758034026
55783,"/** 
 * Project ""orders"" Output Schema: Key: orderkey Value: year (from date)
 */
@Override public void map(PactRecord record,Collector out) throws Exception {
  record.getField(1,inputTuple);
  int year=Integer.parseInt(inputTuple.getStringValueAt(4).substring(0,4));
  record.setField(1,new PactInteger(year));
  out.collect(record);
}","/** 
 * Project ""orders"" Output Schema: Key: orderkey Value: year (from date)
 */
@Override public void map(PactRecord record,Collector out) throws Exception {
  Tuple inputTuple=record.getField(1,this.inputTuple);
  int year=Integer.parseInt(inputTuple.getStringValueAt(4).substring(0,4));
  record.setField(1,new PactInteger(year));
  out.collect(record);
}",0.9683908045977012
55784,"/** 
 * Join ""orders"" and ""lineitem"" by ""orderkey"". Output Schema: Key: (partkey, suppkey) Value: (year, quantity, price)
 */
@Override public void match(PactRecord value1,PactRecord value2,Collector out) throws Exception {
  value1.getField(1,year);
  value2.getField(1,lineItem);
  IntPair newKey=new IntPair(new PactInteger(Integer.parseInt(lineItem.getStringValueAt(0))),new PactInteger(Integer.parseInt(lineItem.getStringValueAt(1))));
  Tuple newValue=new Tuple();
  newValue.addAttribute(year.toString());
  newValue.addAttribute(lineItem.getStringValueAt(2));
  newValue.addAttribute(lineItem.getStringValueAt(3));
  value1.setField(0,newKey);
  value1.setField(1,newValue);
  out.collect(value1);
}","/** 
 * Join ""orders"" and ""lineitem"" by ""orderkey"". Output Schema: Key: (partkey, suppkey) Value: (year, quantity, price)
 */
@Override public void match(PactRecord value1,PactRecord value2,Collector out) throws Exception {
  PactInteger year=value1.getField(1,PactInteger.class);
  Tuple lineItem=value2.getField(1,Tuple.class);
  IntPair newKey=new IntPair(new PactInteger(Integer.parseInt(lineItem.getStringValueAt(0))),new PactInteger(Integer.parseInt(lineItem.getStringValueAt(1))));
  Tuple newValue=new Tuple();
  newValue.addAttribute(year.toString());
  newValue.addAttribute(lineItem.getStringValueAt(2));
  newValue.addAttribute(lineItem.getStringValueAt(3));
  value1.setField(0,newKey);
  value1.setField(1,newValue);
  out.collect(value1);
}",0.4596443228454172
55785,"/** 
 * Filter and project ""part"". The parts are filtered by ""name LIKE %green%"". Output Schema: Key: partkey Value: (empty)
 */
@Override public void map(PactRecord record,Collector out) throws Exception {
  record.getField(1,inputTuple);
  if (inputTuple.getStringValueAt(1).indexOf(COLOR) != -1) {
    record.setField(1,PactNull.getInstance());
    out.collect(record);
  }
}","/** 
 * Filter and project ""part"". The parts are filtered by ""name LIKE %green%"". Output Schema: Key: partkey Value: (empty)
 */
@Override public void map(PactRecord record,Collector out) throws Exception {
  Tuple inputTuple=record.getField(1,this.inputTuple);
  if (inputTuple.getStringValueAt(1).indexOf(COLOR) != -1) {
    record.setField(1,PactNull.getInstance());
    out.collect(record);
  }
}",0.9717223650385604
55786,"/** 
 * Join ""part"" and ""partsupp"" by ""partkey"". Output Schema: Key: (partkey, suppkey) Value: supplycost
 */
@Override public void match(PactRecord value1,PactRecord value2,Collector out) throws Exception {
  value1.getField(0,partKey);
  value2.getField(1,partSuppValue);
  IntPair newKey=new IntPair(partKey,new PactInteger(Integer.parseInt(partSuppValue.getStringValueAt(0))));
  String supplyCost=partSuppValue.getStringValueAt(1);
  value1.setField(0,newKey);
  value1.setField(1,new PactString(supplyCost));
  out.collect(value1);
}","/** 
 * Join ""part"" and ""partsupp"" by ""partkey"". Output Schema: Key: (partkey, suppkey) Value: supplycost
 */
@Override public void match(PactRecord value1,PactRecord value2,Collector out) throws Exception {
  PactInteger partKey=value1.getField(0,this.partKey);
  Tuple partSuppValue=value2.getField(1,this.partSuppValue);
  IntPair newKey=new IntPair(partKey,new PactInteger(Integer.parseInt(partSuppValue.getStringValueAt(0))));
  String supplyCost=partSuppValue.getStringValueAt(1);
  value1.setField(0,newKey);
  value1.setField(1,new PactString(supplyCost));
  out.collect(value1);
}",0.9556737588652482
55787,"/** 
 * Join ""filteredParts"" and ""suppliers"" by ""suppkey"". Output Schema: Key: (nation, year) Value: amount
 */
@Override public void match(PactRecord value1,PactRecord value2,Collector out) throws Exception {
  value1.getField(1,amountYearPair);
  value2.getField(1,nationName);
  PactInteger year=amountYearPair.getSecond();
  PactString amount=amountYearPair.getFirst();
  StringIntPair key=new StringIntPair(nationName,year);
  value1.setField(0,key);
  value1.setField(1,amount);
  out.collect(value1);
}","/** 
 * Join ""filteredParts"" and ""suppliers"" by ""suppkey"". Output Schema: Key: (nation, year) Value: amount
 */
@Override public void match(PactRecord value1,PactRecord value2,Collector out) throws Exception {
  StringIntPair amountYearPair=value1.getField(1,this.amountYearPair);
  PactString nationName=value2.getField(1,this.nationName);
  PactInteger year=amountYearPair.getSecond();
  PactString amount=amountYearPair.getFirst();
  StringIntPair key=new StringIntPair(nationName,year);
  value1.setField(0,key);
  value1.setField(1,amount);
  out.collect(value1);
}",0.943466172381835
55788,"boolean canBeAdded(final TransferEnvelope transferEnvelope){
  if (this.tailSequenceNumber == -1) {
    return true;
  }
  final EventList eventList=transferEnvelope.getEventList();
  if (eventList != null) {
    if (!eventList.isEmpty()) {
      return false;
    }
  }
  if (!this.jobID.equals(transferEnvelope.getJobID())) {
    return false;
  }
  if (!this.source.equals(transferEnvelope.getSource())) {
    return false;
  }
  if (this.tailSequenceNumber != (transferEnvelope.getSequenceNumber() - 1)) {
    return false;
  }
  return true;
}","boolean canBeAdded(final TransferEnvelope transferEnvelope){
  if (this.tailSequenceNumber == -1) {
    return true;
  }
  final EventList eventList=transferEnvelope.getEventList();
  if (eventList != null) {
    if (!eventList.isEmpty()) {
      return false;
    }
  }
  if (!this.jobID.equals(transferEnvelope.getJobID())) {
    return false;
  }
  if (!this.source.equals(transferEnvelope.getSource())) {
    return false;
  }
  if (this.tailSequenceNumber != (transferEnvelope.getSequenceNumber() - 1)) {
    return false;
  }
  if (this.size() >= SIZE_LIMIT) {
    return false;
  }
  return true;
}",0.9262792714657416
55789,"int unspill(final BufferProvider bufferProvider) throws IOException {
  if (this.headSequenceNumber == -1) {
    return 0;
  }
  if (this.headSequenceNumber == this.tailSequenceNumber) {
    final Buffer buffer=(Buffer)this.bufferRef;
    if (buffer == null) {
      return 0;
    }
    if (buffer.isBackedByMemory()) {
      return 0;
    }
    final int size=buffer.size();
    final Buffer memBuffer=bufferProvider.requestEmptyBuffer(size);
    if (memBuffer == null) {
      return 0;
    }
    buffer.copyToBuffer(memBuffer);
    this.bufferRef=memBuffer;
    buffer.recycleBuffer();
    return size;
  }
  @SuppressWarnings(""String_Node_Str"") final Queue<Object> bufferQueue=(Queue<Object>)this.bufferRef;
  final int queueSize=bufferQueue.size();
  int usedMemory=0;
  int count=0;
  while (count++ < queueSize) {
    final Object obj=bufferQueue.poll();
    if (obj == NULL_OBJECT) {
      bufferQueue.add(obj);
      continue;
    }
    final Buffer buffer=(Buffer)obj;
    if (buffer.isBackedByMemory()) {
      bufferQueue.add(buffer);
      continue;
    }
    final int size=buffer.size();
    final Buffer memBuffer=bufferProvider.requestEmptyBuffer(size);
    if (memBuffer != null) {
      buffer.copyToBuffer(memBuffer);
      bufferQueue.add(memBuffer);
      buffer.recycleBuffer();
    }
 else {
      bufferQueue.add(buffer);
      return usedMemory;
    }
    usedMemory+=size;
  }
  return usedMemory;
}","int unspill(final BufferProvider bufferProvider) throws IOException {
  if (this.headSequenceNumber == -1) {
    return 0;
  }
  if (this.headSequenceNumber == this.tailSequenceNumber) {
    final Buffer buffer=(Buffer)this.bufferRef;
    if (buffer == null) {
      return 0;
    }
    if (buffer.isBackedByMemory()) {
      return 0;
    }
    final int size=buffer.size();
    final Buffer memBuffer=bufferProvider.requestEmptyBuffer(size);
    if (memBuffer == null) {
      return 0;
    }
    buffer.copyToBuffer(memBuffer);
    this.bufferRef=memBuffer;
    buffer.recycleBuffer();
    return size;
  }
  @SuppressWarnings(""String_Node_Str"") final Queue<Object> bufferQueue=(Queue<Object>)this.bufferRef;
  final int queueSize=bufferQueue.size();
  int usedMemory=0;
  int count=0;
  while (count++ < queueSize) {
    final Object obj=bufferQueue.poll();
    if (obj == NULL_OBJECT) {
      bufferQueue.add(obj);
      continue;
    }
    final Buffer buffer=(Buffer)obj;
    if (buffer.isBackedByMemory()) {
      bufferQueue.add(buffer);
      continue;
    }
    final int size=buffer.size();
    final Buffer memBuffer=bufferProvider.requestEmptyBuffer(size);
    if (memBuffer != null) {
      buffer.copyToBuffer(memBuffer);
      bufferQueue.add(memBuffer);
      buffer.recycleBuffer();
    }
 else {
      bufferQueue.add(buffer);
      continue;
    }
    usedMemory+=size;
  }
  return usedMemory;
}",0.9912064720365812
55790,"/** 
 * Checks the transition of the execution state and outputs an error in case of an unexpected state transition.
 * @param taskName the name of the task whose execution has changed
 * @param oldState the old execution state
 * @param newState the new execution state
 */
public static void checkTransition(final String taskName,final ExecutionState oldState,final ExecutionState newState){
  if (oldState == ExecutionState.CANCELED || oldState == ExecutionState.FINISHED || oldState == ExecutionState.FAILED) {
    return;
  }
  LOG.info(""String_Node_Str"" + oldState + ""String_Node_Str""+ newState+ ""String_Node_Str""+ taskName);
  boolean unexpectedStateChange=true;
  if (oldState == ExecutionState.CREATED && newState == ExecutionState.SCHEDULED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.SCHEDULED && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.ASSIGNED && newState == ExecutionState.READY) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.READY && newState == ExecutionState.STARTING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.STARTING && newState == ExecutionState.RUNNING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.RUNNING && newState == ExecutionState.FINISHING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FINISHING && newState == ExecutionState.FINISHED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.SCHEDULED && newState == ExecutionState.CANCELED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.ASSIGNED && newState == ExecutionState.CANCELED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.READY && newState == ExecutionState.CANCELED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.STARTING && newState == ExecutionState.FAILED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.RUNNING && newState == ExecutionState.FAILED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FINISHING && newState == ExecutionState.FAILED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.RUNNING && newState == ExecutionState.CANCELING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FINISHING && newState == ExecutionState.CANCELING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.CANCELING && newState == ExecutionState.CANCELED) {
    unexpectedStateChange=false;
  }
  if (unexpectedStateChange) {
    LOG.error(""String_Node_Str"" + oldState + ""String_Node_Str""+ newState);
  }
}","/** 
 * Checks the transition of the execution state and outputs an error in case of an unexpected state transition.
 * @param taskName the name of the task whose execution has changed
 * @param oldState the old execution state
 * @param newState the new execution state
 */
public static void checkTransition(final String taskName,final ExecutionState oldState,final ExecutionState newState){
  if (oldState == ExecutionState.CANCELED || oldState == ExecutionState.FINISHED || oldState == ExecutionState.FAILED) {
    return;
  }
  LOG.info(""String_Node_Str"" + oldState + ""String_Node_Str""+ newState+ ""String_Node_Str""+ taskName);
  boolean unexpectedStateChange=true;
  if (oldState == ExecutionState.CREATED && newState == ExecutionState.SCHEDULED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.SCHEDULED && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.ASSIGNED && newState == ExecutionState.READY) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.READY && newState == ExecutionState.STARTING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.STARTING && newState == ExecutionState.RUNNING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.RUNNING && newState == ExecutionState.FINISHING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FINISHING && newState == ExecutionState.FINISHED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.CREATED && newState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.SCHEDULED && newState == ExecutionState.CANCELED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.ASSIGNED && newState == ExecutionState.CANCELED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.READY && newState == ExecutionState.CANCELED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.STARTING && newState == ExecutionState.FAILED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.RUNNING && newState == ExecutionState.FAILED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FINISHING && newState == ExecutionState.FAILED) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.RUNNING && newState == ExecutionState.CANCELING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.FINISHING && newState == ExecutionState.CANCELING) {
    unexpectedStateChange=false;
  }
  if (oldState == ExecutionState.CANCELING && newState == ExecutionState.CANCELED) {
    unexpectedStateChange=false;
  }
  if (unexpectedStateChange) {
    LOG.error(""String_Node_Str"" + oldState + ""String_Node_Str""+ newState);
  }
}",0.9783158655583664
55791,"protected ThreadBase getReadingThread(ExceptionHandler<IOException> exceptionHandler,MutableObjectIterator<PactRecord> reader,CircularQueues queues,AbstractTask parentTask,long startSpillingBytes){
  this.collector=new InputDataCollector(queues,startSpillingBytes);
  return new DummyThread(exceptionHandler,queues,parentTask);
}","@Override protected ThreadBase getReadingThread(ExceptionHandler<IOException> exceptionHandler,MutableObjectIterator<PactRecord> reader,CircularQueues queues,AbstractInvokable parentTask,long startSpillingBytes){
  this.collector=new InputDataCollector(queues,startSpillingBytes);
  return new DummyThread(exceptionHandler,queues,parentTask);
}",0.9687964338781576
55792,"@Override public void openTask() throws Exception {
  AbstractPactTask.openUserCode(this.combiner,this.config.getStubParameters());
  final long availableMemory=this.config.getMemorySize();
  LocalStrategy ls=config.getLocalStrategy();
  long strategyMinMem=0;
switch (ls) {
case COMBININGSORT:
    strategyMinMem=MIN_REQUIRED_MEMORY;
  break;
}
if (availableMemory < strategyMinMem) {
throw new RuntimeException(""String_Node_Str"" + config.getLocalStrategy() + ""String_Node_Str""+ availableMemory+ ""String_Node_Str""+ ""String_Node_Str""+ strategyMinMem+ ""String_Node_Str"");
}
final MemoryManager memoryManager=this.parent.getEnvironment().getMemoryManager();
final IOManager ioManager=this.parent.getEnvironment().getIOManager();
final int[] keyPositions=this.config.getLocalStrategyKeyPositions(0);
final Class<? extends Key>[] keyClasses=this.config.getLocalStrategyKeyClasses(this.userCodeClassLoader);
if (keyPositions == null || keyClasses == null) {
throw new Exception(""String_Node_Str"");
}
@SuppressWarnings(""String_Node_Str"") final Comparator<Key>[] comparators=new Comparator[keyPositions.length];
final KeyComparator kk=new KeyComparator();
for (int i=0; i < comparators.length; i++) {
comparators[i]=kk;
}
switch (ls) {
case COMBININGSORT:
this.sorter=new AsynchronousPartialSorterCollector(memoryManager,ioManager,availableMemory,comparators,keyPositions,keyClasses,this.parent);
break;
default :
throw new RuntimeException(""String_Node_Str"");
}
this.combinerThread=new CombinerThread(this.sorter,keyPositions,keyClasses,this.combiner,this.outputCollector);
this.combinerThread.start();
}","@Override public void openTask() throws Exception {
  AbstractPactTask.openUserCode(this.combiner,this.config.getStubParameters());
  final long availableMemory=this.config.getMemorySize();
  LocalStrategy ls=config.getLocalStrategy();
  long strategyMinMem=0;
switch (ls) {
case COMBININGSORT:
    strategyMinMem=MIN_REQUIRED_MEMORY;
  break;
}
if (availableMemory < strategyMinMem) {
throw new RuntimeException(""String_Node_Str"" + config.getLocalStrategy() + ""String_Node_Str""+ availableMemory+ ""String_Node_Str""+ ""String_Node_Str""+ strategyMinMem+ ""String_Node_Str"");
}
final MemoryManager memoryManager=this.parent.getEnvironment().getMemoryManager();
final IOManager ioManager=this.parent.getEnvironment().getIOManager();
final int[] keyPositions=this.config.getLocalStrategyKeyPositions(0);
final Class<? extends Key>[] keyClasses=this.config.getLocalStrategyKeyClasses(this.userCodeClassLoader);
if (keyPositions == null || keyClasses == null) {
throw new Exception(""String_Node_Str"");
}
@SuppressWarnings(""String_Node_Str"") final Comparator<Key>[] comparators=new Comparator[keyPositions.length];
final KeyComparator kk=new KeyComparator();
for (int i=0; i < comparators.length; i++) {
comparators[i]=kk;
}
switch (ls) {
case COMBININGSORT:
this.sorter=new AsynchronousPartialSorterCollector(memoryManager,ioManager,availableMemory,comparators,keyPositions,keyClasses,this.parent);
this.inputCollector=this.sorter.getInputCollector();
break;
default :
throw new RuntimeException(""String_Node_Str"");
}
this.combinerThread=new CombinerThread(this.sorter,keyPositions,keyClasses,this.combiner,this.outputCollector);
this.combinerThread.start();
}",0.9836872883964296
55793,"private CombinerThread(AsynchronousPartialSorterCollector sorter,int[] keyPositions,Class<? extends Key>[] keyClasses,ReduceStub stub,Collector output){
  super(""String_Node_Str"");
  setDaemon(true);
  this.sorter=sorter;
  this.keyPositions=keyPositions;
  this.keyClasses=keyClasses;
  this.stub=stub;
  this.output=output;
}","private CombinerThread(AsynchronousPartialSorterCollector sorter,int[] keyPositions,Class<? extends Key>[] keyClasses,ReduceStub stub,Collector output){
  super(""String_Node_Str"");
  setDaemon(true);
  this.sorter=sorter;
  this.keyPositions=keyPositions;
  this.keyClasses=keyClasses;
  this.stub=stub;
  this.output=output;
  this.running=true;
}",0.9688888888888888
55794,"@SuppressWarnings(""String_Node_Str"") private final <K extends Key,V extends Value>RecordReader<KeyValuePair<K,V>> getReader1(){
  return (RecordReader<KeyValuePair<K,V>>)this.reader1;
}","@SuppressWarnings(""String_Node_Str"") private final <K extends Key,V extends Value>Reader<KeyValuePair<K,V>> getReader1(){
  return (Reader<KeyValuePair<K,V>>)this.reader1;
}",0.9664804469273744
55795,"@SuppressWarnings(""String_Node_Str"") private final <K extends Key,V extends Value>RecordReader<KeyValuePair<K,V>> getReader2(){
  return (RecordReader<KeyValuePair<K,V>>)this.reader2;
}","@SuppressWarnings(""String_Node_Str"") private final <K extends Key,V extends Value>Reader<KeyValuePair<K,V>> getReader2(){
  return (Reader<KeyValuePair<K,V>>)this.reader2;
}",0.9664804469273744
55796,"/** 
 * Returns a CoGroupTaskIterator according to the specified local strategy. The iterator is typed according to the given classes.
 * @param < K > The type of the input key.
 * @param < V1 > The type of the first input's value.
 * @param < V2 > The type of the second input's value.
 * @param ikClass The class of the input key.
 * @param iv1Class The class of the first input's value.
 * @param iv2Class The class of the second input's value.
 * @return The iterator implementation for the given local strategy.
 * @throws IllegalConfigurationException Thrown if the local strategy is not supported.
 */
private <K extends Key,V1 extends Value,V2 extends Value>CoGroupTaskIterator<K,V1,V2> getIterator(Class<K> ikClass,Class<V1> iv1Class,Class<V2> iv2Class){
  final MemoryManager memoryManager=getEnvironment().getMemoryManager();
  final IOManager ioManager=getEnvironment().getIOManager();
  RecordReader<KeyValuePair<K,V1>> reader1=getReader1();
  RecordReader<KeyValuePair<K,V2>> reader2=getReader2();
switch (this.config.getLocalStrategy()) {
case SORT_BOTH_MERGE:
    return new SortMergeCoGroupIterator<K,V1,V2>(memoryManager,ioManager,reader1,reader2,ikClass,iv1Class,iv2Class,this.availableMemory,this.maxFileHandles,this.spillThreshold,this.config.getLocalStrategy(),this);
case SORT_FIRST_MERGE:
  return new SortMergeCoGroupIterator<K,V1,V2>(memoryManager,ioManager,reader1,reader2,ikClass,iv1Class,iv2Class,this.availableMemory,this.maxFileHandles,this.spillThreshold,this.config.getLocalStrategy(),this);
case SORT_SECOND_MERGE:
return new SortMergeCoGroupIterator<K,V1,V2>(memoryManager,ioManager,reader1,reader2,ikClass,iv1Class,iv2Class,this.availableMemory,this.maxFileHandles,this.spillThreshold,this.config.getLocalStrategy(),this);
case MERGE:
return new SortMergeCoGroupIterator<K,V1,V2>(memoryManager,ioManager,reader1,reader2,ikClass,iv1Class,iv2Class,this.availableMemory,this.maxFileHandles,this.spillThreshold,this.config.getLocalStrategy(),this);
default :
throw new RuntimeException(""String_Node_Str"" + this.config.getLocalStrategy());
}
}","/** 
 * Returns a CoGroupTaskIterator according to the specified local strategy. The iterator is typed according to the given classes.
 * @param < K > The type of the input key.
 * @param < V1 > The type of the first input's value.
 * @param < V2 > The type of the second input's value.
 * @param ikClass The class of the input key.
 * @param iv1Class The class of the first input's value.
 * @param iv2Class The class of the second input's value.
 * @return The iterator implementation for the given local strategy.
 * @throws IllegalConfigurationException Thrown if the local strategy is not supported.
 */
private <K extends Key,V1 extends Value,V2 extends Value>CoGroupTaskIterator<K,V1,V2> getIterator(Class<K> ikClass,Class<V1> iv1Class,Class<V2> iv2Class){
  final MemoryManager memoryManager=getEnvironment().getMemoryManager();
  final IOManager ioManager=getEnvironment().getIOManager();
  Reader<KeyValuePair<K,V1>> reader1=getReader1();
  Reader<KeyValuePair<K,V2>> reader2=getReader2();
switch (this.config.getLocalStrategy()) {
case SORT_BOTH_MERGE:
    return new SortMergeCoGroupIterator<K,V1,V2>(memoryManager,ioManager,reader1,reader2,ikClass,iv1Class,iv2Class,this.availableMemory,this.maxFileHandles,this.spillThreshold,this.config.getLocalStrategy(),this);
case SORT_FIRST_MERGE:
  return new SortMergeCoGroupIterator<K,V1,V2>(memoryManager,ioManager,reader1,reader2,ikClass,iv1Class,iv2Class,this.availableMemory,this.maxFileHandles,this.spillThreshold,this.config.getLocalStrategy(),this);
case SORT_SECOND_MERGE:
return new SortMergeCoGroupIterator<K,V1,V2>(memoryManager,ioManager,reader1,reader2,ikClass,iv1Class,iv2Class,this.availableMemory,this.maxFileHandles,this.spillThreshold,this.config.getLocalStrategy(),this);
case MERGE:
return new SortMergeCoGroupIterator<K,V1,V2>(memoryManager,ioManager,reader1,reader2,ikClass,iv1Class,iv2Class,this.availableMemory,this.maxFileHandles,this.spillThreshold,this.config.getLocalStrategy(),this);
default :
throw new RuntimeException(""String_Node_Str"" + this.config.getLocalStrategy());
}
}",0.9970986460348162
55797,"void shareInstancesWith(final ExecutionGroupVertex groupVertex) throws GraphConversionException {
  if (userDefinedVertexToShareInstancesWith && this.vertexToShareInstancesWith != null) {
    throw new GraphConversionException(""String_Node_Str"");
  }
  if (groupVertex == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  final ExecutionGroupVertex oldVertex=this.vertexToShareInstancesWith.getAndSet(groupVertex);
  if (oldVertex != null) {
    oldVertex.removeFromVerticesSharingInstances(this);
  }
  groupVertex.addToVerticesSharingInstances(this);
  reassignInstances();
  this.executionGraph.repairInstanceAssignment();
}","void shareInstancesWith(final ExecutionGroupVertex groupVertex) throws GraphConversionException {
  if (userDefinedVertexToShareInstancesWith && this.vertexToShareInstancesWith.get() != null) {
    throw new GraphConversionException(""String_Node_Str"");
  }
  if (groupVertex == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  final ExecutionGroupVertex oldVertex=this.vertexToShareInstancesWith.getAndSet(groupVertex);
  if (oldVertex != null) {
    oldVertex.removeFromVerticesSharingInstances(this);
  }
  groupVertex.addToVerticesSharingInstances(this);
  reassignInstances();
  this.executionGraph.repairInstanceAssignment();
}",0.9954058192955588
55798,"private List<AllocatedResource> collectAvailableResources(){
  List<AllocatedResource> availableResources;
  if (this.vertexToShareInstancesWith != null) {
    availableResources=this.vertexToShareInstancesWith.get().collectAvailableResources();
  }
 else {
    availableResources=new ArrayList<AllocatedResource>();
synchronized (this.groupMembers) {
      final Iterator<ExecutionVertex> it=this.groupMembers.iterator();
      while (it.hasNext()) {
        final ExecutionVertex vertex=it.next();
        final AllocatedResource allocatedResource=vertex.getAllocatedResource();
        if (allocatedResource != null) {
          if (!availableResources.contains(allocatedResource)) {
            availableResources.add(allocatedResource);
          }
        }
      }
    }
  }
  return availableResources;
}","private List<AllocatedResource> collectAvailableResources(){
  List<AllocatedResource> availableResources;
  if (this.vertexToShareInstancesWith.get() != null) {
    availableResources=this.vertexToShareInstancesWith.get().collectAvailableResources();
  }
 else {
    availableResources=new ArrayList<AllocatedResource>();
synchronized (this.groupMembers) {
      final Iterator<ExecutionVertex> it=this.groupMembers.iterator();
      while (it.hasNext()) {
        final ExecutionVertex vertex=it.next();
        final AllocatedResource allocatedResource=vertex.getAllocatedResource();
        if (allocatedResource != null) {
          if (!availableResources.contains(allocatedResource)) {
            availableResources.add(allocatedResource);
          }
        }
      }
    }
  }
  return availableResources;
}",0.996319018404908
55799,"/** 
 * This method step over all inputs recursively and combines all alternatives per input with all other alternative of all other inputs.
 * @param inPlans		all alternative plans for all incoming connections (which are unioned)
 * @param predList		list of currently chosen alternative plans (has one entry for each incoming connection)[this list is build up recursively within the method]
 * @param estimator		the cost estimator
 * @param alternativeSubPlans	all generated alternative for this node
 */
@SuppressWarnings(""String_Node_Str"") final protected void getAlternativeSubPlanCombinationsRecursively(List<? extends OptimizerNode>[] inPlans,ArrayList<OptimizerNode> predList,List<List<OptimizerNode>> alternativeSubPlans){
  final int inputNumberToProcess=predList.size();
  final int numberOfAlternatives=inPlans[inputNumberToProcess].size();
  for (int i=0; i < numberOfAlternatives; ++i) {
    predList.add(inPlans[inputNumberToProcess].get(i));
    if (inputNumberToProcess + 1 == inPlans.length) {
      alternativeSubPlans.add(predList);
      predList=(ArrayList<OptimizerNode>)predList.clone();
    }
 else {
      getAlternativeSubPlanCombinationsRecursively(inPlans,predList,alternativeSubPlans);
    }
    predList.remove(inputNumberToProcess);
  }
}","/** 
 * This method step over all inputs recursively and combines all alternatives per input with all other alternative of all other inputs.
 * @param inPlans		all alternative plans for all incoming connections (which are unioned)
 * @param predList		list of currently chosen alternative plans (has one entry for each incoming connection)[this list is build up recursively within the method]
 * @param estimator		the cost estimator
 * @param alternativeSubPlans	all generated alternative for this node
 */
@SuppressWarnings(""String_Node_Str"") final protected void getAlternativeSubPlanCombinationsRecursively(List<? extends OptimizerNode>[] inPlans,ArrayList<OptimizerNode> predList,List<List<OptimizerNode>> alternativeSubPlans){
  final int inputNumberToProcess=predList.size();
  final int numberOfAlternatives=inPlans[inputNumberToProcess].size();
  for (int i=0; i < numberOfAlternatives; ++i) {
    predList.add(inPlans[inputNumberToProcess].get(i));
    if (inputNumberToProcess + 1 == inPlans.length) {
      alternativeSubPlans.add((ArrayList<OptimizerNode>)predList.clone());
    }
 else {
      getAlternativeSubPlanCombinationsRecursively(inPlans,predList,alternativeSubPlans);
    }
    predList.remove(inputNumberToProcess);
  }
}",0.9892558694787108
55800,"/** 
 * Copy constructor to create a copy of a node with different predecessors. The predecessors is assumed to be of the same type as in the template node and merely copies with different strategies, as they are created in the process of the plan enumeration.
 * @param template The node to create a copy of.
 * @param pred1 The new predecessor for the first input.
 * @param pred2 The new predecessor for the second input.
 * @param conn1 The old connection of the first input to copy properties from.
 * @param conn2 The old connection of the second input to copy properties from.
 * @param globalProps The global properties of this copy.
 * @param localProps The local properties of this copy.
 */
protected TwoInputNode(TwoInputNode template,List<OptimizerNode> pred1,List<OptimizerNode> pred2,List<PactConnection> conn1,List<PactConnection> conn2,GlobalProperties globalProps,LocalProperties localProps){
  super(template,globalProps,localProps);
  this.inputs=new ArrayList<List<PactConnection>>(2);
  int i=0;
  for (  PactConnection c : conn1) {
    PactConnection cc=new PactConnection(c,pred1.get(i++),this);
    this.input1.add(cc);
  }
  this.inputs.add(this.input1);
  i=0;
  for (  PactConnection c : conn2) {
    PactConnection cc=new PactConnection(c,pred2.get(i++),this);
    this.input2.add(cc);
  }
  this.inputs.add(this.input2);
  if (template.openBranches != null) {
    if (this.branchPlan == null) {
      this.branchPlan=new HashMap<OptimizerNode,OptimizerNode>(8);
    }
    Iterator<OptimizerNode> it1=pred1.iterator();
    Iterator<OptimizerNode> it2=pred2.iterator();
    for (    UnclosedBranchDescriptor uc : template.openBranches) {
      OptimizerNode brancher=uc.branchingNode;
      OptimizerNode selectedCandidate=null;
      if (it1.hasNext()) {
        OptimizerNode n=it1.next();
        if (n.branchPlan != null) {
          selectedCandidate=n.branchPlan.get(brancher);
        }
      }
      if (selectedCandidate == null && it2.hasNext()) {
        OptimizerNode n=it2.next();
        if (n.branchPlan != null) {
          selectedCandidate=n.branchPlan.get(brancher);
        }
      }
      if (selectedCandidate == null) {
        throw new CompilerException(""String_Node_Str"");
      }
      this.branchPlan.put(brancher,selectedCandidate);
    }
  }
}","/** 
 * Copy constructor to create a copy of a node with different predecessors. The predecessors is assumed to be of the same type as in the template node and merely copies with different strategies, as they are created in the process of the plan enumeration.
 * @param template The node to create a copy of.
 * @param pred1 The new predecessor for the first input.
 * @param pred2 The new predecessor for the second input.
 * @param conn1 The old connection of the first input to copy properties from.
 * @param conn2 The old connection of the second input to copy properties from.
 * @param globalProps The global properties of this copy.
 * @param localProps The local properties of this copy.
 */
protected TwoInputNode(TwoInputNode template,List<OptimizerNode> pred1,List<OptimizerNode> pred2,List<PactConnection> conn1,List<PactConnection> conn2,GlobalProperties globalProps,LocalProperties localProps){
  super(template,globalProps,localProps);
  this.inputs=new ArrayList<List<PactConnection>>(2);
  int i=0;
  if (pred1 != null) {
    for (    PactConnection c : conn1) {
      PactConnection cc=new PactConnection(c,pred1.get(i++),this);
      this.input1.add(cc);
    }
    this.inputs.add(this.input1);
  }
  if (pred2 != null) {
    i=0;
    for (    PactConnection c : conn2) {
      PactConnection cc=new PactConnection(c,pred2.get(i++),this);
      this.input2.add(cc);
    }
    this.inputs.add(this.input2);
  }
  if (template.openBranches != null) {
    if (this.branchPlan == null) {
      this.branchPlan=new HashMap<OptimizerNode,OptimizerNode>(8);
    }
    for (    UnclosedBranchDescriptor uc : template.openBranches) {
      OptimizerNode brancher=uc.branchingNode;
      OptimizerNode selectedCandidate=null;
      if (pred1 != null) {
        Iterator<OptimizerNode> it1=pred1.iterator();
        while (it1.hasNext()) {
          OptimizerNode n=it1.next();
          if (n.branchPlan != null) {
            selectedCandidate=n.branchPlan.get(brancher);
            this.branchPlan.put(brancher,selectedCandidate);
          }
        }
      }
      if (selectedCandidate == null && pred2 != null) {
        Iterator<OptimizerNode> it2=pred2.iterator();
        while (it2.hasNext()) {
          OptimizerNode n=it2.next();
          if (n.branchPlan != null) {
            selectedCandidate=n.branchPlan.get(brancher);
            this.branchPlan.put(brancher,selectedCandidate);
          }
        }
      }
      if (selectedCandidate == null) {
        throw new CompilerException(""String_Node_Str"");
      }
    }
  }
}",0.741610047354334
55801,"/** 
 * Implements the join between LineItem and Order table on the  order key. WHERE l_orderkey = o_orderkey Output Schema - 0:ORDERKEY, 1:SHIPPRIORITY, 2:EXTENDEDPRICE
 */
@Override public void match(PactRecord first,PactRecord second,Collector out){
  first.unionFields(second);
  out.collect(first);
}","/** 
 * Implements the join between LineItem and Order table on the  order key. WHERE l_orderkey = o_orderkey Output Schema - 0:ORDERKEY, 1:SHIPPRIORITY, 2:EXTENDEDPRICE
 */
@Override public void match(PactRecord first,PactRecord second,Collector out){
  first.setField(1,second.getField(1,PactString.class));
  out.collect(first);
}",0.9184952978056428
55802,"/** 
 * {@inheritDoc}
 */
@Override public Plan getPlan(final String... args){
  int noSubtasks=(args.length > 0 ? Integer.parseInt(args[0]) : 1);
  String ordersPath=(args.length > 1 ? args[1] : ""String_Node_Str"");
  String lineitemsPath=(args.length > 2 ? args[2] : ""String_Node_Str"");
  String output=(args.length > 3 ? args[3] : ""String_Node_Str"");
  FileDataSource orders=new FileDataSource(NewTupleInFormat.class,ordersPath,""String_Node_Str"");
  orders.setParameter(NewTupleInFormat.RECORD_DELIMITER,""String_Node_Str"");
  orders.getCompilerHints().setAvgNumValuesPerKey(1);
  FileDataSource lineitems=new FileDataSource(NewTupleInFormat.class,lineitemsPath,""String_Node_Str"");
  lineitems.setParameter(NewTupleInFormat.RECORD_DELIMITER,""String_Node_Str"");
  lineitems.getCompilerHints().setAvgNumValuesPerKey(4);
  MapContract filterO=new MapContract(FilterO.class,orders,""String_Node_Str"");
  filterO.setParameter(""String_Node_Str"",1993);
  filterO.setParameter(""String_Node_Str"",""String_Node_Str"");
  filterO.getCompilerHints().setAvgBytesPerRecord(16);
  filterO.getCompilerHints().setAvgRecordsEmittedPerStubCall(0.05f);
  filterO.getCompilerHints().setAvgNumValuesPerKey(1);
  MapContract projectLi=new MapContract(ProjectLi.class,lineitems,""String_Node_Str"");
  projectLi.getCompilerHints().setAvgBytesPerRecord(20);
  projectLi.getCompilerHints().setAvgRecordsEmittedPerStubCall(1.0f);
  projectLi.getCompilerHints().setAvgNumValuesPerKey(4);
  MatchContract joinLiO=new MatchContract(JoinLiO.class,PactLong.class,0,0,filterO,projectLi,""String_Node_Str"");
  joinLiO.getCompilerHints().setAvgBytesPerRecord(24);
  joinLiO.getCompilerHints().setAvgNumValuesPerKey(4);
  @SuppressWarnings(""String_Node_Str"") ReduceContract aggLiO=new ReduceContract(AggLiO.class,new Class[]{PactLong.class,PactString.class},new int[]{0,1},joinLiO,""String_Node_Str"");
  aggLiO.getCompilerHints().setAvgBytesPerRecord(30);
  aggLiO.getCompilerHints().setAvgRecordsEmittedPerStubCall(1.0f);
  aggLiO.getCompilerHints().setAvgNumValuesPerKey(1);
  FileDataSink result=new FileDataSink(RecordOutputFormat.class,output,aggLiO,""String_Node_Str"");
  result.getParameters().setString(RecordOutputFormat.RECORD_DELIMITER_PARAMETER,""String_Node_Str"");
  result.getParameters().setString(RecordOutputFormat.FIELD_DELIMITER_PARAMETER,""String_Node_Str"");
  result.getParameters().setInteger(RecordOutputFormat.NUM_FIELDS_PARAMETER,3);
  result.getParameters().setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 0,PactLong.class);
  result.getParameters().setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 1,PactString.class);
  result.getParameters().setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 2,PactDouble.class);
  Plan plan=new Plan(result,""String_Node_Str"");
  plan.setDefaultParallelism(noSubtasks);
  return plan;
}","/** 
 * {@inheritDoc}
 */
@Override public Plan getPlan(final String... args){
  int noSubtasks=(args.length > 0 ? Integer.parseInt(args[0]) : 1);
  String ordersPath=(args.length > 1 ? args[1] : ""String_Node_Str"");
  String lineitemsPath=(args.length > 2 ? args[2] : ""String_Node_Str"");
  String output=(args.length > 3 ? args[3] : ""String_Node_Str"");
  FileDataSource orders=new FileDataSource(NewTupleInFormat.class,ordersPath,""String_Node_Str"");
  orders.setParameter(NewTupleInFormat.RECORD_DELIMITER,""String_Node_Str"");
  orders.getCompilerHints().setAvgNumValuesPerKey(1);
  FileDataSource lineitems=new FileDataSource(NewTupleInFormat.class,lineitemsPath,""String_Node_Str"");
  lineitems.setParameter(NewTupleInFormat.RECORD_DELIMITER,""String_Node_Str"");
  lineitems.getCompilerHints().setAvgNumValuesPerKey(4);
  MapContract filterO=new MapContract(FilterO.class,orders,""String_Node_Str"");
  filterO.setParameter(YEAR_FILTER,1993);
  filterO.setParameter(PRIO_FILTER,""String_Node_Str"");
  filterO.getCompilerHints().setAvgBytesPerRecord(16);
  filterO.getCompilerHints().setAvgRecordsEmittedPerStubCall(0.05f);
  filterO.getCompilerHints().setAvgNumValuesPerKey(1);
  MapContract projectLi=new MapContract(ProjectLi.class,lineitems,""String_Node_Str"");
  projectLi.getCompilerHints().setAvgBytesPerRecord(20);
  projectLi.getCompilerHints().setAvgRecordsEmittedPerStubCall(1.0f);
  projectLi.getCompilerHints().setAvgNumValuesPerKey(4);
  MatchContract joinLiO=new MatchContract(JoinLiO.class,PactLong.class,0,0,filterO,projectLi,""String_Node_Str"");
  joinLiO.getCompilerHints().setAvgBytesPerRecord(24);
  joinLiO.getCompilerHints().setAvgNumValuesPerKey(4);
  @SuppressWarnings(""String_Node_Str"") ReduceContract aggLiO=new ReduceContract(AggLiO.class,new Class[]{PactLong.class,PactString.class},new int[]{0,1},joinLiO,""String_Node_Str"");
  aggLiO.getCompilerHints().setAvgBytesPerRecord(30);
  aggLiO.getCompilerHints().setAvgRecordsEmittedPerStubCall(1.0f);
  aggLiO.getCompilerHints().setAvgNumValuesPerKey(1);
  FileDataSink result=new FileDataSink(RecordOutputFormat.class,output,aggLiO,""String_Node_Str"");
  result.getParameters().setString(RecordOutputFormat.RECORD_DELIMITER_PARAMETER,""String_Node_Str"");
  result.getParameters().setString(RecordOutputFormat.FIELD_DELIMITER_PARAMETER,""String_Node_Str"");
  result.getParameters().setInteger(RecordOutputFormat.NUM_FIELDS_PARAMETER,3);
  result.getParameters().setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 0,PactLong.class);
  result.getParameters().setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 1,PactString.class);
  result.getParameters().setClass(RecordOutputFormat.FIELD_TYPE_PARAMETER_PREFIX + 2,PactDouble.class);
  Plan plan=new Plan(result,""String_Node_Str"");
  plan.setDefaultParallelism(noSubtasks);
  return plan;
}",0.990084985835694
55803,"@Override public int serializeRecord(PactRecord rec,byte[] target) throws Exception {
  Tuple tuple=rec.getField(0,Tuple.class);
  String tupleStr=tuple.toString();
  byte[] tupleBytes=tupleStr.getBytes();
  if (target.length >= tupleBytes.length) {
    System.arraycopy(tupleBytes,0,target,0,tupleBytes.length);
    return tupleBytes.length;
  }
 else {
    return -1 * tupleBytes.length;
  }
}","@Override public int serializeRecord(PactRecord rec,byte[] target) throws Exception {
  String string=rec.getField(0,PactString.class).toString();
  byte[] stringBytes=string.getBytes();
  Tuple tuple=rec.getField(1,Tuple.class);
  String tupleStr=tuple.toString();
  byte[] tupleBytes=tupleStr.getBytes();
  int totalLength=stringBytes.length + 1 + tupleBytes.length;
  if (target.length >= totalLength) {
    System.arraycopy(stringBytes,0,target,0,stringBytes.length);
    target[stringBytes.length]='|';
    System.arraycopy(tupleBytes,0,target,stringBytes.length + 1,tupleBytes.length);
    return totalLength;
  }
 else {
    return -1 * totalLength;
  }
}",0.467360454115421
55804,"public void setContents(byte[] bytes,int offset,int len,char delimiter){
  if (this.bytes == null || this.bytes.length < len) {
    this.bytes=new byte[len];
  }
  System.arraycopy(bytes,offset,this.bytes,0,len);
  int readPos=offset;
  if (this.offsets == null) {
    this.offsets=new short[4];
  }
  int col=1;
  int startPos=readPos;
  while (readPos < offset + len) {
    if (bytes[readPos++] == delimiter) {
      if (offsets.length <= col) {
        this.offsets=new short[this.offsets.length * 2];
      }
      this.offsets[col++]=(short)(readPos - startPos);
    }
  }
  this.numCols=col - 1;
}","public void setContents(byte[] bytes,int offset,int len,char delimiter){
  if (this.bytes == null || this.bytes.length < len) {
    this.bytes=new byte[len];
  }
  System.arraycopy(bytes,offset,this.bytes,0,len);
  int readPos=offset;
  if (this.offsets == null) {
    this.offsets=new short[4];
  }
  int col=1;
  int startPos=readPos;
  while (readPos < offset + len) {
    if (bytes[readPos++] == delimiter) {
      if (offsets.length <= col) {
        short newOffsets[]=new short[this.offsets.length * 2];
        System.arraycopy(this.offsets,0,newOffsets,0,this.offsets.length);
        this.offsets=newOffsets;
      }
      this.offsets[col++]=(short)(readPos - startPos);
    }
  }
  this.numCols=col - 1;
}",0.8954545454545455
55805,"/** 
 * {@inheritDoc}
 */
@Override protected int getTimeout(){
  return 30000;
}","/** 
 * {@inheritDoc}
 */
@Override protected int getTimeout(){
  return 30;
}",0.981132075471698
55806,"@Override public void reduce(Iterator<PactRecord> records,Collector out) throws Exception {
  long count=0;
  PactRecord rec=null;
  while (records.hasNext()) {
    rec=records.next();
    count++;
  }
  if (rec != null) {
    Tuple tuple=rec.getField(1,Tuple.class);
    tuple.addAttribute(""String_Node_Str"" + count);
    rec.setField(1,tuple);
  }
  out.collect(rec);
}","@Override public void reduce(Iterator<PactRecord> records,Collector out) throws Exception {
  long count=0;
  PactRecord rec=null;
  while (records.hasNext()) {
    rec=records.next();
    count++;
  }
  if (rec != null) {
    Tuple tuple=new Tuple();
    tuple.addAttribute(""String_Node_Str"" + count);
    rec.setField(1,tuple);
  }
  out.collect(rec);
}",0.9641873278236914
55807,"/** 
 * Join together parts and orderedParts by matching partkey and suppkey. Output Schema: Key: suppkey Value: (amount, year)
 */
@Override public void match(PactRecord value1,PactRecord value2,Collector out) throws Exception {
  value1.getField(0,partAndSupplierKey);
  value1.getField(1,supplyCostStr);
  value2.getField(1,ordersValue);
  PactInteger year=new PactInteger(Integer.parseInt(ordersValue.getStringValueAt(0)));
  float quantity=Float.parseFloat(ordersValue.getStringValueAt(1));
  float price=Float.parseFloat(ordersValue.getStringValueAt(2));
  float supplyCost=Float.parseFloat(supplyCostStr.toString());
  float amount=price - supplyCost * quantity;
  value1.setField(0,partAndSupplierKey);
  value1.setField(1,new StringIntPair(new PactString(""String_Node_Str"" + amount),year));
  out.collect(value1);
}","/** 
 * Join together parts and orderedParts by matching partkey and suppkey. Output Schema: Key: suppkey Value: (amount, year)
 */
@Override public void match(PactRecord value1,PactRecord value2,Collector out) throws Exception {
  value1.getField(0,partAndSupplierKey);
  value1.getField(1,supplyCostStr);
  value2.getField(1,ordersValue);
  PactInteger year=new PactInteger(Integer.parseInt(ordersValue.getStringValueAt(0)));
  float quantity=Float.parseFloat(ordersValue.getStringValueAt(1));
  float price=Float.parseFloat(ordersValue.getStringValueAt(2));
  float supplyCost=Float.parseFloat(supplyCostStr.toString());
  float amount=price - supplyCost * quantity;
  value1.setField(0,partAndSupplierKey.getSecond());
  value1.setField(1,new StringIntPair(new PactString(""String_Node_Str"" + amount),year));
  out.collect(value1);
}",0.9927710843373494
55808,"/** 
 * Project ""partsupp"". Output Schema: Key: partkey Value: (suppkey, supplycost)
 */
@Override public void map(PactRecord record,Collector out) throws Exception {
  record.getField(1,inputTuple);
  inputTuple.project((0 << 0) | (1 << 1) | (0 << 2)| (1 << 3)| (0 << 4));
  out.collect(record);
}","/** 
 * Project ""partsupp"". Output Schema: Key: partkey Value: (suppkey, supplycost)
 */
@Override public void map(PactRecord record,Collector out) throws Exception {
  record.getField(1,inputTuple);
  inputTuple.project((0 << 0) | (1 << 1) | (0 << 2)| (1 << 3)| (0 << 4));
  record.setField(1,inputTuple);
  out.collect(record);
}",0.890302066772655
55809,"/** 
 * Project ""supplier"". Output Schema: Key: nationkey Value: suppkey
 */
@Override public void map(PactRecord record,Collector out) throws Exception {
  record.getField(0,suppKey);
  record.getField(1,inputTuple);
  PactInteger nationKey=new PactInteger(Integer.parseInt(inputTuple.getStringValueAt(3)));
  record.setField(0,nationKey);
  record.setField(1,suppKey);
}","/** 
 * Project ""supplier"". Output Schema: Key: nationkey Value: suppkey
 */
@Override public void map(PactRecord record,Collector out) throws Exception {
  record.getField(0,suppKey);
  record.getField(1,inputTuple);
  PactInteger nationKey=new PactInteger(Integer.parseInt(inputTuple.getStringValueAt(3)));
  record.setField(0,nationKey);
  record.setField(1,suppKey);
  out.collect(record);
}",0.970013037809648
55810,"@Override public void writeRecord(PactRecord record) throws IOException {
  int numFields=record.getNumFields();
  for (int i=0; i < numFields; i++) {
    buffer.append(record.getField(0,PactString.class).getValue());
    char delim=(i == numFields - 1) ? '\n' : '|';
    buffer.append(delim);
  }
  byte[] bytes=this.buffer.toString().getBytes();
  this.stream.write(bytes);
}","@Override public void writeRecord(PactRecord record) throws IOException {
  buffer.setLength(0);
  buffer.append(record.getField(1,PactInteger.class).toString());
  buffer.append('|');
  buffer.append(record.getField(0,PactString.class).toString());
  buffer.append('|');
  buffer.append(record.getField(2,PactInteger.class).toString());
  buffer.append('|');
  buffer.append('\n');
  byte[] bytes=this.buffer.toString().getBytes();
  this.stream.write(bytes);
}",0.5292014302741359
55811,"/** 
 * Updates the binary representation of the data, such that it reflects the state of the currently stored fields. If the binary representation is already up to date, nothing happens. Otherwise, this function triggers the modified fields to serialize themselves into the records buffer and afterwards updates the offset table.
 */
public void updateBinaryRepresenation(){
  final int firstModified=this.firstModifiedPos;
  final int numFields=this.numFields;
  if (firstModified >= numFields) {
    return;
  }
  final int[] offsets=this.offsets;
  if (this.serializer == null) {
    this.serializer=new InternalDeSerializer();
  }
  final InternalDeSerializer serializer=this.serializer;
  int offset=firstModified <= 0 ? 0 : this.offsets[firstModified - 1] + this.lengths[firstModified - 1];
  serializer.position=offset;
  if (this.lastUnmodifiedPos < firstModified) {
    serializer.memory=this.binaryData == null ? new byte[numFields * DEFAULT_FIELD_LEN] : this.binaryData;
    try {
      for (int i=firstModified; i < numFields; i++) {
        if (offsets[i] == NULL_INDICATOR_OFFSET)         continue;
        offsets[i]=offset;
        this.fields[i].write(serializer);
        int newOffset=serializer.position;
        this.lengths[i]=newOffset - offset;
        offset=newOffset;
      }
    }
 catch (    Exception e) {
      throw new RuntimeException(""String_Node_Str"" + e.getMessage());
    }
  }
 else {
    serializer.memory=this.serializationSwitchBuffer == null ? new byte[numFields * DEFAULT_FIELD_LEN] : this.serializationSwitchBuffer;
    if (offset > 0 & this.binaryData != null) {
      System.arraycopy(this.binaryData,0,serializer.memory,0,offset);
    }
    try {
      for (int i=firstModified; i < numFields; i++) {
        final int co=offsets[i];
        if (co == NULL_INDICATOR_OFFSET)         continue;
        offsets[i]=offset;
        if (co == MODIFIED_INDICATOR_OFFSET)         this.fields[i].write(serializer);
 else         serializer.write(this.binaryData,co,this.lengths[i]);
        this.lengths[i]=serializer.position - offset;
        offset=serializer.position;
      }
    }
 catch (    Exception e) {
      throw new RuntimeException(""String_Node_Str"" + e.getMessage());
    }
    this.serializationSwitchBuffer=this.binaryData;
    this.binaryData=serializer.memory;
  }
  try {
    if (numFields <= 8) {
      int mask=0;
      for (int i=numFields - 1; i > 0; i--) {
        mask<<=1;
        if (offsets[i] != NULL_INDICATOR_OFFSET) {
          serializer.writeValLenIntBackwards(offsets[i]);
          mask|=0x1;
        }
      }
      mask<<=1;
      mask|=(offsets[0] != NULL_INDICATOR_OFFSET) ? 0x1 : 0x0;
      serializer.writeByte(mask);
    }
 else {
      for (int i=numFields - 1; i > 0; i--) {
        if (offsets[i] != NULL_INDICATOR_OFFSET) {
          serializer.writeValLenIntBackwards(offsets[i]);
        }
      }
      int col=numFields - 1;
      int mask=0;
      for (int i=numFields & 0x7; i >= 0; i--, col--) {
        mask<<=1;
        mask|=(offsets[col] != NULL_INDICATOR_OFFSET) ? 0x1 : 0x0;
      }
      serializer.writeByte(mask);
      for (int i=numFields >>> 3; i >= 0; i--) {
        mask=0;
        for (int k=0; k < 8; k++, col--) {
          mask<<=1;
          mask|=(offsets[col] != NULL_INDICATOR_OFFSET) ? 0x1 : 0x0;
        }
        serializer.writeByte(mask);
      }
    }
    serializer.writeValLenIntBackwards(numFields);
  }
 catch (  Exception e) {
    throw new RuntimeException(""String_Node_Str"" + e.getMessage(),e);
  }
  this.binaryData=serializer.memory;
  this.binaryLen=serializer.position;
  this.firstModifiedPos=Integer.MAX_VALUE;
  this.lastUnmodifiedPos=numFields - 1;
}","/** 
 * Updates the binary representation of the data, such that it reflects the state of the currently stored fields. If the binary representation is already up to date, nothing happens. Otherwise, this function triggers the modified fields to serialize themselves into the records buffer and afterwards updates the offset table.
 */
public void updateBinaryRepresenation(){
  if (!this.modified)   return;
  final int firstModified=this.firstModifiedPos;
  final int numFields=this.numFields;
  final int[] offsets=this.offsets;
  if (this.serializer == null) {
    this.serializer=new InternalDeSerializer();
  }
  final InternalDeSerializer serializer=this.serializer;
  if (numFields > 0) {
    int offset=firstModified <= 0 ? 0 : this.offsets[firstModified - 1] + this.lengths[firstModified - 1];
    serializer.position=offset;
    if (firstModified > 0) {
      serializer.memory=this.binaryData == null ? new byte[numFields * DEFAULT_FIELD_LEN] : this.binaryData;
      try {
        for (int i=firstModified; i < numFields; i++) {
          if (offsets[i] == NULL_INDICATOR_OFFSET)           continue;
          offsets[i]=offset;
          this.fields[i].write(serializer);
          int newOffset=serializer.position;
          this.lengths[i]=newOffset - offset;
          offset=newOffset;
        }
      }
 catch (      Exception e) {
        throw new RuntimeException(""String_Node_Str"" + e.getMessage());
      }
    }
 else {
      serializer.memory=this.serializationSwitchBuffer == null ? new byte[numFields * DEFAULT_FIELD_LEN] : this.serializationSwitchBuffer;
      if (offset > 0 & this.binaryData != null) {
        System.arraycopy(this.binaryData,0,serializer.memory,0,offset);
      }
      try {
        for (int i=firstModified; i < numFields; i++) {
          final int co=offsets[i];
          if (co == NULL_INDICATOR_OFFSET)           continue;
          offsets[i]=offset;
          if (co == MODIFIED_INDICATOR_OFFSET)           this.fields[i].write(serializer);
 else           serializer.write(this.binaryData,co,this.lengths[i]);
          this.lengths[i]=serializer.position - offset;
          offset=serializer.position;
        }
      }
 catch (      Exception e) {
        throw new RuntimeException(""String_Node_Str"" + e.getMessage());
      }
      this.serializationSwitchBuffer=this.binaryData;
      this.binaryData=serializer.memory;
    }
  }
  try {
    if (numFields <= 8) {
      int mask=0;
      for (int i=numFields - 1; i > 0; i--) {
        mask<<=1;
        if (offsets[i] != NULL_INDICATOR_OFFSET) {
          serializer.writeValLenIntBackwards(offsets[i]);
          mask|=0x1;
        }
      }
      mask<<=1;
      mask|=(offsets[0] != NULL_INDICATOR_OFFSET) ? 0x1 : 0x0;
      serializer.writeByte(mask);
    }
 else {
      for (int i=numFields - 1; i > 0; i--) {
        if (offsets[i] != NULL_INDICATOR_OFFSET) {
          serializer.writeValLenIntBackwards(offsets[i]);
        }
      }
      int col=numFields - 1;
      int mask=0;
      for (int i=numFields & 0x7; i >= 0; i--, col--) {
        mask<<=1;
        mask|=(offsets[col] != NULL_INDICATOR_OFFSET) ? 0x1 : 0x0;
      }
      serializer.writeByte(mask);
      for (int i=numFields >>> 3; i >= 0; i--) {
        mask=0;
        for (int k=0; k < 8; k++, col--) {
          mask<<=1;
          mask|=(offsets[col] != NULL_INDICATOR_OFFSET) ? 0x1 : 0x0;
        }
        serializer.writeByte(mask);
      }
    }
    serializer.writeValLenIntBackwards(numFields);
  }
 catch (  Exception e) {
    throw new RuntimeException(""String_Node_Str"" + e.getMessage(),e);
  }
  this.binaryData=serializer.memory;
  this.binaryLen=serializer.position;
  this.firstModifiedPos=Integer.MAX_VALUE;
  this.modified=false;
}",0.9627337548769004
55812,"/** 
 * @param target
 */
public void copyTo(PactRecord target){
  updateBinaryRepresenation();
  if (target.binaryData == null || target.binaryData.length < this.binaryLen) {
    target.binaryData=new byte[this.binaryLen];
  }
  if (target.offsets == null || target.offsets.length < this.numFields) {
    target.offsets=new int[this.numFields];
  }
  if (target.lengths == null || target.lengths.length < this.numFields) {
    target.lengths=new int[this.numFields];
  }
  if (target.fields == null || target.fields.length < this.numFields) {
    target.fields=new Value[this.numFields];
  }
  System.arraycopy(this.binaryData,0,target.binaryData,0,this.binaryLen);
  System.arraycopy(this.offsets,0,target.offsets,0,this.numFields);
  System.arraycopy(this.lengths,0,target.lengths,0,this.numFields);
  target.binaryLen=this.binaryLen;
  target.numFields=this.numFields;
  target.firstModifiedPos=Integer.MAX_VALUE;
  target.lastUnmodifiedPos=this.numFields - 1;
}","/** 
 * @param target
 */
public void copyTo(PactRecord target){
  updateBinaryRepresenation();
  if (target.binaryData == null || target.binaryData.length < this.binaryLen) {
    target.binaryData=new byte[this.binaryLen];
  }
  if (target.offsets == null || target.offsets.length < this.numFields) {
    target.offsets=new int[this.numFields];
  }
  if (target.lengths == null || target.lengths.length < this.numFields) {
    target.lengths=new int[this.numFields];
  }
  if (target.fields == null || target.fields.length < this.numFields) {
    target.fields=new Value[this.numFields];
  }
  System.arraycopy(this.binaryData,0,target.binaryData,0,this.binaryLen);
  System.arraycopy(this.offsets,0,target.offsets,0,this.numFields);
  System.arraycopy(this.lengths,0,target.lengths,0,this.numFields);
  target.binaryLen=this.binaryLen;
  target.numFields=this.numFields;
  target.firstModifiedPos=Integer.MAX_VALUE;
  target.modified=false;
}",0.9738219895287958
55813,"/** 
 * Sets the number of fields in the record. If the new number of fields is longer than the current number of fields, then null fields are appended. If the new number of fields is smaller than the current number of fields, then the last fields are truncated.
 * @param numFields The new number of fields.
 */
public void setNumFields(final int numFields){
  final int oldNumFields=this.numFields;
  if (numFields > oldNumFields) {
    makeSpace(numFields);
    for (int i=oldNumFields; i < numFields; i++) {
      this.offsets[i]=NULL_INDICATOR_OFFSET;
    }
  }
 else {
    if (this.lastUnmodifiedPos >= numFields)     this.lastUnmodifiedPos=numFields - 1;
    markModified(numFields);
  }
  this.numFields=numFields;
}","/** 
 * Sets the number of fields in the record. If the new number of fields is longer than the current number of fields, then null fields are appended. If the new number of fields is smaller than the current number of fields, then the last fields are truncated.
 * @param numFields The new number of fields.
 */
public void setNumFields(final int numFields){
  final int oldNumFields=this.numFields;
  if (numFields > oldNumFields) {
    makeSpace(numFields);
    for (int i=oldNumFields; i < numFields; i++) {
      this.offsets[i]=NULL_INDICATOR_OFFSET;
    }
  }
 else {
    markModified(numFields);
  }
  this.numFields=numFields;
}",0.9360764144011756
55814,"/** 
 * Clears the record. After this operation, the record will have zero fields.
 */
public void clear(){
  this.numFields=0;
  this.lastUnmodifiedPos=-1;
  this.firstModifiedPos=Integer.MAX_VALUE;
}","/** 
 * Clears the record. After this operation, the record will have zero fields.
 */
public void clear(){
  if (this.numFields > 0) {
    this.numFields=0;
    this.firstModifiedPos=Integer.MAX_VALUE;
    this.modified=true;
  }
}",0.8036951501154734
55815,"private final void markModified(int field){
  if (this.firstModifiedPos > field) {
    this.firstModifiedPos=field;
  }
  if (field == this.lastUnmodifiedPos) {
    this.lastUnmodifiedPos--;
  }
}","private final void markModified(int field){
  if (this.firstModifiedPos > field) {
    this.firstModifiedPos=field;
  }
  this.modified=true;
}",0.8259587020648967
55816,"private final void initFields(byte[] data,int begin,int len){
  int pos=begin + len - 2;
  int numFields=data[begin + len - 1];
  if (numFields >= MAX_BIT) {
    int shift=7;
    int curr;
    numFields=numFields & 0x7f;
    while ((curr=data[pos--]) >= MAX_BIT) {
      numFields|=(curr & 0x7f) << shift;
      shift+=7;
    }
    numFields|=curr << shift;
  }
  this.numFields=numFields;
  if (this.offsets == null || this.offsets.length < numFields) {
    this.offsets=new int[numFields];
  }
  if (this.fields == null || this.fields.length < numFields) {
    this.fields=new Value[numFields];
  }
  if (this.lengths == null || this.lengths.length < numFields) {
    this.lengths=new int[numFields];
  }
  final int beginMasks=pos;
  final int fieldsBy8=(numFields >>> 3) + ((numFields & 0x7) == 0 ? 0 : 1);
  pos=beginMasks - fieldsBy8;
  int lastNonNullField=-1;
  for (int field=0, chunk=0; chunk < fieldsBy8; chunk++) {
    int mask=data[beginMasks - chunk];
    for (int i=0; i < 8 && field < numFields; i++, field++) {
      if ((mask & 0x1) == 0x1) {
        if (lastNonNullField >= 0) {
          int start=data[pos--];
          if (start >= MAX_BIT) {
            int shift=7;
            int curr;
            start=start & 0x7f;
            while ((curr=data[pos--]) >= MAX_BIT) {
              start|=(curr & 0x7f) << shift;
              shift+=7;
            }
            start|=curr << shift;
          }
          this.offsets[field]=start + begin;
          this.lengths[lastNonNullField]=start + begin - this.offsets[lastNonNullField];
        }
 else {
          this.offsets[field]=begin;
        }
        lastNonNullField=field;
      }
 else {
        this.offsets[field]=NULL_INDICATOR_OFFSET;
      }
      mask>>=1;
    }
  }
  if (lastNonNullField >= 0) {
    this.lengths[lastNonNullField]=pos - this.offsets[lastNonNullField] + 1;
  }
  this.firstModifiedPos=Integer.MAX_VALUE;
  this.lastUnmodifiedPos=numFields - 1;
}","private final void initFields(byte[] data,int begin,int len){
  int pos=begin + len - 2;
  int numFields=data[begin + len - 1];
  if (numFields >= MAX_BIT) {
    int shift=7;
    int curr;
    numFields=numFields & 0x7f;
    while ((curr=data[pos--]) >= MAX_BIT) {
      numFields|=(curr & 0x7f) << shift;
      shift+=7;
    }
    numFields|=curr << shift;
  }
  this.numFields=numFields;
  if (this.offsets == null || this.offsets.length < numFields) {
    this.offsets=new int[numFields];
  }
  if (this.fields == null || this.fields.length < numFields) {
    this.fields=new Value[numFields];
  }
  if (this.lengths == null || this.lengths.length < numFields) {
    this.lengths=new int[numFields];
  }
  final int beginMasks=pos;
  final int fieldsBy8=(numFields >>> 3) + ((numFields & 0x7) == 0 ? 0 : 1);
  pos=beginMasks - fieldsBy8;
  int lastNonNullField=-1;
  for (int field=0, chunk=0; chunk < fieldsBy8; chunk++) {
    int mask=data[beginMasks - chunk];
    for (int i=0; i < 8 && field < numFields; i++, field++) {
      if ((mask & 0x1) == 0x1) {
        if (lastNonNullField >= 0) {
          int start=data[pos--];
          if (start >= MAX_BIT) {
            int shift=7;
            int curr;
            start=start & 0x7f;
            while ((curr=data[pos--]) >= MAX_BIT) {
              start|=(curr & 0x7f) << shift;
              shift+=7;
            }
            start|=curr << shift;
          }
          this.offsets[field]=start + begin;
          this.lengths[lastNonNullField]=start + begin - this.offsets[lastNonNullField];
        }
 else {
          this.offsets[field]=begin;
        }
        lastNonNullField=field;
      }
 else {
        this.offsets[field]=NULL_INDICATOR_OFFSET;
      }
      mask>>=1;
    }
  }
  if (lastNonNullField >= 0) {
    this.lengths[lastNonNullField]=pos - this.offsets[lastNonNullField] + 1;
  }
  this.firstModifiedPos=Integer.MAX_VALUE;
  this.modified=false;
}",0.9884289020313706
55817,"/** 
 * Checks which instance types and how many instances of these types are required to execute this stage of the job graph. The required instance types and the number of instances are collected in the given map. Note that this method does not clear the map before collecting the instances.
 * @param instanceRequestMap the map containing the instances types and the required number of instances of the respective type
 * @param executionState the execution state the considered vertices must be in
 */
public void collectRequiredInstanceTypes(final InstanceRequestMap instanceRequestMap,final ExecutionState executionState){
  final Set<AbstractInstance> collectedInstances=new HashSet<AbstractInstance>();
  for (int i=0; i < getNumberOfStageMembers(); i++) {
    final ExecutionGroupVertex groupVertex=getStageMember(i);
    for (int j=0; j < groupVertex.getCurrentNumberOfGroupMembers(); j++) {
      final ExecutionVertex vertex=groupVertex.getGroupMember(j);
      if (vertex.getExecutionState() == executionState) {
        final AbstractInstance instance=vertex.getAllocatedResource().getInstance();
        if (collectedInstances.contains(instance)) {
          continue;
        }
 else {
          collectedInstances.add(instance);
        }
        if (instance instanceof DummyInstance) {
          final InstanceType instanceType=instance.getType();
          int num=instanceRequestMap.getMaximumNumberOfInstances(instanceType);
          ++num;
          instanceRequestMap.setMaximumNumberOfInstances(instanceType,num);
          if (groupVertex.isInputVertex()) {
            num=instanceRequestMap.getMinimumNumberOfInstances(instanceType);
            ++num;
            instanceRequestMap.setMinimumNumberOfInstances(instanceType,num);
          }
        }
 else {
          LOG.debug(""String_Node_Str"" + vertex.getName() + ""String_Node_Str""+ vertex.getID()+ ""String_Node_Str"");
        }
      }
    }
  }
  final Iterator<Map.Entry<InstanceType,Integer>> it=instanceRequestMap.getMaximumIterator();
  while (it.hasNext()) {
    final Map.Entry<InstanceType,Integer> entry=it.next();
    if (instanceRequestMap.getMinimumNumberOfInstances(entry.getKey()) == 0) {
      instanceRequestMap.setMinimumNumberOfInstances(entry.getKey(),entry.getValue());
    }
  }
}","/** 
 * Checks which instance types and how many instances of these types are required to execute this stage of the job graph. The required instance types and the number of instances are collected in the given map. Note that this method does not clear the map before collecting the instances.
 * @param instanceRequestMap the map containing the instances types and the required number of instances of the respective type
 * @param executionState the execution state the considered vertices must be in
 */
public void collectRequiredInstanceTypes(final InstanceRequestMap instanceRequestMap,final ExecutionState executionState){
  final Set<AbstractInstance> collectedInstances=new HashSet<AbstractInstance>();
  final ExecutionGroupVertexIterator groupIt=new ExecutionGroupVertexIterator(this.getExecutionGraph(),true,this.stageNum);
  while (groupIt.hasNext()) {
    final ExecutionGroupVertex groupVertex=groupIt.next();
    System.out.println(""String_Node_Str"" + groupVertex.getName());
    for (int j=0; j < groupVertex.getCurrentNumberOfGroupMembers(); j++) {
      final ExecutionVertex vertex=groupVertex.getGroupMember(j);
      if (vertex.getExecutionState() == executionState) {
        final AbstractInstance instance=vertex.getAllocatedResource().getInstance();
        if (collectedInstances.contains(instance)) {
          continue;
        }
 else {
          collectedInstances.add(instance);
        }
        if (instance instanceof DummyInstance) {
          final InstanceType instanceType=instance.getType();
          int num=instanceRequestMap.getMaximumNumberOfInstances(instanceType);
          ++num;
          instanceRequestMap.setMaximumNumberOfInstances(instanceType,num);
          if (groupVertex.isInputVertex()) {
            num=instanceRequestMap.getMinimumNumberOfInstances(instanceType);
            ++num;
            instanceRequestMap.setMinimumNumberOfInstances(instanceType,num);
          }
        }
 else {
          LOG.debug(""String_Node_Str"" + vertex.getName() + ""String_Node_Str""+ vertex.getID()+ ""String_Node_Str"");
        }
      }
    }
  }
  final Iterator<Map.Entry<InstanceType,Integer>> it=instanceRequestMap.getMaximumIterator();
  while (it.hasNext()) {
    final Map.Entry<InstanceType,Integer> entry=it.next();
    if (instanceRequestMap.getMinimumNumberOfInstances(entry.getKey()) == 0) {
      instanceRequestMap.setMinimumNumberOfInstances(entry.getKey(),entry.getValue());
    }
  }
}",0.9252533783783784
55818,"private static final int readLengthIncludingLengthBytes(MemorySegment seg,List<MemorySegment> sources,int segmentNum,int segmentOffset){
  int lenBytes=1;
  if (seg.size() - segmentOffset > 5) {
    int val=seg.get(segmentOffset++) & 0xff;
    if (val >= MAX_BIT) {
      int shift=7;
      int curr;
      val=val & 0x7f;
      while ((curr=seg.get(segmentOffset++) & 0xff) >= MAX_BIT) {
        val|=(curr & 0x7f) << shift;
        shift+=7;
        lenBytes++;
      }
      val|=curr << shift;
    }
    return val + lenBytes;
  }
 else {
    int end=seg.size();
    int val=seg.get(segmentOffset++) & 0xff;
    if (segmentOffset == end) {
      segmentOffset=0;
      seg=sources.get(++segmentNum);
    }
    if (val >= MAX_BIT) {
      int shift=7;
      int curr;
      val=val & 0x7f;
      while ((curr=seg.get(segmentOffset++) & 0xff) >= MAX_BIT) {
        val|=(curr & 0x7f) << shift;
        shift+=7;
        lenBytes++;
        if (segmentOffset == end) {
          segmentOffset=0;
          seg=sources.get(++segmentNum);
        }
      }
      val|=curr << shift;
    }
    return val + lenBytes;
  }
}","private static final int readLengthIncludingLengthBytes(MemorySegment seg,List<MemorySegment> sources,int segmentNum,int segmentOffset){
  int lenBytes=1;
  if (seg.size() - segmentOffset > 5) {
    int val=seg.get(segmentOffset++) & 0xff;
    if (val >= MAX_BIT) {
      int shift=7;
      int curr;
      val=val & 0x7f;
      while ((curr=seg.get(segmentOffset++) & 0xff) >= MAX_BIT) {
        val|=(curr & 0x7f) << shift;
        shift+=7;
        lenBytes++;
      }
      val|=curr << shift;
      lenBytes++;
    }
    return val + lenBytes;
  }
 else {
    int end=seg.size();
    int val=seg.get(segmentOffset++) & 0xff;
    if (segmentOffset == end) {
      segmentOffset=0;
      seg=sources.get(++segmentNum);
    }
    if (val >= MAX_BIT) {
      int shift=7;
      int curr;
      val=val & 0x7f;
      while ((curr=seg.get(segmentOffset++) & 0xff) >= MAX_BIT) {
        val|=(curr & 0x7f) << shift;
        shift+=7;
        lenBytes++;
        if (segmentOffset == end) {
          segmentOffset=0;
          seg=sources.get(++segmentNum);
        }
      }
      val|=curr << shift;
    }
    return val + lenBytes;
  }
}",0.992028343666962
55819,"/** 
 * {@inheritDoc}
 */
@Override public void queueTransferEnvelope(final TransferEnvelope transferEnvelope){
  final int sequenceNumber=transferEnvelope.getSequenceNumber();
synchronized (this.queuedEnvelopes) {
    if (sequenceNumber <= this.lastReceivedEnvelope) {
      final Buffer buffer=transferEnvelope.getBuffer();
      if (buffer != null) {
        buffer.recycleBuffer();
      }
      return;
    }
    this.queuedEnvelopes.add(transferEnvelope);
    this.lastReceivedEnvelope=sequenceNumber;
  }
  this.byteBufferedInputChannel.checkForNetworkEvents();
}","/** 
 * {@inheritDoc}
 */
@Override public void queueTransferEnvelope(final TransferEnvelope transferEnvelope){
  final int sequenceNumber=transferEnvelope.getSequenceNumber();
synchronized (this.queuedEnvelopes) {
    if (sequenceNumber != (this.lastReceivedEnvelope + 1)) {
      final Buffer buffer=transferEnvelope.getBuffer();
      if (buffer != null) {
        buffer.recycleBuffer();
      }
      return;
    }
    this.queuedEnvelopes.add(transferEnvelope);
    this.lastReceivedEnvelope=sequenceNumber;
  }
  this.byteBufferedInputChannel.checkForNetworkEvents();
}",0.8115183246073299
55820,"@Override public void copyNormalizedKey(byte[] target,int offset,int len){
  if (len == 4) {
    target[offset]=(byte)((value >>> 24) & 0xff);
    target[offset + 1]=(byte)((value >>> 16) & 0xff);
    target[offset + 2]=(byte)((value >>> 8) & 0xff);
    target[offset + 3]=(byte)((value) & 0xff);
  }
 else   if (len < 4) {
    for (int i=0; len > 0; len--, i++) {
      target[offset + i]=(byte)((value >>> ((3 - i) << 3)) & 0xff);
    }
  }
 else {
    target[offset]=(byte)((value >>> 24) & 0xff);
    target[offset + 1]=(byte)((value >>> 16) & 0xff);
    target[offset + 2]=(byte)((value >>> 8) & 0xff);
    target[offset + 3]=(byte)((value) & 0xff);
    for (int i=4; i < len; i++) {
      target[offset + i]=0;
    }
  }
}","@Override public void copyNormalizedKey(byte[] target,int offset,int len){
  if (len == 4) {
    int highByte=((value >>> 24) & 0xff);
    highByte-=Byte.MIN_VALUE;
    target[offset]=(byte)highByte;
    target[offset + 1]=(byte)((value >>> 16) & 0xff);
    target[offset + 2]=(byte)((value >>> 8) & 0xff);
    target[offset + 3]=(byte)((value) & 0xff);
  }
 else   if (len <= 0) {
  }
 else   if (len < 4) {
    int highByte=((value >>> 24) & 0xff);
    highByte-=Byte.MIN_VALUE;
    target[offset]=(byte)highByte;
    len--;
    for (int i=1; len > 0; len--, i++) {
      target[offset + i]=(byte)((value >>> ((3 - i) << 3)) & 0xff);
    }
  }
 else {
    int highByte=((value >>> 24) & 0xff);
    highByte-=Byte.MIN_VALUE;
    target[offset]=(byte)highByte;
    target[offset + 1]=(byte)((value >>> 16) & 0xff);
    target[offset + 2]=(byte)((value >>> 8) & 0xff);
    target[offset + 3]=(byte)((value) & 0xff);
    for (int i=4; i < len; i++) {
      target[offset + i]=0;
    }
  }
}",0.7855477855477856
55821,"@Override public void copyNormalizedKey(byte[] target,int offset,int len){
  if (len == 8) {
    target[offset]=(byte)(value >>> 56);
    target[offset + 1]=(byte)(value >>> 48);
    target[offset + 2]=(byte)(value >>> 40);
    target[offset + 3]=(byte)(value >>> 32);
    target[offset + 4]=(byte)(value >>> 24);
    target[offset + 5]=(byte)(value >>> 16);
    target[offset + 6]=(byte)(value >>> 8);
    target[offset + 7]=(byte)(value);
  }
 else   if (len < 8) {
    for (int i=0; len > 0; len--, i++) {
      target[offset + i]=(byte)(value >>> ((7 - i) << 3));
    }
  }
 else {
    target[offset]=(byte)(value >>> 56);
    target[offset + 1]=(byte)(value >>> 48);
    target[offset + 2]=(byte)(value >>> 40);
    target[offset + 3]=(byte)(value >>> 32);
    target[offset + 4]=(byte)(value >>> 24);
    target[offset + 5]=(byte)(value >>> 16);
    target[offset + 6]=(byte)(value >>> 8);
    target[offset + 7]=(byte)(value);
    for (int i=8; i < len; i++) {
      target[offset + i]=0;
    }
  }
}","@Override public void copyNormalizedKey(byte[] target,int offset,int len){
  if (len == 8) {
    long highByte=((value >>> 56) & 0xff);
    highByte-=Byte.MIN_VALUE;
    target[offset]=(byte)highByte;
    target[offset + 1]=(byte)(value >>> 48);
    target[offset + 2]=(byte)(value >>> 40);
    target[offset + 3]=(byte)(value >>> 32);
    target[offset + 4]=(byte)(value >>> 24);
    target[offset + 5]=(byte)(value >>> 16);
    target[offset + 6]=(byte)(value >>> 8);
    target[offset + 7]=(byte)(value);
  }
 else   if (len <= 0) {
  }
 else   if (len < 8) {
    long highByte=((value >>> 56) & 0xff);
    highByte-=Byte.MIN_VALUE;
    target[offset]=(byte)highByte;
    len--;
    for (int i=1; len > 0; len--, i++) {
      target[offset + i]=(byte)(value >>> ((7 - i) << 3));
    }
  }
 else {
    long highByte=((value >>> 56) & 0xff);
    highByte-=Byte.MIN_VALUE;
    target[offset]=(byte)highByte;
    target[offset + 1]=(byte)(value >>> 48);
    target[offset + 2]=(byte)(value >>> 40);
    target[offset + 3]=(byte)(value >>> 32);
    target[offset + 4]=(byte)(value >>> 24);
    target[offset + 5]=(byte)(value >>> 16);
    target[offset + 6]=(byte)(value >>> 8);
    target[offset + 7]=(byte)(value);
    for (int i=8; i < len; i++) {
      target[offset + i]=0;
    }
  }
}",0.8313725490196079
55822,"/** 
 * Returns this PactString's internal character data.
 * @return The character data.
 */
public char[] getChars(){
  return this.value;
}","/** 
 * Returns this PactString's internal character data. The array might be larger than the string which is currently stored in the PactString.
 * @return The character data.
 */
public char[] getChars(){
  return this.value;
}",0.7654986522911051
55823,"@Override public char charAt(int index){
  return this.value[index];
}","@Override public char charAt(int index){
  if (index < len) {
    return this.value[index];
  }
 else {
    throw new IndexOutOfBoundsException();
  }
}",0.6306306306306306
55824,"@Test public void testPactNull(){
  final PactNull pn1=new PactNull();
  final PactNull pn2=new PactNull();
  assertNormalizableKey(pn1,pn2,0);
  final PactNull pn=new PactNull();
  try {
    pn.write(mOut);
    pn.read(mIn);
    assertNormalizableKey(pn,pn1,0);
  }
 catch (  IOException ioex) {
    Assert.fail(""String_Node_Str"" + ioex.getMessage());
  }
}","@Test public void testPactNull(){
  final PactNull pn1=new PactNull();
  final PactNull pn2=new PactNull();
  assertNormalizableKey(pn1,pn2,0);
}",0.5765407554671969
55825,"@Test public void testPactString(){
  PactString string0=new PactString(""String_Node_Str"");
  PactString string1=new PactString(""String_Node_Str"");
  PactString string2=new PactString(""String_Node_Str"");
  PactString string3=new PactString(""String_Node_Str"");
  PactString string4=new PactString(""String_Node_Str"");
  for (int length=5; length <= 15; length+=10) {
    assertNormalizableKey(string0,string1,length);
    assertNormalizableKey(string0,string2,length);
    assertNormalizableKey(string0,string3,length);
    assertNormalizableKey(string0,string4,length);
  }
  try {
    string0.write(mOut);
    string4.write(mOut);
    string2.write(mOut);
    string3.write(mOut);
    PactString string1n=new PactString();
    PactString string2n=new PactString();
    PactString string3n=new PactString();
    PactString string4n=new PactString();
    string1n.read(mIn);
    string4n.read(mIn);
    string2n.read(mIn);
    string3n.read(mIn);
    for (int length=5; length <= 15; length+=10) {
      assertNormalizableKey(string0,string1n,length);
      assertNormalizableKey(string0,string2n,length);
      assertNormalizableKey(string0,string3n,length);
      assertNormalizableKey(string0,string4n,length);
    }
    string2.setValue(""String_Node_Str"");
    assertNormalizableKey(string2,string3,32);
  }
 catch (  Exception e) {
    Assert.assertTrue(false);
  }
}","@Test public void testPactString(){
  PactString string0=new PactString(""String_Node_Str"");
  PactString string1=new PactString(""String_Node_Str"");
  PactString string2=new PactString(""String_Node_Str"");
  PactString string3=new PactString(""String_Node_Str"");
  PactString string4=new PactString(""String_Node_Str"");
  for (int length=5; length <= 15; length+=10) {
    assertNormalizableKey(string0,string1,length);
    assertNormalizableKey(string0,string2,length);
    assertNormalizableKey(string0,string3,length);
    assertNormalizableKey(string0,string4,length);
  }
}",0.5905349794238683
55826,"@Test public void testPactInteger(){
  PactInteger int0=new PactInteger(10);
  Assert.assertEquals(10,int0.getValue());
  PactInteger int1=new PactInteger(10);
  PactInteger int2=new PactInteger(-10);
  PactInteger int3=new PactInteger(255);
  for (int length=2; length <= 4; length++) {
    assertNormalizableKey(int0,int1,length);
    assertNormalizableKey(int0,int2,length);
    assertNormalizableKey(int0,int3,length);
  }
  try {
    int0.write(mOut);
    int2.write(mOut);
    int3.write(mOut);
    PactInteger int1n=new PactInteger();
    PactInteger int2n=new PactInteger();
    PactInteger int3n=new PactInteger();
    int1n.read(mIn);
    int2n.read(mIn);
    int3n.read(mIn);
    for (int length=2; length <= 4; length++) {
      assertNormalizableKey(int0,int1n,length);
      assertNormalizableKey(int0,int2n,length);
      assertNormalizableKey(int0,int3n,length);
    }
  }
 catch (  Exception e) {
    Assert.fail(e.getMessage());
  }
}","@Test public void testPactInteger(){
  PactInteger int0=new PactInteger(10);
  PactInteger int1=new PactInteger(10);
  PactInteger int2=new PactInteger(-10);
  PactInteger int3=new PactInteger(255);
  PactInteger int4=new PactInteger(Integer.MAX_VALUE);
  PactInteger int5=new PactInteger(Integer.MAX_VALUE & 0xff800000);
  PactInteger int6=new PactInteger(Integer.MIN_VALUE);
  PactInteger int7=new PactInteger(Integer.MIN_VALUE & 0xff800000);
  for (int length=2; length <= 4; length++) {
    assertNormalizableKey(int0,int1,length);
    assertNormalizableKey(int0,int2,length);
    assertNormalizableKey(int0,int3,length);
    assertNormalizableKey(int0,int4,length);
    assertNormalizableKey(int0,int5,length);
    assertNormalizableKey(int0,int6,length);
    assertNormalizableKey(int0,int7,length);
    assertNormalizableKey(int4,int5,length);
    assertNormalizableKey(int6,int7,length);
  }
}",0.4155423637344846
55827,"@Test public void testPactLong(){
  PactLong long0=new PactLong(10);
  Assert.assertEquals(10,long0.getValue());
  PactLong long1=new PactLong(10);
  PactLong long2=new PactLong(-10);
  PactLong long3=new PactLong(255);
  for (int length=2; length <= 8; length++) {
    assertNormalizableKey(long0,long1,length);
    assertNormalizableKey(long0,long2,length);
    assertNormalizableKey(long0,long3,length);
  }
  try {
    long0.write(mOut);
    long2.write(mOut);
    long3.write(mOut);
    PactLong long1n=new PactLong();
    PactLong long2n=new PactLong();
    PactLong long3n=new PactLong();
    long1n.read(mIn);
    long2n.read(mIn);
    long3n.read(mIn);
    for (int length=2; length <= 8; length++) {
      assertNormalizableKey(long0,long1n,length);
      assertNormalizableKey(long0,long2n,length);
      assertNormalizableKey(long0,long3n,length);
    }
  }
 catch (  Exception e) {
    Assert.fail(e.getMessage());
  }
}","@Test public void testPactLong(){
  PactLong long0=new PactLong(10);
  PactLong long1=new PactLong(10);
  PactLong long2=new PactLong(-10);
  PactLong long3=new PactLong(255);
  PactLong long4=new PactLong(Long.MAX_VALUE);
  PactLong long5=new PactLong(Long.MAX_VALUE & 0xff80000000000000L);
  PactLong long6=new PactLong(Long.MIN_VALUE);
  PactLong long7=new PactLong(Long.MIN_VALUE & 0xff80000000000000L);
  for (int length=2; length <= 8; length++) {
    assertNormalizableKey(long0,long1,length);
    assertNormalizableKey(long0,long2,length);
    assertNormalizableKey(long0,long3,length);
    assertNormalizableKey(long0,long4,length);
    assertNormalizableKey(long0,long5,length);
    assertNormalizableKey(long0,long6,length);
    assertNormalizableKey(long0,long7,length);
    assertNormalizableKey(long4,long5,length);
    assertNormalizableKey(long6,long7,length);
  }
}",0.4055096418732782
55828,"private void assertNormalizableKey(Key key1,Key key2,int len){
  byte[] normalizedKeys=new byte[2 * len];
  ((NormalizableKey)key1).copyNormalizedKey(normalizedKeys,0,len);
  ((NormalizableKey)key2).copyNormalizedKey(normalizedKeys,len,len);
  for (int i=0; i < len; i++) {
    int comp;
    if ((comp=(normalizedKeys[i] - normalizedKeys[len + i])) != 0) {
      if (Math.signum(key1.compareTo(key2)) != Math.signum(comp)) {
        Assert.fail(""String_Node_Str"");
      }
      return;
    }
  }
  if (key1.compareTo(key2) != 0 && ((NormalizableKey)key1).getMaxNormalizedKeyLen() <= len) {
    Assert.fail(""String_Node_Str"" + ""String_Node_Str"");
  }
}","private void assertNormalizableKey(NormalizableKey key1,NormalizableKey key2,int len){
  byte[] normalizedKeys=new byte[2 * len];
  key1.copyNormalizedKey(normalizedKeys,0,len);
  key2.copyNormalizedKey(normalizedKeys,len,len);
  for (int i=0; i < len; i++) {
    int comp;
    int normKey1=normalizedKeys[i] & 0xFF;
    int normKey2=normalizedKeys[len + i] & 0xFF;
    if ((comp=(normKey1 - normKey2)) != 0) {
      if (Math.signum(key1.compareTo(key2)) != Math.signum(comp)) {
        Assert.fail(""String_Node_Str"");
      }
      return;
    }
  }
  if (key1.compareTo(key2) != 0 && key1.getMaxNormalizedKeyLen() <= len) {
    Assert.fail(""String_Node_Str"" + ""String_Node_Str"");
  }
}",0.8409260642270351
55829,"/** 
 * {@inheritDoc}
 */
@Override public void allocatedResourcesDied(final JobID jobID,final List<AllocatedResource> allocatedResources){
}","/** 
 * {@inheritDoc}
 */
@Override public void allocatedResourcesDied(final JobID jobID,final List<AllocatedResource> allocatedResources){
  for (  final AllocatedResource allocatedResource : allocatedResources) {
    LOG.info(""String_Node_Str"" + allocatedResource.getInstance().getName() + ""String_Node_Str""+ jobID+ ""String_Node_Str"");
    ExecutionGraph job=this.jobQueue.getFirst();
synchronized (job) {
      Iterator<ExecutionGraph> iterator=this.jobQueue.descendingIterator();
      while (job.getJobID() != jobID) {
        if (iterator.hasNext()) {
          job=iterator.next();
        }
 else {
          LOG.error(""String_Node_Str"" + jobID + ""String_Node_Str"");
          return;
        }
      }
      List<ExecutionVertex> vertices=job.getVerticesAssignedToResource(allocatedResource);
      Iterator<ExecutionVertex> vertexIter=vertices.iterator();
      while (vertexIter.hasNext()) {
        ExecutionVertex vertex=vertexIter.next();
        vertex.updateExecutionState(ExecutionState.FAILED,""String_Node_Str"" + allocatedResource.getInstance().getName() + ""String_Node_Str""+ vertex.getEnvironment().getTaskName()+ ""String_Node_Str"");
        if (vertex.getExecutionState() == ExecutionState.FAILED) {
          job.executionStateChanged(jobID,vertex.getID(),ExecutionState.FAILED,""String_Node_Str"" + allocatedResource.getInstance().getName() + ""String_Node_Str""+ vertex.getEnvironment().getTaskName()+ ""String_Node_Str"");
          return;
        }
        vertex.setAllocatedResource(new AllocatedResource(DummyInstance.createDummyInstance(allocatedResource.getInstanceType()),allocatedResource.getInstanceType(),null));
      }
      try {
        LOG.info(""String_Node_Str"" + allocatedResource.getInstanceType().getIdentifier());
        final InstanceRequestMap instanceMap=new InstanceRequestMap();
        instanceMap.setMaximumNumberOfInstances(allocatedResource.getInstanceType(),1);
        instanceMap.setMinimumNumberOfInstances(allocatedResource.getInstanceType(),1);
        this.getInstanceManager().requestInstance(jobID,job.getJobConfiguration(),instanceMap,null);
      }
 catch (      InstanceException e) {
        e.printStackTrace();
      }
      job.executionStateChanged(jobID,vertices.get(0).getID(),ExecutionState.RECOVERING,null);
    }
  }
}",0.1160493827160493
55830,"/** 
 * {@inheritDoc}
 */
@Override public synchronized void executionStateChanged(final JobID jobID,final ExecutionVertexID vertexID,final ExecutionState newExecutionState,String optionalMessage){
  final InternalJobStatus oldStatus=this.jobStatus;
  checkAndUpdateJobStatus(newExecutionState);
  if (newExecutionState == ExecutionState.FINISHED) {
    if (this.isCurrentStageCompleted()) {
      ++this.indexToCurrentExecutionStage;
      if (this.indexToCurrentExecutionStage < this.stages.size()) {
        final Iterator<ExecutionStageListener> it=this.executionStageListeners.iterator();
        final ExecutionStage nextExecutionStage=getCurrentExecutionStage();
        while (it.hasNext()) {
          it.next().nextExecutionStageEntered(jobID,nextExecutionStage);
        }
      }
    }
  }
  if (this.jobStatus != oldStatus) {
    if (this.jobStatus == InternalJobStatus.FAILING) {
      this.errorDescription=optionalMessage;
    }
    if (this.jobStatus == InternalJobStatus.FAILED) {
      optionalMessage=this.errorDescription;
    }
    final Iterator<JobStatusListener> it=this.jobStatusListeners.iterator();
    while (it.hasNext()) {
      it.next().jobStatusHasChanged(this,this.jobStatus,optionalMessage);
    }
  }
}","/** 
 * {@inheritDoc}
 */
@Override public synchronized void executionStateChanged(final JobID jobID,final ExecutionVertexID vertexID,final ExecutionState newExecutionState,String optionalMessage){
  final InternalJobStatus oldStatus=this.jobStatus;
  if (newExecutionState == ExecutionState.RERUNNING) {
    this.recovering.remove(getVertexByID(vertexID));
  }
  checkAndUpdateJobStatus(newExecutionState);
  if (newExecutionState == ExecutionState.FINISHED) {
    if (this.isCurrentStageCompleted()) {
      ++this.indexToCurrentExecutionStage;
      if (this.indexToCurrentExecutionStage < this.stages.size()) {
        final Iterator<ExecutionStageListener> it=this.executionStageListeners.iterator();
        final ExecutionStage nextExecutionStage=getCurrentExecutionStage();
        while (it.hasNext()) {
          it.next().nextExecutionStageEntered(jobID,nextExecutionStage);
        }
      }
    }
  }
  if (this.jobStatus == InternalJobStatus.RECOVERING) {
    LOG.info(""String_Node_Str"");
    this.recovering.add(this.getVertexByID(vertexID));
  }
  if (this.jobStatus != oldStatus) {
    if (this.jobStatus == InternalJobStatus.FAILING) {
      this.errorDescription=optionalMessage;
    }
    if (this.jobStatus == InternalJobStatus.FAILED) {
      optionalMessage=this.errorDescription;
    }
    final Iterator<JobStatusListener> it=this.jobStatusListeners.iterator();
    while (it.hasNext()) {
      it.next().jobStatusHasChanged(this,this.jobStatus,optionalMessage);
    }
  }
}",0.9050401753104456
55831,"/** 
 * Checks and updates the current execution status of the job which is represented by this execution graph.
 * @param latestStateChange the latest execution state change which occurred
 */
public synchronized void checkAndUpdateJobStatus(final ExecutionState latestStateChange){
switch (this.jobStatus) {
case CREATED:
    if (jobHasScheduledStatus()) {
      this.jobStatus=InternalJobStatus.SCHEDULED;
    }
 else     if (latestStateChange == ExecutionState.CANCELED) {
      if (jobHasFailedOrCanceledStatus()) {
        this.jobStatus=InternalJobStatus.CANCELED;
      }
    }
  break;
case SCHEDULED:
if (latestStateChange == ExecutionState.RUNNING) {
  this.jobStatus=InternalJobStatus.RUNNING;
  return;
}
 else if (latestStateChange == ExecutionState.CANCELED) {
  if (jobHasFailedOrCanceledStatus()) {
    this.jobStatus=InternalJobStatus.CANCELED;
  }
}
break;
case RUNNING:
if (latestStateChange == ExecutionState.CANCELING || latestStateChange == ExecutionState.CANCELED) {
this.jobStatus=InternalJobStatus.CANCELING;
return;
}
if (latestStateChange == ExecutionState.FAILED) {
final Iterator<ExecutionVertex> it=new ExecutionGraphIterator(this,true);
while (it.hasNext()) {
final ExecutionVertex vertex=it.next();
if (vertex.getExecutionState() == ExecutionState.FAILED && !vertex.hasRetriesLeft()) {
this.jobStatus=InternalJobStatus.FAILING;
return;
}
}
}
if (jobHasFinishedStatus()) {
this.jobStatus=InternalJobStatus.FINISHED;
}
break;
case FAILING:
if (jobHasFailedOrCanceledStatus()) {
this.jobStatus=InternalJobStatus.FAILED;
}
break;
case FAILED:
LOG.error(""String_Node_Str"");
break;
case CANCELING:
if (jobHasFailedOrCanceledStatus()) {
this.jobStatus=InternalJobStatus.CANCELED;
}
break;
case CANCELED:
LOG.error(""String_Node_Str"");
break;
case FINISHED:
LOG.error(""String_Node_Str"");
break;
}
}","/** 
 * Checks and updates the current execution status of the job which is represented by this execution graph.
 * @param latestStateChange the latest execution state change which occurred
 */
public synchronized void checkAndUpdateJobStatus(final ExecutionState latestStateChange){
switch (this.jobStatus) {
case CREATED:
    if (jobHasScheduledStatus()) {
      this.jobStatus=InternalJobStatus.SCHEDULED;
    }
 else     if (latestStateChange == ExecutionState.CANCELED) {
      if (jobHasFailedOrCanceledStatus()) {
        this.jobStatus=InternalJobStatus.CANCELED;
      }
    }
  break;
case SCHEDULED:
if (latestStateChange == ExecutionState.RUNNING) {
  this.jobStatus=InternalJobStatus.RUNNING;
  return;
}
 else if (latestStateChange == ExecutionState.CANCELED) {
  if (jobHasFailedOrCanceledStatus()) {
    this.jobStatus=InternalJobStatus.CANCELED;
  }
}
break;
case RUNNING:
if (latestStateChange == ExecutionState.CANCELING || latestStateChange == ExecutionState.CANCELED) {
this.jobStatus=InternalJobStatus.CANCELING;
return;
}
if (latestStateChange == ExecutionState.FAILED) {
final Iterator<ExecutionVertex> it=new ExecutionGraphIterator(this,true);
while (it.hasNext()) {
final ExecutionVertex vertex=it.next();
if (vertex.getExecutionState() == ExecutionState.FAILED && !vertex.hasRetriesLeft()) {
this.jobStatus=InternalJobStatus.FAILING;
return;
}
}
}
if (latestStateChange == ExecutionState.RECOVERING) {
this.jobStatus=InternalJobStatus.RECOVERING;
return;
}
if (jobHasFinishedStatus()) {
this.jobStatus=InternalJobStatus.FINISHED;
}
break;
case RECOVERING:
if (latestStateChange == ExecutionState.RERUNNING) {
this.recovering.clear();
this.jobStatus=InternalJobStatus.RUNNING;
}
break;
case FAILING:
if (jobHasFailedOrCanceledStatus()) {
this.jobStatus=InternalJobStatus.FAILED;
}
break;
case FAILED:
LOG.error(""String_Node_Str"");
break;
case CANCELING:
if (jobHasFailedOrCanceledStatus()) {
this.jobStatus=InternalJobStatus.CANCELED;
}
break;
case CANCELED:
LOG.error(""String_Node_Str"");
break;
case FINISHED:
LOG.error(""String_Node_Str"");
break;
}
}",0.9345986150294948
55832,"/** 
 * {@inheritDoc}
 */
@Override public void jobStatusHasChanged(final ExecutionGraph executionGraph,final InternalJobStatus newJobStatus,final String optionalMessage){
synchronized (executionGraph) {
    LOG.info(""String_Node_Str"" + executionGraph.getJobName() + ""String_Node_Str""+ executionGraph.getJobID()+ ""String_Node_Str""+ ""String_Node_Str""+ newJobStatus);
  }
  if (newJobStatus == InternalJobStatus.CANCELING || newJobStatus == InternalJobStatus.FAILING) {
    cancelJob(executionGraph);
  }
  if (newJobStatus == InternalJobStatus.FINISHED) {
    removeAllCheckpoints(executionGraph);
  }
  if (newJobStatus == InternalJobStatus.CANCELED || newJobStatus == InternalJobStatus.FAILED || newJobStatus == InternalJobStatus.FINISHED) {
    unregisterJob(executionGraph);
  }
}","/** 
 * {@inheritDoc}
 */
@Override public void jobStatusHasChanged(final ExecutionGraph executionGraph,final InternalJobStatus newJobStatus,final String optionalMessage){
synchronized (executionGraph) {
    LOG.info(""String_Node_Str"" + executionGraph.getJobName() + ""String_Node_Str""+ executionGraph.getJobID()+ ""String_Node_Str""+ ""String_Node_Str""+ newJobStatus);
  }
  if (newJobStatus == InternalJobStatus.CANCELING || newJobStatus == InternalJobStatus.FAILING) {
    cancelJob(executionGraph);
  }
  if (newJobStatus == InternalJobStatus.FINISHED) {
    removeAllCheckpoints(executionGraph);
  }
  if (newJobStatus == InternalJobStatus.CANCELED || newJobStatus == InternalJobStatus.FAILED || newJobStatus == InternalJobStatus.FINISHED) {
    unregisterJob(executionGraph);
  }
  if (newJobStatus == InternalJobStatus.RECOVERING) {
    try {
      RecoveryThread recoverythread=new RecoveryThread(executionGraph,this);
      recoverythread.start();
    }
 catch (    Exception e) {
      e.printStackTrace();
    }
  }
}",0.8666297731045932
55833,"private List<ExecutionVertex> findFollowers(ExecutionVertex vertex,ArrayList<ExecutionVertex> restart){
  ArrayList<ExecutionVertex> follower=new ArrayList<ExecutionVertex>();
  for (int i=0; i < vertex.getNumberOfSuccessors(); i++) {
    ExecutionVertex successor=vertex.getSuccessor(i);
    if (!restart.contains(successor)) {
      follower.add(successor);
      if (successor.getCheckpointState() == CheckpointState.COMPLETE) {
        this.checkpoints.remove(successor);
        final List<ExecutionVertexID> checkpointsToRemove=new ArrayList<ExecutionVertexID>();
        checkpointsToRemove.add(successor.getID());
        try {
          successor.getAllocatedResource().getInstance().removeCheckpoints(checkpointsToRemove);
        }
 catch (        IOException e) {
          e.printStackTrace();
        }
      }
    }
  }
  return follower;
}","private List<ExecutionVertex> findFollowers(ExecutionVertex vertex,ArrayList<ExecutionVertex> restart){
  ArrayList<ExecutionVertex> follower=new ArrayList<ExecutionVertex>();
  for (int i=0; i < vertex.getNumberOfSuccessors(); i++) {
    ExecutionVertex successor=vertex.getSuccessor(i);
    if (!restart.contains(successor)) {
      follower.add(successor);
      if (successor.getCheckpointState() == CheckpointState.PARTIAL) {
        this.checkpoints.remove(successor);
        final List<ExecutionVertexID> checkpointsToRemove=new ArrayList<ExecutionVertexID>();
        checkpointsToRemove.add(successor.getID());
        try {
          successor.getAllocatedResource().getInstance().removeCheckpoints(checkpointsToRemove);
        }
 catch (        IOException e) {
          e.printStackTrace();
        }
      }
    }
  }
  return follower;
}",0.9935634874195436
55834,"/** 
 * @param failed
 * @return
 */
private List<ExecutionVertex> findRestarts(ExecutionVertex failed){
  LOG.info(""String_Node_Str"");
  ArrayList<ExecutionVertex> restart=new ArrayList<ExecutionVertex>();
  Queue<ExecutionVertex> totest=new ArrayDeque<ExecutionVertex>();
  ArrayList<ExecutionVertex> visited=new ArrayList<ExecutionVertex>();
  totest.add(failed);
  int k=0;
  LOG.info(""String_Node_Str"");
  ExecutionVertex vertex=failed;
  while (!totest.isEmpty()) {
    LOG.info(""String_Node_Str"");
    if (k != 0) {
      vertex=totest.peek();
    }
    LOG.info(""String_Node_Str"" + vertex.getName());
    k++;
    totest.remove(vertex);
    if (!restart.contains(vertex)) {
      restart.add(vertex);
    }
    for (int i=0; i < vertex.getNumberOfSuccessors(); i++) {
      ExecutionVertex successor=vertex.getSuccessor(i);
      restart.add(successor);
      LOG.info(""String_Node_Str"" + successor.getName() + ""String_Node_Str"");
      if (successor.getCheckpointState() == CheckpointState.COMPLETE) {
        this.checkpoints.remove(successor);
      }
      List<ExecutionVertex> follower=findFollowers(successor,restart);
      restart.addAll(follower);
      Iterator<ExecutionVertex> iter=follower.iterator();
      while (iter.hasNext()) {
        ExecutionVertex follow=iter.next();
        if (!visited.contains(follow)) {
          LOG.info(""String_Node_Str"" + follow.getName());
          totest.add(follow);
        }
      }
    }
    for (int j=0; j < vertex.getNumberOfPredecessors(); j++) {
      ExecutionVertex predecessor=vertex.getPredecessor(j);
      if (predecessor.getCheckpointState() != CheckpointState.COMPLETE) {
        LOG.info(""String_Node_Str"" + predecessor.getName() + ""String_Node_Str"");
        restart.add(predecessor);
        if (!visited.contains(predecessor)) {
          totest.add(predecessor);
          LOG.info(""String_Node_Str"" + predecessor);
        }
      }
 else {
        if (!this.globalConsistentCheckpoint.contains(predecessor)) {
          this.globalConsistentCheckpoint.add(predecessor);
        }
        List<ExecutionVertex> follower=findFollowers(predecessor,restart);
        for (int i=0; i < follower.size(); i++) {
          LOG.info(""String_Node_Str"" + follower.get(i) + ""String_Node_Str"");
        }
        restart.addAll(follower);
        Iterator<ExecutionVertex> iter=follower.iterator();
        while (iter.hasNext()) {
          ExecutionVertex follow=iter.next();
          if (!visited.contains(follow)) {
            LOG.info(""String_Node_Str"" + follow.getName());
            totest.add(follow);
          }
        }
      }
    }
    visited.add(vertex);
  }
  LOG.info(""String_Node_Str"");
  return restart;
}","/** 
 * @param failed
 * @return
 */
private List<ExecutionVertex> findRestarts(ExecutionVertex failed){
  LOG.info(""String_Node_Str"");
  ArrayList<ExecutionVertex> restart=new ArrayList<ExecutionVertex>();
  Queue<ExecutionVertex> totest=new ArrayDeque<ExecutionVertex>();
  ArrayList<ExecutionVertex> visited=new ArrayList<ExecutionVertex>();
  totest.add(failed);
  int k=0;
  LOG.info(""String_Node_Str"");
  ExecutionVertex vertex=failed;
  while (!totest.isEmpty()) {
    LOG.info(""String_Node_Str"");
    if (k != 0) {
      vertex=totest.peek();
    }
    LOG.info(""String_Node_Str"" + vertex.getName());
    k++;
    totest.remove(vertex);
    if (!restart.contains(vertex)) {
      restart.add(vertex);
    }
    for (int i=0; i < vertex.getNumberOfSuccessors(); i++) {
      ExecutionVertex successor=vertex.getSuccessor(i);
      restart.add(successor);
      LOG.info(""String_Node_Str"" + successor.getName() + ""String_Node_Str"");
      if (successor.getCheckpointState() == CheckpointState.PARTIAL) {
        this.checkpoints.remove(successor);
      }
      List<ExecutionVertex> follower=findFollowers(successor,restart);
      restart.addAll(follower);
      Iterator<ExecutionVertex> iter=follower.iterator();
      while (iter.hasNext()) {
        ExecutionVertex follow=iter.next();
        if (!visited.contains(follow)) {
          LOG.info(""String_Node_Str"" + follow.getName());
          totest.add(follow);
        }
      }
    }
    for (int j=0; j < vertex.getNumberOfPredecessors(); j++) {
      ExecutionVertex predecessor=vertex.getPredecessor(j);
      if (predecessor.getCheckpointState() != CheckpointState.PARTIAL) {
        LOG.info(""String_Node_Str"" + predecessor.getName() + ""String_Node_Str"");
        restart.add(predecessor);
        if (!visited.contains(predecessor)) {
          totest.add(predecessor);
          LOG.info(""String_Node_Str"" + predecessor);
        }
      }
 else {
        if (!this.globalConsistentCheckpoint.contains(predecessor)) {
          this.globalConsistentCheckpoint.add(predecessor);
        }
        List<ExecutionVertex> follower=findFollowers(predecessor,restart);
        for (int i=0; i < follower.size(); i++) {
          LOG.info(""String_Node_Str"" + follower.get(i) + ""String_Node_Str"");
        }
        restart.addAll(follower);
        Iterator<ExecutionVertex> iter=follower.iterator();
        while (iter.hasNext()) {
          ExecutionVertex follow=iter.next();
          if (!visited.contains(follow)) {
            LOG.info(""String_Node_Str"" + follow.getName());
            totest.add(follow);
          }
        }
      }
    }
    visited.add(vertex);
  }
  LOG.info(""String_Node_Str"");
  return restart;
}",0.9959229058561898
55835,"void executionStateChanged(final JobID jobID,final ExecutionVertexID id,final Task task,final ExecutionState newExecutionState,final String optionalDescription){
  if (newExecutionState == ExecutionState.RUNNING) {
synchronized (this.runningTasks) {
      this.runningTasks.put(id,task);
    }
  }
  if (newExecutionState == ExecutionState.FINISHED || newExecutionState == ExecutionState.CANCELED || newExecutionState == ExecutionState.FAILED) {
synchronized (this.runningTasks) {
      this.runningTasks.remove(id);
    }
    unregisterTask(id,task);
  }
synchronized (this.jobManager) {
    try {
      this.jobManager.updateTaskExecutionState(new TaskExecutionState(jobID,id,newExecutionState,optionalDescription));
    }
 catch (    IOException e) {
      LOG.error(StringUtils.stringifyException(e));
    }
  }
}","void executionStateChanged(final JobID jobID,final ExecutionVertexID id,final Task task,final ExecutionState newExecutionState,final String optionalDescription){
  if (newExecutionState == ExecutionState.RUNNING || newExecutionState == ExecutionState.RUNNING) {
synchronized (this.runningTasks) {
      this.runningTasks.put(id,task);
    }
  }
  if (newExecutionState == ExecutionState.FINISHED || newExecutionState == ExecutionState.CANCELED || newExecutionState == ExecutionState.FAILED) {
synchronized (this.runningTasks) {
      this.runningTasks.remove(id);
    }
    unregisterTask(id,task);
  }
synchronized (this.jobManager) {
    try {
      this.jobManager.updateTaskExecutionState(new TaskExecutionState(jobID,id,newExecutionState,optionalDescription));
    }
 catch (    IOException e) {
      LOG.error(StringUtils.stringifyException(e));
    }
  }
}",0.9720404521118382
55836,"/** 
 * Deserializes the next record from one of the data buffers.
 * @return the next record or <code>null</code> if all data buffers are exhausted
 * @throws ExecutionFailureException if the record cannot be deserialized
 */
private T deserializeNextRecord(final T target) throws IOException {
  if (this.bufferedRecord != null) {
    final T record=this.bufferedRecord;
    this.bufferedRecord=null;
    return record;
  }
  if (this.uncompressedDataBuffer == null) {
synchronized (this.synchronisationObject) {
      if (this.ioException != null) {
        throw this.ioException;
      }
      requestReadBuffersFromBroker();
    }
    if (this.uncompressedDataBuffer == null) {
      return null;
    }
    if (this.decompressor != null) {
      this.decompressor.decompress();
    }
  }
  final T nextRecord=this.deserializationBuffer.readData(target,this.uncompressedDataBuffer);
  if (this.uncompressedDataBuffer.remaining() == 0) {
    releasedConsumedReadBuffer();
    this.bufferedRecord=nextRecord;
    return null;
  }
  return nextRecord;
}","/** 
 * Deserializes the next record from one of the data buffers.
 * @return the next record or <code>null</code> if all data buffers are exhausted
 * @throws ExecutionFailureException if the record cannot be deserialized
 */
private T deserializeNextRecord(final T target) throws IOException {
  if (this.uncompressedDataBuffer == null) {
synchronized (this.synchronisationObject) {
      if (this.ioException != null) {
        throw this.ioException;
      }
      requestReadBuffersFromBroker();
    }
    if (this.uncompressedDataBuffer == null) {
      return null;
    }
    if (this.decompressor != null) {
      this.decompressor.decompress();
    }
  }
  final T nextRecord=this.deserializationBuffer.readData(target,this.uncompressedDataBuffer);
  if (this.uncompressedDataBuffer.remaining() == 0) {
    releasedConsumedReadBuffer();
  }
  return nextRecord;
}",0.8894654903995849
55837,"/** 
 * {@inheritDoc}
 */
@Override public boolean isClosed() throws IOException {
  if (this.bufferedRecord != null || this.uncompressedDataBuffer != null) {
    return false;
  }
synchronized (this.synchronisationObject) {
    if (this.ioException != null) {
      throw this.ioException;
    }
    if (!this.brokerAggreedToCloseChannel) {
      return false;
    }
  }
  return true;
}","/** 
 * {@inheritDoc}
 */
@Override public boolean isClosed() throws IOException {
  if (this.uncompressedDataBuffer != null) {
    return false;
  }
synchronized (this.synchronisationObject) {
    if (this.ioException != null) {
      throw this.ioException;
    }
    if (!this.brokerAggreedToCloseChannel) {
      return false;
    }
  }
  return true;
}",0.9583892617449664
55838,"/** 
 * {@inheritDoc}
 */
@Override public void close() throws IOException, InterruptedException {
  this.deserializationBuffer.clear();
  if (this.uncompressedDataBuffer != null) {
    releasedConsumedReadBuffer();
  }
  if (this.getType() == ChannelType.NETWORK) {
synchronized (this.synchronisationObject) {
      if (!this.brokerAggreedToCloseChannel) {
        while (!this.brokerAggreedToCloseChannel) {
          requestReadBuffersFromBroker();
          if (this.uncompressedDataBuffer != null || this.compressedDataBuffer != null) {
            releasedConsumedReadBuffer();
          }
          this.synchronisationObject.wait(500);
        }
        this.bufferedRecord=null;
      }
    }
  }
  final ChannelType type=getType();
  if (type == ChannelType.NETWORK || type == ChannelType.INMEMORY) {
    transferEvent(new ByteBufferedChannelCloseEvent());
  }
}","/** 
 * {@inheritDoc}
 */
@Override public void close() throws IOException, InterruptedException {
  this.deserializationBuffer.clear();
  if (this.uncompressedDataBuffer != null) {
    releasedConsumedReadBuffer();
  }
  if (this.getType() == ChannelType.NETWORK) {
synchronized (this.synchronisationObject) {
      if (!this.brokerAggreedToCloseChannel) {
        while (!this.brokerAggreedToCloseChannel) {
          requestReadBuffersFromBroker();
          if (this.uncompressedDataBuffer != null || this.compressedDataBuffer != null) {
            releasedConsumedReadBuffer();
          }
          this.synchronisationObject.wait(500);
        }
      }
    }
  }
  final ChannelType type=getType();
  if (type == ChannelType.NETWORK || type == ChannelType.INMEMORY) {
    transferEvent(new ByteBufferedChannelCloseEvent());
  }
}",0.9801169590643276
55839,"private List<ExecutionVertex> findFollowers(ExecutionVertex vertex,ArrayList<ExecutionVertex> restart){
  ArrayList<ExecutionVertex> follower=new ArrayList<ExecutionVertex>();
  for (int i=0; i < vertex.getNumberOfSuccessors(); i++) {
    ExecutionVertex successor=vertex.getSuccessor(i);
    if (!restart.contains(successor)) {
      follower.add(successor);
      if (successor.getCheckpointState() == CheckpointState.PARTIAL) {
        this.checkpoints.remove(successor);
        final List<ExecutionVertexID> checkpointsToRemove=new ArrayList<ExecutionVertexID>();
        checkpointsToRemove.add(successor.getID());
        try {
          successor.getAllocatedResource().getInstance().removeCheckpoints(checkpointsToRemove);
        }
 catch (        IOException e) {
          e.printStackTrace();
        }
      }
    }
  }
  return follower;
}","private List<ExecutionVertex> findFollowers(ExecutionVertex vertex,ArrayList<ExecutionVertex> restart){
  ArrayList<ExecutionVertex> follower=new ArrayList<ExecutionVertex>();
  for (int i=0; i < vertex.getNumberOfSuccessors(); i++) {
    ExecutionVertex successor=vertex.getSuccessor(i);
    if (!restart.contains(successor)) {
      follower.add(successor);
      if (successor.getCheckpointState() == CheckpointState.PARTIAL) {
        this.checkpoints.remove(successor);
        this.globalConsistentCheckpoint.remove(successor.getID());
        final SerializableArrayList<ExecutionVertexID> checkpointsToRemove=new SerializableArrayList<ExecutionVertexID>();
        checkpointsToRemove.add(successor.getID());
        try {
          successor.getAllocatedResource().getInstance().removeCheckpoints(checkpointsToRemove);
        }
 catch (        IOException e) {
          e.printStackTrace();
        }
      }
    }
  }
  return follower;
}",0.9467849223946784
55840,"/** 
 * {@inheritDoc}
 */
@Override public void run(){
  if (this.failedVertices.isEmpty()) {
    LOG.error(""String_Node_Str"");
  }
  Iterator<ExecutionVertex> vertexIter=this.failedVertices.iterator();
  while (vertexIter.hasNext()) {
    ExecutionVertex failed=vertexIter.next();
    LOG.info(""String_Node_Str"" + failed);
    List<ExecutionVertex> restart=findRestarts(failed);
    Iterator<ExecutionVertex> restartIterator=restart.iterator();
    while (restartIterator.hasNext()) {
      ExecutionVertex vertex=restartIterator.next();
      if (!vertex.equals(failed)) {
        LOG.info(""String_Node_Str"" + vertex.getName());
        final List<ExecutionVertexID> checkpointsToReplay=new ArrayList<ExecutionVertexID>();
        checkpointsToReplay.add(vertex.getID());
        try {
          vertex.getAllocatedResource().getInstance().replayCheckpoints(checkpointsToReplay);
        }
 catch (        Exception e) {
          LOG.info(""String_Node_Str"" + StringUtils.stringifyException(e) + ""String_Node_Str"");
        }
      }
    }
    LOG.info(""String_Node_Str"" + failed);
  }
  this.job.executionStateChanged(this.job.getJobID(),null,ExecutionState.RERUNNING,null);
  LOG.info(""String_Node_Str"");
}","/** 
 * {@inheritDoc}
 */
@Override public void run(){
  if (this.failedVertices.isEmpty()) {
    LOG.error(""String_Node_Str"");
  }
  List<CheckpointReplayResult> replayCheckpoints=new ArrayList();
  Iterator<ExecutionVertex> vertexIter=this.failedVertices.iterator();
  while (vertexIter.hasNext()) {
    ExecutionVertex failed=vertexIter.next();
    LOG.info(""String_Node_Str"" + failed);
    findRestarts(failed);
    Iterator<ExecutionVertexID> checkpointIterator=this.globalConsistentCheckpoint.iterator();
    while (checkpointIterator.hasNext()) {
      ExecutionVertexID checkpoint=checkpointIterator.next();
      AbstractInstance instance=job.getVertexByID(checkpoint).getAllocatedResource().getInstance();
      try {
        replayCheckpoints.addAll(instance.replayCheckpoints(this.globalConsistentCheckpoint));
      }
 catch (      IOException e) {
        e.printStackTrace();
      }
    }
  }
  for (  CheckpointReplayResult replayResult : replayCheckpoints) {
    if (replayResult.getReturnCode() == ReturnCode.ERROR) {
      LOG.info(""String_Node_Str"" + replayResult.getDescription());
      return;
    }
  }
  this.job.executionStateChanged(this.job.getJobID(),null,ExecutionState.RERUNNING,null);
  LOG.info(""String_Node_Str"");
}",0.3439024390243902
55841,"/** 
 * @param failed
 * @return
 */
private List<ExecutionVertex> findRestarts(ExecutionVertex failed){
  LOG.info(""String_Node_Str"");
  ArrayList<ExecutionVertex> restart=new ArrayList<ExecutionVertex>();
  Queue<ExecutionVertex> totest=new ArrayDeque<ExecutionVertex>();
  ArrayList<ExecutionVertex> visited=new ArrayList<ExecutionVertex>();
  totest.add(failed);
  int k=0;
  LOG.info(""String_Node_Str"");
  ExecutionVertex vertex=failed;
  while (!totest.isEmpty()) {
    LOG.info(""String_Node_Str"");
    if (k != 0) {
      vertex=totest.peek();
    }
    LOG.info(""String_Node_Str"" + vertex.getName());
    k++;
    totest.remove(vertex);
    if (!restart.contains(vertex)) {
      restart.add(vertex);
    }
    for (int i=0; i < vertex.getNumberOfSuccessors(); i++) {
      ExecutionVertex successor=vertex.getSuccessor(i);
      restart.add(successor);
      LOG.info(""String_Node_Str"" + successor.getName() + ""String_Node_Str"");
      if (successor.getCheckpointState() == CheckpointState.PARTIAL) {
        this.checkpoints.remove(successor);
      }
      List<ExecutionVertex> follower=findFollowers(successor,restart);
      restart.addAll(follower);
      Iterator<ExecutionVertex> iter=follower.iterator();
      while (iter.hasNext()) {
        ExecutionVertex follow=iter.next();
        if (!visited.contains(follow)) {
          LOG.info(""String_Node_Str"" + follow.getName());
          totest.add(follow);
        }
      }
    }
    for (int j=0; j < vertex.getNumberOfPredecessors(); j++) {
      ExecutionVertex predecessor=vertex.getPredecessor(j);
      if (predecessor.getCheckpointState() != CheckpointState.PARTIAL) {
        LOG.info(""String_Node_Str"" + predecessor.getName() + ""String_Node_Str"");
        restart.add(predecessor);
        if (!visited.contains(predecessor)) {
          totest.add(predecessor);
          LOG.info(""String_Node_Str"" + predecessor);
        }
      }
 else {
        if (!this.globalConsistentCheckpoint.contains(predecessor)) {
          this.globalConsistentCheckpoint.add(predecessor);
        }
        List<ExecutionVertex> follower=findFollowers(predecessor,restart);
        for (int i=0; i < follower.size(); i++) {
          LOG.info(""String_Node_Str"" + follower.get(i) + ""String_Node_Str"");
        }
        restart.addAll(follower);
        Iterator<ExecutionVertex> iter=follower.iterator();
        while (iter.hasNext()) {
          ExecutionVertex follow=iter.next();
          if (!visited.contains(follow)) {
            LOG.info(""String_Node_Str"" + follow.getName());
            totest.add(follow);
          }
        }
      }
    }
    visited.add(vertex);
  }
  LOG.info(""String_Node_Str"");
  return restart;
}","/** 
 * @param failed
 * @return
 */
private List<ExecutionVertex> findRestarts(ExecutionVertex failed){
  ArrayList<ExecutionVertex> restart=new ArrayList<ExecutionVertex>();
  Queue<ExecutionVertex> totest=new ArrayDeque<ExecutionVertex>();
  ArrayList<ExecutionVertex> visited=new ArrayList<ExecutionVertex>();
  totest.add(failed);
  ExecutionVertex vertex=failed;
  while (!totest.isEmpty()) {
    vertex=totest.peek();
    totest.remove(vertex);
    if (!restart.contains(vertex)) {
      restart.add(vertex);
    }
    for (int i=0; i < vertex.getNumberOfSuccessors(); i++) {
      ExecutionVertex successor=vertex.getSuccessor(i);
      restart.add(successor);
      if (successor.getCheckpointState() == CheckpointState.PARTIAL) {
        this.checkpoints.remove(successor);
        this.globalConsistentCheckpoint.remove(successor.getID());
      }
      List<ExecutionVertex> follower=findFollowers(successor,restart);
      restart.addAll(follower);
      Iterator<ExecutionVertex> iter=follower.iterator();
      while (iter.hasNext()) {
        ExecutionVertex follow=iter.next();
        if (!visited.contains(follow)) {
          totest.add(follow);
        }
      }
    }
    for (int j=0; j < vertex.getNumberOfPredecessors(); j++) {
      ExecutionVertex predecessor=vertex.getPredecessor(j);
      if (predecessor.getCheckpointState() != CheckpointState.PARTIAL) {
        restart.add(predecessor);
        if (!visited.contains(predecessor)) {
          totest.add(predecessor);
        }
      }
 else {
        if (!this.globalConsistentCheckpoint.contains(predecessor.getID())) {
          this.globalConsistentCheckpoint.add(predecessor.getID());
        }
        List<ExecutionVertex> follower=findFollowers(predecessor,restart);
        for (int i=0; i < follower.size(); i++) {
          LOG.info(""String_Node_Str"" + follower.get(i) + ""String_Node_Str"");
        }
        restart.addAll(follower);
        Iterator<ExecutionVertex> iter=follower.iterator();
        while (iter.hasNext()) {
          ExecutionVertex follow=iter.next();
          if (!visited.contains(follow)) {
            LOG.info(""String_Node_Str"" + follow.getName());
            totest.add(follow);
          }
        }
      }
    }
    visited.add(vertex);
  }
  LOG.info(""String_Node_Str"");
  return restart;
}",0.540777666999003
55842,"void executionStateChanged(final JobID jobID,final ExecutionVertexID id,final Task task,final ExecutionState newExecutionState,final String optionalDescription){
  if (newExecutionState == ExecutionState.RUNNING || newExecutionState == ExecutionState.RUNNING) {
synchronized (this.runningTasks) {
      this.runningTasks.put(id,task);
    }
  }
  if (newExecutionState == ExecutionState.FINISHED || newExecutionState == ExecutionState.CANCELED) {
synchronized (this.runningTasks) {
      this.runningTasks.remove(id);
    }
    unregisterTask(id,task);
  }
synchronized (this.jobManager) {
    try {
      this.jobManager.updateTaskExecutionState(new TaskExecutionState(jobID,id,newExecutionState,optionalDescription));
    }
 catch (    IOException e) {
      LOG.error(StringUtils.stringifyException(e));
    }
  }
}","void executionStateChanged(final JobID jobID,final ExecutionVertexID id,final Task task,final ExecutionState newExecutionState,final String optionalDescription){
  if (newExecutionState == ExecutionState.RUNNING || newExecutionState == ExecutionState.RUNNING) {
synchronized (this.runningTasks) {
      this.runningTasks.put(id,task);
    }
  }
  if (newExecutionState == ExecutionState.FINISHED || newExecutionState == ExecutionState.CANCELED) {
synchronized (this.runningTasks) {
      this.runningTasks.remove(id);
    }
    unregisterTask(id,task);
  }
  if (newExecutionState == ExecutionState.FAILED) {
    this.runningTasks.remove(id);
  }
synchronized (this.jobManager) {
    try {
      this.jobManager.updateTaskExecutionState(new TaskExecutionState(jobID,id,newExecutionState,optionalDescription));
    }
 catch (    IOException e) {
      LOG.error(StringUtils.stringifyException(e));
    }
  }
}",0.947856315179606
55843,"/** 
 * {@inheritDoc}
 */
@Override public List<CheckpointReplayResult> replayCheckpoints(final List<ExecutionVertexID> vertexIDs) throws IOException {
  final List<CheckpointReplayResult> checkpointResultList=new SerializableArrayList<CheckpointReplayResult>();
  for (  final ExecutionVertexID vertexID : vertexIDs) {
    if (!this.checkpointManager.hasCompleteCheckpointAvailable(vertexID)) {
      if (this.checkpointManager.hasPartialCheckpointAvailable(vertexID)) {
synchronized (this.runningTasks) {
          if (!this.runningTasks.containsKey(vertexID)) {
            final CheckpointReplayResult result=new CheckpointReplayResult(vertexID,ReturnCode.ERROR);
            result.setDescription(""String_Node_Str"");
            checkpointResultList.add(result);
            continue;
          }
        }
      }
 else {
        final CheckpointReplayResult result=new CheckpointReplayResult(vertexID,ReturnCode.ERROR);
        result.setDescription(""String_Node_Str"");
        checkpointResultList.add(result);
        continue;
      }
    }
    this.checkpointManager.replayCheckpoint(vertexID);
    checkpointResultList.add(new CheckpointReplayResult(vertexID,ReturnCode.SUCCESS));
  }
  return checkpointResultList;
}","/** 
 * {@inheritDoc}
 */
@Override public SerializableArrayList<CheckpointReplayResult> replayCheckpoints(final List<ExecutionVertexID> vertexIDs) throws IOException {
  final SerializableArrayList<CheckpointReplayResult> checkpointResultList=new SerializableArrayList<CheckpointReplayResult>();
  for (  final ExecutionVertexID vertexID : vertexIDs) {
    if (!this.checkpointManager.hasCompleteCheckpointAvailable(vertexID)) {
      if (this.checkpointManager.hasPartialCheckpointAvailable(vertexID)) {
synchronized (this.runningTasks) {
          if (!this.runningTasks.containsKey(vertexID)) {
            final CheckpointReplayResult result=new CheckpointReplayResult(vertexID,ReturnCode.ERROR);
            result.setDescription(""String_Node_Str"");
            checkpointResultList.add(result);
            continue;
          }
        }
      }
 else {
        final CheckpointReplayResult result=new CheckpointReplayResult(vertexID,ReturnCode.ERROR);
        result.setDescription(""String_Node_Str"");
        checkpointResultList.add(result);
        continue;
      }
    }
    this.checkpointManager.replayCheckpoint(vertexID);
    checkpointResultList.add(new CheckpointReplayResult(vertexID,ReturnCode.SUCCESS));
  }
  return checkpointResultList;
}",0.9863563402889246
55844,"/** 
 * {@inheritDoc}
 */
@Override public void processEnvelopeFromInputChannel(final TransferEnvelope transferEnvelope) throws IOException, InterruptedException {
  System.out.println(""String_Node_Str"");
  processEnvelope(transferEnvelope,false);
}","/** 
 * {@inheritDoc}
 */
@Override public void processEnvelopeFromInputChannel(final TransferEnvelope transferEnvelope) throws IOException, InterruptedException {
  processEnvelope(transferEnvelope,false);
}",0.7483588621444202
55845,"private boolean processEnvelopeEnvelopeWithoutBuffer(final TransferEnvelope transferEnvelope,final TransferEnvelopeReceiverList receiverList){
  System.out.println(""String_Node_Str"" + transferEnvelope.getEventList().size());
  final Iterator<ChannelID> localIt=receiverList.getLocalReceivers().iterator();
  while (localIt.hasNext()) {
    final ChannelID localReceiver=localIt.next();
    final ChannelContext channelContext=this.registeredChannels.get(localReceiver);
    if (channelContext == null) {
      if (LOG.isDebugEnabled()) {
        LOG.debug(""String_Node_Str"" + localReceiver + ""String_Node_Str""+ transferEnvelope.getJobID());
      }
      continue;
    }
    channelContext.queueTransferEnvelope(transferEnvelope);
  }
  final Iterator<InetSocketAddress> remoteIt=receiverList.getRemoteReceivers().iterator();
  while (remoteIt.hasNext()) {
    final InetSocketAddress remoteReceiver=remoteIt.next();
    this.networkConnectionManager.queueEnvelopeForTransfer(remoteReceiver,transferEnvelope);
  }
  return true;
}","private boolean processEnvelopeEnvelopeWithoutBuffer(final TransferEnvelope transferEnvelope,final TransferEnvelopeReceiverList receiverList){
  final Iterator<ChannelID> localIt=receiverList.getLocalReceivers().iterator();
  while (localIt.hasNext()) {
    final ChannelID localReceiver=localIt.next();
    final ChannelContext channelContext=this.registeredChannels.get(localReceiver);
    if (channelContext == null) {
      if (LOG.isDebugEnabled()) {
        LOG.debug(""String_Node_Str"" + localReceiver + ""String_Node_Str""+ transferEnvelope.getJobID());
      }
      continue;
    }
    channelContext.queueTransferEnvelope(transferEnvelope);
  }
  final Iterator<InetSocketAddress> remoteIt=receiverList.getRemoteReceivers().iterator();
  while (remoteIt.hasNext()) {
    final InetSocketAddress remoteReceiver=remoteIt.next();
    this.networkConnectionManager.queueEnvelopeForTransfer(remoteReceiver,transferEnvelope);
  }
  return true;
}",0.6228513650151668
55846,"/** 
 * Sets the number of fields in the record. If the new number of fields is longer than the current number of fields, then null fields are appended. If the new number of fields is smaller than the current number of fields, then the last fields are truncated.
 * @param numFields The new number of fields.
 */
public void setNumFields(final int numFields){
  final int oldNumFields=this.numFields;
  if (numFields > oldNumFields) {
    makeSpace(numFields);
    for (int i=oldNumFields; i < numFields; i++) {
      this.offsets[i]=NULL_INDICATOR_OFFSET;
    }
  }
 else {
    if (this.lastUnmodifiedPos >= numFields)     this.lastUnmodifiedPos=numFields - 1;
  }
  this.numFields=numFields;
}","/** 
 * Sets the number of fields in the record. If the new number of fields is longer than the current number of fields, then null fields are appended. If the new number of fields is smaller than the current number of fields, then the last fields are truncated.
 * @param numFields The new number of fields.
 */
public void setNumFields(final int numFields){
  final int oldNumFields=this.numFields;
  if (numFields > oldNumFields) {
    makeSpace(numFields);
    for (int i=oldNumFields; i < numFields; i++) {
      this.offsets[i]=NULL_INDICATOR_OFFSET;
    }
  }
 else {
    if (this.lastUnmodifiedPos >= numFields)     this.lastUnmodifiedPos=numFields - 1;
    markModified(numFields);
  }
  this.numFields=numFields;
}",0.9795630725863284
55847,"/** 
 * Emit the candidate.
 * @param left
 * @param right
 */
protected void emitCandidate(KeyValuePair<JsonNode,JsonNode> left,KeyValuePair<JsonNode,JsonNode> right){
  EvaluationExpression resultProjection1=this.resultProjection1, resultProjection2=this.resultProjection2;
  if (resultProjection1 == null)   resultProjection1=EvaluationExpression.VALUE;
  if (resultProjection2 == null)   resultProjection2=EvaluationExpression.VALUE;
  final EvaluationContext context=this.getContext();
  this.sopremoTestPlan.getExpectedOutput(0).add(createPactJsonArray(resultProjection1.evaluate(left.getValue(),context),resultProjection2.evaluate(right.getValue(),context)));
}","/** 
 * Emit the candidate.
 * @param left
 * @param right
 */
protected void emitCandidate(KeyValuePair<JsonNode,JsonNode> left,KeyValuePair<JsonNode,JsonNode> right){
  EvaluationExpression resultProjection1=this.resultProjection1, resultProjection2=this.resultProjection2;
  if (resultProjection1 == null)   resultProjection1=EvaluationExpression.VALUE;
  if (resultProjection2 == null)   resultProjection2=EvaluationExpression.VALUE;
  final EvaluationContext context=this.getContext();
  this.sopremoTestPlan.getExpectedOutput(0).add(new ArrayNode(resultProjection1.evaluate(left.getValue(),context),resultProjection2.evaluate(right.getValue(),context)));
}",0.9834586466165414
55848,"private JsonNode flatArrayOfElements(SopremoTestPlan testPlan,int[]... ids){
  ArrayNode array=new ArrayNode();
  for (int sourceIndex=0; sourceIndex < ids.length; sourceIndex++) {
    EvaluationExpression resultProjection=this.resultProjections[sourceIndex];
    if (resultProjection == null)     resultProjection=EvaluationExpression.VALUE;
    for (int tupleIndex=0; tupleIndex < ids[sourceIndex].length; tupleIndex++)     array.add(resultProjection.evaluate(this.findTuple(testPlan,sourceIndex,ids[sourceIndex][tupleIndex]),testPlan.getEvaluationContext()));
  }
  return new JsonNode(array);
}","private JsonNode flatArrayOfElements(SopremoTestPlan testPlan,int[]... ids){
  ArrayNode array=new ArrayNode();
  for (int sourceIndex=0; sourceIndex < ids.length; sourceIndex++) {
    EvaluationExpression resultProjection=this.resultProjections[sourceIndex];
    if (resultProjection == null)     resultProjection=EvaluationExpression.VALUE;
    for (int tupleIndex=0; tupleIndex < ids[sourceIndex].length; tupleIndex++)     array.add(resultProjection.evaluate(this.findTuple(testPlan,sourceIndex,ids[sourceIndex][tupleIndex]),testPlan.getEvaluationContext()));
  }
  return new ArrayNode(array);
}",0.9924812030075189
55849,"private void writeObject(final ObjectOutputStream oos) throws IOException {
  oos.defaultWriteObject();
  new JsonNode(this.initialAggregate).write(oos);
}","private void writeObject(final ObjectOutputStream oos) throws IOException {
  oos.defaultWriteObject();
  this.initialAggregate.write(oos);
}",0.9527027027027029
55850,"@Override public void initialize(){
  try {
    final ByteArrayOutputStream cloneBuffer=new ByteArrayOutputStream();
    final JsonNode cloner=new JsonNode(this.initialAggregate);
    cloner.write(new DataOutputStream(cloneBuffer));
    cloner.read(new DataInputStream(new ByteArrayInputStream(cloneBuffer.toByteArray())));
    this.aggregate=cloner;
  }
 catch (  final IOException e) {
    throw new IllegalStateException(""String_Node_Str"");
  }
}","@Override public void initialize(){
  try {
    final ByteArrayOutputStream cloneBuffer=new ByteArrayOutputStream();
    final JsonNode cloner=this.initialAggregate;
    cloner.write(new DataOutputStream(cloneBuffer));
    cloner.read(new DataInputStream(new ByteArrayInputStream(cloneBuffer.toByteArray())));
    this.aggregate=cloner;
  }
 catch (  final IOException e) {
    throw new IllegalStateException(""String_Node_Str"");
  }
}",0.9841628959276018
55851,"private void readObject(final ObjectInputStream ois) throws IOException, ClassNotFoundException {
  ois.defaultReadObject();
  final JsonNode pactJsonObject=new JsonNode();
  pactJsonObject.read(ois);
  this.initialAggregate=pactJsonObject;
}","private void readObject(final ObjectInputStream ois) throws IOException, ClassNotFoundException {
  ois.defaultReadObject();
  final JsonNode jsonObject=new ObjectNode();
  jsonObject.read(ois);
  this.initialAggregate=jsonObject;
}",0.940928270042194
55852,"public void writeTree(JsonNode value) throws IOException {
  if (value != null) {
    this.writer.write(value.toString());
    this.writer.flush();
  }
}","public void writeTree(JsonNode value) throws IOException {
  if (value != null) {
    if (!this.isFirst) {
      this.writer.write(""String_Node_Str"");
    }
    this.writer.write(value.toString());
    this.writer.flush();
    this.isFirst=false;
  }
}",0.4790123456790123
55853,"public void writeEndArray() throws IOException {
  JsonToken.END_ARRAY.write(this.writer);
}","public void writeEndArray() throws IOException {
  JsonToken.END_ARRAY.write(this.writer);
  this.writer.flush();
}",0.8888888888888888
55854,"public void writeStartArray() throws IOException {
  JsonToken.START_ARRAY.write(this.writer);
}","public void writeStartArray() throws IOException {
  JsonToken.START_ARRAY.write(this.writer);
  this.writer.flush();
}",0.8930232558139535
55855,"@Override public int compareTo(Key o){
  return 0;
}","@Override public int compareTo(Key other){
  ArrayNode node=(ArrayNode)other;
  if (node.size() != this.size()) {
    return 1;
  }
  for (int i=0; i < this.size(); i++) {
    int comp=this.get(i).compareTo(node.get(i));
    if (comp != 0) {
      return comp;
    }
  }
  return 0;
}",0.2261904761904762
55856,"@Override public KeyValuePair<JsonNode,JsonNode> createPair(){
  return new KeyValuePair<JsonNode,JsonNode>(NullNode.getInstance(),new PactJsonObject());
}","@Override public KeyValuePair<JsonNode,JsonNode> createPair(){
  return new KeyValuePair<JsonNode,JsonNode>(NullNode.getInstance(),new ObjectNode());
}",0.9607843137254902
55857,"@Parameters public static List<Object[]> combinations(){
  return Arrays.asList(new Object[][]{{""String_Node_Str"",IntNode.valueOf(42),1},{""String_Node_Str"",IntNode.valueOf(42),1},{""String_Node_Str"",NullNode.getInstance(),1},{""String_Node_Str"",BooleanNode.TRUE,1},{""String_Node_Str"",BooleanNode.FALSE,1},{""String_Node_Str"",DecimalNode.valueOf(BigDecimal.valueOf(42.42)),1},{String.valueOf(""String_Node_Str"" + String.valueOf(Long.valueOf(Integer.MAX_VALUE) + 1) + ""String_Node_Str""),LongNode.valueOf(Long.valueOf(Integer.MAX_VALUE) + 1),1},{String.valueOf(""String_Node_Str"" + BigInteger.valueOf(Long.MAX_VALUE).add(BigInteger.ONE) + ""String_Node_Str""),BigIntegerNode.valueOf(BigInteger.valueOf(Long.MAX_VALUE).add(BigInteger.ONE)),1},{""String_Node_Str"",TextNode.valueOf(""String_Node_Str""),1},{""String_Node_Str"",IntNode.valueOf(23),2},{""String_Node_Str"",new ArrayNode().add(IntNode.valueOf(23)).add(new ArrayNode().add(new ArrayNode().add(IntNode.valueOf(24)).add(IntNode.valueOf(55))).add(IntNode.valueOf(12)).add(IntNode.valueOf(17))),2},{""String_Node_Str"",TextNode.valueOf(""String_Node_Str""),1},{""String_Node_Str"",TextNode.valueOf(""String_Node_Str""),1},{""String_Node_Str"",new ArrayNode().add(IntNode.valueOf(23)).add(new ArrayNode().add(new ArrayNode().add(IntNode.valueOf(24)).add(TextNode.valueOf(""String_Node_Str""))).add(IntNode.valueOf(12)).add(TextNode.valueOf(""String_Node_Str""))),2},{""String_Node_Str"",IntNode.valueOf(42),2},{""String_Node_Str"",new ObjectNode().put(""String_Node_Str"",IntNode.valueOf(42)),1},{""String_Node_Str"",new ObjectNode().put(""String_Node_Str"",new ArrayNode().add(IntNode.valueOf(1)).add(IntNode.valueOf(3)).add(TextNode.valueOf(""String_Node_Str""))).put(""String_Node_Str"",new ObjectNode().put(""String_Node_Str"",IntNode.valueOf(23))),1},{""String_Node_Str"",IntNode.valueOf(5),5}});
}","@Parameters public static List<Object[]> combinations(){
  return Arrays.asList(new Object[][]{{""String_Node_Str"",IntNode.valueOf(42),1},{""String_Node_Str"",IntNode.valueOf(42),1},{""String_Node_Str"",NullNode.getInstance(),1},{""String_Node_Str"",NullNode.getInstance(),1},{""String_Node_Str"",NullNode.getInstance(),2},{""String_Node_Str"",BooleanNode.TRUE,1},{""String_Node_Str"",BooleanNode.FALSE,1},{""String_Node_Str"",DecimalNode.valueOf(BigDecimal.valueOf(42.42)),1},{String.valueOf(""String_Node_Str"" + String.valueOf(Long.valueOf(Integer.MAX_VALUE) + 1) + ""String_Node_Str""),LongNode.valueOf(Long.valueOf(Integer.MAX_VALUE) + 1),1},{String.valueOf(""String_Node_Str"" + BigInteger.valueOf(Long.MAX_VALUE).add(BigInteger.ONE) + ""String_Node_Str""),BigIntegerNode.valueOf(BigInteger.valueOf(Long.MAX_VALUE).add(BigInteger.ONE)),1},{""String_Node_Str"",TextNode.valueOf(""String_Node_Str""),1},{""String_Node_Str"",IntNode.valueOf(23),2},{""String_Node_Str"",new ArrayNode().add(IntNode.valueOf(23)).add(new ArrayNode().add(new ArrayNode().add(IntNode.valueOf(24)).add(IntNode.valueOf(55))).add(IntNode.valueOf(12)).add(IntNode.valueOf(17))),2},{""String_Node_Str"",TextNode.valueOf(""String_Node_Str""),1},{""String_Node_Str"",TextNode.valueOf(""String_Node_Str""),1},{""String_Node_Str"",new ArrayNode().add(IntNode.valueOf(23)).add(new ArrayNode().add(new ArrayNode().add(IntNode.valueOf(24)).add(TextNode.valueOf(""String_Node_Str""))).add(IntNode.valueOf(12)).add(TextNode.valueOf(""String_Node_Str""))),2},{""String_Node_Str"",IntNode.valueOf(42),2},{""String_Node_Str"",new ObjectNode().put(""String_Node_Str"",IntNode.valueOf(42)),1},{""String_Node_Str"",new ObjectNode().put(""String_Node_Str"",NullNode.getInstance()),1},{""String_Node_Str"",new ObjectNode().put(""String_Node_Str"",new ArrayNode().add(IntNode.valueOf(1)).add(IntNode.valueOf(3)).add(TextNode.valueOf(""String_Node_Str""))).put(""String_Node_Str"",new ObjectNode().put(""String_Node_Str"",IntNode.valueOf(23))),1},{""String_Node_Str"",NullNode.getInstance(),5}});
}",0.8859626020542534
55858,"public void restartExecution(){
  this.restarting=true;
  changeExecutionState(ExecutionState.RESTARTING,null);
  LOG.info(""String_Node_Str"" + this.taskName);
  this.isCanceled=true;
  if (this.executingThread == null) {
    LOG.error(""String_Node_Str"" + this.taskName + ""String_Node_Str"");
    return;
  }
  try {
    this.invokable.cancel();
  }
 catch (  Exception e) {
    LOG.error(StringUtils.stringifyException(e));
  }
  while (this.isCanceled) {
    this.executingThread.interrupt();
  }
  LOG.info(""String_Node_Str"");
  this.isCanceled=false;
  this.executingThread=new Thread(this,this.taskName);
  this.executingThread.start();
  return;
}","public void restartExecution(){
  this.restarting=true;
  changeExecutionState(ExecutionState.RESTARTING,null);
  LOG.info(""String_Node_Str"" + this.taskName);
  this.isCanceled=true;
  if (this.executingThread == null) {
    LOG.error(""String_Node_Str"" + this.taskName + ""String_Node_Str"");
    return;
  }
  try {
    this.invokable.cancel();
  }
 catch (  Exception e) {
    LOG.error(StringUtils.stringifyException(e));
  }
  while (this.isCanceled) {
    this.executingThread.interrupt();
  }
  LOG.info(""String_Node_Str"");
  System.out.println(""String_Node_Str"");
  this.isCanceled=false;
  this.executingThread=new Thread(this,this.taskName);
  this.executingThread.start();
  return;
}",0.9694713328369322
55859,"public void changeExecutionState(final ExecutionState newExecutionState,final String optionalMessage){
  if (this.executionState == ExecutionState.CANCELED || this.executionState == ExecutionState.FINISHED) {
    return;
  }
  if (this.executionState == ExecutionState.RESTARTING && newExecutionState == ExecutionState.CANCELED) {
    this.isCanceled=false;
    return;
  }
  LOG.info(""String_Node_Str"" + executionState + ""String_Node_Str""+ newExecutionState+ ""String_Node_Str""+ this.getTaskName()+ ""String_Node_Str""+ (this.getIndexInSubtaskGroup() + 1)+ ""String_Node_Str""+ this.getCurrentNumberOfSubtasks()+ ""String_Node_Str"");
  boolean unexpectedStateChange=true;
  if (this.executionState == ExecutionState.CREATED && newExecutionState == ExecutionState.SCHEDULED) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.SCHEDULED && newExecutionState == ExecutionState.ASSIGNING) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.ASSIGNING && newExecutionState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.ASSIGNED && newExecutionState == ExecutionState.READY) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.READY && newExecutionState == ExecutionState.RUNNING) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.RUNNING && newExecutionState == ExecutionState.FINISHING) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.FINISHING && newExecutionState == ExecutionState.FINISHED) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.SCHEDULED && newExecutionState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.SCHEDULED && newExecutionState == ExecutionState.CANCELED) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.ASSIGNING && newExecutionState == ExecutionState.CANCELED) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.ASSIGNED && newExecutionState == ExecutionState.CANCELED) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.READY && newExecutionState == ExecutionState.CANCELED) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.RUNNING && newExecutionState == ExecutionState.FAILED) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.FINISHING && newExecutionState == ExecutionState.FAILED) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.RUNNING && newExecutionState == ExecutionState.CANCELING) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.FINISHING && newExecutionState == ExecutionState.CANCELING) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.CANCELING && newExecutionState == ExecutionState.CANCELED) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.RUNNING && newExecutionState == ExecutionState.RESTARTING) {
    unexpectedStateChange=false;
  }
  if (unexpectedStateChange) {
    LOG.error(""String_Node_Str"" + this.executionState + ""String_Node_Str""+ newExecutionState);
  }
  if (this.restarting && newExecutionState == ExecutionState.RUNNING) {
    this.restarting=false;
  }
  this.executionState=newExecutionState;
synchronized (this.executionListeners) {
    final Iterator<ExecutionListener> it=this.executionListeners.iterator();
    while (it.hasNext()) {
      it.next().executionStateChanged(this,newExecutionState,optionalMessage);
    }
  }
}","public void changeExecutionState(final ExecutionState newExecutionState,final String optionalMessage){
  if (this.executionState == ExecutionState.CANCELED || this.executionState == ExecutionState.FINISHED) {
    return;
  }
  if (this.executionState == ExecutionState.RESTARTING && newExecutionState == ExecutionState.CANCELED) {
    this.isCanceled=false;
    return;
  }
  LOG.info(""String_Node_Str"" + executionState + ""String_Node_Str""+ newExecutionState+ ""String_Node_Str""+ this.getTaskName()+ ""String_Node_Str""+ (this.getIndexInSubtaskGroup() + 1)+ ""String_Node_Str""+ this.getCurrentNumberOfSubtasks()+ ""String_Node_Str"");
  boolean unexpectedStateChange=true;
  if (this.executionState == ExecutionState.CREATED && newExecutionState == ExecutionState.SCHEDULED) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.SCHEDULED && newExecutionState == ExecutionState.ASSIGNING) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.ASSIGNING && newExecutionState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.ASSIGNED && newExecutionState == ExecutionState.READY) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.READY && newExecutionState == ExecutionState.RUNNING) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.RUNNING && newExecutionState == ExecutionState.FINISHING) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.FINISHING && newExecutionState == ExecutionState.FINISHED) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.SCHEDULED && newExecutionState == ExecutionState.ASSIGNED) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.SCHEDULED && newExecutionState == ExecutionState.CANCELED) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.ASSIGNING && newExecutionState == ExecutionState.CANCELED) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.ASSIGNED && newExecutionState == ExecutionState.CANCELED) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.READY && newExecutionState == ExecutionState.CANCELED) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.RUNNING && newExecutionState == ExecutionState.FAILED) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.FINISHING && newExecutionState == ExecutionState.FAILED) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.RUNNING && newExecutionState == ExecutionState.CANCELING) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.FINISHING && newExecutionState == ExecutionState.CANCELING) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.CANCELING && newExecutionState == ExecutionState.CANCELED) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.RUNNING && newExecutionState == ExecutionState.RESTARTING) {
    unexpectedStateChange=false;
  }
  if (this.executionState == ExecutionState.RESTARTING && newExecutionState == ExecutionState.RUNNING) {
    unexpectedStateChange=false;
  }
  if (unexpectedStateChange) {
    LOG.error(""String_Node_Str"" + this.executionState + ""String_Node_Str""+ newExecutionState);
  }
  if (this.restarting && newExecutionState == ExecutionState.RUNNING) {
    this.restarting=false;
  }
  this.executionState=newExecutionState;
synchronized (this.executionListeners) {
    final Iterator<ExecutionListener> it=this.executionListeners.iterator();
    while (it.hasNext()) {
      it.next().executionStateChanged(this,newExecutionState,optionalMessage);
    }
  }
}",0.9812268640930724
55860,"/** 
 * Reads data from the given byte channel and deserializes an object of type <code>T</code> from it.
 * @param readableByteChannel the byte channel to read data from
 * @return an object of type <code>T</code>
 * @throws IOException thrown if an error occurs while reading the data or deserializing the object
 */
public T readData(final ReadableByteChannel readableByteChannel) throws IOException {
  if (this.recordLength < 0) {
    if (readableByteChannel.read(this.lengthBuf) == -1 && this.propagateEndOfStream) {
      if (this.lengthBuf.position() == 0) {
        throw new EOFException();
      }
 else {
        throw new IOException(""String_Node_Str"" + this.lengthBuf.remaining() + ""String_Node_Str"");
      }
    }
    if (this.lengthBuf.hasRemaining()) {
      return null;
    }
    this.recordLength=byteArrayToInt(this.lengthBuf.array());
    if (this.tempBuffer == null) {
      this.tempBuffer=ByteBuffer.allocate(this.recordLength);
    }
    if (this.tempBuffer.capacity() < this.recordLength) {
      this.tempBuffer=ByteBuffer.allocate(this.recordLength);
    }
    this.tempBuffer.position(0);
    this.tempBuffer.limit(this.recordLength);
  }
  if (readableByteChannel.read(tempBuffer) == -1 && this.propagateEndOfStream) {
    throw new IOException(""String_Node_Str"" + this.tempBuffer.remaining() + ""String_Node_Str"");
  }
  if (this.tempBuffer.hasRemaining()) {
    return null;
  }
  this.deserializationBuffer.reset(this.tempBuffer.array(),this.recordLength);
  final T record=deserializer.deserialize(this.deserializationBuffer);
  this.recordLength=-1;
  this.lengthBuf.clear();
  return record;
}","/** 
 * Reads data from the given byte channel and deserializes an object of type <code>T</code> from it.
 * @param readableByteChannel the byte channel to read data from
 * @return an object of type <code>T</code>
 * @throws IOException thrown if an error occurs while reading the data or deserializing the object
 */
public T readData(final ReadableByteChannel readableByteChannel) throws IOException {
  if (this.recordLength < 0) {
    if (readableByteChannel.read(this.lengthBuf) == -1 && this.propagateEndOfStream) {
      if (this.lengthBuf.position() == 0) {
        throw new EOFException();
      }
 else {
        throw new IOException(""String_Node_Str"" + this.lengthBuf.remaining() + ""String_Node_Str"");
      }
    }
    if (this.lengthBuf.hasRemaining()) {
      return null;
    }
    this.recordLength=byteArrayToInt(this.lengthBuf.array());
    if (this.tempBuffer == null) {
      this.tempBuffer=ByteBuffer.allocate(this.recordLength);
    }
    if (this.tempBuffer.capacity() < this.recordLength) {
      this.tempBuffer=ByteBuffer.allocate(this.recordLength);
    }
    this.tempBuffer.position(0);
    this.tempBuffer.limit(this.recordLength);
  }
  long read=readableByteChannel.read(this.tempBuffer);
  if (read == -1 && this.propagateEndOfStream) {
    throw new IOException(""String_Node_Str"" + this.tempBuffer.remaining() + ""String_Node_Str"");
  }
  if (read == -1) {
    System.out.println(""String_Node_Str"");
    while (read == -1 && !this.propagateEndOfStream) {
      read=readableByteChannel.read(this.tempBuffer);
      try {
        Thread.sleep(20000);
      }
 catch (      InterruptedException e) {
        e.printStackTrace();
        break;
      }
    }
  }
  if (this.tempBuffer.hasRemaining()) {
    return null;
  }
  this.deserializationBuffer.reset(this.tempBuffer.array(),this.recordLength);
  final T record=this.deserializer.deserialize(this.deserializationBuffer);
  this.recordLength=-1;
  this.lengthBuf.clear();
  return record;
}",0.8950429243976737
55861,"/** 
 * {@inheritDoc}
 */
@Override public void resourceAllocated(final JobID jobID,final AllocatedResource allocatedResource){
  if (allocatedResource == null) {
    LOG.error(""String_Node_Str"");
    return;
  }
  if (allocatedResource.getInstance() instanceof DummyInstance) {
    LOG.debug(""String_Node_Str"");
    return;
  }
synchronized (this.jobQueue) {
    final ExecutionGraph eg=getExecutionGraphByID(jobID);
    if (eg == null) {
      try {
        getInstanceManager().releaseAllocatedResource(jobID,null,allocatedResource);
      }
 catch (      InstanceException e) {
        LOG.error(e);
      }
      return;
    }
    final int indexOfCurrentStage=eg.getIndexOfCurrentExecutionStage();
    AllocatedResource resourceToBeReplaced=null;
    ExecutionGraphIterator it=new ExecutionGraphIterator(eg,indexOfCurrentStage,true,true);
    while (it.hasNext()) {
      final ExecutionVertex vertex=it.next();
      if (vertex.getExecutionState() == ExecutionState.ASSIGNING && vertex.getAllocatedResource() != null) {
        if (vertex.getAllocatedResource().getInstanceType().equals(allocatedResource.getInstanceType())) {
          resourceToBeReplaced=vertex.getAllocatedResource();
          break;
        }
      }
    }
    if (resourceToBeReplaced == null) {
      LOG.warn(""String_Node_Str"" + allocatedResource.getInstance() + ""String_Node_Str""+ eg.getJobID());
      try {
        getInstanceManager().releaseAllocatedResource(jobID,eg.getJobConfiguration(),allocatedResource);
      }
 catch (      InstanceException e) {
        LOG.error(e);
      }
      return;
    }
    it=new ExecutionGraphIterator(eg,true);
    while (it.hasNext()) {
      final ExecutionVertex vertex=it.next();
      if (vertex.getAllocatedResource().equals(resourceToBeReplaced)) {
        vertex.setAllocatedResource(allocatedResource);
        vertex.setExecutionState(ExecutionState.ASSIGNED);
      }
    }
    deployAssignedVertices(eg);
  }
}","/** 
 * {@inheritDoc}
 */
@Override public void resourceAllocated(final JobID jobID,final AllocatedResource allocatedResource){
  if (allocatedResource == null) {
    LOG.error(""String_Node_Str"");
    return;
  }
  if (allocatedResource.getInstance() instanceof DummyInstance) {
    LOG.debug(""String_Node_Str"");
    return;
  }
synchronized (this.jobQueue) {
    final ExecutionGraph eg=getExecutionGraphByID(jobID);
    if (eg == null) {
      try {
        getInstanceManager().releaseAllocatedResource(jobID,null,allocatedResource);
      }
 catch (      InstanceException e) {
        LOG.error(e);
      }
      return;
    }
    final int indexOfCurrentStage=eg.getIndexOfCurrentExecutionStage();
    AllocatedResource resourceToBeReplaced=null;
    ExecutionGraphIterator it=new ExecutionGraphIterator(eg,indexOfCurrentStage,true,true);
    while (it.hasNext()) {
      final ExecutionVertex vertex=it.next();
      if (vertex.getExecutionState() == ExecutionState.ASSIGNING && vertex.getAllocatedResource() != null) {
        if (vertex.getAllocatedResource().getInstanceType().equals(allocatedResource.getInstanceType())) {
          resourceToBeReplaced=vertex.getAllocatedResource();
          break;
        }
      }
    }
    if (resourceToBeReplaced == null) {
      LOG.warn(""String_Node_Str"" + allocatedResource.getInstance() + ""String_Node_Str""+ eg.getJobID());
      try {
        getInstanceManager().releaseAllocatedResource(jobID,eg.getJobConfiguration(),allocatedResource);
      }
 catch (      InstanceException e) {
        LOG.error(e);
      }
      return;
    }
    it=new ExecutionGraphIterator(eg,true);
    while (it.hasNext()) {
      final ExecutionVertex vertex=it.next();
      if (vertex.getAllocatedResource().equals(resourceToBeReplaced)) {
        System.out.println(""String_Node_Str"" + allocatedResource.getInstance().getName());
        vertex.setAllocatedResource(allocatedResource);
        vertex.setExecutionState(ExecutionState.ASSIGNED);
      }
    }
    deployAssignedVertices(eg);
  }
}",0.9771758214196138
55862,"/** 
 * Returns the number of successors, i.e. the number of vertices this vertex is connected to.
 * @return the number of successors
 */
public synchronized int getNumberOfSuccessors(){
  int numberOfSuccessors=0;
  LOG.info(this.environment.getNumberOfOutputGates());
  for (int i=0; i < this.environment.getNumberOfOutputGates(); i++) {
    LOG.info(this.environment.getOutputGate(i).getNumberOfOutputChannels());
    numberOfSuccessors+=this.environment.getOutputGate(i).getNumberOfOutputChannels();
  }
  return numberOfSuccessors;
}","/** 
 * Returns the number of successors, i.e. the number of vertices this vertex is connected to.
 * @return the number of successors
 */
public synchronized int getNumberOfSuccessors(){
  int numberOfSuccessors=0;
  for (int i=0; i < this.environment.getNumberOfOutputGates(); i++) {
    numberOfSuccessors+=this.environment.getOutputGate(i).getNumberOfOutputChannels();
  }
  return numberOfSuccessors;
}",0.8604651162790697
55863,"/** 
 */
public void recover(ChannelID sourceChannelID){
  try {
    getTaskManager().recover(sourceChannelID);
  }
 catch (  IOException e) {
    e.printStackTrace();
  }
}","/** 
 * recovers the given channel
 */
public void recover(ChannelID sourceChannelID){
  try {
    getTaskManager().recover(sourceChannelID);
  }
 catch (  IOException e) {
    e.printStackTrace();
  }
}",0.9202127659574468
55864,"@Override public void rewind(){
  this.byteBuffer.rewind();
}","@Override public void rewind(){
  this.byteBuffer.position(0);
}",0.912
55865,"/** 
 * {@inheritDoc}
 */
@Override public void vertexAssignmentChanged(ExecutionVertexID id,AllocatedResource newAllocatedResource){
  final ManagementVertexID managementVertexID=id.toManagementVertexID();
  final long timestamp=System.currentTimeMillis();
  final AbstractInstance instance=newAllocatedResource.getInstance();
  VertexAssignmentEvent event;
  if (instance == null) {
    event=new VertexAssignmentEvent(timestamp,managementVertexID,""String_Node_Str"",""String_Node_Str"");
  }
 else {
    event=new VertexAssignmentEvent(timestamp,managementVertexID,instance.getName(),instance.getType().getIdentifier());
  }
  this.eventCollector.updateManagementGraph(jobID,event);
  this.eventCollector.addEvent(this.jobID,event);
}","/** 
 * {@inheritDoc}
 */
@Override public void vertexAssignmentChanged(ExecutionVertexID id,AllocatedResource newAllocatedResource){
  final ManagementVertexID managementVertexID=id.toManagementVertexID();
  final long timestamp=System.currentTimeMillis();
  final AbstractInstance instance=newAllocatedResource.getInstance();
  VertexAssignmentEvent event;
  if (instance == null) {
    event=new VertexAssignmentEvent(timestamp,managementVertexID,""String_Node_Str"",""String_Node_Str"");
  }
 else {
    event=new VertexAssignmentEvent(timestamp,managementVertexID,instance.getName(),instance.getType().getIdentifier());
  }
  this.eventCollector.updateManagementGraph(this.jobID,event);
  this.eventCollector.addEvent(this.jobID,event);
}",0.9966055668703326
55866,"/** 
 * {@inheritDoc}
 */
@Override public ConnectionInfoLookupResponse lookupConnectionInfo(JobID jobID,ChannelID sourceChannelID){
  final ExecutionGraph eg=this.scheduler.getExecutionGraphByID(jobID);
  if (eg == null) {
    LOG.error(""String_Node_Str"" + jobID);
    return ConnectionInfoLookupResponse.createReceiverNotFound();
  }
  AbstractChannel sourceChannel=eg.getOutputChannelByID(sourceChannelID);
  if (sourceChannel == null) {
    sourceChannel=eg.getInputChannelByID(sourceChannelID);
    if (sourceChannel == null) {
      LOG.error(""String_Node_Str"" + sourceChannelID);
      return ConnectionInfoLookupResponse.createReceiverNotFound();
    }
  }
  final ChannelID targetChannelID=sourceChannel.getConnectedChannelID();
  final ExecutionVertex vertex=eg.getVertexByChannelID(targetChannelID);
  if (vertex == null) {
    LOG.error(""String_Node_Str"" + targetChannelID + ""String_Node_Str""+ jobID);
    return ConnectionInfoLookupResponse.createReceiverNotFound();
  }
  final ExecutionState executionState=vertex.getExecutionState();
  if (executionState != ExecutionState.RUNNING && executionState != ExecutionState.FINISHING) {
    return ConnectionInfoLookupResponse.createReceiverNotReady();
  }
  final AbstractInstance assignedInstance=vertex.getAllocatedResource().getInstance();
  if (assignedInstance == null) {
    LOG.debug(""String_Node_Str"" + targetChannelID + ""String_Node_Str"");
    return ConnectionInfoLookupResponse.createReceiverNotReady();
  }
  return ConnectionInfoLookupResponse.createReceiverFoundAndReady(assignedInstance.getInstanceConnectionInfo());
}","/** 
 * {@inheritDoc}
 */
@Override public ConnectionInfoLookupResponse lookupConnectionInfo(JobID jobID,ChannelID sourceChannelID){
  final ExecutionGraph eg=this.scheduler.getExecutionGraphByID(jobID);
  if (eg == null) {
    LOG.error(""String_Node_Str"" + jobID);
    return ConnectionInfoLookupResponse.createReceiverNotFound();
  }
  AbstractChannel sourceChannel=eg.getOutputChannelByID(sourceChannelID);
  if (sourceChannel == null) {
    sourceChannel=eg.getInputChannelByID(sourceChannelID);
    if (sourceChannel == null) {
      LOG.error(""String_Node_Str"" + sourceChannelID);
      return ConnectionInfoLookupResponse.createReceiverNotFound();
    }
  }
  final ChannelID targetChannelID=sourceChannel.getConnectedChannelID();
  final ExecutionVertex vertex=eg.getVertexByChannelID(targetChannelID);
  if (vertex == null) {
    LOG.error(""String_Node_Str"" + targetChannelID + ""String_Node_Str""+ jobID);
    return ConnectionInfoLookupResponse.createReceiverNotFound();
  }
  final ExecutionState executionState=vertex.getExecutionState();
  if (executionState != ExecutionState.RUNNING && executionState != ExecutionState.FINISHING) {
    return ConnectionInfoLookupResponse.createReceiverNotReady();
  }
  final AbstractInstance assignedInstance=vertex.getAllocatedResource().getInstance();
  if (assignedInstance == null) {
    LOG.debug(""String_Node_Str"" + targetChannelID + ""String_Node_Str"");
    return ConnectionInfoLookupResponse.createReceiverNotReady();
  }
  LOG.info(""String_Node_Str"" + assignedInstance.getName());
  return ConnectionInfoLookupResponse.createReceiverFoundAndReady(assignedInstance.getInstanceConnectionInfo());
}",0.9685767097966728
55867,"/** 
 * {@inheritDoc}
 */
@Override public void run(){
  LOG.info(""String_Node_Str"");
  if (this.failedVertices.isEmpty()) {
    LOG.error(""String_Node_Str"");
  }
  Iterator<ExecutionVertex> vertexIter=this.failedVertices.iterator();
  while (vertexIter.hasNext()) {
    ExecutionVertex failed=vertexIter.next();
    LOG.info(""String_Node_Str"" + failed);
    List<ExecutionVertex> restart=findRestarts(failed);
    if (restart.size() < 2) {
      LOG.info(""String_Node_Str"");
    }
 else {
      LOG.info(restart.size());
    }
    Iterator<ExecutionVertex> restartIterator=restart.iterator();
    while (restartIterator.hasNext()) {
      ExecutionVertex vertex=restartIterator.next();
      if (!vertex.equals(failed)) {
        LOG.info(""String_Node_Str"");
        LOG.info(""String_Node_Str"" + vertex.getName());
        vertex.getAllocatedResource().getInstance().restart(vertex.getID(),job.getJobConfiguration());
        LOG.info(""String_Node_Str"");
      }
    }
    Iterator<ExecutionVertex> checkpointIterator=this.globalConsistentCheckpoint.iterator();
    while (checkpointIterator.hasNext()) {
      ExecutionVertex checkpoint=checkpointIterator.next();
      AbstractInstance instance=checkpoint.getAllocatedResource().getInstance();
      instance.recoverAll(checkpoint.getEnvironment().getOutputGate(0).getOutputChannel(0).getID());
    }
    LOG.info(""String_Node_Str"" + failed);
  }
  this.job.executionStateChanged(null,ExecutionState.RERUNNING,null);
  LOG.info(""String_Node_Str"");
}","/** 
 * {@inheritDoc}
 */
@Override public void run(){
  LOG.info(""String_Node_Str"");
  if (this.failedVertices.isEmpty()) {
    LOG.error(""String_Node_Str"");
  }
  Iterator<ExecutionVertex> vertexIter=this.failedVertices.iterator();
  while (vertexIter.hasNext()) {
    ExecutionVertex failed=vertexIter.next();
    LOG.info(""String_Node_Str"" + failed);
    List<ExecutionVertex> restart=findRestarts(failed);
    if (restart.size() < 2) {
      LOG.info(""String_Node_Str"");
    }
 else {
      LOG.info(restart.size());
    }
    Iterator<ExecutionVertex> restartIterator=restart.iterator();
    while (restartIterator.hasNext()) {
      ExecutionVertex vertex=restartIterator.next();
      if (!vertex.equals(failed)) {
        LOG.info(""String_Node_Str"");
        LOG.info(""String_Node_Str"" + vertex.getName());
        try {
          vertex.getAllocatedResource().getInstance().restart(vertex.getID(),job.getJobConfiguration());
        }
 catch (        Exception e) {
          LOG.info(""String_Node_Str"" + StringUtils.stringifyException(e) + ""String_Node_Str"");
        }
        System.out.println(""String_Node_Str"" + vertex.getName());
        LOG.info(""String_Node_Str"");
      }
    }
    Iterator<ExecutionVertex> checkpointIterator=this.globalConsistentCheckpoint.iterator();
    while (checkpointIterator.hasNext()) {
      ExecutionVertex checkpoint=checkpointIterator.next();
      AbstractInstance instance=checkpoint.getAllocatedResource().getInstance();
      instance.recoverAll(checkpoint.getEnvironment().getOutputGate(0).getOutputChannel(0).getID());
    }
    LOG.info(""String_Node_Str"" + failed);
  }
  this.job.executionStateChanged(null,ExecutionState.RERUNNING,null);
  LOG.info(""String_Node_Str"");
}",0.9294554455445544
55868,"/** 
 */
void recoverAll(ChannelID sourceChannelID);","/** 
 * @param sourceChannelID
 * @param address
 */
void recoverAll(ChannelID sourceChannelID);",0.7027027027027027
55869,"/** 
 */
void recover(ChannelID sourceChannelID);","/** 
 * @param sourceChannelID
 * @param instanceConnectionInfo
 */
void recover(ChannelID sourceChannelID);",0.6242038216560509
55870,"public void recoverAll(ChannelID sourceChannelID){
  this.checkpointManager.recoverAllChannelCheckpoints(sourceChannelID);
}","@Override public void recoverAll(ChannelID sourceChannelID){
  this.checkpointManager.recoverAllChannelCheckpoints(sourceChannelID);
}",0.9612403100775194
55871,"@Override public void restart(ExecutionVertexID executionVertexID,Configuration jobConfiguration){
  Environment ee=this.runningTasks.remove(executionVertexID);
  ee.restartExecution();
  for (int i=0; i < ee.getNumberOfInputGates(); i++) {
    InputGate<? extends Record> ingate=ee.getInputGate(i);
    for (int j=0; j < ingate.getNumberOfInputChannels(); j++) {
      this.byteBufferedChannelManager.clear(ingate.getInputChannel(j).getID());
    }
  }
  for (int i=0; i < ee.getNumberOfOutputGates(); i++) {
    OutputGate<? extends Record> outgate=ee.getOutputGate(i);
    for (int j=0; j < outgate.getNumberOfOutputChannels(); j++) {
      this.byteBufferedChannelManager.clear(outgate.getOutputChannel(j).getID());
    }
  }
}","@Override public void restart(ExecutionVertexID executionVertexID,Configuration jobConfiguration){
  Environment ee=this.runningTasks.remove(executionVertexID);
  ee.restartExecution();
  for (int i=0; i < ee.getNumberOfInputGates(); i++) {
    InputGate<? extends Record> ingate=ee.getInputGate(i);
    for (int j=0; j < ingate.getNumberOfInputChannels(); j++) {
      if (!(ingate.getInputChannel(j) instanceof FileInputChannel<?>)) {
        this.byteBufferedChannelManager.clear(ingate.getInputChannel(j).getID());
      }
    }
  }
  for (int i=0; i < ee.getNumberOfOutputGates(); i++) {
    OutputGate<? extends Record> outgate=ee.getOutputGate(i);
    for (int j=0; j < outgate.getNumberOfOutputChannels(); j++) {
      this.byteBufferedChannelManager.clear(outgate.getOutputChannel(j).getID());
    }
  }
}",0.9462783171521036
55872,"/** 
 * @param 
 */
public void clear(ChannelID channelID){
  ByteBufferedChannelWrapper wrapper=this.registeredChannels.get(channelID);
  wrapper.clear();
}","/** 
 * @param 
 */
public void clear(ChannelID channelID){
  ByteBufferedChannelWrapper wrapper=this.registeredChannels.get(channelID);
  wrapper.clear();
  this.incomingConnectionThread.clear();
}",0.8845070422535212
55873,"/** 
 * @param byteBufferedChannelManager
 * @param fileInputChannel
 * @param sourceChannelID 
 * @return CheckpointOutgoingConnection
 */
public CheckpointOutgoingConnection createOutgoingCheckpointConnection(ByteBufferedChannelManager byteBufferedChannelManager,FileChannel fileInputChannel,ChannelID sourceChannelID){
  try {
    final InetSocketAddress connectionAddress=getPeerConnectionAddress(sourceChannelID);
    OutgoingConnectionThread connectionThread=new OutgoingConnectionThread();
    CheckpointOutgoingConnection outgoingConnection=new CheckpointOutgoingConnection(this,connectionAddress,connectionThread,10,fileInputChannel);
    this.outgoingConnections.put(connectionAddress,outgoingConnection);
    return outgoingConnection;
  }
 catch (  InterruptedException e) {
    e.printStackTrace();
  }
catch (  IOException e) {
    e.printStackTrace();
  }
  return null;
}","/** 
 * @param byteBufferedChannelManager
 * @param fileInputChannel
 * @param sourceChannelID 
 * @param address 
 * @return CheckpointOutgoingConnection
 */
public CheckpointOutgoingConnection createOutgoingCheckpointConnection(ByteBufferedChannelManager byteBufferedChannelManager,FileChannel fileInputChannel,ChannelID sourceChannelID){
  try {
    final InetSocketAddress connectionAddress=getPeerConnectionAddress(sourceChannelID);
    OutgoingConnectionThread connectionThread=new OutgoingConnectionThread();
    connectionThread.start();
    CheckpointOutgoingConnection outgoingConnection=new CheckpointOutgoingConnection(this,connectionAddress,connectionThread,10,fileInputChannel);
    this.outgoingConnections.put(connectionAddress,outgoingConnection);
    return outgoingConnection;
  }
 catch (  IOException e) {
    e.printStackTrace();
  }
catch (  InterruptedException e) {
    e.printStackTrace();
  }
  return null;
}",0.9610532089961602
55874,"public void clear(){
  releaseAllResources();
  this.nextExpectedSequenceNumber=0;
}","public void clear(){
  releaseAllResources();
  this.nextExpectedSequenceNumber=0;
  this.byteBufferedInputChannel.clear();
}",0.8038277511961722
55875,"/** 
 * Called by the attached output channel wrapper to forward a   {@link TransferEnvelope} objectto its final destination. Within this method the provided transfer envelope is possibly also forwarded to the assigned ephemeral checkpoint.
 * @param channelWrapper the channel wrapper which called this method
 * @param outgoingTransferEnvelope the transfer envelope to be forwarded
 * @throws IOException thrown if an I/O error occurs while processing the envelope
 * @throws InterruptedException thrown if the thread is interrupted while waiting for the envelope to be processed
 */
public void processEnvelope(ByteBufferedOutputChannelWrapper channelWrapper,TransferEnvelope outgoingTransferEnvelope) throws IOException, InterruptedException {
  final TransferEnvelopeProcessingLog processingLog=outgoingTransferEnvelope.getProcessingLog();
  if (this.ephemeralCheckpoint != null && processingLog.mustBeWrittenToCheckpoint()) {
    this.ephemeralCheckpoint.addTransferEnvelope(outgoingTransferEnvelope);
    final EventList eventList=outgoingTransferEnvelope.getEventList();
    if (!eventList.isEmpty()) {
      final Iterator<AbstractEvent> it=eventList.iterator();
      while (it.hasNext()) {
        if (it.next() instanceof ByteBufferedChannelCloseEvent) {
          this.ephemeralCheckpoint.markChannelAsFinished(outgoingTransferEnvelope.getSource());
          if (this.ephemeralCheckpoint.isPersistent()) {
            channelWrapper.processEvent(new ByteBufferedChannelCloseEvent());
          }
          break;
        }
      }
    }
  }
  if (processingLog.mustBeSentViaNetwork() && !processingLog.isSentViaNetwork()) {
    this.byteBufferedChannelManager.queueOutgoingTransferEnvelope(outgoingTransferEnvelope);
  }
  if (outgoingTransferEnvelope.getBuffer() != null) {
    this.channelsWithWriteBuffers.remove(channelWrapper);
  }
}","/** 
 * Called by the attached output channel wrapper to forward a   {@link TransferEnvelope} objectto its final destination. Within this method the provided transfer envelope is possibly also forwarded to the assigned ephemeral checkpoint.
 * @param channelWrapper the channel wrapper which called this method
 * @param outgoingTransferEnvelope the transfer envelope to be forwarded
 * @throws IOException thrown if an I/O error occurs while processing the envelope
 * @throws InterruptedException thrown if the thread is interrupted while waiting for the envelope to be processed
 */
public void processEnvelope(ByteBufferedOutputChannelWrapper channelWrapper,TransferEnvelope outgoingTransferEnvelope) throws IOException, InterruptedException {
  final TransferEnvelopeProcessingLog processingLog=outgoingTransferEnvelope.getProcessingLog();
  if (this.ephemeralCheckpoint != null && processingLog.mustBeWrittenToCheckpoint()) {
    this.ephemeralCheckpoint.addTransferEnvelope(outgoingTransferEnvelope);
    final EventList eventList=outgoingTransferEnvelope.getEventList();
    if (!eventList.isEmpty()) {
      final Iterator<AbstractEvent> it=eventList.iterator();
      while (it.hasNext()) {
        if (it.next() instanceof ByteBufferedChannelCloseEvent && this.commonChannelType == ChannelType.FILE) {
          ;
          System.out.println(""String_Node_Str"" + outgoingTransferEnvelope.getSequenceNumber() + ""String_Node_Str""+ outgoingTransferEnvelope.getSource());
          this.ephemeralCheckpoint.markChannelAsFinished(outgoingTransferEnvelope.getSource(),outgoingTransferEnvelope.getSequenceNumber());
          if (this.ephemeralCheckpoint.isPersistent() && this.commonChannelType == ChannelType.FILE) {
            channelWrapper.processEvent(new ByteBufferedChannelCloseEvent());
          }
          break;
        }
      }
    }
  }
  if (processingLog.mustBeSentViaNetwork() && !processingLog.isSentViaNetwork()) {
    this.byteBufferedChannelManager.queueOutgoingTransferEnvelope(outgoingTransferEnvelope);
  }
  if (outgoingTransferEnvelope.getBuffer() != null) {
    this.channelsWithWriteBuffers.remove(channelWrapper);
  }
}",0.9243823309208884
55876,"public void clear(){
  if (this.outgoingTransferEnvelope != null) {
    this.outgoingTransferEnvelope.getProcessingLog().setSentViaNetwork();
    this.outgoingTransferEnvelope=null;
  }
  this.sequenceNumber=0;
  if (this.uncompressedDataBuffer != null) {
    this.uncompressedDataBuffer.recycleBuffer();
  }
}","public void clear(){
  if (this.outgoingTransferEnvelope != null) {
    this.outgoingTransferEnvelope.getProcessingLog().setSentViaNetwork();
    this.outgoingTransferEnvelope=null;
  }
  this.sequenceNumber=0;
  if (this.uncompressedDataBuffer != null) {
    this.uncompressedDataBuffer.getInternalBuffer().recycleBuffer();
  }
}",0.96875
55877,"private long byteBufferToLong(final ByteBuffer byteBuffer) throws IOException {
  long l=0;
  if (SIZEOFLONG > byteBuffer.limit()) {
    throw new IOException(""String_Node_Str"" + byteBuffer.limit() + ""String_Node_Str"");
  }
  for (int i=0; i < SIZEOFLONG; ++i) {
    l|=(byteBuffer.get((SIZEOFLONG - 1) - i) & 0xff) << (i << 3);
  }
  return l;
}","private long byteBufferToLong(final ByteBuffer byteBuffer) throws IOException {
  long l=0;
  if (SIZEOFLONG > byteBuffer.limit()) {
    throw new IOException(""String_Node_Str"" + byteBuffer.limit() + ""String_Node_Str"");
  }
  for (int i=0; i < SIZEOFLONG; ++i) {
    l|=(byteBuffer.get((SIZEOFLONG - 1) - i) & 0xffL) << (i << 3);
  }
  return l;
}",0.9985569985569984
55878,"private void longToByteBuffer(long longToSerialize,ByteBuffer byteBuffer) throws IOException {
  if (SIZEOFLONG > byteBuffer.capacity()) {
    throw new IOException(""String_Node_Str"" + byteBuffer.limit() + ""String_Node_Str""+ SIZEOFLONG+ ""String_Node_Str"");
  }
  byteBuffer.limit(SIZEOFLONG);
  for (int i=0; i < SIZEOFLONG; ++i) {
    final int shift=i << 3;
    byteBuffer.put((SIZEOFLONG - 1) - i,(byte)((longToSerialize & (0xff << shift)) >>> shift));
  }
}","private void longToByteBuffer(long longToSerialize,ByteBuffer byteBuffer) throws IOException {
  if (SIZEOFLONG > byteBuffer.capacity()) {
    throw new IOException(""String_Node_Str"" + byteBuffer.limit() + ""String_Node_Str""+ SIZEOFLONG+ ""String_Node_Str"");
  }
  byteBuffer.limit(SIZEOFLONG);
  for (int i=0; i < SIZEOFLONG; ++i) {
    final int shift=i << 3;
    byteBuffer.put((SIZEOFLONG - 1) - i,(byte)((longToSerialize & (0xffL << shift)) >>> shift));
  }
}",0.9989165763813652
55879,"/** 
 * Checks whether there is a floating instance with the specific type. If there are instances available, they will be removed from the list and returned...
 * @param awsAccessId the access ID into AWS
 * @param awsSecretKey the secret key used to generate signatures for authentication
 * @param type the type of the floating instance, which is checked
 * @return a list of suitable floating instances.
 * @throws InstanceException something wrong happens to the global configuration
 */
private LinkedList<FloatingInstance> anyFloatingInstancesAvailable(final String awsAccessId,final String awsSecretKey,final InstanceType type,final int count) throws InstanceException {
  LOG.info(""String_Node_Str"" + count + ""String_Node_Str""+ type.getIdentifier());
  final LinkedList<FloatingInstance> foundfloatinginstances=new LinkedList<FloatingInstance>();
synchronized (this.floatingInstances) {
    final Iterator<Map.Entry<InstanceConnectionInfo,FloatingInstance>> it=this.floatingInstances.entrySet().iterator();
    while (it.hasNext()) {
      final FloatingInstance i=it.next().getValue();
      if (i.isFromThisOwner(awsAccessId,awsSecretKey)) {
        if (i.getType().equals(type)) {
          it.remove();
          foundfloatinginstances.add(i);
        }
      }
    }
  }
  LOG.info(""String_Node_Str"" + foundfloatinginstances.size() + ""String_Node_Str"");
  return foundfloatinginstances;
}","/** 
 * Checks whether there is a floating instance with the specific type. If there are instances available, they will be removed from the list and returned...
 * @param awsAccessId the access ID into AWS
 * @param awsSecretKey the secret key used to generate signatures for authentication
 * @param type the type of the floating instance, which is checked
 * @return a list of suitable floating instances.
 * @throws InstanceException something wrong happens to the global configuration
 */
private LinkedList<FloatingInstance> anyFloatingInstancesAvailable(final String awsAccessId,final String awsSecretKey,final InstanceType type,final int count) throws InstanceException {
  LOG.info(""String_Node_Str"" + count + ""String_Node_Str""+ type.getIdentifier());
  final LinkedList<FloatingInstance> foundfloatinginstances=new LinkedList<FloatingInstance>();
synchronized (this.floatingInstances) {
    final Iterator<Map.Entry<InstanceConnectionInfo,FloatingInstance>> it=this.floatingInstances.entrySet().iterator();
    while (it.hasNext()) {
      final FloatingInstance i=it.next().getValue();
      if (i.isFromThisOwner(awsAccessId,awsSecretKey)) {
        if (i.getType().equals(type)) {
          it.remove();
          foundfloatinginstances.add(i);
          if (foundfloatinginstances.size() >= count) {
            break;
          }
        }
      }
    }
  }
  LOG.info(""String_Node_Str"" + foundfloatinginstances.size() + ""String_Node_Str"");
  return foundfloatinginstances;
}",0.9699066067104808
55880,"/** 
 * @param pair
 * @param hashCode
 * @throws IOException
 */
protected final void insertIntoTable(final PactRecord record,final int hashCode) throws IOException {
  final int posHashCode=hashCode % this.numBuckets;
  final int bucketArrayPos=posHashCode >> this.bucketsPerSegmentBits;
  final int bucketInSegmentPos=(posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS;
  final MemorySegment bucket=this.buckets[bucketArrayPos];
  final int partitionNumber=bucket.get(bucketInSegmentPos + HEADER_PARTITION_OFFSET);
  if (partitionNumber < 0 || partitionNumber >= this.partitionsBeingBuilt.size()) {
    throw new RuntimeException(""String_Node_Str"");
  }
  final Partition p=this.partitionsBeingBuilt.get(partitionNumber);
  long pointer=p.insertIntoBuildBuffer(record);
  if (pointer == -1) {
    MemorySegment nextSeg=getNextBuffer();
    if (nextSeg == null) {
      spillPartition();
      nextSeg=getNextBuffer();
      if (nextSeg == null) {
        throw new RuntimeException(""String_Node_Str"");
      }
    }
    p.addBuildSideBuffer(nextSeg);
    pointer=p.insertIntoBuildBuffer(record);
    if (pointer == -1) {
      throw new IOException(""String_Node_Str"");
    }
  }
  if (p.isInMemory()) {
    insertBucketEntry(p,bucket,bucketInSegmentPos,hashCode,pointer);
  }
 else {
    return;
  }
}","/** 
 * @param pair
 * @param hashCode
 * @throws IOException
 */
protected final void insertIntoTable(final PactRecord record,final int hashCode) throws IOException {
  final int posHashCode=hashCode % this.numBuckets;
  final int bucketArrayPos=posHashCode >> this.bucketsPerSegmentBits;
  final int bucketInSegmentPos=(posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS;
  final MemorySegment bucket=this.buckets[bucketArrayPos];
  final int partitionNumber=bucket.get(bucketInSegmentPos + HEADER_PARTITION_OFFSET);
  if (partitionNumber < 0 || partitionNumber >= this.partitionsBeingBuilt.size()) {
    throw new RuntimeException(""String_Node_Str"");
  }
  final Partition p=this.partitionsBeingBuilt.get(partitionNumber);
  long pointer=p.insertIntoBuildBuffer(record);
  if (pointer == -1) {
    MemorySegment nextSeg=getNextBuffer();
    if (nextSeg == null) {
      int spilledPartitionNum=spillPartition();
      if (spilledPartitionNum != partitionNumber) {
        nextSeg=getNextBuffer();
        if (nextSeg == null) {
          throw new RuntimeException(""String_Node_Str"");
        }
        p.addBuildSideBuffer(nextSeg);
      }
    }
 else {
      p.addBuildSideBuffer(nextSeg);
    }
    pointer=p.insertIntoBuildBuffer(record);
    if (pointer == -1) {
      throw new IOException(""String_Node_Str"");
    }
  }
  if (p.isInMemory()) {
    insertBucketEntry(p,bucket,bucketInSegmentPos,hashCode,pointer);
  }
 else {
    return;
  }
}",0.940839010397992
55881,"/** 
 * Initializes the PactString to a sub-string of the given PactString. 
 * @param value The string containing the substring.
 * @param offset The offset of the substring.
 * @param len The length of the substring.
 */
public PactString(final PactString value,final int offset,final int len){
  setValue(value,offset,len);
}","/** 
 * Initializes the PactString to a sub-string of the given PactString. 
 * @param value The string containing the substring.
 * @param offset The offset of the substring.
 * @param len The length of the substring.
 */
public PactString(final PactString value,final int offset,final int len){
  this.value=EMPTY_STRING;
  setValue(value,offset,len);
}",0.9604685212298684
55882,"/** 
 * Writes this buffer completely to the given writer.
 * @param writer The writer to write the segment to.
 * @throws IOException Thrown, if the writer caused an I/O exception.
 */
public void writeToChannel(final Writer writer) throws IOException {
  int recordsLeft=this.numRecords;
  int currentMemSeg=0;
  while (recordsLeft > 0) {
    final MemorySegment currentIndexSegment=this.sortIndex.get(currentMemSeg++);
    int offset=0;
    if (recordsLeft >= this.indexEntriesPerSegment) {
      for (; offset <= this.lastIndexEntryOffset; offset+=this.indexEntrySize) {
        final long pointer=currentIndexSegment.getLong(offset);
      }
      recordsLeft-=this.indexEntriesPerSegment;
    }
 else {
      for (; recordsLeft > 0; recordsLeft--, offset+=this.indexEntrySize) {
        final long pointer=currentIndexSegment.getLong(offset);
      }
    }
  }
}","/** 
 * Writes this buffer completely to the given writer.
 * @param writer The writer to write the segment to.
 * @throws IOException Thrown, if the writer caused an I/O exception.
 */
public void writeToChannel(final Writer writer) throws IOException {
  throw new UnsupportedOperationException();
}",0.4499572284003422
55883,"public void setKey(int key){
  this.key=key;
}","public void setKey(int key){
  setValue(key);
}",0.8172043010752689
55884,"public int getKey(){
  return key;
}","public int getKey(){
  return getValue();
}",0.8607594936708861
55885,"public Key(int k){
  key=k;
}","public Key(int k){
  super(k);
}",0.819672131147541
55886,"public int compare(int i,int j){
  final int bufferNumI=i / this.indexEntriesPerSegment;
  final int segmentOffsetI=(i % this.indexEntriesPerSegment) * this.indexEntrySize;
  final int bufferNumJ=j / this.indexEntriesPerSegment;
  final int segmentOffsetJ=(j % this.indexEntriesPerSegment) * this.indexEntrySize;
  final MemorySegment segI=this.sortIndex.get(bufferNumI);
  final MemorySegment segJ=this.sortIndex.get(bufferNumJ);
  final byte[] bI=segI.getBackingArray();
  final byte[] bJ=segJ.getBackingArray();
  int val=0;
  for (int pos=0, posI=segI.translateOffset(segmentOffsetI + OFFSET_LEN), posJ=segJ.translateOffset(segmentOffsetJ + OFFSET_LEN); pos < this.numKeyBytes & (val=(bI[posI] & 0xff) - (bJ[posJ] & 0xff)) == 0; pos++, posI++, posJ++)   ;
  if (val != 0 || this.normalizedKeyFullyDetermines) {
    return val;
  }
  final long pointerI=segI.getLong(segmentOffsetI);
  final long pointerJ=segJ.getLong(segmentOffsetJ);
  return compareRecords(pointerI,pointerJ);
}","public int compare(int i,int j){
  final int bufferNumI=i / this.indexEntriesPerSegment;
  final int segmentOffsetI=(i % this.indexEntriesPerSegment) * this.indexEntrySize;
  final int bufferNumJ=j / this.indexEntriesPerSegment;
  final int segmentOffsetJ=(j % this.indexEntriesPerSegment) * this.indexEntrySize;
  final MemorySegment segI=this.sortIndex.get(bufferNumI);
  final MemorySegment segJ=this.sortIndex.get(bufferNumJ);
  final byte[] bI=segI.getBackingArray();
  final byte[] bJ=segJ.getBackingArray();
  int val=0;
  for (int pos=0, posI=segI.translateOffset(segmentOffsetI + OFFSET_LEN), posJ=segJ.translateOffset(segmentOffsetJ + OFFSET_LEN); pos < this.numKeyBytes && (val=(bI[posI] & 0xff) - (bJ[posJ] & 0xff)) == 0; pos++, posI++, posJ++)   ;
  if (val != 0 || this.normalizedKeyFullyDetermines) {
    return val;
  }
  final long pointerI=segI.getLong(segmentOffsetI);
  final long pointerJ=segJ.getLong(segmentOffsetJ);
  return compareRecords(pointerI,pointerJ);
}",0.999492127983748
55887,"public List<MemorySegment> dispose(){
  this.freeMemory.addAll(this.sortIndex);
  this.freeMemory.addAll(this.recordBuffers);
  this.recordBuffers.clear();
  this.sortIndex.clear();
  return this.freeMemory;
}","/** 
 * Collects all memory segments from this sorter.
 * @return All memory segments from this sorter.
 */
public List<MemorySegment> dispose(){
  this.freeMemory.addAll(this.sortIndex);
  this.freeMemory.addAll(this.recordBuffers);
  this.recordBuffers.clear();
  this.sortIndex.clear();
  return this.freeMemory;
}",0.7946768060836502
55888,"@Test public void testSort() throws Exception {
  final int numSegments=MEMORY_SIZE / MEMORY_SEGMENT_SIZE;
  final List<MemorySegment> memory=this.memoryManager.allocate(new DummyInvokable(),numSegments,MEMORY_SEGMENT_SIZE);
  NormalizedKeySorter<PactRecord> sorter=newSortBuffer(memory);
  TestData.Generator generator=new TestData.Generator(SEED,KEY_MAX,VALUE_LENGTH,KeyMode.RANDOM,ValueMode.RANDOM_LENGTH);
  long writeStart=System.nanoTime();
  PactRecord record=new PactRecord();
  do {
    generator.next(record);
  }
 while (sorter.write(record));
  long writeStop=System.nanoTime();
  System.out.println(""String_Node_Str"" + (writeStop - writeStart) / 1000000 + ""String_Node_Str"");
  long sortStart=System.nanoTime();
  QuickSort qs=new QuickSort();
  qs.sort(sorter);
  long sortStop=System.nanoTime();
  System.out.println(""String_Node_Str"" + (sortStop - sortStart) / 1000000 + ""String_Node_Str"");
  MutableObjectIterator<PactRecord> iter=sorter.getIterator();
  PactRecord readTarget=new PactRecord();
  Key current=new Key();
  Key last=new Key();
  iter.next(readTarget);
  readTarget.getFieldInto(0,last);
  while (iter.next(readTarget)) {
    readTarget.getFieldInto(0,current);
    final int cmp=last.compareTo(current);
    if (cmp > 0)     Assert.fail(""String_Node_Str"");
    Key tmp=current;
    current=last;
    last=tmp;
  }
  this.memoryManager.release(sorter.dispose());
}","@Test public void testSort() throws Exception {
  final int numSegments=MEMORY_SIZE / MEMORY_SEGMENT_SIZE;
  final List<MemorySegment> memory=this.memoryManager.allocate(new DummyInvokable(),numSegments,MEMORY_SEGMENT_SIZE);
  NormalizedKeySorter<PactRecord> sorter=newSortBuffer(memory);
  TestData.Generator generator=new TestData.Generator(SEED,KEY_MAX,VALUE_LENGTH,KeyMode.RANDOM,ValueMode.RANDOM_LENGTH);
  PactRecord record=new PactRecord();
  do {
    generator.next(record);
  }
 while (sorter.write(record));
  QuickSort qs=new QuickSort();
  qs.sort(sorter);
  MutableObjectIterator<PactRecord> iter=sorter.getIterator();
  PactRecord readTarget=new PactRecord();
  Key current=new Key();
  Key last=new Key();
  iter.next(readTarget);
  readTarget.getFieldInto(0,last);
  while (iter.next(readTarget)) {
    readTarget.getFieldInto(0,current);
    final int cmp=last.compareTo(current);
    if (cmp > 0)     Assert.fail(""String_Node_Str"");
    Key tmp=current;
    current=last;
    last=tmp;
  }
  this.memoryManager.release(sorter.dispose());
}",0.8621533442088092
55889,"/** 
 * {@inheritDoc}
 */
@Override public synchronized void requestInstance(JobID jobID,Configuration conf,Map<InstanceType,Integer> instanceMap,List<String> splitAffinityList) throws InstanceException {
  final Iterator<Map.Entry<InstanceType,Integer>> it=instanceMap.entrySet().iterator();
  while (it.hasNext()) {
    final Map.Entry<InstanceType,Integer> entry=it.next();
    for (int i=0; i < entry.getValue().intValue(); i++) {
      LOG.info(""String_Node_Str"" + entry.getKey().getIdentifier());
      AllocatedSlice slice=null;
      for (      final ClusterInstance host : this.registeredHosts.values()) {
        if (host.getType().equals(entry.getKey())) {
          slice=host.createSlice(entry.getKey(),jobID);
          if (slice != null) {
            break;
          }
        }
      }
      if (slice == null) {
        for (        final ClusterInstance host : this.registeredHosts.values()) {
          slice=host.createSlice(entry.getKey(),jobID);
          if (slice != null) {
            break;
          }
        }
      }
      if (slice == null) {
        throw new InstanceException(""String_Node_Str"");
      }
      List<AllocatedSlice> allocatedSlices=this.slicesOfJobs.get(jobID);
      if (allocatedSlices == null) {
        allocatedSlices=new ArrayList<AllocatedSlice>();
        this.slicesOfJobs.put(jobID,allocatedSlices);
      }
      allocatedSlices.add(slice);
      if (this.instanceListener != null) {
        ClusterInstanceNotifier clusterInstanceNotifier=new ClusterInstanceNotifier(this.instanceListener,slice);
        clusterInstanceNotifier.start();
      }
      LOG.info(""String_Node_Str"" + host.getName());
      return;
    }
  }
}","/** 
 * {@inheritDoc}
 */
@Override public synchronized void requestInstance(JobID jobID,Configuration conf,Map<InstanceType,Integer> instanceMap,List<String> splitAffinityList) throws InstanceException {
  final Iterator<Map.Entry<InstanceType,Integer>> it=instanceMap.entrySet().iterator();
  while (it.hasNext()) {
    final Map.Entry<InstanceType,Integer> entry=it.next();
    for (int i=0; i < entry.getValue().intValue(); i++) {
      LOG.info(""String_Node_Str"" + entry.getKey().getIdentifier());
      AllocatedSlice slice=null;
      for (      final ClusterInstance host : this.registeredHosts.values()) {
        if (host.getType().equals(entry.getKey())) {
          slice=host.createSlice(entry.getKey(),jobID);
          if (slice != null) {
            break;
          }
        }
      }
      if (slice == null) {
        for (        final ClusterInstance host : this.registeredHosts.values()) {
          slice=host.createSlice(entry.getKey(),jobID);
          if (slice != null) {
            break;
          }
        }
      }
      if (slice == null) {
        throw new InstanceException(""String_Node_Str"");
      }
      List<AllocatedSlice> allocatedSlices=this.slicesOfJobs.get(jobID);
      if (allocatedSlices == null) {
        allocatedSlices=new ArrayList<AllocatedSlice>();
        this.slicesOfJobs.put(jobID,allocatedSlices);
      }
      allocatedSlices.add(slice);
      if (this.instanceListener != null) {
        ClusterInstanceNotifier clusterInstanceNotifier=new ClusterInstanceNotifier(this.instanceListener,slice);
        clusterInstanceNotifier.start();
      }
      return;
    }
  }
}",0.9843467790487658
55890,"/** 
 * {@inheritDoc}
 */
@Override public void allocatedResourceDied(final JobID jobID,final AllocatedResource allocatedResource){
  LOG.info(""String_Node_Str"" + allocatedResource.getInstance().getName() + ""String_Node_Str""+ jobID+ ""String_Node_Str"");
  ExecutionGraph job=this.jobQueue.getFirst();
  Iterator<ExecutionGraph> iterator=this.jobQueue.descendingIterator();
  while (job.getJobID() != jobID) {
    if (iterator.hasNext()) {
      job=iterator.next();
    }
 else {
      LOG.error(""String_Node_Str"" + jobID + ""String_Node_Str"");
      return;
    }
  }
  List<ExecutionVertex> vertices=job.getVerticesAssignedToResource(allocatedResource);
  Iterator<ExecutionVertex> vertexIter=vertices.iterator();
  while (vertexIter.hasNext()) {
    ExecutionVertex vertex=vertexIter.next();
    vertex.getEnvironment().changeExecutionState(ExecutionState.FAILED,""String_Node_Str"" + allocatedResource.getInstance().getName() + ""String_Node_Str""+ vertex.getEnvironment().getTaskName()+ ""String_Node_Str"");
    if (vertex.getExecutionState() == ExecutionState.FAILED) {
      job.executionStateChanged(vertex.getEnvironment(),ExecutionState.FAILED,""String_Node_Str"" + allocatedResource.getInstance().getName() + ""String_Node_Str""+ vertex.getEnvironment().getTaskName()+ ""String_Node_Str"");
      return;
    }
    vertex.setAllocatedResource(new AllocatedResource(DummyInstance.createDummyInstance(allocatedResource.getInstanceType()),allocatedResource.getInstanceType(),null));
    vertex.getEnvironment().changeExecutionState(ExecutionState.ASSIGNING,null);
  }
  try {
    LOG.info(""String_Node_Str"" + allocatedResource.getInstanceType().getIdentifier());
    this.instanceManager.requestInstance(jobID,job.getJobConfiguration(),allocatedResource.getInstanceType());
  }
 catch (  InstanceException e) {
    e.printStackTrace();
  }
  job.executionStateChanged(vertices.get(0).getEnvironment(),ExecutionState.RECOVERING,null);
}","/** 
 * {@inheritDoc}
 */
@Override public void allocatedResourceDied(final JobID jobID,final AllocatedResource allocatedResource){
  LOG.info(""String_Node_Str"" + allocatedResource.getInstance().getName() + ""String_Node_Str""+ jobID+ ""String_Node_Str"");
  ExecutionGraph job=this.jobQueue.getFirst();
  Iterator<ExecutionGraph> iterator=this.jobQueue.descendingIterator();
  while (job.getJobID() != jobID) {
    if (iterator.hasNext()) {
      job=iterator.next();
    }
 else {
      LOG.error(""String_Node_Str"" + jobID + ""String_Node_Str"");
      return;
    }
  }
  List<ExecutionVertex> vertices=job.getVerticesAssignedToResource(allocatedResource);
  Iterator<ExecutionVertex> vertexIter=vertices.iterator();
  while (vertexIter.hasNext()) {
    ExecutionVertex vertex=vertexIter.next();
    vertex.getEnvironment().changeExecutionState(ExecutionState.FAILED,""String_Node_Str"" + allocatedResource.getInstance().getName() + ""String_Node_Str""+ vertex.getEnvironment().getTaskName()+ ""String_Node_Str"");
    if (vertex.getExecutionState() == ExecutionState.FAILED) {
      job.executionStateChanged(vertex.getEnvironment(),ExecutionState.FAILED,""String_Node_Str"" + allocatedResource.getInstance().getName() + ""String_Node_Str""+ vertex.getEnvironment().getTaskName()+ ""String_Node_Str"");
      return;
    }
    vertex.setAllocatedResource(new AllocatedResource(DummyInstance.createDummyInstance(allocatedResource.getInstanceType()),allocatedResource.getInstanceType(),null));
    vertex.getEnvironment().changeExecutionState(ExecutionState.ASSIGNING,null);
  }
  try {
    LOG.info(""String_Node_Str"" + allocatedResource.getInstanceType().getIdentifier());
    Map<InstanceType,Integer> instanceMap=new HashMap<InstanceType,Integer>();
    instanceMap.put(allocatedResource.getInstanceType(),1);
    this.getInstanceManager().requestInstance(jobID,job.getJobConfiguration(),instanceMap,null);
  }
 catch (  InstanceException e) {
    e.printStackTrace();
  }
  job.executionStateChanged(vertices.get(0).getEnvironment(),ExecutionState.RECOVERING,null);
}",0.9430363864491844
55891,"@Override public void reportPersistenCheckpoint(ExecutionVertexID executionVertexID,JobID jobID){
}","@Override public void reportPersistenCheckpoint(ExecutionVertexID executionVertexID,JobID jobID){
  getExecutionGraphByID(jobID).getVertexByID(executionVertexID).setCheckpoint();
}",0.7096774193548387
55892,"@Override public void reportPersistenCheckpoint(ExecutionVertexID executionVertexID,JobID jobID){
}","@Override public void reportPersistenCheckpoint(ExecutionVertexID executionVertexID,JobID jobID){
  this.scheduler.reportPersistenCheckpoint(executionVertexID,jobID);
}",0.7415730337078652
55893,"@Override public void reportPersistenCheckpoint(ExecutionVertexID executionVertexID,JobID jobID){
}","@Override public void reportPersistenCheckpoint(ExecutionVertexID executionVertexID,JobID jobID){
  getExecutionGraphByID(jobID).getVertexByID(executionVertexID).setCheckpoint();
}",0.7096774193548387
55894,"/** 
 * {@inheritDoc}
 */
@Override public void schedulJob(final ExecutionGraph executionGraph) throws SchedulingException {
  final Map<InstanceType,InstanceTypeDescription> availableInstances=getInstanceManager().getMapOfAvailableInstanceTypes();
  for (int i=0; i < executionGraph.getNumberOfStages(); i++) {
    final InstanceRequestMap instanceRequestMap=new InstanceRequestMap();
    final ExecutionStage stage=executionGraph.getStage(i);
    stage.collectRequiredInstanceTypes(instanceRequestMap,ExecutionState.CREATED);
    final Iterator<Map.Entry<InstanceType,Integer>> it=instanceRequestMap.getMinimumIterator();
    while (it.hasNext()) {
      final Map.Entry<InstanceType,Integer> entry=it.next();
      final InstanceTypeDescription descr=availableInstances.get(entry.getKey());
      if (descr == null) {
        throw new SchedulingException(""String_Node_Str"" + entry.getKey() + ""String_Node_Str"");
      }
      if (descr.getMaximumNumberOfAvailableInstances() != -1 && descr.getMaximumNumberOfAvailableInstances() < entry.getValue().intValue()) {
        throw new SchedulingException(""String_Node_Str"" + entry.getValue().intValue() + ""String_Node_Str""+ entry.getKey()+ ""String_Node_Str""+ descr.getMaximumNumberOfAvailableInstances()+ ""String_Node_Str"");
      }
    }
  }
  executionGraph.registerJobStatusListener(this);
  final ExecutionGraphIterator it2=new ExecutionGraphIterator(executionGraph,true);
  while (it2.hasNext()) {
    final ExecutionVertex vertex=it2.next();
    vertex.registerExecutionListener(new QueueExecutionListener(this,vertex));
  }
  executionGraph.registerExecutionStageListener(this);
synchronized (this.jobQueue) {
    this.jobQueue.add(executionGraph);
    final ExecutionStage executionStage=executionGraph.getCurrentExecutionStage();
    try {
      requestInstances(executionStage);
    }
 catch (    InstanceException e) {
      final String exceptionMessage=StringUtils.stringifyException(e);
      LOG.error(exceptionMessage);
      this.jobQueue.remove(executionGraph);
      throw new SchedulingException(exceptionMessage);
    }
  }
}","/** 
 * {@inheritDoc}
 */
@Override public void schedulJob(final ExecutionGraph executionGraph) throws SchedulingException {
synchronized (executionGraph) {
    final Map<InstanceType,InstanceTypeDescription> availableInstances=getInstanceManager().getMapOfAvailableInstanceTypes();
    for (int i=0; i < executionGraph.getNumberOfStages(); i++) {
      final InstanceRequestMap instanceRequestMap=new InstanceRequestMap();
      final ExecutionStage stage=executionGraph.getStage(i);
      stage.collectRequiredInstanceTypes(instanceRequestMap,ExecutionState.CREATED);
      final Iterator<Map.Entry<InstanceType,Integer>> it=instanceRequestMap.getMinimumIterator();
      while (it.hasNext()) {
        final Map.Entry<InstanceType,Integer> entry=it.next();
        final InstanceTypeDescription descr=availableInstances.get(entry.getKey());
        if (descr == null) {
          throw new SchedulingException(""String_Node_Str"" + entry.getKey() + ""String_Node_Str"");
        }
        if (descr.getMaximumNumberOfAvailableInstances() != -1 && descr.getMaximumNumberOfAvailableInstances() < entry.getValue().intValue()) {
          throw new SchedulingException(""String_Node_Str"" + entry.getValue().intValue() + ""String_Node_Str""+ entry.getKey()+ ""String_Node_Str""+ descr.getMaximumNumberOfAvailableInstances()+ ""String_Node_Str"");
        }
      }
    }
    executionGraph.registerJobStatusListener(this);
    final ExecutionGraphIterator it2=new ExecutionGraphIterator(executionGraph,true);
    while (it2.hasNext()) {
      final ExecutionVertex vertex=it2.next();
      vertex.registerExecutionListener(new QueueExecutionListener(this,vertex));
    }
    executionGraph.registerExecutionStageListener(this);
  }
synchronized (this.jobQueue) {
    this.jobQueue.add(executionGraph);
  }
synchronized (executionGraph) {
    final ExecutionStage executionStage=executionGraph.getCurrentExecutionStage();
    try {
      requestInstances(executionStage);
    }
 catch (    InstanceException e) {
      final String exceptionMessage=StringUtils.stringifyException(e);
      LOG.error(exceptionMessage);
      this.jobQueue.remove(executionGraph);
      throw new SchedulingException(exceptionMessage);
    }
  }
}",0.9721577726218096
55895,"/** 
 * Sets the maximum number of members this group vertex can have.
 * @param maxSize the maximum number of members this group vertex can have
 */
void setMaxMemberSize(final int maxSize){
  if (maxSize < 0) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  this.maxMemberSize=maxSize;
}","/** 
 * Sets the maximum number of members this group vertex can have.
 * @param maxSize the maximum number of members this group vertex can have
 */
void setMaxMemberSize(final int maxSize){
  this.maxMemberSize=maxSize;
}",0.7433962264150943
55896,"/** 
 * Sets the minimum number of members this group vertex must have.
 * @param minSize the minimum number of members this group vertex must have
 */
void setMinMemberSize(final int minSize){
  if (minSize < 0) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  this.minMemberSize=minSize;
}","/** 
 * Sets the minimum number of members this group vertex must have.
 * @param minSize the minimum number of members this group vertex must have
 */
void setMinMemberSize(final int minSize){
  this.minMemberSize=minSize;
}",0.7453183520599251
55897,"/** 
 * Cancels and removes the task represented by this vertex from the instance it is currently running on. If the task is not currently running, its execution state is simply updated to <code>CANCELLED</code>.
 * @return the result of the task cancel attempt
 */
public TaskCancelResult cancelTask(){
  if (this.groupVertex.getStageNumber() != this.executionGraph.getIndexOfCurrentExecutionStage()) {
    updateExecutionState(ExecutionState.CANCELED,null);
    return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
  }
  if (this.executionState == ExecutionState.FINISHED || this.executionState == ExecutionState.FAILED) {
    return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
  }
  if (this.executionState != ExecutionState.RUNNING && this.executionState != ExecutionState.FINISHING) {
    updateExecutionState(ExecutionState.CANCELED,null);
    return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
  }
  if (this.allocatedResource == null) {
    final TaskCancelResult result=new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.ERROR);
    result.setDescription(""String_Node_Str"" + this.toString() + ""String_Node_Str"");
    return result;
  }
  try {
    return this.allocatedResource.getInstance().cancelTask(this.vertexID);
  }
 catch (  IOException e) {
    final TaskCancelResult result=new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.ERROR);
    result.setDescription(StringUtils.stringifyException(e));
    return result;
  }
}","/** 
 * Cancels and removes the task represented by this vertex from the instance it is currently running on. If the task is not currently running, its execution state is simply updated to <code>CANCELLED</code>.
 * @return the result of the task cancel attempt
 */
public TaskCancelResult cancelTask(){
  if (this.groupVertex.getStageNumber() != this.executionGraph.getIndexOfCurrentExecutionStage()) {
    updateExecutionState(ExecutionState.CANCELED,null);
    return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
  }
  if (this.executionState == ExecutionState.FINISHED || this.executionState == ExecutionState.FAILED) {
    return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
  }
  if (this.executionState != ExecutionState.RUNNING && this.executionState != ExecutionState.STARTING && this.executionState != ExecutionState.FINISHING) {
    updateExecutionState(ExecutionState.CANCELED,null);
    return new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.SUCCESS);
  }
  if (this.allocatedResource == null) {
    final TaskCancelResult result=new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.ERROR);
    result.setDescription(""String_Node_Str"" + this.toString() + ""String_Node_Str"");
    return result;
  }
  try {
    return this.allocatedResource.getInstance().cancelTask(this.vertexID);
  }
 catch (  IOException e) {
    final TaskCancelResult result=new TaskCancelResult(getID(),AbstractTaskResult.ReturnCode.ERROR);
    result.setDescription(StringUtils.stringifyException(e));
    return result;
  }
}",0.9838917525773196
55898,"private void reassignGraphFragment(final ExecutionVertex vertex,final AllocatedResource oldResource,final AllocatedResource newResource){
  if (oldResource.equals(vertex.getAllocatedResource())) {
    vertex.setAllocatedResource(newResource);
    if (vertex.getExecutionState() == ExecutionState.SCHEDULED) {
      vertex.updateExecutionState(ExecutionState.ASSIGNED);
    }
    final int numberOfOutputGates=vertex.getEnvironment().getNumberOfOutputGates();
    for (int i=0; i < numberOfOutputGates; ++i) {
      final OutputGate<? extends Record> outputGate=vertex.getEnvironment().getOutputGate(i);
      if (outputGate.getChannelType() == ChannelType.NETWORK) {
        continue;
      }
      final int numberOfOutputChannels=outputGate.getNumberOfOutputChannels();
      for (int j=0; j < numberOfOutputChannels; ++j) {
        final AbstractOutputChannel<? extends Record> outputChannel=outputGate.getOutputChannel(j);
        final ExecutionVertex connectedVertex=vertex.getExecutionGraph().getVertexByChannelID(outputChannel.getConnectedChannelID());
        reassignGraphFragment(connectedVertex,oldResource,newResource);
      }
    }
  }
}","private void reassignGraphFragment(final ExecutionVertex vertex,final AllocatedResource oldResource,final AllocatedResource newResource){
synchronized (vertex.getExecutionGraph()) {
    if (oldResource.equals(vertex.getAllocatedResource())) {
      vertex.setAllocatedResource(newResource);
      if (vertex.getExecutionState() == ExecutionState.SCHEDULED) {
        vertex.updateExecutionState(ExecutionState.ASSIGNED);
      }
      final int numberOfOutputGates=vertex.getEnvironment().getNumberOfOutputGates();
      for (int i=0; i < numberOfOutputGates; ++i) {
        final OutputGate<? extends Record> outputGate=vertex.getEnvironment().getOutputGate(i);
        if (outputGate.getChannelType() == ChannelType.NETWORK) {
          continue;
        }
        final int numberOfOutputChannels=outputGate.getNumberOfOutputChannels();
        for (int j=0; j < numberOfOutputChannels; ++j) {
          final AbstractOutputChannel<? extends Record> outputChannel=outputGate.getOutputChannel(j);
          final ExecutionVertex connectedVertex=vertex.getExecutionGraph().getVertexByChannelID(outputChannel.getConnectedChannelID());
          reassignGraphFragment(connectedVertex,oldResource,newResource);
        }
      }
    }
  }
}",0.9640167364016736
55899,"/** 
 * {@inheritDoc}
 */
@Override public void executionStateChanged(final JobID jobID,final ExecutionVertexID vertexID,final ExecutionState newExecutionState,final String optionalMessage){
  final ExecutionGraph eg=this.executionVertex.getExecutionGraph();
  if (newExecutionState == ExecutionState.FINISHED) {
    final ExecutionGroupVertex groupVertex=this.executionVertex.getGroupVertex();
    for (int i=0; i < groupVertex.getCurrentNumberOfGroupMembers(); ++i) {
      final ExecutionVertex groupMember=groupVertex.getGroupMember(i);
      if (groupMember.getExecutionState() == ExecutionState.SCHEDULED) {
        groupMember.setAllocatedResource(this.executionVertex.getAllocatedResource());
        groupMember.updateExecutionState(ExecutionState.READY);
        this.scheduler.deployAssignedVertices(eg);
        return;
      }
    }
    final Iterator<ExecutionVertex> it=new ExecutionGraphIterator(eg,eg.getIndexOfCurrentExecutionStage(),true,true);
    while (it.hasNext()) {
      final ExecutionVertex nextVertex=it.next();
      if (nextVertex.getExecutionState() == ExecutionState.SCHEDULED) {
        if (nextVertex.getAllocatedResource().getInstanceType().equals(this.executionVertex.getAllocatedResource().getInstanceType())) {
          nextVertex.setAllocatedResource(this.executionVertex.getAllocatedResource());
          nextVertex.updateExecutionState(ExecutionState.READY);
          this.scheduler.deployAssignedVertices(eg);
          return;
        }
      }
    }
  }
  if (newExecutionState == ExecutionState.FINISHED || newExecutionState == ExecutionState.CANCELED || newExecutionState == ExecutionState.FAILED) {
    this.scheduler.checkAndReleaseAllocatedResource(eg,this.executionVertex.getAllocatedResource());
  }
  if (newExecutionState == ExecutionState.FAILED) {
    if (this.executionVertex.hasRetriesLeft()) {
      this.executionVertex.updateExecutionState(ExecutionState.SCHEDULED);
    }
  }
}","/** 
 * {@inheritDoc}
 */
@Override public void executionStateChanged(final JobID jobID,final ExecutionVertexID vertexID,final ExecutionState newExecutionState,final String optionalMessage){
  final ExecutionGraph eg=this.executionVertex.getExecutionGraph();
synchronized (eg) {
    if (newExecutionState == ExecutionState.FINISHED) {
      final ExecutionGroupVertex groupVertex=this.executionVertex.getGroupVertex();
      for (int i=0; i < groupVertex.getCurrentNumberOfGroupMembers(); ++i) {
        final ExecutionVertex groupMember=groupVertex.getGroupMember(i);
        if (groupMember.getExecutionState() == ExecutionState.SCHEDULED) {
          groupMember.setAllocatedResource(this.executionVertex.getAllocatedResource());
          groupMember.updateExecutionState(ExecutionState.READY);
          this.scheduler.deployAssignedVertices(eg);
          return;
        }
      }
      final Iterator<ExecutionVertex> it=new ExecutionGraphIterator(eg,eg.getIndexOfCurrentExecutionStage(),true,true);
      while (it.hasNext()) {
        final ExecutionVertex nextVertex=it.next();
        if (nextVertex.getExecutionState() == ExecutionState.SCHEDULED) {
          if (nextVertex.getAllocatedResource().getInstanceType().equals(this.executionVertex.getAllocatedResource().getInstanceType())) {
            nextVertex.setAllocatedResource(this.executionVertex.getAllocatedResource());
            nextVertex.updateExecutionState(ExecutionState.READY);
            this.scheduler.deployAssignedVertices(eg);
            return;
          }
        }
      }
    }
    if (newExecutionState == ExecutionState.FINISHED || newExecutionState == ExecutionState.CANCELED || newExecutionState == ExecutionState.FAILED) {
      this.scheduler.checkAndReleaseAllocatedResource(eg,this.executionVertex.getAllocatedResource());
    }
    if (newExecutionState == ExecutionState.FAILED) {
      if (this.executionVertex.hasRetriesLeft()) {
        this.executionVertex.updateExecutionState(ExecutionState.SCHEDULED);
      }
    }
  }
}",0.9778449144008056
55900,"/** 
 * {@inheritDoc}
 */
@Override public void initialExecutionResourcesExhausted(final JobID jobID,final ExecutionVertexID vertexID,final ResourceUtilizationSnapshot resourceUtilizationSnapshot){
  final ExecutionGraph executionGraph=this.executionVertex.getExecutionGraph();
  System.out.println(this.executionVertex + ""String_Node_Str"");
  final Map<ExecutionVertex,Long> targetVertices=new HashMap<ExecutionVertex,Long>();
  final Map<AllocatedResource,Long> availableResources=new HashMap<AllocatedResource,Long>();
  final Environment ee=this.executionVertex.getEnvironment();
synchronized (executionGraph) {
    for (int i=0; i < ee.getNumberOfOutputGates(); ++i) {
      final OutputGate<? extends Record> outputGate=ee.getOutputGate(i);
      for (int j=0; j < outputGate.getNumberOfOutputChannels(); ++j) {
        final AbstractOutputChannel<? extends Record> outputChannel=outputGate.getOutputChannel(j);
        final long transmittedData=resourceUtilizationSnapshot.getAmountOfDataTransmitted(outputChannel.getID());
        final ExecutionVertex connectedVertex=executionGraph.getVertexByChannelID(outputChannel.getConnectedChannelID());
        final ExecutionState state=connectedVertex.getExecutionState();
        if (state == ExecutionState.SCHEDULED || state == ExecutionState.ASSIGNED) {
          targetVertices.put(connectedVertex,Long.valueOf(transmittedData));
          final AllocatedResource allocatedResource=connectedVertex.getAllocatedResource();
          if (!(allocatedResource.getInstance() instanceof DummyInstance)) {
            availableResources.put(allocatedResource,Long.valueOf(0L));
          }
        }
      }
    }
    if (targetVertices.isEmpty()) {
      return;
    }
    final Queue<ExecutionVertex> vertexQueue=new PriorityQueue<ExecutionVertex>(targetVertices.size(),new Comparator<ExecutionVertex>(){
      @Override public int compare(      final ExecutionVertex arg0,      final ExecutionVertex arg1){
        final Long l0=targetVertices.get(arg0);
        final Long l1=targetVertices.get(arg1);
        if (l0.longValue() == l1.longValue()) {
          return 0;
        }
        if (l0.longValue() < l1.longValue()) {
          return 1;
        }
        return -1;
      }
    }
);
    final Queue<AllocatedResource> resourceQueue=new PriorityQueue<AllocatedResource>(availableResources.size(),new Comparator<AllocatedResource>(){
      @Override public int compare(      final AllocatedResource arg0,      final AllocatedResource arg1){
        final Long l0=availableResources.get(arg0);
        final Long l1=availableResources.get(arg1);
        if (l0.longValue() == l1.longValue()) {
          return 0;
        }
        if (l0.longValue() < l1.longValue()) {
          return -1;
        }
        return 1;
      }
    }
);
    Iterator<ExecutionVertex> vertexIt=targetVertices.keySet().iterator();
    while (vertexIt.hasNext()) {
      vertexQueue.add(vertexIt.next());
    }
    final Iterator<AllocatedResource> resourceIt=availableResources.keySet().iterator();
    while (resourceIt.hasNext()) {
      resourceQueue.add(resourceIt.next());
    }
    while (!vertexQueue.isEmpty()) {
      final ExecutionVertex v=vertexQueue.poll();
      final long vertexLoad=targetVertices.get(v);
      System.out.println(v + ""String_Node_Str"" + vertexLoad);
      final AllocatedResource ar=resourceQueue.poll();
      final long resourceLoad=availableResources.get(ar).longValue();
      System.out.println(ar + ""String_Node_Str"" + resourceLoad);
      availableResources.put(ar,Long.valueOf(vertexLoad + resourceLoad));
      resourceQueue.add(ar);
      reassignGraphFragment(v,v.getAllocatedResource(),ar);
    }
    final Map<AbstractInstance,List<ExecutionVertex>> verticesToBeDeployed=new HashMap<AbstractInstance,List<ExecutionVertex>>();
    vertexIt=targetVertices.keySet().iterator();
    while (vertexIt.hasNext()) {
      this.scheduler.findVerticesToBeDeployed(vertexIt.next(),verticesToBeDeployed);
    }
    final Iterator<Map.Entry<AbstractInstance,List<ExecutionVertex>>> deploymentIt=verticesToBeDeployed.entrySet().iterator();
    while (deploymentIt.hasNext()) {
      final Map.Entry<AbstractInstance,List<ExecutionVertex>> entry=deploymentIt.next();
      this.scheduler.getDeploymentManager().deploy(executionGraph.getJobID(),entry.getKey(),entry.getValue());
    }
  }
}","/** 
 * {@inheritDoc}
 */
@Override public void initialExecutionResourcesExhausted(final JobID jobID,final ExecutionVertexID vertexID,final ResourceUtilizationSnapshot resourceUtilizationSnapshot){
  final ExecutionGraph executionGraph=this.executionVertex.getExecutionGraph();
  System.out.println(this.executionVertex + ""String_Node_Str"");
  final Map<ExecutionVertex,Long> targetVertices=new HashMap<ExecutionVertex,Long>();
  final Map<AllocatedResource,Long> availableResources=new HashMap<AllocatedResource,Long>();
synchronized (executionGraph) {
    final Environment ee=this.executionVertex.getEnvironment();
    for (int i=0; i < ee.getNumberOfOutputGates(); ++i) {
      final OutputGate<? extends Record> outputGate=ee.getOutputGate(i);
      for (int j=0; j < outputGate.getNumberOfOutputChannels(); ++j) {
        final AbstractOutputChannel<? extends Record> outputChannel=outputGate.getOutputChannel(j);
        final long transmittedData=resourceUtilizationSnapshot.getAmountOfDataTransmitted(outputChannel.getID());
        final ExecutionVertex connectedVertex=executionGraph.getVertexByChannelID(outputChannel.getConnectedChannelID());
        final ExecutionState state=connectedVertex.getExecutionState();
        if (state == ExecutionState.SCHEDULED || state == ExecutionState.ASSIGNED) {
          targetVertices.put(connectedVertex,Long.valueOf(transmittedData));
          final AllocatedResource allocatedResource=connectedVertex.getAllocatedResource();
          if (!(allocatedResource.getInstance() instanceof DummyInstance)) {
            availableResources.put(allocatedResource,Long.valueOf(0L));
          }
        }
      }
    }
    if (targetVertices.isEmpty()) {
      return;
    }
    final Queue<ExecutionVertex> vertexQueue=new PriorityQueue<ExecutionVertex>(targetVertices.size(),new Comparator<ExecutionVertex>(){
      @Override public int compare(      final ExecutionVertex arg0,      final ExecutionVertex arg1){
        final Long l0=targetVertices.get(arg0);
        final Long l1=targetVertices.get(arg1);
        if (l0.longValue() == l1.longValue()) {
          return 0;
        }
        if (l0.longValue() < l1.longValue()) {
          return 1;
        }
        return -1;
      }
    }
);
    final Queue<AllocatedResource> resourceQueue=new PriorityQueue<AllocatedResource>(availableResources.size(),new Comparator<AllocatedResource>(){
      @Override public int compare(      final AllocatedResource arg0,      final AllocatedResource arg1){
        final Long l0=availableResources.get(arg0);
        final Long l1=availableResources.get(arg1);
        if (l0.longValue() == l1.longValue()) {
          return 0;
        }
        if (l0.longValue() < l1.longValue()) {
          return -1;
        }
        return 1;
      }
    }
);
    Iterator<ExecutionVertex> vertexIt=targetVertices.keySet().iterator();
    while (vertexIt.hasNext()) {
      vertexQueue.add(vertexIt.next());
    }
    final Iterator<AllocatedResource> resourceIt=availableResources.keySet().iterator();
    while (resourceIt.hasNext()) {
      resourceQueue.add(resourceIt.next());
    }
    while (!vertexQueue.isEmpty()) {
      final ExecutionVertex v=vertexQueue.poll();
      final long vertexLoad=targetVertices.get(v);
      System.out.println(v + ""String_Node_Str"" + vertexLoad);
      final AllocatedResource ar=resourceQueue.poll();
      final long resourceLoad=availableResources.get(ar).longValue();
      System.out.println(ar + ""String_Node_Str"" + resourceLoad);
      availableResources.put(ar,Long.valueOf(vertexLoad + resourceLoad));
      resourceQueue.add(ar);
      reassignGraphFragment(v,v.getAllocatedResource(),ar);
    }
    final Map<AbstractInstance,List<ExecutionVertex>> verticesToBeDeployed=new HashMap<AbstractInstance,List<ExecutionVertex>>();
    vertexIt=targetVertices.keySet().iterator();
    while (vertexIt.hasNext()) {
      this.scheduler.findVerticesToBeDeployed(vertexIt.next(),verticesToBeDeployed);
    }
    final Iterator<Map.Entry<AbstractInstance,List<ExecutionVertex>>> deploymentIt=verticesToBeDeployed.entrySet().iterator();
    while (deploymentIt.hasNext()) {
      final Map.Entry<AbstractInstance,List<ExecutionVertex>> entry=deploymentIt.next();
      this.scheduler.getDeploymentManager().deploy(executionGraph.getJobID(),entry.getKey(),entry.getValue());
    }
  }
}",0.9924398625429554
55901,"/** 
 * Checks if the given   {@link AllocatedResource} is still required for theexecution of the given execution graph. If the resource is no longer assigned to a vertex that is either currently running or about to run the given resource is returned to the instance manager for deallocation.
 * @param executionGraph the execution graph the provided resource has been used for so far
 * @param allocatedResource the allocated resource to check the assignment for
 */
public void checkAndReleaseAllocatedResource(ExecutionGraph executionGraph,AllocatedResource allocatedResource){
  if (allocatedResource == null) {
    LOG.error(""String_Node_Str"");
    return;
  }
  if (allocatedResource.getInstance() instanceof DummyInstance) {
    LOG.debug(""String_Node_Str"");
    return;
  }
synchronized (executionGraph) {
    final List<ExecutionVertex> assignedVertices=executionGraph.getVerticesAssignedToResource(allocatedResource);
    if (assignedVertices.isEmpty()) {
      return;
    }
    boolean instanceCanBeReleased=true;
    final Iterator<ExecutionVertex> it=assignedVertices.iterator();
    while (it.hasNext()) {
      final ExecutionVertex vertex=it.next();
      final ExecutionState state=vertex.getExecutionState();
      if (state != ExecutionState.CREATED && state != ExecutionState.FINISHED && state != ExecutionState.FAILED) {
        instanceCanBeReleased=false;
        break;
      }
    }
    if (instanceCanBeReleased) {
      LOG.info(""String_Node_Str"" + allocatedResource.getInstance());
      try {
        getInstanceManager().releaseAllocatedResource(executionGraph.getJobID(),executionGraph.getJobConfiguration(),allocatedResource);
      }
 catch (      InstanceException e) {
        LOG.error(StringUtils.stringifyException(e));
      }
    }
  }
}","/** 
 * Checks if the given   {@link AllocatedResource} is still required for theexecution of the given execution graph. If the resource is no longer assigned to a vertex that is either currently running or about to run the given resource is returned to the instance manager for deallocation.
 * @param executionGraph the execution graph the provided resource has been used for so far
 * @param allocatedResource the allocated resource to check the assignment for
 */
public void checkAndReleaseAllocatedResource(ExecutionGraph executionGraph,AllocatedResource allocatedResource){
  if (allocatedResource == null) {
    LOG.error(""String_Node_Str"");
    return;
  }
  if (allocatedResource.getInstance() instanceof DummyInstance) {
    LOG.debug(""String_Node_Str"");
    return;
  }
synchronized (executionGraph) {
    final List<ExecutionVertex> assignedVertices=executionGraph.getVerticesAssignedToResource(allocatedResource);
    if (assignedVertices.isEmpty()) {
      return;
    }
    boolean instanceCanBeReleased=true;
    final Iterator<ExecutionVertex> it=assignedVertices.iterator();
    while (it.hasNext()) {
      final ExecutionVertex vertex=it.next();
      final ExecutionState state=vertex.getExecutionState();
      if (state != ExecutionState.CREATED && state != ExecutionState.FINISHED && state != ExecutionState.FAILED && state != ExecutionState.CANCELED) {
        instanceCanBeReleased=false;
        break;
      }
    }
    if (instanceCanBeReleased) {
      LOG.info(""String_Node_Str"" + allocatedResource.getInstance());
      try {
        getInstanceManager().releaseAllocatedResource(executionGraph.getJobID(),executionGraph.getJobConfiguration(),allocatedResource);
      }
 catch (      InstanceException e) {
        LOG.error(StringUtils.stringifyException(e));
      }
    }
  }
}",0.989977728285078
55902,"void flushQueuedOutgoingEnvelopes() throws IOException, InterruptedException {
  System.out.println(""String_Node_Str"" + this.queuedOutgoingEnvelopes.size() + ""String_Node_Str"");
  while (!this.queuedOutgoingEnvelopes.isEmpty()) {
    this.outputGateContext.processEnvelope(this,this.queuedOutgoingEnvelopes.poll());
  }
}","void flushQueuedOutgoingEnvelopes() throws IOException, InterruptedException {
  while (!this.queuedOutgoingEnvelopes.isEmpty()) {
    this.outputGateContext.processEnvelope(this,this.queuedOutgoingEnvelopes.poll());
  }
}",0.8176795580110497
55903,"public FSDataOutputStream getFSDataOutputStream() throws Exception {
  long start=System.currentTimeMillis();
  long remaining=this.timeoutMillies;
  if (this.exception != null) {
    throw this.exception;
  }
  if (this.fdos != null) {
    return this.fdos;
  }
synchronized (this.lock) {
    do {
      try {
        this.lock.wait(remaining);
      }
 catch (      InterruptedException iex) {
        this.canceled=true;
        if (this.fdos != null) {
          try {
            this.fdos.close();
          }
 catch (          Throwable t) {
          }
        }
        throw new Exception(""String_Node_Str"");
      }
    }
 while (this.exception == null && this.fdos == null && (remaining=this.timeoutMillies + start - System.currentTimeMillis()) > 0);
    if (this.exception != null) {
      if (this.fdos != null) {
        try {
          this.fdos.close();
        }
 catch (        Throwable t) {
        }
      }
      throw this.exception;
    }
    if (this.fdos != null) {
      return this.fdos;
    }
  }
  throw new Exception(""String_Node_Str"");
}","public FSDataOutputStream getFSDataOutputStream() throws Exception {
  long start=System.currentTimeMillis();
  long remaining=this.timeoutMillies;
synchronized (this.lock) {
    boolean success=false;
    try {
      while (this.exception == null && this.fdos == null && (remaining=this.timeoutMillies + start - System.currentTimeMillis()) > 0) {
        this.lock.wait(remaining);
      }
      if (this.exception != null) {
        throw this.exception;
      }
      if (this.fdos != null) {
        success=true;
        return this.fdos;
      }
    }
  finally {
      if (!success) {
        this.canceled=true;
      }
    }
  }
  throw new Exception(""String_Node_Str"");
}",0.3426613363792118
55904,"@Override public void run(){
  try {
    final FileSystem fs=path.getFileSystem();
    Path p=this.path;
    if (fs.exists(this.path) && fs.getFileStatus(this.path).isDir()) {
      p=this.path.suffix(""String_Node_Str"" + this.taskIndex);
    }
    final FSDataOutputStream stream=fs.create(p,true);
synchronized (this.lock) {
      this.lock.notifyAll();
      if (!this.canceled) {
        this.fdos=stream;
      }
 else {
        this.fdos=null;
        stream.close();
      }
    }
  }
 catch (  Exception t) {
synchronized (this.lock) {
      this.canceled=true;
      this.exception=t;
    }
  }
}","@Override public void run(){
  try {
    final FileSystem fs=path.getFileSystem();
    Path p=this.path;
    if (fs.exists(this.path) && fs.getFileStatus(this.path).isDir()) {
      p=this.path.suffix(""String_Node_Str"" + this.taskIndex);
    }
    final FSDataOutputStream stream=fs.create(p,true);
synchronized (this.lock) {
      if (canceled) {
        try {
          stream.close();
        }
 catch (        Throwable t) {
        }
      }
 else {
        this.fdos=stream;
      }
      this.lock.notifyAll();
    }
  }
 catch (  Exception t) {
synchronized (this.lock) {
      this.exception=t;
      this.lock.notifyAll();
    }
  }
catch (  Throwable t) {
synchronized (this.lock) {
      this.exception=new Exception(t);
      this.lock.notifyAll();
    }
  }
}",0.6564996368917938
55905,"/** 
 * Private constructor used to duplicate execution vertices.
 * @param vertexID the ID of the new execution vertex.
 * @param invokableClass the task that is assigned to this execution vertex
 * @param executionGraph the execution graph the new vertex belongs to
 * @param groupVertex the group vertex the new vertex belongs to
 */
private ExecutionVertex(ExecutionVertexID vertexID,Class<? extends AbstractInvokable> invokableClass,ExecutionGraph executionGraph,ExecutionGroupVertex groupVertex){
  this.vertexID=vertexID;
  this.invokableClass=invokableClass;
  this.executionGraph=executionGraph;
  this.groupVertex=groupVertex;
}","/** 
 * Private constructor used to duplicate execution vertices.
 * @param vertexID the ID of the new execution vertex.
 * @param invokableClass the task that is assigned to this execution vertex
 * @param executionGraph the execution graph the new vertex belongs to
 * @param groupVertex the group vertex the new vertex belongs to
 */
private ExecutionVertex(ExecutionVertexID vertexID,Class<? extends AbstractInvokable> invokableClass,ExecutionGraph executionGraph,ExecutionGroupVertex groupVertex){
  this.vertexID=vertexID;
  this.invokableClass=invokableClass;
  this.executionGraph=executionGraph;
  this.groupVertex=groupVertex;
  registerExecutionListener(this.executionGraph);
}",0.9622926093514328
55906,"/** 
 * Updates the vertex's current execution state.
 * @param newExecutionState the new execution state
 * @param optionalMessage an optional message related to the state change
 */
public synchronized void updateExecutionState(final ExecutionState newExecutionState,final String optionalMessage){
  if (this.executionState == newExecutionState) {
    return;
  }
  ExecutionStateTransition.checkTransition(getName(),this.executionState,newExecutionState);
  final Iterator<ExecutionListener> it=this.executionListeners.iterator();
  while (it.hasNext()) {
    it.next().executionStateChanged(this.executionGraph.getJobID(),this.vertexID,newExecutionState,optionalMessage);
  }
  this.executionState=newExecutionState;
}","/** 
 * Updates the vertex's current execution state.
 * @param newExecutionState the new execution state
 * @param optionalMessage an optional message related to the state change
 */
public synchronized void updateExecutionState(final ExecutionState newExecutionState,final String optionalMessage){
  if (this.executionState == newExecutionState) {
    return;
  }
  ExecutionStateTransition.checkTransition(getName(),this.executionState,newExecutionState);
  this.executionState=newExecutionState;
  final Iterator<ExecutionListener> it=this.executionListeners.iterator();
  while (it.hasNext()) {
    it.next().executionStateChanged(this.executionGraph.getJobID(),this.vertexID,newExecutionState,optionalMessage);
  }
}",0.943213296398892
55907,"@Test public void testConvertJobGraphToExecutionGraph4(){
  File inputFile1=null;
  File inputFile2=null;
  JobID jobID=null;
  try {
    inputFile1=ServerTestUtils.createInputFile(0);
    inputFile2=ServerTestUtils.createInputFile(0);
    final JobGraph jg=new JobGraph(""String_Node_Str"");
    jobID=jg.getJobID();
    final JobFileInputVertex i1=new JobFileInputVertex(""String_Node_Str"",jg);
    i1.setFileInputClass(FileLineReader.class);
    i1.setFilePath(new Path(""String_Node_Str"" + inputFile1.getAbsolutePath()));
    i1.setNumberOfSubtasks(4);
    i1.setNumberOfSubtasksPerInstance(2);
    final JobFileInputVertex i2=new JobFileInputVertex(""String_Node_Str"",jg);
    i2.setFileInputClass(FileLineReader.class);
    i2.setFilePath(new Path(""String_Node_Str"" + inputFile2.getAbsolutePath()));
    i2.setNumberOfSubtasks(4);
    i2.setNumberOfSubtasksPerInstance(2);
    final JobTaskVertex t1=new JobTaskVertex(""String_Node_Str"",jg);
    t1.setTaskClass(ForwardTask1Input1Output.class);
    t1.setNumberOfSubtasks(4);
    t1.setNumberOfSubtasksPerInstance(2);
    final JobTaskVertex t2=new JobTaskVertex(""String_Node_Str"",jg);
    t2.setTaskClass(ForwardTask1Input1Output.class);
    t2.setNumberOfSubtasks(4);
    t2.setNumberOfSubtasksPerInstance(2);
    final JobTaskVertex t3=new JobTaskVertex(""String_Node_Str"",jg);
    t3.setTaskClass(ForwardTask2Inputs1Output.class);
    t3.setNumberOfSubtasks(8);
    t3.setNumberOfSubtasksPerInstance(4);
    final JobTaskVertex t4=new JobTaskVertex(""String_Node_Str"",jg);
    t4.setTaskClass(ForwardTask1Input2Outputs.class);
    t4.setNumberOfSubtasks(8);
    t4.setNumberOfSubtasksPerInstance(4);
    final JobFileOutputVertex o1=new JobFileOutputVertex(""String_Node_Str"",jg);
    o1.setFileOutputClass(FileLineWriter.class);
    o1.setFilePath(new Path(""String_Node_Str"" + ServerTestUtils.getRandomFilename()));
    o1.setNumberOfSubtasks(4);
    o1.setNumberOfSubtasksPerInstance(2);
    final JobFileOutputVertex o2=new JobFileOutputVertex(""String_Node_Str"",jg);
    o2.setFileOutputClass(FileLineWriter.class);
    o2.setFilePath(new Path(""String_Node_Str"" + ServerTestUtils.getRandomFilename()));
    o2.setNumberOfSubtasks(4);
    o2.setNumberOfSubtasksPerInstance(2);
    o1.setVertexToShareInstancesWith(o2);
    i1.connectTo(t1,ChannelType.FILE,CompressionLevel.NO_COMPRESSION);
    i2.connectTo(t2,ChannelType.FILE,CompressionLevel.NO_COMPRESSION);
    t1.connectTo(t3,ChannelType.NETWORK,CompressionLevel.NO_COMPRESSION);
    t2.connectTo(t3,ChannelType.NETWORK,CompressionLevel.NO_COMPRESSION);
    t3.connectTo(t4,ChannelType.INMEMORY,CompressionLevel.NO_COMPRESSION);
    t4.connectTo(o1,ChannelType.NETWORK,CompressionLevel.NO_COMPRESSION);
    t4.connectTo(o2,ChannelType.NETWORK,CompressionLevel.NO_COMPRESSION);
    LibraryCacheManager.register(jobID,new String[0]);
    final ExecutionGraph eg=new ExecutionGraph(jg,INSTANCE_MANAGER);
    final InstanceRequestMap instanceRequestMap=new InstanceRequestMap();
    ExecutionStage executionStage=eg.getCurrentExecutionStage();
    executionStage.collectRequiredInstanceTypes(instanceRequestMap,ExecutionState.CREATED);
    assertEquals(1,instanceRequestMap.size());
    assertEquals(4,(int)instanceRequestMap.getMaximumNumberOfInstances(INSTANCE_MANAGER.getInstanceTypeByName(DEFAULT_INSTANCE_TYPE_NAME)));
    final Iterator<ExecutionVertex> it=new ExecutionGraphIterator(eg,eg.getIndexOfCurrentExecutionStage(),true,true);
    while (it.hasNext()) {
      final ExecutionVertex ev=it.next();
      ev.updateExecutionState(ExecutionState.SCHEDULED);
      ev.updateExecutionState(ExecutionState.READY);
      ev.updateExecutionState(ExecutionState.STARTING);
      ev.updateExecutionState(ExecutionState.RUNNING);
      ev.updateExecutionState(ExecutionState.FINISHING);
      ev.updateExecutionState(ExecutionState.FINISHED);
    }
    instanceRequestMap.clear();
    executionStage=eg.getCurrentExecutionStage();
    executionStage.collectRequiredInstanceTypes(instanceRequestMap,ExecutionState.SCHEDULED);
    assertEquals(1,instanceRequestMap.size());
    assertEquals(8,(int)instanceRequestMap.getMaximumNumberOfInstances(INSTANCE_MANAGER.getInstanceTypeByName(DEFAULT_INSTANCE_TYPE_NAME)));
  }
 catch (  GraphConversionException e) {
    fail(e.getMessage());
  }
catch (  JobGraphDefinitionException e) {
    fail(e.getMessage());
  }
catch (  IOException e) {
    fail(e.getMessage());
  }
 finally {
    if (inputFile1 != null) {
      inputFile1.delete();
    }
    if (inputFile2 != null) {
      inputFile2.delete();
    }
    if (jobID != null) {
      try {
        LibraryCacheManager.unregister(jobID);
      }
 catch (      IOException e) {
      }
    }
  }
}","@Test public void testConvertJobGraphToExecutionGraph4(){
  File inputFile1=null;
  File inputFile2=null;
  JobID jobID=null;
  try {
    inputFile1=ServerTestUtils.createInputFile(0);
    inputFile2=ServerTestUtils.createInputFile(0);
    final JobGraph jg=new JobGraph(""String_Node_Str"");
    jobID=jg.getJobID();
    final JobFileInputVertex i1=new JobFileInputVertex(""String_Node_Str"",jg);
    i1.setFileInputClass(FileLineReader.class);
    i1.setFilePath(new Path(""String_Node_Str"" + inputFile1.getAbsolutePath()));
    i1.setNumberOfSubtasks(4);
    i1.setNumberOfSubtasksPerInstance(2);
    final JobFileInputVertex i2=new JobFileInputVertex(""String_Node_Str"",jg);
    i2.setFileInputClass(FileLineReader.class);
    i2.setFilePath(new Path(""String_Node_Str"" + inputFile2.getAbsolutePath()));
    i2.setNumberOfSubtasks(4);
    i2.setNumberOfSubtasksPerInstance(2);
    final JobTaskVertex t1=new JobTaskVertex(""String_Node_Str"",jg);
    t1.setTaskClass(ForwardTask1Input1Output.class);
    t1.setNumberOfSubtasks(4);
    t1.setNumberOfSubtasksPerInstance(2);
    final JobTaskVertex t2=new JobTaskVertex(""String_Node_Str"",jg);
    t2.setTaskClass(ForwardTask1Input1Output.class);
    t2.setNumberOfSubtasks(4);
    t2.setNumberOfSubtasksPerInstance(2);
    final JobTaskVertex t3=new JobTaskVertex(""String_Node_Str"",jg);
    t3.setTaskClass(ForwardTask2Inputs1Output.class);
    t3.setNumberOfSubtasks(8);
    t3.setNumberOfSubtasksPerInstance(4);
    final JobTaskVertex t4=new JobTaskVertex(""String_Node_Str"",jg);
    t4.setTaskClass(ForwardTask1Input2Outputs.class);
    t4.setNumberOfSubtasks(8);
    t4.setNumberOfSubtasksPerInstance(4);
    final JobFileOutputVertex o1=new JobFileOutputVertex(""String_Node_Str"",jg);
    o1.setFileOutputClass(FileLineWriter.class);
    o1.setFilePath(new Path(""String_Node_Str"" + ServerTestUtils.getRandomFilename()));
    o1.setNumberOfSubtasks(4);
    o1.setNumberOfSubtasksPerInstance(2);
    final JobFileOutputVertex o2=new JobFileOutputVertex(""String_Node_Str"",jg);
    o2.setFileOutputClass(FileLineWriter.class);
    o2.setFilePath(new Path(""String_Node_Str"" + ServerTestUtils.getRandomFilename()));
    o2.setNumberOfSubtasks(4);
    o2.setNumberOfSubtasksPerInstance(2);
    o1.setVertexToShareInstancesWith(o2);
    i1.connectTo(t1,ChannelType.FILE,CompressionLevel.NO_COMPRESSION);
    i2.connectTo(t2,ChannelType.FILE,CompressionLevel.NO_COMPRESSION);
    t1.connectTo(t3,ChannelType.NETWORK,CompressionLevel.NO_COMPRESSION);
    t2.connectTo(t3,ChannelType.NETWORK,CompressionLevel.NO_COMPRESSION);
    t3.connectTo(t4,ChannelType.INMEMORY,CompressionLevel.NO_COMPRESSION);
    t4.connectTo(o1,ChannelType.NETWORK,CompressionLevel.NO_COMPRESSION);
    t4.connectTo(o2,ChannelType.NETWORK,CompressionLevel.NO_COMPRESSION);
    LibraryCacheManager.register(jobID,new String[0]);
    final ExecutionGraph eg=new ExecutionGraph(jg,INSTANCE_MANAGER);
    final InstanceRequestMap instanceRequestMap=new InstanceRequestMap();
    ExecutionStage executionStage=eg.getCurrentExecutionStage();
    executionStage.collectRequiredInstanceTypes(instanceRequestMap,ExecutionState.CREATED);
    assertEquals(1,instanceRequestMap.size());
    assertEquals(4,(int)instanceRequestMap.getMaximumNumberOfInstances(INSTANCE_MANAGER.getInstanceTypeByName(DEFAULT_INSTANCE_TYPE_NAME)));
    final Iterator<ExecutionVertex> it=new ExecutionGraphIterator(eg,eg.getIndexOfCurrentExecutionStage(),true,true);
    while (it.hasNext()) {
      final ExecutionVertex ev=it.next();
      ev.updateExecutionState(ExecutionState.SCHEDULED);
      ev.updateExecutionState(ExecutionState.ASSIGNED);
      ev.updateExecutionState(ExecutionState.READY);
      ev.updateExecutionState(ExecutionState.STARTING);
      ev.updateExecutionState(ExecutionState.RUNNING);
      ev.updateExecutionState(ExecutionState.FINISHING);
      ev.updateExecutionState(ExecutionState.FINISHED);
    }
    instanceRequestMap.clear();
    executionStage=eg.getCurrentExecutionStage();
    assertEquals(1,executionStage.getStageNumber());
    executionStage.collectRequiredInstanceTypes(instanceRequestMap,ExecutionState.CREATED);
    assertEquals(1,instanceRequestMap.size());
    assertEquals(8,(int)instanceRequestMap.getMaximumNumberOfInstances(INSTANCE_MANAGER.getInstanceTypeByName(DEFAULT_INSTANCE_TYPE_NAME)));
  }
 catch (  GraphConversionException e) {
    fail(e.getMessage());
  }
catch (  JobGraphDefinitionException e) {
    fail(e.getMessage());
  }
catch (  IOException e) {
    fail(e.getMessage());
  }
 finally {
    if (inputFile1 != null) {
      inputFile1.delete();
    }
    if (inputFile2 != null) {
      inputFile2.delete();
    }
    if (jobID != null) {
      try {
        LibraryCacheManager.unregister(jobID);
      }
 catch (      IOException e) {
      }
    }
  }
}",0.98748290733144
55908,"/** 
 * Checks if the given   {@link AllocatedResource} is still required for theexecution of the given execution graph. If the resource is no longer assigned to a vertex that is either currently running or about to run the given resource is returned to the instance manager for deallocation.
 * @param executionGraph the execution graph the provided resource has been used for so far
 * @param allocatedResource the allocated resource to check the assignment for
 */
public void checkAndReleaseAllocatedResource(ExecutionGraph executionGraph,AllocatedResource allocatedResource){
  if (allocatedResource == null) {
    LOG.error(""String_Node_Str"");
    return;
  }
  if (allocatedResource.getInstance() instanceof DummyInstance) {
    LOG.debug(""String_Node_Str"");
    return;
  }
synchronized (executionGraph) {
    final List<ExecutionVertex> assignedVertices=executionGraph.getVerticesAssignedToResource(allocatedResource);
    if (assignedVertices.isEmpty()) {
      return;
    }
    boolean instanceCanBeReleased=true;
    final Iterator<ExecutionVertex> it=assignedVertices.iterator();
    while (it.hasNext()) {
      final ExecutionVertex vertex=it.next();
      final ExecutionState state=vertex.getExecutionState();
      if (state == ExecutionState.SCHEDULED || state == ExecutionState.READY || state == ExecutionState.RUNNING || state == ExecutionState.FINISHING || state == ExecutionState.CANCELING) {
        instanceCanBeReleased=false;
        break;
      }
    }
    if (instanceCanBeReleased) {
      LOG.info(""String_Node_Str"" + allocatedResource.getInstance());
      try {
        getInstanceManager().releaseAllocatedResource(executionGraph.getJobID(),executionGraph.getJobConfiguration(),allocatedResource);
      }
 catch (      InstanceException e) {
        LOG.error(StringUtils.stringifyException(e));
      }
    }
  }
}","/** 
 * Checks if the given   {@link AllocatedResource} is still required for theexecution of the given execution graph. If the resource is no longer assigned to a vertex that is either currently running or about to run the given resource is returned to the instance manager for deallocation.
 * @param executionGraph the execution graph the provided resource has been used for so far
 * @param allocatedResource the allocated resource to check the assignment for
 */
public void checkAndReleaseAllocatedResource(ExecutionGraph executionGraph,AllocatedResource allocatedResource){
  if (allocatedResource == null) {
    LOG.error(""String_Node_Str"");
    return;
  }
  if (allocatedResource.getInstance() instanceof DummyInstance) {
    LOG.debug(""String_Node_Str"");
    return;
  }
synchronized (executionGraph) {
    final List<ExecutionVertex> assignedVertices=executionGraph.getVerticesAssignedToResource(allocatedResource);
    if (assignedVertices.isEmpty()) {
      return;
    }
    boolean instanceCanBeReleased=true;
    final Iterator<ExecutionVertex> it=assignedVertices.iterator();
    while (it.hasNext()) {
      final ExecutionVertex vertex=it.next();
      final ExecutionState state=vertex.getExecutionState();
      if (state != ExecutionState.CREATED && state != ExecutionState.FINISHED && state != ExecutionState.FAILED) {
        instanceCanBeReleased=false;
        break;
      }
    }
    if (instanceCanBeReleased) {
      LOG.info(""String_Node_Str"" + allocatedResource.getInstance());
      try {
        getInstanceManager().releaseAllocatedResource(executionGraph.getJobID(),executionGraph.getJobConfiguration(),allocatedResource);
      }
 catch (      InstanceException e) {
        LOG.error(StringUtils.stringifyException(e));
      }
    }
  }
}",0.953168044077135
55909,"public void wire(ExecutionGroupVertex source,int indexOfOutputGate,ExecutionGroupVertex target,int indexOfInputGate,ChannelType channelType,CompressionLevel compressionLevel) throws GraphConversionException {
  for (int i=0; i < source.getCurrentNumberOfGroupMembers(); i++) {
    final ExecutionVertex sourceVertex=source.getGroupMember(i);
    final OutputGate<? extends Record> outputGate=sourceVertex.getEnvironment().getOutputGate(indexOfOutputGate);
    if (outputGate == null) {
      throw new GraphConversionException(""String_Node_Str"" + sourceVertex.getName() + ""String_Node_Str""+ indexOfOutputGate);
    }
    if (outputGate.getNumberOfOutputChannels() > 0) {
      throw new GraphConversionException(""String_Node_Str"" + sourceVertex.getName() + ""String_Node_Str""+ i+ ""String_Node_Str""+ outputGate.getNumberOfOutputChannels()+ ""String_Node_Str"");
    }
    for (int j=0; j < target.getCurrentNumberOfGroupMembers(); j++) {
      final ExecutionVertex targetVertex=target.getGroupMember(j);
      final InputGate<? extends Record> inputGate=targetVertex.getEnvironment().getInputGate(indexOfInputGate);
      if (inputGate == null) {
        throw new GraphConversionException(""String_Node_Str"" + targetVertex.getName() + ""String_Node_Str""+ indexOfInputGate);
      }
      if (inputGate.getNumberOfInputChannels() > 0 && i == 0) {
        throw new GraphConversionException(""String_Node_Str"" + targetVertex.getName() + ""String_Node_Str""+ j+ ""String_Node_Str""+ inputGate.getNumberOfInputChannels()+ ""String_Node_Str"");
      }
      if (inputGate.getDistributionPattern().createWire(i,j,source.getCurrentNumberOfGroupMembers(),target.getCurrentNumberOfGroupMembers())) {
        createChannel(sourceVertex,outputGate,targetVertex,inputGate,channelType,compressionLevel);
      }
    }
  }
}","public void wire(ExecutionGroupVertex source,int indexOfOutputGate,ExecutionGroupVertex target,int indexOfInputGate,ChannelType channelType,CompressionLevel compressionLevel) throws GraphConversionException {
  for (int i=0; i < source.getCurrentNumberOfGroupMembers(); i++) {
    final ExecutionVertex sourceVertex=source.getGroupMember(i);
    final OutputGate<? extends Record> outputGate=sourceVertex.getEnvironment().getOutputGate(indexOfOutputGate);
    if (outputGate == null) {
      throw new GraphConversionException(""String_Node_Str"" + sourceVertex.getName() + ""String_Node_Str""+ indexOfOutputGate);
    }
    if (outputGate.getNumberOfOutputChannels() > 0) {
      throw new GraphConversionException(""String_Node_Str"" + sourceVertex.getName() + ""String_Node_Str""+ i+ ""String_Node_Str""+ outputGate.getNumberOfOutputChannels()+ ""String_Node_Str"");
    }
    for (int j=0; j < target.getCurrentNumberOfGroupMembers(); j++) {
      final ExecutionVertex targetVertex=target.getGroupMember(j);
      final InputGate<? extends Record> inputGate=targetVertex.getEnvironment().getInputGate(indexOfInputGate);
      if (inputGate == null) {
        throw new GraphConversionException(""String_Node_Str"" + targetVertex.getName() + ""String_Node_Str""+ indexOfInputGate);
      }
      if (inputGate.getNumberOfInputChannels() > 0 && i == 0) {
        throw new GraphConversionException(""String_Node_Str"" + targetVertex.getName() + ""String_Node_Str""+ j+ ""String_Node_Str""+ inputGate.getNumberOfInputChannels()+ ""String_Node_Str"");
      }
      if (inputGate.getDistributionPattern().createWire(i,j,source.getCurrentNumberOfGroupMembers(),target.getCurrentNumberOfGroupMembers())) {
        createChannel(sourceVertex,outputGate,targetVertex,inputGate,channelType,compressionLevel);
      }
      inputGate.setChannelType(channelType);
    }
    outputGate.setChannelType(channelType);
  }
}",0.9758742206560044
55910,"public SerializableHashSet<ChannelID> constructInitialActiveOutputChannelsSet(){
  final SerializableHashSet<ChannelID> activeOutputChannels=new SerializableHashSet<ChannelID>();
synchronized (this) {
    final int numberOfOutputGates=this.environment.getNumberOfOutputGates();
    for (int i=0; i < numberOfOutputGates; ++i) {
      final OutputGate<? extends Record> outputGate=this.environment.getOutputGate(i);
      final ChannelType channelType=outputGate.getChannelType();
      final int numberOfOutputChannels=outputGate.getNumberOfOutputChannels();
      for (int j=0; j < numberOfOutputChannels; ++j) {
        final AbstractOutputChannel<? extends Record> outputChannel=outputGate.getOutputChannel(j);
        if (channelType == ChannelType.FILE) {
          continue;
        }
        if (channelType == ChannelType.INMEMORY) {
          activeOutputChannels.add(outputChannel.getID());
          continue;
        }
        if (channelType == ChannelType.NETWORK) {
          final ExecutionVertex connectedVertex=this.executionGraph.getVertexByChannelID(outputChannel.getConnectedChannelID());
          final ExecutionState state=connectedVertex.getExecutionState();
          if (state == ExecutionState.READY || state == ExecutionState.STARTING || state == ExecutionState.RUNNING) {
            activeOutputChannels.add(outputChannel.getID());
          }
        }
      }
    }
  }
  return activeOutputChannels;
}","public SerializableHashSet<ChannelID> constructInitialActiveOutputChannelsSet(){
  final SerializableHashSet<ChannelID> activeOutputChannels=new SerializableHashSet<ChannelID>();
synchronized (this) {
    final int numberOfOutputGates=this.environment.getNumberOfOutputGates();
    for (int i=0; i < numberOfOutputGates; ++i) {
      final OutputGate<? extends Record> outputGate=this.environment.getOutputGate(i);
      final ChannelType channelType=outputGate.getChannelType();
      final int numberOfOutputChannels=outputGate.getNumberOfOutputChannels();
      for (int j=0; j < numberOfOutputChannels; ++j) {
        final AbstractOutputChannel<? extends Record> outputChannel=outputGate.getOutputChannel(j);
        if (channelType == ChannelType.FILE) {
          activeOutputChannels.add(outputChannel.getID());
          continue;
        }
        if (channelType == ChannelType.INMEMORY) {
          activeOutputChannels.add(outputChannel.getID());
          continue;
        }
        if (channelType == ChannelType.NETWORK) {
          final ExecutionVertex connectedVertex=this.executionGraph.getVertexByChannelID(outputChannel.getConnectedChannelID());
          final ExecutionState state=connectedVertex.getExecutionState();
          if (state == ExecutionState.READY || state == ExecutionState.STARTING || state == ExecutionState.RUNNING) {
            activeOutputChannels.add(outputChannel.getID());
          }
        }
      }
    }
  }
  return activeOutputChannels;
}",0.97985660635029
55911,"/** 
 * {@inheritDoc}
 */
@Override public void close() throws IOException, InterruptedException {
  this.deserializationBuffer.clear();
  if (this.uncompressedDataBuffer != null) {
    releasedConsumedReadBuffer();
  }
  if (this.getType() == ChannelType.NETWORK) {
synchronized (this.synchronisationObject) {
      if (!this.brokerAggreedToCloseChannel) {
        while (!this.brokerAggreedToCloseChannel) {
          requestReadBuffersFromBroker();
          if (this.uncompressedDataBuffer != null || this.compressedDataBuffer != null) {
            releasedConsumedReadBuffer();
          }
          this.synchronisationObject.wait(500);
        }
        this.bufferedRecord=null;
      }
    }
  }
  if (getType() == ChannelType.NETWORK) {
    transferEvent(new ByteBufferedChannelCloseEvent());
  }
}","/** 
 * {@inheritDoc}
 */
@Override public void close() throws IOException, InterruptedException {
  this.deserializationBuffer.clear();
  if (this.uncompressedDataBuffer != null) {
    releasedConsumedReadBuffer();
  }
  if (this.getType() == ChannelType.NETWORK) {
synchronized (this.synchronisationObject) {
      if (!this.brokerAggreedToCloseChannel) {
        while (!this.brokerAggreedToCloseChannel) {
          requestReadBuffersFromBroker();
          if (this.uncompressedDataBuffer != null || this.compressedDataBuffer != null) {
            releasedConsumedReadBuffer();
          }
          this.synchronisationObject.wait(500);
        }
        this.bufferedRecord=null;
      }
    }
  }
  final ChannelType type=getType();
  if (type == ChannelType.NETWORK || type == ChannelType.INMEMORY) {
    transferEvent(new ByteBufferedChannelCloseEvent());
  }
}",0.9577632361689472
55912,"@Override public void run() throws Exception {
  final KeyGroupedIterator it=new KeyGroupedIterator(closeableInput.getIterator(),keyPositions,keyClasses);
  while (this.running && it.nextKey()) {
    System.out.println(""String_Node_Str"" + it.getKeys()[0]);
    crossValues(it.getValues(),output);
  }
}","@Override public void run() throws Exception {
  final KeyGroupedIterator it=new KeyGroupedIterator(closeableInput.getIterator(),keyPositions,keyClasses);
  while (this.running && it.nextKey()) {
    crossValues(it.getValues(),output);
  }
}",0.7697974217311234
55913,"/** 
 * Crosses the values of all pairs that have the same key. The   {@link MatchStub#match(Key,Iterator,Collector)} method is called for each element of the Cartesian product. 
 * @param key The key of all values in the iterator.
 * @param vals An iterator over values that share the same key.
 * @param out The collector to write the results to.
 * @throws Exception 
 */
private final void crossValues(final Iterator<PactRecord> values,final OutputCollector out) throws Exception {
  final PactRecord[] valBuffer=new PactRecord[VALUE_BUFFER_SIZE];
  int bufferValCnt;
  for (bufferValCnt=0; bufferValCnt < VALUE_BUFFER_SIZE; bufferValCnt++) {
    if (values.hasNext()) {
      valBuffer[bufferValCnt]=values.next().createCopy();
    }
 else {
      break;
    }
  }
  for (int i=0; i < bufferValCnt; i++) {
    if (!this.running)     return;
    for (int j=0; j < bufferValCnt; j++) {
      if (!this.running)       return;
      stub.match(valBuffer[i].createCopy(),valBuffer[j].createCopy(),out);
    }
  }
  if (this.running && values.hasNext()) {
    MutableObjectIterator<PactRecord> valReader=new MutableObjectIterator<PactRecord>(){
      @Override public boolean next(      PactRecord target) throws IOException {
        if (!running || !values.hasNext()) {
          return false;
        }
        values.next().copyTo(target);
        for (int i=0; i < VALUE_BUFFER_SIZE; i++) {
          try {
            stub.match(valBuffer[i].createCopy(),target.createCopy(),out);
          }
 catch (          Exception e) {
            e.printStackTrace();
          }
        }
        return true;
      }
    }
;
    SpillingResettableMutableObjectIterator outerValResettableIterator=null;
    SpillingResettableMutableObjectIterator innerValResettableIterator=null;
    try {
      outerValResettableIterator=new SpillingResettableMutableObjectIterator(memoryManager,ioManager,valReader,(long)(availableMemory * (MEMORY_SHARE_RATIO / 2)),this);
      outerValResettableIterator.open();
      BufferIncludingIterator bii=new BufferIncludingIterator(valBuffer,outerValResettableIterator);
      PactRecord outerRecord=new PactRecord();
      PactRecord innerRecord=new PactRecord();
      if (this.running && outerValResettableIterator.next(outerRecord)) {
        innerValResettableIterator=new SpillingResettableMutableObjectIterator(memoryManager,ioManager,bii,(long)(availableMemory * (MEMORY_SHARE_RATIO / 2)),this);
        innerValResettableIterator.open();
        outerValResettableIterator.reset();
        while (this.running && outerValResettableIterator.next(outerRecord)) {
          bufferValCnt=0;
          do {
            outerRecord.copyTo(valBuffer[bufferValCnt++]);
          }
 while (this.running && outerValResettableIterator.next(outerRecord) && bufferValCnt < VALUE_BUFFER_SIZE);
          if (bufferValCnt == 0)           break;
          while (this.running && innerValResettableIterator.next(innerRecord)) {
            for (int i=0; i < bufferValCnt; i++) {
              stub.match(valBuffer[i].createCopy(),innerRecord,out);
              if (i < bufferValCnt - 1)               innerValResettableIterator.repeatLast(innerRecord);
            }
          }
          innerValResettableIterator.reset();
        }
      }
    }
 catch (    Exception e) {
      throw new RuntimeException(e);
    }
 finally {
      if (innerValResettableIterator != null) {
        innerValResettableIterator.close();
      }
      if (outerValResettableIterator != null) {
        outerValResettableIterator.close();
      }
    }
  }
}","/** 
 * Crosses the values of all pairs that have the same key. The   {@link MatchStub#match(Key,Iterator,Collector)} method is called for each element of the Cartesian product. 
 * @param values An iterator over values that share the same key.
 * @param out The collector to write the results to.
 * @throws Exception 
 */
private final void crossValues(final Iterator<PactRecord> values,final OutputCollector out) throws Exception {
  final PactRecord[] valBuffer=new PactRecord[VALUE_BUFFER_SIZE];
  int bufferValCnt;
  for (bufferValCnt=0; bufferValCnt < VALUE_BUFFER_SIZE; bufferValCnt++) {
    if (values.hasNext()) {
      valBuffer[bufferValCnt]=values.next().createCopy();
    }
 else {
      break;
    }
  }
  for (int i=0; i < bufferValCnt; i++) {
    if (!this.running)     return;
    for (int j=0; j < bufferValCnt; j++) {
      if (!this.running)       return;
      stub.match(valBuffer[i].createCopy(),valBuffer[j].createCopy(),out);
    }
  }
  if (this.running && values.hasNext()) {
    MutableObjectIterator<PactRecord> valReader=new MutableObjectIterator<PactRecord>(){
      @Override public boolean next(      PactRecord target) throws IOException {
        if (!running || !values.hasNext()) {
          return false;
        }
        values.next().copyTo(target);
        for (int i=0; i < VALUE_BUFFER_SIZE; i++) {
          try {
            stub.match(valBuffer[i].createCopy(),target.createCopy(),out);
          }
 catch (          Exception e) {
            exceptionInMatchForValReader=e;
            return false;
          }
        }
        return true;
      }
    }
;
    SpillingResettableMutableObjectIterator outerValResettableIterator=null;
    SpillingResettableMutableObjectIterator innerValResettableIterator=null;
    try {
      outerValResettableIterator=new SpillingResettableMutableObjectIterator(memoryManager,ioManager,valReader,(long)(availableMemory * (MEMORY_SHARE_RATIO / 2)),this);
      outerValResettableIterator.open();
      if (exceptionInMatchForValReader != null) {
        throw exceptionInMatchForValReader;
      }
      BufferIncludingIterator bii=new BufferIncludingIterator(valBuffer,outerValResettableIterator);
      PactRecord outerRecord=new PactRecord();
      PactRecord innerRecord=new PactRecord();
      if (this.running) {
        innerValResettableIterator=new SpillingResettableMutableObjectIterator(memoryManager,ioManager,bii,(long)(availableMemory * (MEMORY_SHARE_RATIO / 2)),this);
        innerValResettableIterator.open();
        outerValResettableIterator.reset();
        while (this.running && outerValResettableIterator.next(outerRecord)) {
          bufferValCnt=0;
          do {
            outerRecord.copyTo(valBuffer[bufferValCnt++]);
          }
 while (this.running && bufferValCnt < VALUE_BUFFER_SIZE && outerValResettableIterator.next(outerRecord));
          if (bufferValCnt == 0)           break;
          while (this.running && innerValResettableIterator.next(innerRecord)) {
            for (int i=0; i < bufferValCnt; i++) {
              stub.match(valBuffer[i].createCopy(),innerRecord,out);
              if (i < bufferValCnt - 1)               innerValResettableIterator.repeatLast(innerRecord);
            }
          }
          innerValResettableIterator.reset();
        }
      }
    }
 catch (    Exception e) {
      throw new RuntimeException(e);
    }
 finally {
      if (innerValResettableIterator != null) {
        innerValResettableIterator.close();
      }
      if (outerValResettableIterator != null) {
        outerValResettableIterator.close();
      }
    }
  }
}",0.9486177045518012
55914,"@Test public void testNoneSelfMatchTask(){
  int keyCnt=100;
  int valCnt=5;
  super.initEnvironment(3 * 1024 * 1024);
  super.addInput(new RegularlyGeneratedInputGenerator(keyCnt,valCnt,true));
  super.addOutput(outList);
  SelfMatchTask testTask=new SelfMatchTask();
  super.getTaskConfig().setLocalStrategy(LocalStrategy.SELF_NESTEDLOOP);
  super.getTaskConfig().setMemorySize(3 * 1024 * 1024);
  super.getTaskConfig().setNumFilehandles(4);
  super.getTaskConfig().setLocalStrategyKeyTypes(0,new int[]{0});
  super.getTaskConfig().setLocalStrategyKeyTypes(new Class[]{PactInteger.class});
  super.registerTask(testTask,MockMatchStub.class);
  try {
    testTask.invoke();
  }
 catch (  Exception e) {
    LOG.debug(e);
    Assert.fail(""String_Node_Str"");
  }
  int expCnt=keyCnt * (valCnt * valCnt);
  Assert.assertTrue(""String_Node_Str"" + outList.size() + ""String_Node_Str""+ expCnt,outList.size() == expCnt);
  HashMap<Integer,Integer> keyValCntMap=new HashMap<Integer,Integer>(keyCnt);
  int lk=0;
  for (  PactRecord record : outList) {
    Integer key=record.getField(0,PactInteger.class).getValue();
    if (key == 0) {
      System.out.println((++lk) + ""String_Node_Str"" + record.getField(1,PactInteger.class).getValue());
    }
    if (!keyValCntMap.containsKey(key)) {
      keyValCntMap.put(key,1);
    }
 else {
      keyValCntMap.put(key,keyValCntMap.get(key) + 1);
    }
  }
  for (  Integer key : keyValCntMap.keySet()) {
    if (keyValCntMap.get(key) == (valCnt * valCnt)) {
      System.out.println(""String_Node_Str"");
    }
 else {
      System.out.println(""String_Node_Str"");
    }
    Assert.assertTrue(""String_Node_Str"" + keyValCntMap.get(key) + ""String_Node_Str""+ (valCnt * valCnt),keyValCntMap.get(key) == (valCnt * valCnt));
  }
  outList.clear();
}","@Test public void testNoneSelfMatchTask(){
  int keyCnt=100;
  int valCnt=5;
  super.initEnvironment(3 * 1024 * 1024);
  super.addInput(new RegularlyGeneratedInputGenerator(keyCnt,valCnt,true));
  super.addOutput(outList);
  SelfMatchTask testTask=new SelfMatchTask();
  super.getTaskConfig().setLocalStrategy(LocalStrategy.SELF_NESTEDLOOP);
  super.getTaskConfig().setMemorySize(3 * 1024 * 1024);
  super.getTaskConfig().setNumFilehandles(4);
  super.getTaskConfig().setLocalStrategyKeyTypes(0,new int[]{0});
  super.getTaskConfig().setLocalStrategyKeyTypes(new Class[]{PactInteger.class});
  super.registerTask(testTask,MockMatchStub.class);
  try {
    testTask.invoke();
  }
 catch (  Exception e) {
    LOG.debug(e);
    Assert.fail(""String_Node_Str"");
  }
  int expCnt=keyCnt * (valCnt * valCnt);
  Assert.assertTrue(""String_Node_Str"" + outList.size() + ""String_Node_Str""+ expCnt,outList.size() == expCnt);
  HashMap<Integer,Integer> keyValCntMap=new HashMap<Integer,Integer>(keyCnt);
  for (  PactRecord record : outList) {
    Integer key=record.getField(0,PactInteger.class).getValue();
    if (!keyValCntMap.containsKey(key)) {
      keyValCntMap.put(key,1);
    }
 else {
      keyValCntMap.put(key,keyValCntMap.get(key) + 1);
    }
  }
  for (  Integer key : keyValCntMap.keySet()) {
    Assert.assertTrue(""String_Node_Str"" + keyValCntMap.get(key) + ""String_Node_Str""+ (valCnt * valCnt),keyValCntMap.get(key) == (valCnt * valCnt));
  }
  outList.clear();
}",0.6878470080197409
55915,"/** 
 * {@inheritDoc}
 */
@Override public void userThreadFinished(Environment ee,Thread userThread){
}","/** 
 * {@inheritDoc}
 */
@Override public void userThreadFinished(final Environment ee,final Thread userThread){
}",0.944954128440367
55916,"/** 
 * {@inheritDoc}
 */
@Override public void userThreadStarted(Environment ee,Thread userThread){
}","/** 
 * {@inheritDoc}
 */
@Override public void userThreadStarted(final Environment ee,final Thread userThread){
}",0.9444444444444444
55917,"public SerializableHashSet<ChannelID> constructInitialActiveOutputChannelsSet(){
  final SerializableHashSet<ChannelID> activeOutputChannels=new SerializableHashSet<ChannelID>();
synchronized (this) {
    final int numberOfOutputGates=this.environment.getNumberOfOutputGates();
    for (int i=0; i < numberOfOutputGates; ++i) {
      final OutputGate<? extends Record> outputGate=this.environment.getOutputGate(i);
      final ChannelType channelType=outputGate.getChannelType();
      final int numberOfOutputChannels=outputGate.getNumberOfOutputChannels();
      for (int j=0; j < numberOfOutputChannels; ++j) {
        final AbstractOutputChannel<? extends Record> outputChannel=outputGate.getOutputChannel(j);
        if (channelType == ChannelType.FILE) {
          continue;
        }
        if (channelType == ChannelType.INMEMORY) {
          activeOutputChannels.add(outputChannel.getID());
          continue;
        }
        if (channelType == ChannelType.NETWORK) {
          final ExecutionVertex connectedVertex=this.executionGraph.getVertexByChannelID(outputChannel.getConnectedChannelID());
          final ExecutionState state=connectedVertex.getExecutionState();
          if (state == ExecutionState.READY || state == ExecutionState.RUNNING) {
            activeOutputChannels.add(outputChannel.getID());
          }
        }
      }
    }
  }
  return activeOutputChannels;
}","public SerializableHashSet<ChannelID> constructInitialActiveOutputChannelsSet(){
  final SerializableHashSet<ChannelID> activeOutputChannels=new SerializableHashSet<ChannelID>();
synchronized (this) {
    final int numberOfOutputGates=this.environment.getNumberOfOutputGates();
    for (int i=0; i < numberOfOutputGates; ++i) {
      final OutputGate<? extends Record> outputGate=this.environment.getOutputGate(i);
      final ChannelType channelType=outputGate.getChannelType();
      final int numberOfOutputChannels=outputGate.getNumberOfOutputChannels();
      for (int j=0; j < numberOfOutputChannels; ++j) {
        final AbstractOutputChannel<? extends Record> outputChannel=outputGate.getOutputChannel(j);
        if (channelType == ChannelType.FILE) {
          continue;
        }
        if (channelType == ChannelType.INMEMORY) {
          activeOutputChannels.add(outputChannel.getID());
          continue;
        }
        if (channelType == ChannelType.NETWORK) {
          final ExecutionVertex connectedVertex=this.executionGraph.getVertexByChannelID(outputChannel.getConnectedChannelID());
          final ExecutionState state=connectedVertex.getExecutionState();
          if (state == ExecutionState.READY || state == ExecutionState.STARTING || state == ExecutionState.RUNNING) {
            activeOutputChannels.add(outputChannel.getID());
          }
        }
      }
    }
  }
  return activeOutputChannels;
}",0.9872971065631616
55918,"public InstanceSummaryProfilingEvent getInstanceSummaryProfilingData(long timestamp){
  final Set<AbstractInstance> tempSet=new HashSet<AbstractInstance>();
  final ExecutionGroupVertexIterator it=new ExecutionGroupVertexIterator(this.executionGraph,true,this.executionGraph.getIndexOfCurrentExecutionStage());
  while (it.hasNext()) {
    final ExecutionGroupVertex groupVertex=it.next();
    for (int i=0; i < groupVertex.getCurrentNumberOfGroupMembers(); i++) {
      final ExecutionVertex executionVertex=groupVertex.getGroupMember(i);
      tempSet.add(executionVertex.getAllocatedResource().getInstance());
    }
  }
  if (tempSet.size() != this.collectedInstanceProfilingData.size()) {
    return null;
  }
  return constructInstanceSummary(timestamp);
}","public InstanceSummaryProfilingEvent getInstanceSummaryProfilingData(long timestamp){
  final Set<AbstractInstance> tempSet=new HashSet<AbstractInstance>();
  final ExecutionGroupVertexIterator it=new ExecutionGroupVertexIterator(this.executionGraph,true,this.executionGraph.getIndexOfCurrentExecutionStage());
  while (it.hasNext()) {
    final ExecutionGroupVertex groupVertex=it.next();
    for (int i=0; i < groupVertex.getCurrentNumberOfGroupMembers(); i++) {
      final ExecutionVertex executionVertex=groupVertex.getGroupMember(i);
      final AbstractInstance instance=executionVertex.getAllocatedResource().getInstance();
      if (!(instance instanceof DummyInstance)) {
        tempSet.add(instance);
      }
    }
  }
  if (tempSet.size() != this.collectedInstanceProfilingData.size()) {
    return null;
  }
  return constructInstanceSummary(timestamp);
}",0.8674846625766871
55919,"/** 
 * Runs a blocked nested loop strategy to build the Cartesian product and call the <code>cross()</code> method of the CrossStub implementation. The outer side is read using a BlockResettableIterator. The inner side is read using a SpillingResettableIterator.
 * @see eu.stratosphere.pact.runtime.resettable.SpillingResettableIterator
 * @see eu.stratosphere.pact.runtime.resettable.BlockResettableIterator
 * @param memoryManager The task manager's memory manager.
 * @param ioManager The task manager's IO manager
 * @param innerReader The inner reader of the nested loops.
 * @param outerReader The outer reader of the nested loops.
 * @throws RuntimeException Throws a RuntimeException if something fails during execution.
 */
private void runBlocked(MemoryManager memoryManager,IOManager ioManager,Iterator<KeyValuePair<Key,Value>> innerReader,Iterator<KeyValuePair<Key,Value>> outerReader) throws Exception {
  SpillingResettableIterator<KeyValuePair<Key,Value>> innerInput=null;
  BlockResettableIterator<KeyValuePair<Key,Value>> outerInput=null;
  try {
    final boolean firstInputIsOuter;
    if (this.config.getLocalStrategy() == LocalStrategy.NESTEDLOOP_BLOCKED_OUTER_SECOND) {
      try {
        innerInput=new SpillingResettableIterator<KeyValuePair<Key,Value>>(memoryManager,ioManager,innerReader,this.availableMemory / 2,new KeyValuePairDeserializer<Key,Value>(stub.getFirstInKeyType(),stub.getFirstInValueType()),this);
        this.spillingResetIt=innerInput;
      }
 catch (      MemoryAllocationException mae) {
        throw new RuntimeException(""String_Node_Str"",mae);
      }
      try {
        outerInput=new BlockResettableIterator<KeyValuePair<Key,Value>>(memoryManager,outerReader,this.availableMemory / 2,1,new KeyValuePairDeserializer<Key,Value>(stub.getSecondInKeyType(),stub.getSecondInValueType()),this);
        this.blockResetIt=outerInput;
      }
 catch (      MemoryAllocationException mae) {
        throw new RuntimeException(""String_Node_Str"",mae);
      }
      firstInputIsOuter=false;
    }
 else     if (this.config.getLocalStrategy() == LocalStrategy.NESTEDLOOP_BLOCKED_OUTER_FIRST) {
      try {
        innerInput=new SpillingResettableIterator<KeyValuePair<Key,Value>>(memoryManager,ioManager,innerReader,this.availableMemory / 2,new KeyValuePairDeserializer<Key,Value>(stub.getSecondInKeyType(),stub.getSecondInValueType()),this);
        this.spillingResetIt=innerInput;
      }
 catch (      MemoryAllocationException mae) {
        throw new RuntimeException(""String_Node_Str"",mae);
      }
      try {
        outerInput=new BlockResettableIterator<KeyValuePair<Key,Value>>(memoryManager,outerReader,this.availableMemory / 2,1,new KeyValuePairDeserializer<Key,Value>(stub.getFirstInKeyType(),stub.getFirstInValueType()),this);
        this.blockResetIt=outerInput;
      }
 catch (      MemoryAllocationException mae) {
        throw new RuntimeException(""String_Node_Str"",mae);
      }
      firstInputIsOuter=true;
    }
 else {
      throw new RuntimeException(""String_Node_Str"" + config.getLocalStrategy());
    }
    try {
      innerInput.open();
    }
 catch (    ServiceException se) {
      throw new RuntimeException(""String_Node_Str"",se);
    }
catch (    IOException ioe) {
      throw new RuntimeException(""String_Node_Str"",ioe);
    }
catch (    InterruptedException ie) {
      throw new RuntimeException(""String_Node_Str"",ie);
    }
    if (this.taskCanceled)     return;
    outerInput.open();
    if (LOG.isDebugEnabled()) {
      LOG.debug(getLogString(""String_Node_Str""));
      LOG.debug(getLogString(""String_Node_Str""));
    }
    this.stub.open();
    boolean moreOuterBlocks=false;
    if (innerInput.hasNext()) {
      do {
        while (!this.taskCanceled && innerInput.hasNext()) {
          KeyValuePair<Key,Value> innerPair=innerInput.next();
          while (!this.taskCanceled && outerInput.hasNext()) {
            KeyValuePair<Key,Value> outerPair=outerInput.next();
            if (firstInputIsOuter) {
              stub.cross(outerPair.getKey(),outerPair.getValue(),innerPair.getKey(),innerPair.getValue(),output);
            }
 else {
              stub.cross(innerPair.getKey(),innerPair.getValue(),outerPair.getKey(),outerPair.getValue(),output);
            }
            innerPair=innerInput.repeatLast();
          }
          outerInput.reset();
        }
        moreOuterBlocks=outerInput.nextBlock();
        if (moreOuterBlocks) {
          innerInput.reset();
        }
      }
 while (!this.taskCanceled && moreOuterBlocks);
    }
    this.stub.close();
  }
 catch (  Exception ex) {
    if (!this.taskCanceled) {
      LOG.error(getLogString(""String_Node_Str""));
      throw ex;
    }
  }
 finally {
    Throwable t1=null, t2=null;
    try {
      if (innerInput != null) {
        innerInput.close();
      }
    }
 catch (    Throwable t) {
      LOG.warn(t);
      t1=t;
    }
    try {
      if (outerInput != null) {
        outerInput.close();
      }
    }
 catch (    Throwable t) {
      LOG.warn(t);
      t2=t;
    }
    if (t1 != null)     throw new RuntimeException(""String_Node_Str"",t1);
    if (t2 != null)     throw new RuntimeException(""String_Node_Str"",t2);
  }
}","/** 
 * Runs a blocked nested loop strategy to build the Cartesian product and call the <code>cross()</code> method of the CrossStub implementation. The outer side is read using a BlockResettableIterator. The inner side is read using a SpillingResettableIterator.
 * @see eu.stratosphere.pact.runtime.resettable.SpillingResettableIterator
 * @see eu.stratosphere.pact.runtime.resettable.BlockResettableIterator
 * @param memoryManager The task manager's memory manager.
 * @param ioManager The task manager's IO manager
 * @param innerReader The inner reader of the nested loops.
 * @param outerReader The outer reader of the nested loops.
 * @throws RuntimeException Throws a RuntimeException if something fails during execution.
 */
private void runBlocked(MemoryManager memoryManager,IOManager ioManager,Iterator<KeyValuePair<Key,Value>> innerReader,Iterator<KeyValuePair<Key,Value>> outerReader) throws Exception {
  SpillingResettableIterator<KeyValuePair<Key,Value>> innerInput=null;
  BlockResettableIterator<KeyValuePair<Key,Value>> outerInput=null;
  try {
    final boolean firstInputIsOuter;
    if (this.config.getLocalStrategy() == LocalStrategy.NESTEDLOOP_BLOCKED_OUTER_SECOND) {
      try {
        innerInput=new SpillingResettableIterator<KeyValuePair<Key,Value>>(memoryManager,ioManager,innerReader,this.availableMemory / 2,new KeyValuePairDeserializer<Key,Value>(stub.getFirstInKeyType(),stub.getFirstInValueType()),this);
        this.spillingResetIt=innerInput;
      }
 catch (      MemoryAllocationException mae) {
        throw new RuntimeException(""String_Node_Str"",mae);
      }
      try {
        outerInput=new BlockResettableIterator<KeyValuePair<Key,Value>>(memoryManager,outerReader,this.availableMemory / 2,1,new KeyValuePairDeserializer<Key,Value>(stub.getSecondInKeyType(),stub.getSecondInValueType()),this);
        this.blockResetIt=outerInput;
      }
 catch (      MemoryAllocationException mae) {
        throw new RuntimeException(""String_Node_Str"",mae);
      }
      firstInputIsOuter=false;
    }
 else     if (this.config.getLocalStrategy() == LocalStrategy.NESTEDLOOP_BLOCKED_OUTER_FIRST) {
      try {
        innerInput=new SpillingResettableIterator<KeyValuePair<Key,Value>>(memoryManager,ioManager,innerReader,this.availableMemory / 2,new KeyValuePairDeserializer<Key,Value>(stub.getSecondInKeyType(),stub.getSecondInValueType()),this);
        this.spillingResetIt=innerInput;
      }
 catch (      MemoryAllocationException mae) {
        throw new RuntimeException(""String_Node_Str"",mae);
      }
      try {
        outerInput=new BlockResettableIterator<KeyValuePair<Key,Value>>(memoryManager,outerReader,this.availableMemory / 2,1,new KeyValuePairDeserializer<Key,Value>(stub.getFirstInKeyType(),stub.getFirstInValueType()),this);
        this.blockResetIt=outerInput;
      }
 catch (      MemoryAllocationException mae) {
        throw new RuntimeException(""String_Node_Str"",mae);
      }
      firstInputIsOuter=true;
    }
 else {
      throw new RuntimeException(""String_Node_Str"" + config.getLocalStrategy());
    }
    try {
      innerInput.open();
    }
 catch (    ServiceException se) {
      throw new RuntimeException(""String_Node_Str"",se);
    }
catch (    IOException ioe) {
      throw new RuntimeException(""String_Node_Str"",ioe);
    }
catch (    InterruptedException ie) {
      throw new RuntimeException(""String_Node_Str"",ie);
    }
    if (this.taskCanceled)     return;
    outerInput.open();
    if (LOG.isDebugEnabled()) {
      LOG.debug(getLogString(""String_Node_Str""));
      LOG.debug(getLogString(""String_Node_Str""));
    }
    this.stub.open();
    boolean moreOuterBlocks=false;
    if (innerInput.hasNext()) {
      do {
        while (!this.taskCanceled && innerInput.hasNext()) {
          KeyValuePair<Key,Value> innerPair=innerInput.next();
          while (!this.taskCanceled && outerInput.hasNext()) {
            KeyValuePair<Key,Value> outerPair=outerInput.next();
            if (firstInputIsOuter) {
              stub.cross(outerPair.getKey(),outerPair.getValue(),innerPair.getKey(),innerPair.getValue(),output);
            }
 else {
              stub.cross(innerPair.getKey(),innerPair.getValue(),outerPair.getKey(),outerPair.getValue(),output);
            }
            innerPair=innerInput.repeatLast();
          }
          outerInput.reset();
        }
        moreOuterBlocks=outerInput.nextBlock();
        if (moreOuterBlocks) {
          innerInput.reset();
        }
      }
 while (!this.taskCanceled && moreOuterBlocks);
    }
 else {
      LOG.debug(""String_Node_Str"");
      do {
        while (outerInput.hasNext()) {
          outerInput.next();
        }
      }
 while (outerInput.nextBlock());
    }
    this.stub.close();
  }
 catch (  Exception ex) {
    if (!this.taskCanceled) {
      LOG.error(getLogString(""String_Node_Str""));
      throw ex;
    }
  }
 finally {
    Throwable t1=null, t2=null;
    try {
      if (innerInput != null) {
        innerInput.close();
      }
    }
 catch (    Throwable t) {
      LOG.warn(t);
      t1=t;
    }
    try {
      if (outerInput != null) {
        outerInput.close();
      }
    }
 catch (    Throwable t) {
      LOG.warn(t);
      t2=t;
    }
    if (t1 != null)     throw new RuntimeException(""String_Node_Str"",t1);
    if (t2 != null)     throw new RuntimeException(""String_Node_Str"",t2);
  }
}",0.9320461858792352
55920,"/** 
 * {@inheritDoc}
 */
@Override public void close() throws IOException, InterruptedException {
  this.deserializationBuffer.clear();
  if (this.uncompressedDataBuffer != null) {
    releasedConsumedReadBuffer();
  }
  if (getType() == ChannelType.NETWORK) {
    transferEvent(new ByteBufferedChannelCloseEvent());
  }
}","/** 
 * {@inheritDoc}
 */
@Override public void close() throws IOException, InterruptedException {
  this.deserializationBuffer.clear();
  if (this.uncompressedDataBuffer != null) {
    releasedConsumedReadBuffer();
  }
synchronized (this.synchronisationObject) {
    if (!this.brokerAggreedToCloseChannel) {
      while (!this.brokerAggreedToCloseChannel) {
        requestReadBuffersFromBroker();
        if (this.uncompressedDataBuffer != null || this.compressedDataBuffer != null) {
          releasedConsumedReadBuffer();
        }
        this.synchronisationObject.wait(500);
      }
      this.bufferedRecord=null;
    }
  }
  if (getType() == ChannelType.NETWORK) {
    transferEvent(new ByteBufferedChannelCloseEvent());
  }
}",0.6100094428706326
55921,"/** 
 * {@inheritDoc}
 */
@Override public void close() throws IOException, InterruptedException {
  this.deserializationBuffer.clear();
  if (this.uncompressedDataBuffer != null) {
    releasedConsumedReadBuffer();
  }
synchronized (this.synchronisationObject) {
    if (!this.brokerAggreedToCloseChannel) {
      while (!this.brokerAggreedToCloseChannel) {
        requestReadBuffersFromBroker();
        if (this.uncompressedDataBuffer != null || this.compressedDataBuffer != null) {
          releasedConsumedReadBuffer();
        }
        this.synchronisationObject.wait(500);
      }
      this.bufferedRecord=null;
    }
  }
  if (getType() == ChannelType.NETWORK) {
    transferEvent(new ByteBufferedChannelCloseEvent());
  }
}","/** 
 * {@inheritDoc}
 */
@Override public void close() throws IOException, InterruptedException {
  this.deserializationBuffer.clear();
  if (this.uncompressedDataBuffer != null) {
    releasedConsumedReadBuffer();
  }
  if (this.getType() == ChannelType.NETWORK) {
synchronized (this.synchronisationObject) {
      if (!this.brokerAggreedToCloseChannel) {
        while (!this.brokerAggreedToCloseChannel) {
          requestReadBuffersFromBroker();
          if (this.uncompressedDataBuffer != null || this.compressedDataBuffer != null) {
            releasedConsumedReadBuffer();
          }
          this.synchronisationObject.wait(500);
        }
        this.bufferedRecord=null;
      }
    }
  }
  if (getType() == ChannelType.NETWORK) {
    transferEvent(new ByteBufferedChannelCloseEvent());
  }
}",0.4103559870550162
55922,"/** 
 * Adds the necessary vertexes for sampling & histogram creation etc for range partitioning
 * @param connection
 * @param outputVertex
 * @param inputVertex
 * @throws JobGraphDefinitionException 
 */
private void connectWithSamplingPartitionRangeStrategy(PactConnection connection,AbstractJobVertex outputVertex,AbstractJobVertex inputVertex) throws JobGraphDefinitionException {
  TaskConfig inputConfig=new TaskConfig(inputVertex.getConfiguration());
  TaskConfig outputConfig=new TaskConfig(outputVertex.getConfiguration());
  int sourceDOP=connection.getSourcePact().getDegreeOfParallelism();
  int sourceIPM=connection.getSourcePact().getInstancesPerMachine();
  int targetDOP=connection.getTargetPact().getDegreeOfParallelism();
  int targetIPM=connection.getTargetPact().getInstancesPerMachine();
  Class<?> sourceStub=connection.getSourcePact().getPactContract().getUserCodeClass();
  if (targetDOP == 1) {
    if (sourceDOP == 1) {
      outputVertex.connectTo(inputVertex,ChannelType.INMEMORY,CompressionLevel.NO_COMPRESSION);
    }
 else {
      outputVertex.connectTo(inputVertex,ChannelType.NETWORK,CompressionLevel.NO_COMPRESSION);
    }
    outputConfig.addOutputShipStrategy(ShipStrategy.FORWARD);
    inputConfig.addInputShipStrategy(ShipStrategy.FORWARD);
    return;
  }
  JobTaskVertex sampleVertex=new JobTaskVertex(""String_Node_Str"",this.jobGraph);
  auxVertices.add(sampleVertex);
  sampleVertex.setTaskClass(SampleTask.class);
  TaskConfig sampleConfig=new TaskConfig(sampleVertex.getConfiguration());
  sampleVertex.setNumberOfSubtasks(sourceDOP);
  if (sourceIPM >= 1) {
    sampleVertex.setNumberOfSubtasksPerInstance(sourceIPM);
  }
  sampleConfig.setStubClass(sourceStub);
  outputVertex.connectTo(sampleVertex,ChannelType.INMEMORY,CompressionLevel.NO_COMPRESSION);
  outputConfig.addOutputShipStrategy(ShipStrategy.FORWARD);
  sampleConfig.addInputShipStrategy(ShipStrategy.FORWARD);
  JobTaskVertex histogramVertex=new JobTaskVertex(""String_Node_Str"",this.jobGraph);
  auxVertices.add(histogramVertex);
  histogramVertex.setTaskClass(HistogramTask.class);
  histogramVertex.setNumberOfSubtasks(1);
  TaskConfig histogramConfig=new TaskConfig(histogramVertex.getConfiguration());
  histogramConfig.setStubClass(sourceStub);
  histogramConfig.setLocalStrategy(LocalStrategy.SORT);
  Configuration histogramStubConfig=new Configuration();
  histogramStubConfig.setInteger(HistogramTask.NUMBER_OF_BUCKETS,targetDOP);
  histogramConfig.setStubParameters(histogramStubConfig);
  assignMemory(histogramConfig,outputConfig.getStubParameters().getInteger(HistogramTask.HISTOGRAM_MEMORY,-1));
  histogramConfig.addInputShipStrategy(ShipStrategy.FORWARD);
  sampleConfig.addOutputShipStrategy(ShipStrategy.FORWARD);
  sampleVertex.connectTo(histogramVertex,ChannelType.NETWORK,CompressionLevel.NO_COMPRESSION);
  JobTaskVertex partitionVertex=new JobTaskVertex(""String_Node_Str"",this.jobGraph);
  auxVertices.add(partitionVertex);
  partitionVertex.setTaskClass(PartitionTask.class);
  partitionVertex.setNumberOfSubtasks(sourceDOP);
  if (sourceIPM >= 1) {
    partitionVertex.setNumberOfSubtasksPerInstance(sourceIPM);
  }
  TaskConfig partitionConfig=new TaskConfig(partitionVertex.getConfiguration());
  partitionConfig.setStubClass(sourceStub);
  Configuration partitionStubConfig=new Configuration();
  partitionStubConfig.setString(PartitionTask.GLOBAL_PARTITIONING_ORDER,connection.getTargetPact().getGlobalProperties().getKeyOrder().name());
  partitionConfig.setStubParameters(partitionStubConfig);
  JobTaskVertex tempVertex=generateTempVertex(connection.getSourcePact().getPactContract().getUserCodeClass(),sourceDOP);
  tempVertex.setVertexToShareInstancesWith(outputVertex);
  TaskConfig tempConfig=new TaskConfig(tempVertex.getConfiguration());
  outputVertex.connectTo(tempVertex,ChannelType.INMEMORY,CompressionLevel.NO_COMPRESSION);
  tempConfig.addInputShipStrategy(ShipStrategy.FORWARD);
  outputConfig.addOutputShipStrategy(ShipStrategy.FORWARD);
  tempVertex.connectTo(partitionVertex,ChannelType.INMEMORY,CompressionLevel.NO_COMPRESSION);
  partitionConfig.addInputShipStrategy(ShipStrategy.FORWARD);
  tempConfig.addOutputShipStrategy(ShipStrategy.FORWARD);
  histogramVertex.connectTo(partitionVertex,ChannelType.NETWORK,CompressionLevel.NO_COMPRESSION);
  partitionConfig.addInputShipStrategy(ShipStrategy.BROADCAST);
  histogramConfig.addOutputShipStrategy(ShipStrategy.BROADCAST);
  partitionVertex.connectTo(inputVertex,ChannelType.NETWORK,CompressionLevel.NO_COMPRESSION);
  inputConfig.addInputShipStrategy(ShipStrategy.PARTITION_RANGE);
  partitionConfig.addOutputShipStrategy(ShipStrategy.PARTITION_RANGE);
}","/** 
 * Adds the necessary vertexes for sampling & histogram creation etc for range partitioning
 * @param connection
 * @param outputVertex
 * @param inputVertex
 * @throws JobGraphDefinitionException 
 */
private void connectWithSamplingPartitionRangeStrategy(PactConnection connection,AbstractJobVertex outputVertex,AbstractJobVertex inputVertex) throws JobGraphDefinitionException {
  TaskConfig inputConfig=new TaskConfig(inputVertex.getConfiguration());
  TaskConfig outputConfig=new TaskConfig(outputVertex.getConfiguration());
  int sourceDOP=connection.getSourcePact().getDegreeOfParallelism();
  int sourceIPM=connection.getSourcePact().getInstancesPerMachine();
  int targetDOP=connection.getTargetPact().getDegreeOfParallelism();
  int targetIPM=connection.getTargetPact().getInstancesPerMachine();
  Class<?> sourceStub=connection.getSourcePact().getPactContract().getUserCodeClass();
  if (targetDOP == 1) {
    if (sourceDOP == 1) {
      outputVertex.connectTo(inputVertex,ChannelType.INMEMORY,CompressionLevel.NO_COMPRESSION);
    }
 else {
      outputVertex.connectTo(inputVertex,ChannelType.NETWORK,CompressionLevel.NO_COMPRESSION);
    }
    outputConfig.addOutputShipStrategy(ShipStrategy.FORWARD);
    inputConfig.addInputShipStrategy(ShipStrategy.FORWARD);
    return;
  }
  JobTaskVertex sampleVertex=new JobTaskVertex(""String_Node_Str"",this.jobGraph);
  auxVertices.add(sampleVertex);
  sampleVertex.setTaskClass(SampleTask.class);
  TaskConfig sampleConfig=new TaskConfig(sampleVertex.getConfiguration());
  sampleVertex.setNumberOfSubtasks(sourceDOP);
  if (sourceIPM >= 1) {
    sampleVertex.setNumberOfSubtasksPerInstance(sourceIPM);
  }
  sampleConfig.setStubClass(sourceStub);
  outputVertex.connectTo(sampleVertex,ChannelType.INMEMORY,CompressionLevel.NO_COMPRESSION);
  outputConfig.addOutputShipStrategy(ShipStrategy.FORWARD);
  sampleConfig.addInputShipStrategy(ShipStrategy.FORWARD);
  JobTaskVertex histogramVertex=new JobTaskVertex(""String_Node_Str"",this.jobGraph);
  auxVertices.add(histogramVertex);
  histogramVertex.setTaskClass(HistogramTask.class);
  histogramVertex.setNumberOfSubtasks(1);
  TaskConfig histogramConfig=new TaskConfig(histogramVertex.getConfiguration());
  histogramConfig.setStubClass(sourceStub);
  histogramConfig.setLocalStrategy(LocalStrategy.SORT);
  Configuration histogramStubConfig=new Configuration();
  histogramStubConfig.setInteger(HistogramTask.NUMBER_OF_BUCKETS,targetDOP);
  histogramConfig.setStubParameters(histogramStubConfig);
  assignMemory(histogramConfig,outputConfig.getStubParameters().getInteger(HistogramTask.HISTOGRAM_MEMORY,-1));
  histogramConfig.addInputShipStrategy(ShipStrategy.FORWARD);
  sampleConfig.addOutputShipStrategy(ShipStrategy.FORWARD);
  sampleVertex.connectTo(histogramVertex,ChannelType.NETWORK,CompressionLevel.NO_COMPRESSION);
  JobTaskVertex partitionVertex=new JobTaskVertex(""String_Node_Str"",this.jobGraph);
  auxVertices.add(partitionVertex);
  partitionVertex.setTaskClass(PartitionTask.class);
  partitionVertex.setNumberOfSubtasks(sourceDOP);
  if (sourceIPM >= 1) {
    partitionVertex.setNumberOfSubtasksPerInstance(sourceIPM);
  }
  TaskConfig partitionConfig=new TaskConfig(partitionVertex.getConfiguration());
  partitionConfig.setStubClass(sourceStub);
  Configuration partitionStubConfig=new Configuration();
  partitionStubConfig.setString(PartitionTask.GLOBAL_PARTITIONING_ORDER,connection.getTargetPact().getGlobalProperties().getKeyOrder().name());
  partitionConfig.setStubParameters(partitionStubConfig);
  JobTaskVertex tempVertex=generateTempVertex(connection.getSourcePact().getPactContract().getUserCodeClass(),sourceDOP,sourceIPM);
  tempVertex.setVertexToShareInstancesWith(outputVertex);
  TaskConfig tempConfig=new TaskConfig(tempVertex.getConfiguration());
  outputVertex.connectTo(tempVertex,ChannelType.INMEMORY,CompressionLevel.NO_COMPRESSION);
  tempConfig.addInputShipStrategy(ShipStrategy.FORWARD);
  outputConfig.addOutputShipStrategy(ShipStrategy.FORWARD);
  tempVertex.connectTo(partitionVertex,ChannelType.INMEMORY,CompressionLevel.NO_COMPRESSION);
  partitionConfig.addInputShipStrategy(ShipStrategy.FORWARD);
  tempConfig.addOutputShipStrategy(ShipStrategy.FORWARD);
  histogramVertex.connectTo(partitionVertex,ChannelType.NETWORK,CompressionLevel.NO_COMPRESSION);
  partitionConfig.addInputShipStrategy(ShipStrategy.BROADCAST);
  histogramConfig.addOutputShipStrategy(ShipStrategy.BROADCAST);
  partitionVertex.connectTo(inputVertex,ChannelType.NETWORK,CompressionLevel.NO_COMPRESSION);
  inputConfig.addInputShipStrategy(ShipStrategy.PARTITION_RANGE);
  partitionConfig.addOutputShipStrategy(ShipStrategy.PARTITION_RANGE);
}",0.998930023539482
55923,"/** 
 * @param connection
 * @param outputVertex
 * @param inputVertex
 * @throws JobGraphDefinitionException
 * @throws CompilerException
 */
private void connectJobVertices(PactConnection connection,AbstractJobVertex outputVertex,AbstractJobVertex inputVertex) throws JobGraphDefinitionException, CompilerException {
  ChannelType channelType=null;
switch (connection.getShipStrategy()) {
case FORWARD:
case PARTITION_LOCAL_HASH:
    int sourceDOP=connection.getSourcePact().getDegreeOfParallelism();
  int sourceInnerDOP=connection.getSourcePact().getInstancesPerMachine();
int sourceNumInstances=(int)Math.ceil((double)sourceDOP / (double)sourceInnerDOP);
int targetDOP=connection.getTargetPact().getDegreeOfParallelism();
int targetInnerDOP=connection.getTargetPact().getInstancesPerMachine();
int targetNumInstances=(int)Math.ceil((double)targetDOP / (double)targetInnerDOP);
channelType=sourceNumInstances == targetNumInstances ? ChannelType.INMEMORY : ChannelType.NETWORK;
break;
case PARTITION_HASH:
case BROADCAST:
case SFR:
channelType=ChannelType.NETWORK;
break;
default :
throw new IllegalArgumentException(""String_Node_Str"" + connection.getShipStrategy().name());
}
TaskConfig outputConfig=new TaskConfig(outputVertex.getConfiguration());
TaskConfig inputConfig=new TaskConfig(inputVertex.getConfiguration());
TaskConfig tempConfig=null;
switch (connection.getTempMode()) {
case NONE:
outputVertex.connectTo(inputVertex,channelType,CompressionLevel.NO_COMPRESSION);
outputConfig.addOutputShipStrategy(connection.getShipStrategy());
inputConfig.addInputShipStrategy(connection.getShipStrategy());
break;
case TEMP_SENDER_SIDE:
int pd=connection.getSourcePact().getDegreeOfParallelism();
JobTaskVertex tempVertex=generateTempVertex(connection.getSourcePact().getPactContract().getUserCodeClass(),pd);
outputVertex.connectTo(tempVertex,ChannelType.INMEMORY,CompressionLevel.NO_COMPRESSION);
tempVertex.connectTo(inputVertex,channelType,CompressionLevel.NO_COMPRESSION);
tempVertex.setVertexToShareInstancesWith(outputVertex);
tempConfig=new TaskConfig(tempVertex.getConfiguration());
outputConfig.addOutputShipStrategy(ShipStrategy.FORWARD);
tempConfig.addInputShipStrategy(ShipStrategy.FORWARD);
tempConfig.addOutputShipStrategy(connection.getShipStrategy());
inputConfig.addInputShipStrategy(connection.getShipStrategy());
break;
case TEMP_RECEIVER_SIDE:
int pdr=connection.getTargetPact().getDegreeOfParallelism();
tempVertex=generateTempVertex(connection.getSourcePact().getPactContract().getUserCodeClass(),pdr);
outputVertex.connectTo(tempVertex,channelType,CompressionLevel.NO_COMPRESSION);
tempVertex.connectTo(inputVertex,ChannelType.INMEMORY,CompressionLevel.NO_COMPRESSION);
tempVertex.setVertexToShareInstancesWith(inputVertex);
tempConfig=new TaskConfig(tempVertex.getConfiguration());
outputConfig.addOutputShipStrategy(connection.getShipStrategy());
tempConfig.addInputShipStrategy(connection.getShipStrategy());
tempConfig.addOutputShipStrategy(ShipStrategy.FORWARD);
inputConfig.addInputShipStrategy(ShipStrategy.FORWARD);
break;
default :
throw new CompilerException(""String_Node_Str"" + connection.getTempMode());
}
}","/** 
 * @param connection
 * @param outputVertex
 * @param inputVertex
 * @throws JobGraphDefinitionException
 * @throws CompilerException
 */
private void connectJobVertices(PactConnection connection,AbstractJobVertex outputVertex,AbstractJobVertex inputVertex) throws JobGraphDefinitionException, CompilerException {
  ChannelType channelType=null;
switch (connection.getShipStrategy()) {
case FORWARD:
case PARTITION_LOCAL_HASH:
    int sourceDOP=connection.getSourcePact().getDegreeOfParallelism();
  int sourceInnerDOP=connection.getSourcePact().getInstancesPerMachine();
int sourceNumInstances=(int)Math.ceil((double)sourceDOP / (double)sourceInnerDOP);
int targetDOP=connection.getTargetPact().getDegreeOfParallelism();
int targetInnerDOP=connection.getTargetPact().getInstancesPerMachine();
int targetNumInstances=(int)Math.ceil((double)targetDOP / (double)targetInnerDOP);
channelType=sourceNumInstances == targetNumInstances ? ChannelType.INMEMORY : ChannelType.NETWORK;
break;
case PARTITION_HASH:
case BROADCAST:
case SFR:
channelType=ChannelType.NETWORK;
break;
default :
throw new IllegalArgumentException(""String_Node_Str"" + connection.getShipStrategy().name());
}
TaskConfig outputConfig=new TaskConfig(outputVertex.getConfiguration());
TaskConfig inputConfig=new TaskConfig(inputVertex.getConfiguration());
TaskConfig tempConfig=null;
switch (connection.getTempMode()) {
case NONE:
outputVertex.connectTo(inputVertex,channelType,CompressionLevel.NO_COMPRESSION);
outputConfig.addOutputShipStrategy(connection.getShipStrategy());
inputConfig.addInputShipStrategy(connection.getShipStrategy());
break;
case TEMP_SENDER_SIDE:
int degreeOfParallelism=connection.getSourcePact().getDegreeOfParallelism();
int instancesPerMachine=connection.getSourcePact().getInstancesPerMachine();
JobTaskVertex tempVertex=generateTempVertex(connection.getSourcePact().getPactContract().getUserCodeClass(),degreeOfParallelism,instancesPerMachine);
outputVertex.connectTo(tempVertex,ChannelType.INMEMORY,CompressionLevel.NO_COMPRESSION);
tempVertex.connectTo(inputVertex,channelType,CompressionLevel.NO_COMPRESSION);
tempVertex.setVertexToShareInstancesWith(outputVertex);
tempConfig=new TaskConfig(tempVertex.getConfiguration());
outputConfig.addOutputShipStrategy(ShipStrategy.FORWARD);
tempConfig.addInputShipStrategy(ShipStrategy.FORWARD);
tempConfig.addOutputShipStrategy(connection.getShipStrategy());
inputConfig.addInputShipStrategy(connection.getShipStrategy());
break;
case TEMP_RECEIVER_SIDE:
degreeOfParallelism=connection.getTargetPact().getDegreeOfParallelism();
instancesPerMachine=connection.getTargetPact().getInstancesPerMachine();
tempVertex=generateTempVertex(connection.getSourcePact().getPactContract().getUserCodeClass(),degreeOfParallelism,instancesPerMachine);
outputVertex.connectTo(tempVertex,channelType,CompressionLevel.NO_COMPRESSION);
tempVertex.connectTo(inputVertex,ChannelType.INMEMORY,CompressionLevel.NO_COMPRESSION);
tempVertex.setVertexToShareInstancesWith(inputVertex);
tempConfig=new TaskConfig(tempVertex.getConfiguration());
outputConfig.addOutputShipStrategy(connection.getShipStrategy());
tempConfig.addInputShipStrategy(connection.getShipStrategy());
tempConfig.addOutputShipStrategy(ShipStrategy.FORWARD);
inputConfig.addInputShipStrategy(ShipStrategy.FORWARD);
break;
default :
throw new CompilerException(""String_Node_Str"" + connection.getTempMode());
}
}",0.9572127139364304
55924,"/** 
 * @param stubClass
 * @param dop
 * @return
 */
private JobTaskVertex generateTempVertex(Class<?> stubClass,int dop){
  JobTaskVertex tempVertex=new JobTaskVertex(""String_Node_Str"",this.jobGraph);
  tempVertex.setTaskClass(TempTask.class);
  TaskConfig tempConfig=new TaskConfig(tempVertex.getConfiguration());
  tempConfig.setStubClass(stubClass);
  assignMemory(tempConfig,PactCompiler.DEFAULT_TEMP_TASK_MEMORY);
  tempVertex.setNumberOfSubtasks(dop);
  return tempVertex;
}","/** 
 * @param stubClass
 * @param dop
 * @return
 */
private JobTaskVertex generateTempVertex(Class<?> stubClass,int dop,int instancesPerMachine){
  JobTaskVertex tempVertex=new JobTaskVertex(""String_Node_Str"",this.jobGraph);
  tempVertex.setTaskClass(TempTask.class);
  TaskConfig tempConfig=new TaskConfig(tempVertex.getConfiguration());
  tempConfig.setStubClass(stubClass);
  assignMemory(tempConfig,PactCompiler.DEFAULT_TEMP_TASK_MEMORY);
  tempVertex.setNumberOfSubtasks(dop);
  tempVertex.setNumberOfSubtasksPerInstance(instancesPerMachine);
  return tempVertex;
}",0.9146110056925996
55925,"/** 
 * Requests an empty buffer with a minimum size of <code>minimumSizeOfBuffer</code>. The method returns immediately, even if the request could not be fulfilled. Note that <code>minimumSizeOfBuffer</code> must not exceed the value returned by the method <code>getMaximumBufferSize()</code>.
 * @param minimumSizeOfBuffer the minimum size of the requested read buffer in bytes
 * @return the buffer with at least the requested size or <code>null</code> if no such buffer is currently available
 * @throws IOException thrown if an I/O error occurs while allocating the buffer
 */
Buffer requestEmptyBuffer(int minimumSizeOfBuffer) throws IOException ;","/** 
 * Requests an empty buffer with a minimum size of <code>minimumSizeOfBuffer</code>. The method returns immediately, even if the request could not be fulfilled. Note that <code>minimumSizeOfBuffer</code> must not exceed the value returned by the method <code>getMaximumBufferSize()</code>.
 * @param minimumSizeOfBuffer the minimum size of the requested read buffer in bytes
 * @param minimumReserve the minimum buffer reserve that must be kept by the buffer provider
 * @return the buffer with at least the requested size or <code>null</code> if no such buffer is currently available
 * @throws IOException thrown if an I/O error occurs while allocating the buffer
 */
Buffer requestEmptyBuffer(int minimumSizeOfBuffer,int minimumReserve) throws IOException ;",0.921015514809591
55926,"/** 
 * Requests an empty buffer with a minimum size of <code>minimumSizeOfBuffer</code>. The method blocks until the request can be fulfilled. Note that <code>minimumSizeOfBuffer</code> must not exceed the value returned by the method <code>getMaximumBufferSize()</code>.
 * @param minimumSizeOfBuffer the minimum size of the requested read buffer in bytes
 * @return the buffer with at least the requested size
 * @throws IOException thrown if an I/O error occurs while allocating the buffer
 * @throws InterruptedException thrown if the thread waiting for the buffer is interrupted
 */
Buffer requestEmptyBufferBlocking(int minimumSizeOfBuffer) throws IOException, InterruptedException ;","/** 
 * Requests an empty buffer with a minimum size of <code>minimumSizeOfBuffer</code>. The method blocks until the request can be fulfilled. Note that <code>minimumSizeOfBuffer</code> must not exceed the value returned by the method <code>getMaximumBufferSize()</code>.
 * @param minimumSizeOfBuffer the minimum size of the requested read buffer in bytes
 * @param minimumReserve the minimum buffer reserve that must be kept by the buffer provider
 * @return the buffer with at least the requested size
 * @throws IOException thrown if an I/O error occurs while allocating the buffer
 * @throws InterruptedException thrown if the thread waiting for the buffer is interrupted
 */
Buffer requestEmptyBufferBlocking(int minimumSizeOfBuffer,int minimumReserve) throws IOException, InterruptedException ;",0.9249329758713136
55927,"/** 
 * Sets the designated number of buffers for this local buffer cache.
 * @param designatedNumberOfBuffers the designated number of buffers for this local buffer cache
 */
public void setDesignatedNumberOfBuffers(final int designatedNumberOfBuffers){
synchronized (this.buffers) {
    this.designatedNumberOfBuffers=designatedNumberOfBuffers;
    while (this.designatedNumberOfBuffers > this.requestedNumberOfBuffers) {
      if (this.buffers.isEmpty()) {
        break;
      }
      this.globalBufferPool.releaseGlobalBuffer(this.buffers.poll());
      this.requestedNumberOfBuffers--;
    }
    this.buffers.notify();
  }
}","/** 
 * Sets the designated number of buffers for this local buffer cache.
 * @param designatedNumberOfBuffers the designated number of buffers for this local buffer cache
 */
public void setDesignatedNumberOfBuffers(final int designatedNumberOfBuffers){
synchronized (this.buffers) {
    this.designatedNumberOfBuffers=designatedNumberOfBuffers;
    while (this.requestedNumberOfBuffers > this.designatedNumberOfBuffers) {
      if (this.buffers.isEmpty()) {
        break;
      }
      this.globalBufferPool.releaseGlobalBuffer(this.buffers.poll());
      this.requestedNumberOfBuffers--;
    }
    this.buffers.notify();
  }
}",0.9793650793650792
55928,"private Buffer requestBufferInternal(final int minimumSizeOfBuffer,final boolean block) throws InterruptedException {
  if (minimumSizeOfBuffer > this.maximumBufferSize) {
    throw new IllegalArgumentException(""String_Node_Str"" + minimumSizeOfBuffer + ""String_Node_Str""+ this.maximumBufferSize);
  }
synchronized (this.buffers) {
    if (this.requestedNumberOfBuffers > this.designatedNumberOfBuffers) {
      while (this.requestedNumberOfBuffers < this.designatedNumberOfBuffers) {
        final ByteBuffer buffer=this.buffers.poll();
        if (buffer == null) {
          break;
        }
        this.globalBufferPool.releaseGlobalBuffer(buffer);
        this.requestedNumberOfBuffers--;
      }
    }
    while (this.buffers.isEmpty()) {
      if (this.requestedNumberOfBuffers < this.designatedNumberOfBuffers) {
        final ByteBuffer buffer=this.globalBufferPool.lockGlobalBuffer();
        if (buffer != null) {
          this.buffers.add(buffer);
          this.requestedNumberOfBuffers++;
          continue;
        }
      }
      if (block) {
        this.buffers.wait();
      }
 else {
        return null;
      }
    }
    final ByteBuffer byteBuffer=this.buffers.poll();
    return BufferFactory.createFromMemory(minimumSizeOfBuffer,byteBuffer,this.buffers);
  }
}","private Buffer requestBufferInternal(final int minimumSizeOfBuffer,int minimumReserve,final boolean block) throws InterruptedException {
  if (minimumSizeOfBuffer > this.maximumBufferSize) {
    throw new IllegalArgumentException(""String_Node_Str"" + minimumSizeOfBuffer + ""String_Node_Str""+ this.maximumBufferSize);
  }
synchronized (this.buffers) {
    while (this.requestedNumberOfBuffers > this.designatedNumberOfBuffers) {
      final ByteBuffer buffer=this.buffers.poll();
      if (buffer == null) {
        break;
      }
      this.globalBufferPool.releaseGlobalBuffer(buffer);
      this.requestedNumberOfBuffers--;
    }
    if (minimumReserve > this.requestedNumberOfBuffers) {
      LOG.warn(""String_Node_Str"");
      minimumReserve=this.requestedNumberOfBuffers;
    }
    while (this.buffers.size() <= minimumReserve) {
      if (this.requestedNumberOfBuffers < this.designatedNumberOfBuffers) {
        final ByteBuffer buffer=this.globalBufferPool.lockGlobalBuffer();
        if (buffer != null) {
          this.buffers.add(buffer);
          this.requestedNumberOfBuffers++;
          continue;
        }
      }
      if (block) {
        this.buffers.wait();
      }
 else {
        return null;
      }
    }
    final ByteBuffer byteBuffer=this.buffers.poll();
    return BufferFactory.createFromMemory(minimumSizeOfBuffer,byteBuffer,this.buffers);
  }
}",0.8884716485167105
55929,"/** 
 * {@inheritDoc}
 */
@Override public Buffer requestEmptyBuffer(final int minimumSizeOfBuffer) throws IOException {
  try {
    return requestBufferInternal(minimumSizeOfBuffer,false);
  }
 catch (  InterruptedException e) {
    LOG.error(""String_Node_Str"");
  }
  return null;
}","/** 
 * {@inheritDoc}
 */
@Override public Buffer requestEmptyBuffer(final int minimumSizeOfBuffer,final int minimumReserve) throws IOException {
  try {
    return requestBufferInternal(minimumSizeOfBuffer,minimumReserve,false);
  }
 catch (  InterruptedException e) {
    LOG.error(""String_Node_Str"");
  }
  return null;
}",0.9342105263157896
55930,"/** 
 * {@inheritDoc}
 */
@Override public Buffer requestEmptyBufferBlocking(int minimumSizeOfBuffer) throws IOException, InterruptedException {
  return requestBufferInternal(minimumSizeOfBuffer,true);
}","/** 
 * {@inheritDoc}
 */
@Override public Buffer requestEmptyBufferBlocking(final int minimumSizeOfBuffer,final int minimumReserve) throws IOException, InterruptedException {
  return requestBufferInternal(minimumSizeOfBuffer,minimumReserve,true);
}",0.8986784140969163
55931,"private void processEnvelopeWithBuffer(final TransferEnvelope transferEnvelope,final TransferEnvelopeReceiverList receiverList,final boolean freeSourceBuffer) throws IOException, InterruptedException {
  if (!freeSourceBuffer) {
    final List<ChannelID> localReceivers=receiverList.getLocalReceivers();
    if (localReceivers.size() != 1) {
      throw new IOException(""String_Node_Str"");
    }
    final ChannelID localReceiver=localReceivers.get(0);
    final ChannelContext cc=this.registeredChannels.get(localReceiver);
    if (cc == null) {
      throw new IOException(""String_Node_Str"" + localReceiver);
    }
    if (!cc.isInputChannel()) {
      throw new IOException(""String_Node_Str"" + localReceiver + ""String_Node_Str"");
    }
    cc.queueTransferEnvelope(transferEnvelope);
    return;
  }
  final Buffer srcBuffer=transferEnvelope.getBuffer();
  if (receiverList.hasLocalReceivers()) {
    final List<ChannelID> localReceivers=receiverList.getLocalReceivers();
    for (    final ChannelID localReceiver : localReceivers) {
      final ChannelContext cc=this.registeredChannels.get(localReceiver);
      if (cc == null) {
        throw new IOException(""String_Node_Str"" + localReceiver);
      }
      if (!cc.isInputChannel()) {
        throw new IOException(""String_Node_Str"" + localReceiver + ""String_Node_Str"");
      }
      final InputChannelContext inputChannelContext=(InputChannelContext)cc;
      final Buffer destBuffer=inputChannelContext.requestEmptyBufferBlocking(srcBuffer.size());
      srcBuffer.copyToBuffer(destBuffer);
      final TransferEnvelope dup=transferEnvelope.duplicateWithoutBuffer();
      dup.setBuffer(destBuffer);
      inputChannelContext.queueTransferEnvelope(dup);
    }
  }
  if (receiverList.hasRemoteReceivers()) {
    final List<InetSocketAddress> remoteReceivers=receiverList.getRemoteReceivers();
    for (    final InetSocketAddress remoteReceiver : remoteReceivers) {
      this.networkConnectionManager.queueEnvelopeForTransfer(remoteReceiver,transferEnvelope.duplicate());
    }
  }
  srcBuffer.recycleBuffer();
}","private void processEnvelopeWithBuffer(final TransferEnvelope transferEnvelope,final TransferEnvelopeReceiverList receiverList,final boolean freeSourceBuffer) throws IOException, InterruptedException {
  if (!freeSourceBuffer) {
    final List<ChannelID> localReceivers=receiverList.getLocalReceivers();
    if (localReceivers.size() != 1) {
      throw new IOException(""String_Node_Str"");
    }
    final ChannelID localReceiver=localReceivers.get(0);
    final ChannelContext cc=this.registeredChannels.get(localReceiver);
    if (cc == null) {
      throw new IOException(""String_Node_Str"" + localReceiver);
    }
    if (!cc.isInputChannel()) {
      throw new IOException(""String_Node_Str"" + localReceiver + ""String_Node_Str"");
    }
    cc.queueTransferEnvelope(transferEnvelope);
    return;
  }
  final Buffer srcBuffer=transferEnvelope.getBuffer();
  if (receiverList.hasLocalReceivers()) {
    final List<ChannelID> localReceivers=receiverList.getLocalReceivers();
    for (    final ChannelID localReceiver : localReceivers) {
      final ChannelContext cc=this.registeredChannels.get(localReceiver);
      if (cc == null) {
        throw new IOException(""String_Node_Str"" + localReceiver);
      }
      if (!cc.isInputChannel()) {
        throw new IOException(""String_Node_Str"" + localReceiver + ""String_Node_Str"");
      }
      final InputChannelContext inputChannelContext=(InputChannelContext)cc;
      final Buffer destBuffer=inputChannelContext.requestEmptyBufferBlocking(srcBuffer.size(),1);
      srcBuffer.copyToBuffer(destBuffer);
      final TransferEnvelope dup=transferEnvelope.duplicateWithoutBuffer();
      dup.setBuffer(destBuffer);
      inputChannelContext.queueTransferEnvelope(dup);
    }
  }
  if (receiverList.hasRemoteReceivers()) {
    final List<InetSocketAddress> remoteReceivers=receiverList.getRemoteReceivers();
    for (    final InetSocketAddress remoteReceiver : remoteReceivers) {
      this.networkConnectionManager.queueEnvelopeForTransfer(remoteReceiver,transferEnvelope.duplicate());
    }
  }
  srcBuffer.recycleBuffer();
}",0.9995180722891568
55932,"@Override public Buffer requestEmptyBuffer(int minimumSizeOfBuffer) throws IOException {
  return this.inputGateContext.requestEmptyBuffer(minimumSizeOfBuffer);
}","@Override public Buffer requestEmptyBuffer(final int minimumSizeOfBuffer,final int minimumReserve) throws IOException {
  return this.inputGateContext.requestEmptyBuffer(minimumSizeOfBuffer,minimumReserve);
}",0.8756756756756757
55933,"@Override public Buffer requestEmptyBufferBlocking(int minimumSizeOfBuffer) throws IOException, InterruptedException {
  return this.inputGateContext.requestEmptyBufferBlocking(minimumSizeOfBuffer);
}","@Override public Buffer requestEmptyBufferBlocking(final int minimumSizeOfBuffer,final int minimumReserve) throws IOException, InterruptedException {
  return this.inputGateContext.requestEmptyBufferBlocking(minimumSizeOfBuffer,minimumReserve);
}",0.8968609865470852
55934,"/** 
 * {@inheritDoc}
 */
@Override public Buffer requestEmptyBuffer(final int minimumSizeOfBuffer) throws IOException {
  return this.taskContext.requestEmptyBuffer(minimumSizeOfBuffer);
}","/** 
 * {@inheritDoc}
 */
@Override public Buffer requestEmptyBuffer(final int minimumSizeOfBuffer,final int minimumReserve) throws IOException {
  return this.taskContext.requestEmptyBuffer(minimumSizeOfBuffer,minimumReserve);
}",0.9043062200956936
55935,"/** 
 * {@inheritDoc}
 */
@Override public Buffer requestEmptyBufferBlocking(final int minimumSizeOfBuffer) throws IOException, InterruptedException {
  return this.taskContext.requestEmptyBufferBlocking(minimumSizeOfBuffer);
}","/** 
 * {@inheritDoc}
 */
@Override public Buffer requestEmptyBufferBlocking(final int minimumSizeOfBuffer,final int minimumReserve) throws IOException, InterruptedException {
  return this.taskContext.requestEmptyBufferBlocking(minimumSizeOfBuffer,minimumReserve);
}",0.9190283400809716
55936,"/** 
 * {@inheritDoc}
 */
@Override public void releaseWriteBuffers() throws IOException, InterruptedException {
  if (this.outgoingTransferEnvelope == null) {
    LOG.error(""String_Node_Str"" + this.byteBufferedOutputChannel.getID());
    return;
  }
  if (this.outgoingTransferEnvelope.getBuffer() == null) {
    LOG.error(""String_Node_Str"" + this.byteBufferedOutputChannel.getID() + ""String_Node_Str"");
    return;
  }
  try {
    this.outgoingTransferEnvelope.getBuffer().finishWritePhase();
  }
 catch (  final IOException ioe) {
    this.byteBufferedOutputChannel.reportIOException(ioe);
  }
  if (!this.isReceiverRunning) {
    final Buffer memBuffer=this.outgoingTransferEnvelope.getBuffer();
    final Buffer fileBuffer=this.outputGateContext.getFileBuffer(memBuffer.size());
    memBuffer.copyToBuffer(fileBuffer);
    this.outgoingTransferEnvelope.setBuffer(fileBuffer);
    this.queuedOutgoingEnvelopes.add(this.outgoingTransferEnvelope);
    this.outgoingTransferEnvelope=null;
    memBuffer.recycleBuffer();
    return;
  }
  while (!this.queuedOutgoingEnvelopes.isEmpty()) {
    this.outputGateContext.processEnvelope(this.queuedOutgoingEnvelopes.poll());
  }
  this.outputGateContext.processEnvelope(this.outgoingTransferEnvelope);
  this.outgoingTransferEnvelope=null;
}","/** 
 * {@inheritDoc}
 */
@Override public void releaseWriteBuffers() throws IOException, InterruptedException {
  if (this.outgoingTransferEnvelope == null) {
    LOG.error(""String_Node_Str"" + this.byteBufferedOutputChannel.getID());
    return;
  }
  if (this.outgoingTransferEnvelope.getBuffer() == null) {
    LOG.error(""String_Node_Str"" + this.byteBufferedOutputChannel.getID() + ""String_Node_Str"");
    return;
  }
  try {
    this.outgoingTransferEnvelope.getBuffer().finishWritePhase();
  }
 catch (  final IOException ioe) {
    this.byteBufferedOutputChannel.reportIOException(ioe);
  }
  if (!this.isReceiverRunning) {
    final Buffer memBuffer=this.outgoingTransferEnvelope.getBuffer();
    final Buffer fileBuffer=this.outputGateContext.getFileBuffer(memBuffer.size());
    memBuffer.copyToBuffer(fileBuffer);
    this.outgoingTransferEnvelope.setBuffer(fileBuffer);
    this.queuedOutgoingEnvelopes.add(this.outgoingTransferEnvelope);
    this.outgoingTransferEnvelope=null;
    memBuffer.recycleBuffer();
    return;
  }
  while (!this.queuedOutgoingEnvelopes.isEmpty()) {
    this.outputGateContext.processEnvelope(this,this.queuedOutgoingEnvelopes.poll());
  }
  this.outputGateContext.processEnvelope(this,this.outgoingTransferEnvelope);
  this.outgoingTransferEnvelope=null;
}",0.9961270333075136
55937,"/** 
 * {@inheritDoc}
 */
@Override public BufferPairResponse requestEmptyWriteBuffers() throws InterruptedException, IOException {
  if (this.outgoingTransferEnvelope == null) {
    this.outgoingTransferEnvelope=createNewOutgoingTransferEnvelope();
  }
 else {
    if (this.outgoingTransferEnvelope.getBuffer() != null) {
      LOG.error(""String_Node_Str"" + this.byteBufferedOutputChannel.getID() + ""String_Node_Str"");
      return null;
    }
  }
  final int uncompressedBufferSize=calculateBufferSize();
  final Buffer buffer=this.outputGateContext.requestEmptyBufferBlocking(uncompressedBufferSize);
  final BufferPairResponse bufferResponse=new BufferPairResponse(null,buffer);
  this.outgoingTransferEnvelope.setBuffer(bufferResponse.getUncompressedDataBuffer());
  return bufferResponse;
}","/** 
 * {@inheritDoc}
 */
@Override public BufferPairResponse requestEmptyWriteBuffers() throws InterruptedException, IOException {
  if (this.outgoingTransferEnvelope == null) {
    this.outgoingTransferEnvelope=createNewOutgoingTransferEnvelope();
  }
 else {
    if (this.outgoingTransferEnvelope.getBuffer() != null) {
      LOG.error(""String_Node_Str"" + this.byteBufferedOutputChannel.getID() + ""String_Node_Str"");
      return null;
    }
  }
  final int uncompressedBufferSize=calculateBufferSize();
  final Buffer buffer=this.outputGateContext.requestEmptyBufferBlocking(this,uncompressedBufferSize);
  final BufferPairResponse bufferResponse=new BufferPairResponse(null,buffer);
  this.outgoingTransferEnvelope.setBuffer(bufferResponse.getUncompressedDataBuffer());
  return bufferResponse;
}",0.996869129618034
55938,"@Override public boolean hasDataLeftToTransmit() throws IOException, InterruptedException {
  if (!this.isReceiverRunning) {
    return true;
  }
  while (!this.queuedOutgoingEnvelopes.isEmpty()) {
    this.outputGateContext.processEnvelope(this.queuedOutgoingEnvelopes.poll());
  }
  return false;
}","@Override public boolean hasDataLeftToTransmit() throws IOException, InterruptedException {
  if (!this.isReceiverRunning) {
    return true;
  }
  while (!this.queuedOutgoingEnvelopes.isEmpty()) {
    this.outputGateContext.processEnvelope(this,this.queuedOutgoingEnvelopes.poll());
  }
  return false;
}",0.9917355371900828
55939,"/** 
 * {@inheritDoc}
 */
@Override public void transferEventToInputChannel(final AbstractEvent event) throws IOException, InterruptedException {
  if (this.outgoingTransferEnvelope != null) {
    this.outgoingTransferEnvelope.addEvent(event);
  }
 else {
    final TransferEnvelope ephemeralTransferEnvelope=createNewOutgoingTransferEnvelope();
    ephemeralTransferEnvelope.addEvent(event);
    if (!this.isReceiverRunning) {
      this.queuedOutgoingEnvelopes.add(ephemeralTransferEnvelope);
      return;
    }
    while (!this.queuedOutgoingEnvelopes.isEmpty()) {
      this.outputGateContext.processEnvelope(this.queuedOutgoingEnvelopes.poll());
    }
    this.outputGateContext.processEnvelope(ephemeralTransferEnvelope);
  }
}","/** 
 * {@inheritDoc}
 */
@Override public void transferEventToInputChannel(final AbstractEvent event) throws IOException, InterruptedException {
  if (this.outgoingTransferEnvelope != null) {
    this.outgoingTransferEnvelope.addEvent(event);
  }
 else {
    final TransferEnvelope ephemeralTransferEnvelope=createNewOutgoingTransferEnvelope();
    ephemeralTransferEnvelope.addEvent(event);
    if (!this.isReceiverRunning) {
      this.queuedOutgoingEnvelopes.add(ephemeralTransferEnvelope);
      return;
    }
    while (!this.queuedOutgoingEnvelopes.isEmpty()) {
      this.outputGateContext.processEnvelope(this,this.queuedOutgoingEnvelopes.poll());
    }
    this.outputGateContext.processEnvelope(this,ephemeralTransferEnvelope);
  }
}",0.993234100135318
55940,"/** 
 * Unregisters the given job represented by its   {@link ExecutionGraph} with the input split manager.
 * @param executionGraph the job to be unregistered
 */
public void unregisterJob(final ExecutionGraph executionGraph){
  final Iterator<ExecutionGroupVertex> it=new ExecutionGroupVertexIterator(executionGraph,true,-1);
  while (it.hasNext()) {
    final ExecutionGroupVertex groupVertex=it.next();
    final InputSplitAssigner assigner=this.assignerCache.remove(groupVertex);
    if (assigner == null) {
      LOG.error(""String_Node_Str"" + groupVertex.getName() + ""String_Node_Str"");
      continue;
    }
    assigner.unregisterGroupVertex(groupVertex);
  }
}","/** 
 * Unregisters the given job represented by its   {@link ExecutionGraph} with the input split manager.
 * @param executionGraph the job to be unregistered
 */
public void unregisterJob(final ExecutionGraph executionGraph){
  final Iterator<ExecutionGroupVertex> it=new ExecutionGroupVertexIterator(executionGraph,true,-1);
  while (it.hasNext()) {
    final ExecutionGroupVertex groupVertex=it.next();
    final InputSplit[] inputSplits=groupVertex.getInputSplits();
    if (inputSplits == null) {
      continue;
    }
    if (inputSplits.length == 0) {
      continue;
    }
    final InputSplitAssigner assigner=this.assignerCache.remove(groupVertex);
    if (assigner == null) {
      LOG.error(""String_Node_Str"" + groupVertex.getName() + ""String_Node_Str"");
      continue;
    }
    assigner.unregisterGroupVertex(groupVertex);
  }
}",0.88433575677462
55941,"@Override public void copyToBuffer(final Buffer destinationBuffer) throws IOException {
  if (destinationBuffer.isBackedByMemory()) {
    final long tbr=this.totalBytesRead;
    if (this.fileChannel != null) {
      this.fileBufferManager.releaseFileChannelForReading(this.gateID,this.fileID);
    }
    this.totalBytesRead=0;
    destinationBuffer.write(this);
    destinationBuffer.finishWritePhase();
    if (this.fileChannel != null) {
      this.fileBufferManager.releaseFileChannelForReading(this.gateID,this.fileID);
    }
    this.fileChannel=null;
    this.totalBytesRead=tbr;
    return;
  }
  throw new UnsupportedOperationException(""String_Node_Str"");
}","@Override public void copyToBuffer(final Buffer destinationBuffer) throws IOException {
  if (destinationBuffer.isBackedByMemory()) {
    final long tbr=this.totalBytesRead;
    if (this.fileChannel != null) {
      this.fileBufferManager.releaseFileChannelForReading(this.gateID,this.fileID);
    }
    this.totalBytesRead=0;
    while (remaining() > 0) {
      destinationBuffer.write(this);
    }
    destinationBuffer.finishWritePhase();
    if (this.fileChannel != null) {
      this.fileBufferManager.releaseFileChannelForReading(this.gateID,this.fileID);
    }
    this.fileChannel=null;
    this.totalBytesRead=tbr;
    return;
  }
  throw new UnsupportedOperationException(""String_Node_Str"");
}",0.9298245614035088
55942,"@Override public void copyToBuffer(Buffer destinationBuffer) throws IOException {
  final int oldPos=this.byteBuffer.position();
  while (remaining() > 0) {
    destinationBuffer.write(this);
  }
  this.byteBuffer.position(oldPos);
  if (!this.writeMode) {
    destinationBuffer.finishWritePhase();
  }
}","@Override public void copyToBuffer(Buffer destinationBuffer) throws IOException {
  final int oldPos=this.byteBuffer.position();
  this.byteBuffer.position(0);
  while (remaining() > 0) {
    destinationBuffer.write(this);
  }
  this.byteBuffer.position(oldPos);
  destinationBuffer.finishWritePhase();
}",0.6776315789473685
55943,"@Override public Map<InstanceType,InstanceTypeDescription> getMapOfAvailableInstanceTypes(){
  Map<InstanceType,InstanceTypeDescription> availableinstances=new HashMap<InstanceType,InstanceTypeDescription>();
  for (  InstanceType t : this.availableInstanceTypes) {
    availableinstances.put(t,InstanceTypeDescriptionFactory.construct(t,null,-1));
  }
  return availableinstances;
}","/** 
 * {@inheritDoc}
 */
@Override public Map<InstanceType,InstanceTypeDescription> getMapOfAvailableInstanceTypes(){
  final Map<InstanceType,InstanceTypeDescription> availableinstances=new SerializableHashMap<InstanceType,InstanceTypeDescription>();
  for (  InstanceType t : this.availableInstanceTypes) {
    availableinstances.put(t,InstanceTypeDescriptionFactory.construct(t,null,-1));
  }
  return availableinstances;
}",0.945679012345679
55944,"@Override public InternalBuffer duplicate() throws IOException, InterruptedException {
  this.fileBufferManager.increaseFileCounter(this.gateID,this.fileID);
  final FileBuffer dup=new FileBuffer((int)this.bufferSize,this.gateID,this.fileBufferManager);
  dup.writeMode=this.writeMode;
  dup.fileID=this.fileID;
  dup.offset=this.offset;
  return dup;
}","@Override public InternalBuffer duplicate() throws IOException, InterruptedException {
  this.fileBufferManager.increaseBufferCounter(this.gateID,this.fileID);
  final FileBuffer dup=new FileBuffer((int)this.bufferSize,this.gateID,this.fileBufferManager);
  dup.writeMode=this.writeMode;
  dup.fileID=this.fileID;
  dup.offset=this.offset;
  return dup;
}",0.9858757062146892
55945,"@Override public void recycleBuffer(){
  this.fileBufferManager.releaseFileChannelForReading(this.gateID,this.fileID,true);
}","@Override public void recycleBuffer(){
  try {
    if (this.fileChannel != null) {
      this.fileBufferManager.releaseFileChannelForReading(this.gateID,this.fileID);
      this.fileChannel=null;
    }
  }
 catch (  Exception e) {
    e.printStackTrace();
  }
  this.fileBufferManager.decreaseBufferCounter(this.gateID,this.fileID);
}",0.5315904139433552
55946,"@Override public void copyToBuffer(final Buffer destinationBuffer) throws IOException {
  if (destinationBuffer.isBackedByMemory()) {
    final long tbr=this.totalBytesRead;
    if (this.fileChannel != null) {
      this.fileBufferManager.releaseFileChannelForReading(this.gateID,this.fileID,false);
    }
    this.totalBytesRead=0;
    destinationBuffer.write(this);
    destinationBuffer.finishWritePhase();
    this.fileBufferManager.releaseFileChannelForReading(this.gateID,this.fileID,false);
    this.fileChannel=null;
    this.totalBytesRead=tbr;
    return;
  }
  throw new UnsupportedOperationException(""String_Node_Str"");
}","@Override public void copyToBuffer(final Buffer destinationBuffer) throws IOException {
  if (destinationBuffer.isBackedByMemory()) {
    final long tbr=this.totalBytesRead;
    if (this.fileChannel != null) {
      this.fileBufferManager.releaseFileChannelForReading(this.gateID,this.fileID);
    }
    this.totalBytesRead=0;
    destinationBuffer.write(this);
    destinationBuffer.finishWritePhase();
    if (this.fileChannel != null) {
      this.fileBufferManager.releaseFileChannelForReading(this.gateID,this.fileID);
    }
    this.fileChannel=null;
    this.totalBytesRead=tbr;
    return;
  }
  throw new UnsupportedOperationException(""String_Node_Str"");
}",0.9537750385208013
55947,"@Override public int read(ByteBuffer dst) throws IOException {
  if (this.writeMode) {
    throw new IOException(""String_Node_Str"");
  }
  if (this.fileChannel == null) {
    try {
      this.fileChannel=this.fileBufferManager.getFileChannelForReading(this.gateID,this.fileID);
    }
 catch (    InterruptedException e) {
      return -1;
    }
    if (this.fileChannel.position() != this.offset) {
      this.fileChannel.position(this.offset);
    }
  }
  if (this.totalBytesRead >= this.bufferSize) {
    return -1;
  }
  final int rem=remaining();
  int bytesRead;
  if (dst.remaining() > rem) {
    final int excess=dst.remaining() - rem;
    dst.limit(dst.limit() - excess);
    bytesRead=this.fileChannel.read(dst);
    dst.limit(dst.limit() + excess);
  }
 else {
    bytesRead=this.fileChannel.read(dst);
  }
  if (bytesRead < 0) {
    return -1;
  }
  this.totalBytesRead+=bytesRead;
  return bytesRead;
}","@Override public int read(ByteBuffer dst) throws IOException {
  if (this.writeMode) {
    throw new IOException(""String_Node_Str"");
  }
  if (this.fileChannel == null) {
    try {
      this.fileChannel=this.fileBufferManager.getFileChannelForReading(this.gateID,this.fileID);
    }
 catch (    InterruptedException e) {
      return -1;
    }
    if (this.fileChannel.position() != (this.offset + this.totalBytesRead)) {
      this.fileChannel.position(this.offset + this.totalBytesRead);
    }
  }
  if (this.totalBytesRead >= this.bufferSize) {
    return -1;
  }
  final int rem=remaining();
  int bytesRead;
  if (dst.remaining() > rem) {
    final int excess=dst.remaining() - rem;
    dst.limit(dst.limit() - excess);
    bytesRead=this.fileChannel.read(dst);
    dst.limit(dst.limit() + excess);
  }
 else {
    bytesRead=this.fileChannel.read(dst);
  }
  if (bytesRead < 0) {
    return -1;
  }
  this.totalBytesRead+=bytesRead;
  return bytesRead;
}",0.9637139807897546
55948,"@Override public void finishWritePhase() throws IOException {
  if (this.writeMode) {
    final long currentFileSize=this.offset + this.totalBytesWritten;
    this.fileChannel=null;
    this.bufferSize=this.totalBytesWritten;
    this.writeMode=false;
    this.fileID=this.fileBufferManager.reportEndOfWritePhase(this.gateID,currentFileSize);
  }
}","@Override public void finishWritePhase() throws IOException {
  if (this.writeMode) {
    final long currentFileSize=this.offset + this.totalBytesWritten;
    if (this.fileChannel != null) {
      this.fileChannel.position(currentFileSize);
    }
    this.fileChannel=null;
    this.bufferSize=this.totalBytesWritten;
    this.writeMode=false;
    this.fileID=this.fileBufferManager.reportEndOfWritePhase(this.gateID,currentFileSize);
  }
}",0.883248730964467
55949,"@Override public void recycleBuffer(){
  this.fileBufferManager.reportFileBufferAsConsumed(this.gateID,this.fileID);
}","@Override public void recycleBuffer(){
  this.fileBufferManager.releaseFileChannelForReading(this.gateID,this.fileID,true);
}",0.831275720164609
55950,"@Override public void copyToBuffer(final Buffer destinationBuffer) throws IOException {
  if (destinationBuffer.isBackedByMemory()) {
    destinationBuffer.write(this);
    destinationBuffer.finishWritePhase();
    return;
  }
  throw new UnsupportedOperationException(""String_Node_Str"");
}","@Override public void copyToBuffer(final Buffer destinationBuffer) throws IOException {
  if (destinationBuffer.isBackedByMemory()) {
    final long tbr=this.totalBytesRead;
    if (this.fileChannel != null) {
      this.fileBufferManager.releaseFileChannelForReading(this.gateID,this.fileID,false);
    }
    this.totalBytesRead=0;
    destinationBuffer.write(this);
    destinationBuffer.finishWritePhase();
    this.fileBufferManager.releaseFileChannelForReading(this.gateID,this.fileID,false);
    this.fileChannel=null;
    this.totalBytesRead=tbr;
    return;
  }
  throw new UnsupportedOperationException(""String_Node_Str"");
}",0.628385698808234
55951,"/** 
 * Returns the lock for a file channel of a   {@link WritableSpillingFile}.
 * @param gateID the ID of the gate the lock has been acquired for
 * @param currentFileSize the size of the file after the last write operation using the locked file channel
 * @throws IOException thrown if the lock could not be released
 */
public FileID reportEndOfWritePhase(final GateID gateID,final long currentFileSize) throws IOException {
  WritableSpillingFile writableSpillingFile=null;
  boolean removed=false;
synchronized (this.writableSpillingFileMap) {
    writableSpillingFile=this.writableSpillingFileMap.get(gateID);
    if (writableSpillingFile == null) {
      throw new IOException(""String_Node_Str"" + gateID);
    }
    writableSpillingFile.unlockWritableFileChannel(currentFileSize);
    if (writableSpillingFile.isReadRequested() && writableSpillingFile.isSafeToClose()) {
      this.writableSpillingFileMap.remove(gateID);
      removed=true;
    }
  }
  if (removed) {
    writableSpillingFile.close();
    Map<FileID,ReadableSpillingFile> map=null;
synchronized (this.readableSpillingFileMap) {
      map=this.readableSpillingFileMap.get(gateID);
      if (map == null) {
        map=new HashMap<FileID,ReadableSpillingFile>();
        this.readableSpillingFileMap.put(gateID,map);
      }
    }
synchronized (map) {
      map.put(writableSpillingFile.getFileID(),new ReadableSpillingFile(writableSpillingFile.getPhysicalFile()));
      map.notify();
    }
  }
  return writableSpillingFile.getFileID();
}","/** 
 * Returns the lock for a file channel of a   {@link WritableSpillingFile}.
 * @param gateID the ID of the gate the lock has been acquired for
 * @param currentFileSize the size of the file after the last write operation using the locked file channel
 * @throws IOException thrown if the lock could not be released
 */
public FileID reportEndOfWritePhase(final GateID gateID,final long currentFileSize) throws IOException {
  WritableSpillingFile writableSpillingFile=null;
  boolean removed=false;
synchronized (this.writableSpillingFileMap) {
    writableSpillingFile=this.writableSpillingFileMap.get(gateID);
    if (writableSpillingFile == null) {
      throw new IOException(""String_Node_Str"" + gateID);
    }
    writableSpillingFile.unlockWritableFileChannel(currentFileSize);
    if (writableSpillingFile.isReadRequested() && writableSpillingFile.isSafeToClose()) {
      this.writableSpillingFileMap.remove(gateID);
      removed=true;
    }
  }
  if (removed) {
    writableSpillingFile.close();
    Map<FileID,ReadableSpillingFile> map=null;
synchronized (this.readableSpillingFileMap) {
      map=this.readableSpillingFileMap.get(gateID);
      if (map == null) {
        map=new HashMap<FileID,ReadableSpillingFile>();
        this.readableSpillingFileMap.put(gateID,map);
      }
    }
synchronized (map) {
      map.put(writableSpillingFile.getFileID(),writableSpillingFile.toReadableSpillingFile());
      map.notify();
    }
  }
  return writableSpillingFile.getFileID();
}",0.9351944167497508
55952,"private ReadableSpillingFile getReadableSpillingFile(final GateID gateID,final FileID fileID) throws IOException, InterruptedException {
  if (gateID == null) {
    throw new IllegalStateException(""String_Node_Str"");
  }
  if (fileID == null) {
    throw new IllegalStateException(""String_Node_Str"");
  }
  Map<FileID,ReadableSpillingFile> map=null;
synchronized (this.readableSpillingFileMap) {
    map=this.readableSpillingFileMap.get(gateID);
    if (map == null) {
      map=new HashMap<FileID,ReadableSpillingFile>();
      this.readableSpillingFileMap.put(gateID,map);
    }
  }
synchronized (map) {
    while (!map.containsKey(fileID)) {
synchronized (this.writableSpillingFileMap) {
        WritableSpillingFile writableSpillingFile=this.writableSpillingFileMap.get(gateID);
        if (writableSpillingFile != null) {
          writableSpillingFile.requestReadAccess();
          if (writableSpillingFile.isSafeToClose()) {
            writableSpillingFile.close();
            this.writableSpillingFileMap.remove(gateID);
            map.put(writableSpillingFile.getFileID(),new ReadableSpillingFile(writableSpillingFile.getPhysicalFile()));
          }
        }
      }
      if (!map.containsKey(fileID)) {
        map.wait(WritableSpillingFile.MAXIMUM_TIME_WITHOUT_WRITE_ACCESS);
      }
    }
    return map.get(fileID);
  }
}","private ReadableSpillingFile getReadableSpillingFile(final GateID gateID,final FileID fileID) throws IOException, InterruptedException {
  if (gateID == null) {
    throw new IllegalStateException(""String_Node_Str"");
  }
  if (fileID == null) {
    throw new IllegalStateException(""String_Node_Str"");
  }
  Map<FileID,ReadableSpillingFile> map=null;
synchronized (this.readableSpillingFileMap) {
    map=this.readableSpillingFileMap.get(gateID);
    if (map == null) {
      map=new HashMap<FileID,ReadableSpillingFile>();
      this.readableSpillingFileMap.put(gateID,map);
    }
  }
synchronized (map) {
    while (!map.containsKey(fileID)) {
synchronized (this.writableSpillingFileMap) {
        WritableSpillingFile writableSpillingFile=this.writableSpillingFileMap.get(gateID);
        if (writableSpillingFile != null) {
          writableSpillingFile.requestReadAccess();
          if (writableSpillingFile.isSafeToClose()) {
            writableSpillingFile.close();
            this.writableSpillingFileMap.remove(gateID);
            map.put(writableSpillingFile.getFileID(),writableSpillingFile.toReadableSpillingFile());
          }
        }
      }
      if (!map.containsKey(fileID)) {
        map.wait(WritableSpillingFile.MAXIMUM_TIME_WITHOUT_WRITE_ACCESS);
      }
    }
    return map.get(fileID);
  }
}",0.9755914382275628
55953,"public void increaseFileCounter(final GateID gateID,final FileID fileID) throws IOException, InterruptedException {
  getReadableSpillingFile(gateID,fileID).increaseLeaseCounter();
}","public void increaseFileCounter(final GateID gateID,final FileID fileID) throws IOException, InterruptedException {
  getReadableSpillingFile(gateID,fileID).increaseNumberOfBuffers();
}",0.9427792915531336
55954,"public synchronized boolean checkForEndOfFile() throws IOException {
  --this.leaseCounter;
  if (this.leaseCounter == 0) {
    this.readableFileChannel.close();
    this.physicalFile.delete();
    return true;
  }
  return false;
}","public synchronized boolean checkForEndOfFile() throws IOException {
  --this.numberOfBuffers;
  if (this.numberOfBuffers == 0) {
    this.readableFileChannel.close();
    this.physicalFile.delete();
    return true;
  }
  return false;
}",0.8297872340425532
55955,"public ReadableSpillingFile(final File physicalFile) throws IOException {
  this.physicalFile=physicalFile;
  this.readableFileChannel=new FileInputStream(this.physicalFile).getChannel();
}","public ReadableSpillingFile(final File physicalFile,int numberOfBuffers) throws IOException {
  this.physicalFile=physicalFile;
  this.numberOfBuffers=numberOfBuffers;
  this.readableFileChannel=new FileInputStream(this.physicalFile).getChannel();
}",0.863013698630137
55956,"/** 
 * Releases the lock on the spilling file's   {@link WritableByteChannel}.
 * @param currentFileSize the current size of the spilling file in bytes
 */
void unlockWritableFileChannel(final long currentFileSize){
  this.writableChannelLocked=false;
  this.currentFileSize=currentFileSize;
  this.lastUnlockTime=System.currentTimeMillis();
}","/** 
 * Releases the lock on the spilling file's   {@link WritableByteChannel}.
 * @param currentFileSize the current size of the spilling file in bytes
 */
void unlockWritableFileChannel(final long currentFileSize){
  this.writableChannelLocked=false;
  this.currentFileSize=currentFileSize;
  this.lastUnlockTime=System.currentTimeMillis();
  ++this.numberOfBuffers;
}",0.9635854341736696
55957,"public void releaseFileChannelForReading(final GateID gateID,final FileID fileID,boolean deleteFile){
  try {
    Map<FileID,ReadableSpillingFile> map=null;
synchronized (this.readableSpillingFileMap) {
      map=this.readableSpillingFileMap.get(gateID);
      if (map == null) {
        if (this.canceledChannels.contains(gateID)) {
          return;
        }
 else {
          throw new IOException(""String_Node_Str"" + gateID);
        }
      }
      ReadableSpillingFile readableSpillingFile=null;
synchronized (map) {
        readableSpillingFile=map.get(fileID);
        if (readableSpillingFile == null) {
          if (this.canceledChannels.contains(gateID)) {
            return;
          }
 else {
            throw new IOException(""String_Node_Str"" + gateID);
          }
        }
        try {
          readableSpillingFile.unlockReadableFileChannel();
          if (deleteFile) {
            if (readableSpillingFile.checkForEndOfFile()) {
              map.remove(fileID);
              if (map.isEmpty()) {
                this.readableSpillingFileMap.remove(gateID);
              }
            }
          }
        }
 catch (        ClosedChannelException e) {
          if (this.canceledChannels.contains(gateID)) {
            readableSpillingFile.getPhysicalFile().delete();
          }
 else {
            throw e;
          }
        }
      }
    }
  }
 catch (  IOException ioe) {
    LOG.error(StringUtils.stringifyException(ioe));
  }
}","public void releaseFileChannelForReading(final GateID gateID,final FileID fileID){
  try {
    getReadableSpillingFile(gateID,fileID).unlockReadableFileChannel();
  }
 catch (  Exception e) {
    LOG.error(StringUtils.stringifyException(e));
  }
}",0.1936989498249708
55958,"/** 
 * Registers the given task with the byte buffered channel manager.
 * @param vertexID the ID of the task to be registered
 * @param environment the environment of the task
 * @param the set of output channels which are initially active
 */
public void register(final ExecutionVertexID vertexID,final Environment environment,final Set<ChannelID> activeOutputChannels){
  final TaskContext taskContext=new TaskContext();
synchronized (this.registeredChannels) {
    for (int i=0; i < environment.getNumberOfOutputGates(); ++i) {
      final OutputGate<?> outputGate=environment.getOutputGate(i);
      final OutputGateContext outputGateContext=new OutputGateContext(taskContext,outputGate,this,this.fileBufferManager);
      for (int j=0; j < outputGate.getNumberOfOutputChannels(); ++j) {
        final AbstractOutputChannel<?> outputChannel=outputGate.getOutputChannel(j);
        if (!(outputChannel instanceof AbstractByteBufferedOutputChannel)) {
          LOG.error(""String_Node_Str"" + outputChannel.getID() + ""String_Node_Str""+ environment.getJobID()+ ""String_Node_Str"");
          continue;
        }
        final AbstractByteBufferedOutputChannel<?> bboc=(AbstractByteBufferedOutputChannel<?>)outputChannel;
        if (this.registeredChannels.containsKey(bboc.getID())) {
          LOG.error(""String_Node_Str"" + bboc.getID() + ""String_Node_Str"");
          continue;
        }
        LOG.info(""String_Node_Str"" + bboc.getID());
        final OutputChannelContext outputChannelContext=new OutputChannelContext(outputGateContext,bboc,activeOutputChannels.contains(bboc.getID()));
        this.registeredChannels.put(bboc.getID(),outputChannelContext);
      }
    }
    for (int i=0; i < environment.getNumberOfInputGates(); ++i) {
      final InputGate<?> inputGate=environment.getInputGate(i);
      final InputGateContext inputGateContext=new InputGateContext(taskContext);
      for (int j=0; j < inputGate.getNumberOfInputChannels(); ++j) {
        final AbstractInputChannel<?> inputChannel=inputGate.getInputChannel(j);
        if (!(inputChannel instanceof AbstractByteBufferedInputChannel)) {
          LOG.error(""String_Node_Str"" + inputChannel.getID() + ""String_Node_Str""+ environment.getJobID()+ ""String_Node_Str"");
          continue;
        }
        final AbstractByteBufferedInputChannel<?> bbic=(AbstractByteBufferedInputChannel<?>)inputChannel;
        if (this.registeredChannels.containsKey(bbic.getID())) {
          LOG.error(""String_Node_Str"" + bbic.getID() + ""String_Node_Str"");
          continue;
        }
        LOG.info(""String_Node_Str"" + bbic.getID());
        final InputChannelContext inputChannelContext=new InputChannelContext(inputGateContext,this,bbic);
        this.registeredChannels.put(bbic.getID(),inputChannelContext);
      }
    }
  }
synchronized (this.taskMap) {
    this.taskMap.put(vertexID,taskContext);
  }
  redistributeGlobalBuffers();
}","/** 
 * Registers the given task with the byte buffered channel manager.
 * @param vertexID the ID of the task to be registered
 * @param environment the environment of the task
 * @param the set of output channels which are initially active
 */
public void register(final ExecutionVertexID vertexID,final Environment environment,final Set<ChannelID> activeOutputChannels){
  final TaskContext taskContext=new TaskContext();
synchronized (this.registeredChannels) {
    for (int i=0; i < environment.getNumberOfOutputGates(); ++i) {
      final OutputGate<?> outputGate=environment.getOutputGate(i);
      final OutputGateContext outputGateContext=new OutputGateContext(taskContext,outputGate,this,this.fileBufferManager);
      for (int j=0; j < outputGate.getNumberOfOutputChannels(); ++j) {
        final AbstractOutputChannel<?> outputChannel=outputGate.getOutputChannel(j);
        if (!(outputChannel instanceof AbstractByteBufferedOutputChannel)) {
          LOG.error(""String_Node_Str"" + outputChannel.getID() + ""String_Node_Str""+ environment.getJobID()+ ""String_Node_Str"");
          continue;
        }
        final AbstractByteBufferedOutputChannel<?> bboc=(AbstractByteBufferedOutputChannel<?>)outputChannel;
        if (this.registeredChannels.containsKey(bboc.getID())) {
          LOG.error(""String_Node_Str"" + bboc.getID() + ""String_Node_Str"");
          continue;
        }
        final boolean isActive=activeOutputChannels.contains(bboc.getID());
        LOG.info(""String_Node_Str"" + bboc.getID() + ""String_Node_Str""+ (isActive ? ""String_Node_Str"" : ""String_Node_Str"")+ ""String_Node_Str"");
        final OutputChannelContext outputChannelContext=new OutputChannelContext(outputGateContext,bboc,isActive);
        this.registeredChannels.put(bboc.getID(),outputChannelContext);
      }
    }
    for (int i=0; i < environment.getNumberOfInputGates(); ++i) {
      final InputGate<?> inputGate=environment.getInputGate(i);
      final InputGateContext inputGateContext=new InputGateContext(taskContext);
      for (int j=0; j < inputGate.getNumberOfInputChannels(); ++j) {
        final AbstractInputChannel<?> inputChannel=inputGate.getInputChannel(j);
        if (!(inputChannel instanceof AbstractByteBufferedInputChannel)) {
          LOG.error(""String_Node_Str"" + inputChannel.getID() + ""String_Node_Str""+ environment.getJobID()+ ""String_Node_Str"");
          continue;
        }
        final AbstractByteBufferedInputChannel<?> bbic=(AbstractByteBufferedInputChannel<?>)inputChannel;
        if (this.registeredChannels.containsKey(bbic.getID())) {
          LOG.error(""String_Node_Str"" + bbic.getID() + ""String_Node_Str"");
          continue;
        }
        LOG.info(""String_Node_Str"" + bbic.getID());
        final InputChannelContext inputChannelContext=new InputChannelContext(inputGateContext,this,bbic);
        this.registeredChannels.put(bbic.getID(),inputChannelContext);
      }
    }
  }
synchronized (this.taskMap) {
    this.taskMap.put(vertexID,taskContext);
  }
  redistributeGlobalBuffers();
}",0.9650067294751008
55959,"/** 
 * Entry point for the program.
 * @param args arguments from the command line
 */
@SuppressWarnings(""String_Node_Str"") public static void main(String[] args){
  Option configDirOpt=OptionBuilder.withArgName(""String_Node_Str"").hasArg().withDescription(""String_Node_Str"").create(""String_Node_Str"");
  Options options=new Options();
  options.addOption(configDirOpt);
  CommandLineParser parser=new GnuParser();
  CommandLine line=null;
  try {
    line=parser.parse(options,args);
  }
 catch (  ParseException e) {
    System.err.println(""String_Node_Str"" + e.getMessage());
    System.exit(FAILURERETURNCODE);
  }
  String configDir=line.getOptionValue(configDirOpt.getOpt(),null);
  TaskManager taskManager=null;
  try {
    taskManager=new TaskManager(configDir);
  }
 catch (  Throwable t) {
    LOG.fatal(""String_Node_Str"" + t.getMessage());
    LOG.error(System.err);
    System.exit(FAILURERETURNCODE);
  }
  taskManager.runIOLoop();
  taskManager.shutdown();
}","/** 
 * Entry point for the program.
 * @param args arguments from the command line
 */
@SuppressWarnings(""String_Node_Str"") public static void main(String[] args){
  Option configDirOpt=OptionBuilder.withArgName(""String_Node_Str"").hasArg().withDescription(""String_Node_Str"").create(""String_Node_Str"");
  Options options=new Options();
  options.addOption(configDirOpt);
  CommandLineParser parser=new GnuParser();
  CommandLine line=null;
  try {
    line=parser.parse(options,args);
  }
 catch (  ParseException e) {
    System.err.println(""String_Node_Str"" + e.getMessage());
    System.exit(FAILURERETURNCODE);
  }
  String configDir=line.getOptionValue(configDirOpt.getOpt(),null);
  TaskManager taskManager=null;
  try {
    taskManager=new TaskManager(configDir);
  }
 catch (  Throwable t) {
    LOG.fatal(""String_Node_Str"" + t.getMessage());
    System.exit(FAILURERETURNCODE);
  }
  taskManager.runIOLoop();
  taskManager.shutdown();
}",0.9859154929577464
55960,"/** 
 * {@inheritDoc}
 */
@Override public void releaseWriteBuffers() throws IOException, InterruptedException {
  if (this.outgoingTransferEnvelope == null) {
    LOG.error(""String_Node_Str"" + this.byteBufferedOutputChannel.getID());
    return;
  }
  if (this.outgoingTransferEnvelope.getBuffer() == null) {
    LOG.error(""String_Node_Str"" + this.byteBufferedOutputChannel.getID() + ""String_Node_Str"");
    return;
  }
  try {
    this.outgoingTransferEnvelope.getBuffer().finishWritePhase();
  }
 catch (  final IOException ioe) {
    this.byteBufferedOutputChannel.reportIOException(ioe);
  }
  if (!this.isReceiverRunning) {
    final Buffer memBuffer=this.outgoingTransferEnvelope.getBuffer();
    final Buffer fileBuffer=this.outputGateContext.getFileBuffer(memBuffer.size());
    memBuffer.copyToBuffer(fileBuffer);
    this.outgoingTransferEnvelope.setBuffer(fileBuffer);
    this.queuedOutgoingEnvelopes.add(this.outgoingTransferEnvelope);
    memBuffer.recycleBuffer();
    return;
  }
  while (!this.queuedOutgoingEnvelopes.isEmpty()) {
    this.outputGateContext.processEnvelope(this.queuedOutgoingEnvelopes.poll());
  }
  this.outputGateContext.processEnvelope(this.outgoingTransferEnvelope);
  this.outgoingTransferEnvelope=null;
}","/** 
 * {@inheritDoc}
 */
@Override public void releaseWriteBuffers() throws IOException, InterruptedException {
  if (this.outgoingTransferEnvelope == null) {
    LOG.error(""String_Node_Str"" + this.byteBufferedOutputChannel.getID());
    return;
  }
  if (this.outgoingTransferEnvelope.getBuffer() == null) {
    LOG.error(""String_Node_Str"" + this.byteBufferedOutputChannel.getID() + ""String_Node_Str"");
    return;
  }
  try {
    this.outgoingTransferEnvelope.getBuffer().finishWritePhase();
  }
 catch (  final IOException ioe) {
    this.byteBufferedOutputChannel.reportIOException(ioe);
  }
  if (!this.isReceiverRunning) {
    final Buffer memBuffer=this.outgoingTransferEnvelope.getBuffer();
    final Buffer fileBuffer=this.outputGateContext.getFileBuffer(memBuffer.size());
    memBuffer.copyToBuffer(fileBuffer);
    this.outgoingTransferEnvelope.setBuffer(fileBuffer);
    this.queuedOutgoingEnvelopes.add(this.outgoingTransferEnvelope);
    this.outgoingTransferEnvelope=null;
    memBuffer.recycleBuffer();
    return;
  }
  while (!this.queuedOutgoingEnvelopes.isEmpty()) {
    this.outputGateContext.processEnvelope(this.queuedOutgoingEnvelopes.poll());
  }
  this.outputGateContext.processEnvelope(this.outgoingTransferEnvelope);
  this.outgoingTransferEnvelope=null;
}",0.9842022116903634
55961,"/** 
 * Sets the designated number of buffers for this local buffer cache.
 * @param designatedNumberOfBuffers the designated number of buffers for this local buffer cache
 */
public void setDesignatedNumberOfBuffers(final int designatedNumberOfBuffers){
synchronized (this.buffers) {
    this.designatedNumberOfBuffers=designatedNumberOfBuffers;
    this.buffers.notify();
  }
}","/** 
 * Sets the designated number of buffers for this local buffer cache.
 * @param designatedNumberOfBuffers the designated number of buffers for this local buffer cache
 */
public void setDesignatedNumberOfBuffers(final int designatedNumberOfBuffers){
synchronized (this.buffers) {
    this.designatedNumberOfBuffers=designatedNumberOfBuffers;
    while (this.designatedNumberOfBuffers > this.requestedNumberOfBuffers) {
      if (this.buffers.isEmpty()) {
        break;
      }
      this.globalBufferPool.releaseGlobalBuffer(this.buffers.poll());
      this.requestedNumberOfBuffers--;
    }
    this.buffers.notify();
  }
}",0.7155599603567889
55962,"public LocalBufferCache(final int designatedNumberOfBuffers){
  this.globalBufferPool=GlobalBufferPool.getInstance();
  this.maximumBufferSize=this.globalBufferPool.getMaximumBufferSize();
  this.designatedNumberOfBuffers=designatedNumberOfBuffers;
}","public LocalBufferCache(final int designatedNumberOfBuffers,final boolean isShared){
  this.globalBufferPool=GlobalBufferPool.getInstance();
  this.maximumBufferSize=this.globalBufferPool.getMaximumBufferSize();
  this.designatedNumberOfBuffers=designatedNumberOfBuffers;
  this.isShared=isShared;
}",0.9107468123861566
55963,"/** 
 * {@inheritDoc}
 */
@Override public boolean isShared(){
  return false;
}","/** 
 * {@inheritDoc}
 */
@Override public boolean isShared(){
  return this.isShared;
}",0.9166666666666666
55964,"private void processEnvelopeWithBuffer(final TransferEnvelope transferEnvelope,final TransferEnvelopeReceiverList receiverList,final boolean freeSourceBuffer) throws IOException, InterruptedException {
  if (!freeSourceBuffer) {
    final List<ChannelID> localReceivers=receiverList.getLocalReceivers();
    if (localReceivers.size() != 1) {
      throw new IOException(""String_Node_Str"");
    }
    final ChannelID localReceiver=localReceivers.get(0);
synchronized (this.registeredChannels) {
      final ChannelContext cc=this.registeredChannels.get(localReceiver);
      if (cc == null) {
        throw new IOException(""String_Node_Str"" + localReceiver);
      }
      if (!cc.isInputChannel()) {
        throw new IOException(""String_Node_Str"" + localReceiver + ""String_Node_Str"");
      }
      cc.queueTransferEnvelope(transferEnvelope);
    }
    return;
  }
  final Buffer srcBuffer=transferEnvelope.getBuffer();
  if (receiverList.hasLocalReceivers()) {
    final List<ChannelID> localReceivers=receiverList.getLocalReceivers();
synchronized (this.registeredChannels) {
      for (      final ChannelID localReceiver : localReceivers) {
        final ChannelContext cc=this.registeredChannels.get(localReceiver);
        if (cc == null) {
          throw new IOException(""String_Node_Str"" + localReceiver);
        }
        if (!cc.isInputChannel()) {
          throw new IOException(""String_Node_Str"" + localReceiver + ""String_Node_Str"");
        }
        final InputChannelContext inputChannelContext=(InputChannelContext)cc;
        final Buffer destBuffer=inputChannelContext.requestEmptyBufferBlocking(srcBuffer.size());
        final TransferEnvelope dup=transferEnvelope.duplicateWithoutBuffer();
        dup.setBuffer(destBuffer);
        inputChannelContext.queueTransferEnvelope(dup);
      }
    }
  }
  if (receiverList.hasRemoteReceivers()) {
    final List<InetSocketAddress> remoteReceivers=receiverList.getRemoteReceivers();
    for (int i=0; i < remoteReceivers.size(); ++i) {
      this.networkConnectionManager.queueEnvelopeForTransfer(remoteReceivers.get(i),transferEnvelope.duplicate());
    }
  }
  srcBuffer.recycleBuffer();
}","private void processEnvelopeWithBuffer(final TransferEnvelope transferEnvelope,final TransferEnvelopeReceiverList receiverList,final boolean freeSourceBuffer) throws IOException, InterruptedException {
  if (!freeSourceBuffer) {
    final List<ChannelID> localReceivers=receiverList.getLocalReceivers();
    if (localReceivers.size() != 1) {
      throw new IOException(""String_Node_Str"");
    }
    final ChannelID localReceiver=localReceivers.get(0);
synchronized (this.registeredChannels) {
      final ChannelContext cc=this.registeredChannels.get(localReceiver);
      if (cc == null) {
        throw new IOException(""String_Node_Str"" + localReceiver);
      }
      if (!cc.isInputChannel()) {
        throw new IOException(""String_Node_Str"" + localReceiver + ""String_Node_Str"");
      }
      cc.queueTransferEnvelope(transferEnvelope);
    }
    return;
  }
  final Buffer srcBuffer=transferEnvelope.getBuffer();
  if (receiverList.hasLocalReceivers()) {
    final List<ChannelID> localReceivers=receiverList.getLocalReceivers();
synchronized (this.registeredChannels) {
      for (      final ChannelID localReceiver : localReceivers) {
        final ChannelContext cc=this.registeredChannels.get(localReceiver);
        if (cc == null) {
          throw new IOException(""String_Node_Str"" + localReceiver);
        }
        if (!cc.isInputChannel()) {
          throw new IOException(""String_Node_Str"" + localReceiver + ""String_Node_Str"");
        }
        final InputChannelContext inputChannelContext=(InputChannelContext)cc;
        final Buffer destBuffer=inputChannelContext.requestEmptyBufferBlocking(srcBuffer.size());
        srcBuffer.copyToBuffer(destBuffer);
        final TransferEnvelope dup=transferEnvelope.duplicateWithoutBuffer();
        dup.setBuffer(destBuffer);
        inputChannelContext.queueTransferEnvelope(dup);
      }
    }
  }
  if (receiverList.hasRemoteReceivers()) {
    final List<InetSocketAddress> remoteReceivers=receiverList.getRemoteReceivers();
    for (    final InetSocketAddress remoteReceiver : remoteReceivers) {
      this.networkConnectionManager.queueEnvelopeForTransfer(remoteReceiver,transferEnvelope.duplicate());
    }
  }
  srcBuffer.recycleBuffer();
}",0.8985374771480804
55965,"public ByteBufferedChannelManager(ChannelLookupProtocol channelLookupService,InstanceConnectionInfo localInstanceConnectionInfo) throws IOException {
  this.channelLookupService=channelLookupService;
  this.localConnectionInfo=localInstanceConnectionInfo;
  this.canceledChannelSet=new CanceledChannelSet();
  this.fileBufferManager=new FileBufferManager(this.canceledChannelSet);
  GlobalBufferPool.getInstance();
  this.transitBufferPool=TransitBufferPool.getInstance();
  this.networkConnectionManager=new NetworkConnectionManager(this,localInstanceConnectionInfo.getAddress(),localInstanceConnectionInfo.getDataPort());
}","public ByteBufferedChannelManager(ChannelLookupProtocol channelLookupService,InstanceConnectionInfo localInstanceConnectionInfo) throws IOException {
  this.channelLookupService=channelLookupService;
  this.localConnectionInfo=localInstanceConnectionInfo;
  this.canceledChannelSet=new CanceledChannelSet();
  this.fileBufferManager=new FileBufferManager(this.canceledChannelSet);
  GlobalBufferPool.getInstance();
  this.transitBufferPool=new LocalBufferCache(128,true);
  this.networkConnectionManager=new NetworkConnectionManager(this,localInstanceConnectionInfo.getAddress(),localInstanceConnectionInfo.getDataPort());
}",0.9623698959167334
55966,"private void redistributeGlobalBuffers(){
  final int totalNumberOfBuffers=GlobalBufferPool.getInstance().getTotalNumberOfBuffers();
synchronized (this.taskMap) {
    if (this.taskMap.isEmpty()) {
      return;
    }
    final int buffersPerTask=(int)Math.ceil((double)totalNumberOfBuffers / (double)this.taskMap.size());
    System.out.println(""String_Node_Str"" + buffersPerTask);
    final Iterator<TaskContext> it=this.taskMap.values().iterator();
    while (it.hasNext()) {
      it.next().setBufferLimit(buffersPerTask);
    }
  }
}","private void redistributeGlobalBuffers(){
  final int totalNumberOfBuffers=GlobalBufferPool.getInstance().getTotalNumberOfBuffers();
synchronized (this.taskMap) {
    if (this.taskMap.isEmpty()) {
      return;
    }
    final int numberOfTasks=this.taskMap.size() + (this.multicastEnabled ? 1 : 0);
    final int buffersPerTask=(int)Math.ceil((double)totalNumberOfBuffers / (double)numberOfTasks);
    System.out.println(""String_Node_Str"" + buffersPerTask);
    final Iterator<TaskContext> it=this.taskMap.values().iterator();
    while (it.hasNext()) {
      it.next().setBufferLimit(buffersPerTask);
    }
    if (this.multicastEnabled) {
      this.transitBufferPool.setDesignatedNumberOfBuffers(buffersPerTask);
    }
  }
}",0.8189723320158103
55967,"public TaskContext(){
  this.localBufferCache=new LocalBufferCache(1);
}","public TaskContext(){
  this.localBufferCache=new LocalBufferCache(1,false);
}",0.96
55968,"/** 
 * Submits the job assigned to this job client to the job manager.
 * @return a <code>JobSubmissionResult</code> object encapsulating the results of the job submission
 * @throws IOException thrown in case of submission errors while transmitting the data to the job manager
 */
public JobSubmissionResult submitJob() throws IOException {
synchronized (this.jobSubmitClient) {
    final JobSubmissionResult result=this.jobSubmitClient.submitJob(this.jobGraph);
    if (result.getReturnCode() == ReturnCode.SUCCESS) {
      Runtime.getRuntime().addShutdownHook(this.jobCleanUp);
    }
    return result;
  }
}","/** 
 * Submits the job assigned to this job client to the job manager.
 * @return a <code>JobSubmissionResult</code> object encapsulating the results of the job submission
 * @throws IOException thrown in case of submission errors while transmitting the data to the job manager
 */
public JobSubmissionResult submitJob() throws IOException {
synchronized (this.jobSubmitClient) {
    return this.jobSubmitClient.submitJob(this.jobGraph);
  }
}",0.8276515151515151
55969,"/** 
 * Cancels the job assigned to this job client.
 * @return a <code>JobCancelResult</code> object encapsulating the result of the job cancel request
 * @throws IOException thrown if an error occurred while transmitting the request to the job manager
 */
public JobCancelResult cancelJob() throws IOException {
  Runtime.getRuntime().removeShutdownHook(this.jobCleanUp);
synchronized (this.jobSubmitClient) {
    return this.jobSubmitClient.cancelJob(this.jobGraph.getJobID());
  }
}","/** 
 * Cancels the job assigned to this job client.
 * @return a <code>JobCancelResult</code> object encapsulating the result of the job cancel request
 * @throws IOException thrown if an error occurred while transmitting the request to the job manager
 */
public JobCancelResult cancelJob() throws IOException {
synchronized (this.jobSubmitClient) {
    return this.jobSubmitClient.cancelJob(this.jobGraph.getJobID());
  }
}",0.9342105263157896
55970,"/** 
 * {@inheritDoc}
 */
@Override public void run(){
  try {
    if (this.jobClient.getConfiguration().getBoolean(ConfigConstants.JOBCLIENT_SHUTDOWN_TERMINATEJOB_KEY,ConfigConstants.DEFAULT_JOBCLIENT_SHUTDOWN_TERMINATEJOB)) {
      this.jobClient.cancelJob();
    }
    this.jobClient.close();
  }
 catch (  IOException ioe) {
    LOG.warn(StringUtils.stringifyException(ioe));
  }
}","/** 
 * {@inheritDoc}
 */
@Override public void run(){
  try {
    if (this.jobClient.getConfiguration().getBoolean(ConfigConstants.JOBCLIENT_SHUTDOWN_TERMINATEJOB_KEY,ConfigConstants.DEFAULT_JOBCLIENT_SHUTDOWN_TERMINATEJOB)) {
      System.out.println(AbstractEvent.timestampToString(System.currentTimeMillis()) + ""String_Node_Str"");
      this.jobClient.cancelJob();
    }
    this.jobClient.close();
  }
 catch (  IOException ioe) {
    LOG.warn(StringUtils.stringifyException(ioe));
  }
}",0.8779931584948689
55971,"/** 
 * Submits the job assigned to this job client to the job manager and queries the job manager about the progress of the job until it is either finished or aborted.
 * @throws IOException thrown if an error occurred while transmitting the request
 * @throws JobExecutionException thrown if the job has been aborted either by the user or as a result of an error
 */
public void submitJobAndWait() throws IOException, JobExecutionException {
synchronized (this.jobSubmitClient) {
    final JobSubmissionResult submissionResult=this.jobSubmitClient.submitJob(this.jobGraph);
    if (submissionResult.getReturnCode() == AbstractJobResult.ReturnCode.ERROR) {
      LOG.error(""String_Node_Str"" + submissionResult.getDescription());
      throw new JobExecutionException(submissionResult.getDescription(),false);
    }
 else {
      Runtime.getRuntime().addShutdownHook(this.jobCleanUp);
    }
  }
  long sleep=0;
  try {
    final IntegerRecord interval=this.jobSubmitClient.getRecommendedPollingInterval();
    sleep=interval.getValue() * 1000;
  }
 catch (  IOException ioe) {
    logErrorAndRethrow(StringUtils.stringifyException(ioe));
  }
  try {
    Thread.sleep(sleep / 2);
  }
 catch (  InterruptedException e) {
    logErrorAndRethrow(StringUtils.stringifyException(e));
  }
  while (true) {
    if (Thread.interrupted()) {
      logErrorAndRethrow(""String_Node_Str"");
    }
    final JobProgressResult jobProgressResult=getJobProgress();
    if (jobProgressResult == null) {
      logErrorAndRethrow(""String_Node_Str"");
    }
    if (jobProgressResult.getReturnCode() == AbstractJobResult.ReturnCode.ERROR) {
      logErrorAndRethrow(""String_Node_Str"" + jobProgressResult.getDescription());
    }
    final Iterator<AbstractEvent> it=jobProgressResult.getEvents();
    while (it.hasNext()) {
      final AbstractEvent event=it.next();
      if (this.processedEvents.contains(event)) {
        continue;
      }
      System.out.println(event.toString());
      this.processedEvents.add(event);
      if (event instanceof JobEvent) {
        final JobEvent jobEvent=(JobEvent)event;
        final JobStatus jobStatus=jobEvent.getCurrentJobStatus();
        if (jobStatus == JobStatus.FINISHED) {
          Runtime.getRuntime().removeShutdownHook(this.jobCleanUp);
          return;
        }
 else         if (jobStatus == JobStatus.CANCELED || jobStatus == JobStatus.FAILED) {
          Runtime.getRuntime().removeShutdownHook(this.jobCleanUp);
          LOG.info(jobEvent.getOptionalMessage());
          throw new JobExecutionException(jobEvent.getOptionalMessage(),(jobStatus == JobStatus.CANCELED) ? true : false);
        }
      }
    }
    cleanUpOldEvents(sleep);
    try {
      Thread.sleep(sleep);
    }
 catch (    InterruptedException e) {
      logErrorAndRethrow(StringUtils.stringifyException(e));
    }
  }
}","/** 
 * Submits the job assigned to this job client to the job manager and queries the job manager about the progress of the job until it is either finished or aborted.
 * @throws IOException thrown if an error occurred while transmitting the request
 * @throws JobExecutionException thrown if the job has been aborted either by the user or as a result of an error
 */
public void submitJobAndWait() throws IOException, JobExecutionException {
synchronized (this.jobSubmitClient) {
    final JobSubmissionResult submissionResult=this.jobSubmitClient.submitJob(this.jobGraph);
    if (submissionResult.getReturnCode() == AbstractJobResult.ReturnCode.ERROR) {
      LOG.error(""String_Node_Str"" + submissionResult.getDescription());
      throw new JobExecutionException(submissionResult.getDescription(),false);
    }
    Runtime.getRuntime().addShutdownHook(this.jobCleanUp);
  }
  long sleep=0;
  try {
    final IntegerRecord interval=this.jobSubmitClient.getRecommendedPollingInterval();
    sleep=interval.getValue() * 1000;
  }
 catch (  IOException ioe) {
    logErrorAndRethrow(StringUtils.stringifyException(ioe));
  }
  try {
    Thread.sleep(sleep / 2);
  }
 catch (  InterruptedException e) {
    logErrorAndRethrow(StringUtils.stringifyException(e));
  }
  while (true) {
    if (Thread.interrupted()) {
      logErrorAndRethrow(""String_Node_Str"");
    }
    final JobProgressResult jobProgressResult=getJobProgress();
    if (jobProgressResult == null) {
      logErrorAndRethrow(""String_Node_Str"");
    }
    if (jobProgressResult.getReturnCode() == AbstractJobResult.ReturnCode.ERROR) {
      logErrorAndRethrow(""String_Node_Str"" + jobProgressResult.getDescription());
    }
    final Iterator<AbstractEvent> it=jobProgressResult.getEvents();
    while (it.hasNext()) {
      final AbstractEvent event=it.next();
      if (this.processedEvents.contains(event)) {
        continue;
      }
      System.out.println(event.toString());
      this.processedEvents.add(event);
      if (event instanceof JobEvent) {
        final JobEvent jobEvent=(JobEvent)event;
        final JobStatus jobStatus=jobEvent.getCurrentJobStatus();
        if (jobStatus == JobStatus.FINISHED) {
          Runtime.getRuntime().removeShutdownHook(this.jobCleanUp);
          return;
        }
 else         if (jobStatus == JobStatus.CANCELED || jobStatus == JobStatus.FAILED) {
          Runtime.getRuntime().removeShutdownHook(this.jobCleanUp);
          LOG.info(jobEvent.getOptionalMessage());
          throw new JobExecutionException(jobEvent.getOptionalMessage(),(jobStatus == JobStatus.CANCELED) ? true : false);
        }
      }
    }
    cleanUpOldEvents(sleep);
    try {
      Thread.sleep(sleep);
    }
 catch (    InterruptedException e) {
      logErrorAndRethrow(StringUtils.stringifyException(e));
    }
  }
}",0.9971681415929204
55972,"/** 
 * Converts the timestamp of an event from its ""milliseconds since beginning the epoch"" representation into a unified string representation.
 * @param timestamp the timestamp in milliseconds since the beginning of ""the epoch""
 * @return the string unified representation of the timestamp
 */
protected static String timestampToString(long timestamp){
  return dateFormatter.format(new Date(timestamp));
}","/** 
 * Converts the timestamp of an event from its ""milliseconds since beginning the epoch"" representation into a unified string representation.
 * @param timestamp the timestamp in milliseconds since the beginning of ""the epoch""
 * @return the string unified representation of the timestamp
 */
public static String timestampToString(long timestamp){
  return dateFormatter.format(new Date(timestamp));
}",0.9840490797546012
55973,"/** 
 * @param connection
 * @param outputVertex
 * @param inputVertex
 * @throws JobGraphDefinitionException
 * @throws CompilerException
 */
private void connectJobVertices(PactConnection connection,AbstractJobVertex outputVertex,AbstractJobVertex inputVertex) throws JobGraphDefinitionException, CompilerException {
  ChannelType channelType=null;
switch (connection.getShipStrategy()) {
case FORWARD:
case PARTITION_LOCAL_HASH:
    int sourceDOP=connection.getSourcePact().getDegreeOfParallelism();
  int sourceInnerDOP=connection.getSourcePact().getInstancesPerMachine();
int sourceNumInstances=(int)Math.ceil((double)sourceDOP / (double)sourceInnerDOP);
int targetDOP=connection.getTargetPact().getDegreeOfParallelism();
int targetInnerDOP=connection.getTargetPact().getInstancesPerMachine();
int targetNumInstances=(int)Math.ceil((double)targetDOP / (double)targetInnerDOP);
channelType=sourceNumInstances == targetNumInstances ? ChannelType.INMEMORY : ChannelType.NETWORK;
break;
case PARTITION_HASH:
case BROADCAST:
case SFR:
channelType=ChannelType.NETWORK;
break;
default :
throw new IllegalArgumentException(""String_Node_Str"" + connection.getShipStrategy().name());
}
TaskConfig outputConfig=new TaskConfig(outputVertex.getConfiguration());
TaskConfig inputConfig=new TaskConfig(inputVertex.getConfiguration());
TaskConfig tempConfig=null;
switch (connection.getTempMode()) {
case NONE:
outputVertex.connectTo(inputVertex,channelType,CompressionLevel.NO_COMPRESSION);
outputConfig.addOutputShipStrategy(connection.getShipStrategy());
inputConfig.addInputShipStrategy(connection.getShipStrategy());
break;
case TEMP_SENDER_SIDE:
int pd=connection.getSourcePact().getDegreeOfParallelism();
JobTaskVertex tempVertex=generateTempVertex(connection.getSourcePact().getPactContract().getUserCodeClass(),pd);
outputVertex.connectTo(tempVertex,ChannelType.INMEMORY,CompressionLevel.NO_COMPRESSION);
tempVertex.connectTo(inputVertex,channelType,CompressionLevel.NO_COMPRESSION);
tempConfig=new TaskConfig(tempVertex.getConfiguration());
outputConfig.addOutputShipStrategy(ShipStrategy.FORWARD);
tempConfig.addInputShipStrategy(ShipStrategy.FORWARD);
tempConfig.addOutputShipStrategy(connection.getShipStrategy());
inputConfig.addInputShipStrategy(connection.getShipStrategy());
break;
case TEMP_RECEIVER_SIDE:
int pdr=connection.getTargetPact().getDegreeOfParallelism();
tempVertex=generateTempVertex(connection.getSourcePact().getPactContract().getUserCodeClass(),pdr);
outputVertex.connectTo(tempVertex,channelType,CompressionLevel.NO_COMPRESSION);
tempVertex.connectTo(inputVertex,ChannelType.INMEMORY,CompressionLevel.NO_COMPRESSION);
tempConfig=new TaskConfig(tempVertex.getConfiguration());
outputConfig.addOutputShipStrategy(connection.getShipStrategy());
tempConfig.addInputShipStrategy(connection.getShipStrategy());
tempConfig.addOutputShipStrategy(ShipStrategy.FORWARD);
inputConfig.addInputShipStrategy(ShipStrategy.FORWARD);
break;
default :
throw new CompilerException(""String_Node_Str"" + connection.getTempMode());
}
}","/** 
 * @param connection
 * @param outputVertex
 * @param inputVertex
 * @throws JobGraphDefinitionException
 * @throws CompilerException
 */
private void connectJobVertices(PactConnection connection,AbstractJobVertex outputVertex,AbstractJobVertex inputVertex) throws JobGraphDefinitionException, CompilerException {
  ChannelType channelType=null;
switch (connection.getShipStrategy()) {
case FORWARD:
case PARTITION_LOCAL_HASH:
    int sourceDOP=connection.getSourcePact().getDegreeOfParallelism();
  int sourceInnerDOP=connection.getSourcePact().getInstancesPerMachine();
int sourceNumInstances=(int)Math.ceil((double)sourceDOP / (double)sourceInnerDOP);
int targetDOP=connection.getTargetPact().getDegreeOfParallelism();
int targetInnerDOP=connection.getTargetPact().getInstancesPerMachine();
int targetNumInstances=(int)Math.ceil((double)targetDOP / (double)targetInnerDOP);
channelType=sourceNumInstances == targetNumInstances ? ChannelType.INMEMORY : ChannelType.NETWORK;
break;
case PARTITION_HASH:
case BROADCAST:
case SFR:
channelType=ChannelType.NETWORK;
break;
default :
throw new IllegalArgumentException(""String_Node_Str"" + connection.getShipStrategy().name());
}
TaskConfig outputConfig=new TaskConfig(outputVertex.getConfiguration());
TaskConfig inputConfig=new TaskConfig(inputVertex.getConfiguration());
TaskConfig tempConfig=null;
switch (connection.getTempMode()) {
case NONE:
outputVertex.connectTo(inputVertex,channelType,CompressionLevel.NO_COMPRESSION);
outputConfig.addOutputShipStrategy(connection.getShipStrategy());
inputConfig.addInputShipStrategy(connection.getShipStrategy());
break;
case TEMP_SENDER_SIDE:
int pd=connection.getSourcePact().getDegreeOfParallelism();
JobTaskVertex tempVertex=generateTempVertex(connection.getSourcePact().getPactContract().getUserCodeClass(),pd);
outputVertex.connectTo(tempVertex,ChannelType.INMEMORY,CompressionLevel.NO_COMPRESSION);
tempVertex.connectTo(inputVertex,channelType,CompressionLevel.NO_COMPRESSION);
tempVertex.setVertexToShareInstancesWith(outputVertex);
tempConfig=new TaskConfig(tempVertex.getConfiguration());
outputConfig.addOutputShipStrategy(ShipStrategy.FORWARD);
tempConfig.addInputShipStrategy(ShipStrategy.FORWARD);
tempConfig.addOutputShipStrategy(connection.getShipStrategy());
inputConfig.addInputShipStrategy(connection.getShipStrategy());
break;
case TEMP_RECEIVER_SIDE:
int pdr=connection.getTargetPact().getDegreeOfParallelism();
tempVertex=generateTempVertex(connection.getSourcePact().getPactContract().getUserCodeClass(),pdr);
outputVertex.connectTo(tempVertex,channelType,CompressionLevel.NO_COMPRESSION);
tempVertex.connectTo(inputVertex,ChannelType.INMEMORY,CompressionLevel.NO_COMPRESSION);
tempVertex.setVertexToShareInstancesWith(inputVertex);
tempConfig=new TaskConfig(tempVertex.getConfiguration());
outputConfig.addOutputShipStrategy(connection.getShipStrategy());
tempConfig.addInputShipStrategy(connection.getShipStrategy());
tempConfig.addOutputShipStrategy(ShipStrategy.FORWARD);
inputConfig.addInputShipStrategy(ShipStrategy.FORWARD);
break;
default :
throw new CompilerException(""String_Node_Str"" + connection.getTempMode());
}
}",0.9820417408186376
55974,"/** 
 * This method implements the post-visit during the depth-first traversal. When the post visit happens, all of the descendants have been processed, so this method connects all of the current node's predecessors to the current node.
 * @param node The node currently processed during the post-visit.
 * @see eu.stratosphere.pact.common.plan.Visitor#postVisit(eu.stratosphere.pact.common.plan.Visitable)
 */
@Override public void postVisit(OptimizerNode node){
  try {
    AbstractJobVertex inputVertex=this.vertices.get(node);
    List<PactConnection> incomingConns=node.getIncomingConnections();
    if (incomingConns == null) {
      return;
    }
    for (    PactConnection connection : node.getIncomingConnections()) {
      AbstractJobVertex outputVertex=this.vertices.get(connection.getSourcePact());
      if (outputVertex == null) {
        throw new Exception(""String_Node_Str"");
      }
switch (connection.getShipStrategy()) {
case FORWARD:
        connectWithForwardStrategy(connection,outputVertex,inputVertex);
      break;
case PARTITION_HASH:
    connectWithPartitionStrategy(connection,outputVertex,inputVertex);
  break;
case BROADCAST:
connectWithBroadcastStrategy(connection,outputVertex,inputVertex);
break;
case PARTITION_RANGE:
if (isDistributionGiven(connection)) {
connectWithGivenDistributionPartitionRangeStrategy(connection,outputVertex,inputVertex);
}
 else {
connectWithSamplingPartitionRangeStrategy(connection,outputVertex,inputVertex);
}
break;
case SFR:
connectWithSFRStrategy(connection,outputVertex,inputVertex);
default :
throw new Exception(""String_Node_Str"" + connection.getShipStrategy());
}
}
}
 catch (Exception e) {
throw new CompilerException(""String_Node_Str"" + e.getMessage(),e);
}
}","/** 
 * This method implements the post-visit during the depth-first traversal. When the post visit happens, all of the descendants have been processed, so this method connects all of the current node's predecessors to the current node.
 * @param node The node currently processed during the post-visit.
 * @see eu.stratosphere.pact.common.plan.Visitor#postVisit(eu.stratosphere.pact.common.plan.Visitable)
 */
@Override public void postVisit(OptimizerNode node){
  try {
    AbstractJobVertex inputVertex=this.vertices.get(node);
    List<PactConnection> incomingConns=node.getIncomingConnections();
    if (incomingConns == null) {
      return;
    }
    for (    PactConnection connection : node.getIncomingConnections()) {
      AbstractJobVertex outputVertex=this.vertices.get(connection.getSourcePact());
      if (outputVertex == null) {
        throw new Exception(""String_Node_Str"");
      }
switch (connection.getShipStrategy()) {
case FORWARD:
        connectWithForwardStrategy(connection,outputVertex,inputVertex);
      break;
case PARTITION_LOCAL_HASH:
case PARTITION_HASH:
    connectWithPartitionStrategy(connection,outputVertex,inputVertex);
  break;
case BROADCAST:
connectWithBroadcastStrategy(connection,outputVertex,inputVertex);
break;
case PARTITION_RANGE:
if (isDistributionGiven(connection)) {
connectWithGivenDistributionPartitionRangeStrategy(connection,outputVertex,inputVertex);
}
 else {
connectWithSamplingPartitionRangeStrategy(connection,outputVertex,inputVertex);
}
break;
case SFR:
connectWithSFRStrategy(connection,outputVertex,inputVertex);
default :
throw new Exception(""String_Node_Str"" + connection.getShipStrategy());
}
}
}
 catch (Exception e) {
throw new CompilerException(""String_Node_Str"" + e.getMessage(),e);
}
}",0.9922702547953048
55975,"/** 
 * {@inheritDoc}
 */
public void write(DataOutput out) throws IOException {
  super.write(out);
  out.writeInt(this.getNumberOfOutputChannels());
  for (int i=0; i < getNumberOfOutputChannels(); i++) {
    getOutputChannel(i).getID().write(out);
    EnumUtils.writeEnum(out,getOutputChannel(i).getCompressionLevel());
    StringRecord.writeString(out,getOutputChannel(i).getClass().getName());
    getOutputChannel(i).write(out);
  }
}","/** 
 * {@inheritDoc}
 */
public void write(DataOutput out) throws IOException {
  super.write(out);
  out.writeInt(this.getNumberOfOutputChannels());
  for (int i=0; i < getNumberOfOutputChannels(); i++) {
    EnumUtils.writeEnum(out,getOutputChannel(i).getType());
    if (getOutputChannel(i).getType() == ChannelType.NETWORK) {
      out.writeBoolean(getOutputChannel(i).followsPushModel());
    }
    getOutputChannel(i).getID().write(out);
    EnumUtils.writeEnum(out,getOutputChannel(i).getCompressionLevel());
    StringRecord.writeString(out,getOutputChannel(i).getClass().getName());
    getOutputChannel(i).write(out);
  }
}",0.819366852886406
55976,"/** 
 * {@inheritDoc}
 */
@SuppressWarnings(""String_Node_Str"") public void read(DataInput in) throws IOException {
  super.read(in);
  final int numOutputChannels=in.readInt();
  final Class<?>[] parameters={this.getClass(),int.class,ChannelID.class,CompressionLevel.class};
  for (int i=0; i < numOutputChannels; i++) {
    final ChannelID channelID=new ChannelID();
    channelID.read(in);
    final CompressionLevel compressionLevel=EnumUtils.readEnum(in,CompressionLevel.class);
    final String className=StringRecord.readString(in);
    Class<? extends IOReadableWritable> c=null;
    try {
      c=ClassUtils.getRecordByName(className);
    }
 catch (    ClassNotFoundException e) {
      LOG.error(e);
    }
    if (c == null) {
      throw new IOException(""String_Node_Str"");
    }
    AbstractOutputChannel<T> eoc=null;
    try {
      final Constructor<AbstractOutputChannel<T>> constructor=(Constructor<AbstractOutputChannel<T>>)c.getDeclaredConstructor(parameters);
      if (constructor == null) {
        throw new IOException(""String_Node_Str"");
      }
      constructor.setAccessible(true);
      eoc=constructor.newInstance(this,i,channelID,compressionLevel);
    }
 catch (    InstantiationException e) {
      LOG.error(e);
    }
catch (    IllegalArgumentException e) {
      LOG.error(e);
    }
catch (    IllegalAccessException e) {
      LOG.error(e);
    }
catch (    InvocationTargetException e) {
      LOG.error(e);
    }
catch (    SecurityException e) {
      LOG.error(e);
    }
catch (    NoSuchMethodException e) {
      LOG.error(e);
    }
    if (eoc == null) {
      throw new IOException(""String_Node_Str"");
    }
    eoc.read(in);
    addOutputChannel(eoc);
  }
}","/** 
 * {@inheritDoc}
 */
@SuppressWarnings(""String_Node_Str"") public void read(DataInput in) throws IOException {
  super.read(in);
  final int numOutputChannels=in.readInt();
  Class<?>[] parameters={this.getClass(),int.class,ChannelID.class,CompressionLevel.class};
  Class<?>[] networkParameters={this.getClass(),int.class,ChannelID.class,CompressionLevel.class,boolean.class};
  for (int i=0; i < numOutputChannels; i++) {
    final ChannelType channelType=EnumUtils.readEnum(in,ChannelType.class);
    boolean followsPushModel=false;
    if (channelType == ChannelType.NETWORK) {
      followsPushModel=in.readBoolean();
    }
    final ChannelID channelID=new ChannelID();
    channelID.read(in);
    final CompressionLevel compressionLevel=EnumUtils.readEnum(in,CompressionLevel.class);
    final String className=StringRecord.readString(in);
    Class<? extends IOReadableWritable> c=null;
    try {
      c=ClassUtils.getRecordByName(className);
    }
 catch (    ClassNotFoundException e) {
      LOG.error(e);
    }
    if (c == null) {
      throw new IOException(""String_Node_Str"");
    }
    AbstractOutputChannel<T> eoc=null;
    try {
      Constructor<AbstractOutputChannel<T>> constructor;
      if (channelType == ChannelType.NETWORK) {
        constructor=(Constructor<AbstractOutputChannel<T>>)c.getDeclaredConstructor(networkParameters);
      }
 else {
        constructor=(Constructor<AbstractOutputChannel<T>>)c.getDeclaredConstructor(parameters);
      }
      if (constructor == null) {
        throw new IOException(""String_Node_Str"");
      }
      constructor.setAccessible(true);
      if (channelType == ChannelType.NETWORK) {
        eoc=constructor.newInstance(this,i,channelID,compressionLevel,followsPushModel);
      }
 else {
        eoc=constructor.newInstance(this,i,channelID,compressionLevel);
      }
    }
 catch (    InstantiationException e) {
      LOG.error(e);
    }
catch (    IllegalArgumentException e) {
      LOG.error(e);
    }
catch (    IllegalAccessException e) {
      LOG.error(e);
    }
catch (    InvocationTargetException e) {
      LOG.error(e);
    }
catch (    SecurityException e) {
      LOG.error(e);
    }
catch (    NoSuchMethodException e) {
      LOG.error(e);
    }
    if (eoc == null) {
      throw new IOException(""String_Node_Str"");
    }
    eoc.read(in);
    addOutputChannel(eoc);
  }
}",0.828992628992629
55977,"/** 
 * Creates a new output channel object.
 * @param outputGate the output gate this channel is connected to.
 * @param channelIndex the channel's index at the associated output gate
 * @param channelID the channel ID to assign to the new channel, <code>null</code> to generate a new ID
 * @param compressionLevel the level of compression to be used for this channel
 */
public AbstractOutputChannel(OutputGate<T> outputGate,int channelIndex,ChannelID channelID,CompressionLevel compressionLevel){
  super(channelIndex,channelID,compressionLevel);
  this.outputGate=outputGate;
}","/** 
 * Creates a new output channel object.
 * @param outputGate the output gate this channel is connected to.
 * @param channelIndex the channel's index at the associated output gate
 * @param channelID the channel ID to assign to the new channel, <code>null</code> to generate a new ID
 * @param compressionLevel the level of compression to be used for this channel
 */
public AbstractOutputChannel(OutputGate<T> outputGate,int channelIndex,ChannelID channelID,CompressionLevel compressionLevel,boolean followsPushModel){
  super(channelIndex,channelID,compressionLevel);
  this.outputGate=outputGate;
  this.followsPushModel=followsPushModel;
}",0.9454841334418226
55978,"/** 
 * Creates a new byte buffered output channel.
 * @param outputGate the output gate this channel is wired to
 * @param channelIndex the channel's index at the associated output gate
 * @param channelID the channel ID to assign to the new channel, <code>null</code> to generate a new ID
 * @param compressionLevel the level of compression to be used for this channel
 */
public AbstractByteBufferedOutputChannel(OutputGate<T> outputGate,int channelIndex,ChannelID channelID,CompressionLevel compressionLevel,boolean followsPushModel){
  super(outputGate,channelIndex,channelID,compressionLevel);
  this.compressor=CompressionLoader.getCompressorByCompressionLevel(compressionLevel,this);
  this.followsPushModel=followsPushModel;
}","/** 
 * Creates a new byte buffered output channel.
 * @param outputGate the output gate this channel is wired to
 * @param channelIndex the channel's index at the associated output gate
 * @param channelID the channel ID to assign to the new channel, <code>null</code> to generate a new ID
 * @param compressionLevel the level of compression to be used for this channel
 */
public AbstractByteBufferedOutputChannel(OutputGate<T> outputGate,int channelIndex,ChannelID channelID,CompressionLevel compressionLevel,boolean followsPushModel){
  super(outputGate,channelIndex,channelID,compressionLevel,followsPushModel);
  this.compressor=CompressionLoader.getCompressorByCompressionLevel(compressionLevel,this);
}",0.9591695501730104
55979,"/** 
 * Registers the given task with the byte buffered channel manager.
 * @param vertexID the ID of the task to be registered
 * @param environment the environment of the task
 */
public void register(final ExecutionVertexID vertexID,final Environment environment){
  final TaskContext taskContext=new TaskContext();
  for (int i=0; i < environment.getNumberOfOutputGates(); ++i) {
    final OutputGate<?> outputGate=environment.getOutputGate(i);
    final OutputGateContext outputGateContext=new OutputGateContext(taskContext,outputGate,this,this.fileBufferManager);
    for (int j=0; j < outputGate.getNumberOfOutputChannels(); ++j) {
      final AbstractOutputChannel<?> outputChannel=outputGate.getOutputChannel(j);
      if (outputChannel instanceof AbstractByteBufferedOutputChannel) {
        LOG.error(""String_Node_Str"" + outputChannel.getID() + ""String_Node_Str""+ environment.getJobID()+ ""String_Node_Str"");
        continue;
      }
      final AbstractByteBufferedOutputChannel<?> bboc=(AbstractByteBufferedOutputChannel<?>)outputChannel;
      if (this.registeredChannels.containsKey(bboc.getID())) {
        LOG.error(""String_Node_Str"" + bboc.getID() + ""String_Node_Str"");
        continue;
      }
      LOG.info(""String_Node_Str"" + bboc.getID());
      final OutputChannelContext outputChannelContext=new OutputChannelContext(outputGateContext,bboc);
      this.registeredChannels.put(bboc.getID(),outputChannelContext);
    }
  }
  for (int i=0; i < environment.getNumberOfInputGates(); ++i) {
    final InputGate<?> inputGate=environment.getInputGate(i);
    final InputGateContext inputGateContext=new InputGateContext(taskContext);
    for (int j=0; j < inputGate.getNumberOfInputChannels(); ++j) {
      final AbstractInputChannel<?> inputChannel=inputGate.getInputChannel(j);
      if (inputChannel instanceof AbstractByteBufferedInputChannel) {
        LOG.error(""String_Node_Str"" + inputChannel.getID() + ""String_Node_Str""+ environment.getJobID()+ ""String_Node_Str"");
        continue;
      }
      final AbstractByteBufferedInputChannel<?> bbic=(AbstractByteBufferedInputChannel<?>)inputChannel;
      if (this.registeredChannels.containsKey(bbic.getID())) {
        LOG.error(""String_Node_Str"" + bbic.getID() + ""String_Node_Str"");
        continue;
      }
      LOG.info(""String_Node_Str"" + bbic.getID());
      final InputChannelContext inputChannelContext=new InputChannelContext(inputGateContext,this,bbic);
      this.registeredChannels.put(bbic.getID(),inputChannelContext);
    }
  }
}","/** 
 * Registers the given task with the byte buffered channel manager.
 * @param vertexID the ID of the task to be registered
 * @param environment the environment of the task
 */
public void register(final ExecutionVertexID vertexID,final Environment environment){
  final TaskContext taskContext=new TaskContext();
  for (int i=0; i < environment.getNumberOfOutputGates(); ++i) {
    final OutputGate<?> outputGate=environment.getOutputGate(i);
    final OutputGateContext outputGateContext=new OutputGateContext(taskContext,outputGate,this,this.fileBufferManager);
    for (int j=0; j < outputGate.getNumberOfOutputChannels(); ++j) {
      final AbstractOutputChannel<?> outputChannel=outputGate.getOutputChannel(j);
      if (!(outputChannel instanceof AbstractByteBufferedOutputChannel)) {
        LOG.error(""String_Node_Str"" + outputChannel.getID() + ""String_Node_Str""+ environment.getJobID()+ ""String_Node_Str"");
        continue;
      }
      final AbstractByteBufferedOutputChannel<?> bboc=(AbstractByteBufferedOutputChannel<?>)outputChannel;
      if (this.registeredChannels.containsKey(bboc.getID())) {
        LOG.error(""String_Node_Str"" + bboc.getID() + ""String_Node_Str"");
        continue;
      }
      LOG.info(""String_Node_Str"" + bboc.getID());
      final OutputChannelContext outputChannelContext=new OutputChannelContext(outputGateContext,bboc);
      this.registeredChannels.put(bboc.getID(),outputChannelContext);
    }
  }
  for (int i=0; i < environment.getNumberOfInputGates(); ++i) {
    final InputGate<?> inputGate=environment.getInputGate(i);
    final InputGateContext inputGateContext=new InputGateContext(taskContext);
    for (int j=0; j < inputGate.getNumberOfInputChannels(); ++j) {
      final AbstractInputChannel<?> inputChannel=inputGate.getInputChannel(j);
      if (!(inputChannel instanceof AbstractByteBufferedInputChannel)) {
        LOG.error(""String_Node_Str"" + inputChannel.getID() + ""String_Node_Str""+ environment.getJobID()+ ""String_Node_Str"");
        continue;
      }
      final AbstractByteBufferedInputChannel<?> bbic=(AbstractByteBufferedInputChannel<?>)inputChannel;
      if (this.registeredChannels.containsKey(bbic.getID())) {
        LOG.error(""String_Node_Str"" + bbic.getID() + ""String_Node_Str"");
        continue;
      }
      LOG.info(""String_Node_Str"" + bbic.getID());
      final InputChannelContext inputChannelContext=new InputChannelContext(inputGateContext,this,bbic);
      this.registeredChannels.put(bbic.getID(),inputChannelContext);
    }
  }
}",0.9988109393579072
55980,"/** 
 * Constructs a new broadcast record writer and registers a new output gate with the application's environment.
 * @param inputBase the application that instantiated the record writer
 * @param outputClass the class of records that can be emitted with this record writer
 */
public BroadcastRecordWriter(AbstractInputTask inputBase,Class<T> outputClass){
  super(inputBase,outputClass,null,true);
}","/** 
 * Constructs a new broadcast record writer and registers a new output gate with the application's environment.
 * @param inputBase the application that instantiated the record writer
 * @param outputClass the class of records that can be emitted with this record writer
 */
public BroadcastRecordWriter(AbstractInputTask<?> inputBase,Class<T> outputClass){
  super(inputBase,outputClass,null,true);
}",0.9962917181705808
55981,"/** 
 * {@inheritDoc}
 */
@SuppressWarnings(""String_Node_Str"") public void read(DataInput in) throws IOException {
}","/** 
 * {@inheritDoc}
 */
@SuppressWarnings(""String_Node_Str"") public void read(DataInput in) throws IOException {
  super.read(in);
  final int numOutputChannels=in.readInt();
  final Class<?>[] parameters={this.getClass(),int.class,ChannelID.class,CompressionLevel.class};
  for (int i=0; i < numOutputChannels; i++) {
    final ChannelID channelID=new ChannelID();
    channelID.read(in);
    final CompressionLevel compressionLevel=EnumUtils.readEnum(in,CompressionLevel.class);
    final String className=StringRecord.readString(in);
    Class<? extends IOReadableWritable> c=null;
    try {
      c=ClassUtils.getRecordByName(className);
    }
 catch (    ClassNotFoundException e) {
      LOG.error(e);
    }
    if (c == null) {
      throw new IOException(""String_Node_Str"");
    }
    AbstractOutputChannel<T> eoc=null;
    try {
      final Constructor<AbstractOutputChannel<T>> constructor=(Constructor<AbstractOutputChannel<T>>)c.getDeclaredConstructor(parameters);
      if (constructor == null) {
        throw new IOException(""String_Node_Str"");
      }
      constructor.setAccessible(true);
      eoc=constructor.newInstance(this,i,channelID,compressionLevel);
    }
 catch (    InstantiationException e) {
      LOG.error(e);
    }
catch (    IllegalArgumentException e) {
      LOG.error(e);
    }
catch (    IllegalAccessException e) {
      LOG.error(e);
    }
catch (    InvocationTargetException e) {
      LOG.error(e);
    }
catch (    SecurityException e) {
      LOG.error(e);
    }
catch (    NoSuchMethodException e) {
      LOG.error(e);
    }
    if (eoc == null) {
      throw new IOException(""String_Node_Str"");
    }
    eoc.read(in);
    addOutputChannel(eoc);
  }
}",0.1276127612761276
55982,"/** 
 * Constructs a new record writer and registers a new output gate with the application's environment.
 * @param inputBase the application that instantiated the record writer
 * @param outputClass the class of records that can be emitted with this record writer
 * @param selector the channel selector to be used to determine the output channel to be used for a record
 */
public RecordWriter(AbstractInputTask inputBase,Class<T> outputClass,ChannelSelector<T> selector){
  super(inputBase,outputClass,selector,false);
}","/** 
 * Constructs a new record writer and registers a new output gate with the application's environment.
 * @param inputBase the application that instantiated the record writer
 * @param outputClass the class of records that can be emitted with this record writer
 * @param selector the channel selector to be used to determine the output channel to be used for a record
 */
public RecordWriter(AbstractInputTask<?> inputBase,Class<T> outputClass,ChannelSelector<T> selector){
  super(inputBase,outputClass,selector,false);
}",0.9971455756422456
55983,"@Override public boolean nextBlock(){
  if (this.closed) {
    throw new IllegalStateException(""String_Node_Str"");
  }
  if (this.noMoreBlocks) {
    return false;
  }
  collectAllBuffers(this.emptySegments);
  this.bufferCurrentlyFilled=new Buffer.Output(this.emptySegments.remove(this.emptySegments.size() - 1));
  if (this.leftOverElement != null) {
    if (!this.bufferCurrentlyFilled.write(this.leftOverElement)) {
      throw new RuntimeException(""String_Node_Str"" + ""String_Node_Str"");
    }
    this.nextElement=this.leftOverElement;
    this.leftOverElement=null;
  }
  return true;
}","@Override public boolean nextBlock(){
  if (this.closed) {
    throw new IllegalStateException(""String_Node_Str"");
  }
  if (this.noMoreBlocks) {
    return false;
  }
  collectAllBuffers(this.emptySegments);
  this.bufferCurrentlyFilled=new Buffer.Output(this.emptySegments.remove(this.emptySegments.size() - 1));
  T next=this.leftOverElement;
  this.leftOverElement=null;
  if (next == null) {
    if (this.input.hasNext()) {
      next=this.input.next();
    }
 else {
      this.noMoreBlocks=true;
      return false;
    }
  }
  if (!this.bufferCurrentlyFilled.write(next)) {
    throw new RuntimeException(""String_Node_Str"" + ""String_Node_Str"");
  }
  this.nextElement=next;
  return true;
}",0.7591014717273431
55984,"/** 
 * Runs a blocked nested loop strategy to build the Cartesian product and call the <code>cross()</code> method of the CrossStub implementation. The outer side is read using a BlockResettableIterator. The inner side is read using a SpillingResettableIterator.
 * @see eu.stratosphere.pact.runtime.resettable.SpillingResettableIterator
 * @see eu.stratosphere.pact.runtime.resettable.BlockResettableIterator
 * @param memoryManager The task manager's memory manager.
 * @param ioManager The task manager's IO manager
 * @param innerReader The inner reader of the nested loops.
 * @param outerReader The outer reader of the nested loops.
 * @throws RuntimeException Throws a RuntimeException if something fails during execution.
 */
private void runBlocked(MemoryManager memoryManager,IOManager ioManager,Iterator<KeyValuePair<Key,Value>> innerReader,Iterator<KeyValuePair<Key,Value>> outerReader) throws Exception {
  SpillingResettableIterator<KeyValuePair<Key,Value>> innerInput=null;
  BlockResettableIterator<KeyValuePair<Key,Value>> outerInput=null;
  try {
    final boolean firstInputIsOuter;
    if (this.config.getLocalStrategy() == LocalStrategy.NESTEDLOOP_BLOCKED_OUTER_SECOND) {
      try {
        innerInput=new SpillingResettableIterator<KeyValuePair<Key,Value>>(memoryManager,ioManager,innerReader,this.availableMemory / 2,new KeyValuePairDeserializer<Key,Value>(stub.getFirstInKeyType(),stub.getFirstInValueType()),this);
        this.spillingResetIt=innerInput;
      }
 catch (      MemoryAllocationException mae) {
        throw new RuntimeException(""String_Node_Str"",mae);
      }
      try {
        outerInput=new BlockResettableIterator<KeyValuePair<Key,Value>>(memoryManager,outerReader,this.availableMemory / 2,1,new KeyValuePairDeserializer<Key,Value>(stub.getSecondInKeyType(),stub.getSecondInValueType()),this);
        this.blockResetIt=outerInput;
      }
 catch (      MemoryAllocationException mae) {
        throw new RuntimeException(""String_Node_Str"",mae);
      }
      firstInputIsOuter=false;
    }
 else     if (this.config.getLocalStrategy() == LocalStrategy.NESTEDLOOP_BLOCKED_OUTER_FIRST) {
      try {
        innerInput=new SpillingResettableIterator<KeyValuePair<Key,Value>>(memoryManager,ioManager,innerReader,this.availableMemory / 2,new KeyValuePairDeserializer<Key,Value>(stub.getSecondInKeyType(),stub.getSecondInValueType()),this);
        this.spillingResetIt=innerInput;
      }
 catch (      MemoryAllocationException mae) {
        throw new RuntimeException(""String_Node_Str"",mae);
      }
      try {
        outerInput=new BlockResettableIterator<KeyValuePair<Key,Value>>(memoryManager,outerReader,this.availableMemory / 2,1,new KeyValuePairDeserializer<Key,Value>(stub.getFirstInKeyType(),stub.getFirstInValueType()),this);
        this.blockResetIt=outerInput;
      }
 catch (      MemoryAllocationException mae) {
        throw new RuntimeException(""String_Node_Str"",mae);
      }
      firstInputIsOuter=true;
    }
 else {
      throw new RuntimeException(""String_Node_Str"" + config.getLocalStrategy());
    }
    try {
      innerInput.open();
    }
 catch (    ServiceException se) {
      throw new RuntimeException(""String_Node_Str"",se);
    }
catch (    IOException ioe) {
      throw new RuntimeException(""String_Node_Str"",ioe);
    }
catch (    InterruptedException ie) {
      throw new RuntimeException(""String_Node_Str"",ie);
    }
    if (this.taskCanceled)     return;
    outerInput.open();
    if (LOG.isDebugEnabled()) {
      LOG.debug(getLogString(""String_Node_Str""));
      LOG.debug(getLogString(""String_Node_Str""));
    }
    this.stub.open();
    boolean moreOuterBlocks=false;
    do {
      while (!this.taskCanceled && innerInput.hasNext()) {
        KeyValuePair<Key,Value> innerPair=innerInput.next();
        while (!this.taskCanceled && outerInput.hasNext()) {
          KeyValuePair<Key,Value> outerPair=outerInput.next();
          if (firstInputIsOuter) {
            stub.cross(outerPair.getKey(),outerPair.getValue(),innerPair.getKey(),innerPair.getValue(),output);
          }
 else {
            stub.cross(innerPair.getKey(),innerPair.getValue(),outerPair.getKey(),outerPair.getValue(),output);
          }
          innerPair=innerInput.repeatLast();
        }
        outerInput.reset();
      }
      moreOuterBlocks=outerInput.nextBlock();
      if (moreOuterBlocks) {
        innerInput.reset();
      }
    }
 while (!this.taskCanceled && moreOuterBlocks);
    this.stub.close();
  }
 catch (  Exception ex) {
    if (!this.taskCanceled) {
      LOG.error(getLogString(""String_Node_Str""));
      throw ex;
    }
  }
 finally {
    Throwable t1=null, t2=null;
    try {
      if (innerInput != null) {
        innerInput.close();
      }
    }
 catch (    Throwable t) {
      LOG.warn(t);
      t1=t;
    }
    try {
      if (outerInput != null) {
        outerInput.close();
      }
    }
 catch (    Throwable t) {
      LOG.warn(t);
      t2=t;
    }
    if (t1 != null)     throw new RuntimeException(""String_Node_Str"",t1);
    if (t2 != null)     throw new RuntimeException(""String_Node_Str"",t2);
  }
}","/** 
 * Runs a blocked nested loop strategy to build the Cartesian product and call the <code>cross()</code> method of the CrossStub implementation. The outer side is read using a BlockResettableIterator. The inner side is read using a SpillingResettableIterator.
 * @see eu.stratosphere.pact.runtime.resettable.SpillingResettableIterator
 * @see eu.stratosphere.pact.runtime.resettable.BlockResettableIterator
 * @param memoryManager The task manager's memory manager.
 * @param ioManager The task manager's IO manager
 * @param innerReader The inner reader of the nested loops.
 * @param outerReader The outer reader of the nested loops.
 * @throws RuntimeException Throws a RuntimeException if something fails during execution.
 */
private void runBlocked(MemoryManager memoryManager,IOManager ioManager,Iterator<KeyValuePair<Key,Value>> innerReader,Iterator<KeyValuePair<Key,Value>> outerReader) throws Exception {
  SpillingResettableIterator<KeyValuePair<Key,Value>> innerInput=null;
  BlockResettableIterator<KeyValuePair<Key,Value>> outerInput=null;
  try {
    final boolean firstInputIsOuter;
    if (this.config.getLocalStrategy() == LocalStrategy.NESTEDLOOP_BLOCKED_OUTER_SECOND) {
      try {
        innerInput=new SpillingResettableIterator<KeyValuePair<Key,Value>>(memoryManager,ioManager,innerReader,this.availableMemory / 2,new KeyValuePairDeserializer<Key,Value>(stub.getFirstInKeyType(),stub.getFirstInValueType()),this);
        this.spillingResetIt=innerInput;
      }
 catch (      MemoryAllocationException mae) {
        throw new RuntimeException(""String_Node_Str"",mae);
      }
      try {
        outerInput=new BlockResettableIterator<KeyValuePair<Key,Value>>(memoryManager,outerReader,this.availableMemory / 2,1,new KeyValuePairDeserializer<Key,Value>(stub.getSecondInKeyType(),stub.getSecondInValueType()),this);
        this.blockResetIt=outerInput;
      }
 catch (      MemoryAllocationException mae) {
        throw new RuntimeException(""String_Node_Str"",mae);
      }
      firstInputIsOuter=false;
    }
 else     if (this.config.getLocalStrategy() == LocalStrategy.NESTEDLOOP_BLOCKED_OUTER_FIRST) {
      try {
        innerInput=new SpillingResettableIterator<KeyValuePair<Key,Value>>(memoryManager,ioManager,innerReader,this.availableMemory / 2,new KeyValuePairDeserializer<Key,Value>(stub.getSecondInKeyType(),stub.getSecondInValueType()),this);
        this.spillingResetIt=innerInput;
      }
 catch (      MemoryAllocationException mae) {
        throw new RuntimeException(""String_Node_Str"",mae);
      }
      try {
        outerInput=new BlockResettableIterator<KeyValuePair<Key,Value>>(memoryManager,outerReader,this.availableMemory / 2,1,new KeyValuePairDeserializer<Key,Value>(stub.getFirstInKeyType(),stub.getFirstInValueType()),this);
        this.blockResetIt=outerInput;
      }
 catch (      MemoryAllocationException mae) {
        throw new RuntimeException(""String_Node_Str"",mae);
      }
      firstInputIsOuter=true;
    }
 else {
      throw new RuntimeException(""String_Node_Str"" + config.getLocalStrategy());
    }
    try {
      innerInput.open();
    }
 catch (    ServiceException se) {
      throw new RuntimeException(""String_Node_Str"",se);
    }
catch (    IOException ioe) {
      throw new RuntimeException(""String_Node_Str"",ioe);
    }
catch (    InterruptedException ie) {
      throw new RuntimeException(""String_Node_Str"",ie);
    }
    if (this.taskCanceled)     return;
    outerInput.open();
    if (LOG.isDebugEnabled()) {
      LOG.debug(getLogString(""String_Node_Str""));
      LOG.debug(getLogString(""String_Node_Str""));
    }
    this.stub.open();
    boolean moreOuterBlocks=false;
    if (innerInput.hasNext()) {
      do {
        while (!this.taskCanceled && innerInput.hasNext()) {
          KeyValuePair<Key,Value> innerPair=innerInput.next();
          while (!this.taskCanceled && outerInput.hasNext()) {
            KeyValuePair<Key,Value> outerPair=outerInput.next();
            if (firstInputIsOuter) {
              stub.cross(outerPair.getKey(),outerPair.getValue(),innerPair.getKey(),innerPair.getValue(),output);
            }
 else {
              stub.cross(innerPair.getKey(),innerPair.getValue(),outerPair.getKey(),outerPair.getValue(),output);
            }
            innerPair=innerInput.repeatLast();
          }
          outerInput.reset();
        }
        moreOuterBlocks=outerInput.nextBlock();
        if (moreOuterBlocks) {
          innerInput.reset();
        }
      }
 while (!this.taskCanceled && moreOuterBlocks);
    }
    this.stub.close();
  }
 catch (  Exception ex) {
    if (!this.taskCanceled) {
      LOG.error(getLogString(""String_Node_Str""));
      throw ex;
    }
  }
 finally {
    Throwable t1=null, t2=null;
    try {
      if (innerInput != null) {
        innerInput.close();
      }
    }
 catch (    Throwable t) {
      LOG.warn(t);
      t1=t;
    }
    try {
      if (outerInput != null) {
        outerInput.close();
      }
    }
 catch (    Throwable t) {
      LOG.warn(t);
      t2=t;
    }
    if (t1 != null)     throw new RuntimeException(""String_Node_Str"",t1);
    if (t2 != null)     throw new RuntimeException(""String_Node_Str"",t2);
  }
}",0.9922405431619786
55985,"/** 
 * Move the iterator to the next memory block
 * @return true if a new memory block was loaded, false if there were no further records
 */
public boolean nextBlock();","/** 
 * Move the iterator to the next memory block. The next memory block starts at the first element that was not in the block before. A special case is when no record was in the block before, which happens when this function is invoked two times directly in a sequence, without calling hasNext() or next in between. Then the block moves one element.
 * @return true if a new memory block was loaded, false if there were no further records
 */
public boolean nextBlock();",0.5318818040435459
55986,"/** 
 * {@inheritDoc}
 */
@Override public synchronized void requestInstance(JobID jobID,Configuration conf,InstanceType instanceType) throws InstanceException {
  for (  ClusterInstance host : registeredHosts.values()) {
    final AllocatedSlice slice=host.createSlice(instanceType,jobID);
    if (slice != null) {
      List<AllocatedSlice> allocatedSlices=this.slicesOfJobs.get(jobID);
      if (allocatedSlices == null) {
        allocatedSlices=new ArrayList<AllocatedSlice>();
        this.slicesOfJobs.put(jobID,allocatedSlices);
      }
      allocatedSlices.add(slice);
      if (this.instanceListener != null) {
        ClusterInstanceNotifier clusterInstanceNotifier=new ClusterInstanceNotifier(this.instanceListener,slice);
        clusterInstanceNotifier.start();
      }
      return;
    }
  }
  throw new InstanceException(""String_Node_Str"");
}","/** 
 * {@inheritDoc}
 */
@Override public synchronized void requestInstance(JobID jobID,Configuration conf,InstanceType instanceType) throws InstanceException {
  AllocatedSlice slice=null;
  for (  final ClusterInstance host : this.registeredHosts.values()) {
    if (host.getType().equals(instanceType)) {
      slice=host.createSlice(instanceType,jobID);
      if (slice != null) {
        break;
      }
    }
  }
  if (slice == null) {
    for (    final ClusterInstance host : this.registeredHosts.values()) {
      slice=host.createSlice(instanceType,jobID);
      if (slice != null) {
        break;
      }
    }
  }
  if (slice == null) {
    throw new InstanceException(""String_Node_Str"");
  }
  List<AllocatedSlice> allocatedSlices=this.slicesOfJobs.get(jobID);
  if (allocatedSlices == null) {
    allocatedSlices=new ArrayList<AllocatedSlice>();
    this.slicesOfJobs.put(jobID,allocatedSlices);
  }
  allocatedSlices.add(slice);
  if (this.instanceListener != null) {
    ClusterInstanceNotifier clusterInstanceNotifier=new ClusterInstanceNotifier(this.instanceListener,slice);
    clusterInstanceNotifier.start();
  }
}",0.3456913827655311
55987,"/** 
 * @param sinkNode
 * @return
 * @throws CompilerException
 */
private JobOutputVertex generateDataSinkVertex(OptimizerNode sinkNode) throws CompilerException {
  DataSinkNode sNode=(DataSinkNode)sinkNode;
  GenericDataSink<?,?> sinkContract=sNode.getPactContract();
  JobGenericOutputVertex sinkVertex=new JobGenericOutputVertex(sinkNode.getPactContract().getName(),this.jobGraph);
  sinkVertex.setOutputClass(DataSinkTask.class);
  TaskConfig sinkConfig=new TaskConfig(sinkVertex.getConfiguration());
  sinkConfig.setStubClass(sinkContract.getUserCodeClass());
  sinkConfig.setStubParameters(sinkContract.getParameters());
switch (sinkNode.getLocalStrategy()) {
case NONE:
    sinkConfig.setLocalStrategy(LocalStrategy.NONE);
  break;
default :
throw new CompilerException(""String_Node_Str"" + sinkNode.getName() + ""String_Node_Str""+ sinkNode.getLocalStrategy());
}
return sinkVertex;
}","/** 
 * @param sinkNode
 * @return
 * @throws CompilerException
 */
private JobOutputVertex generateDataSinkVertex(OptimizerNode sinkNode) throws CompilerException {
  DataSinkNode sNode=(DataSinkNode)sinkNode;
  GenericDataSink<?,?> sinkContract=sNode.getPactContract();
  JobGenericOutputVertex sinkVertex=new JobGenericOutputVertex(sinkNode.getPactContract().getName(),this.jobGraph);
  sinkVertex.setOutputClass(DataSinkTask.class);
  sinkVertex.getConfiguration().setInteger(DataSinkTask.DEGREE_OF_PARALLELISM_KEY,sinkNode.getDegreeOfParallelism());
  TaskConfig sinkConfig=new TaskConfig(sinkVertex.getConfiguration());
  sinkConfig.setStubClass(sinkContract.getUserCodeClass());
  sinkConfig.setStubParameters(sinkContract.getParameters());
switch (sinkNode.getLocalStrategy()) {
case NONE:
    sinkConfig.setLocalStrategy(LocalStrategy.NONE);
  break;
default :
throw new CompilerException(""String_Node_Str"" + sinkNode.getName() + ""String_Node_Str""+ sinkNode.getLocalStrategy());
}
return sinkVertex;
}",0.9379600420609884
55988,"/** 
 * {@inheritDoc}
 */
@Override public int getMaximumNumberOfSubtasks(){
  if (!(this.format instanceof FileOutputFormat)) {
    return -1;
  }
  final String pathName=this.config.getStubParameter(FileOutputFormat.FILE_PARAMETER_KEY,null);
  final Path path;
  if (pathName == null) {
    return 0;
  }
  try {
    path=new Path(pathName);
  }
 catch (  Throwable t) {
    return 0;
  }
  try {
    final FileSystem fs=path.getFileSystem();
    try {
      final FileStatus f=fs.getFileStatus(path);
      if (f == null) {
        return 1;
      }
      if (f.isDir()) {
        return -1;
      }
 else {
        return 1;
      }
    }
 catch (    FileNotFoundException fnfex) {
      fs.mkdirs(path);
      return -1;
    }
  }
 catch (  IOException e) {
    return 1;
  }
}","/** 
 * {@inheritDoc}
 */
@Override public int getMaximumNumberOfSubtasks(){
  if (!(this.format instanceof FileOutputFormat)) {
    return -1;
  }
  final String pathName=this.config.getStubParameter(FileOutputFormat.FILE_PARAMETER_KEY,null);
  final Path path;
  if (pathName == null) {
    return 0;
  }
  try {
    path=new Path(pathName);
  }
 catch (  Throwable t) {
    return 0;
  }
  try {
    final FileSystem fs=path.getFileSystem();
    try {
      final FileStatus f=fs.getFileStatus(path);
      if (f == null) {
        return 1;
      }
      if (f.isDir())       return -1;
 else       return 1;
    }
 catch (    FileNotFoundException fnfex) {
      int dop=getRuntimeConfiguration().getInteger(DEGREE_OF_PARALLELISM_KEY,-1);
      if (dop == 1) {
        return 1;
      }
      fs.mkdirs(path);
      return -1;
    }
  }
 catch (  IOException e) {
    return 1;
  }
}",0.902994011976048
55989,"/** 
 * Takes all JAR files that are contained in this program's JAR file and extracts them to the system's temp directory.
 * @return The file names of the extracted temporary files.
 * @throws IOException Thrown, if the extraction process failed.
 */
public File[] extractContainedLibaries() throws IOException {
  Random rnd=new Random();
  try {
    final JarFile jar=new JarFile(jarFile);
    final List<JarEntry> containedJarFileEntries=new ArrayList<JarEntry>();
    Enumeration<JarEntry> entries=jar.entries();
    while (entries.hasMoreElements()) {
      JarEntry entry=entries.nextElement();
      String name=entry.getName();
      if (name.length() > 8 && name.startsWith(""String_Node_Str"") && name.endsWith(""String_Node_Str"")) {
        containedJarFileEntries.add(entry);
      }
    }
    if (containedJarFileEntries.isEmpty()) {
      return null;
    }
    this.extractedTempLibraries=new File[containedJarFileEntries.size()];
    for (int i=0; i < this.extractedTempLibraries.length; i++) {
      final JarEntry entry=containedJarFileEntries.get(i);
      String name=entry.getName();
      name=name.replace(File.separatorChar,'_');
      File tempFile=File.createTempFile(String.valueOf(Math.abs(rnd.nextInt()) + ""String_Node_Str""),entry.getName());
      this.extractedTempLibraries[i]=tempFile;
      OutputStream out=null;
      InputStream in=null;
      try {
        out=new FileOutputStream(tempFile);
        in=new BufferedInputStream(jar.getInputStream(entry));
        byte[] buffer=new byte[1024];
        int numRead=0;
        while ((numRead=in.read(buffer)) != -1) {
          out.write(buffer,0,numRead);
        }
      }
  finally {
        if (out != null) {
          out.close();
        }
        if (in != null) {
          in.close();
        }
      }
    }
    return this.extractedTempLibraries;
  }
 catch (  IOException ioex) {
    throw ioex;
  }
catch (  Throwable t) {
    throw new IOException(""String_Node_Str"",t);
  }
}","/** 
 * Takes all JAR files that are contained in this program's JAR file and extracts them to the system's temp directory.
 * @return The file names of the extracted temporary files.
 * @throws IOException Thrown, if the extraction process failed.
 */
public File[] extractContainedLibaries() throws IOException {
  Random rnd=new Random();
  try {
    final JarFile jar=new JarFile(jarFile);
    final List<JarEntry> containedJarFileEntries=new ArrayList<JarEntry>();
    Enumeration<JarEntry> entries=jar.entries();
    while (entries.hasMoreElements()) {
      JarEntry entry=entries.nextElement();
      String name=entry.getName();
      if (name.length() > 8 && name.startsWith(""String_Node_Str"") && name.endsWith(""String_Node_Str"")) {
        containedJarFileEntries.add(entry);
      }
    }
    if (containedJarFileEntries.isEmpty()) {
      return null;
    }
    this.extractedTempLibraries=new File[containedJarFileEntries.size()];
    for (int i=0; i < this.extractedTempLibraries.length; i++) {
      final JarEntry entry=containedJarFileEntries.get(i);
      String name=entry.getName();
      name=name.replace(File.separatorChar,'_');
      File tempFile=File.createTempFile(String.valueOf(Math.abs(rnd.nextInt()) + ""String_Node_Str""),name);
      this.extractedTempLibraries[i]=tempFile;
      OutputStream out=null;
      InputStream in=null;
      try {
        out=new FileOutputStream(tempFile);
        in=new BufferedInputStream(jar.getInputStream(entry));
        byte[] buffer=new byte[1024];
        int numRead=0;
        while ((numRead=in.read(buffer)) != -1) {
          out.write(buffer,0,numRead);
        }
      }
  finally {
        if (out != null) {
          out.close();
        }
        if (in != null) {
          in.close();
        }
      }
    }
    return this.extractedTempLibraries;
  }
 catch (  IOException ioex) {
    throw ioex;
  }
catch (  Throwable t) {
    throw new IOException(""String_Node_Str"",t);
  }
}",0.9951788886069526
55990,"/** 
 * {@inheritDoc}
 */
@Override public void initialize(URI name) throws IOException {
  this.host=name.getHost();
  if (this.host == null) {
    LOG.debug(""String_Node_Str"");
    this.host=GlobalConfiguration.getString(S3_HOST_KEY,DEFAULT_S3_HOST);
  }
  this.port=name.getPort();
  if (this.port == -1) {
    LOG.debug(""String_Node_Str"");
    this.port=GlobalConfiguration.getInteger(S3_PORT_KEY,DEFAULT_S3_PORT);
  }
  final String userInfo=name.getUserInfo();
  String awsAccessKey=null;
  String awsSecretKey=null;
  if (userInfo != null) {
    final String[] splits=userInfo.split(""String_Node_Str"");
    if (splits.length > 1) {
      awsAccessKey=splits[0];
      awsSecretKey=splits[1];
    }
  }
  if (awsAccessKey == null) {
    LOG.debug(""String_Node_Str"");
    awsAccessKey=GlobalConfiguration.getString(S3_ACCESS_KEY_KEY,null);
    if (awsAccessKey == null) {
      throw new IOException(""String_Node_Str"");
    }
  }
  if (awsSecretKey == null) {
    LOG.debug(""String_Node_Str"");
    awsSecretKey=GlobalConfiguration.getString(S3_SECRET_KEY_KEY,null);
    if (awsSecretKey == null) {
      throw new IOException(""String_Node_Str"");
    }
  }
  final AWSCredentials credentials=new BasicAWSCredentials(awsAccessKey,awsSecretKey);
  this.s3Client=new AmazonS3Client(credentials);
  initializeDirectoryStructure(name);
}","/** 
 * {@inheritDoc}
 */
@Override public void initialize(URI name) throws IOException {
  this.host=name.getHost();
  if (this.host == null) {
    LOG.debug(""String_Node_Str"");
    this.host=GlobalConfiguration.getString(S3_HOST_KEY,DEFAULT_S3_HOST);
  }
  this.port=name.getPort();
  if (this.port == -1) {
    LOG.debug(""String_Node_Str"");
    this.port=GlobalConfiguration.getInteger(S3_PORT_KEY,DEFAULT_S3_PORT);
  }
  final String userInfo=name.getUserInfo();
  String awsAccessKey=null;
  String awsSecretKey=null;
  if (userInfo != null) {
    final String[] splits=userInfo.split(""String_Node_Str"");
    if (splits.length > 1) {
      awsAccessKey=URLDecoder.decode(splits[0],URL_ENCODE_CHARACTER);
      awsSecretKey=URLDecoder.decode(splits[1],URL_ENCODE_CHARACTER);
    }
  }
  if (awsAccessKey == null) {
    LOG.debug(""String_Node_Str"");
    awsAccessKey=GlobalConfiguration.getString(S3_ACCESS_KEY_KEY,null);
    if (awsAccessKey == null) {
      throw new IOException(""String_Node_Str"");
    }
  }
  if (awsSecretKey == null) {
    LOG.debug(""String_Node_Str"");
    awsSecretKey=GlobalConfiguration.getString(S3_SECRET_KEY_KEY,null);
    if (awsSecretKey == null) {
      throw new IOException(""String_Node_Str"");
    }
  }
  final AWSCredentials credentials=new BasicAWSCredentials(awsAccessKey,awsSecretKey);
  this.s3Client=new AmazonS3Client(credentials);
  initializeDirectoryStructure(name);
}",0.9709302325581396
55991,"public boolean hasAssignedChannels(){
  return (!this.assignedChannels.isEmpty());
}","boolean hasAssignedChannels(){
  return (!this.assignedChannels.isEmpty());
}",0.9565217391304348
55992,"public void removeAssignedChannel(final ChannelID channelID){
  if (!this.assignedChannels.remove(channelID)) {
    throw new IllegalStateException(channelID + ""String_Node_Str"");
  }
}","void removeAssignedChannel(final ChannelID channelID){
  if (!this.assignedChannels.remove(channelID)) {
    throw new IllegalStateException(channelID + ""String_Node_Str"");
  }
}",0.9807162534435262
55993,"protected void addAssignedChannel(final ChannelID channelID){
  this.assignedChannels.add(channelID);
}","void addAssignedChannel(final ChannelID channelID){
  if (!this.assignedChannels.add(channelID)) {
    throw new IllegalStateException(channelID + ""String_Node_Str"");
  }
}",0.6763636363636364
55994,"@Override public final synchronized Compressor getCompressor(final AbstractByteBufferedOutputChannel<?> outputChannel) throws CompressionException {
  final OutputGate<?> outputGate=outputChannel.getOutputGate();
  CompressorCacheEntry cacheEntry=this.compressorCache.get(outputGate);
  if (cacheEntry == null) {
    Compressor compressor=initNewCompressor(outputChannel);
    cacheEntry=new CompressorCacheEntry(compressor,outputGate);
    this.compressorCache.put(outputGate,cacheEntry);
    this.compressorMap.put(compressor,outputGate);
  }
  return cacheEntry.getCompressor();
}","@Override public final synchronized Compressor getCompressor(final AbstractByteBufferedOutputChannel<?> outputChannel) throws CompressionException {
  final OutputGate<?> outputGate=outputChannel.getOutputGate();
  CompressorCacheEntry cacheEntry=this.compressorCache.get(outputGate);
  if (cacheEntry == null) {
    Compressor compressor=initNewCompressor(outputChannel);
    cacheEntry=new CompressorCacheEntry(compressor);
    this.compressorCache.put(outputGate,cacheEntry);
    this.compressorMap.put(compressor,outputGate);
  }
  cacheEntry.addAssignedChannel(outputChannel.getID());
  return cacheEntry.getCompressor();
}",0.7613542526837325
55995,"@Override public final synchronized Decompressor getDecompressor(final AbstractByteBufferedInputChannel<?> inputChannel) throws CompressionException {
  final InputGate<?> inputGate=inputChannel.getInputGate();
  DecompressorCacheEntry cacheEntry=this.decompressorCache.get(inputGate);
  if (cacheEntry == null) {
    Decompressor decompressor=initNewDecompressor(inputChannel);
    cacheEntry=new DecompressorCacheEntry(decompressor,inputGate);
    this.decompressorCache.put(inputGate,cacheEntry);
    this.decompressorMap.put(decompressor,inputGate);
  }
  return cacheEntry.getDecompressor();
}","@Override public final synchronized Decompressor getDecompressor(final AbstractByteBufferedInputChannel<?> inputChannel) throws CompressionException {
  final InputGate<?> inputGate=inputChannel.getInputGate();
  DecompressorCacheEntry cacheEntry=this.decompressorCache.get(inputGate);
  if (cacheEntry == null) {
    Decompressor decompressor=initNewDecompressor(inputChannel);
    cacheEntry=new DecompressorCacheEntry(decompressor);
    this.decompressorCache.put(inputGate,cacheEntry);
    this.decompressorMap.put(decompressor,inputGate);
  }
  cacheEntry.addAssignedChannel(inputChannel.getID());
  return cacheEntry.getDecompressor();
}",0.7606768734891217
55996,"CompressorCacheEntry(final Compressor compressor,final OutputGate<?> outputGate){
  this.compressor=compressor;
  for (int i=0; i < outputGate.getNumberOfOutputChannels(); i++) {
    final AbstractOutputChannel<?> outputChannel=outputGate.getOutputChannel(i);
    addAssignedChannel(outputChannel.getID());
  }
}","CompressorCacheEntry(final Compressor compressor){
  this.compressor=compressor;
}",0.416243654822335
55997,"DecompressorCacheEntry(final Decompressor decompressor,final InputGate<?> inputGate){
  this.decompressor=decompressor;
  for (int i=0; i < inputGate.getNumberOfInputChannels(); i++) {
    final AbstractInputChannel<?> inputChannel=inputGate.getInputChannel(i);
    addAssignedChannel(inputChannel.getID());
  }
}","DecompressorCacheEntry(final Decompressor decompressor){
  this.decompressor=decompressor;
}",0.454320987654321
55998,"/** 
 * {@inheritDoc}
 */
@Override public ManagementVertex next(){
  if (traversalStack.isEmpty()) {
    if (numVisitedEntryVertices < 0) {
      return null;
    }
    TraversalEntry newentry;
    if (forward) {
      newentry=new TraversalEntry(managementGraph.getInputVertex(this.startStage,numVisitedEntryVertices),0,0);
    }
 else {
      newentry=new TraversalEntry(managementGraph.getOutputVertex(this.startStage,numVisitedEntryVertices),0,0);
    }
    traversalStack.push(newentry);
  }
  final ManagementVertex returnVertex=traversalStack.peek().getManagementVertex();
  do {
    final TraversalEntry te=traversalStack.peek();
    final ManagementVertex candidateVertex=getCandidateVertex(te,forward);
    if (candidateVertex == null) {
      traversalStack.pop();
    }
 else {
      final TraversalEntry newte=new TraversalEntry(candidateVertex,0,0);
      traversalStack.add(newte);
      break;
    }
  }
 while (!traversalStack.isEmpty());
  alreadyVisited.add(returnVertex);
  return returnVertex;
}","/** 
 * {@inheritDoc}
 */
@Override public ManagementVertex next(){
  if (this.traversalStack.isEmpty()) {
    if (this.numVisitedEntryVertices < 0) {
      return null;
    }
    TraversalEntry newentry;
    if (this.forward) {
      newentry=new TraversalEntry(this.managementGraph.getInputVertex(this.startStage,this.numVisitedEntryVertices),0,0);
    }
 else {
      newentry=new TraversalEntry(managementGraph.getOutputVertex(this.startStage,this.numVisitedEntryVertices),0,0);
    }
    this.traversalStack.push(newentry);
    this.alreadyVisited.add(newentry.getManagementVertex());
  }
  final ManagementVertex returnVertex=this.traversalStack.peek().getManagementVertex();
  do {
    final TraversalEntry te=this.traversalStack.peek();
    final ManagementVertex candidateVertex=getCandidateVertex(te,this.forward);
    if (candidateVertex == null) {
      this.traversalStack.pop();
    }
 else {
      final TraversalEntry newte=new TraversalEntry(candidateVertex,0,0);
      this.traversalStack.push(newte);
      this.alreadyVisited.add(candidateVertex);
      break;
    }
  }
 while (!this.traversalStack.isEmpty());
  return returnVertex;
}",0.8946157386102163
55999,"/** 
 * {@inheritDoc}
 */
@Override public boolean hasNext(){
  if (traversalStack.isEmpty()) {
    if (numVisitedEntryVertices < 0) {
      return false;
    }
    numVisitedEntryVertices++;
    if (forward) {
      if (managementGraph.getNumberOfInputVertices(this.startStage) <= numVisitedEntryVertices) {
        return false;
      }
    }
 else {
      if (managementGraph.getNumberOfOutputVertices(this.startStage) <= numVisitedEntryVertices) {
        return false;
      }
    }
  }
  return true;
}","/** 
 * {@inheritDoc}
 */
@Override public boolean hasNext(){
  if (this.traversalStack.isEmpty()) {
    if (this.numVisitedEntryVertices < 0) {
      return false;
    }
    ++this.numVisitedEntryVertices;
    if (this.forward) {
      if (this.managementGraph.getNumberOfInputVertices(this.startStage) <= this.numVisitedEntryVertices) {
        return false;
      }
    }
 else {
      if (this.managementGraph.getNumberOfOutputVertices(this.startStage) <= this.numVisitedEntryVertices) {
        return false;
      }
    }
  }
  return true;
}",0.9583333333333334
56000,"/** 
 * Returns a candidate vertex which could potentially be visited next because it is reachable from the currently considered vertex.
 * @param te the traversal entry for the current source vertex
 * @param forward <code>true</code> if the graph should be traversed in correct order, <code>false</code> to traverse it in reverse order
 * @return a candidate vertex which could potentially be visited next
 */
private ManagementVertex getCandidateVertex(final TraversalEntry te,final boolean forward){
  if (forward) {
    while (true) {
      if (this.confinedToStage && te.getCurrentChannel() == 0) {
        while (currentGateLeadsToOtherStage(te,this.forward)) {
          te.increaseCurrentGate();
        }
      }
      if (te.getCurrentGate() >= te.getManagementVertex().getNumberOfOutputGates()) {
        break;
      }
      if (te.getCurrentChannel() >= te.getManagementVertex().getOutputGate(te.getCurrentGate()).getNumberOfForwardEdges()) {
        te.increaseCurrentGate();
        te.resetCurrentChannel();
      }
 else {
        final ManagementEdge forwardEdge=te.getManagementVertex().getOutputGate(te.getCurrentGate()).getForwardEdge(te.getCurrentChannel());
        final ManagementVertex target=forwardEdge.getTarget().getVertex();
        te.increaseCurrentChannel();
        if (!alreadyVisited.contains(target)) {
          return target;
        }
      }
    }
  }
 else {
    while (true) {
      if (this.confinedToStage && te.getCurrentChannel() == 0) {
        while (currentGateLeadsToOtherStage(te,this.forward)) {
          te.increaseCurrentGate();
        }
      }
      if (te.getCurrentGate() >= te.getManagementVertex().getNumberOfInputGates()) {
        break;
      }
      if (te.getCurrentChannel() >= te.getManagementVertex().getInputGate(te.getCurrentGate()).getNumberOfBackwardEdges()) {
        te.increaseCurrentGate();
        te.resetCurrentChannel();
      }
 else {
        final ManagementEdge backwardEdge=te.getManagementVertex().getInputGate(te.getCurrentGate()).getBackwardEdge(te.getCurrentChannel());
        final ManagementVertex source=backwardEdge.getSource().getVertex();
        if (source == null) {
          LOG.error(""String_Node_Str"");
        }
        te.increaseCurrentChannel();
        if (!alreadyVisited.contains(source)) {
          return source;
        }
      }
    }
  }
  return null;
}","/** 
 * Returns a candidate vertex which could potentially be visited next because it is reachable from the currently considered vertex.
 * @param te the traversal entry for the current source vertex
 * @param forward <code>true</code> if the graph should be traversed in correct order, <code>false</code> to traverse it in reverse order
 * @return a candidate vertex which could potentially be visited next
 */
private ManagementVertex getCandidateVertex(final TraversalEntry te,final boolean forward){
  if (forward) {
    while (true) {
      if (this.confinedToStage && te.getCurrentChannel() == 0) {
        while (currentGateLeadsToOtherStage(te,this.forward)) {
          te.increaseCurrentGate();
        }
      }
      if (te.getCurrentGate() >= te.getManagementVertex().getNumberOfOutputGates()) {
        break;
      }
      if (te.getCurrentChannel() >= te.getManagementVertex().getOutputGate(te.getCurrentGate()).getNumberOfForwardEdges()) {
        te.increaseCurrentGate();
        te.resetCurrentChannel();
      }
 else {
        final ManagementEdge forwardEdge=te.getManagementVertex().getOutputGate(te.getCurrentGate()).getForwardEdge(te.getCurrentChannel());
        final ManagementVertex target=forwardEdge.getTarget().getVertex();
        te.increaseCurrentChannel();
        if (!alreadyVisited.contains(target)) {
          return target;
        }
      }
    }
  }
 else {
    while (true) {
      if (this.confinedToStage && te.getCurrentChannel() == 0) {
        while (currentGateLeadsToOtherStage(te,this.forward)) {
          te.increaseCurrentGate();
        }
      }
      if (te.getCurrentGate() >= te.getManagementVertex().getNumberOfInputGates()) {
        break;
      }
      if (te.getCurrentChannel() >= te.getManagementVertex().getInputGate(te.getCurrentGate()).getNumberOfBackwardEdges()) {
        te.increaseCurrentGate();
        te.resetCurrentChannel();
      }
 else {
        final ManagementEdge backwardEdge=te.getManagementVertex().getInputGate(te.getCurrentGate()).getBackwardEdge(te.getCurrentChannel());
        final ManagementVertex source=backwardEdge.getSource().getVertex();
        if (source == null) {
          LOG.error(""String_Node_Str"");
        }
        te.increaseCurrentChannel();
        if (!this.alreadyVisited.contains(source)) {
          return source;
        }
      }
    }
  }
  return null;
}",0.998948032821376
