record_number,buggy_code,fixed_code
37001,"/** 
 * Returns a hash code for a   {@code int} value; compatible with{@code Integer.hashCode()}.
 * @since 1.8
 * @return a hash code value for a {@code int} value.
 */
public static int hashCode(int value){
  return value;
}","/** 
 * Returns a hash code for a   {@code int} value; compatible with{@code Integer.hashCode()}.
 * @param value the value to hash
 * @since 1.8
 * @return a hash code value for a {@code int} value.
 */
public static int hashCode(int value){
  return value;
}"
37002,"/** 
 * Returns an   {@code int} value with at most a single one-bit, in theposition of the lowest-order (""rightmost"") one-bit in the specified {@code int} value.  Returns zero if the specified value has noone-bits in its two's complement binary representation, that is, if it is equal to zero.
 * @return an {@code int} value with a single one-bit, in the positionof the lowest-order one-bit in the specified value, or zero if the specified value is itself equal to zero.
 * @since 1.5
 */
public static int lowestOneBit(int i){
  return i & -i;
}","/** 
 * Returns an   {@code int} value with at most a single one-bit, in theposition of the lowest-order (""rightmost"") one-bit in the specified {@code int} value.  Returns zero if the specified value has noone-bits in its two's complement binary representation, that is, if it is equal to zero.
 * @param i the value whose lowest one bit is to be computed
 * @return an {@code int} value with a single one-bit, in the positionof the lowest-order one-bit in the specified value, or zero if the specified value is itself equal to zero.
 * @since 1.5
 */
public static int lowestOneBit(int i){
  return i & -i;
}"
37003,"/** 
 * Returns the signum function of the specified   {@code int} value.  (Thereturn value is -1 if the specified value is negative; 0 if the specified value is zero; and 1 if the specified value is positive.)
 * @return the signum function of the specified {@code int} value.
 * @since 1.5
 */
public static int signum(int i){
  return (i >> 31) | (-i >>> 31);
}","/** 
 * Returns the signum function of the specified   {@code int} value.  (Thereturn value is -1 if the specified value is negative; 0 if the specified value is zero; and 1 if the specified value is positive.)
 * @param i the value whose signum is to be computed
 * @return the signum function of the specified {@code int} value.
 * @since 1.5
 */
public static int signum(int i){
  return (i >> 31) | (-i >>> 31);
}"
37004,"/** 
 * Returns the value obtained by rotating the two's complement binary representation of the specified   {@code int} value right by thespecified number of bits.  (Bits shifted out of the right hand, or low-order, side reenter on the left, or high-order.) <p>Note that right rotation with a negative distance is equivalent to left rotation:  {@code rotateRight(val, -distance) == rotateLeft(val,distance)}.  Note also that rotation by any multiple of 32 is a no-op, so all but the last five bits of the rotation distance can be ignored, even if the distance is negative:   {@code rotateRight(val,distance) == rotateRight(val, distance & 0x1F)}.
 * @return the value obtained by rotating the two's complement binaryrepresentation of the specified  {@code int} value right by thespecified number of bits.
 * @since 1.5
 */
public static int rotateRight(int i,int distance){
  return (i >>> distance) | (i << -distance);
}","/** 
 * Returns the value obtained by rotating the two's complement binary representation of the specified   {@code int} value right by thespecified number of bits.  (Bits shifted out of the right hand, or low-order, side reenter on the left, or high-order.) <p>Note that right rotation with a negative distance is equivalent to left rotation:  {@code rotateRight(val, -distance) == rotateLeft(val,distance)}.  Note also that rotation by any multiple of 32 is a no-op, so all but the last five bits of the rotation distance can be ignored, even if the distance is negative:   {@code rotateRight(val,distance) == rotateRight(val, distance & 0x1F)}.
 * @param i the value whose bits are to be rotated right
 * @param distance the number of bit positions to rotate right
 * @return the value obtained by rotating the two's complement binaryrepresentation of the specified  {@code int} value right by thespecified number of bits.
 * @since 1.5
 */
public static int rotateRight(int i,int distance){
  return (i >>> distance) | (i << -distance);
}"
37005,"/** 
 * Returns the value obtained by reversing the order of the bits in the two's complement binary representation of the specified   {@code int}value.
 * @return the value obtained by reversing order of the bits in thespecified  {@code int} value.
 * @since 1.5
 */
public static int reverse(int i){
  i=(i & 0x55555555) << 1 | (i >>> 1) & 0x55555555;
  i=(i & 0x33333333) << 2 | (i >>> 2) & 0x33333333;
  i=(i & 0x0f0f0f0f) << 4 | (i >>> 4) & 0x0f0f0f0f;
  i=(i << 24) | ((i & 0xff00) << 8) | ((i >>> 8) & 0xff00)| (i >>> 24);
  return i;
}","/** 
 * Returns the value obtained by reversing the order of the bits in the two's complement binary representation of the specified   {@code int}value.
 * @param i the value to be reversed
 * @return the value obtained by reversing order of the bits in thespecified  {@code int} value.
 * @since 1.5
 */
public static int reverse(int i){
  i=(i & 0x55555555) << 1 | (i >>> 1) & 0x55555555;
  i=(i & 0x33333333) << 2 | (i >>> 2) & 0x33333333;
  i=(i & 0x0f0f0f0f) << 4 | (i >>> 4) & 0x0f0f0f0f;
  i=(i << 24) | ((i & 0xff00) << 8) | ((i >>> 8) & 0xff00)| (i >>> 24);
  return i;
}"
37006,"/** 
 * Returns the number of zero bits preceding the highest-order (""leftmost"") one-bit in the two's complement binary representation of the specified   {@code int} value.  Returns 32 if thespecified value has no one-bits in its two's complement representation, in other words if it is equal to zero. <p>Note that this method is closely related to the logarithm base 2. For all positive  {@code int} values x:<ul> <li>floor(log<sub>2</sub>(x)) =  {@code 31 - numberOfLeadingZeros(x)}<li>ceil(log<sub>2</sub>(x)) =   {@code 32 - numberOfLeadingZeros(x - 1)}</ul>
 * @return the number of zero bits preceding the highest-order(""leftmost"") one-bit in the two's complement binary representation of the specified  {@code int} value, or 32 if the valueis equal to zero.
 * @since 1.5
 */
public static int numberOfLeadingZeros(int i){
  if (i == 0)   return 32;
  int n=1;
  if (i >>> 16 == 0) {
    n+=16;
    i<<=16;
  }
  if (i >>> 24 == 0) {
    n+=8;
    i<<=8;
  }
  if (i >>> 28 == 0) {
    n+=4;
    i<<=4;
  }
  if (i >>> 30 == 0) {
    n+=2;
    i<<=2;
  }
  n-=i >>> 31;
  return n;
}","/** 
 * Returns the number of zero bits preceding the highest-order (""leftmost"") one-bit in the two's complement binary representation of the specified   {@code int} value.  Returns 32 if thespecified value has no one-bits in its two's complement representation, in other words if it is equal to zero. <p>Note that this method is closely related to the logarithm base 2. For all positive  {@code int} values x:<ul> <li>floor(log<sub>2</sub>(x)) =  {@code 31 - numberOfLeadingZeros(x)}<li>ceil(log<sub>2</sub>(x)) =   {@code 32 - numberOfLeadingZeros(x - 1)}</ul>
 * @param i the value whose number of leading zeros is to be computed
 * @return the number of zero bits preceding the highest-order(""leftmost"") one-bit in the two's complement binary representation of the specified  {@code int} value, or 32 if the valueis equal to zero.
 * @since 1.5
 */
public static int numberOfLeadingZeros(int i){
  if (i == 0)   return 32;
  int n=1;
  if (i >>> 16 == 0) {
    n+=16;
    i<<=16;
  }
  if (i >>> 24 == 0) {
    n+=8;
    i<<=8;
  }
  if (i >>> 28 == 0) {
    n+=4;
    i<<=4;
  }
  if (i >>> 30 == 0) {
    n+=2;
    i<<=2;
  }
  n-=i >>> 31;
  return n;
}"
37007,"/** 
 * Returns the number of one-bits in the two's complement binary representation of the specified   {@code int} value.  This function issometimes referred to as the <i>population count</i>.
 * @return the number of one-bits in the two's complement binaryrepresentation of the specified  {@code int} value.
 * @since 1.5
 */
public static int bitCount(int i){
  i=i - ((i >>> 1) & 0x55555555);
  i=(i & 0x33333333) + ((i >>> 2) & 0x33333333);
  i=(i + (i >>> 4)) & 0x0f0f0f0f;
  i=i + (i >>> 8);
  i=i + (i >>> 16);
  return i & 0x3f;
}","/** 
 * Returns the number of one-bits in the two's complement binary representation of the specified   {@code int} value.  This function issometimes referred to as the <i>population count</i>.
 * @param i the value whose bits are to be counted
 * @return the number of one-bits in the two's complement binaryrepresentation of the specified  {@code int} value.
 * @since 1.5
 */
public static int bitCount(int i){
  i=i - ((i >>> 1) & 0x55555555);
  i=(i & 0x33333333) + ((i >>> 2) & 0x33333333);
  i=(i + (i >>> 4)) & 0x0f0f0f0f;
  i=i + (i >>> 8);
  i=i + (i >>> 16);
  return i & 0x3f;
}"
37008,"/** 
 * Returns an   {@code int} value with at most a single one-bit, in theposition of the highest-order (""leftmost"") one-bit in the specified {@code int} value.  Returns zero if the specified value has noone-bits in its two's complement binary representation, that is, if it is equal to zero.
 * @return an {@code int} value with a single one-bit, in the positionof the highest-order one-bit in the specified value, or zero if the specified value is itself equal to zero.
 * @since 1.5
 */
public static int highestOneBit(int i){
  i|=(i >> 1);
  i|=(i >> 2);
  i|=(i >> 4);
  i|=(i >> 8);
  i|=(i >> 16);
  return i - (i >>> 1);
}","/** 
 * Returns an   {@code int} value with at most a single one-bit, in theposition of the highest-order (""leftmost"") one-bit in the specified {@code int} value.  Returns zero if the specified value has noone-bits in its two's complement binary representation, that is, if it is equal to zero.
 * @param i the value whose highest one bit is to be computed
 * @return an {@code int} value with a single one-bit, in the positionof the highest-order one-bit in the specified value, or zero if the specified value is itself equal to zero.
 * @since 1.5
 */
public static int highestOneBit(int i){
  i|=(i >> 1);
  i|=(i >> 2);
  i|=(i >> 4);
  i|=(i >> 8);
  i|=(i >> 16);
  return i - (i >>> 1);
}"
37009,"/** 
 * Returns the number of zero bits following the lowest-order (""rightmost"") one-bit in the two's complement binary representation of the specified  {@code int} value.  Returns 32 if the specified value has noone-bits in its two's complement representation, in other words if it is equal to zero.
 * @return the number of zero bits following the lowest-order (""rightmost"")one-bit in the two's complement binary representation of the specified  {@code int} value, or 32 if the value is equalto zero.
 * @since 1.5
 */
public static int numberOfTrailingZeros(int i){
  int y;
  if (i == 0)   return 32;
  int n=31;
  y=i << 16;
  if (y != 0) {
    n=n - 16;
    i=y;
  }
  y=i << 8;
  if (y != 0) {
    n=n - 8;
    i=y;
  }
  y=i << 4;
  if (y != 0) {
    n=n - 4;
    i=y;
  }
  y=i << 2;
  if (y != 0) {
    n=n - 2;
    i=y;
  }
  return n - ((i << 1) >>> 31);
}","/** 
 * Returns the number of zero bits following the lowest-order (""rightmost"") one-bit in the two's complement binary representation of the specified  {@code int} value.  Returns 32 if the specified value has noone-bits in its two's complement representation, in other words if it is equal to zero.
 * @param i the value whose number of trailing zeros is to be computed
 * @return the number of zero bits following the lowest-order (""rightmost"")one-bit in the two's complement binary representation of the specified  {@code int} value, or 32 if the value is equalto zero.
 * @since 1.5
 */
public static int numberOfTrailingZeros(int i){
  int y;
  if (i == 0)   return 32;
  int n=31;
  y=i << 16;
  if (y != 0) {
    n=n - 16;
    i=y;
  }
  y=i << 8;
  if (y != 0) {
    n=n - 8;
    i=y;
  }
  y=i << 4;
  if (y != 0) {
    n=n - 4;
    i=y;
  }
  y=i << 2;
  if (y != 0) {
    n=n - 2;
    i=y;
  }
  return n - ((i << 1) >>> 31);
}"
37010,"/** 
 * Returns the value obtained by reversing the order of the bytes in the two's complement representation of the specified   {@code int} value.
 * @return the value obtained by reversing the bytes in the specified{@code int} value.
 * @since 1.5
 */
public static int reverseBytes(int i){
  return ((i >>> 24)) | ((i >> 8) & 0xFF00) | ((i << 8) & 0xFF0000)| ((i << 24));
}","/** 
 * Returns the value obtained by reversing the order of the bytes in the two's complement representation of the specified   {@code int} value.
 * @param i the value whose bytes are to be reversed
 * @return the value obtained by reversing the bytes in the specified{@code int} value.
 * @since 1.5
 */
public static int reverseBytes(int i){
  return ((i >>> 24)) | ((i >> 8) & 0xFF00) | ((i << 8) & 0xFF0000)| ((i << 24));
}"
37011,"/** 
 * Returns the value obtained by rotating the two's complement binary representation of the specified   {@code long} value left by thespecified number of bits.  (Bits shifted out of the left hand, or high-order, side reenter on the right, or low-order.) <p>Note that left rotation with a negative distance is equivalent to right rotation:  {@code rotateLeft(val, -distance) == rotateRight(val,distance)}.  Note also that rotation by any multiple of 64 is a no-op, so all but the last six bits of the rotation distance can be ignored, even if the distance is negative:   {@code rotateLeft(val,distance) == rotateLeft(val, distance & 0x3F)}.
 * @return the value obtained by rotating the two's complement binaryrepresentation of the specified  {@code long} value left by thespecified number of bits.
 * @since 1.5
 */
public static long rotateLeft(long i,int distance){
  return (i << distance) | (i >>> -distance);
}","/** 
 * Returns the value obtained by rotating the two's complement binary representation of the specified   {@code long} value left by thespecified number of bits.  (Bits shifted out of the left hand, or high-order, side reenter on the right, or low-order.) <p>Note that left rotation with a negative distance is equivalent to right rotation:  {@code rotateLeft(val, -distance) == rotateRight(val,distance)}.  Note also that rotation by any multiple of 64 is a no-op, so all but the last six bits of the rotation distance can be ignored, even if the distance is negative:   {@code rotateLeft(val,distance) == rotateLeft(val, distance & 0x3F)}.
 * @param i the value whose bits are to be rotated left
 * @param distance the number of bit positions to rotate left
 * @return the value obtained by rotating the two's complement binaryrepresentation of the specified  {@code long} value left by thespecified number of bits.
 * @since 1.5
 */
public static long rotateLeft(long i,int distance){
  return (i << distance) | (i >>> -distance);
}"
37012,"/** 
 * Returns a hash code for a   {@code long} value; compatible with{@code Long.hashCode()}.
 * @since 1.8
 * @return a hash code value for a {@code long} value.
 */
public static int hashCode(long value){
  return (int)(value ^ (value >>> 32));
}","/** 
 * Returns a hash code for a   {@code long} value; compatible with{@code Long.hashCode()}.
 * @param value the value to hash
 * @return a hash code value for a {@code long} value.
 * @since 1.8
 */
public static int hashCode(long value){
  return (int)(value ^ (value >>> 32));
}"
37013,"/** 
 * Returns a   {@code long} value with at most a single one-bit, in theposition of the lowest-order (""rightmost"") one-bit in the specified {@code long} value.  Returns zero if the specified value has noone-bits in its two's complement binary representation, that is, if it is equal to zero.
 * @return a {@code long} value with a single one-bit, in the positionof the lowest-order one-bit in the specified value, or zero if the specified value is itself equal to zero.
 * @since 1.5
 */
public static long lowestOneBit(long i){
  return i & -i;
}","/** 
 * Returns a   {@code long} value with at most a single one-bit, in theposition of the lowest-order (""rightmost"") one-bit in the specified {@code long} value.  Returns zero if the specified value has noone-bits in its two's complement binary representation, that is, if it is equal to zero.
 * @param i the value whose lowest one bit is to be computed
 * @return a {@code long} value with a single one-bit, in the positionof the lowest-order one-bit in the specified value, or zero if the specified value is itself equal to zero.
 * @since 1.5
 */
public static long lowestOneBit(long i){
  return i & -i;
}"
37014,"/** 
 * Returns the signum function of the specified   {@code long} value.  (Thereturn value is -1 if the specified value is negative; 0 if the specified value is zero; and 1 if the specified value is positive.)
 * @return the signum function of the specified {@code long} value.
 * @since 1.5
 */
public static int signum(long i){
  return (int)((i >> 63) | (-i >>> 63));
}","/** 
 * Returns the signum function of the specified   {@code long} value.  (Thereturn value is -1 if the specified value is negative; 0 if the specified value is zero; and 1 if the specified value is positive.)
 * @param i the value whose signum is to be computed
 * @return the signum function of the specified {@code long} value.
 * @since 1.5
 */
public static int signum(long i){
  return (int)((i >> 63) | (-i >>> 63));
}"
37015,"/** 
 * Returns the value obtained by rotating the two's complement binary representation of the specified   {@code long} value right by thespecified number of bits.  (Bits shifted out of the right hand, or low-order, side reenter on the left, or high-order.) <p>Note that right rotation with a negative distance is equivalent to left rotation:  {@code rotateRight(val, -distance) == rotateLeft(val,distance)}.  Note also that rotation by any multiple of 64 is a no-op, so all but the last six bits of the rotation distance can be ignored, even if the distance is negative:   {@code rotateRight(val,distance) == rotateRight(val, distance & 0x3F)}.
 * @return the value obtained by rotating the two's complement binaryrepresentation of the specified  {@code long} value right by thespecified number of bits.
 * @since 1.5
 */
public static long rotateRight(long i,int distance){
  return (i >>> distance) | (i << -distance);
}","/** 
 * Returns the value obtained by rotating the two's complement binary representation of the specified   {@code long} value right by thespecified number of bits.  (Bits shifted out of the right hand, or low-order, side reenter on the left, or high-order.) <p>Note that right rotation with a negative distance is equivalent to left rotation:  {@code rotateRight(val, -distance) == rotateLeft(val,distance)}.  Note also that rotation by any multiple of 64 is a no-op, so all but the last six bits of the rotation distance can be ignored, even if the distance is negative:   {@code rotateRight(val,distance) == rotateRight(val, distance & 0x3F)}.
 * @param i the value whose bits are to be rotated right
 * @param distance the number of bit positions to rotate right
 * @return the value obtained by rotating the two's complement binaryrepresentation of the specified  {@code long} value right by thespecified number of bits.
 * @since 1.5
 */
public static long rotateRight(long i,int distance){
  return (i >>> distance) | (i << -distance);
}"
37016,"/** 
 * Returns the value obtained by reversing the order of the bits in the two's complement binary representation of the specified   {@code long}value.
 * @return the value obtained by reversing order of the bits in thespecified  {@code long} value.
 * @since 1.5
 */
public static long reverse(long i){
  i=(i & 0x5555555555555555L) << 1 | (i >>> 1) & 0x5555555555555555L;
  i=(i & 0x3333333333333333L) << 2 | (i >>> 2) & 0x3333333333333333L;
  i=(i & 0x0f0f0f0f0f0f0f0fL) << 4 | (i >>> 4) & 0x0f0f0f0f0f0f0f0fL;
  i=(i & 0x00ff00ff00ff00ffL) << 8 | (i >>> 8) & 0x00ff00ff00ff00ffL;
  i=(i << 48) | ((i & 0xffff0000L) << 16) | ((i >>> 16) & 0xffff0000L)| (i >>> 48);
  return i;
}","/** 
 * Returns the value obtained by reversing the order of the bits in the two's complement binary representation of the specified   {@code long}value.
 * @param i the value to be reversed
 * @return the value obtained by reversing order of the bits in thespecified  {@code long} value.
 * @since 1.5
 */
public static long reverse(long i){
  i=(i & 0x5555555555555555L) << 1 | (i >>> 1) & 0x5555555555555555L;
  i=(i & 0x3333333333333333L) << 2 | (i >>> 2) & 0x3333333333333333L;
  i=(i & 0x0f0f0f0f0f0f0f0fL) << 4 | (i >>> 4) & 0x0f0f0f0f0f0f0f0fL;
  i=(i & 0x00ff00ff00ff00ffL) << 8 | (i >>> 8) & 0x00ff00ff00ff00ffL;
  i=(i << 48) | ((i & 0xffff0000L) << 16) | ((i >>> 16) & 0xffff0000L)| (i >>> 48);
  return i;
}"
37017,"/** 
 * Returns the number of zero bits preceding the highest-order (""leftmost"") one-bit in the two's complement binary representation of the specified   {@code long} value.  Returns 64 if thespecified value has no one-bits in its two's complement representation, in other words if it is equal to zero. <p>Note that this method is closely related to the logarithm base 2. For all positive  {@code long} values x:<ul> <li>floor(log<sub>2</sub>(x)) =  {@code 63 - numberOfLeadingZeros(x)}<li>ceil(log<sub>2</sub>(x)) =   {@code 64 - numberOfLeadingZeros(x - 1)}</ul>
 * @return the number of zero bits preceding the highest-order(""leftmost"") one-bit in the two's complement binary representation of the specified  {@code long} value, or 64 if the valueis equal to zero.
 * @since 1.5
 */
public static int numberOfLeadingZeros(long i){
  if (i == 0)   return 64;
  int n=1;
  int x=(int)(i >>> 32);
  if (x == 0) {
    n+=32;
    x=(int)i;
  }
  if (x >>> 16 == 0) {
    n+=16;
    x<<=16;
  }
  if (x >>> 24 == 0) {
    n+=8;
    x<<=8;
  }
  if (x >>> 28 == 0) {
    n+=4;
    x<<=4;
  }
  if (x >>> 30 == 0) {
    n+=2;
    x<<=2;
  }
  n-=x >>> 31;
  return n;
}","/** 
 * Returns the number of zero bits preceding the highest-order (""leftmost"") one-bit in the two's complement binary representation of the specified   {@code long} value.  Returns 64 if thespecified value has no one-bits in its two's complement representation, in other words if it is equal to zero. <p>Note that this method is closely related to the logarithm base 2. For all positive  {@code long} values x:<ul> <li>floor(log<sub>2</sub>(x)) =  {@code 63 - numberOfLeadingZeros(x)}<li>ceil(log<sub>2</sub>(x)) =   {@code 64 - numberOfLeadingZeros(x - 1)}</ul>
 * @param i the value whose number of leading zeros is to be computed
 * @return the number of zero bits preceding the highest-order(""leftmost"") one-bit in the two's complement binary representation of the specified  {@code long} value, or 64 if the valueis equal to zero.
 * @since 1.5
 */
public static int numberOfLeadingZeros(long i){
  if (i == 0)   return 64;
  int n=1;
  int x=(int)(i >>> 32);
  if (x == 0) {
    n+=32;
    x=(int)i;
  }
  if (x >>> 16 == 0) {
    n+=16;
    x<<=16;
  }
  if (x >>> 24 == 0) {
    n+=8;
    x<<=8;
  }
  if (x >>> 28 == 0) {
    n+=4;
    x<<=4;
  }
  if (x >>> 30 == 0) {
    n+=2;
    x<<=2;
  }
  n-=x >>> 31;
  return n;
}"
37018,"/** 
 * Returns the number of one-bits in the two's complement binary representation of the specified   {@code long} value.  This function issometimes referred to as the <i>population count</i>.
 * @return the number of one-bits in the two's complement binaryrepresentation of the specified  {@code long} value.
 * @since 1.5
 */
public static int bitCount(long i){
  i=i - ((i >>> 1) & 0x5555555555555555L);
  i=(i & 0x3333333333333333L) + ((i >>> 2) & 0x3333333333333333L);
  i=(i + (i >>> 4)) & 0x0f0f0f0f0f0f0f0fL;
  i=i + (i >>> 8);
  i=i + (i >>> 16);
  i=i + (i >>> 32);
  return (int)i & 0x7f;
}","/** 
 * Returns the number of one-bits in the two's complement binary representation of the specified   {@code long} value.  This function issometimes referred to as the <i>population count</i>.
 * @param i the value whose bits are to be counted
 * @return the number of one-bits in the two's complement binaryrepresentation of the specified  {@code long} value.
 * @since 1.5
 */
public static int bitCount(long i){
  i=i - ((i >>> 1) & 0x5555555555555555L);
  i=(i & 0x3333333333333333L) + ((i >>> 2) & 0x3333333333333333L);
  i=(i + (i >>> 4)) & 0x0f0f0f0f0f0f0f0fL;
  i=i + (i >>> 8);
  i=i + (i >>> 16);
  i=i + (i >>> 32);
  return (int)i & 0x7f;
}"
37019,"/** 
 * Returns a   {@code long} value with at most a single one-bit, in theposition of the highest-order (""leftmost"") one-bit in the specified {@code long} value.  Returns zero if the specified value has noone-bits in its two's complement binary representation, that is, if it is equal to zero.
 * @return a {@code long} value with a single one-bit, in the positionof the highest-order one-bit in the specified value, or zero if the specified value is itself equal to zero.
 * @since 1.5
 */
public static long highestOneBit(long i){
  i|=(i >> 1);
  i|=(i >> 2);
  i|=(i >> 4);
  i|=(i >> 8);
  i|=(i >> 16);
  i|=(i >> 32);
  return i - (i >>> 1);
}","/** 
 * Returns a   {@code long} value with at most a single one-bit, in theposition of the highest-order (""leftmost"") one-bit in the specified {@code long} value.  Returns zero if the specified value has noone-bits in its two's complement binary representation, that is, if it is equal to zero.
 * @param i the value whose highest one bit is to be computed
 * @return a {@code long} value with a single one-bit, in the positionof the highest-order one-bit in the specified value, or zero if the specified value is itself equal to zero.
 * @since 1.5
 */
public static long highestOneBit(long i){
  i|=(i >> 1);
  i|=(i >> 2);
  i|=(i >> 4);
  i|=(i >> 8);
  i|=(i >> 16);
  i|=(i >> 32);
  return i - (i >>> 1);
}"
37020,"/** 
 * Returns the number of zero bits following the lowest-order (""rightmost"") one-bit in the two's complement binary representation of the specified  {@code long} value.  Returns 64 if the specified value has noone-bits in its two's complement representation, in other words if it is equal to zero.
 * @return the number of zero bits following the lowest-order (""rightmost"")one-bit in the two's complement binary representation of the specified  {@code long} value, or 64 if the value is equalto zero.
 * @since 1.5
 */
public static int numberOfTrailingZeros(long i){
  int x, y;
  if (i == 0)   return 64;
  int n=63;
  y=(int)i;
  if (y != 0) {
    n=n - 32;
    x=y;
  }
 else   x=(int)(i >>> 32);
  y=x << 16;
  if (y != 0) {
    n=n - 16;
    x=y;
  }
  y=x << 8;
  if (y != 0) {
    n=n - 8;
    x=y;
  }
  y=x << 4;
  if (y != 0) {
    n=n - 4;
    x=y;
  }
  y=x << 2;
  if (y != 0) {
    n=n - 2;
    x=y;
  }
  return n - ((x << 1) >>> 31);
}","/** 
 * Returns the number of zero bits following the lowest-order (""rightmost"") one-bit in the two's complement binary representation of the specified  {@code long} value.  Returns 64 if the specified value has noone-bits in its two's complement representation, in other words if it is equal to zero.
 * @param i the value whose number of trailing zeros is to be computed
 * @return the number of zero bits following the lowest-order (""rightmost"")one-bit in the two's complement binary representation of the specified  {@code long} value, or 64 if the value is equalto zero.
 * @since 1.5
 */
public static int numberOfTrailingZeros(long i){
  int x, y;
  if (i == 0)   return 64;
  int n=63;
  y=(int)i;
  if (y != 0) {
    n=n - 32;
    x=y;
  }
 else   x=(int)(i >>> 32);
  y=x << 16;
  if (y != 0) {
    n=n - 16;
    x=y;
  }
  y=x << 8;
  if (y != 0) {
    n=n - 8;
    x=y;
  }
  y=x << 4;
  if (y != 0) {
    n=n - 4;
    x=y;
  }
  y=x << 2;
  if (y != 0) {
    n=n - 2;
    x=y;
  }
  return n - ((x << 1) >>> 31);
}"
37021,"/** 
 * Returns the value obtained by reversing the order of the bytes in the two's complement representation of the specified   {@code long} value.
 * @return the value obtained by reversing the bytes in the specified{@code long} value.
 * @since 1.5
 */
public static long reverseBytes(long i){
  i=(i & 0x00ff00ff00ff00ffL) << 8 | (i >>> 8) & 0x00ff00ff00ff00ffL;
  return (i << 48) | ((i & 0xffff0000L) << 16) | ((i >>> 16) & 0xffff0000L)| (i >>> 48);
}","/** 
 * Returns the value obtained by reversing the order of the bytes in the two's complement representation of the specified   {@code long} value.
 * @param i the value whose bytes are to be reversed
 * @return the value obtained by reversing the bytes in the specified{@code long} value.
 * @since 1.5
 */
public static long reverseBytes(long i){
  i=(i & 0x00ff00ff00ff00ffL) << 8 | (i >>> 8) & 0x00ff00ff00ff00ffL;
  return (i << 48) | ((i & 0xffff0000L) << 16) | ((i >>> 16) & 0xffff0000L)| (i >>> 48);
}"
37022,"/** 
 * Registers a new virtual-machine shutdown hook. <p> The Java virtual machine <i>shuts down</i> in response to two kinds of events: <ul> <p> <li> The program <i>exits</i> normally, when the last non-daemon thread exits or when the <tt>  {@link #exit exit}</tt> (equivalently, <tt>  {@link System#exit(int) System.exit}</tt>) method is invoked, or <p> <li> The virtual machine is <i>terminated</i> in response to a user interrupt, such as typing <tt>^C</tt>, or a system-wide event, such as user logoff or system shutdown. </ul> <p> A <i>shutdown hook</i> is simply an initialized but unstarted thread.  When the virtual machine begins its shutdown sequence it will start all registered shutdown hooks in some unspecified order and let them run concurrently.  When all the hooks have finished it will then run all uninvoked finalizers if finalization-on-exit has been enabled. Finally, the virtual machine will halt.  Note that daemon threads will continue to run during the shutdown sequence, as will non-daemon threads if shutdown was initiated by invoking the <tt>  {@link #exit exit}</tt> method. <p> Once the shutdown sequence has begun it can be stopped only by invoking the <tt>  {@link #halt halt}</tt> method, which forcibly terminates the virtual machine. <p> Once the shutdown sequence has begun it is impossible to register a new shutdown hook or de-register a previously-registered hook. Attempting either of these operations will cause an <tt>  {@link IllegalStateException}</tt> to be thrown. <p> Shutdown hooks run at a delicate time in the life cycle of a virtual machine and should therefore be coded defensively.  They should, in particular, be written to be thread-safe and to avoid deadlocks insofar as possible.  They should also not rely blindly upon services that may have registered their own shutdown hooks and therefore may themselves in the process of shutting down.  Attempts to use other thread-based services such as the AWT event-dispatch thread, for example, may lead to deadlocks. <p> Shutdown hooks should also finish their work quickly.  When a program invokes <tt>  {@link #exit exit}</tt> the expectation is that the virtual machine will promptly shut down and exit.  When the virtual machine is terminated due to user logoff or system shutdown the underlying operating system may only allow a fixed amount of time in which to shut down and exit.  It is therefore inadvisable to attempt any user interaction or to perform a long-running computation in a shutdown hook. <p> Uncaught exceptions are handled in shutdown hooks just as in any other thread, by invoking the <tt>  {@link ThreadGroup#uncaughtException uncaughtException}</tt> method of the thread's <tt>  {@link ThreadGroup}</tt> object.  The default implementation of this method prints the exception's stack trace to <tt>  {@link System#err}</tt> and terminates the thread; it does not cause the virtual machine to exit or halt. <p> In rare circumstances the virtual machine may <i>abort</i>, that is, stop running without shutting down cleanly.  This occurs when the virtual machine is terminated externally, for example with the <tt>SIGKILL</tt> signal on Unix or the <tt>TerminateProcess</tt> call on Microsoft Windows.  The virtual machine may also abort if a native method goes awry by, for example, corrupting internal data structures or attempting to access nonexistent memory.  If the virtual machine aborts then no guarantee can be made about whether or not any shutdown hooks will be run. <p>
 * @param hook An initialized but unstarted <tt> {@link Thread}</tt> object
 * @throws IllegalArgumentException If the specified hook has already been registered, or if it can be determined that the hook is already running or has already been run
 * @throws IllegalStateException If the virtual machine is already in the process of shutting down
 * @throws SecurityException If a security manager is present and it denies <tt> {@link RuntimePermission}(""shutdownHooks"")</tt>
 * @see #removeShutdownHook
 * @see #halt(int)
 * @see #exit(int)
 * @since 1.3
 */
public void addShutdownHook(Thread hook){
  SecurityManager sm=System.getSecurityManager();
  if (sm != null) {
    sm.checkPermission(new RuntimePermission(""String_Node_Str""));
  }
  ApplicationShutdownHooks.add(hook);
}","/** 
 * Registers a new virtual-machine shutdown hook. <p> The Java virtual machine <i>shuts down</i> in response to two kinds of events: <ul> <li> The program <i>exits</i> normally, when the last non-daemon thread exits or when the <tt>  {@link #exit exit}</tt> (equivalently,  {@link System#exit(int) System.exit}) method is invoked, or <li> The virtual machine is <i>terminated</i> in response to a user interrupt, such as typing <tt>^C</tt>, or a system-wide event, such as user logoff or system shutdown. </ul> <p> A <i>shutdown hook</i> is simply an initialized but unstarted thread.  When the virtual machine begins its shutdown sequence it will start all registered shutdown hooks in some unspecified order and let them run concurrently.  When all the hooks have finished it will then run all uninvoked finalizers if finalization-on-exit has been enabled. Finally, the virtual machine will halt.  Note that daemon threads will continue to run during the shutdown sequence, as will non-daemon threads if shutdown was initiated by invoking the <tt>  {@link #exit exit}</tt> method. <p> Once the shutdown sequence has begun it can be stopped only by invoking the <tt>  {@link #halt halt}</tt> method, which forcibly terminates the virtual machine. <p> Once the shutdown sequence has begun it is impossible to register a new shutdown hook or de-register a previously-registered hook. Attempting either of these operations will cause an <tt>  {@link IllegalStateException}</tt> to be thrown. <p> Shutdown hooks run at a delicate time in the life cycle of a virtual machine and should therefore be coded defensively.  They should, in particular, be written to be thread-safe and to avoid deadlocks insofar as possible.  They should also not rely blindly upon services that may have registered their own shutdown hooks and therefore may themselves in the process of shutting down.  Attempts to use other thread-based services such as the AWT event-dispatch thread, for example, may lead to deadlocks. <p> Shutdown hooks should also finish their work quickly.  When a program invokes <tt>  {@link #exit exit}</tt> the expectation is that the virtual machine will promptly shut down and exit.  When the virtual machine is terminated due to user logoff or system shutdown the underlying operating system may only allow a fixed amount of time in which to shut down and exit.  It is therefore inadvisable to attempt any user interaction or to perform a long-running computation in a shutdown hook. <p> Uncaught exceptions are handled in shutdown hooks just as in any other thread, by invoking the <tt>  {@link ThreadGroup#uncaughtException uncaughtException}</tt> method of the thread's <tt>  {@link ThreadGroup}</tt> object.  The default implementation of this method prints the exception's stack trace to <tt>  {@link System#err}</tt> and terminates the thread; it does not cause the virtual machine to exit or halt. <p> In rare circumstances the virtual machine may <i>abort</i>, that is, stop running without shutting down cleanly.  This occurs when the virtual machine is terminated externally, for example with the <tt>SIGKILL</tt> signal on Unix or the <tt>TerminateProcess</tt> call on Microsoft Windows.  The virtual machine may also abort if a native method goes awry by, for example, corrupting internal data structures or attempting to access nonexistent memory.  If the virtual machine aborts then no guarantee can be made about whether or not any shutdown hooks will be run. <p>
 * @param hook An initialized but unstarted <tt> {@link Thread}</tt> object
 * @throws IllegalArgumentException If the specified hook has already been registered, or if it can be determined that the hook is already running or has already been run
 * @throws IllegalStateException If the virtual machine is already in the process of shutting down
 * @throws SecurityException If a security manager is present and it denies <tt> {@link RuntimePermission}(""shutdownHooks"")</tt>
 * @see #removeShutdownHook
 * @see #halt(int)
 * @see #exit(int)
 * @since 1.3
 */
public void addShutdownHook(Thread hook){
  SecurityManager sm=System.getSecurityManager();
  if (sm != null) {
    sm.checkPermission(new RuntimePermission(""String_Node_Str""));
  }
  ApplicationShutdownHooks.add(hook);
}"
37023,"/** 
 * Returns a hash code for a   {@code short} value; compatible with{@code Short.hashCode()}.
 * @since 1.8
 * @return a hash code value for a {@code short} value.
 */
public static int hashCode(short value){
  return (int)value;
}","/** 
 * Returns a hash code for a   {@code short} value; compatible with{@code Short.hashCode()}.
 * @param value the value to hash
 * @return a hash code value for a {@code short} value.
 * @since 1.8
 */
public static int hashCode(short value){
  return (int)value;
}"
37024,"/** 
 * Returns the value obtained by reversing the order of the bytes in the two's complement representation of the specified   {@code short} value.
 * @return the value obtained by reversing (or, equivalently, swapping)the bytes in the specified  {@code short} value.
 * @since 1.5
 */
public static short reverseBytes(short i){
  return (short)(((i & 0xFF00) >> 8) | (i << 8));
}","/** 
 * Returns the value obtained by reversing the order of the bytes in the two's complement representation of the specified   {@code short} value.
 * @param i the value whose bytes are to be reversed
 * @return the value obtained by reversing (or, equivalently, swapping)the bytes in the specified  {@code short} value.
 * @since 1.5
 */
public static short reverseBytes(short i){
  return (short)(((i & 0xFF00) >> 8) | (i << 8));
}"
37025,"/** 
 * Returns the unbiased exponent used in the representation of a  {@code double}.  Special cases: <ul> <li>If the argument is NaN or infinite, then the result is  {@link Double#MAX_EXPONENT} + 1.<li>If the argument is zero or subnormal, then the result is {@link Double#MIN_EXPONENT} -1.</ul>
 * @param d a {@code double} value
 * @since 1.6
 */
public static int getExponent(double d){
  return Math.getExponent(d);
}","/** 
 * Returns the unbiased exponent used in the representation of a  {@code double}.  Special cases: <ul> <li>If the argument is NaN or infinite, then the result is  {@link Double#MAX_EXPONENT} + 1.<li>If the argument is zero or subnormal, then the result is {@link Double#MIN_EXPONENT} -1.</ul>
 * @param d a {@code double} value
 * @return the unbiased exponent of the argument
 * @since 1.6
 */
public static int getExponent(double d){
  return Math.getExponent(d);
}"
37026,"/** 
 * Return the global LogManager object.
 */
public static LogManager getLogManager(){
  if (manager != null) {
    manager.readPrimordialConfiguration();
  }
  return manager;
}","/** 
 * Returns the global LogManager object.
 * @return the global LogManager object
 */
public static LogManager getLogManager(){
  if (manager != null) {
    manager.readPrimordialConfiguration();
  }
  return manager;
}"
37027,"/** 
 * Get the localization resource bundle name <p> This is the name for the ResourceBundle that should be used to localize the message string before formatting it. The result may be null if the message is not localizable.
 */
public String getResourceBundleName(){
  return resourceBundleName;
}","/** 
 * Get the localization resource bundle name <p> This is the name for the ResourceBundle that should be used to localize the message string before formatting it. The result may be null if the message is not localizable.
 * @return the localization resource bundle name
 */
public String getResourceBundleName(){
  return resourceBundleName;
}"
37028,"/** 
 * Get the localization resource bundle <p> This is the ResourceBundle that should be used to localize the message string before formatting it.  The result may be null if the message is not localizable, or if no suitable ResourceBundle is available.
 */
public ResourceBundle getResourceBundle(){
  return resourceBundle;
}","/** 
 * Get the localization resource bundle <p> This is the ResourceBundle that should be used to localize the message string before formatting it.  The result may be null if the message is not localizable, or if no suitable ResourceBundle is available.
 * @return the localization resource bundle
 */
public ResourceBundle getResourceBundle(){
  return resourceBundle;
}"
37029,"/** 
 * Set the sequence number. <p> Sequence numbers are normally assigned in the LogRecord constructor, so it should not normally be necessary to use this method.
 */
public void setSequenceNumber(long seq){
  sequenceNumber=seq;
}","/** 
 * Set the sequence number. <p> Sequence numbers are normally assigned in the LogRecord constructor, so it should not normally be necessary to use this method.
 * @param seq the sequence number
 */
public void setSequenceNumber(long seq){
  sequenceNumber=seq;
}"
37030,"/** 
 * Return the kind of this tag. similar or synonymous tags.  For most tags, <code>kind()&nbsp;==&nbsp;name()</code>; the following table lists those cases where there is more than one tag of a given kind: <p> <table border=""1"" cellpadding=""4"" cellspacing=""0""> <tr><th><tt> kind()  </tt></th>  <th><tt> name()      </tt></th></tr> <tr><td><tt> @throws </tt></td>  <td><tt> @throws     </tt></td></tr> <tr><td><tt> @throws </tt></td>  <td><tt> @exception  </tt></td></tr> <tr><td><tt> @see    </tt></td>  <td><tt> @see        </tt></td></tr> <tr><td><tt> @see    </tt></td>  <td><tt> @link       </tt></td></tr> <tr><td><tt> @see    </tt></td>  <td><tt> @linkplain  </tt></td></tr> <tr><td><tt> @serial </tt></td>  <td><tt> @serial     </tt></td></tr> <tr><td><tt> @serial </tt></td>  <td><tt> @serialData </tt></td></tr> </table>
 */
String kind();","/** 
 * Return the kind of this tag. For most tags, <code>kind()&nbsp;==&nbsp;name()</code>; the following table lists those cases where there is more than one tag of a given kind: <p> <table border=""1"" cellpadding=""4"" cellspacing=""0"" summary=""related tags""> <tr><th>  {@code kind()  }</th>  <th>  {@code name()      }</th></tr> <tr><td>  {@code @throws }</td>  <td>  {@code @throws     }</td></tr> <tr><td>  {@code @throws }</td>  <td>  {@code @exception  }</td></tr> <tr><td>  {@code @see    }</td>  <td>  {@code @see        }</td></tr> <tr><td>  {@code @see    }</td>  <td>  {@code @link       }</td></tr> <tr><td>  {@code @see    }</td>  <td>  {@code @linkplain  }</td></tr> <tr><td>  {@code @serial }</td>  <td>  {@code @serial     }</td></tr> <tr><td>  {@code @serial }</td>  <td>  {@code @serialData }</td></tr> </table>
 * @return the kind of this tag.
 */
String kind();"
37031,"/** 
 * Return the name of this tag.  The name is the string starting with ""@"" that is used in a doc comment, such as <code>@return</code>.  For inline tags, such as <code>{&#064;link}</code>, the curly brackets are not part of the name, so in this example the name would be simply <code>@link</code>.
 */
String name();","/** 
 * Return the name of this tag.  The name is the string starting with ""@"" that is used in a doc comment, such as <code>@return</code>.  For inline tags, such as <code>{&#064;link}</code>, the curly brackets are not part of the name, so in this example the name would be simply <code>@link</code>.
 * @return the name of this tag
 */
String name();"
37032,"/** 
 * Return the containing   {@link Doc} of this Tag element.
 */
Doc holder();","/** 
 * Return the containing   {@link Doc} of this Tag element.
 * @return the containing {@link Doc} of this Tag element
 */
Doc holder();"
37033,"/** 
 * Return the text of this tag, that is, portion beyond tag name.
 */
String text();","/** 
 * Return the text of this tag, that is, the portion beyond tag name.
 * @return the text of this tag
 */
String text();"
37034,"/** 
 * Return the kind of this tag. similar or synonymous tags.  For most tags, <code>kind()&nbsp;==&nbsp;name()</code>; the following table lists those cases where there is more than one tag of a given kind: <p> <table border=""1"" cellpadding=""4"" cellspacing=""0""> <tr><th><tt> kind()  </tt></th>  <th><tt> name()      </tt></th></tr> <tr><td><tt> @throws </tt></td>  <td><tt> @throws     </tt></td></tr> <tr><td><tt> @throws </tt></td>  <td><tt> @exception  </tt></td></tr> <tr><td><tt> @see    </tt></td>  <td><tt> @see        </tt></td></tr> <tr><td><tt> @see    </tt></td>  <td><tt> @link       </tt></td></tr> <tr><td><tt> @see    </tt></td>  <td><tt> @linkplain  </tt></td></tr> <tr><td><tt> @serial </tt></td>  <td><tt> @serial     </tt></td></tr> <tr><td><tt> @serial </tt></td>  <td><tt> @serialData </tt></td></tr> </table>
 */
String kind();","/** 
 * Return the kind of this tag. For most tags, <code>kind()&nbsp;==&nbsp;name()</code>; the following table lists those cases where there is more than one tag of a given kind: <p> <table border=""1"" cellpadding=""4"" cellspacing=""0"" summary=""related tags""> <tr><th>  {@code kind()  }</th>  <th>  {@code name()      }</th></tr> <tr><td>  {@code @throws }</td>  <td>  {@code @throws     }</td></tr> <tr><td>  {@code @throws }</td>  <td>  {@code @exception  }</td></tr> <tr><td>  {@code @see    }</td>  <td>  {@code @see        }</td></tr> <tr><td>  {@code @see    }</td>  <td>  {@code @link       }</td></tr> <tr><td>  {@code @see    }</td>  <td>  {@code @linkplain  }</td></tr> <tr><td>  {@code @serial }</td>  <td>  {@code @serial     }</td></tr> <tr><td>  {@code @serial }</td>  <td>  {@code @serialData }</td></tr> </table>
 * @return the kind of this tag.
 */
String kind();"
37035,"/** 
 * Return the name of this tag.  The name is the string starting with ""@"" that is used in a doc comment, such as <code>@return</code>.  For inline tags, such as <code>{&#064;link}</code>, the curly brackets are not part of the name, so in this example the name would be simply <code>@link</code>.
 */
String name();","/** 
 * Return the name of this tag.  The name is the string starting with ""@"" that is used in a doc comment, such as <code>@return</code>.  For inline tags, such as <code>{&#064;link}</code>, the curly brackets are not part of the name, so in this example the name would be simply <code>@link</code>.
 * @return the name of this tag
 */
String name();"
37036,"/** 
 * Return the containing   {@link Doc} of this Tag element.
 */
Doc holder();","/** 
 * Return the containing   {@link Doc} of this Tag element.
 * @return the containing {@link Doc} of this Tag element
 */
Doc holder();"
37037,"/** 
 * Return the text of this tag, that is, portion beyond tag name.
 */
String text();","/** 
 * Return the text of this tag, that is, the portion beyond tag name.
 * @return the text of this tag
 */
String text();"
37038,"BasicLookupHelper(Name name,Type site,List<Type> argtypes,List<Type> typeargtypes){
  super(name,site,argtypes,typeargtypes,MethodResolutionPhase.VARARITY);
}","BasicLookupHelper(Name name,Type site,List<Type> argtypes,List<Type> typeargtypes,MethodResolutionPhase maxPhase){
  super(name,site,argtypes,typeargtypes,maxPhase);
}"
37039,"/** 
 * Select the best method for a call site among two choices.
 * @param env              The current environment.
 * @param site             The original type from where theselection takes place.
 * @param argtypes         The invocation's value arguments,
 * @param typeargtypes     The invocation's type arguments,
 * @param sym              Proposed new best match.
 * @param bestSoFar        Previously found best match.
 * @param allowBoxing Allow boxing conversions of arguments.
 * @param useVarargs Box trailing arguments into an array for varargs.
 */
@SuppressWarnings(""String_Node_Str"") Symbol selectBest(Env<AttrContext> env,Type site,List<Type> argtypes,List<Type> typeargtypes,Symbol sym,Symbol bestSoFar,boolean allowBoxing,boolean useVarargs,boolean operator){
  if (sym.kind == ERR || !sym.isInheritedIn(site.tsym,types)) {
    return bestSoFar;
  }
 else   if (useVarargs && (sym.flags() & VARARGS) == 0) {
    return bestSoFar.kind >= ERRONEOUS ? new BadVarargsMethod((ResolveError)bestSoFar) : bestSoFar;
  }
  Assert.check(sym.kind < AMBIGUOUS);
  try {
    Type mt=rawInstantiate(env,site,sym,null,argtypes,typeargtypes,allowBoxing,useVarargs,types.noWarnings);
    if (!operator)     currentResolutionContext.addApplicableCandidate(sym,mt);
  }
 catch (  InapplicableMethodException ex) {
    if (!operator)     currentResolutionContext.addInapplicableCandidate(sym,ex.getDiagnostic());
switch (bestSoFar.kind) {
case ABSENT_MTH:
      return new InapplicableSymbolError(currentResolutionContext);
case WRONG_MTH:
    if (operator)     return bestSoFar;
  bestSoFar=new InapplicableSymbolsError(currentResolutionContext);
default :
return bestSoFar;
}
}
if (!isAccessible(env,site,sym)) {
return (bestSoFar.kind == ABSENT_MTH) ? new AccessError(env,site,sym) : bestSoFar;
}
return (bestSoFar.kind > AMBIGUOUS) ? sym : mostSpecific(argtypes,sym,bestSoFar,env,site,allowBoxing && operator,useVarargs);
}","/** 
 * Select the best method for a call site among two choices.
 * @param env              The current environment.
 * @param site             The original type from where theselection takes place.
 * @param argtypes         The invocation's value arguments,
 * @param typeargtypes     The invocation's type arguments,
 * @param sym              Proposed new best match.
 * @param bestSoFar        Previously found best match.
 * @param allowBoxing Allow boxing conversions of arguments.
 * @param useVarargs Box trailing arguments into an array for varargs.
 */
@SuppressWarnings(""String_Node_Str"") Symbol selectBest(Env<AttrContext> env,Type site,List<Type> argtypes,List<Type> typeargtypes,Symbol sym,Symbol bestSoFar,boolean allowBoxing,boolean useVarargs,boolean operator){
  if (sym.kind == ERR || !sym.isInheritedIn(site.tsym,types)) {
    return bestSoFar;
  }
 else   if (useVarargs && (sym.flags() & VARARGS) == 0) {
    return bestSoFar.kind >= ERRONEOUS ? new BadVarargsMethod((ResolveError)bestSoFar) : bestSoFar;
  }
  Assert.check(sym.kind < AMBIGUOUS);
  try {
    Type mt=rawInstantiate(env,site,sym,null,argtypes,typeargtypes,allowBoxing,useVarargs,types.noWarnings);
    if (!operator || verboseResolutionMode.contains(VerboseResolutionMode.PREDEF))     currentResolutionContext.addApplicableCandidate(sym,mt);
  }
 catch (  InapplicableMethodException ex) {
    if (!operator)     currentResolutionContext.addInapplicableCandidate(sym,ex.getDiagnostic());
switch (bestSoFar.kind) {
case ABSENT_MTH:
      return new InapplicableSymbolError(currentResolutionContext);
case WRONG_MTH:
    if (operator)     return bestSoFar;
  bestSoFar=new InapplicableSymbolsError(currentResolutionContext);
default :
return bestSoFar;
}
}
if (!isAccessible(env,site,sym)) {
return (bestSoFar.kind == ABSENT_MTH) ? new AccessError(env,site,sym) : bestSoFar;
}
return (bestSoFar.kind > AMBIGUOUS) ? sym : mostSpecific(argtypes,sym,bestSoFar,env,site,allowBoxing && operator,useVarargs);
}"
37040,"/** 
 * Resolve operator.
 * @param pos       The position to use for error reporting.
 * @param optag     The tag of the operation tree.
 * @param env       The environment current at the operation.
 * @param argtypes  The types of the operands.
 */
Symbol resolveOperator(DiagnosticPosition pos,JCTree.Tag optag,Env<AttrContext> env,List<Type> argtypes){
  MethodResolutionContext prevResolutionContext=currentResolutionContext;
  try {
    currentResolutionContext=new MethodResolutionContext();
    Name name=treeinfo.operatorName(optag);
    env.info.pendingResolutionPhase=currentResolutionContext.step=BASIC;
    Symbol sym=findMethod(env,syms.predefClass.type,name,argtypes,null,false,false,true);
    if (boxingEnabled && sym.kind >= WRONG_MTHS)     env.info.pendingResolutionPhase=currentResolutionContext.step=BOX;
    sym=findMethod(env,syms.predefClass.type,name,argtypes,null,true,false,true);
    return accessMethod(sym,pos,env.enclClass.sym.type,name,false,argtypes,null);
  }
  finally {
    currentResolutionContext=prevResolutionContext;
  }
}","/** 
 * Resolve operator.
 * @param pos       The position to use for error reporting.
 * @param optag     The tag of the operation tree.
 * @param env       The environment current at the operation.
 * @param argtypes  The types of the operands.
 */
Symbol resolveOperator(DiagnosticPosition pos,JCTree.Tag optag,Env<AttrContext> env,List<Type> argtypes){
  MethodResolutionContext prevResolutionContext=currentResolutionContext;
  try {
    currentResolutionContext=new MethodResolutionContext();
    Name name=treeinfo.operatorName(optag);
    return lookupMethod(env,pos,syms.predefClass,currentResolutionContext,new BasicLookupHelper(name,syms.predefClass.type,argtypes,null,BOX){
      @Override Symbol lookup(      Env<AttrContext> env,      MethodResolutionPhase phase){
        return findMethod(env,site,name,argtypes,typeargtypes,phase.isBoxingRequired(),phase.isVarargsRequired(),true);
      }
      @Override Symbol access(      Env<AttrContext> env,      DiagnosticPosition pos,      Symbol location,      Symbol sym){
        return accessMethod(sym,pos,env.enclClass.sym.type,name,false,argtypes,null);
      }
    }
);
  }
  finally {
    currentResolutionContext=prevResolutionContext;
  }
}"
37041,"String computeKey(Element e){
  StringBuilder buf=new StringBuilder();
  while (e != null) {
    buf.append(e.toString());
    e=e.getEnclosingElement();
  }
  buf.append(jfo.getName());
  return buf.toString();
}","String computeKey(Element e){
  StringBuilder buf=new StringBuilder();
  if (predefTranslationMap.containsKey(e.getSimpleName().toString())) {
    buf.append(""String_Node_Str"");
    String replacedName=predefTranslationMap.get(e.getSimpleName().toString());
    buf.append(e.toString().replace(e.getSimpleName().toString(),replacedName));
  }
 else   if (e.getSimpleName().toString().startsWith(""String_Node_Str"")) {
    buf.append(""String_Node_Str"");
    buf.append(e.toString());
  }
 else {
    while (e != null) {
      buf.append(e.toString());
      e=e.getEnclosingElement();
    }
    buf.append(jfo.getName());
  }
  return buf.toString();
}"
37042,"protected ResolveHarness(JavaFileObject jfo){
  this.jfo=jfo;
  this.diagProcessors=new DiagnosticProcessor[]{new VerboseResolutionNoteProcessor(),new VerboseDeferredInferenceNoteProcessor(),new ErrorProcessor()};
}","protected ResolveHarness(JavaFileObject jfo){
  this.jfo=jfo;
  this.diagProcessors=new DiagnosticProcessor[]{new VerboseResolutionNoteProcessor(),new VerboseDeferredInferenceNoteProcessor(),new ErrorProcessor()};
  predefTranslationMap.put(""String_Node_Str"",""String_Node_Str"");
  predefTranslationMap.put(""String_Node_Str"",""String_Node_Str"");
  predefTranslationMap.put(""String_Node_Str"",""String_Node_Str"");
  predefTranslationMap.put(""String_Node_Str"",""String_Node_Str"");
  predefTranslationMap.put(""String_Node_Str"",""String_Node_Str"");
  predefTranslationMap.put(""String_Node_Str"",""String_Node_Str"");
  predefTranslationMap.put(""String_Node_Str"",""String_Node_Str"");
  predefTranslationMap.put(""String_Node_Str"",""String_Node_Str"");
  predefTranslationMap.put(""String_Node_Str"",""String_Node_Str"");
  predefTranslationMap.put(""String_Node_Str"",""String_Node_Str"");
  predefTranslationMap.put(""String_Node_Str"",""String_Node_Str"");
  predefTranslationMap.put(""String_Node_Str"",""String_Node_Str"");
  predefTranslationMap.put(""String_Node_Str"",""String_Node_Str"");
  predefTranslationMap.put(""String_Node_Str"",""String_Node_Str"");
  predefTranslationMap.put(""String_Node_Str"",""String_Node_Str"");
  predefTranslationMap.put(""String_Node_Str"",""String_Node_Str"");
  predefTranslationMap.put(""String_Node_Str"",""String_Node_Str"");
  predefTranslationMap.put(""String_Node_Str"",""String_Node_Str"");
  predefTranslationMap.put(""String_Node_Str"",""String_Node_Str"");
  predefTranslationMap.put(""String_Node_Str"",""String_Node_Str"");
  predefTranslationMap.put(""String_Node_Str"",""String_Node_Str"");
  predefTranslationMap.put(""String_Node_Str"",""String_Node_Str"");
  predefTranslationMap.put(""String_Node_Str"",""String_Node_Str"");
  predefTranslationMap.put(""String_Node_Str"",""String_Node_Str"");
}"
37043,"BasicLookupHelper(Name name,Type site,List<Type> argtypes,List<Type> typeargtypes){
  super(name,site,argtypes,typeargtypes,MethodResolutionPhase.VARARITY);
}","BasicLookupHelper(Name name,Type site,List<Type> argtypes,List<Type> typeargtypes,MethodResolutionPhase maxPhase){
  super(name,site,argtypes,typeargtypes,maxPhase);
}"
37044,"/** 
 * Select the best method for a call site among two choices.
 * @param env              The current environment.
 * @param site             The original type from where theselection takes place.
 * @param argtypes         The invocation's value arguments,
 * @param typeargtypes     The invocation's type arguments,
 * @param sym              Proposed new best match.
 * @param bestSoFar        Previously found best match.
 * @param allowBoxing Allow boxing conversions of arguments.
 * @param useVarargs Box trailing arguments into an array for varargs.
 */
@SuppressWarnings(""String_Node_Str"") Symbol selectBest(Env<AttrContext> env,Type site,List<Type> argtypes,List<Type> typeargtypes,Symbol sym,Symbol bestSoFar,boolean allowBoxing,boolean useVarargs,boolean operator){
  if (sym.kind == ERR || !sym.isInheritedIn(site.tsym,types)) {
    return bestSoFar;
  }
 else   if (useVarargs && (sym.flags() & VARARGS) == 0) {
    return bestSoFar.kind >= ERRONEOUS ? new BadVarargsMethod((ResolveError)bestSoFar) : bestSoFar;
  }
  Assert.check(sym.kind < AMBIGUOUS);
  try {
    Type mt=rawInstantiate(env,site,sym,null,argtypes,typeargtypes,allowBoxing,useVarargs,types.noWarnings);
    if (!operator)     currentResolutionContext.addApplicableCandidate(sym,mt);
  }
 catch (  InapplicableMethodException ex) {
    if (!operator)     currentResolutionContext.addInapplicableCandidate(sym,ex.getDiagnostic());
switch (bestSoFar.kind) {
case ABSENT_MTH:
      return new InapplicableSymbolError(currentResolutionContext);
case WRONG_MTH:
    if (operator)     return bestSoFar;
  bestSoFar=new InapplicableSymbolsError(currentResolutionContext);
default :
return bestSoFar;
}
}
if (!isAccessible(env,site,sym)) {
return (bestSoFar.kind == ABSENT_MTH) ? new AccessError(env,site,sym) : bestSoFar;
}
return (bestSoFar.kind > AMBIGUOUS) ? sym : mostSpecific(argtypes,sym,bestSoFar,env,site,allowBoxing && operator,useVarargs);
}","/** 
 * Select the best method for a call site among two choices.
 * @param env              The current environment.
 * @param site             The original type from where theselection takes place.
 * @param argtypes         The invocation's value arguments,
 * @param typeargtypes     The invocation's type arguments,
 * @param sym              Proposed new best match.
 * @param bestSoFar        Previously found best match.
 * @param allowBoxing Allow boxing conversions of arguments.
 * @param useVarargs Box trailing arguments into an array for varargs.
 */
@SuppressWarnings(""String_Node_Str"") Symbol selectBest(Env<AttrContext> env,Type site,List<Type> argtypes,List<Type> typeargtypes,Symbol sym,Symbol bestSoFar,boolean allowBoxing,boolean useVarargs,boolean operator){
  if (sym.kind == ERR || !sym.isInheritedIn(site.tsym,types)) {
    return bestSoFar;
  }
 else   if (useVarargs && (sym.flags() & VARARGS) == 0) {
    return bestSoFar.kind >= ERRONEOUS ? new BadVarargsMethod((ResolveError)bestSoFar) : bestSoFar;
  }
  Assert.check(sym.kind < AMBIGUOUS);
  try {
    Type mt=rawInstantiate(env,site,sym,null,argtypes,typeargtypes,allowBoxing,useVarargs,types.noWarnings);
    if (!operator || verboseResolutionMode.contains(VerboseResolutionMode.PREDEF))     currentResolutionContext.addApplicableCandidate(sym,mt);
  }
 catch (  InapplicableMethodException ex) {
    if (!operator)     currentResolutionContext.addInapplicableCandidate(sym,ex.getDiagnostic());
switch (bestSoFar.kind) {
case ABSENT_MTH:
      return new InapplicableSymbolError(currentResolutionContext);
case WRONG_MTH:
    if (operator)     return bestSoFar;
  bestSoFar=new InapplicableSymbolsError(currentResolutionContext);
default :
return bestSoFar;
}
}
if (!isAccessible(env,site,sym)) {
return (bestSoFar.kind == ABSENT_MTH) ? new AccessError(env,site,sym) : bestSoFar;
}
return (bestSoFar.kind > AMBIGUOUS) ? sym : mostSpecific(argtypes,sym,bestSoFar,env,site,allowBoxing && operator,useVarargs);
}"
37045,"/** 
 * Resolve operator.
 * @param pos       The position to use for error reporting.
 * @param optag     The tag of the operation tree.
 * @param env       The environment current at the operation.
 * @param argtypes  The types of the operands.
 */
Symbol resolveOperator(DiagnosticPosition pos,JCTree.Tag optag,Env<AttrContext> env,List<Type> argtypes){
  MethodResolutionContext prevResolutionContext=currentResolutionContext;
  try {
    currentResolutionContext=new MethodResolutionContext();
    Name name=treeinfo.operatorName(optag);
    env.info.pendingResolutionPhase=currentResolutionContext.step=BASIC;
    Symbol sym=findMethod(env,syms.predefClass.type,name,argtypes,null,false,false,true);
    if (boxingEnabled && sym.kind >= WRONG_MTHS)     env.info.pendingResolutionPhase=currentResolutionContext.step=BOX;
    sym=findMethod(env,syms.predefClass.type,name,argtypes,null,true,false,true);
    return accessMethod(sym,pos,env.enclClass.sym.type,name,false,argtypes,null);
  }
  finally {
    currentResolutionContext=prevResolutionContext;
  }
}","/** 
 * Resolve operator.
 * @param pos       The position to use for error reporting.
 * @param optag     The tag of the operation tree.
 * @param env       The environment current at the operation.
 * @param argtypes  The types of the operands.
 */
Symbol resolveOperator(DiagnosticPosition pos,JCTree.Tag optag,Env<AttrContext> env,List<Type> argtypes){
  MethodResolutionContext prevResolutionContext=currentResolutionContext;
  try {
    currentResolutionContext=new MethodResolutionContext();
    Name name=treeinfo.operatorName(optag);
    return lookupMethod(env,pos,syms.predefClass,currentResolutionContext,new BasicLookupHelper(name,syms.predefClass.type,argtypes,null,BOX){
      @Override Symbol lookup(      Env<AttrContext> env,      MethodResolutionPhase phase){
        return findMethod(env,site,name,argtypes,typeargtypes,phase.isBoxingRequired(),phase.isVarargsRequired(),true);
      }
      @Override Symbol access(      Env<AttrContext> env,      DiagnosticPosition pos,      Symbol location,      Symbol sym){
        return accessMethod(sym,pos,env.enclClass.sym.type,name,false,argtypes,null);
      }
    }
);
  }
  finally {
    currentResolutionContext=prevResolutionContext;
  }
}"
37046,"/** 
 * Convenience method equivalent to   {@code v.scan(e, null)}.
 * @return the result of scanning {@code e}.
 */
public final R scan(Element e){
  return scan(e,null);
}","/** 
 * Convenience method equivalent to   {@code v.scan(e, null)}.
 * @param e the element to scan
 * @return the result of scanning {@code e}.
 */
public final R scan(Element e){
  return scan(e,null);
}"
37047,"/** 
 * Return a name with the same sequence of characters as the argument.
 * @param cs the character sequence to return as a name
 */
Name getName(CharSequence cs);","/** 
 * Return a name with the same sequence of characters as the argument.
 * @param cs the character sequence to return as a name
 * @return a name with the same sequence of characters as the argument
 */
Name getName(CharSequence cs);"
37048,"/** 
 * Returns the element corresponding to a type. The type may be a   {@code DeclaredType} or {@code TypeVariable}. Returns   {@code null} if the type is not one with acorresponding element.
 * @return the element corresponding to the given type
 */
Element asElement(TypeMirror t);","/** 
 * Returns the element corresponding to a type. The type may be a   {@code DeclaredType} or {@code TypeVariable}. Returns   {@code null} if the type is not one with acorresponding element.
 * @param t the type to map to an element
 * @return the element corresponding to the given type
 */
Element asElement(TypeMirror t);"
37049,"/** 
 * Convenience method equivalent to   {@code v.scan(e, null)}.
 * @return the result of scanning {@code e}.
 */
public final R scan(Element e){
  return scan(e,null);
}","/** 
 * Convenience method equivalent to   {@code v.scan(e, null)}.
 * @param e the element to scan
 * @return the result of scanning {@code e}.
 */
public final R scan(Element e){
  return scan(e,null);
}"
37050,"/** 
 * Return a name with the same sequence of characters as the argument.
 * @param cs the character sequence to return as a name
 */
Name getName(CharSequence cs);","/** 
 * Return a name with the same sequence of characters as the argument.
 * @param cs the character sequence to return as a name
 * @return a name with the same sequence of characters as the argument
 */
Name getName(CharSequence cs);"
37051,"/** 
 * Returns the element corresponding to a type. The type may be a   {@code DeclaredType} or {@code TypeVariable}. Returns   {@code null} if the type is not one with acorresponding element.
 * @return the element corresponding to the given type
 */
Element asElement(TypeMirror t);","/** 
 * Returns the element corresponding to a type. The type may be a   {@code DeclaredType} or {@code TypeVariable}. Returns   {@code null} if the type is not one with acorresponding element.
 * @param t the type to map to an element
 * @return the element corresponding to the given type
 */
Element asElement(TypeMirror t);"
37052,"private static List<Archive> init(){
  List<Archive> result=new ArrayList<Archive>();
  String javaHome=System.getProperty(""String_Node_Str"");
  List<File> files=new ArrayList<File>();
  File jre=new File(javaHome,""String_Node_Str"");
  File lib=new File(javaHome,""String_Node_Str"");
  try {
    if (jre.exists() && jre.isDirectory()) {
      result.addAll(addJarFiles(new File(jre,""String_Node_Str"")));
      result.addAll(addJarFiles(lib));
    }
 else     if (lib.exists() && lib.isDirectory()) {
      File classes=new File(javaHome,""String_Node_Str"");
      if (classes.exists() && classes.isDirectory()) {
        result.add(new Archive(classes,ClassFileReader.newInstance(classes)));
      }
      result.addAll(addJarFiles(lib));
    }
 else {
      throw new RuntimeException(""String_Node_Str"" + javaHome + ""String_Node_Str"");
    }
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
  return result;
}","private static List<Archive> init(){
  List<Archive> result=new ArrayList<Archive>();
  String javaHome=System.getProperty(""String_Node_Str"");
  File jre=new File(javaHome,""String_Node_Str"");
  File lib=new File(javaHome,""String_Node_Str"");
  try {
    if (jre.exists() && jre.isDirectory()) {
      result.addAll(addJarFiles(new File(jre,""String_Node_Str"")));
      result.addAll(addJarFiles(lib));
    }
 else     if (lib.exists() && lib.isDirectory()) {
      File classes=new File(javaHome,""String_Node_Str"");
      if (classes.exists() && classes.isDirectory()) {
        result.add(new Archive(classes,ClassFileReader.newInstance(classes)));
      }
      result.addAll(addJarFiles(lib));
    }
 else {
      throw new RuntimeException(""String_Node_Str"" + javaHome + ""String_Node_Str"");
    }
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
  return result;
}"
37053,"/** 
 * Scan the arguments for -i -x -xf -if followed by the option -src, -sourcepath, -modulepath or -classpath and produce a map of all the files to referenced for that particular option. Store the found sources and the found modules in the supplied maps.
 */
private boolean findFiles(String[] args,String option,Set<String> suffixes,Map<String,Source> found_files,Map<String,Module> found_modules,Module current_module,boolean inLinksrc) throws ProblemException, ProblemException {
  Set<File> roots=new HashSet<File>();
  List<String> includes=new LinkedList<String>();
  List<String> excludes=new LinkedList<String>();
  List<String> excludefiles=new LinkedList<String>();
  List<String> includefiles=new LinkedList<String>();
  List<String> moduleinfo=new LinkedList<String>();
  moduleinfo.add(""String_Node_Str"");
  for (int i=0; i < args.length; ++i) {
    if (args[i].equals(""String_Node_Str"")) {
      if (i + 1 >= args.length) {
        throw new ProblemException(""String_Node_Str"");
      }
      String incl=args[i + 1];
      checkPattern(incl);
      includes.add(incl);
    }
    if (args[i].equals(""String_Node_Str"")) {
      if (i + 1 >= args.length) {
        throw new ProblemException(""String_Node_Str"");
      }
      String excl=args[i + 1];
      checkPattern(excl);
      excludes.add(excl);
    }
    if (args[i].equals(""String_Node_Str"")) {
      if (i + 1 >= args.length) {
        throw new ProblemException(""String_Node_Str"");
      }
      String exclf=args[i + 1];
      checkFilePattern(exclf);
      exclf=Util.normalizeDriveLetter(exclf);
      excludefiles.add(fixupSeparator(exclf));
    }
    if (args[i].equals(""String_Node_Str"")) {
      if (i + 1 >= args.length) {
        throw new ProblemException(""String_Node_Str"");
      }
      String inclf=args[i + 1];
      checkFilePattern(inclf);
      inclf=Util.normalizeDriveLetter(inclf);
      includefiles.add(fixupSeparator(inclf));
    }
    if (args[i].equals(option)) {
      if (i + 1 >= args.length) {
        throw new ProblemException(""String_Node_Str"" + option);
      }
      String[] root_dirs=args[i + 1].split(File.pathSeparator);
      for (      String r : root_dirs) {
        File root=new File(r);
        if (!root.isDirectory()) {
          throw new ProblemException(""String_Node_Str"" + r + ""String_Node_Str"");
        }
        try {
          root=root.getCanonicalFile();
        }
 catch (        IOException e) {
          throw new ProblemException(""String_Node_Str"" + e);
        }
        if (roots.contains(root)) {
          throw new ProblemException(""String_Node_Str"" + r + ""String_Node_Str""+ option);
        }
        if (roots.equals(bin_dir)) {
          throw new ProblemException(""String_Node_Str"" + r + ""String_Node_Str""+ option+ ""String_Node_Str"");
        }
        if (roots.equals(gensrc_dir)) {
          throw new ProblemException(""String_Node_Str"" + r + ""String_Node_Str""+ option+ ""String_Node_Str"");
        }
        if (roots.equals(header_dir)) {
          throw new ProblemException(""String_Node_Str"" + r + ""String_Node_Str""+ option+ ""String_Node_Str"");
        }
        roots.add(root);
        Source.scanRoot(root,suffixes,excludes,includes,excludefiles,includefiles,found_files,found_modules,current_module,findBooleanOption(args,""String_Node_Str""),false,inLinksrc);
      }
    }
    if (args[i].equals(""String_Node_Str"") || args[i].equals(""String_Node_Str"") || args[i].equals(""String_Node_Str"")|| args[i].equals(""String_Node_Str"")|| args[i].equals(""String_Node_Str"")) {
      includes=new LinkedList<String>();
      excludes=new LinkedList<String>();
      excludefiles=new LinkedList<String>();
      includefiles=new LinkedList<String>();
    }
  }
  return true;
}","/** 
 * Scan the arguments for -i -x -xf -if followed by the option -src, -sourcepath, -modulepath or -classpath and produce a map of all the files to referenced for that particular option. Store the found sources and the found modules in the supplied maps.
 */
private boolean findFiles(String[] args,String option,Set<String> suffixes,Map<String,Source> found_files,Map<String,Module> found_modules,Module current_module,boolean inLinksrc) throws ProblemException, ProblemException {
  Set<File> roots=new HashSet<File>();
  List<String> includes=new LinkedList<String>();
  List<String> excludes=new LinkedList<String>();
  List<String> excludefiles=new LinkedList<String>();
  List<String> includefiles=new LinkedList<String>();
  List<String> moduleinfo=new LinkedList<String>();
  moduleinfo.add(""String_Node_Str"");
  for (int i=0; i < args.length; ++i) {
    if (args[i].equals(""String_Node_Str"")) {
      if (i + 1 >= args.length) {
        throw new ProblemException(""String_Node_Str"");
      }
      String incl=args[i + 1];
      checkPattern(incl);
      includes.add(incl);
    }
    if (args[i].equals(""String_Node_Str"")) {
      if (i + 1 >= args.length) {
        throw new ProblemException(""String_Node_Str"");
      }
      String excl=args[i + 1];
      checkPattern(excl);
      excludes.add(excl);
    }
    if (args[i].equals(""String_Node_Str"")) {
      if (i + 1 >= args.length) {
        throw new ProblemException(""String_Node_Str"");
      }
      String exclf=args[i + 1];
      checkFilePattern(exclf);
      exclf=Util.normalizeDriveLetter(exclf);
      excludefiles.add(fixupSeparator(exclf));
    }
    if (args[i].equals(""String_Node_Str"")) {
      if (i + 1 >= args.length) {
        throw new ProblemException(""String_Node_Str"");
      }
      String inclf=args[i + 1];
      checkFilePattern(inclf);
      inclf=Util.normalizeDriveLetter(inclf);
      includefiles.add(fixupSeparator(inclf));
    }
    if (args[i].equals(option)) {
      if (i + 1 >= args.length) {
        throw new ProblemException(""String_Node_Str"" + option);
      }
      String[] root_dirs=args[i + 1].split(File.pathSeparator);
      for (      String r : root_dirs) {
        File root=new File(r);
        if (!root.isDirectory()) {
          throw new ProblemException(""String_Node_Str"" + r + ""String_Node_Str"");
        }
        try {
          root=root.getCanonicalFile();
        }
 catch (        IOException e) {
          throw new ProblemException(""String_Node_Str"" + e);
        }
        if (roots.contains(root)) {
          throw new ProblemException(""String_Node_Str"" + r + ""String_Node_Str""+ option);
        }
        if (root.equals(bin_dir)) {
          throw new ProblemException(""String_Node_Str"" + r + ""String_Node_Str""+ option+ ""String_Node_Str"");
        }
        if (root.equals(gensrc_dir)) {
          throw new ProblemException(""String_Node_Str"" + r + ""String_Node_Str""+ option+ ""String_Node_Str"");
        }
        if (root.equals(header_dir)) {
          throw new ProblemException(""String_Node_Str"" + r + ""String_Node_Str""+ option+ ""String_Node_Str"");
        }
        roots.add(root);
        Source.scanRoot(root,suffixes,excludes,includes,excludefiles,includefiles,found_files,found_modules,current_module,findBooleanOption(args,""String_Node_Str""),false,inLinksrc);
      }
    }
    if (args[i].equals(""String_Node_Str"") || args[i].equals(""String_Node_Str"") || args[i].equals(""String_Node_Str"")|| args[i].equals(""String_Node_Str"")|| args[i].equals(""String_Node_Str"")) {
      includes=new LinkedList<String>();
      excludes=new LinkedList<String>();
      excludefiles=new LinkedList<String>();
      includefiles=new LinkedList<String>();
    }
  }
  return true;
}"
37054,"public int go(String[] args,PrintStream out,PrintStream err){
  try {
    if (args.length == 0 || findJavaSourceFiles(args) || findAtFile(args) || null == Util.findServerSettings(args)) {
      printHelp();
      return 0;
    }
    Log.setLogLevel(findLogLevel(args),out,err);
    String server_settings=Util.findServerSettings(args);
    args=verifyImplicitOption(args);
    args=addSrcBeforeDirectories(args);
    checkSrcOption(args);
    bin_dir=findDirectoryOption(args,""String_Node_Str"",""String_Node_Str"",true,false,true);
    gensrc_dir=findDirectoryOption(args,""String_Node_Str"",""String_Node_Str"",false,false,true);
    header_dir=findDirectoryOption(args,""String_Node_Str"",""String_Node_Str"",false,false,true);
    makefile_source_list=findFileOption(args,""String_Node_Str"",""String_Node_Str"",false);
    javac_state=JavacState.load(args,bin_dir,gensrc_dir,header_dir,findBooleanOption(args,""String_Node_Str""),out,err);
    suffix_rules=javac_state.getJavaSuffixRule();
    findTranslateOptions(args,suffix_rules);
    if (suffix_rules.keySet().size() > 1 && gensrc_dir == null) {
      Log.error(""String_Node_Str"");
      return -1;
    }
    findCopyOptions(args,suffix_rules);
    Map<String,Module> modules=new HashMap<String,Module>();
    Module current_module=new Module(""String_Node_Str"",""String_Node_Str"");
    modules.put(""String_Node_Str"",current_module);
    Map<String,Source> sources=new HashMap<String,Source>();
    findFiles(args,""String_Node_Str"",suffix_rules.keySet(),sources,modules,current_module,false);
    if (sources.isEmpty()) {
      Log.error(""String_Node_Str"");
      return -1;
    }
    Map<String,Source> sources_to_link_to=new HashMap<String,Source>();
    rewriteOptions(args,""String_Node_Str"",""String_Node_Str"");
    findFiles(args,""String_Node_Str"",Util.set(""String_Node_Str""),sources_to_link_to,modules,current_module,true);
    Map<String,Source> classes_to_link_to=new HashMap<String,Source>();
    Map<String,Source> modules_to_link_to=new HashMap<String,Source>();
    javac_state.now().collectPackagesSourcesAndArtifacts(modules);
    javac_state.now().checkInternalState(""String_Node_Str"",false,sources);
    javac_state.now().checkInternalState(""String_Node_Str"",true,sources_to_link_to);
    javac_state.setVisibleSources(sources_to_link_to);
    javac_state.checkSourceStatus(false);
    javac_state.findAllArtifacts();
    if (!findBooleanOption(args,""String_Node_Str"")) {
      javac_state.removeUnidentifiedArtifacts();
    }
    javac_state.taintPackagesThatMissArtifacts();
    javac_state.deleteClassArtifactsInTaintedPackages();
    javac_state.performCopying(bin_dir,suffix_rules);
    javac_state.performTranslation(gensrc_dir,suffix_rules);
    Map<String,Source> generated_sources=new HashMap<String,Source>();
    Source.scanRoot(gensrc_dir,Util.set(""String_Node_Str""),null,null,null,null,generated_sources,modules,current_module,false,true,false);
    javac_state.now().collectPackagesSourcesAndArtifacts(modules);
    javac_state.checkSourceStatus(true);
    javac_state.compareWithMakefileList(makefile_source_list);
    boolean again;
    Set<String> recently_compiled=new HashSet<String>();
    boolean[] rc=new boolean[1];
    do {
      javac_state.deleteClassArtifactsInTaintedPackages();
      again=javac_state.performJavaCompilations(bin_dir,server_settings,args,recently_compiled,rc);
      if (!rc[0])       break;
    }
 while (again);
    if (rc[0]) {
      javac_state.save();
      javac_state.now().collectArtifacts(modules);
      javac_state.removeSuperfluousArtifacts(recently_compiled);
    }
    return rc[0] ? 0 : -1;
  }
 catch (  ProblemException e) {
    Log.error(e.getMessage());
    return -1;
  }
catch (  Exception e) {
    e.printStackTrace(err);
    return -1;
  }
}","public int go(String[] args,PrintStream out,PrintStream err){
  try {
    if (args.length == 0 || findJavaSourceFiles(args) || findAtFile(args) || null == Util.findServerSettings(args)) {
      printHelp();
      return 0;
    }
    Log.setLogLevel(findLogLevel(args),out,err);
    String server_settings=Util.findServerSettings(args);
    args=verifyImplicitOption(args);
    args=addSrcBeforeDirectories(args);
    checkSrcOption(args);
    bin_dir=findDirectoryOption(args,""String_Node_Str"",""String_Node_Str"",true,false,true);
    gensrc_dir=findDirectoryOption(args,""String_Node_Str"",""String_Node_Str"",false,false,true);
    header_dir=findDirectoryOption(args,""String_Node_Str"",""String_Node_Str"",false,false,true);
    makefile_source_list=findFileOption(args,""String_Node_Str"",""String_Node_Str"",false);
    javac_state=JavacState.load(args,bin_dir,gensrc_dir,header_dir,findBooleanOption(args,""String_Node_Str""),out,err);
    suffix_rules=javac_state.getJavaSuffixRule();
    findTranslateOptions(args,suffix_rules);
    if (suffix_rules.keySet().size() > 1 && gensrc_dir == null) {
      Log.error(""String_Node_Str"");
      return -1;
    }
    findCopyOptions(args,suffix_rules);
    Map<String,Module> modules=new HashMap<String,Module>();
    Module current_module=new Module(""String_Node_Str"",""String_Node_Str"");
    modules.put(""String_Node_Str"",current_module);
    Map<String,Source> sources=new HashMap<String,Source>();
    findFiles(args,""String_Node_Str"",suffix_rules.keySet(),sources,modules,current_module,false);
    if (sources.isEmpty()) {
      Log.error(""String_Node_Str"");
      return -1;
    }
    Map<String,Source> sources_to_link_to=new HashMap<String,Source>();
    rewriteOptions(args,""String_Node_Str"",""String_Node_Str"");
    findFiles(args,""String_Node_Str"",Util.set(""String_Node_Str""),sources_to_link_to,modules,current_module,true);
    javac_state.now().collectPackagesSourcesAndArtifacts(modules);
    javac_state.now().checkInternalState(""String_Node_Str"",false,sources);
    javac_state.now().checkInternalState(""String_Node_Str"",true,sources_to_link_to);
    javac_state.setVisibleSources(sources_to_link_to);
    javac_state.checkSourceStatus(false);
    javac_state.findAllArtifacts();
    if (!findBooleanOption(args,""String_Node_Str"")) {
      javac_state.removeUnidentifiedArtifacts();
    }
    javac_state.taintPackagesThatMissArtifacts();
    javac_state.deleteClassArtifactsInTaintedPackages();
    javac_state.performCopying(bin_dir,suffix_rules);
    javac_state.performTranslation(gensrc_dir,suffix_rules);
    Map<String,Source> generated_sources=new HashMap<String,Source>();
    Source.scanRoot(gensrc_dir,Util.set(""String_Node_Str""),null,null,null,null,generated_sources,modules,current_module,false,true,false);
    javac_state.now().collectPackagesSourcesAndArtifacts(modules);
    javac_state.checkSourceStatus(true);
    javac_state.compareWithMakefileList(makefile_source_list);
    boolean again;
    Set<String> recently_compiled=new HashSet<String>();
    boolean[] rc=new boolean[1];
    do {
      javac_state.deleteClassArtifactsInTaintedPackages();
      again=javac_state.performJavaCompilations(bin_dir,server_settings,args,recently_compiled,rc);
      if (!rc[0])       break;
    }
 while (again);
    if (rc[0]) {
      javac_state.save();
      javac_state.now().collectArtifacts(modules);
      javac_state.removeSuperfluousArtifacts(recently_compiled);
    }
    return rc[0] ? 0 : -1;
  }
 catch (  ProblemException e) {
    Log.error(e.getMessage());
    return -1;
  }
catch (  Exception e) {
    e.printStackTrace(err);
    return -1;
  }
}"
37055,"private static List<Archive> init(){
  List<Archive> result=new ArrayList<Archive>();
  String javaHome=System.getProperty(""String_Node_Str"");
  List<File> files=new ArrayList<File>();
  File jre=new File(javaHome,""String_Node_Str"");
  File lib=new File(javaHome,""String_Node_Str"");
  try {
    if (jre.exists() && jre.isDirectory()) {
      result.addAll(addJarFiles(new File(jre,""String_Node_Str"")));
      result.addAll(addJarFiles(lib));
    }
 else     if (lib.exists() && lib.isDirectory()) {
      File classes=new File(javaHome,""String_Node_Str"");
      if (classes.exists() && classes.isDirectory()) {
        result.add(new Archive(classes,ClassFileReader.newInstance(classes)));
      }
      result.addAll(addJarFiles(lib));
    }
 else {
      throw new RuntimeException(""String_Node_Str"" + javaHome + ""String_Node_Str"");
    }
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
  return result;
}","private static List<Archive> init(){
  List<Archive> result=new ArrayList<Archive>();
  String javaHome=System.getProperty(""String_Node_Str"");
  File jre=new File(javaHome,""String_Node_Str"");
  File lib=new File(javaHome,""String_Node_Str"");
  try {
    if (jre.exists() && jre.isDirectory()) {
      result.addAll(addJarFiles(new File(jre,""String_Node_Str"")));
      result.addAll(addJarFiles(lib));
    }
 else     if (lib.exists() && lib.isDirectory()) {
      File classes=new File(javaHome,""String_Node_Str"");
      if (classes.exists() && classes.isDirectory()) {
        result.add(new Archive(classes,ClassFileReader.newInstance(classes)));
      }
      result.addAll(addJarFiles(lib));
    }
 else {
      throw new RuntimeException(""String_Node_Str"" + javaHome + ""String_Node_Str"");
    }
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
  return result;
}"
37056,"/** 
 * Scan the arguments for -i -x -xf -if followed by the option -src, -sourcepath, -modulepath or -classpath and produce a map of all the files to referenced for that particular option. Store the found sources and the found modules in the supplied maps.
 */
private boolean findFiles(String[] args,String option,Set<String> suffixes,Map<String,Source> found_files,Map<String,Module> found_modules,Module current_module,boolean inLinksrc) throws ProblemException, ProblemException {
  Set<File> roots=new HashSet<File>();
  List<String> includes=new LinkedList<String>();
  List<String> excludes=new LinkedList<String>();
  List<String> excludefiles=new LinkedList<String>();
  List<String> includefiles=new LinkedList<String>();
  List<String> moduleinfo=new LinkedList<String>();
  moduleinfo.add(""String_Node_Str"");
  for (int i=0; i < args.length; ++i) {
    if (args[i].equals(""String_Node_Str"")) {
      if (i + 1 >= args.length) {
        throw new ProblemException(""String_Node_Str"");
      }
      String incl=args[i + 1];
      checkPattern(incl);
      includes.add(incl);
    }
    if (args[i].equals(""String_Node_Str"")) {
      if (i + 1 >= args.length) {
        throw new ProblemException(""String_Node_Str"");
      }
      String excl=args[i + 1];
      checkPattern(excl);
      excludes.add(excl);
    }
    if (args[i].equals(""String_Node_Str"")) {
      if (i + 1 >= args.length) {
        throw new ProblemException(""String_Node_Str"");
      }
      String exclf=args[i + 1];
      checkFilePattern(exclf);
      exclf=Util.normalizeDriveLetter(exclf);
      excludefiles.add(fixupSeparator(exclf));
    }
    if (args[i].equals(""String_Node_Str"")) {
      if (i + 1 >= args.length) {
        throw new ProblemException(""String_Node_Str"");
      }
      String inclf=args[i + 1];
      checkFilePattern(inclf);
      inclf=Util.normalizeDriveLetter(inclf);
      includefiles.add(fixupSeparator(inclf));
    }
    if (args[i].equals(option)) {
      if (i + 1 >= args.length) {
        throw new ProblemException(""String_Node_Str"" + option);
      }
      String[] root_dirs=args[i + 1].split(File.pathSeparator);
      for (      String r : root_dirs) {
        File root=new File(r);
        if (!root.isDirectory()) {
          throw new ProblemException(""String_Node_Str"" + r + ""String_Node_Str"");
        }
        try {
          root=root.getCanonicalFile();
        }
 catch (        IOException e) {
          throw new ProblemException(""String_Node_Str"" + e);
        }
        if (roots.contains(root)) {
          throw new ProblemException(""String_Node_Str"" + r + ""String_Node_Str""+ option);
        }
        if (roots.equals(bin_dir)) {
          throw new ProblemException(""String_Node_Str"" + r + ""String_Node_Str""+ option+ ""String_Node_Str"");
        }
        if (roots.equals(gensrc_dir)) {
          throw new ProblemException(""String_Node_Str"" + r + ""String_Node_Str""+ option+ ""String_Node_Str"");
        }
        if (roots.equals(header_dir)) {
          throw new ProblemException(""String_Node_Str"" + r + ""String_Node_Str""+ option+ ""String_Node_Str"");
        }
        roots.add(root);
        Source.scanRoot(root,suffixes,excludes,includes,excludefiles,includefiles,found_files,found_modules,current_module,findBooleanOption(args,""String_Node_Str""),false,inLinksrc);
      }
    }
    if (args[i].equals(""String_Node_Str"") || args[i].equals(""String_Node_Str"") || args[i].equals(""String_Node_Str"")|| args[i].equals(""String_Node_Str"")|| args[i].equals(""String_Node_Str"")) {
      includes=new LinkedList<String>();
      excludes=new LinkedList<String>();
      excludefiles=new LinkedList<String>();
      includefiles=new LinkedList<String>();
    }
  }
  return true;
}","/** 
 * Scan the arguments for -i -x -xf -if followed by the option -src, -sourcepath, -modulepath or -classpath and produce a map of all the files to referenced for that particular option. Store the found sources and the found modules in the supplied maps.
 */
private boolean findFiles(String[] args,String option,Set<String> suffixes,Map<String,Source> found_files,Map<String,Module> found_modules,Module current_module,boolean inLinksrc) throws ProblemException, ProblemException {
  Set<File> roots=new HashSet<File>();
  List<String> includes=new LinkedList<String>();
  List<String> excludes=new LinkedList<String>();
  List<String> excludefiles=new LinkedList<String>();
  List<String> includefiles=new LinkedList<String>();
  List<String> moduleinfo=new LinkedList<String>();
  moduleinfo.add(""String_Node_Str"");
  for (int i=0; i < args.length; ++i) {
    if (args[i].equals(""String_Node_Str"")) {
      if (i + 1 >= args.length) {
        throw new ProblemException(""String_Node_Str"");
      }
      String incl=args[i + 1];
      checkPattern(incl);
      includes.add(incl);
    }
    if (args[i].equals(""String_Node_Str"")) {
      if (i + 1 >= args.length) {
        throw new ProblemException(""String_Node_Str"");
      }
      String excl=args[i + 1];
      checkPattern(excl);
      excludes.add(excl);
    }
    if (args[i].equals(""String_Node_Str"")) {
      if (i + 1 >= args.length) {
        throw new ProblemException(""String_Node_Str"");
      }
      String exclf=args[i + 1];
      checkFilePattern(exclf);
      exclf=Util.normalizeDriveLetter(exclf);
      excludefiles.add(fixupSeparator(exclf));
    }
    if (args[i].equals(""String_Node_Str"")) {
      if (i + 1 >= args.length) {
        throw new ProblemException(""String_Node_Str"");
      }
      String inclf=args[i + 1];
      checkFilePattern(inclf);
      inclf=Util.normalizeDriveLetter(inclf);
      includefiles.add(fixupSeparator(inclf));
    }
    if (args[i].equals(option)) {
      if (i + 1 >= args.length) {
        throw new ProblemException(""String_Node_Str"" + option);
      }
      String[] root_dirs=args[i + 1].split(File.pathSeparator);
      for (      String r : root_dirs) {
        File root=new File(r);
        if (!root.isDirectory()) {
          throw new ProblemException(""String_Node_Str"" + r + ""String_Node_Str"");
        }
        try {
          root=root.getCanonicalFile();
        }
 catch (        IOException e) {
          throw new ProblemException(""String_Node_Str"" + e);
        }
        if (roots.contains(root)) {
          throw new ProblemException(""String_Node_Str"" + r + ""String_Node_Str""+ option);
        }
        if (root.equals(bin_dir)) {
          throw new ProblemException(""String_Node_Str"" + r + ""String_Node_Str""+ option+ ""String_Node_Str"");
        }
        if (root.equals(gensrc_dir)) {
          throw new ProblemException(""String_Node_Str"" + r + ""String_Node_Str""+ option+ ""String_Node_Str"");
        }
        if (root.equals(header_dir)) {
          throw new ProblemException(""String_Node_Str"" + r + ""String_Node_Str""+ option+ ""String_Node_Str"");
        }
        roots.add(root);
        Source.scanRoot(root,suffixes,excludes,includes,excludefiles,includefiles,found_files,found_modules,current_module,findBooleanOption(args,""String_Node_Str""),false,inLinksrc);
      }
    }
    if (args[i].equals(""String_Node_Str"") || args[i].equals(""String_Node_Str"") || args[i].equals(""String_Node_Str"")|| args[i].equals(""String_Node_Str"")|| args[i].equals(""String_Node_Str"")) {
      includes=new LinkedList<String>();
      excludes=new LinkedList<String>();
      excludefiles=new LinkedList<String>();
      includefiles=new LinkedList<String>();
    }
  }
  return true;
}"
37057,"public int go(String[] args,PrintStream out,PrintStream err){
  try {
    if (args.length == 0 || findJavaSourceFiles(args) || findAtFile(args) || null == Util.findServerSettings(args)) {
      printHelp();
      return 0;
    }
    Log.setLogLevel(findLogLevel(args),out,err);
    String server_settings=Util.findServerSettings(args);
    args=verifyImplicitOption(args);
    args=addSrcBeforeDirectories(args);
    checkSrcOption(args);
    bin_dir=findDirectoryOption(args,""String_Node_Str"",""String_Node_Str"",true,false,true);
    gensrc_dir=findDirectoryOption(args,""String_Node_Str"",""String_Node_Str"",false,false,true);
    header_dir=findDirectoryOption(args,""String_Node_Str"",""String_Node_Str"",false,false,true);
    makefile_source_list=findFileOption(args,""String_Node_Str"",""String_Node_Str"",false);
    javac_state=JavacState.load(args,bin_dir,gensrc_dir,header_dir,findBooleanOption(args,""String_Node_Str""),out,err);
    suffix_rules=javac_state.getJavaSuffixRule();
    findTranslateOptions(args,suffix_rules);
    if (suffix_rules.keySet().size() > 1 && gensrc_dir == null) {
      Log.error(""String_Node_Str"");
      return -1;
    }
    findCopyOptions(args,suffix_rules);
    Map<String,Module> modules=new HashMap<String,Module>();
    Module current_module=new Module(""String_Node_Str"",""String_Node_Str"");
    modules.put(""String_Node_Str"",current_module);
    Map<String,Source> sources=new HashMap<String,Source>();
    findFiles(args,""String_Node_Str"",suffix_rules.keySet(),sources,modules,current_module,false);
    if (sources.isEmpty()) {
      Log.error(""String_Node_Str"");
      return -1;
    }
    Map<String,Source> sources_to_link_to=new HashMap<String,Source>();
    rewriteOptions(args,""String_Node_Str"",""String_Node_Str"");
    findFiles(args,""String_Node_Str"",Util.set(""String_Node_Str""),sources_to_link_to,modules,current_module,true);
    Map<String,Source> classes_to_link_to=new HashMap<String,Source>();
    Map<String,Source> modules_to_link_to=new HashMap<String,Source>();
    javac_state.now().collectPackagesSourcesAndArtifacts(modules);
    javac_state.now().checkInternalState(""String_Node_Str"",false,sources);
    javac_state.now().checkInternalState(""String_Node_Str"",true,sources_to_link_to);
    javac_state.setVisibleSources(sources_to_link_to);
    javac_state.checkSourceStatus(false);
    javac_state.findAllArtifacts();
    if (!findBooleanOption(args,""String_Node_Str"")) {
      javac_state.removeUnidentifiedArtifacts();
    }
    javac_state.taintPackagesThatMissArtifacts();
    javac_state.deleteClassArtifactsInTaintedPackages();
    javac_state.performCopying(bin_dir,suffix_rules);
    javac_state.performTranslation(gensrc_dir,suffix_rules);
    Map<String,Source> generated_sources=new HashMap<String,Source>();
    Source.scanRoot(gensrc_dir,Util.set(""String_Node_Str""),null,null,null,null,generated_sources,modules,current_module,false,true,false);
    javac_state.now().collectPackagesSourcesAndArtifacts(modules);
    javac_state.checkSourceStatus(true);
    javac_state.compareWithMakefileList(makefile_source_list);
    boolean again;
    Set<String> recently_compiled=new HashSet<String>();
    boolean[] rc=new boolean[1];
    do {
      javac_state.deleteClassArtifactsInTaintedPackages();
      again=javac_state.performJavaCompilations(bin_dir,server_settings,args,recently_compiled,rc);
      if (!rc[0])       break;
    }
 while (again);
    if (rc[0]) {
      javac_state.save();
      javac_state.now().collectArtifacts(modules);
      javac_state.removeSuperfluousArtifacts(recently_compiled);
    }
    return rc[0] ? 0 : -1;
  }
 catch (  ProblemException e) {
    Log.error(e.getMessage());
    return -1;
  }
catch (  Exception e) {
    e.printStackTrace(err);
    return -1;
  }
}","public int go(String[] args,PrintStream out,PrintStream err){
  try {
    if (args.length == 0 || findJavaSourceFiles(args) || findAtFile(args) || null == Util.findServerSettings(args)) {
      printHelp();
      return 0;
    }
    Log.setLogLevel(findLogLevel(args),out,err);
    String server_settings=Util.findServerSettings(args);
    args=verifyImplicitOption(args);
    args=addSrcBeforeDirectories(args);
    checkSrcOption(args);
    bin_dir=findDirectoryOption(args,""String_Node_Str"",""String_Node_Str"",true,false,true);
    gensrc_dir=findDirectoryOption(args,""String_Node_Str"",""String_Node_Str"",false,false,true);
    header_dir=findDirectoryOption(args,""String_Node_Str"",""String_Node_Str"",false,false,true);
    makefile_source_list=findFileOption(args,""String_Node_Str"",""String_Node_Str"",false);
    javac_state=JavacState.load(args,bin_dir,gensrc_dir,header_dir,findBooleanOption(args,""String_Node_Str""),out,err);
    suffix_rules=javac_state.getJavaSuffixRule();
    findTranslateOptions(args,suffix_rules);
    if (suffix_rules.keySet().size() > 1 && gensrc_dir == null) {
      Log.error(""String_Node_Str"");
      return -1;
    }
    findCopyOptions(args,suffix_rules);
    Map<String,Module> modules=new HashMap<String,Module>();
    Module current_module=new Module(""String_Node_Str"",""String_Node_Str"");
    modules.put(""String_Node_Str"",current_module);
    Map<String,Source> sources=new HashMap<String,Source>();
    findFiles(args,""String_Node_Str"",suffix_rules.keySet(),sources,modules,current_module,false);
    if (sources.isEmpty()) {
      Log.error(""String_Node_Str"");
      return -1;
    }
    Map<String,Source> sources_to_link_to=new HashMap<String,Source>();
    rewriteOptions(args,""String_Node_Str"",""String_Node_Str"");
    findFiles(args,""String_Node_Str"",Util.set(""String_Node_Str""),sources_to_link_to,modules,current_module,true);
    javac_state.now().collectPackagesSourcesAndArtifacts(modules);
    javac_state.now().checkInternalState(""String_Node_Str"",false,sources);
    javac_state.now().checkInternalState(""String_Node_Str"",true,sources_to_link_to);
    javac_state.setVisibleSources(sources_to_link_to);
    javac_state.checkSourceStatus(false);
    javac_state.findAllArtifacts();
    if (!findBooleanOption(args,""String_Node_Str"")) {
      javac_state.removeUnidentifiedArtifacts();
    }
    javac_state.taintPackagesThatMissArtifacts();
    javac_state.deleteClassArtifactsInTaintedPackages();
    javac_state.performCopying(bin_dir,suffix_rules);
    javac_state.performTranslation(gensrc_dir,suffix_rules);
    Map<String,Source> generated_sources=new HashMap<String,Source>();
    Source.scanRoot(gensrc_dir,Util.set(""String_Node_Str""),null,null,null,null,generated_sources,modules,current_module,false,true,false);
    javac_state.now().collectPackagesSourcesAndArtifacts(modules);
    javac_state.checkSourceStatus(true);
    javac_state.compareWithMakefileList(makefile_source_list);
    boolean again;
    Set<String> recently_compiled=new HashSet<String>();
    boolean[] rc=new boolean[1];
    do {
      javac_state.deleteClassArtifactsInTaintedPackages();
      again=javac_state.performJavaCompilations(bin_dir,server_settings,args,recently_compiled,rc);
      if (!rc[0])       break;
    }
 while (again);
    if (rc[0]) {
      javac_state.save();
      javac_state.now().collectArtifacts(modules);
      javac_state.removeSuperfluousArtifacts(recently_compiled);
    }
    return rc[0] ? 0 : -1;
  }
 catch (  ProblemException e) {
    Log.error(e.getMessage());
    return -1;
  }
catch (  Exception e) {
    e.printStackTrace(err);
    return -1;
  }
}"
37058,"private void checkConfigPermission(){
  final SecurityManager sm=System.getSecurityManager();
  if (sm != null) {
    sm.checkPermission(new RuntimePermission(""String_Node_Str""));
  }
}","private static void checkConfigPermission(){
  final SecurityManager sm=System.getSecurityManager();
  if (sm != null) {
    sm.checkPermission(new RuntimePermission(""String_Node_Str""));
  }
}"
37059,"@Override protected void makeObject(final MethodEmitter m){
  final String className=SCRIPTFUNCTION_IMPL_OBJECT;
  m._new(className).dup();
  loadConstant(new RecompilableScriptFunctionData(functionNode,compiler.getCodeInstaller(),Compiler.binaryName(getClassName()),makeMap()));
  if (isLazy || functionNode.needsParentScope()) {
    m.loadScope();
  }
 else {
    m.loadNull();
  }
  m.invoke(constructorNoLookup(className,cparams));
}","@Override protected void makeObject(final MethodEmitter m){
  final String className=SCRIPTFUNCTION_IMPL_OBJECT;
  m._new(className).dup();
  loadConstant(new RecompilableScriptFunctionData(functionNode,compiler.getCodeInstaller(),Compiler.binaryName(getClassName()),makeMap()));
  if (isLazy || functionNode.needsParentScope()) {
    m.loadScope();
  }
 else {
    m.loadNull();
  }
  m.invoke(constructorNoLookup(className,RecompilableScriptFunctionData.class,ScriptObject.class));
}"
37060,"private void newFunctionObject(final FunctionNode functionNode){
  final boolean isLazy=functionNode.isLazy();
  final Class<?>[] cparams=new Class<?>[]{RecompilableScriptFunctionData.class,ScriptObject.class};
  new ObjectCreator(this,new ArrayList<String>(),new ArrayList<Symbol>(),false,false){
    @Override protected void makeObject(    final MethodEmitter m){
      final String className=SCRIPTFUNCTION_IMPL_OBJECT;
      m._new(className).dup();
      loadConstant(new RecompilableScriptFunctionData(functionNode,compiler.getCodeInstaller(),Compiler.binaryName(getClassName()),makeMap()));
      if (isLazy || functionNode.needsParentScope()) {
        m.loadScope();
      }
 else {
        m.loadNull();
      }
      m.invoke(constructorNoLookup(className,cparams));
    }
  }
.makeObject(method);
}","private void newFunctionObject(final FunctionNode functionNode){
  final boolean isLazy=functionNode.isLazy();
  new ObjectCreator(this,new ArrayList<String>(),new ArrayList<Symbol>(),false,false){
    @Override protected void makeObject(    final MethodEmitter m){
      final String className=SCRIPTFUNCTION_IMPL_OBJECT;
      m._new(className).dup();
      loadConstant(new RecompilableScriptFunctionData(functionNode,compiler.getCodeInstaller(),Compiler.binaryName(getClassName()),makeMap()));
      if (isLazy || functionNode.needsParentScope()) {
        m.loadScope();
      }
 else {
        m.loadNull();
      }
      m.invoke(constructorNoLookup(className,RecompilableScriptFunctionData.class,ScriptObject.class));
    }
  }
.makeObject(method);
}"
37061,"/** 
 * Check if this function's generated Java method needs a   {@code callee} parameter. Functions that need access totheir parent scope, functions that reference themselves, and non-strict functions that need an Arguments object (since it exposes  {@code arguments.callee} property) will need to have a callee parameter.We also conservatively need a callee if we have lazy children, i.e. nested function nodes that have not yet been evaluated. _They_ may need the callee and we don't know it
 * @return true if the function's generated Java method needs a {@code callee} parameter.
 */
public boolean needsCallee(){
  return hasLazyChildren() || needsParentScope() || needsSelfSymbol()|| (needsArguments() && !isStrictMode());
}","/** 
 * Check if this function's generated Java method needs a   {@code callee} parameter. Functions that need access totheir parent scope, functions that reference themselves, and non-strict functions that need an Arguments object (since it exposes  {@code arguments.callee} property) will need to have a callee parameter.
 * @return true if the function's generated Java method needs a {@code callee} parameter.
 */
public boolean needsCallee(){
  return needsParentScope() || needsSelfSymbol() || (needsArguments() && !isStrictMode());
}"
37062,"private void copyOptions(final ScriptObject options,final ScriptEnvironment scriptEnv){
  AccessController.doPrivileged(new PrivilegedAction<Void>(){
    public Void run(){
      for (      Field f : scriptEnv.getClass().getFields()) {
        try {
          options.set(f.getName(),f.get(scriptEnv),false);
        }
 catch (        final IllegalArgumentException|IllegalAccessException exp) {
          throw new RuntimeException(exp);
        }
      }
      return null;
    }
  }
);
}","private static void copyOptions(final ScriptObject options,final ScriptEnvironment scriptEnv){
  AccessController.doPrivileged(new PrivilegedAction<Void>(){
    @Override public Void run(){
      for (      Field f : scriptEnv.getClass().getFields()) {
        try {
          options.set(f.getName(),f.get(scriptEnv),false);
        }
 catch (        final IllegalArgumentException|IllegalAccessException exp) {
          throw new RuntimeException(exp);
        }
      }
      return null;
    }
  }
);
}"
37063,"public Void run(){
  for (  Field f : scriptEnv.getClass().getFields()) {
    try {
      options.set(f.getName(),f.get(scriptEnv),false);
    }
 catch (    final IllegalArgumentException|IllegalAccessException exp) {
      throw new RuntimeException(exp);
    }
  }
  return null;
}","@Override public Void run(){
  for (  Field f : scriptEnv.getClass().getFields()) {
    try {
      options.set(f.getName(),f.get(scriptEnv),false);
    }
 catch (    final IllegalArgumentException|IllegalAccessException exp) {
      throw new RuntimeException(exp);
    }
  }
  return null;
}"
37064,"private synchronized Class<?> compile(final Source source,final ErrorManager errMan,final boolean strict){
  errMan.reset();
  GlobalObject global=null;
  Class<?> script;
  if (env._class_cache_size > 0) {
    global=(GlobalObject)Context.getGlobalTrusted();
    script=global.findCachedClass(source);
    if (script != null) {
      return script;
    }
  }
  final FunctionNode functionNode=new Parser(env,source,errMan,strict).parse();
  if (errors.hasErrors() || env._parse_only) {
    return null;
  }
  if (env._print_ast) {
    getErr().println(new ASTWriter(functionNode));
  }
  if (env._print_parse) {
    getErr().println(new PrintVisitor(functionNode));
  }
  final URL url=source.getURL();
  final ScriptLoader loader=env._loader_per_compile ? createNewLoader() : scriptLoader;
  final CodeSource cs=url == null ? null : new CodeSource(url,(CodeSigner[])null);
  final CodeInstaller<ScriptEnvironment> installer=new ContextCodeInstaller(this,loader,cs);
  final Compiler compiler=new Compiler(installer,functionNode,strict);
  compiler.compile();
  script=compiler.install();
  if (global != null) {
    global.cacheClass(source,script);
  }
  return script;
}","private synchronized Class<?> compile(final Source source,final ErrorManager errMan,final boolean strict){
  errMan.reset();
  GlobalObject global=null;
  Class<?> script;
  if (env._class_cache_size > 0) {
    global=(GlobalObject)Context.getGlobalTrusted();
    script=global.findCachedClass(source);
    if (script != null) {
      Compiler.LOG.fine(""String_Node_Str"" + source + ""String_Node_Str"");
      return script;
    }
  }
  final FunctionNode functionNode=new Parser(env,source,errMan,strict).parse();
  if (errors.hasErrors() || env._parse_only) {
    return null;
  }
  if (env._print_ast) {
    getErr().println(new ASTWriter(functionNode));
  }
  if (env._print_parse) {
    getErr().println(new PrintVisitor(functionNode));
  }
  final URL url=source.getURL();
  final ScriptLoader loader=env._loader_per_compile ? createNewLoader() : scriptLoader;
  final CodeSource cs=url == null ? null : new CodeSource(url,(CodeSigner[])null);
  final CodeInstaller<ScriptEnvironment> installer=new ContextCodeInstaller(this,loader,cs);
  final Compiler compiler=new Compiler(installer,functionNode,strict);
  compiler.compile();
  script=compiler.install();
  if (global != null) {
    global.cacheClass(source,script);
  }
  return script;
}"
37065,"/** 
 * Install a class for use by the Nashorn runtime
 * @param name Binary name of class.
 * @param data Class data bytes.
 * @param cs CodeSource code source of the class bytes.
 * @return Installed class.
 */
synchronized Class<?> installClass(final String name,final byte[] data,final CodeSource cs){
  if (cs == null) {
    return defineClass(name,data,0,data.length,new ProtectionDomain(null,getPermissions(null)));
  }
 else {
    return defineClass(name,data,0,data.length,cs);
  }
}","/** 
 * Install a class for use by the Nashorn runtime
 * @param name Binary name of class.
 * @param data Class data bytes.
 * @param cs CodeSource code source of the class bytes.
 * @return Installed class.
 */
synchronized Class<?> installClass(final String name,final byte[] data,final CodeSource cs){
  if (cs == null) {
    return defineClass(name,data,0,data.length,new ProtectionDomain(null,getPermissions(null)));
  }
  return defineClass(name,data,0,data.length,cs);
}"
37066,"/** 
 * Returns a method handle representing a constructor that takes a single argument of the source type (which, really, should be one of   {@link ScriptObject},   {@link ScriptFunction}, or   {@link Object}, and returns an instance of the adapter for the target type. Used to implement the function autoconverters as well as the Nashorn's JSR-223 script engine's   {@code getInterface()} method.
 * @param sourceType the source type; should be either {@link ScriptObject},   {@link ScriptFunction}, or  {@link Object}. In case of   {@code Object}, it will return a method handle that dispatches to either the script object or function constructor at invocation based on the actual argument.
 * @param targetType the target type, for which adapter instances will be created
 * @return the constructor method handle.
 * @throws Exception if anything goes wrong
 */
public static MethodHandle getConstructor(final Class<?> sourceType,final Class<?> targetType) throws Exception {
  final StaticClass adapterClass=getAdapterClassFor(new Class<?>[]{targetType});
  return AccessController.doPrivileged(new PrivilegedExceptionAction<MethodHandle>(){
    public MethodHandle run() throws Exception {
      return MH.bindTo(Bootstrap.getLinkerServices().getGuardedInvocation(new LinkRequestImpl(NashornCallSiteDescriptor.get(""String_Node_Str"",MethodType.methodType(targetType,StaticClass.class,sourceType),0),false,adapterClass,null)).getInvocation(),adapterClass);
    }
  }
);
}","/** 
 * Returns a method handle representing a constructor that takes a single argument of the source type (which, really, should be one of   {@link ScriptObject},   {@link ScriptFunction}, or   {@link Object}, and returns an instance of the adapter for the target type. Used to implement the function autoconverters as well as the Nashorn's JSR-223 script engine's   {@code getInterface()} method.
 * @param sourceType the source type; should be either {@link ScriptObject},   {@link ScriptFunction}, or  {@link Object}. In case of   {@code Object}, it will return a method handle that dispatches to either the script object or function constructor at invocation based on the actual argument.
 * @param targetType the target type, for which adapter instances will be created
 * @return the constructor method handle.
 * @throws Exception if anything goes wrong
 */
public static MethodHandle getConstructor(final Class<?> sourceType,final Class<?> targetType) throws Exception {
  final StaticClass adapterClass=getAdapterClassFor(new Class<?>[]{targetType});
  return AccessController.doPrivileged(new PrivilegedExceptionAction<MethodHandle>(){
    @Override public MethodHandle run() throws Exception {
      return MH.bindTo(Bootstrap.getLinkerServices().getGuardedInvocation(new LinkRequestImpl(NashornCallSiteDescriptor.get(""String_Node_Str"",MethodType.methodType(targetType,StaticClass.class,sourceType),0),false,adapterClass,null)).getInvocation(),adapterClass);
    }
  }
);
}"
37067,"@Override public RegExpMatcher match(final String str){
  if (pattern == null) {
    return null;
  }
  RegExpMatcher matcher=this.matcher;
  if (matcher == null || matcher.getInput() != str) {
    matcher=new DefaultMatcher(str);
    this.matcher=matcher;
  }
  return matcher;
}","@Override public RegExpMatcher match(final String str){
  if (pattern == null) {
    return null;
  }
  RegExpMatcher currentMatcher=this.matcher;
  if (currentMatcher == null || matcher.getInput() != str) {
    currentMatcher=new DefaultMatcher(str);
    this.matcher=currentMatcher;
  }
  return currentMatcher;
}"
37068,"@Override public RegExpMatcher match(final String input){
  if (regex == null) {
    return null;
  }
  RegExpMatcher matcher=this.matcher;
  if (matcher == null || input != matcher.getInput()) {
    matcher=new JoniMatcher(input);
    this.matcher=matcher;
  }
  return matcher;
}","@Override public RegExpMatcher match(final String input){
  if (regex == null) {
    return null;
  }
  RegExpMatcher currentMatcher=this.matcher;
  if (currentMatcher == null || input != currentMatcher.getInput()) {
    currentMatcher=new JoniMatcher(input);
    this.matcher=currentMatcher;
  }
  return currentMatcher;
}"
37069,"/** 
 * Throw a regexp parser exception.
 * @param key the message key
 * @param str string argument
 * @throws jdk.nashorn.internal.runtime.ParserException
 */
protected static void throwParserException(final String key,final String str) throws ParserException {
  throw new ParserException(ECMAErrors.getMessage(""String_Node_Str"" + key,str));
}","/** 
 * Throw a regexp parser exception.
 * @param key the message key
 * @param str string argument
 * @throws jdk.nashorn.internal.runtime.ParserException unconditionally
 */
protected static void throwParserException(final String key,final String str) throws ParserException {
  throw new ParserException(ECMAErrors.getMessage(""String_Node_Str"" + key,str));
}"
37070,"/** 
 * Creates a Regular expression from the given   {@code pattern} and {@code flags} strings.
 * @param pattern RegExp pattern string
 * @param flags RegExp flags string
 * @throws ParserException if flags is invalid or pattern string has syntax error.
 */
protected RegExp compile(final String pattern,final String flags) throws ParserException {
  return new DefaultRegExp(pattern,flags);
}","/** 
 * Creates a Regular expression from the given   {@code pattern} and {@code flags} strings.
 * @param pattern RegExp pattern string
 * @param flags   RegExp flags string
 * @return new RegExp
 * @throws ParserException if flags is invalid or pattern string has syntax error.
 */
protected RegExp compile(final String pattern,final String flags) throws ParserException {
  return new DefaultRegExp(pattern,flags);
}"
37071,"/** 
 * Compile a regexp with the given   {@code source} and {@code flags}.
 * @param pattern RegExp pattern string
 * @param flags  flag string
 * @throws ParserException if invalid source or flags
 */
public static RegExp create(final String pattern,final String flags){
  return instance.compile(pattern,flags);
}","/** 
 * Compile a regexp with the given   {@code source} and {@code flags}.
 * @param pattern RegExp pattern string
 * @param flags   flag string
 * @return new RegExp
 * @throws ParserException if invalid source or flags
 */
public static RegExp create(final String pattern,final String flags){
  return instance.compile(pattern,flags);
}"
37072,"/** 
 * Get the group with the given index or the empty string if group index is not valid.
 * @param index the group index
 * @return the group or """"
 */
public Object getGroup(int index){
  return index >= 0 && index < groups.length ? groups[index] : ""String_Node_Str"";
}","/** 
 * Get the group with the given index or the empty string if group index is not valid.
 * @param groupIndex the group index
 * @return the group or """"
 */
public Object getGroup(final int groupIndex){
  return groupIndex >= 0 && groupIndex < groups.length ? groups[groupIndex] : ""String_Node_Str"";
}"
37073,"private void checkConfigPermission(){
  final SecurityManager sm=System.getSecurityManager();
  if (sm != null) {
    sm.checkPermission(new RuntimePermission(""String_Node_Str""));
  }
}","private static void checkConfigPermission(){
  final SecurityManager sm=System.getSecurityManager();
  if (sm != null) {
    sm.checkPermission(new RuntimePermission(""String_Node_Str""));
  }
}"
37074,"@Override protected void makeObject(final MethodEmitter m){
  final String className=SCRIPTFUNCTION_IMPL_OBJECT;
  m._new(className).dup();
  loadConstant(new RecompilableScriptFunctionData(functionNode,compiler.getCodeInstaller(),Compiler.binaryName(getClassName()),makeMap()));
  if (isLazy || functionNode.needsParentScope()) {
    m.loadScope();
  }
 else {
    m.loadNull();
  }
  m.invoke(constructorNoLookup(className,cparams));
}","@Override protected void makeObject(final MethodEmitter m){
  final String className=SCRIPTFUNCTION_IMPL_OBJECT;
  m._new(className).dup();
  loadConstant(new RecompilableScriptFunctionData(functionNode,compiler.getCodeInstaller(),Compiler.binaryName(getClassName()),makeMap()));
  if (isLazy || functionNode.needsParentScope()) {
    m.loadScope();
  }
 else {
    m.loadNull();
  }
  m.invoke(constructorNoLookup(className,RecompilableScriptFunctionData.class,ScriptObject.class));
}"
37075,"private void newFunctionObject(final FunctionNode functionNode){
  final boolean isLazy=functionNode.isLazy();
  final Class<?>[] cparams=new Class<?>[]{RecompilableScriptFunctionData.class,ScriptObject.class};
  new ObjectCreator(this,new ArrayList<String>(),new ArrayList<Symbol>(),false,false){
    @Override protected void makeObject(    final MethodEmitter m){
      final String className=SCRIPTFUNCTION_IMPL_OBJECT;
      m._new(className).dup();
      loadConstant(new RecompilableScriptFunctionData(functionNode,compiler.getCodeInstaller(),Compiler.binaryName(getClassName()),makeMap()));
      if (isLazy || functionNode.needsParentScope()) {
        m.loadScope();
      }
 else {
        m.loadNull();
      }
      m.invoke(constructorNoLookup(className,cparams));
    }
  }
.makeObject(method);
}","private void newFunctionObject(final FunctionNode functionNode){
  final boolean isLazy=functionNode.isLazy();
  new ObjectCreator(this,new ArrayList<String>(),new ArrayList<Symbol>(),false,false){
    @Override protected void makeObject(    final MethodEmitter m){
      final String className=SCRIPTFUNCTION_IMPL_OBJECT;
      m._new(className).dup();
      loadConstant(new RecompilableScriptFunctionData(functionNode,compiler.getCodeInstaller(),Compiler.binaryName(getClassName()),makeMap()));
      if (isLazy || functionNode.needsParentScope()) {
        m.loadScope();
      }
 else {
        m.loadNull();
      }
      m.invoke(constructorNoLookup(className,RecompilableScriptFunctionData.class,ScriptObject.class));
    }
  }
.makeObject(method);
}"
37076,"/** 
 * Check if this function's generated Java method needs a   {@code callee} parameter. Functions that need access totheir parent scope, functions that reference themselves, and non-strict functions that need an Arguments object (since it exposes  {@code arguments.callee} property) will need to have a callee parameter.We also conservatively need a callee if we have lazy children, i.e. nested function nodes that have not yet been evaluated. _They_ may need the callee and we don't know it
 * @return true if the function's generated Java method needs a {@code callee} parameter.
 */
public boolean needsCallee(){
  return hasLazyChildren() || needsParentScope() || needsSelfSymbol()|| (needsArguments() && !isStrictMode());
}","/** 
 * Check if this function's generated Java method needs a   {@code callee} parameter. Functions that need access totheir parent scope, functions that reference themselves, and non-strict functions that need an Arguments object (since it exposes  {@code arguments.callee} property) will need to have a callee parameter.
 * @return true if the function's generated Java method needs a {@code callee} parameter.
 */
public boolean needsCallee(){
  return needsParentScope() || needsSelfSymbol() || (needsArguments() && !isStrictMode());
}"
37077,"private void copyOptions(final ScriptObject options,final ScriptEnvironment scriptEnv){
  AccessController.doPrivileged(new PrivilegedAction<Void>(){
    public Void run(){
      for (      Field f : scriptEnv.getClass().getFields()) {
        try {
          options.set(f.getName(),f.get(scriptEnv),false);
        }
 catch (        final IllegalArgumentException|IllegalAccessException exp) {
          throw new RuntimeException(exp);
        }
      }
      return null;
    }
  }
);
}","private static void copyOptions(final ScriptObject options,final ScriptEnvironment scriptEnv){
  AccessController.doPrivileged(new PrivilegedAction<Void>(){
    @Override public Void run(){
      for (      Field f : scriptEnv.getClass().getFields()) {
        try {
          options.set(f.getName(),f.get(scriptEnv),false);
        }
 catch (        final IllegalArgumentException|IllegalAccessException exp) {
          throw new RuntimeException(exp);
        }
      }
      return null;
    }
  }
);
}"
37078,"public Void run(){
  for (  Field f : scriptEnv.getClass().getFields()) {
    try {
      options.set(f.getName(),f.get(scriptEnv),false);
    }
 catch (    final IllegalArgumentException|IllegalAccessException exp) {
      throw new RuntimeException(exp);
    }
  }
  return null;
}","@Override public Void run(){
  for (  Field f : scriptEnv.getClass().getFields()) {
    try {
      options.set(f.getName(),f.get(scriptEnv),false);
    }
 catch (    final IllegalArgumentException|IllegalAccessException exp) {
      throw new RuntimeException(exp);
    }
  }
  return null;
}"
37079,"private synchronized Class<?> compile(final Source source,final ErrorManager errMan,final boolean strict){
  errMan.reset();
  GlobalObject global=null;
  Class<?> script;
  if (env._class_cache_size > 0) {
    global=(GlobalObject)Context.getGlobalTrusted();
    script=global.findCachedClass(source);
    if (script != null) {
      return script;
    }
  }
  final FunctionNode functionNode=new Parser(env,source,errMan,strict).parse();
  if (errors.hasErrors() || env._parse_only) {
    return null;
  }
  if (env._print_ast) {
    getErr().println(new ASTWriter(functionNode));
  }
  if (env._print_parse) {
    getErr().println(new PrintVisitor(functionNode));
  }
  final URL url=source.getURL();
  final ScriptLoader loader=env._loader_per_compile ? createNewLoader() : scriptLoader;
  final CodeSource cs=url == null ? null : new CodeSource(url,(CodeSigner[])null);
  final CodeInstaller<ScriptEnvironment> installer=new ContextCodeInstaller(this,loader,cs);
  final Compiler compiler=new Compiler(installer,functionNode,strict);
  compiler.compile();
  script=compiler.install();
  if (global != null) {
    global.cacheClass(source,script);
  }
  return script;
}","private synchronized Class<?> compile(final Source source,final ErrorManager errMan,final boolean strict){
  errMan.reset();
  GlobalObject global=null;
  Class<?> script;
  if (env._class_cache_size > 0) {
    global=(GlobalObject)Context.getGlobalTrusted();
    script=global.findCachedClass(source);
    if (script != null) {
      Compiler.LOG.fine(""String_Node_Str"" + source + ""String_Node_Str"");
      return script;
    }
  }
  final FunctionNode functionNode=new Parser(env,source,errMan,strict).parse();
  if (errors.hasErrors() || env._parse_only) {
    return null;
  }
  if (env._print_ast) {
    getErr().println(new ASTWriter(functionNode));
  }
  if (env._print_parse) {
    getErr().println(new PrintVisitor(functionNode));
  }
  final URL url=source.getURL();
  final ScriptLoader loader=env._loader_per_compile ? createNewLoader() : scriptLoader;
  final CodeSource cs=url == null ? null : new CodeSource(url,(CodeSigner[])null);
  final CodeInstaller<ScriptEnvironment> installer=new ContextCodeInstaller(this,loader,cs);
  final Compiler compiler=new Compiler(installer,functionNode,strict);
  compiler.compile();
  script=compiler.install();
  if (global != null) {
    global.cacheClass(source,script);
  }
  return script;
}"
37080,"/** 
 * Install a class for use by the Nashorn runtime
 * @param name Binary name of class.
 * @param data Class data bytes.
 * @param cs CodeSource code source of the class bytes.
 * @return Installed class.
 */
synchronized Class<?> installClass(final String name,final byte[] data,final CodeSource cs){
  if (cs == null) {
    return defineClass(name,data,0,data.length,new ProtectionDomain(null,getPermissions(null)));
  }
 else {
    return defineClass(name,data,0,data.length,cs);
  }
}","/** 
 * Install a class for use by the Nashorn runtime
 * @param name Binary name of class.
 * @param data Class data bytes.
 * @param cs CodeSource code source of the class bytes.
 * @return Installed class.
 */
synchronized Class<?> installClass(final String name,final byte[] data,final CodeSource cs){
  if (cs == null) {
    return defineClass(name,data,0,data.length,new ProtectionDomain(null,getPermissions(null)));
  }
  return defineClass(name,data,0,data.length,cs);
}"
37081,"/** 
 * Returns a method handle representing a constructor that takes a single argument of the source type (which, really, should be one of   {@link ScriptObject},   {@link ScriptFunction}, or   {@link Object}, and returns an instance of the adapter for the target type. Used to implement the function autoconverters as well as the Nashorn's JSR-223 script engine's   {@code getInterface()} method.
 * @param sourceType the source type; should be either {@link ScriptObject},   {@link ScriptFunction}, or  {@link Object}. In case of   {@code Object}, it will return a method handle that dispatches to either the script object or function constructor at invocation based on the actual argument.
 * @param targetType the target type, for which adapter instances will be created
 * @return the constructor method handle.
 * @throws Exception if anything goes wrong
 */
public static MethodHandle getConstructor(final Class<?> sourceType,final Class<?> targetType) throws Exception {
  final StaticClass adapterClass=getAdapterClassFor(new Class<?>[]{targetType});
  return AccessController.doPrivileged(new PrivilegedExceptionAction<MethodHandle>(){
    public MethodHandle run() throws Exception {
      return MH.bindTo(Bootstrap.getLinkerServices().getGuardedInvocation(new LinkRequestImpl(NashornCallSiteDescriptor.get(""String_Node_Str"",MethodType.methodType(targetType,StaticClass.class,sourceType),0),false,adapterClass,null)).getInvocation(),adapterClass);
    }
  }
);
}","/** 
 * Returns a method handle representing a constructor that takes a single argument of the source type (which, really, should be one of   {@link ScriptObject},   {@link ScriptFunction}, or   {@link Object}, and returns an instance of the adapter for the target type. Used to implement the function autoconverters as well as the Nashorn's JSR-223 script engine's   {@code getInterface()} method.
 * @param sourceType the source type; should be either {@link ScriptObject},   {@link ScriptFunction}, or  {@link Object}. In case of   {@code Object}, it will return a method handle that dispatches to either the script object or function constructor at invocation based on the actual argument.
 * @param targetType the target type, for which adapter instances will be created
 * @return the constructor method handle.
 * @throws Exception if anything goes wrong
 */
public static MethodHandle getConstructor(final Class<?> sourceType,final Class<?> targetType) throws Exception {
  final StaticClass adapterClass=getAdapterClassFor(new Class<?>[]{targetType});
  return AccessController.doPrivileged(new PrivilegedExceptionAction<MethodHandle>(){
    @Override public MethodHandle run() throws Exception {
      return MH.bindTo(Bootstrap.getLinkerServices().getGuardedInvocation(new LinkRequestImpl(NashornCallSiteDescriptor.get(""String_Node_Str"",MethodType.methodType(targetType,StaticClass.class,sourceType),0),false,adapterClass,null)).getInvocation(),adapterClass);
    }
  }
);
}"
37082,"@Override public RegExpMatcher match(final String str){
  if (pattern == null) {
    return null;
  }
  RegExpMatcher matcher=this.matcher;
  if (matcher == null || matcher.getInput() != str) {
    matcher=new DefaultMatcher(str);
    this.matcher=matcher;
  }
  return matcher;
}","@Override public RegExpMatcher match(final String str){
  if (pattern == null) {
    return null;
  }
  RegExpMatcher currentMatcher=this.matcher;
  if (currentMatcher == null || matcher.getInput() != str) {
    currentMatcher=new DefaultMatcher(str);
    this.matcher=currentMatcher;
  }
  return currentMatcher;
}"
37083,"@Override public RegExpMatcher match(final String input){
  if (regex == null) {
    return null;
  }
  RegExpMatcher matcher=this.matcher;
  if (matcher == null || input != matcher.getInput()) {
    matcher=new JoniMatcher(input);
    this.matcher=matcher;
  }
  return matcher;
}","@Override public RegExpMatcher match(final String input){
  if (regex == null) {
    return null;
  }
  RegExpMatcher currentMatcher=this.matcher;
  if (currentMatcher == null || input != currentMatcher.getInput()) {
    currentMatcher=new JoniMatcher(input);
    this.matcher=currentMatcher;
  }
  return currentMatcher;
}"
37084,"/** 
 * Throw a regexp parser exception.
 * @param key the message key
 * @param str string argument
 * @throws jdk.nashorn.internal.runtime.ParserException
 */
protected static void throwParserException(final String key,final String str) throws ParserException {
  throw new ParserException(ECMAErrors.getMessage(""String_Node_Str"" + key,str));
}","/** 
 * Throw a regexp parser exception.
 * @param key the message key
 * @param str string argument
 * @throws jdk.nashorn.internal.runtime.ParserException unconditionally
 */
protected static void throwParserException(final String key,final String str) throws ParserException {
  throw new ParserException(ECMAErrors.getMessage(""String_Node_Str"" + key,str));
}"
37085,"/** 
 * Creates a Regular expression from the given   {@code pattern} and {@code flags} strings.
 * @param pattern RegExp pattern string
 * @param flags RegExp flags string
 * @throws ParserException if flags is invalid or pattern string has syntax error.
 */
protected RegExp compile(final String pattern,final String flags) throws ParserException {
  return new DefaultRegExp(pattern,flags);
}","/** 
 * Creates a Regular expression from the given   {@code pattern} and {@code flags} strings.
 * @param pattern RegExp pattern string
 * @param flags   RegExp flags string
 * @return new RegExp
 * @throws ParserException if flags is invalid or pattern string has syntax error.
 */
protected RegExp compile(final String pattern,final String flags) throws ParserException {
  return new DefaultRegExp(pattern,flags);
}"
37086,"/** 
 * Compile a regexp with the given   {@code source} and {@code flags}.
 * @param pattern RegExp pattern string
 * @param flags  flag string
 * @throws ParserException if invalid source or flags
 */
public static RegExp create(final String pattern,final String flags){
  return instance.compile(pattern,flags);
}","/** 
 * Compile a regexp with the given   {@code source} and {@code flags}.
 * @param pattern RegExp pattern string
 * @param flags   flag string
 * @return new RegExp
 * @throws ParserException if invalid source or flags
 */
public static RegExp create(final String pattern,final String flags){
  return instance.compile(pattern,flags);
}"
37087,"/** 
 * Get the group with the given index or the empty string if group index is not valid.
 * @param index the group index
 * @return the group or """"
 */
public Object getGroup(int index){
  return index >= 0 && index < groups.length ? groups[index] : ""String_Node_Str"";
}","/** 
 * Get the group with the given index or the empty string if group index is not valid.
 * @param groupIndex the group index
 * @return the group or """"
 */
public Object getGroup(final int groupIndex){
  return groupIndex >= 0 && groupIndex < groups.length ? groups[groupIndex] : ""String_Node_Str"";
}"
37088,"public static boolean isDynamicMethod(final Object obj){
  return obj instanceof DynamicMethod;
}","/** 
 * Returns true if the object is a Dynalink Java dynamic method.
 * @param obj the object we want to test for being a dynamic method
 * @return true if it is a dynamic method, false otherwise.
 */
public static boolean isDynamicMethod(final Object obj){
  return obj instanceof DynamicMethod;
}"
37089,"public static boolean isDynamicMethod(final Object obj){
  return obj instanceof DynamicMethod;
}","/** 
 * Returns true if the object is a Dynalink Java dynamic method.
 * @param obj the object we want to test for being a dynamic method
 * @return true if it is a dynamic method, false otherwise.
 */
public static boolean isDynamicMethod(final Object obj){
  return obj instanceof DynamicMethod;
}"
37090,"public static final Attribute readAttribute(DataInputStream file,ConstantPool constant_pool) throws IOException, ClassFormatException {
  ConstantUtf8 c;
  String name;
  int name_index;
  int length;
  byte tag=Constants.ATTR_UNKNOWN;
  name_index=(int)file.readUnsignedShort();
  c=(ConstantUtf8)constant_pool.getConstant(name_index,Constants.CONSTANT_Utf8);
  name=c.getBytes();
  length=file.readInt();
  for (byte i=0; i < Constants.KNOWN_ATTRIBUTES; i++) {
    if (name.equals(Constants.ATTRIBUTE_NAMES[i])) {
      tag=i;
      break;
    }
  }
switch (tag) {
case Constants.ATTR_UNKNOWN:
    AttributeReader r=(AttributeReader)readers.get(name);
  if (r != null)   return r.createAttribute(name_index,length,file,constant_pool);
 else   return new Unknown(name_index,length,file,constant_pool);
case Constants.ATTR_CONSTANT_VALUE:
return new ConstantValue(name_index,length,file,constant_pool);
case Constants.ATTR_SOURCE_FILE:
return new SourceFile(name_index,length,file,constant_pool);
case Constants.ATTR_CODE:
return new Code(name_index,length,file,constant_pool);
case Constants.ATTR_EXCEPTIONS:
return new ExceptionTable(name_index,length,file,constant_pool);
case Constants.ATTR_LINE_NUMBER_TABLE:
return new LineNumberTable(name_index,length,file,constant_pool);
case Constants.ATTR_LOCAL_VARIABLE_TABLE:
return new LocalVariableTable(name_index,length,file,constant_pool);
case Constants.ATTR_INNER_CLASSES:
return new InnerClasses(name_index,length,file,constant_pool);
case Constants.ATTR_SYNTHETIC:
return new Synthetic(name_index,length,file,constant_pool);
case Constants.ATTR_DEPRECATED:
return new Deprecated(name_index,length,file,constant_pool);
case Constants.ATTR_PMG:
return new PMGClass(name_index,length,file,constant_pool);
case Constants.ATTR_SIGNATURE:
return new Signature(name_index,length,file,constant_pool);
case Constants.ATTR_STACK_MAP:
return new StackMap(name_index,length,file,constant_pool);
default :
throw new IllegalStateException(""String_Node_Str"");
}
}","public static final Attribute readAttribute(DataInputStream file,ConstantPool constant_pool) throws IOException, ClassFormatException {
  ConstantUtf8 c;
  String name;
  int name_index;
  int length;
  byte tag=Constants.ATTR_UNKNOWN;
  name_index=(int)file.readUnsignedShort();
  c=(ConstantUtf8)constant_pool.getConstant(name_index,Constants.CONSTANT_Utf8);
  name=c.getBytes();
  length=file.readInt();
  for (byte i=0; i < Constants.KNOWN_ATTRIBUTES; i++) {
    if (name.equals(Constants.ATTRIBUTE_NAMES[i])) {
      tag=i;
      break;
    }
  }
switch (tag) {
case Constants.ATTR_UNKNOWN:
    AttributeReader r=(AttributeReader)readers.get(name);
  if (r != null)   return r.createAttribute(name_index,length,file,constant_pool);
 else   return new Unknown(name_index,length,file,constant_pool);
case Constants.ATTR_CONSTANT_VALUE:
return new ConstantValue(name_index,length,file,constant_pool);
case Constants.ATTR_SOURCE_FILE:
return new SourceFile(name_index,length,file,constant_pool);
case Constants.ATTR_CODE:
return new Code(name_index,length,file,constant_pool);
case Constants.ATTR_EXCEPTIONS:
return new ExceptionTable(name_index,length,file,constant_pool);
case Constants.ATTR_LINE_NUMBER_TABLE:
return new LineNumberTable(name_index,length,file,constant_pool);
case Constants.ATTR_LOCAL_VARIABLE_TABLE:
return new LocalVariableTable(name_index,length,file,constant_pool);
case Constants.ATTR_LOCAL_VARIABLE_TYPE_TABLE:
return new LocalVariableTypeTable(name_index,length,file,constant_pool);
case Constants.ATTR_INNER_CLASSES:
return new InnerClasses(name_index,length,file,constant_pool);
case Constants.ATTR_SYNTHETIC:
return new Synthetic(name_index,length,file,constant_pool);
case Constants.ATTR_DEPRECATED:
return new Deprecated(name_index,length,file,constant_pool);
case Constants.ATTR_PMG:
return new PMGClass(name_index,length,file,constant_pool);
case Constants.ATTR_SIGNATURE:
return new Signature(name_index,length,file,constant_pool);
case Constants.ATTR_STACK_MAP:
return new StackMap(name_index,length,file,constant_pool);
default :
throw new IllegalStateException(""String_Node_Str"");
}
}"
37091,"/** 
 * Instantiate from existing method.
 * @param m method
 * @param class_name class name containing this method
 * @param cp constant pool
 */
public MethodGen(Method m,String class_name,ConstantPoolGen cp){
  this(m.getAccessFlags(),Type.getReturnType(m.getSignature()),Type.getArgumentTypes(m.getSignature()),null,m.getName(),class_name,((m.getAccessFlags() & (Constants.ACC_ABSTRACT | Constants.ACC_NATIVE)) == 0) ? new InstructionList(m.getCode().getCode()) : null,cp);
  Attribute[] attributes=m.getAttributes();
  for (int i=0; i < attributes.length; i++) {
    Attribute a=attributes[i];
    if (a instanceof Code) {
      Code c=(Code)a;
      setMaxStack(c.getMaxStack());
      setMaxLocals(c.getMaxLocals());
      CodeException[] ces=c.getExceptionTable();
      if (ces != null) {
        for (int j=0; j < ces.length; j++) {
          CodeException ce=ces[j];
          int type=ce.getCatchType();
          ObjectType c_type=null;
          if (type > 0) {
            String cen=m.getConstantPool().getConstantString(type,Constants.CONSTANT_Class);
            c_type=new ObjectType(cen);
          }
          int end_pc=ce.getEndPC();
          int length=m.getCode().getCode().length;
          InstructionHandle end;
          if (length == end_pc) {
            end=il.getEnd();
          }
 else {
            end=il.findHandle(end_pc);
            end=end.getPrev();
          }
          addExceptionHandler(il.findHandle(ce.getStartPC()),end,il.findHandle(ce.getHandlerPC()),c_type);
        }
      }
      Attribute[] c_attributes=c.getAttributes();
      for (int j=0; j < c_attributes.length; j++) {
        a=c_attributes[j];
        if (a instanceof LineNumberTable) {
          LineNumber[] ln=((LineNumberTable)a).getLineNumberTable();
          for (int k=0; k < ln.length; k++) {
            LineNumber l=ln[k];
            addLineNumber(il.findHandle(l.getStartPC()),l.getLineNumber());
          }
        }
 else         if (a instanceof LocalVariableTable) {
          LocalVariable[] lv=((LocalVariableTable)a).getLocalVariableTable();
          removeLocalVariables();
          for (int k=0; k < lv.length; k++) {
            LocalVariable l=lv[k];
            InstructionHandle start=il.findHandle(l.getStartPC());
            InstructionHandle end=il.findHandle(l.getStartPC() + l.getLength());
            if (null == start) {
              start=il.getStart();
            }
            if (null == end) {
              end=il.getEnd();
            }
            addLocalVariable(l.getName(),Type.getType(l.getSignature()),l.getIndex(),start,end);
          }
        }
 else         addCodeAttribute(a);
      }
    }
 else     if (a instanceof ExceptionTable) {
      String[] names=((ExceptionTable)a).getExceptionNames();
      for (int j=0; j < names.length; j++)       addException(names[j]);
    }
 else     addAttribute(a);
  }
}","/** 
 * Instantiate from existing method.
 * @param m method
 * @param class_name class name containing this method
 * @param cp constant pool
 */
public MethodGen(Method m,String class_name,ConstantPoolGen cp){
  this(m.getAccessFlags(),Type.getReturnType(m.getSignature()),Type.getArgumentTypes(m.getSignature()),null,m.getName(),class_name,((m.getAccessFlags() & (Constants.ACC_ABSTRACT | Constants.ACC_NATIVE)) == 0) ? new InstructionList(m.getCode().getCode()) : null,cp);
  Attribute[] attributes=m.getAttributes();
  for (int i=0; i < attributes.length; i++) {
    Attribute a=attributes[i];
    if (a instanceof Code) {
      Code c=(Code)a;
      setMaxStack(c.getMaxStack());
      setMaxLocals(c.getMaxLocals());
      CodeException[] ces=c.getExceptionTable();
      if (ces != null) {
        for (int j=0; j < ces.length; j++) {
          CodeException ce=ces[j];
          int type=ce.getCatchType();
          ObjectType c_type=null;
          if (type > 0) {
            String cen=m.getConstantPool().getConstantString(type,Constants.CONSTANT_Class);
            c_type=new ObjectType(cen);
          }
          int end_pc=ce.getEndPC();
          int length=m.getCode().getCode().length;
          InstructionHandle end;
          if (length == end_pc) {
            end=il.getEnd();
          }
 else {
            end=il.findHandle(end_pc);
            end=end.getPrev();
          }
          addExceptionHandler(il.findHandle(ce.getStartPC()),end,il.findHandle(ce.getHandlerPC()),c_type);
        }
      }
      Attribute[] c_attributes=c.getAttributes();
      for (int j=0; j < c_attributes.length; j++) {
        a=c_attributes[j];
        if (a instanceof LineNumberTable) {
          LineNumber[] ln=((LineNumberTable)a).getLineNumberTable();
          for (int k=0; k < ln.length; k++) {
            LineNumber l=ln[k];
            addLineNumber(il.findHandle(l.getStartPC()),l.getLineNumber());
          }
        }
 else         if (a instanceof LocalVariableTable) {
          LocalVariable[] lv=((LocalVariableTable)a).getLocalVariableTable();
          removeLocalVariables();
          for (int k=0; k < lv.length; k++) {
            LocalVariable l=lv[k];
            InstructionHandle start=il.findHandle(l.getStartPC());
            InstructionHandle end=il.findHandle(l.getStartPC() + l.getLength());
            if (null == start) {
              start=il.getStart();
            }
            if (null == end) {
              end=il.getEnd();
            }
            addLocalVariable(l.getName(),Type.getType(l.getSignature()),l.getIndex(),start,end);
          }
        }
 else         if (a instanceof LocalVariableTypeTable) {
          LocalVariable[] lv=((LocalVariableTypeTable)a).getLocalVariableTypeTable();
          removeLocalVariables();
          for (int k=0; k < lv.length; k++) {
            LocalVariable l=lv[k];
            InstructionHandle start=il.findHandle(l.getStartPC());
            InstructionHandle end=il.findHandle(l.getStartPC() + l.getLength());
            if (null == start) {
              start=il.getStart();
            }
            if (null == end) {
              end=il.getEnd();
            }
            addLocalVariable(l.getName(),Type.getType(l.getSignature()),l.getIndex(),start,end);
          }
        }
 else         addCodeAttribute(a);
      }
    }
 else     if (a instanceof ExceptionTable) {
      String[] names=((ExceptionTable)a).getExceptionNames();
      for (int j=0; j < names.length; j++)       addException(names[j]);
    }
 else     addAttribute(a);
  }
}"
37092,"public static final Attribute readAttribute(DataInputStream file,ConstantPool constant_pool) throws IOException, ClassFormatException {
  ConstantUtf8 c;
  String name;
  int name_index;
  int length;
  byte tag=Constants.ATTR_UNKNOWN;
  name_index=(int)file.readUnsignedShort();
  c=(ConstantUtf8)constant_pool.getConstant(name_index,Constants.CONSTANT_Utf8);
  name=c.getBytes();
  length=file.readInt();
  for (byte i=0; i < Constants.KNOWN_ATTRIBUTES; i++) {
    if (name.equals(Constants.ATTRIBUTE_NAMES[i])) {
      tag=i;
      break;
    }
  }
switch (tag) {
case Constants.ATTR_UNKNOWN:
    AttributeReader r=(AttributeReader)readers.get(name);
  if (r != null)   return r.createAttribute(name_index,length,file,constant_pool);
 else   return new Unknown(name_index,length,file,constant_pool);
case Constants.ATTR_CONSTANT_VALUE:
return new ConstantValue(name_index,length,file,constant_pool);
case Constants.ATTR_SOURCE_FILE:
return new SourceFile(name_index,length,file,constant_pool);
case Constants.ATTR_CODE:
return new Code(name_index,length,file,constant_pool);
case Constants.ATTR_EXCEPTIONS:
return new ExceptionTable(name_index,length,file,constant_pool);
case Constants.ATTR_LINE_NUMBER_TABLE:
return new LineNumberTable(name_index,length,file,constant_pool);
case Constants.ATTR_LOCAL_VARIABLE_TABLE:
return new LocalVariableTable(name_index,length,file,constant_pool);
case Constants.ATTR_INNER_CLASSES:
return new InnerClasses(name_index,length,file,constant_pool);
case Constants.ATTR_SYNTHETIC:
return new Synthetic(name_index,length,file,constant_pool);
case Constants.ATTR_DEPRECATED:
return new Deprecated(name_index,length,file,constant_pool);
case Constants.ATTR_PMG:
return new PMGClass(name_index,length,file,constant_pool);
case Constants.ATTR_SIGNATURE:
return new Signature(name_index,length,file,constant_pool);
case Constants.ATTR_STACK_MAP:
return new StackMap(name_index,length,file,constant_pool);
default :
throw new IllegalStateException(""String_Node_Str"");
}
}","public static final Attribute readAttribute(DataInputStream file,ConstantPool constant_pool) throws IOException, ClassFormatException {
  ConstantUtf8 c;
  String name;
  int name_index;
  int length;
  byte tag=Constants.ATTR_UNKNOWN;
  name_index=(int)file.readUnsignedShort();
  c=(ConstantUtf8)constant_pool.getConstant(name_index,Constants.CONSTANT_Utf8);
  name=c.getBytes();
  length=file.readInt();
  for (byte i=0; i < Constants.KNOWN_ATTRIBUTES; i++) {
    if (name.equals(Constants.ATTRIBUTE_NAMES[i])) {
      tag=i;
      break;
    }
  }
switch (tag) {
case Constants.ATTR_UNKNOWN:
    AttributeReader r=(AttributeReader)readers.get(name);
  if (r != null)   return r.createAttribute(name_index,length,file,constant_pool);
 else   return new Unknown(name_index,length,file,constant_pool);
case Constants.ATTR_CONSTANT_VALUE:
return new ConstantValue(name_index,length,file,constant_pool);
case Constants.ATTR_SOURCE_FILE:
return new SourceFile(name_index,length,file,constant_pool);
case Constants.ATTR_CODE:
return new Code(name_index,length,file,constant_pool);
case Constants.ATTR_EXCEPTIONS:
return new ExceptionTable(name_index,length,file,constant_pool);
case Constants.ATTR_LINE_NUMBER_TABLE:
return new LineNumberTable(name_index,length,file,constant_pool);
case Constants.ATTR_LOCAL_VARIABLE_TABLE:
return new LocalVariableTable(name_index,length,file,constant_pool);
case Constants.ATTR_LOCAL_VARIABLE_TYPE_TABLE:
return new LocalVariableTypeTable(name_index,length,file,constant_pool);
case Constants.ATTR_INNER_CLASSES:
return new InnerClasses(name_index,length,file,constant_pool);
case Constants.ATTR_SYNTHETIC:
return new Synthetic(name_index,length,file,constant_pool);
case Constants.ATTR_DEPRECATED:
return new Deprecated(name_index,length,file,constant_pool);
case Constants.ATTR_PMG:
return new PMGClass(name_index,length,file,constant_pool);
case Constants.ATTR_SIGNATURE:
return new Signature(name_index,length,file,constant_pool);
case Constants.ATTR_STACK_MAP:
return new StackMap(name_index,length,file,constant_pool);
default :
throw new IllegalStateException(""String_Node_Str"");
}
}"
37093,"/** 
 * Instantiate from existing method.
 * @param m method
 * @param class_name class name containing this method
 * @param cp constant pool
 */
public MethodGen(Method m,String class_name,ConstantPoolGen cp){
  this(m.getAccessFlags(),Type.getReturnType(m.getSignature()),Type.getArgumentTypes(m.getSignature()),null,m.getName(),class_name,((m.getAccessFlags() & (Constants.ACC_ABSTRACT | Constants.ACC_NATIVE)) == 0) ? new InstructionList(m.getCode().getCode()) : null,cp);
  Attribute[] attributes=m.getAttributes();
  for (int i=0; i < attributes.length; i++) {
    Attribute a=attributes[i];
    if (a instanceof Code) {
      Code c=(Code)a;
      setMaxStack(c.getMaxStack());
      setMaxLocals(c.getMaxLocals());
      CodeException[] ces=c.getExceptionTable();
      if (ces != null) {
        for (int j=0; j < ces.length; j++) {
          CodeException ce=ces[j];
          int type=ce.getCatchType();
          ObjectType c_type=null;
          if (type > 0) {
            String cen=m.getConstantPool().getConstantString(type,Constants.CONSTANT_Class);
            c_type=new ObjectType(cen);
          }
          int end_pc=ce.getEndPC();
          int length=m.getCode().getCode().length;
          InstructionHandle end;
          if (length == end_pc) {
            end=il.getEnd();
          }
 else {
            end=il.findHandle(end_pc);
            end=end.getPrev();
          }
          addExceptionHandler(il.findHandle(ce.getStartPC()),end,il.findHandle(ce.getHandlerPC()),c_type);
        }
      }
      Attribute[] c_attributes=c.getAttributes();
      for (int j=0; j < c_attributes.length; j++) {
        a=c_attributes[j];
        if (a instanceof LineNumberTable) {
          LineNumber[] ln=((LineNumberTable)a).getLineNumberTable();
          for (int k=0; k < ln.length; k++) {
            LineNumber l=ln[k];
            addLineNumber(il.findHandle(l.getStartPC()),l.getLineNumber());
          }
        }
 else         if (a instanceof LocalVariableTable) {
          LocalVariable[] lv=((LocalVariableTable)a).getLocalVariableTable();
          removeLocalVariables();
          for (int k=0; k < lv.length; k++) {
            LocalVariable l=lv[k];
            InstructionHandle start=il.findHandle(l.getStartPC());
            InstructionHandle end=il.findHandle(l.getStartPC() + l.getLength());
            if (null == start) {
              start=il.getStart();
            }
            if (null == end) {
              end=il.getEnd();
            }
            addLocalVariable(l.getName(),Type.getType(l.getSignature()),l.getIndex(),start,end);
          }
        }
 else         addCodeAttribute(a);
      }
    }
 else     if (a instanceof ExceptionTable) {
      String[] names=((ExceptionTable)a).getExceptionNames();
      for (int j=0; j < names.length; j++)       addException(names[j]);
    }
 else     addAttribute(a);
  }
}","/** 
 * Instantiate from existing method.
 * @param m method
 * @param class_name class name containing this method
 * @param cp constant pool
 */
public MethodGen(Method m,String class_name,ConstantPoolGen cp){
  this(m.getAccessFlags(),Type.getReturnType(m.getSignature()),Type.getArgumentTypes(m.getSignature()),null,m.getName(),class_name,((m.getAccessFlags() & (Constants.ACC_ABSTRACT | Constants.ACC_NATIVE)) == 0) ? new InstructionList(m.getCode().getCode()) : null,cp);
  Attribute[] attributes=m.getAttributes();
  for (int i=0; i < attributes.length; i++) {
    Attribute a=attributes[i];
    if (a instanceof Code) {
      Code c=(Code)a;
      setMaxStack(c.getMaxStack());
      setMaxLocals(c.getMaxLocals());
      CodeException[] ces=c.getExceptionTable();
      if (ces != null) {
        for (int j=0; j < ces.length; j++) {
          CodeException ce=ces[j];
          int type=ce.getCatchType();
          ObjectType c_type=null;
          if (type > 0) {
            String cen=m.getConstantPool().getConstantString(type,Constants.CONSTANT_Class);
            c_type=new ObjectType(cen);
          }
          int end_pc=ce.getEndPC();
          int length=m.getCode().getCode().length;
          InstructionHandle end;
          if (length == end_pc) {
            end=il.getEnd();
          }
 else {
            end=il.findHandle(end_pc);
            end=end.getPrev();
          }
          addExceptionHandler(il.findHandle(ce.getStartPC()),end,il.findHandle(ce.getHandlerPC()),c_type);
        }
      }
      Attribute[] c_attributes=c.getAttributes();
      for (int j=0; j < c_attributes.length; j++) {
        a=c_attributes[j];
        if (a instanceof LineNumberTable) {
          LineNumber[] ln=((LineNumberTable)a).getLineNumberTable();
          for (int k=0; k < ln.length; k++) {
            LineNumber l=ln[k];
            addLineNumber(il.findHandle(l.getStartPC()),l.getLineNumber());
          }
        }
 else         if (a instanceof LocalVariableTable) {
          LocalVariable[] lv=((LocalVariableTable)a).getLocalVariableTable();
          removeLocalVariables();
          for (int k=0; k < lv.length; k++) {
            LocalVariable l=lv[k];
            InstructionHandle start=il.findHandle(l.getStartPC());
            InstructionHandle end=il.findHandle(l.getStartPC() + l.getLength());
            if (null == start) {
              start=il.getStart();
            }
            if (null == end) {
              end=il.getEnd();
            }
            addLocalVariable(l.getName(),Type.getType(l.getSignature()),l.getIndex(),start,end);
          }
        }
 else         if (a instanceof LocalVariableTypeTable) {
          LocalVariable[] lv=((LocalVariableTypeTable)a).getLocalVariableTypeTable();
          removeLocalVariables();
          for (int k=0; k < lv.length; k++) {
            LocalVariable l=lv[k];
            InstructionHandle start=il.findHandle(l.getStartPC());
            InstructionHandle end=il.findHandle(l.getStartPC() + l.getLength());
            if (null == start) {
              start=il.getStart();
            }
            if (null == end) {
              end=il.getEnd();
            }
            addLocalVariable(l.getName(),Type.getType(l.getSignature()),l.getIndex(),start,end);
          }
        }
 else         addCodeAttribute(a);
      }
    }
 else     if (a instanceof ExceptionTable) {
      String[] names=((ExceptionTable)a).getExceptionNames();
      for (int j=0; j < names.length; j++)       addException(names[j]);
    }
 else     addAttribute(a);
  }
}"
37094,"@Override public Symbol access(Name name,TypeSymbol location){
  return types.createErrorType(name,location,syms.errSymbol.type).tsym;
}","@Override protected Symbol access(Name name,TypeSymbol location){
  return ambiguousSyms.last();
}"
37095,"Symbol mostSpecific(List<Type> argtypes,Symbol m1,Symbol m2,Env<AttrContext> env,final Type site,boolean allowBoxing,boolean useVarargs){
switch (m2.kind) {
case MTH:
    if (m1 == m2)     return m1;
  boolean m1SignatureMoreSpecific=signatureMoreSpecific(argtypes,env,site,m1,m2,allowBoxing,useVarargs);
boolean m2SignatureMoreSpecific=signatureMoreSpecific(argtypes,env,site,m2,m1,allowBoxing,useVarargs);
if (m1SignatureMoreSpecific && m2SignatureMoreSpecific) {
Type mt1=types.memberType(site,m1);
Type mt2=types.memberType(site,m2);
if (!types.overrideEquivalent(mt1,mt2)) return ambiguityError(m1,m2);
if ((m1.flags() & BRIDGE) != (m2.flags() & BRIDGE)) return ((m1.flags() & BRIDGE) != 0) ? m2 : m1;
TypeSymbol m1Owner=(TypeSymbol)m1.owner;
TypeSymbol m2Owner=(TypeSymbol)m2.owner;
if (types.asSuper(m1Owner.type,m2Owner) != null && ((m1.owner.flags_field & INTERFACE) == 0 || (m2.owner.flags_field & INTERFACE) != 0) && m1.overrides(m2,m1Owner,types,false)) return m1;
if (types.asSuper(m2Owner.type,m1Owner) != null && ((m2.owner.flags_field & INTERFACE) == 0 || (m1.owner.flags_field & INTERFACE) != 0) && m2.overrides(m1,m2Owner,types,false)) return m2;
boolean m1Abstract=(m1.flags() & ABSTRACT) != 0;
boolean m2Abstract=(m2.flags() & ABSTRACT) != 0;
if (m1Abstract && !m2Abstract) return m2;
if (m2Abstract && !m1Abstract) return m1;
if (!m1Abstract && !m2Abstract) return ambiguityError(m1,m2);
if (!types.isSameTypes(m1.erasure(types).getParameterTypes(),m2.erasure(types).getParameterTypes())) return ambiguityError(m1,m2);
Type mst=mostSpecificReturnType(mt1,mt2);
if (mst == null) {
  return ambiguityError(m1,m2);
}
Symbol mostSpecific=mst == mt1 ? m1 : m2;
List<Type> allThrown=chk.intersect(mt1.getThrownTypes(),mt2.getThrownTypes());
Type newSig=types.createMethodTypeWithThrown(mostSpecific.type,allThrown);
MethodSymbol result=new MethodSymbol(mostSpecific.flags(),mostSpecific.name,newSig,mostSpecific.owner){
  @Override public MethodSymbol implementation(  TypeSymbol origin,  Types types,  boolean checkResult){
    if (origin == site.tsym)     return this;
 else     return super.implementation(origin,types,checkResult);
  }
}
;
return result;
}
if (m1SignatureMoreSpecific) return m1;
if (m2SignatureMoreSpecific) return m2;
return ambiguityError(m1,m2);
case AMBIGUOUS:
AmbiguityError e=(AmbiguityError)m2;
Symbol err1=mostSpecific(argtypes,m1,e.sym,env,site,allowBoxing,useVarargs);
Symbol err2=mostSpecific(argtypes,m1,e.sym2,env,site,allowBoxing,useVarargs);
if (err1 == err2) return err1;
if (err1 == e.sym && err2 == e.sym2) return m2;
if (err1 instanceof AmbiguityError && err2 instanceof AmbiguityError && ((AmbiguityError)err1).sym == ((AmbiguityError)err2).sym) return ambiguityError(m1,m2);
 else return ambiguityError(err1,err2);
default :
throw new AssertionError();
}
}","Symbol mostSpecific(List<Type> argtypes,Symbol m1,Symbol m2,Env<AttrContext> env,final Type site,boolean allowBoxing,boolean useVarargs){
switch (m2.kind) {
case MTH:
    if (m1 == m2)     return m1;
  boolean m1SignatureMoreSpecific=signatureMoreSpecific(argtypes,env,site,m1,m2,allowBoxing,useVarargs);
boolean m2SignatureMoreSpecific=signatureMoreSpecific(argtypes,env,site,m2,m1,allowBoxing,useVarargs);
if (m1SignatureMoreSpecific && m2SignatureMoreSpecific) {
Type mt1=types.memberType(site,m1);
Type mt2=types.memberType(site,m2);
if (!types.overrideEquivalent(mt1,mt2)) return ambiguityError(m1,m2);
if ((m1.flags() & BRIDGE) != (m2.flags() & BRIDGE)) return ((m1.flags() & BRIDGE) != 0) ? m2 : m1;
TypeSymbol m1Owner=(TypeSymbol)m1.owner;
TypeSymbol m2Owner=(TypeSymbol)m2.owner;
if (types.asSuper(m1Owner.type,m2Owner) != null && ((m1.owner.flags_field & INTERFACE) == 0 || (m2.owner.flags_field & INTERFACE) != 0) && m1.overrides(m2,m1Owner,types,false)) return m1;
if (types.asSuper(m2Owner.type,m1Owner) != null && ((m2.owner.flags_field & INTERFACE) == 0 || (m1.owner.flags_field & INTERFACE) != 0) && m2.overrides(m1,m2Owner,types,false)) return m2;
boolean m1Abstract=(m1.flags() & ABSTRACT) != 0;
boolean m2Abstract=(m2.flags() & ABSTRACT) != 0;
if (m1Abstract && !m2Abstract) return m2;
if (m2Abstract && !m1Abstract) return m1;
return ambiguityError(m1,m2);
}
if (m1SignatureMoreSpecific) return m1;
if (m2SignatureMoreSpecific) return m2;
return ambiguityError(m1,m2);
case AMBIGUOUS:
AmbiguityError e=(AmbiguityError)m2;
for (Symbol s : e.ambiguousSyms) {
if (mostSpecific(argtypes,m1,s,env,site,allowBoxing,useVarargs) != m1) {
return e.addAmbiguousSymbol(m1);
}
}
return m1;
default :
throw new AssertionError();
}
}"
37096,"AmbiguityError(Symbol sym1,Symbol sym2){
  super(AMBIGUOUS,sym1,""String_Node_Str"");
  this.sym2=sym2;
}","AmbiguityError(Symbol sym1,Symbol sym2){
  super(AMBIGUOUS,""String_Node_Str"");
  ambiguousSyms=flatten(sym2).appendList(flatten(sym1));
}"
37097,"@Override JCDiagnostic getDiagnostic(JCDiagnostic.DiagnosticType dkind,DiagnosticPosition pos,Symbol location,Type site,Name name,List<Type> argtypes,List<Type> typeargtypes){
  AmbiguityError pair=this;
  while (true) {
    if (pair.sym.kind == AMBIGUOUS)     pair=(AmbiguityError)pair.sym;
 else     if (pair.sym2.kind == AMBIGUOUS)     pair=(AmbiguityError)pair.sym2;
 else     break;
  }
  Name sname=pair.sym.name;
  if (sname == names.init)   sname=pair.sym.owner.name;
  return diags.create(dkind,log.currentSource(),pos,""String_Node_Str"",sname,kindName(pair.sym),pair.sym,pair.sym.location(site,types),kindName(pair.sym2),pair.sym2,pair.sym2.location(site,types));
}","@Override JCDiagnostic getDiagnostic(JCDiagnostic.DiagnosticType dkind,DiagnosticPosition pos,Symbol location,Type site,Name name,List<Type> argtypes,List<Type> typeargtypes){
  List<Symbol> diagSyms=ambiguousSyms.reverse();
  Symbol s1=diagSyms.head;
  Symbol s2=diagSyms.tail.head;
  Name sname=s1.name;
  if (sname == names.init)   sname=s1.owner.name;
  return diags.create(dkind,log.currentSource(),pos,""String_Node_Str"",sname,kindName(s1),s1,s1.location(site,types),kindName(s2),s2,s2.location(site,types));
}"
37098,"@Override public boolean exists(){
  return false;
}","@Override public boolean exists(){
  return true;
}"
37099,"@Override public Symbol access(Name name,TypeSymbol location){
  return types.createErrorType(name,location,syms.errSymbol.type).tsym;
}","@Override protected Symbol access(Name name,TypeSymbol location){
  return ambiguousSyms.last();
}"
37100,"Symbol mostSpecific(List<Type> argtypes,Symbol m1,Symbol m2,Env<AttrContext> env,final Type site,boolean allowBoxing,boolean useVarargs){
switch (m2.kind) {
case MTH:
    if (m1 == m2)     return m1;
  boolean m1SignatureMoreSpecific=signatureMoreSpecific(argtypes,env,site,m1,m2,allowBoxing,useVarargs);
boolean m2SignatureMoreSpecific=signatureMoreSpecific(argtypes,env,site,m2,m1,allowBoxing,useVarargs);
if (m1SignatureMoreSpecific && m2SignatureMoreSpecific) {
Type mt1=types.memberType(site,m1);
Type mt2=types.memberType(site,m2);
if (!types.overrideEquivalent(mt1,mt2)) return ambiguityError(m1,m2);
if ((m1.flags() & BRIDGE) != (m2.flags() & BRIDGE)) return ((m1.flags() & BRIDGE) != 0) ? m2 : m1;
TypeSymbol m1Owner=(TypeSymbol)m1.owner;
TypeSymbol m2Owner=(TypeSymbol)m2.owner;
if (types.asSuper(m1Owner.type,m2Owner) != null && ((m1.owner.flags_field & INTERFACE) == 0 || (m2.owner.flags_field & INTERFACE) != 0) && m1.overrides(m2,m1Owner,types,false)) return m1;
if (types.asSuper(m2Owner.type,m1Owner) != null && ((m2.owner.flags_field & INTERFACE) == 0 || (m1.owner.flags_field & INTERFACE) != 0) && m2.overrides(m1,m2Owner,types,false)) return m2;
boolean m1Abstract=(m1.flags() & ABSTRACT) != 0;
boolean m2Abstract=(m2.flags() & ABSTRACT) != 0;
if (m1Abstract && !m2Abstract) return m2;
if (m2Abstract && !m1Abstract) return m1;
if (!m1Abstract && !m2Abstract) return ambiguityError(m1,m2);
if (!types.isSameTypes(m1.erasure(types).getParameterTypes(),m2.erasure(types).getParameterTypes())) return ambiguityError(m1,m2);
Type mst=mostSpecificReturnType(mt1,mt2);
if (mst == null) {
  return ambiguityError(m1,m2);
}
Symbol mostSpecific=mst == mt1 ? m1 : m2;
List<Type> allThrown=chk.intersect(mt1.getThrownTypes(),mt2.getThrownTypes());
Type newSig=types.createMethodTypeWithThrown(mostSpecific.type,allThrown);
MethodSymbol result=new MethodSymbol(mostSpecific.flags(),mostSpecific.name,newSig,mostSpecific.owner){
  @Override public MethodSymbol implementation(  TypeSymbol origin,  Types types,  boolean checkResult){
    if (origin == site.tsym)     return this;
 else     return super.implementation(origin,types,checkResult);
  }
}
;
return result;
}
if (m1SignatureMoreSpecific) return m1;
if (m2SignatureMoreSpecific) return m2;
return ambiguityError(m1,m2);
case AMBIGUOUS:
AmbiguityError e=(AmbiguityError)m2;
Symbol err1=mostSpecific(argtypes,m1,e.sym,env,site,allowBoxing,useVarargs);
Symbol err2=mostSpecific(argtypes,m1,e.sym2,env,site,allowBoxing,useVarargs);
if (err1 == err2) return err1;
if (err1 == e.sym && err2 == e.sym2) return m2;
if (err1 instanceof AmbiguityError && err2 instanceof AmbiguityError && ((AmbiguityError)err1).sym == ((AmbiguityError)err2).sym) return ambiguityError(m1,m2);
 else return ambiguityError(err1,err2);
default :
throw new AssertionError();
}
}","Symbol mostSpecific(List<Type> argtypes,Symbol m1,Symbol m2,Env<AttrContext> env,final Type site,boolean allowBoxing,boolean useVarargs){
switch (m2.kind) {
case MTH:
    if (m1 == m2)     return m1;
  boolean m1SignatureMoreSpecific=signatureMoreSpecific(argtypes,env,site,m1,m2,allowBoxing,useVarargs);
boolean m2SignatureMoreSpecific=signatureMoreSpecific(argtypes,env,site,m2,m1,allowBoxing,useVarargs);
if (m1SignatureMoreSpecific && m2SignatureMoreSpecific) {
Type mt1=types.memberType(site,m1);
Type mt2=types.memberType(site,m2);
if (!types.overrideEquivalent(mt1,mt2)) return ambiguityError(m1,m2);
if ((m1.flags() & BRIDGE) != (m2.flags() & BRIDGE)) return ((m1.flags() & BRIDGE) != 0) ? m2 : m1;
TypeSymbol m1Owner=(TypeSymbol)m1.owner;
TypeSymbol m2Owner=(TypeSymbol)m2.owner;
if (types.asSuper(m1Owner.type,m2Owner) != null && ((m1.owner.flags_field & INTERFACE) == 0 || (m2.owner.flags_field & INTERFACE) != 0) && m1.overrides(m2,m1Owner,types,false)) return m1;
if (types.asSuper(m2Owner.type,m1Owner) != null && ((m2.owner.flags_field & INTERFACE) == 0 || (m1.owner.flags_field & INTERFACE) != 0) && m2.overrides(m1,m2Owner,types,false)) return m2;
boolean m1Abstract=(m1.flags() & ABSTRACT) != 0;
boolean m2Abstract=(m2.flags() & ABSTRACT) != 0;
if (m1Abstract && !m2Abstract) return m2;
if (m2Abstract && !m1Abstract) return m1;
return ambiguityError(m1,m2);
}
if (m1SignatureMoreSpecific) return m1;
if (m2SignatureMoreSpecific) return m2;
return ambiguityError(m1,m2);
case AMBIGUOUS:
AmbiguityError e=(AmbiguityError)m2;
for (Symbol s : e.ambiguousSyms) {
if (mostSpecific(argtypes,m1,s,env,site,allowBoxing,useVarargs) != m1) {
return e.addAmbiguousSymbol(m1);
}
}
return m1;
default :
throw new AssertionError();
}
}"
37101,"AmbiguityError(Symbol sym1,Symbol sym2){
  super(AMBIGUOUS,sym1,""String_Node_Str"");
  this.sym2=sym2;
}","AmbiguityError(Symbol sym1,Symbol sym2){
  super(AMBIGUOUS,""String_Node_Str"");
  ambiguousSyms=flatten(sym2).appendList(flatten(sym1));
}"
37102,"@Override JCDiagnostic getDiagnostic(JCDiagnostic.DiagnosticType dkind,DiagnosticPosition pos,Symbol location,Type site,Name name,List<Type> argtypes,List<Type> typeargtypes){
  AmbiguityError pair=this;
  while (true) {
    if (pair.sym.kind == AMBIGUOUS)     pair=(AmbiguityError)pair.sym;
 else     if (pair.sym2.kind == AMBIGUOUS)     pair=(AmbiguityError)pair.sym2;
 else     break;
  }
  Name sname=pair.sym.name;
  if (sname == names.init)   sname=pair.sym.owner.name;
  return diags.create(dkind,log.currentSource(),pos,""String_Node_Str"",sname,kindName(pair.sym),pair.sym,pair.sym.location(site,types),kindName(pair.sym2),pair.sym2,pair.sym2.location(site,types));
}","@Override JCDiagnostic getDiagnostic(JCDiagnostic.DiagnosticType dkind,DiagnosticPosition pos,Symbol location,Type site,Name name,List<Type> argtypes,List<Type> typeargtypes){
  List<Symbol> diagSyms=ambiguousSyms.reverse();
  Symbol s1=diagSyms.head;
  Symbol s2=diagSyms.tail.head;
  Name sname=s1.name;
  if (sname == names.init)   sname=s1.owner.name;
  return diags.create(dkind,log.currentSource(),pos,""String_Node_Str"",sname,kindName(s1),s1,s1.location(site,types),kindName(s2),s2,s2.location(site,types));
}"
37103,"@Override public boolean exists(){
  return false;
}","@Override public boolean exists(){
  return true;
}"
37104,"/** 
 * Construct the SplitIndexWriter. Uses path to this file and relative path from this file.
 * @param path       Path to the file which is getting generated.
 * @param filename   Name of the file which is getting genrated.
 * @param relpath    Relative path from this file to the current directory.
 * @param indexbuilder Unicode based Index from {@link IndexBuilder}
 */
public SplitIndexWriter(ConfigurationImpl configuration,DocPath path,IndexBuilder indexbuilder,int prev,int next) throws IOException {
  super(configuration,path,indexbuilder);
  this.prev=prev;
  this.next=next;
}","/** 
 * Construct the SplitIndexWriter. Uses path to this file and relative path from this file.
 * @param path       Path to the file which is getting generated.
 * @param indexbuilder Unicode based Index from {@link IndexBuilder}
 */
public SplitIndexWriter(ConfigurationImpl configuration,DocPath path,IndexBuilder indexbuilder,int prev,int next) throws IOException {
  super(configuration,path,indexbuilder);
  this.prev=prev;
  this.next=next;
}"
37105,"/** 
 * Constructor.
 * @param path The directory path to be created for this fileor null if none to be created.
 * @param filename File Name to which the PrintWriter willdo the Output.
 * @exception IOException Exception raised by the FileWriter is passed onto next level.
 * @exception UnsupportedEncodingException Exception raised by theOutputStreamWriter is passed on to next level.
 */
public HtmlWriter(Configuration configuration,DocPath path) throws IOException, UnsupportedEncodingException {
  writer=Util.genWriter(configuration,path);
  this.configuration=configuration;
  this.memberDetailsListPrinted=false;
  packageTableHeader=new String[]{configuration.getText(""String_Node_Str""),configuration.getText(""String_Node_Str"")};
  useTableSummary=configuration.getText(""String_Node_Str"",configuration.getText(""String_Node_Str""));
  modifierTypeHeader=configuration.getText(""String_Node_Str"",configuration.getText(""String_Node_Str""),configuration.getText(""String_Node_Str""));
  overviewLabel=getResource(""String_Node_Str"");
  defaultPackageLabel=new RawHtml(DocletConstants.DEFAULT_PACKAGE_NAME);
  packageLabel=getResource(""String_Node_Str"");
  useLabel=getResource(""String_Node_Str"");
  prevLabel=getResource(""String_Node_Str"");
  nextLabel=getResource(""String_Node_Str"");
  prevclassLabel=getResource(""String_Node_Str"");
  nextclassLabel=getResource(""String_Node_Str"");
  summaryLabel=getResource(""String_Node_Str"");
  detailLabel=getResource(""String_Node_Str"");
  framesLabel=getResource(""String_Node_Str"");
  noframesLabel=getResource(""String_Node_Str"");
  treeLabel=getResource(""String_Node_Str"");
  classLabel=getResource(""String_Node_Str"");
  deprecatedLabel=getResource(""String_Node_Str"");
  deprecatedPhrase=getResource(""String_Node_Str"");
  allclassesLabel=getResource(""String_Node_Str"");
  indexLabel=getResource(""String_Node_Str"");
  helpLabel=getResource(""String_Node_Str"");
  seeLabel=getResource(""String_Node_Str"");
  descriptionLabel=getResource(""String_Node_Str"");
  prevpackageLabel=getResource(""String_Node_Str"");
  nextpackageLabel=getResource(""String_Node_Str"");
  packagesLabel=getResource(""String_Node_Str"");
  methodDetailsLabel=getResource(""String_Node_Str"");
  annotationTypeDetailsLabel=getResource(""String_Node_Str"");
  fieldDetailsLabel=getResource(""String_Node_Str"");
  constructorDetailsLabel=getResource(""String_Node_Str"");
  enumConstantsDetailsLabel=getResource(""String_Node_Str"");
  specifiedByLabel=getResource(""String_Node_Str"");
  overridesLabel=getResource(""String_Node_Str"");
  descfrmClassLabel=getResource(""String_Node_Str"");
  descfrmInterfaceLabel=getResource(""String_Node_Str"");
}","/** 
 * Constructor.
 * @param path The directory path to be created for this fileor null if none to be created.
 * @exception IOException Exception raised by the FileWriter is passed onto next level.
 * @exception UnsupportedEncodingException Exception raised by theOutputStreamWriter is passed on to next level.
 */
public HtmlWriter(Configuration configuration,DocPath path) throws IOException, UnsupportedEncodingException {
  writer=Util.genWriter(configuration,path);
  this.configuration=configuration;
  this.memberDetailsListPrinted=false;
  packageTableHeader=new String[]{configuration.getText(""String_Node_Str""),configuration.getText(""String_Node_Str"")};
  useTableSummary=configuration.getText(""String_Node_Str"",configuration.getText(""String_Node_Str""));
  modifierTypeHeader=configuration.getText(""String_Node_Str"",configuration.getText(""String_Node_Str""),configuration.getText(""String_Node_Str""));
  overviewLabel=getResource(""String_Node_Str"");
  defaultPackageLabel=new RawHtml(DocletConstants.DEFAULT_PACKAGE_NAME);
  packageLabel=getResource(""String_Node_Str"");
  useLabel=getResource(""String_Node_Str"");
  prevLabel=getResource(""String_Node_Str"");
  nextLabel=getResource(""String_Node_Str"");
  prevclassLabel=getResource(""String_Node_Str"");
  nextclassLabel=getResource(""String_Node_Str"");
  summaryLabel=getResource(""String_Node_Str"");
  detailLabel=getResource(""String_Node_Str"");
  framesLabel=getResource(""String_Node_Str"");
  noframesLabel=getResource(""String_Node_Str"");
  treeLabel=getResource(""String_Node_Str"");
  classLabel=getResource(""String_Node_Str"");
  deprecatedLabel=getResource(""String_Node_Str"");
  deprecatedPhrase=getResource(""String_Node_Str"");
  allclassesLabel=getResource(""String_Node_Str"");
  indexLabel=getResource(""String_Node_Str"");
  helpLabel=getResource(""String_Node_Str"");
  seeLabel=getResource(""String_Node_Str"");
  descriptionLabel=getResource(""String_Node_Str"");
  prevpackageLabel=getResource(""String_Node_Str"");
  nextpackageLabel=getResource(""String_Node_Str"");
  packagesLabel=getResource(""String_Node_Str"");
  methodDetailsLabel=getResource(""String_Node_Str"");
  annotationTypeDetailsLabel=getResource(""String_Node_Str"");
  fieldDetailsLabel=getResource(""String_Node_Str"");
  constructorDetailsLabel=getResource(""String_Node_Str"");
  enumConstantsDetailsLabel=getResource(""String_Node_Str"");
  specifiedByLabel=getResource(""String_Node_Str"");
  overridesLabel=getResource(""String_Node_Str"");
  descfrmClassLabel=getResource(""String_Node_Str"");
  descfrmInterfaceLabel=getResource(""String_Node_Str"");
}"
37106,"/** 
 * @inheritDoc 
 */
@Override public int hashCode(){
  return path.hashCode();
}","/** 
 * {@inheritDoc} 
 */
@Override public int hashCode(){
  return path.hashCode();
}"
37107,"/** 
 * @inheritDoc 
 */
@Override public boolean equals(Object other){
  return (other instanceof DocPath) && path.equals(((DocPath)other).path);
}","/** 
 * {@inheritDoc} 
 */
@Override public boolean equals(Object other){
  return (other instanceof DocPath) && path.equals(((DocPath)other).path);
}"
37108,"/** 
 * Find the specified directory in the source path.
 * @param name Name of the directory to be searched for in the source path.
 * @return File Return the directory if found else return null.
 */
public File getDirectory(DocPath p){
  for (int i=0; i < sourcePath.length; i++) {
    File directoryNeeded=new File(sourcePath[i],p.getPath());
    if (directoryNeeded.isDirectory()) {
      return directoryNeeded;
    }
  }
  return null;
}","/** 
 * Find the specified directory in the source path.
 * @param p Name of the directory to be searched for in the source path.
 * @return File Return the directory if found else return null.
 */
public File getDirectory(DocPath p){
  for (int i=0; i < sourcePath.length; i++) {
    File directoryNeeded=new File(sourcePath[i],p.getPath());
    if (directoryNeeded.isDirectory()) {
      return directoryNeeded;
    }
  }
  return null;
}"
37109,"/** 
 * Create the directory path for the file to be generated, construct FileOutputStream and OutputStreamWriter depending upon docencoding.
 * @param path The directory path to be created for this file.
 * @param filename File Name to which the PrintWriter will do the Output.
 * @param docencoding Encoding to be used for this file.
 * @exception IOException Exception raised by the FileWriter is passed onto next level.
 * @exception UnsupportedEncodingException Exception raised by theOutputStreamWriter is passed on to next level.
 * @return Writer Writer for the file getting generated.
 * @see java.io.FileOutputStream
 * @see java.io.OutputStreamWriter
 */
public static Writer genWriter(Configuration configuration,DocPath path) throws IOException, UnsupportedEncodingException {
  File file=path.resolveAgainst(configuration.destDirName);
  createDirectory(configuration,file.getParentFile());
  FileOutputStream fos=new FileOutputStream(file);
  if (configuration.docencoding == null) {
    return new BufferedWriter(new OutputStreamWriter(fos));
  }
 else {
    return new BufferedWriter(new OutputStreamWriter(fos,configuration.docencoding));
  }
}","/** 
 * Create the directory path for the file to be generated, construct FileOutputStream and OutputStreamWriter depending upon docencoding.
 * @param path The directory path to be created for this file.
 * @exception IOException Exception raised by the FileWriter is passed onto next level.
 * @exception UnsupportedEncodingException Exception raised by theOutputStreamWriter is passed on to next level.
 * @return Writer Writer for the file getting generated.
 * @see java.io.FileOutputStream
 * @see java.io.OutputStreamWriter
 */
public static Writer genWriter(Configuration configuration,DocPath path) throws IOException, UnsupportedEncodingException {
  File file=path.resolveAgainst(configuration.destDirName);
  createDirectory(configuration,file.getParentFile());
  FileOutputStream fos=new FileOutputStream(file);
  if (configuration.docencoding == null) {
    return new BufferedWriter(new OutputStreamWriter(fos));
  }
 else {
    return new BufferedWriter(new OutputStreamWriter(fos,configuration.docencoding));
  }
}"
37110,"/** 
 * Given a path string create all the directories in the path. For example, if the path string is ""java/applet"", the method will create directory ""java"" and then ""java/applet"" if they don't exist. The file separator string ""/"" is platform dependent system property.
 * @param path Directory path string.
 */
public static void createDirectory(Configuration configuration,File dir){
  if (dir == null) {
    return;
  }
  if (dir.exists()) {
    return;
  }
 else {
    if (dir.mkdirs()) {
      return;
    }
 else {
      configuration.message.error(""String_Node_Str"",dir.getPath());
      throw new DocletAbortException();
    }
  }
}","/** 
 * Given a path string create all the directories in the path. For example, if the path string is ""java/applet"", the method will create directory ""java"" and then ""java/applet"" if they don't exist. The file separator string ""/"" is platform dependent system property.
 * @param dir Directory path string.
 */
public static void createDirectory(Configuration configuration,File dir){
  if (dir == null) {
    return;
  }
  if (dir.exists()) {
    return;
  }
 else {
    if (dir.mkdirs()) {
      return;
    }
 else {
      configuration.message.error(""String_Node_Str"",dir.getPath());
      throw new DocletAbortException();
    }
  }
}"
37111,"/** 
 * Construct the SplitIndexWriter. Uses path to this file and relative path from this file.
 * @param path       Path to the file which is getting generated.
 * @param filename   Name of the file which is getting genrated.
 * @param relpath    Relative path from this file to the current directory.
 * @param indexbuilder Unicode based Index from {@link IndexBuilder}
 */
public SplitIndexWriter(ConfigurationImpl configuration,DocPath path,IndexBuilder indexbuilder,int prev,int next) throws IOException {
  super(configuration,path,indexbuilder);
  this.prev=prev;
  this.next=next;
}","/** 
 * Construct the SplitIndexWriter. Uses path to this file and relative path from this file.
 * @param path       Path to the file which is getting generated.
 * @param indexbuilder Unicode based Index from {@link IndexBuilder}
 */
public SplitIndexWriter(ConfigurationImpl configuration,DocPath path,IndexBuilder indexbuilder,int prev,int next) throws IOException {
  super(configuration,path,indexbuilder);
  this.prev=prev;
  this.next=next;
}"
37112,"/** 
 * Constructor.
 * @param path The directory path to be created for this fileor null if none to be created.
 * @param filename File Name to which the PrintWriter willdo the Output.
 * @exception IOException Exception raised by the FileWriter is passed onto next level.
 * @exception UnsupportedEncodingException Exception raised by theOutputStreamWriter is passed on to next level.
 */
public HtmlWriter(Configuration configuration,DocPath path) throws IOException, UnsupportedEncodingException {
  writer=Util.genWriter(configuration,path);
  this.configuration=configuration;
  this.memberDetailsListPrinted=false;
  packageTableHeader=new String[]{configuration.getText(""String_Node_Str""),configuration.getText(""String_Node_Str"")};
  useTableSummary=configuration.getText(""String_Node_Str"",configuration.getText(""String_Node_Str""));
  modifierTypeHeader=configuration.getText(""String_Node_Str"",configuration.getText(""String_Node_Str""),configuration.getText(""String_Node_Str""));
  overviewLabel=getResource(""String_Node_Str"");
  defaultPackageLabel=new RawHtml(DocletConstants.DEFAULT_PACKAGE_NAME);
  packageLabel=getResource(""String_Node_Str"");
  useLabel=getResource(""String_Node_Str"");
  prevLabel=getResource(""String_Node_Str"");
  nextLabel=getResource(""String_Node_Str"");
  prevclassLabel=getResource(""String_Node_Str"");
  nextclassLabel=getResource(""String_Node_Str"");
  summaryLabel=getResource(""String_Node_Str"");
  detailLabel=getResource(""String_Node_Str"");
  framesLabel=getResource(""String_Node_Str"");
  noframesLabel=getResource(""String_Node_Str"");
  treeLabel=getResource(""String_Node_Str"");
  classLabel=getResource(""String_Node_Str"");
  deprecatedLabel=getResource(""String_Node_Str"");
  deprecatedPhrase=getResource(""String_Node_Str"");
  allclassesLabel=getResource(""String_Node_Str"");
  indexLabel=getResource(""String_Node_Str"");
  helpLabel=getResource(""String_Node_Str"");
  seeLabel=getResource(""String_Node_Str"");
  descriptionLabel=getResource(""String_Node_Str"");
  prevpackageLabel=getResource(""String_Node_Str"");
  nextpackageLabel=getResource(""String_Node_Str"");
  packagesLabel=getResource(""String_Node_Str"");
  methodDetailsLabel=getResource(""String_Node_Str"");
  annotationTypeDetailsLabel=getResource(""String_Node_Str"");
  fieldDetailsLabel=getResource(""String_Node_Str"");
  constructorDetailsLabel=getResource(""String_Node_Str"");
  enumConstantsDetailsLabel=getResource(""String_Node_Str"");
  specifiedByLabel=getResource(""String_Node_Str"");
  overridesLabel=getResource(""String_Node_Str"");
  descfrmClassLabel=getResource(""String_Node_Str"");
  descfrmInterfaceLabel=getResource(""String_Node_Str"");
}","/** 
 * Constructor.
 * @param path The directory path to be created for this fileor null if none to be created.
 * @exception IOException Exception raised by the FileWriter is passed onto next level.
 * @exception UnsupportedEncodingException Exception raised by theOutputStreamWriter is passed on to next level.
 */
public HtmlWriter(Configuration configuration,DocPath path) throws IOException, UnsupportedEncodingException {
  writer=Util.genWriter(configuration,path);
  this.configuration=configuration;
  this.memberDetailsListPrinted=false;
  packageTableHeader=new String[]{configuration.getText(""String_Node_Str""),configuration.getText(""String_Node_Str"")};
  useTableSummary=configuration.getText(""String_Node_Str"",configuration.getText(""String_Node_Str""));
  modifierTypeHeader=configuration.getText(""String_Node_Str"",configuration.getText(""String_Node_Str""),configuration.getText(""String_Node_Str""));
  overviewLabel=getResource(""String_Node_Str"");
  defaultPackageLabel=new RawHtml(DocletConstants.DEFAULT_PACKAGE_NAME);
  packageLabel=getResource(""String_Node_Str"");
  useLabel=getResource(""String_Node_Str"");
  prevLabel=getResource(""String_Node_Str"");
  nextLabel=getResource(""String_Node_Str"");
  prevclassLabel=getResource(""String_Node_Str"");
  nextclassLabel=getResource(""String_Node_Str"");
  summaryLabel=getResource(""String_Node_Str"");
  detailLabel=getResource(""String_Node_Str"");
  framesLabel=getResource(""String_Node_Str"");
  noframesLabel=getResource(""String_Node_Str"");
  treeLabel=getResource(""String_Node_Str"");
  classLabel=getResource(""String_Node_Str"");
  deprecatedLabel=getResource(""String_Node_Str"");
  deprecatedPhrase=getResource(""String_Node_Str"");
  allclassesLabel=getResource(""String_Node_Str"");
  indexLabel=getResource(""String_Node_Str"");
  helpLabel=getResource(""String_Node_Str"");
  seeLabel=getResource(""String_Node_Str"");
  descriptionLabel=getResource(""String_Node_Str"");
  prevpackageLabel=getResource(""String_Node_Str"");
  nextpackageLabel=getResource(""String_Node_Str"");
  packagesLabel=getResource(""String_Node_Str"");
  methodDetailsLabel=getResource(""String_Node_Str"");
  annotationTypeDetailsLabel=getResource(""String_Node_Str"");
  fieldDetailsLabel=getResource(""String_Node_Str"");
  constructorDetailsLabel=getResource(""String_Node_Str"");
  enumConstantsDetailsLabel=getResource(""String_Node_Str"");
  specifiedByLabel=getResource(""String_Node_Str"");
  overridesLabel=getResource(""String_Node_Str"");
  descfrmClassLabel=getResource(""String_Node_Str"");
  descfrmInterfaceLabel=getResource(""String_Node_Str"");
}"
37113,"/** 
 * @inheritDoc 
 */
@Override public int hashCode(){
  return path.hashCode();
}","/** 
 * {@inheritDoc} 
 */
@Override public int hashCode(){
  return path.hashCode();
}"
37114,"/** 
 * @inheritDoc 
 */
@Override public boolean equals(Object other){
  return (other instanceof DocPath) && path.equals(((DocPath)other).path);
}","/** 
 * {@inheritDoc} 
 */
@Override public boolean equals(Object other){
  return (other instanceof DocPath) && path.equals(((DocPath)other).path);
}"
37115,"/** 
 * Find the specified directory in the source path.
 * @param name Name of the directory to be searched for in the source path.
 * @return File Return the directory if found else return null.
 */
public File getDirectory(DocPath p){
  for (int i=0; i < sourcePath.length; i++) {
    File directoryNeeded=new File(sourcePath[i],p.getPath());
    if (directoryNeeded.isDirectory()) {
      return directoryNeeded;
    }
  }
  return null;
}","/** 
 * Find the specified directory in the source path.
 * @param p Name of the directory to be searched for in the source path.
 * @return File Return the directory if found else return null.
 */
public File getDirectory(DocPath p){
  for (int i=0; i < sourcePath.length; i++) {
    File directoryNeeded=new File(sourcePath[i],p.getPath());
    if (directoryNeeded.isDirectory()) {
      return directoryNeeded;
    }
  }
  return null;
}"
37116,"/** 
 * Create the directory path for the file to be generated, construct FileOutputStream and OutputStreamWriter depending upon docencoding.
 * @param path The directory path to be created for this file.
 * @param filename File Name to which the PrintWriter will do the Output.
 * @param docencoding Encoding to be used for this file.
 * @exception IOException Exception raised by the FileWriter is passed onto next level.
 * @exception UnsupportedEncodingException Exception raised by theOutputStreamWriter is passed on to next level.
 * @return Writer Writer for the file getting generated.
 * @see java.io.FileOutputStream
 * @see java.io.OutputStreamWriter
 */
public static Writer genWriter(Configuration configuration,DocPath path) throws IOException, UnsupportedEncodingException {
  File file=path.resolveAgainst(configuration.destDirName);
  createDirectory(configuration,file.getParentFile());
  FileOutputStream fos=new FileOutputStream(file);
  if (configuration.docencoding == null) {
    return new BufferedWriter(new OutputStreamWriter(fos));
  }
 else {
    return new BufferedWriter(new OutputStreamWriter(fos,configuration.docencoding));
  }
}","/** 
 * Create the directory path for the file to be generated, construct FileOutputStream and OutputStreamWriter depending upon docencoding.
 * @param path The directory path to be created for this file.
 * @exception IOException Exception raised by the FileWriter is passed onto next level.
 * @exception UnsupportedEncodingException Exception raised by theOutputStreamWriter is passed on to next level.
 * @return Writer Writer for the file getting generated.
 * @see java.io.FileOutputStream
 * @see java.io.OutputStreamWriter
 */
public static Writer genWriter(Configuration configuration,DocPath path) throws IOException, UnsupportedEncodingException {
  File file=path.resolveAgainst(configuration.destDirName);
  createDirectory(configuration,file.getParentFile());
  FileOutputStream fos=new FileOutputStream(file);
  if (configuration.docencoding == null) {
    return new BufferedWriter(new OutputStreamWriter(fos));
  }
 else {
    return new BufferedWriter(new OutputStreamWriter(fos,configuration.docencoding));
  }
}"
37117,"/** 
 * Given a path string create all the directories in the path. For example, if the path string is ""java/applet"", the method will create directory ""java"" and then ""java/applet"" if they don't exist. The file separator string ""/"" is platform dependent system property.
 * @param path Directory path string.
 */
public static void createDirectory(Configuration configuration,File dir){
  if (dir == null) {
    return;
  }
  if (dir.exists()) {
    return;
  }
 else {
    if (dir.mkdirs()) {
      return;
    }
 else {
      configuration.message.error(""String_Node_Str"",dir.getPath());
      throw new DocletAbortException();
    }
  }
}","/** 
 * Given a path string create all the directories in the path. For example, if the path string is ""java/applet"", the method will create directory ""java"" and then ""java/applet"" if they don't exist. The file separator string ""/"" is platform dependent system property.
 * @param dir Directory path string.
 */
public static void createDirectory(Configuration configuration,File dir){
  if (dir == null) {
    return;
  }
  if (dir.exists()) {
    return;
  }
 else {
    if (dir.mkdirs()) {
      return;
    }
 else {
      configuration.message.error(""String_Node_Str"",dir.getPath());
      throw new DocletAbortException();
    }
  }
}"
37118,"/** 
 * Return the kind of this tag. similar or synonymous tags.  For most tags, <code>kind()&nbsp;==&nbsp;name()</code>; the following table lists those cases where there is more than one tag of a given kind: <p> <table border=""1"" cellpadding=""4"" cellspacing=""0""> <tr><th><tt> kind()  </th>  <th><tt> name()      </th></tr> <tr><td><tt> @throws </td>  <td><tt> @throws     </td></tr> <tr><td><tt> @throws </td>  <td><tt> @exception  </td></tr> <tr><td><tt> @see    </td>  <td><tt> @see        </td></tr> <tr><td><tt> @see    </td>  <td><tt> @link       </td></tr> <tr><td><tt> @see    </td>  <td><tt> @linkplain  </td></tr> <tr><td><tt> @serial </td>  <td><tt> @serial     </td></tr> <tr><td><tt> @serial </td>  <td><tt> @serialData </td></tr> </table>
 */
String kind();","/** 
 * Return the kind of this tag. similar or synonymous tags.  For most tags, <code>kind()&nbsp;==&nbsp;name()</code>; the following table lists those cases where there is more than one tag of a given kind: <p> <table border=""1"" cellpadding=""4"" cellspacing=""0""> <tr><th><tt> kind()  </tt></th>  <th><tt> name()      </tt></th></tr> <tr><td><tt> @throws </tt></td>  <td><tt> @throws     </tt></td></tr> <tr><td><tt> @throws </tt></td>  <td><tt> @exception  </tt></td></tr> <tr><td><tt> @see    </tt></td>  <td><tt> @see        </tt></td></tr> <tr><td><tt> @see    </tt></td>  <td><tt> @link       </tt></td></tr> <tr><td><tt> @see    </tt></td>  <td><tt> @linkplain  </tt></td></tr> <tr><td><tt> @serial </tt></td>  <td><tt> @serial     </tt></td></tr> <tr><td><tt> @serial </tt></td>  <td><tt> @serialData </tt></td></tr> </table>
 */
String kind();"
37119,"/** 
 * Get the ClassFile object for a specified class.
 * @param className the name of the class to be returned.
 * @return the ClassFile for the given class
 * @throws Dependencies #ClassFileNotFoundException if the classfile cannot be found
 */
public ClassFile getClassFile(String className) throws ClassFileNotFoundException ;","/** 
 * Get the ClassFile object for a specified class.
 * @param className the name of the class to be returned.
 * @return the ClassFile for the given class
 * @throws Dependencies.ClassFileNotFoundException if the classfile cannot befound
 */
public ClassFile getClassFile(String className) throws ClassFileNotFoundException ;"
37120,"/** 
 * See   {@link Kind#LOCAL_UBYTE}. 
 */
R visitLocalAndValue(Instruction instr,int index,int value,P p);","/** 
 * See   {@link Kind#LOCAL_BYTE}. 
 */
R visitLocalAndValue(Instruction instr,int index,int value,P p);"
37121,"/** 
 * Add all the parameters for the executable member.
 * @param member the member to write parameters for.
 * @param includeAnnotations true if annotation information needs to be added.
 * @param tree the content tree to which the parameters information will be added.
 */
protected void addParameters(ExecutableMemberDoc member,boolean includeAnnotations,Content htmltree){
  htmltree.addContent(""String_Node_Str"");
  Parameter[] params=member.parameters();
  String indent=makeSpace(writer.displayLength);
  if (configuration().linksource) {
    indent+=makeSpace(member.name().length());
  }
  int paramstart;
  for (paramstart=0; paramstart < params.length; paramstart++) {
    Parameter param=params[paramstart];
    if (!param.name().startsWith(""String_Node_Str"")) {
      if (includeAnnotations) {
        boolean foundAnnotations=writer.addAnnotationInfo(indent.length(),member,param,htmltree);
        if (foundAnnotations) {
          htmltree.addContent(DocletConstants.NL);
          htmltree.addContent(indent);
        }
      }
      addParam(member,param,(paramstart == params.length - 1) && member.isVarArgs(),htmltree);
      break;
    }
  }
  for (int i=paramstart + 1; i < params.length; i++) {
    htmltree.addContent(""String_Node_Str"");
    htmltree.addContent(DocletConstants.NL);
    htmltree.addContent(indent);
    if (includeAnnotations) {
      boolean foundAnnotations=writer.addAnnotationInfo(indent.length(),member,params[i],htmltree);
      if (foundAnnotations) {
        htmltree.addContent(DocletConstants.NL);
        htmltree.addContent(indent);
      }
    }
    addParam(member,params[i],(i == params.length - 1) && member.isVarArgs(),htmltree);
  }
  htmltree.addContent(""String_Node_Str"");
}","/** 
 * Add all the parameters for the executable member.
 * @param member the member to write parameters for.
 * @param includeAnnotations true if annotation information needs to be added.
 * @param htmltree the content tree to which the parameters information will be added.
 */
protected void addParameters(ExecutableMemberDoc member,boolean includeAnnotations,Content htmltree){
  htmltree.addContent(""String_Node_Str"");
  Parameter[] params=member.parameters();
  String indent=makeSpace(writer.displayLength);
  if (configuration().linksource) {
    indent+=makeSpace(member.name().length());
  }
  int paramstart;
  for (paramstart=0; paramstart < params.length; paramstart++) {
    Parameter param=params[paramstart];
    if (!param.name().startsWith(""String_Node_Str"")) {
      if (includeAnnotations) {
        boolean foundAnnotations=writer.addAnnotationInfo(indent.length(),member,param,htmltree);
        if (foundAnnotations) {
          htmltree.addContent(DocletConstants.NL);
          htmltree.addContent(indent);
        }
      }
      addParam(member,param,(paramstart == params.length - 1) && member.isVarArgs(),htmltree);
      break;
    }
  }
  for (int i=paramstart + 1; i < params.length; i++) {
    htmltree.addContent(""String_Node_Str"");
    htmltree.addContent(DocletConstants.NL);
    htmltree.addContent(indent);
    if (includeAnnotations) {
      boolean foundAnnotations=writer.addAnnotationInfo(indent.length(),member,params[i],htmltree);
      if (foundAnnotations) {
        htmltree.addContent(DocletConstants.NL);
        htmltree.addContent(indent);
      }
    }
    addParam(member,params[i],(i == params.length - 1) && member.isVarArgs(),htmltree);
  }
  htmltree.addContent(""String_Node_Str"");
}"
37122,"/** 
 * Add the inherited summary link for the member.
 * @param classDoc the classDoc that we should link to
 * @param member the member being linked to
 * @param linksTree the content tree to which the link will be added
 */
protected void addInheritedSummaryLink(ClassDoc cd,ProgramElementDoc member,Content linksTree){
  linksTree.addContent(new RawHtml(writer.getDocLink(LinkInfoImpl.CONTEXT_MEMBER,cd,(MemberDoc)member,member.name(),false)));
}","/** 
 * Add the inherited summary link for the member.
 * @param cd the classDoc that we should link to
 * @param member the member being linked to
 * @param linksTree the content tree to which the link will be added
 */
protected void addInheritedSummaryLink(ClassDoc cd,ProgramElementDoc member,Content linksTree){
  linksTree.addContent(new RawHtml(writer.getDocLink(LinkInfoImpl.CONTEXT_MEMBER,cd,(MemberDoc)member,member.name(),false)));
}"
37123,"/** 
 * Add the summary link for the member.
 * @param context the id of the context where the link will be printed
 * @param classDoc the classDoc that we should link to
 * @param member the member being linked to
 * @param tdSummary the content tree to which the link will be added
 */
protected void addSummaryLink(int context,ClassDoc cd,ProgramElementDoc member,Content tdSummary){
  ExecutableMemberDoc emd=(ExecutableMemberDoc)member;
  String name=emd.name();
  Content strong=HtmlTree.STRONG(new RawHtml(writer.getDocLink(context,cd,(MemberDoc)emd,name,false)));
  Content code=HtmlTree.CODE(strong);
  writer.displayLength=name.length();
  addParameters(emd,false,code);
  tdSummary.addContent(code);
}","/** 
 * Add the summary link for the member.
 * @param context the id of the context where the link will be printed
 * @param cd the classDoc that we should link to
 * @param member the member being linked to
 * @param tdSummary the content tree to which the link will be added
 */
protected void addSummaryLink(int context,ClassDoc cd,ProgramElementDoc member,Content tdSummary){
  ExecutableMemberDoc emd=(ExecutableMemberDoc)member;
  String name=emd.name();
  Content strong=HtmlTree.STRONG(new RawHtml(writer.getDocLink(context,cd,(MemberDoc)emd,name,false)));
  Content code=HtmlTree.CODE(strong);
  writer.displayLength=name.length();
  addParameters(emd,false,code);
  tdSummary.addContent(code);
}"
37124,"/** 
 * Add the comment for the given member.
 * @param member the member being documented.
 * @param contentTree the content tree to which the comment will be added.
 */
protected void addComment(ProgramElementDoc member,Content htmltree){
  if (member.inlineTags().length > 0) {
    writer.addInlineComment(member,htmltree);
  }
}","/** 
 * Add the comment for the given member.
 * @param member the member being documented.
 * @param htmltree the content tree to which the comment will be added.
 */
protected void addComment(ProgramElementDoc member,Content htmltree){
  if (member.inlineTags().length > 0) {
    writer.addInlineComment(member,htmltree);
  }
}"
37125,"/** 
 * Constructor. Initialises resource for the  {@link com.sun.tools.doclets.MessageRetriever}.
 */
private ConfigurationImpl(){
  standardmessage=new MessageRetriever(this,""String_Node_Str"");
}","/** 
 * Constructor. Initializes resource for the  {@link com.sun.tools.doclets.internal.toolkit.util.MessageRetriever MessageRetriever}.
 */
private ConfigurationImpl(){
  standardmessage=new MessageRetriever(this,""String_Node_Str"");
}"
37126,"/** 
 * Add the anchor.
 * @param builder the deprecated list builder
 * @param type the type of list being documented
 * @param contentTree the content tree to which the anchor will be added
 */
private void addAnchor(DeprecatedAPIListBuilder builder,int type,Content htmlTree){
  if (builder.hasDocumentation(type)) {
    htmlTree.addContent(getMarkerAnchor(ANCHORS[type]));
  }
}","/** 
 * Add the anchor.
 * @param builder the deprecated list builder
 * @param type the type of list being documented
 * @param htmlTree the content tree to which the anchor will be added
 */
private void addAnchor(DeprecatedAPIListBuilder builder,int type,Content htmlTree){
  if (builder.hasDocumentation(type)) {
    htmlTree.addContent(getMarkerAnchor(ANCHORS[type]));
  }
}"
37127,"/** 
 * Returns a package name label.
 * @param parsedName the package name
 * @return the package name content
 */
public Content getPackageLabel(String packageName){
  return new StringContent(packageName);
}","/** 
 * Returns a package name label.
 * @param packageName the package name
 * @return the package name content
 */
public Content getPackageLabel(String packageName){
  return new StringContent(packageName);
}"
37128,"/** 
 * Add the member header.
 * @param fieldsType the class document to be listed
 * @param fieldTypeStr the string for the filed type to be documented
 * @param fieldDimensions the dimensions of the field string to be added
 * @param firldName name of the field to be added
 * @param contentTree the content tree to which the member header will be added
 */
public void addMemberHeader(ClassDoc fieldType,String fieldTypeStr,String fieldDimensions,String fieldName,Content contentTree){
  Content nameContent=new RawHtml(fieldName);
  Content heading=HtmlTree.HEADING(HtmlConstants.MEMBER_HEADING,nameContent);
  contentTree.addContent(heading);
  Content pre=new HtmlTree(HtmlTag.PRE);
  if (fieldType == null) {
    pre.addContent(fieldTypeStr);
  }
 else {
    Content fieldContent=new RawHtml(writer.getLink(new LinkInfoImpl(LinkInfoImpl.CONTEXT_SERIAL_MEMBER,fieldType)));
    pre.addContent(fieldContent);
  }
  pre.addContent(fieldDimensions + ""String_Node_Str"");
  pre.addContent(fieldName);
  contentTree.addContent(pre);
}","/** 
 * Add the member header.
 * @param fieldType the class document to be listed
 * @param fieldTypeStr the string for the field type to be documented
 * @param fieldDimensions the dimensions of the field string to be added
 * @param fieldName name of the field to be added
 * @param contentTree the content tree to which the member header will be added
 */
public void addMemberHeader(ClassDoc fieldType,String fieldTypeStr,String fieldDimensions,String fieldName,Content contentTree){
  Content nameContent=new RawHtml(fieldName);
  Content heading=HtmlTree.HEADING(HtmlConstants.MEMBER_HEADING,nameContent);
  contentTree.addContent(heading);
  Content pre=new HtmlTree(HtmlTag.PRE);
  if (fieldType == null) {
    pre.addContent(fieldTypeStr);
  }
 else {
    Content fieldContent=new RawHtml(writer.getLink(new LinkInfoImpl(LinkInfoImpl.CONTEXT_SERIAL_MEMBER,fieldType)));
    pre.addContent(fieldContent);
  }
  pre.addContent(fieldDimensions + ""String_Node_Str"");
  pre.addContent(fieldName);
  contentTree.addContent(pre);
}"
37129,"/** 
 * Return path to the given file name in the given package. So if the name passed is ""Object.html"" and the name of the package is ""java.lang"", and if the relative path is ""../.."" then returned string will be ""../../java/lang/Object.html""
 * @param linkInfo the information about the link.
 * @param fileName the file name, to which path string is.
 */
private String pathString(LinkInfoImpl linkInfo){
  if (linkInfo.context == LinkInfoImpl.PACKAGE_FRAME) {
    return linkInfo.classDoc.name() + ""String_Node_Str"";
  }
  StringBuffer buf=new StringBuffer(m_writer.relativePath);
  buf.append(DirectoryManager.getPathToPackage(linkInfo.classDoc.containingPackage(),linkInfo.classDoc.name() + ""String_Node_Str""));
  return buf.toString();
}","/** 
 * Return path to the given file name in the given package. So if the name passed is ""Object.html"" and the name of the package is ""java.lang"", and if the relative path is ""../.."" then returned string will be ""../../java/lang/Object.html""
 * @param linkInfo the information about the link.
 */
private String pathString(LinkInfoImpl linkInfo){
  if (linkInfo.context == LinkInfoImpl.PACKAGE_FRAME) {
    return linkInfo.classDoc.name() + ""String_Node_Str"";
  }
  StringBuffer buf=new StringBuffer(m_writer.relativePath);
  buf.append(DirectoryManager.getPathToPackage(linkInfo.classDoc.containingPackage(),linkInfo.classDoc.name() + ""String_Node_Str""));
  return buf.toString();
}"
37130,"/** 
 * Adds the lower navigation bar and the bottom text (from the -bottom option) at the bottom of page.
 * @param the documentation tree to which the navigation bar footer will be added
 */
protected void addNavigationBarFooter(Content body){
  addNavLinks(false,body);
  addBottom(body);
}","/** 
 * Adds the lower navigation bar and the bottom text (from the -bottom option) at the bottom of page.
 * @param body the documentation tree to which the navigation bar footer will be added
 */
protected void addNavigationBarFooter(Content body){
  addNavLinks(false,body);
  addBottom(body);
}"
37131,"/** 
 * Constructor.
 * @param path The directory path to be created for this fileor null if none to be created.
 * @param filename File Name to which the PrintWriter willdo the Output.
 * @param docencoding Encoding to be used for this file.
 * @exception IOException Exception raised by the FileWriter is passed onto next level.
 * @exception UnSupportedEncodingException Exception raised by theOutputStreamWriter is passed on to next level.
 */
public HtmlWriter(Configuration configuration,String path,String filename,String docencoding) throws IOException, UnsupportedEncodingException {
  super(Util.genWriter(configuration,path,filename,docencoding));
  this.configuration=configuration;
  htmlFilename=filename;
  this.memberDetailsListPrinted=false;
  packageTableHeader=new String[]{configuration.getText(""String_Node_Str""),configuration.getText(""String_Node_Str"")};
  useTableSummary=configuration.getText(""String_Node_Str"",configuration.getText(""String_Node_Str""));
  modifierTypeHeader=configuration.getText(""String_Node_Str"",configuration.getText(""String_Node_Str""),configuration.getText(""String_Node_Str""));
  overviewLabel=getResource(""String_Node_Str"");
  defaultPackageLabel=new RawHtml(DocletConstants.DEFAULT_PACKAGE_NAME);
  packageLabel=getResource(""String_Node_Str"");
  useLabel=getResource(""String_Node_Str"");
  prevLabel=getResource(""String_Node_Str"");
  nextLabel=getResource(""String_Node_Str"");
  prevclassLabel=getResource(""String_Node_Str"");
  nextclassLabel=getResource(""String_Node_Str"");
  summaryLabel=getResource(""String_Node_Str"");
  detailLabel=getResource(""String_Node_Str"");
  framesLabel=getResource(""String_Node_Str"");
  noframesLabel=getResource(""String_Node_Str"");
  treeLabel=getResource(""String_Node_Str"");
  classLabel=getResource(""String_Node_Str"");
  deprecatedLabel=getResource(""String_Node_Str"");
  deprecatedPhrase=getResource(""String_Node_Str"");
  allclassesLabel=getResource(""String_Node_Str"");
  indexLabel=getResource(""String_Node_Str"");
  helpLabel=getResource(""String_Node_Str"");
  seeLabel=getResource(""String_Node_Str"");
  descriptionLabel=getResource(""String_Node_Str"");
  prevpackageLabel=getResource(""String_Node_Str"");
  nextpackageLabel=getResource(""String_Node_Str"");
  packagesLabel=getResource(""String_Node_Str"");
  methodDetailsLabel=getResource(""String_Node_Str"");
  annotationTypeDetailsLabel=getResource(""String_Node_Str"");
  fieldDetailsLabel=getResource(""String_Node_Str"");
  constructorDetailsLabel=getResource(""String_Node_Str"");
  enumConstantsDetailsLabel=getResource(""String_Node_Str"");
  specifiedByLabel=getResource(""String_Node_Str"");
  overridesLabel=getResource(""String_Node_Str"");
  descfrmClassLabel=getResource(""String_Node_Str"");
  descfrmInterfaceLabel=getResource(""String_Node_Str"");
}","/** 
 * Constructor.
 * @param path The directory path to be created for this fileor null if none to be created.
 * @param filename File Name to which the PrintWriter willdo the Output.
 * @param docencoding Encoding to be used for this file.
 * @exception IOException Exception raised by the FileWriter is passed onto next level.
 * @exception UnsupportedEncodingException Exception raised by theOutputStreamWriter is passed on to next level.
 */
public HtmlWriter(Configuration configuration,String path,String filename,String docencoding) throws IOException, UnsupportedEncodingException {
  super(Util.genWriter(configuration,path,filename,docencoding));
  this.configuration=configuration;
  htmlFilename=filename;
  this.memberDetailsListPrinted=false;
  packageTableHeader=new String[]{configuration.getText(""String_Node_Str""),configuration.getText(""String_Node_Str"")};
  useTableSummary=configuration.getText(""String_Node_Str"",configuration.getText(""String_Node_Str""));
  modifierTypeHeader=configuration.getText(""String_Node_Str"",configuration.getText(""String_Node_Str""),configuration.getText(""String_Node_Str""));
  overviewLabel=getResource(""String_Node_Str"");
  defaultPackageLabel=new RawHtml(DocletConstants.DEFAULT_PACKAGE_NAME);
  packageLabel=getResource(""String_Node_Str"");
  useLabel=getResource(""String_Node_Str"");
  prevLabel=getResource(""String_Node_Str"");
  nextLabel=getResource(""String_Node_Str"");
  prevclassLabel=getResource(""String_Node_Str"");
  nextclassLabel=getResource(""String_Node_Str"");
  summaryLabel=getResource(""String_Node_Str"");
  detailLabel=getResource(""String_Node_Str"");
  framesLabel=getResource(""String_Node_Str"");
  noframesLabel=getResource(""String_Node_Str"");
  treeLabel=getResource(""String_Node_Str"");
  classLabel=getResource(""String_Node_Str"");
  deprecatedLabel=getResource(""String_Node_Str"");
  deprecatedPhrase=getResource(""String_Node_Str"");
  allclassesLabel=getResource(""String_Node_Str"");
  indexLabel=getResource(""String_Node_Str"");
  helpLabel=getResource(""String_Node_Str"");
  seeLabel=getResource(""String_Node_Str"");
  descriptionLabel=getResource(""String_Node_Str"");
  prevpackageLabel=getResource(""String_Node_Str"");
  nextpackageLabel=getResource(""String_Node_Str"");
  packagesLabel=getResource(""String_Node_Str"");
  methodDetailsLabel=getResource(""String_Node_Str"");
  annotationTypeDetailsLabel=getResource(""String_Node_Str"");
  fieldDetailsLabel=getResource(""String_Node_Str"");
  constructorDetailsLabel=getResource(""String_Node_Str"");
  enumConstantsDetailsLabel=getResource(""String_Node_Str"");
  specifiedByLabel=getResource(""String_Node_Str"");
  overridesLabel=getResource(""String_Node_Str"");
  descfrmClassLabel=getResource(""String_Node_Str"");
  descfrmInterfaceLabel=getResource(""String_Node_Str"");
}"
37132,"/** 
 * Get the enum constants documentation tree header.
 * @param enumConstant the enum constant being documented
 * @param enumConstantDetailsTree the content tree representing enum constant details
 * @return content tree for the enum constant documentation header
 */
public Content getEnumConstantsTreeHeader(FieldDoc enumConstant,Content enumConstantsDetailsTree);","/** 
 * Get the enum constants documentation tree header.
 * @param enumConstant the enum constant being documented
 * @param enumConstantsDetailsTree the content tree representing enum constant details
 * @return content tree for the enum constant documentation header
 */
public Content getEnumConstantsTreeHeader(FieldDoc enumConstant,Content enumConstantsDetailsTree);"
37133,"/** 
 * Return the list of visible constant fields for the given classdoc.
 * @param cd the classdoc to examine.
 * @return the list of visible constant fields for the given classdoc.
 */
protected List<FieldDoc> members(){
  List<ProgramElementDoc> l=visibleMemberMapFields.getLeafClassMembers(configuration);
  l.addAll(visibleMemberMapEnumConst.getLeafClassMembers(configuration));
  Iterator<ProgramElementDoc> iter;
  if (l != null) {
    iter=l.iterator();
  }
 else {
    return null;
  }
  List<FieldDoc> inclList=new LinkedList<FieldDoc>();
  FieldDoc member;
  while (iter.hasNext()) {
    member=(FieldDoc)iter.next();
    if (member.constantValue() != null) {
      inclList.add(member);
    }
  }
  return inclList;
}","/** 
 * Return the list of visible constant fields for the given classdoc.
 * @return the list of visible constant fields for the given classdoc.
 */
protected List<FieldDoc> members(){
  List<ProgramElementDoc> l=visibleMemberMapFields.getLeafClassMembers(configuration);
  l.addAll(visibleMemberMapEnumConst.getLeafClassMembers(configuration));
  Iterator<ProgramElementDoc> iter;
  if (l != null) {
    iter=l.iterator();
  }
 else {
    return null;
  }
  List<FieldDoc> inclList=new LinkedList<FieldDoc>();
  FieldDoc member;
  while (iter.hasNext()) {
    member=(FieldDoc)iter.next();
    if (member.constantValue() != null) {
      inclList.add(member);
    }
  }
  return inclList;
}"
37134,"/** 
 * Returns a list of methods that will be documented for the given class. This information can be used for doclet specific documentation generation.
 * @param classDoc the {@link ClassDoc} we want to check.
 * @param type the type of members to return.
 * @return a list of methods that will be documented.
 * @see VisibleMemberMap
 */
public List<ProgramElementDoc> members(int type){
  return visibleMemberMaps[type].getLeafClassMembers(configuration);
}","/** 
 * Returns a list of methods that will be documented for the given class. This information can be used for doclet specific documentation generation.
 * @param type the type of members to return.
 * @return a list of methods that will be documented.
 * @see VisibleMemberMap
 */
public List<ProgramElementDoc> members(int type){
  return visibleMemberMaps[type].getLeafClassMembers(configuration);
}"
37135,"/** 
 * Given an array of <code>Tag</code>s representing this custom tag, return its string representation.  Print a warning for param tags that do not map to parameters.  Print a warning for param tags that are duplicated.
 * @param paramTags the array of <code>ParamTag</code>s to convert.
 * @param writer the TagletWriter that will write this tag.
 * @param alreadyDocumented the set of exceptions that have alreadybeen documented.
 * @param rankMap a {@link java.util.Map} which holds orderinginformation about the parameters.
 * @param nameMap a {@link java.util.Map} which holds a mappingof a rank of a parameter to its name.  This is used to ensure that the right name is used when parameter documentation is inherited.
 * @return the TagletOutput representation of this <code>Tag</code>.
 */
private TagletOutput processParamTags(boolean isNonTypeParams,ParamTag[] paramTags,Map<String,String> rankMap,TagletWriter writer,Set<String> alreadyDocumented){
  TagletOutput result=writer.getOutputInstance();
  if (paramTags.length > 0) {
    for (int i=0; i < paramTags.length; ++i) {
      ParamTag pt=paramTags[i];
      String paramName=isNonTypeParams ? pt.parameterName() : ""String_Node_Str"" + pt.parameterName() + ""String_Node_Str"";
      if (!rankMap.containsKey(pt.parameterName())) {
        writer.getMsgRetriever().warning(pt.position(),isNonTypeParams ? ""String_Node_Str"" : ""String_Node_Str"",paramName);
      }
      String rank=rankMap.get(pt.parameterName());
      if (rank != null && alreadyDocumented.contains(rank)) {
        writer.getMsgRetriever().warning(pt.position(),isNonTypeParams ? ""String_Node_Str"" : ""String_Node_Str"",paramName);
      }
      result.appendOutput(processParamTag(isNonTypeParams,writer,pt,pt.parameterName(),alreadyDocumented.size() == 0));
      alreadyDocumented.add(rank);
    }
  }
  return result;
}","/** 
 * Given an array of <code>Tag</code>s representing this custom tag, return its string representation.  Print a warning for param tags that do not map to parameters.  Print a warning for param tags that are duplicated.
 * @param paramTags the array of <code>ParamTag</code>s to convert.
 * @param writer the TagletWriter that will write this tag.
 * @param alreadyDocumented the set of exceptions that have alreadybeen documented.
 * @param rankMap a {@link java.util.Map} which holds orderinginformation about the parameters.
 * @param rankMap a {@link java.util.Map} which holds a mappingof a rank of a parameter to its name.  This is used to ensure that the right name is used when parameter documentation is inherited.
 * @return the TagletOutput representation of this <code>Tag</code>.
 */
private TagletOutput processParamTags(boolean isNonTypeParams,ParamTag[] paramTags,Map<String,String> rankMap,TagletWriter writer,Set<String> alreadyDocumented){
  TagletOutput result=writer.getOutputInstance();
  if (paramTags.length > 0) {
    for (int i=0; i < paramTags.length; ++i) {
      ParamTag pt=paramTags[i];
      String paramName=isNonTypeParams ? pt.parameterName() : ""String_Node_Str"" + pt.parameterName() + ""String_Node_Str"";
      if (!rankMap.containsKey(pt.parameterName())) {
        writer.getMsgRetriever().warning(pt.position(),isNonTypeParams ? ""String_Node_Str"" : ""String_Node_Str"",paramName);
      }
      String rank=rankMap.get(pt.parameterName());
      if (rank != null && alreadyDocumented.contains(rank)) {
        writer.getMsgRetriever().warning(pt.position(),isNonTypeParams ? ""String_Node_Str"" : ""String_Node_Str"",paramName);
      }
      result.appendOutput(processParamTag(isNonTypeParams,writer,pt,pt.parameterName(),alreadyDocumented.size() == 0));
      alreadyDocumented.add(rank);
    }
  }
  return result;
}"
37136,"/** 
 * Given an array of <code>ParamTag</code>s,return its string representation. Try to inherit the param tags that are missing.
 * @param doc               the doc that holds the param tags.
 * @param writer            the TagletWriter that will write this tag.
 * @param formalParameters  The array of parmeters (from type or executablemember) to check.
 * @return the TagletOutput representation of these <code>ParamTag</code>s.
 */
private TagletOutput getTagletOutput(boolean isNonTypeParams,Doc holder,TagletWriter writer,Object[] formalParameters,ParamTag[] paramTags){
  TagletOutput result=writer.getOutputInstance();
  Set<String> alreadyDocumented=new HashSet<String>();
  if (paramTags.length > 0) {
    result.appendOutput(processParamTags(isNonTypeParams,paramTags,getRankMap(formalParameters),writer,alreadyDocumented));
  }
  if (alreadyDocumented.size() != formalParameters.length) {
    result.appendOutput(getInheritedTagletOutput(isNonTypeParams,holder,writer,formalParameters,alreadyDocumented));
  }
  return result;
}","/** 
 * Given an array of <code>ParamTag</code>s,return its string representation. Try to inherit the param tags that are missing.
 * @param holder            the doc that holds the param tags.
 * @param writer            the TagletWriter that will write this tag.
 * @param formalParameters  The array of parmeters (from type or executablemember) to check.
 * @return the TagletOutput representation of these <code>ParamTag</code>s.
 */
private TagletOutput getTagletOutput(boolean isNonTypeParams,Doc holder,TagletWriter writer,Object[] formalParameters,ParamTag[] paramTags){
  TagletOutput result=writer.getOutputInstance();
  Set<String> alreadyDocumented=new HashSet<String>();
  if (paramTags.length > 0) {
    result.appendOutput(processParamTags(isNonTypeParams,paramTags,getRankMap(formalParameters),writer,alreadyDocumented));
  }
  if (alreadyDocumented.size() != formalParameters.length) {
    result.appendOutput(getInheritedTagletOutput(isNonTypeParams,holder,writer,formalParameters,alreadyDocumented));
  }
  return result;
}"
37137,"/** 
 * Given the name of the field, return the corresponding FieldDoc.
 * @param config the current configuration of the doclet.
 * @param tag the value tag.
 * @param name the name of the field to search for.  The name should be in<qualified class name>#<field name> format. If the class name is omitted, it is assumed that the field is in the current class.
 * @return the corresponding FieldDoc. If the name is null or empty string,return field that the value tag was used in.
 * @throws DocletAbortException if the value tag does not specify a name toa value field and it is not used within the comments of a valid field.
 */
private FieldDoc getFieldDoc(Configuration config,Tag tag,String name){
  if (name == null || name.length() == 0) {
    if (tag.holder() instanceof FieldDoc) {
      return (FieldDoc)tag.holder();
    }
 else {
      throw new DocletAbortException();
    }
  }
  StringTokenizer st=new StringTokenizer(name,""String_Node_Str"");
  String memberName=null;
  ClassDoc cd=null;
  if (st.countTokens() == 1) {
    Doc holder=tag.holder();
    if (holder instanceof MemberDoc) {
      cd=((MemberDoc)holder).containingClass();
    }
 else     if (holder instanceof ClassDoc) {
      cd=(ClassDoc)holder;
    }
    memberName=st.nextToken();
  }
 else {
    cd=config.root.classNamed(st.nextToken());
    memberName=st.nextToken();
  }
  if (cd == null) {
    return null;
  }
  FieldDoc[] fields=cd.fields();
  for (int i=0; i < fields.length; i++) {
    if (fields[i].name().equals(memberName)) {
      return fields[i];
    }
  }
  return null;
}","/** 
 * Given the name of the field, return the corresponding FieldDoc.
 * @param config the current configuration of the doclet.
 * @param tag the value tag.
 * @param name the name of the field to search for.  The name should be in{@code <qualified class name>#<field name>} format. If the class name is omitted,it is assumed that the field is in the current class.
 * @return the corresponding FieldDoc. If the name is null or empty string,return field that the value tag was used in.
 * @throws DocletAbortException if the value tag does not specify a name toa value field and it is not used within the comments of a valid field.
 */
private FieldDoc getFieldDoc(Configuration config,Tag tag,String name){
  if (name == null || name.length() == 0) {
    if (tag.holder() instanceof FieldDoc) {
      return (FieldDoc)tag.holder();
    }
 else {
      throw new DocletAbortException();
    }
  }
  StringTokenizer st=new StringTokenizer(name,""String_Node_Str"");
  String memberName=null;
  ClassDoc cd=null;
  if (st.countTokens() == 1) {
    Doc holder=tag.holder();
    if (holder instanceof MemberDoc) {
      cd=((MemberDoc)holder).containingClass();
    }
 else     if (holder instanceof ClassDoc) {
      cd=(ClassDoc)holder;
    }
    memberName=st.nextToken();
  }
 else {
    cd=config.root.classNamed(st.nextToken());
    memberName=st.nextToken();
  }
  if (cd == null) {
    return null;
  }
  FieldDoc[] fields=cd.fields();
  for (int i=0; i < fields.length; i++) {
    if (fields[i].name().equals(memberName)) {
      return fields[i];
    }
  }
  return null;
}"
37138,"/** 
 * Return the list of deprecated Doc objects of a given type.
 * @param the constant representing the type of list being returned.
 */
public List<Doc> getList(int type){
  return deprecatedLists.get(type);
}","/** 
 * Return the list of deprecated Doc objects of a given type.
 * @param type the constant representing the type of list being returned.
 */
public List<Doc> getList(int type){
  return deprecatedLists.get(type);
}"
37139,"/** 
 * Get the Extern Item object associated with this package name.
 * @param pkgname Package name.
 */
private Item findPackageItem(String pkgName){
  if (packageToItemMap == null) {
    return null;
  }
  return packageToItemMap.get(pkgName);
}","/** 
 * Get the Extern Item object associated with this package name.
 * @param pkgName Package name.
 */
private Item findPackageItem(String pkgName){
  if (packageToItemMap == null) {
    return null;
  }
  return packageToItemMap.get(pkgName);
}"
37140,"/** 
 * Constructor to build a Extern Item object and map it with the package name. If the same package name is found in the map, then the first mapped Item object or offline location will be retained.
 * @param packagename Package name found in the ""package-list"" file.
 * @param path        URL or Directory path from where the ""package-list""file is picked.
 * @param relative    True if path is URL, false if directory path.
 */
Item(String packageName,String path,boolean relative){
  this.packageName=packageName;
  this.path=path;
  this.relative=relative;
  if (packageToItemMap == null) {
    packageToItemMap=new HashMap<String,Item>();
  }
  if (!packageToItemMap.containsKey(packageName)) {
    packageToItemMap.put(packageName,this);
  }
}","/** 
 * Constructor to build a Extern Item object and map it with the package name. If the same package name is found in the map, then the first mapped Item object or offline location will be retained.
 * @param packageName Package name found in the ""package-list"" file.
 * @param path        URL or Directory path from where the ""package-list""file is picked.
 * @param relative    True if path is URL, false if directory path.
 */
Item(String packageName,String path,boolean relative){
  this.packageName=packageName;
  this.path=path;
  this.relative=relative;
  if (packageToItemMap == null) {
    packageToItemMap=new HashMap<String,Item>();
  }
  if (!packageToItemMap.containsKey(packageName)) {
    packageToItemMap.put(packageName,this);
  }
}"
37141,"/** 
 * Return the package private members inherited by the class.  Only return if parent is package private and not documented.
 * @param configuation the current configuration of the doclet.
 * @return the package private members inherited by the class.
 */
private List<ProgramElementDoc> getInheritedPackagePrivateMethods(Configuration configuration){
  List<ProgramElementDoc> results=new ArrayList<ProgramElementDoc>();
  for (Iterator<ClassDoc> iter=visibleClasses.iterator(); iter.hasNext(); ) {
    ClassDoc currentClass=iter.next();
    if (currentClass != classdoc && currentClass.isPackagePrivate() && !Util.isLinkable(currentClass,configuration)) {
      results.addAll(getMembersFor(currentClass));
    }
  }
  return results;
}","/** 
 * Return the package private members inherited by the class.  Only return if parent is package private and not documented.
 * @param configuration the current configuration of the doclet.
 * @return the package private members inherited by the class.
 */
private List<ProgramElementDoc> getInheritedPackagePrivateMethods(Configuration configuration){
  List<ProgramElementDoc> results=new ArrayList<ProgramElementDoc>();
  for (Iterator<ClassDoc> iter=visibleClasses.iterator(); iter.hasNext(); ) {
    ClassDoc currentClass=iter.next();
    if (currentClass != classdoc && currentClass.isPackagePrivate() && !Util.isLinkable(currentClass,configuration)) {
      results.addAll(getMembersFor(currentClass));
    }
  }
  return results;
}"
37142,"/** 
 * Return the visible members of the class being mapped.  Also append at the end of the list members that are inherited by inaccessible parents. We document these members in the child because the parent is not documented.
 * @param configuation the current configuration of the doclet.
 */
public List<ProgramElementDoc> getLeafClassMembers(Configuration configuration){
  List<ProgramElementDoc> result=getMembersFor(classdoc);
  result.addAll(getInheritedPackagePrivateMethods(configuration));
  return result;
}","/** 
 * Return the visible members of the class being mapped.  Also append at the end of the list members that are inherited by inaccessible parents. We document these members in the child because the parent is not documented.
 * @param configuration the current configuration of the doclet.
 */
public List<ProgramElementDoc> getLeafClassMembers(Configuration configuration){
  List<ProgramElementDoc> result=getMembersFor(classdoc);
  result.addAll(getInheritedPackagePrivateMethods(configuration));
  return result;
}"
37143,"/** 
 * Configure the set of diagnostic parts that should be displayed by the formatter.
 * @param options options to set
 */
public void setVisible(Set<DiagnosticPart> visibleParts);","/** 
 * Configure the set of diagnostic parts that should be displayed by the formatter.
 * @param visibleParts the parts to be set
 */
public void setVisible(Set<DiagnosticPart> visibleParts);"
37144,"/** 
 * Constructor used by service provider mechanism.  The recommended way to obtain an instance of this class is by using   {@link #create} or theservice provider mechanism.
 * @see javax.tools.JavaCompilerTool
 * @see javax.tools.ToolProvider
 * @see #create
 */
@Deprecated public JavacTool(){
}","/** 
 * Constructor used by service provider mechanism.  The recommended way to obtain an instance of this class is by using   {@link #create} or theservice provider mechanism.
 * @see javax.tools.JavaCompiler
 * @see javax.tools.ToolProvider
 * @see #create
 */
@Deprecated public JavacTool(){
}"
37145,"/** 
 * Return the kind of this tag. similar or synonymous tags.  For most tags, <code>kind()&nbsp;==&nbsp;name()</code>; the following table lists those cases where there is more than one tag of a given kind: <p> <table border=""1"" cellpadding=""4"" cellspacing=""0""> <tr><th><tt> kind()  </th>  <th><tt> name()      </th></tr> <tr><td><tt> @throws </td>  <td><tt> @throws     </td></tr> <tr><td><tt> @throws </td>  <td><tt> @exception  </td></tr> <tr><td><tt> @see    </td>  <td><tt> @see        </td></tr> <tr><td><tt> @see    </td>  <td><tt> @link       </td></tr> <tr><td><tt> @see    </td>  <td><tt> @linkplain  </td></tr> <tr><td><tt> @serial </td>  <td><tt> @serial     </td></tr> <tr><td><tt> @serial </td>  <td><tt> @serialData </td></tr> </table>
 */
String kind();","/** 
 * Return the kind of this tag. similar or synonymous tags.  For most tags, <code>kind()&nbsp;==&nbsp;name()</code>; the following table lists those cases where there is more than one tag of a given kind: <p> <table border=""1"" cellpadding=""4"" cellspacing=""0""> <tr><th><tt> kind()  </tt></th>  <th><tt> name()      </tt></th></tr> <tr><td><tt> @throws </tt></td>  <td><tt> @throws     </tt></td></tr> <tr><td><tt> @throws </tt></td>  <td><tt> @exception  </tt></td></tr> <tr><td><tt> @see    </tt></td>  <td><tt> @see        </tt></td></tr> <tr><td><tt> @see    </tt></td>  <td><tt> @link       </tt></td></tr> <tr><td><tt> @see    </tt></td>  <td><tt> @linkplain  </tt></td></tr> <tr><td><tt> @serial </tt></td>  <td><tt> @serial     </tt></td></tr> <tr><td><tt> @serial </tt></td>  <td><tt> @serialData </tt></td></tr> </table>
 */
String kind();"
37146,"/** 
 * Get the ClassFile object for a specified class.
 * @param className the name of the class to be returned.
 * @return the ClassFile for the given class
 * @throws Dependencies #ClassFileNotFoundException if the classfile cannot be found
 */
public ClassFile getClassFile(String className) throws ClassFileNotFoundException ;","/** 
 * Get the ClassFile object for a specified class.
 * @param className the name of the class to be returned.
 * @return the ClassFile for the given class
 * @throws Dependencies.ClassFileNotFoundException if the classfile cannot befound
 */
public ClassFile getClassFile(String className) throws ClassFileNotFoundException ;"
37147,"/** 
 * See   {@link Kind#LOCAL_UBYTE}. 
 */
R visitLocalAndValue(Instruction instr,int index,int value,P p);","/** 
 * See   {@link Kind#LOCAL_BYTE}. 
 */
R visitLocalAndValue(Instruction instr,int index,int value,P p);"
37148,"/** 
 * Add all the parameters for the executable member.
 * @param member the member to write parameters for.
 * @param includeAnnotations true if annotation information needs to be added.
 * @param tree the content tree to which the parameters information will be added.
 */
protected void addParameters(ExecutableMemberDoc member,boolean includeAnnotations,Content htmltree){
  htmltree.addContent(""String_Node_Str"");
  Parameter[] params=member.parameters();
  String indent=makeSpace(writer.displayLength);
  if (configuration().linksource) {
    indent+=makeSpace(member.name().length());
  }
  int paramstart;
  for (paramstart=0; paramstart < params.length; paramstart++) {
    Parameter param=params[paramstart];
    if (!param.name().startsWith(""String_Node_Str"")) {
      if (includeAnnotations) {
        boolean foundAnnotations=writer.addAnnotationInfo(indent.length(),member,param,htmltree);
        if (foundAnnotations) {
          htmltree.addContent(DocletConstants.NL);
          htmltree.addContent(indent);
        }
      }
      addParam(member,param,(paramstart == params.length - 1) && member.isVarArgs(),htmltree);
      break;
    }
  }
  for (int i=paramstart + 1; i < params.length; i++) {
    htmltree.addContent(""String_Node_Str"");
    htmltree.addContent(DocletConstants.NL);
    htmltree.addContent(indent);
    if (includeAnnotations) {
      boolean foundAnnotations=writer.addAnnotationInfo(indent.length(),member,params[i],htmltree);
      if (foundAnnotations) {
        htmltree.addContent(DocletConstants.NL);
        htmltree.addContent(indent);
      }
    }
    addParam(member,params[i],(i == params.length - 1) && member.isVarArgs(),htmltree);
  }
  htmltree.addContent(""String_Node_Str"");
}","/** 
 * Add all the parameters for the executable member.
 * @param member the member to write parameters for.
 * @param includeAnnotations true if annotation information needs to be added.
 * @param htmltree the content tree to which the parameters information will be added.
 */
protected void addParameters(ExecutableMemberDoc member,boolean includeAnnotations,Content htmltree){
  htmltree.addContent(""String_Node_Str"");
  Parameter[] params=member.parameters();
  String indent=makeSpace(writer.displayLength);
  if (configuration().linksource) {
    indent+=makeSpace(member.name().length());
  }
  int paramstart;
  for (paramstart=0; paramstart < params.length; paramstart++) {
    Parameter param=params[paramstart];
    if (!param.name().startsWith(""String_Node_Str"")) {
      if (includeAnnotations) {
        boolean foundAnnotations=writer.addAnnotationInfo(indent.length(),member,param,htmltree);
        if (foundAnnotations) {
          htmltree.addContent(DocletConstants.NL);
          htmltree.addContent(indent);
        }
      }
      addParam(member,param,(paramstart == params.length - 1) && member.isVarArgs(),htmltree);
      break;
    }
  }
  for (int i=paramstart + 1; i < params.length; i++) {
    htmltree.addContent(""String_Node_Str"");
    htmltree.addContent(DocletConstants.NL);
    htmltree.addContent(indent);
    if (includeAnnotations) {
      boolean foundAnnotations=writer.addAnnotationInfo(indent.length(),member,params[i],htmltree);
      if (foundAnnotations) {
        htmltree.addContent(DocletConstants.NL);
        htmltree.addContent(indent);
      }
    }
    addParam(member,params[i],(i == params.length - 1) && member.isVarArgs(),htmltree);
  }
  htmltree.addContent(""String_Node_Str"");
}"
37149,"/** 
 * Add the inherited summary link for the member.
 * @param classDoc the classDoc that we should link to
 * @param member the member being linked to
 * @param linksTree the content tree to which the link will be added
 */
protected void addInheritedSummaryLink(ClassDoc cd,ProgramElementDoc member,Content linksTree){
  linksTree.addContent(new RawHtml(writer.getDocLink(LinkInfoImpl.CONTEXT_MEMBER,cd,(MemberDoc)member,member.name(),false)));
}","/** 
 * Add the inherited summary link for the member.
 * @param cd the classDoc that we should link to
 * @param member the member being linked to
 * @param linksTree the content tree to which the link will be added
 */
protected void addInheritedSummaryLink(ClassDoc cd,ProgramElementDoc member,Content linksTree){
  linksTree.addContent(new RawHtml(writer.getDocLink(LinkInfoImpl.CONTEXT_MEMBER,cd,(MemberDoc)member,member.name(),false)));
}"
37150,"/** 
 * Add the summary link for the member.
 * @param context the id of the context where the link will be printed
 * @param classDoc the classDoc that we should link to
 * @param member the member being linked to
 * @param tdSummary the content tree to which the link will be added
 */
protected void addSummaryLink(int context,ClassDoc cd,ProgramElementDoc member,Content tdSummary){
  ExecutableMemberDoc emd=(ExecutableMemberDoc)member;
  String name=emd.name();
  Content strong=HtmlTree.STRONG(new RawHtml(writer.getDocLink(context,cd,(MemberDoc)emd,name,false)));
  Content code=HtmlTree.CODE(strong);
  writer.displayLength=name.length();
  addParameters(emd,false,code);
  tdSummary.addContent(code);
}","/** 
 * Add the summary link for the member.
 * @param context the id of the context where the link will be printed
 * @param cd the classDoc that we should link to
 * @param member the member being linked to
 * @param tdSummary the content tree to which the link will be added
 */
protected void addSummaryLink(int context,ClassDoc cd,ProgramElementDoc member,Content tdSummary){
  ExecutableMemberDoc emd=(ExecutableMemberDoc)member;
  String name=emd.name();
  Content strong=HtmlTree.STRONG(new RawHtml(writer.getDocLink(context,cd,(MemberDoc)emd,name,false)));
  Content code=HtmlTree.CODE(strong);
  writer.displayLength=name.length();
  addParameters(emd,false,code);
  tdSummary.addContent(code);
}"
37151,"/** 
 * Add the comment for the given member.
 * @param member the member being documented.
 * @param contentTree the content tree to which the comment will be added.
 */
protected void addComment(ProgramElementDoc member,Content htmltree){
  if (member.inlineTags().length > 0) {
    writer.addInlineComment(member,htmltree);
  }
}","/** 
 * Add the comment for the given member.
 * @param member the member being documented.
 * @param htmltree the content tree to which the comment will be added.
 */
protected void addComment(ProgramElementDoc member,Content htmltree){
  if (member.inlineTags().length > 0) {
    writer.addInlineComment(member,htmltree);
  }
}"
37152,"/** 
 * Constructor. Initialises resource for the  {@link com.sun.tools.doclets.MessageRetriever}.
 */
private ConfigurationImpl(){
  standardmessage=new MessageRetriever(this,""String_Node_Str"");
}","/** 
 * Constructor. Initializes resource for the  {@link com.sun.tools.doclets.internal.toolkit.util.MessageRetriever MessageRetriever}.
 */
private ConfigurationImpl(){
  standardmessage=new MessageRetriever(this,""String_Node_Str"");
}"
37153,"/** 
 * Add the anchor.
 * @param builder the deprecated list builder
 * @param type the type of list being documented
 * @param contentTree the content tree to which the anchor will be added
 */
private void addAnchor(DeprecatedAPIListBuilder builder,int type,Content htmlTree){
  if (builder.hasDocumentation(type)) {
    htmlTree.addContent(getMarkerAnchor(ANCHORS[type]));
  }
}","/** 
 * Add the anchor.
 * @param builder the deprecated list builder
 * @param type the type of list being documented
 * @param htmlTree the content tree to which the anchor will be added
 */
private void addAnchor(DeprecatedAPIListBuilder builder,int type,Content htmlTree){
  if (builder.hasDocumentation(type)) {
    htmlTree.addContent(getMarkerAnchor(ANCHORS[type]));
  }
}"
37154,"/** 
 * Returns a package name label.
 * @param parsedName the package name
 * @return the package name content
 */
public Content getPackageLabel(String packageName){
  return new StringContent(packageName);
}","/** 
 * Returns a package name label.
 * @param packageName the package name
 * @return the package name content
 */
public Content getPackageLabel(String packageName){
  return new StringContent(packageName);
}"
37155,"/** 
 * Add the member header.
 * @param fieldsType the class document to be listed
 * @param fieldTypeStr the string for the filed type to be documented
 * @param fieldDimensions the dimensions of the field string to be added
 * @param firldName name of the field to be added
 * @param contentTree the content tree to which the member header will be added
 */
public void addMemberHeader(ClassDoc fieldType,String fieldTypeStr,String fieldDimensions,String fieldName,Content contentTree){
  Content nameContent=new RawHtml(fieldName);
  Content heading=HtmlTree.HEADING(HtmlConstants.MEMBER_HEADING,nameContent);
  contentTree.addContent(heading);
  Content pre=new HtmlTree(HtmlTag.PRE);
  if (fieldType == null) {
    pre.addContent(fieldTypeStr);
  }
 else {
    Content fieldContent=new RawHtml(writer.getLink(new LinkInfoImpl(LinkInfoImpl.CONTEXT_SERIAL_MEMBER,fieldType)));
    pre.addContent(fieldContent);
  }
  pre.addContent(fieldDimensions + ""String_Node_Str"");
  pre.addContent(fieldName);
  contentTree.addContent(pre);
}","/** 
 * Add the member header.
 * @param fieldType the class document to be listed
 * @param fieldTypeStr the string for the field type to be documented
 * @param fieldDimensions the dimensions of the field string to be added
 * @param fieldName name of the field to be added
 * @param contentTree the content tree to which the member header will be added
 */
public void addMemberHeader(ClassDoc fieldType,String fieldTypeStr,String fieldDimensions,String fieldName,Content contentTree){
  Content nameContent=new RawHtml(fieldName);
  Content heading=HtmlTree.HEADING(HtmlConstants.MEMBER_HEADING,nameContent);
  contentTree.addContent(heading);
  Content pre=new HtmlTree(HtmlTag.PRE);
  if (fieldType == null) {
    pre.addContent(fieldTypeStr);
  }
 else {
    Content fieldContent=new RawHtml(writer.getLink(new LinkInfoImpl(LinkInfoImpl.CONTEXT_SERIAL_MEMBER,fieldType)));
    pre.addContent(fieldContent);
  }
  pre.addContent(fieldDimensions + ""String_Node_Str"");
  pre.addContent(fieldName);
  contentTree.addContent(pre);
}"
37156,"/** 
 * Return path to the given file name in the given package. So if the name passed is ""Object.html"" and the name of the package is ""java.lang"", and if the relative path is ""../.."" then returned string will be ""../../java/lang/Object.html""
 * @param linkInfo the information about the link.
 * @param fileName the file name, to which path string is.
 */
private String pathString(LinkInfoImpl linkInfo){
  if (linkInfo.context == LinkInfoImpl.PACKAGE_FRAME) {
    return linkInfo.classDoc.name() + ""String_Node_Str"";
  }
  StringBuffer buf=new StringBuffer(m_writer.relativePath);
  buf.append(DirectoryManager.getPathToPackage(linkInfo.classDoc.containingPackage(),linkInfo.classDoc.name() + ""String_Node_Str""));
  return buf.toString();
}","/** 
 * Return path to the given file name in the given package. So if the name passed is ""Object.html"" and the name of the package is ""java.lang"", and if the relative path is ""../.."" then returned string will be ""../../java/lang/Object.html""
 * @param linkInfo the information about the link.
 */
private String pathString(LinkInfoImpl linkInfo){
  if (linkInfo.context == LinkInfoImpl.PACKAGE_FRAME) {
    return linkInfo.classDoc.name() + ""String_Node_Str"";
  }
  StringBuffer buf=new StringBuffer(m_writer.relativePath);
  buf.append(DirectoryManager.getPathToPackage(linkInfo.classDoc.containingPackage(),linkInfo.classDoc.name() + ""String_Node_Str""));
  return buf.toString();
}"
37157,"/** 
 * Adds the lower navigation bar and the bottom text (from the -bottom option) at the bottom of page.
 * @param the documentation tree to which the navigation bar footer will be added
 */
protected void addNavigationBarFooter(Content body){
  addNavLinks(false,body);
  addBottom(body);
}","/** 
 * Adds the lower navigation bar and the bottom text (from the -bottom option) at the bottom of page.
 * @param body the documentation tree to which the navigation bar footer will be added
 */
protected void addNavigationBarFooter(Content body){
  addNavLinks(false,body);
  addBottom(body);
}"
37158,"/** 
 * Constructor.
 * @param path The directory path to be created for this fileor null if none to be created.
 * @param filename File Name to which the PrintWriter willdo the Output.
 * @param docencoding Encoding to be used for this file.
 * @exception IOException Exception raised by the FileWriter is passed onto next level.
 * @exception UnSupportedEncodingException Exception raised by theOutputStreamWriter is passed on to next level.
 */
public HtmlWriter(Configuration configuration,String path,String filename,String docencoding) throws IOException, UnsupportedEncodingException {
  super(Util.genWriter(configuration,path,filename,docencoding));
  this.configuration=configuration;
  htmlFilename=filename;
  this.memberDetailsListPrinted=false;
  packageTableHeader=new String[]{configuration.getText(""String_Node_Str""),configuration.getText(""String_Node_Str"")};
  useTableSummary=configuration.getText(""String_Node_Str"",configuration.getText(""String_Node_Str""));
  modifierTypeHeader=configuration.getText(""String_Node_Str"",configuration.getText(""String_Node_Str""),configuration.getText(""String_Node_Str""));
  overviewLabel=getResource(""String_Node_Str"");
  defaultPackageLabel=new RawHtml(DocletConstants.DEFAULT_PACKAGE_NAME);
  packageLabel=getResource(""String_Node_Str"");
  useLabel=getResource(""String_Node_Str"");
  prevLabel=getResource(""String_Node_Str"");
  nextLabel=getResource(""String_Node_Str"");
  prevclassLabel=getResource(""String_Node_Str"");
  nextclassLabel=getResource(""String_Node_Str"");
  summaryLabel=getResource(""String_Node_Str"");
  detailLabel=getResource(""String_Node_Str"");
  framesLabel=getResource(""String_Node_Str"");
  noframesLabel=getResource(""String_Node_Str"");
  treeLabel=getResource(""String_Node_Str"");
  classLabel=getResource(""String_Node_Str"");
  deprecatedLabel=getResource(""String_Node_Str"");
  deprecatedPhrase=getResource(""String_Node_Str"");
  allclassesLabel=getResource(""String_Node_Str"");
  indexLabel=getResource(""String_Node_Str"");
  helpLabel=getResource(""String_Node_Str"");
  seeLabel=getResource(""String_Node_Str"");
  descriptionLabel=getResource(""String_Node_Str"");
  prevpackageLabel=getResource(""String_Node_Str"");
  nextpackageLabel=getResource(""String_Node_Str"");
  packagesLabel=getResource(""String_Node_Str"");
  methodDetailsLabel=getResource(""String_Node_Str"");
  annotationTypeDetailsLabel=getResource(""String_Node_Str"");
  fieldDetailsLabel=getResource(""String_Node_Str"");
  constructorDetailsLabel=getResource(""String_Node_Str"");
  enumConstantsDetailsLabel=getResource(""String_Node_Str"");
  specifiedByLabel=getResource(""String_Node_Str"");
  overridesLabel=getResource(""String_Node_Str"");
  descfrmClassLabel=getResource(""String_Node_Str"");
  descfrmInterfaceLabel=getResource(""String_Node_Str"");
}","/** 
 * Constructor.
 * @param path The directory path to be created for this fileor null if none to be created.
 * @param filename File Name to which the PrintWriter willdo the Output.
 * @param docencoding Encoding to be used for this file.
 * @exception IOException Exception raised by the FileWriter is passed onto next level.
 * @exception UnsupportedEncodingException Exception raised by theOutputStreamWriter is passed on to next level.
 */
public HtmlWriter(Configuration configuration,String path,String filename,String docencoding) throws IOException, UnsupportedEncodingException {
  super(Util.genWriter(configuration,path,filename,docencoding));
  this.configuration=configuration;
  htmlFilename=filename;
  this.memberDetailsListPrinted=false;
  packageTableHeader=new String[]{configuration.getText(""String_Node_Str""),configuration.getText(""String_Node_Str"")};
  useTableSummary=configuration.getText(""String_Node_Str"",configuration.getText(""String_Node_Str""));
  modifierTypeHeader=configuration.getText(""String_Node_Str"",configuration.getText(""String_Node_Str""),configuration.getText(""String_Node_Str""));
  overviewLabel=getResource(""String_Node_Str"");
  defaultPackageLabel=new RawHtml(DocletConstants.DEFAULT_PACKAGE_NAME);
  packageLabel=getResource(""String_Node_Str"");
  useLabel=getResource(""String_Node_Str"");
  prevLabel=getResource(""String_Node_Str"");
  nextLabel=getResource(""String_Node_Str"");
  prevclassLabel=getResource(""String_Node_Str"");
  nextclassLabel=getResource(""String_Node_Str"");
  summaryLabel=getResource(""String_Node_Str"");
  detailLabel=getResource(""String_Node_Str"");
  framesLabel=getResource(""String_Node_Str"");
  noframesLabel=getResource(""String_Node_Str"");
  treeLabel=getResource(""String_Node_Str"");
  classLabel=getResource(""String_Node_Str"");
  deprecatedLabel=getResource(""String_Node_Str"");
  deprecatedPhrase=getResource(""String_Node_Str"");
  allclassesLabel=getResource(""String_Node_Str"");
  indexLabel=getResource(""String_Node_Str"");
  helpLabel=getResource(""String_Node_Str"");
  seeLabel=getResource(""String_Node_Str"");
  descriptionLabel=getResource(""String_Node_Str"");
  prevpackageLabel=getResource(""String_Node_Str"");
  nextpackageLabel=getResource(""String_Node_Str"");
  packagesLabel=getResource(""String_Node_Str"");
  methodDetailsLabel=getResource(""String_Node_Str"");
  annotationTypeDetailsLabel=getResource(""String_Node_Str"");
  fieldDetailsLabel=getResource(""String_Node_Str"");
  constructorDetailsLabel=getResource(""String_Node_Str"");
  enumConstantsDetailsLabel=getResource(""String_Node_Str"");
  specifiedByLabel=getResource(""String_Node_Str"");
  overridesLabel=getResource(""String_Node_Str"");
  descfrmClassLabel=getResource(""String_Node_Str"");
  descfrmInterfaceLabel=getResource(""String_Node_Str"");
}"
37159,"/** 
 * Get the enum constants documentation tree header.
 * @param enumConstant the enum constant being documented
 * @param enumConstantDetailsTree the content tree representing enum constant details
 * @return content tree for the enum constant documentation header
 */
public Content getEnumConstantsTreeHeader(FieldDoc enumConstant,Content enumConstantsDetailsTree);","/** 
 * Get the enum constants documentation tree header.
 * @param enumConstant the enum constant being documented
 * @param enumConstantsDetailsTree the content tree representing enum constant details
 * @return content tree for the enum constant documentation header
 */
public Content getEnumConstantsTreeHeader(FieldDoc enumConstant,Content enumConstantsDetailsTree);"
37160,"/** 
 * Return the list of visible constant fields for the given classdoc.
 * @param cd the classdoc to examine.
 * @return the list of visible constant fields for the given classdoc.
 */
protected List<FieldDoc> members(){
  List<ProgramElementDoc> l=visibleMemberMapFields.getLeafClassMembers(configuration);
  l.addAll(visibleMemberMapEnumConst.getLeafClassMembers(configuration));
  Iterator<ProgramElementDoc> iter;
  if (l != null) {
    iter=l.iterator();
  }
 else {
    return null;
  }
  List<FieldDoc> inclList=new LinkedList<FieldDoc>();
  FieldDoc member;
  while (iter.hasNext()) {
    member=(FieldDoc)iter.next();
    if (member.constantValue() != null) {
      inclList.add(member);
    }
  }
  return inclList;
}","/** 
 * Return the list of visible constant fields for the given classdoc.
 * @return the list of visible constant fields for the given classdoc.
 */
protected List<FieldDoc> members(){
  List<ProgramElementDoc> l=visibleMemberMapFields.getLeafClassMembers(configuration);
  l.addAll(visibleMemberMapEnumConst.getLeafClassMembers(configuration));
  Iterator<ProgramElementDoc> iter;
  if (l != null) {
    iter=l.iterator();
  }
 else {
    return null;
  }
  List<FieldDoc> inclList=new LinkedList<FieldDoc>();
  FieldDoc member;
  while (iter.hasNext()) {
    member=(FieldDoc)iter.next();
    if (member.constantValue() != null) {
      inclList.add(member);
    }
  }
  return inclList;
}"
37161,"/** 
 * Returns a list of methods that will be documented for the given class. This information can be used for doclet specific documentation generation.
 * @param classDoc the {@link ClassDoc} we want to check.
 * @param type the type of members to return.
 * @return a list of methods that will be documented.
 * @see VisibleMemberMap
 */
public List<ProgramElementDoc> members(int type){
  return visibleMemberMaps[type].getLeafClassMembers(configuration);
}","/** 
 * Returns a list of methods that will be documented for the given class. This information can be used for doclet specific documentation generation.
 * @param type the type of members to return.
 * @return a list of methods that will be documented.
 * @see VisibleMemberMap
 */
public List<ProgramElementDoc> members(int type){
  return visibleMemberMaps[type].getLeafClassMembers(configuration);
}"
37162,"/** 
 * Given an array of <code>Tag</code>s representing this custom tag, return its string representation.  Print a warning for param tags that do not map to parameters.  Print a warning for param tags that are duplicated.
 * @param paramTags the array of <code>ParamTag</code>s to convert.
 * @param writer the TagletWriter that will write this tag.
 * @param alreadyDocumented the set of exceptions that have alreadybeen documented.
 * @param rankMap a {@link java.util.Map} which holds orderinginformation about the parameters.
 * @param nameMap a {@link java.util.Map} which holds a mappingof a rank of a parameter to its name.  This is used to ensure that the right name is used when parameter documentation is inherited.
 * @return the TagletOutput representation of this <code>Tag</code>.
 */
private TagletOutput processParamTags(boolean isNonTypeParams,ParamTag[] paramTags,Map<String,String> rankMap,TagletWriter writer,Set<String> alreadyDocumented){
  TagletOutput result=writer.getOutputInstance();
  if (paramTags.length > 0) {
    for (int i=0; i < paramTags.length; ++i) {
      ParamTag pt=paramTags[i];
      String paramName=isNonTypeParams ? pt.parameterName() : ""String_Node_Str"" + pt.parameterName() + ""String_Node_Str"";
      if (!rankMap.containsKey(pt.parameterName())) {
        writer.getMsgRetriever().warning(pt.position(),isNonTypeParams ? ""String_Node_Str"" : ""String_Node_Str"",paramName);
      }
      String rank=rankMap.get(pt.parameterName());
      if (rank != null && alreadyDocumented.contains(rank)) {
        writer.getMsgRetriever().warning(pt.position(),isNonTypeParams ? ""String_Node_Str"" : ""String_Node_Str"",paramName);
      }
      result.appendOutput(processParamTag(isNonTypeParams,writer,pt,pt.parameterName(),alreadyDocumented.size() == 0));
      alreadyDocumented.add(rank);
    }
  }
  return result;
}","/** 
 * Given an array of <code>Tag</code>s representing this custom tag, return its string representation.  Print a warning for param tags that do not map to parameters.  Print a warning for param tags that are duplicated.
 * @param paramTags the array of <code>ParamTag</code>s to convert.
 * @param writer the TagletWriter that will write this tag.
 * @param alreadyDocumented the set of exceptions that have alreadybeen documented.
 * @param rankMap a {@link java.util.Map} which holds orderinginformation about the parameters.
 * @param rankMap a {@link java.util.Map} which holds a mappingof a rank of a parameter to its name.  This is used to ensure that the right name is used when parameter documentation is inherited.
 * @return the TagletOutput representation of this <code>Tag</code>.
 */
private TagletOutput processParamTags(boolean isNonTypeParams,ParamTag[] paramTags,Map<String,String> rankMap,TagletWriter writer,Set<String> alreadyDocumented){
  TagletOutput result=writer.getOutputInstance();
  if (paramTags.length > 0) {
    for (int i=0; i < paramTags.length; ++i) {
      ParamTag pt=paramTags[i];
      String paramName=isNonTypeParams ? pt.parameterName() : ""String_Node_Str"" + pt.parameterName() + ""String_Node_Str"";
      if (!rankMap.containsKey(pt.parameterName())) {
        writer.getMsgRetriever().warning(pt.position(),isNonTypeParams ? ""String_Node_Str"" : ""String_Node_Str"",paramName);
      }
      String rank=rankMap.get(pt.parameterName());
      if (rank != null && alreadyDocumented.contains(rank)) {
        writer.getMsgRetriever().warning(pt.position(),isNonTypeParams ? ""String_Node_Str"" : ""String_Node_Str"",paramName);
      }
      result.appendOutput(processParamTag(isNonTypeParams,writer,pt,pt.parameterName(),alreadyDocumented.size() == 0));
      alreadyDocumented.add(rank);
    }
  }
  return result;
}"
37163,"/** 
 * Given an array of <code>ParamTag</code>s,return its string representation. Try to inherit the param tags that are missing.
 * @param doc               the doc that holds the param tags.
 * @param writer            the TagletWriter that will write this tag.
 * @param formalParameters  The array of parmeters (from type or executablemember) to check.
 * @return the TagletOutput representation of these <code>ParamTag</code>s.
 */
private TagletOutput getTagletOutput(boolean isNonTypeParams,Doc holder,TagletWriter writer,Object[] formalParameters,ParamTag[] paramTags){
  TagletOutput result=writer.getOutputInstance();
  Set<String> alreadyDocumented=new HashSet<String>();
  if (paramTags.length > 0) {
    result.appendOutput(processParamTags(isNonTypeParams,paramTags,getRankMap(formalParameters),writer,alreadyDocumented));
  }
  if (alreadyDocumented.size() != formalParameters.length) {
    result.appendOutput(getInheritedTagletOutput(isNonTypeParams,holder,writer,formalParameters,alreadyDocumented));
  }
  return result;
}","/** 
 * Given an array of <code>ParamTag</code>s,return its string representation. Try to inherit the param tags that are missing.
 * @param holder            the doc that holds the param tags.
 * @param writer            the TagletWriter that will write this tag.
 * @param formalParameters  The array of parmeters (from type or executablemember) to check.
 * @return the TagletOutput representation of these <code>ParamTag</code>s.
 */
private TagletOutput getTagletOutput(boolean isNonTypeParams,Doc holder,TagletWriter writer,Object[] formalParameters,ParamTag[] paramTags){
  TagletOutput result=writer.getOutputInstance();
  Set<String> alreadyDocumented=new HashSet<String>();
  if (paramTags.length > 0) {
    result.appendOutput(processParamTags(isNonTypeParams,paramTags,getRankMap(formalParameters),writer,alreadyDocumented));
  }
  if (alreadyDocumented.size() != formalParameters.length) {
    result.appendOutput(getInheritedTagletOutput(isNonTypeParams,holder,writer,formalParameters,alreadyDocumented));
  }
  return result;
}"
37164,"/** 
 * Given the name of the field, return the corresponding FieldDoc.
 * @param config the current configuration of the doclet.
 * @param tag the value tag.
 * @param name the name of the field to search for.  The name should be in<qualified class name>#<field name> format. If the class name is omitted, it is assumed that the field is in the current class.
 * @return the corresponding FieldDoc. If the name is null or empty string,return field that the value tag was used in.
 * @throws DocletAbortException if the value tag does not specify a name toa value field and it is not used within the comments of a valid field.
 */
private FieldDoc getFieldDoc(Configuration config,Tag tag,String name){
  if (name == null || name.length() == 0) {
    if (tag.holder() instanceof FieldDoc) {
      return (FieldDoc)tag.holder();
    }
 else {
      throw new DocletAbortException();
    }
  }
  StringTokenizer st=new StringTokenizer(name,""String_Node_Str"");
  String memberName=null;
  ClassDoc cd=null;
  if (st.countTokens() == 1) {
    Doc holder=tag.holder();
    if (holder instanceof MemberDoc) {
      cd=((MemberDoc)holder).containingClass();
    }
 else     if (holder instanceof ClassDoc) {
      cd=(ClassDoc)holder;
    }
    memberName=st.nextToken();
  }
 else {
    cd=config.root.classNamed(st.nextToken());
    memberName=st.nextToken();
  }
  if (cd == null) {
    return null;
  }
  FieldDoc[] fields=cd.fields();
  for (int i=0; i < fields.length; i++) {
    if (fields[i].name().equals(memberName)) {
      return fields[i];
    }
  }
  return null;
}","/** 
 * Given the name of the field, return the corresponding FieldDoc.
 * @param config the current configuration of the doclet.
 * @param tag the value tag.
 * @param name the name of the field to search for.  The name should be in{@code <qualified class name>#<field name>} format. If the class name is omitted,it is assumed that the field is in the current class.
 * @return the corresponding FieldDoc. If the name is null or empty string,return field that the value tag was used in.
 * @throws DocletAbortException if the value tag does not specify a name toa value field and it is not used within the comments of a valid field.
 */
private FieldDoc getFieldDoc(Configuration config,Tag tag,String name){
  if (name == null || name.length() == 0) {
    if (tag.holder() instanceof FieldDoc) {
      return (FieldDoc)tag.holder();
    }
 else {
      throw new DocletAbortException();
    }
  }
  StringTokenizer st=new StringTokenizer(name,""String_Node_Str"");
  String memberName=null;
  ClassDoc cd=null;
  if (st.countTokens() == 1) {
    Doc holder=tag.holder();
    if (holder instanceof MemberDoc) {
      cd=((MemberDoc)holder).containingClass();
    }
 else     if (holder instanceof ClassDoc) {
      cd=(ClassDoc)holder;
    }
    memberName=st.nextToken();
  }
 else {
    cd=config.root.classNamed(st.nextToken());
    memberName=st.nextToken();
  }
  if (cd == null) {
    return null;
  }
  FieldDoc[] fields=cd.fields();
  for (int i=0; i < fields.length; i++) {
    if (fields[i].name().equals(memberName)) {
      return fields[i];
    }
  }
  return null;
}"
37165,"/** 
 * Return the list of deprecated Doc objects of a given type.
 * @param the constant representing the type of list being returned.
 */
public List<Doc> getList(int type){
  return deprecatedLists.get(type);
}","/** 
 * Return the list of deprecated Doc objects of a given type.
 * @param type the constant representing the type of list being returned.
 */
public List<Doc> getList(int type){
  return deprecatedLists.get(type);
}"
37166,"/** 
 * Get the Extern Item object associated with this package name.
 * @param pkgname Package name.
 */
private Item findPackageItem(String pkgName){
  if (packageToItemMap == null) {
    return null;
  }
  return packageToItemMap.get(pkgName);
}","/** 
 * Get the Extern Item object associated with this package name.
 * @param pkgName Package name.
 */
private Item findPackageItem(String pkgName){
  if (packageToItemMap == null) {
    return null;
  }
  return packageToItemMap.get(pkgName);
}"
37167,"/** 
 * Constructor to build a Extern Item object and map it with the package name. If the same package name is found in the map, then the first mapped Item object or offline location will be retained.
 * @param packagename Package name found in the ""package-list"" file.
 * @param path        URL or Directory path from where the ""package-list""file is picked.
 * @param relative    True if path is URL, false if directory path.
 */
Item(String packageName,String path,boolean relative){
  this.packageName=packageName;
  this.path=path;
  this.relative=relative;
  if (packageToItemMap == null) {
    packageToItemMap=new HashMap<String,Item>();
  }
  if (!packageToItemMap.containsKey(packageName)) {
    packageToItemMap.put(packageName,this);
  }
}","/** 
 * Constructor to build a Extern Item object and map it with the package name. If the same package name is found in the map, then the first mapped Item object or offline location will be retained.
 * @param packageName Package name found in the ""package-list"" file.
 * @param path        URL or Directory path from where the ""package-list""file is picked.
 * @param relative    True if path is URL, false if directory path.
 */
Item(String packageName,String path,boolean relative){
  this.packageName=packageName;
  this.path=path;
  this.relative=relative;
  if (packageToItemMap == null) {
    packageToItemMap=new HashMap<String,Item>();
  }
  if (!packageToItemMap.containsKey(packageName)) {
    packageToItemMap.put(packageName,this);
  }
}"
37168,"/** 
 * Return the package private members inherited by the class.  Only return if parent is package private and not documented.
 * @param configuation the current configuration of the doclet.
 * @return the package private members inherited by the class.
 */
private List<ProgramElementDoc> getInheritedPackagePrivateMethods(Configuration configuration){
  List<ProgramElementDoc> results=new ArrayList<ProgramElementDoc>();
  for (Iterator<ClassDoc> iter=visibleClasses.iterator(); iter.hasNext(); ) {
    ClassDoc currentClass=iter.next();
    if (currentClass != classdoc && currentClass.isPackagePrivate() && !Util.isLinkable(currentClass,configuration)) {
      results.addAll(getMembersFor(currentClass));
    }
  }
  return results;
}","/** 
 * Return the package private members inherited by the class.  Only return if parent is package private and not documented.
 * @param configuration the current configuration of the doclet.
 * @return the package private members inherited by the class.
 */
private List<ProgramElementDoc> getInheritedPackagePrivateMethods(Configuration configuration){
  List<ProgramElementDoc> results=new ArrayList<ProgramElementDoc>();
  for (Iterator<ClassDoc> iter=visibleClasses.iterator(); iter.hasNext(); ) {
    ClassDoc currentClass=iter.next();
    if (currentClass != classdoc && currentClass.isPackagePrivate() && !Util.isLinkable(currentClass,configuration)) {
      results.addAll(getMembersFor(currentClass));
    }
  }
  return results;
}"
37169,"/** 
 * Return the visible members of the class being mapped.  Also append at the end of the list members that are inherited by inaccessible parents. We document these members in the child because the parent is not documented.
 * @param configuation the current configuration of the doclet.
 */
public List<ProgramElementDoc> getLeafClassMembers(Configuration configuration){
  List<ProgramElementDoc> result=getMembersFor(classdoc);
  result.addAll(getInheritedPackagePrivateMethods(configuration));
  return result;
}","/** 
 * Return the visible members of the class being mapped.  Also append at the end of the list members that are inherited by inaccessible parents. We document these members in the child because the parent is not documented.
 * @param configuration the current configuration of the doclet.
 */
public List<ProgramElementDoc> getLeafClassMembers(Configuration configuration){
  List<ProgramElementDoc> result=getMembersFor(classdoc);
  result.addAll(getInheritedPackagePrivateMethods(configuration));
  return result;
}"
37170,"/** 
 * Configure the set of diagnostic parts that should be displayed by the formatter.
 * @param options options to set
 */
public void setVisible(Set<DiagnosticPart> visibleParts);","/** 
 * Configure the set of diagnostic parts that should be displayed by the formatter.
 * @param visibleParts the parts to be set
 */
public void setVisible(Set<DiagnosticPart> visibleParts);"
37171,"/** 
 * Constructor used by service provider mechanism.  The recommended way to obtain an instance of this class is by using   {@link #create} or theservice provider mechanism.
 * @see javax.tools.JavaCompilerTool
 * @see javax.tools.ToolProvider
 * @see #create
 */
@Deprecated public JavacTool(){
}","/** 
 * Constructor used by service provider mechanism.  The recommended way to obtain an instance of this class is by using   {@link #create} or theservice provider mechanism.
 * @see javax.tools.JavaCompiler
 * @see javax.tools.ToolProvider
 * @see #create
 */
@Deprecated public JavacTool(){
}"
37172,"public Iterator<TypeSymbol> iterator(){
  return new Iterator<TypeSymbol>(){
    List<TypeSymbol> seen=List.nil();
    TypeSymbol currentSym=getSymbol(intype);
    public boolean hasNext(){
      return currentSym != null;
    }
    public TypeSymbol next(){
      TypeSymbol prevSym=currentSym;
      currentSym=getSymbol(types.supertype(currentSym.type));
      return prevSym;
    }
    public void remove(){
      throw new UnsupportedOperationException(""String_Node_Str"");
    }
    TypeSymbol getSymbol(    Type intype){
      if (intype.tag != CLASS && intype.tag != TYPEVAR) {
        return null;
      }
      while (intype.tag == TYPEVAR)       intype=intype.getUpperBound();
      if (seen.contains(intype.tsym)) {
        return null;
      }
      seen=seen.prepend(intype.tsym);
      return intype.tsym;
    }
  }
;
}","public Iterator<TypeSymbol> iterator(){
  return new Iterator<TypeSymbol>(){
    List<TypeSymbol> seen=List.nil();
    TypeSymbol currentSym=symbolFor(intype);
    TypeSymbol prevSym=null;
    public boolean hasNext(){
      if (currentSym == syms.noSymbol) {
        currentSym=symbolFor(types.supertype(prevSym.type));
      }
      return currentSym != null;
    }
    public TypeSymbol next(){
      prevSym=currentSym;
      currentSym=syms.noSymbol;
      Assert.check(prevSym != null || prevSym != syms.noSymbol);
      return prevSym;
    }
    public void remove(){
      throw new UnsupportedOperationException();
    }
    TypeSymbol symbolFor(    Type t){
      if (t.tag != CLASS && t.tag != TYPEVAR) {
        return null;
      }
      while (t.tag == TYPEVAR)       t=t.getUpperBound();
      if (seen.contains(t.tsym)) {
        return null;
      }
      seen=seen.prepend(t.tsym);
      return t.tsym;
    }
  }
;
}"
37173,"public boolean hasNext(){
  return currentSym != null;
}","public boolean hasNext(){
  if (currentSym == syms.noSymbol) {
    currentSym=symbolFor(types.supertype(prevSym.type));
  }
  return currentSym != null;
}"
37174,"public TypeSymbol next(){
  TypeSymbol prevSym=currentSym;
  currentSym=getSymbol(types.supertype(currentSym.type));
  return prevSym;
}","public TypeSymbol next(){
  prevSym=currentSym;
  currentSym=syms.noSymbol;
  Assert.check(prevSym != null || prevSym != syms.noSymbol);
  return prevSym;
}"
37175,"public void remove(){
  throw new UnsupportedOperationException(""String_Node_Str"");
}","public void remove(){
  throw new UnsupportedOperationException();
}"
37176,"/** 
 * Return an Iterable object to scan the superclasses of a given type. It's crucial that the scan is done lazily, as we don't want to accidentally access more supertypes than strictly needed (as this could trigger completion errors if some of the not-needed supertypes are missing/ill-formed).
 */
Iterable<TypeSymbol> superclasses(final Type intype){
  return new Iterable<TypeSymbol>(){
    public Iterator<TypeSymbol> iterator(){
      return new Iterator<TypeSymbol>(){
        List<TypeSymbol> seen=List.nil();
        TypeSymbol currentSym=getSymbol(intype);
        public boolean hasNext(){
          return currentSym != null;
        }
        public TypeSymbol next(){
          TypeSymbol prevSym=currentSym;
          currentSym=getSymbol(types.supertype(currentSym.type));
          return prevSym;
        }
        public void remove(){
          throw new UnsupportedOperationException(""String_Node_Str"");
        }
        TypeSymbol getSymbol(        Type intype){
          if (intype.tag != CLASS && intype.tag != TYPEVAR) {
            return null;
          }
          while (intype.tag == TYPEVAR)           intype=intype.getUpperBound();
          if (seen.contains(intype.tsym)) {
            return null;
          }
          seen=seen.prepend(intype.tsym);
          return intype.tsym;
        }
      }
;
    }
  }
;
}","/** 
 * Return an Iterable object to scan the superclasses of a given type. It's crucial that the scan is done lazily, as we don't want to accidentally access more supertypes than strictly needed (as this could trigger completion errors if some of the not-needed supertypes are missing/ill-formed).
 */
Iterable<TypeSymbol> superclasses(final Type intype){
  return new Iterable<TypeSymbol>(){
    public Iterator<TypeSymbol> iterator(){
      return new Iterator<TypeSymbol>(){
        List<TypeSymbol> seen=List.nil();
        TypeSymbol currentSym=symbolFor(intype);
        TypeSymbol prevSym=null;
        public boolean hasNext(){
          if (currentSym == syms.noSymbol) {
            currentSym=symbolFor(types.supertype(prevSym.type));
          }
          return currentSym != null;
        }
        public TypeSymbol next(){
          prevSym=currentSym;
          currentSym=syms.noSymbol;
          Assert.check(prevSym != null || prevSym != syms.noSymbol);
          return prevSym;
        }
        public void remove(){
          throw new UnsupportedOperationException();
        }
        TypeSymbol symbolFor(        Type t){
          if (t.tag != CLASS && t.tag != TYPEVAR) {
            return null;
          }
          while (t.tag == TYPEVAR)           t=t.getUpperBound();
          if (seen.contains(t.tsym)) {
            return null;
          }
          seen=seen.prepend(t.tsym);
          return t.tsym;
        }
      }
;
    }
  }
;
}"
37177,"private Symbol findMethod(Env<AttrContext> env,Type site,Name name,List<Type> argtypes,List<Type> typeargtypes,Type intype,Symbol bestSoFar,boolean allowBoxing,boolean useVarargs,boolean operator){
  boolean abstractOk=true;
  List<Type> itypes=List.nil();
  for (  TypeSymbol s : superclasses(intype)) {
    bestSoFar=lookupMethod(env,site,name,argtypes,typeargtypes,s.members(),bestSoFar,allowBoxing,useVarargs,operator,true);
    abstractOk&=excludeAbstractsFilter.accepts(s);
    if (abstractOk) {
      for (      Type itype : types.interfaces(s.type)) {
        itypes=types.union(types.closure(itype),itypes);
      }
    }
    if (name == names.init)     break;
  }
  Symbol concrete=bestSoFar.kind < ERR && (bestSoFar.flags() & ABSTRACT) == 0 ? bestSoFar : methodNotFound;
  if (name != names.init) {
    for (    Type itype : itypes) {
      if (!itype.isInterface())       continue;
      bestSoFar=lookupMethod(env,site,name,argtypes,typeargtypes,itype.tsym.members(),bestSoFar,allowBoxing,useVarargs,operator,true);
      if (concrete != bestSoFar && concrete.kind < ERR && bestSoFar.kind < ERR && types.isSubSignature(concrete.type,bestSoFar.type)) {
        bestSoFar=concrete;
      }
    }
  }
  return bestSoFar;
}","private Symbol findMethod(Env<AttrContext> env,Type site,Name name,List<Type> argtypes,List<Type> typeargtypes,Type intype,Symbol bestSoFar,boolean allowBoxing,boolean useVarargs,boolean operator){
  boolean abstractOk=true;
  List<Type> itypes=List.nil();
  for (  TypeSymbol s : superclasses(intype)) {
    bestSoFar=lookupMethod(env,site,name,argtypes,typeargtypes,s.members(),bestSoFar,allowBoxing,useVarargs,operator,true);
    abstractOk&=(s.flags() & (ABSTRACT | INTERFACE | ENUM)) != 0;
    if (abstractOk) {
      for (      Type itype : types.interfaces(s.type)) {
        itypes=types.union(types.closure(itype),itypes);
      }
    }
    if (name == names.init)     break;
  }
  Symbol concrete=bestSoFar.kind < ERR && (bestSoFar.flags() & ABSTRACT) == 0 ? bestSoFar : methodNotFound;
  if (name != names.init) {
    for (    Type itype : itypes) {
      if (!itype.isInterface())       continue;
      bestSoFar=lookupMethod(env,site,name,argtypes,typeargtypes,itype.tsym.members(),bestSoFar,allowBoxing,useVarargs,operator,true);
      if (concrete != bestSoFar && concrete.kind < ERR && bestSoFar.kind < ERR && types.isSubSignature(concrete.type,bestSoFar.type)) {
        bestSoFar=concrete;
      }
    }
  }
  return bestSoFar;
}"
37178,"public boolean accepts(Name n){
  return n == names.init;
}","public boolean accepts(Name n){
  return n == n.table.names.init;
}"
37179,"public MethodHandle(int refKind,Symbol refSym,Names names){
  this.refKind=refKind;
  this.refSym=refSym;
  this.names=names;
  checkConsistent();
}","public MethodHandle(int refKind,Symbol refSym){
  this.refKind=refKind;
  this.refSym=refSym;
  checkConsistent();
}"
37180,"public Names(Context context){
  Options options=Options.instance(context);
  table=createTable(options);
  asterisk=fromString(""String_Node_Str"");
  comma=fromString(""String_Node_Str"");
  empty=fromString(""String_Node_Str"");
  hyphen=fromString(""String_Node_Str"");
  one=fromString(""String_Node_Str"");
  period=fromString(""String_Node_Str"");
  semicolon=fromString(""String_Node_Str"");
  slash=fromString(""String_Node_Str"");
  slashequals=fromString(""String_Node_Str"");
  _class=fromString(""String_Node_Str"");
  _default=fromString(""String_Node_Str"");
  _super=fromString(""String_Node_Str"");
  _this=fromString(""String_Node_Str"");
  _name=fromString(""String_Node_Str"");
  addSuppressed=fromString(""String_Node_Str"");
  any=fromString(""String_Node_Str"");
  append=fromString(""String_Node_Str"");
  clinit=fromString(""String_Node_Str"");
  clone=fromString(""String_Node_Str"");
  close=fromString(""String_Node_Str"");
  compareTo=fromString(""String_Node_Str"");
  desiredAssertionStatus=fromString(""String_Node_Str"");
  equals=fromString(""String_Node_Str"");
  error=fromString(""String_Node_Str"");
  family=fromString(""String_Node_Str"");
  finalize=fromString(""String_Node_Str"");
  forName=fromString(""String_Node_Str"");
  getClass=fromString(""String_Node_Str"");
  getClassLoader=fromString(""String_Node_Str"");
  getComponentType=fromString(""String_Node_Str"");
  getDeclaringClass=fromString(""String_Node_Str"");
  getMessage=fromString(""String_Node_Str"");
  hasNext=fromString(""String_Node_Str"");
  hashCode=fromString(""String_Node_Str"");
  init=fromString(""String_Node_Str"");
  initCause=fromString(""String_Node_Str"");
  iterator=fromString(""String_Node_Str"");
  length=fromString(""String_Node_Str"");
  next=fromString(""String_Node_Str"");
  ordinal=fromString(""String_Node_Str"");
  serialVersionUID=fromString(""String_Node_Str"");
  toString=fromString(""String_Node_Str"");
  value=fromString(""String_Node_Str"");
  valueOf=fromString(""String_Node_Str"");
  values=fromString(""String_Node_Str"");
  java_io_Serializable=fromString(""String_Node_Str"");
  java_lang_AutoCloseable=fromString(""String_Node_Str"");
  java_lang_Class=fromString(""String_Node_Str"");
  java_lang_Cloneable=fromString(""String_Node_Str"");
  java_lang_Enum=fromString(""String_Node_Str"");
  java_lang_Object=fromString(""String_Node_Str"");
  java_lang_invoke_MethodHandle=fromString(""String_Node_Str"");
  Array=fromString(""String_Node_Str"");
  Bound=fromString(""String_Node_Str"");
  Method=fromString(""String_Node_Str"");
  java_lang=fromString(""String_Node_Str"");
  Annotation=fromString(""String_Node_Str"");
  AnnotationDefault=fromString(""String_Node_Str"");
  Bridge=fromString(""String_Node_Str"");
  CharacterRangeTable=fromString(""String_Node_Str"");
  Code=fromString(""String_Node_Str"");
  CompilationID=fromString(""String_Node_Str"");
  ConstantValue=fromString(""String_Node_Str"");
  Deprecated=fromString(""String_Node_Str"");
  EnclosingMethod=fromString(""String_Node_Str"");
  Enum=fromString(""String_Node_Str"");
  Exceptions=fromString(""String_Node_Str"");
  InnerClasses=fromString(""String_Node_Str"");
  LineNumberTable=fromString(""String_Node_Str"");
  LocalVariableTable=fromString(""String_Node_Str"");
  LocalVariableTypeTable=fromString(""String_Node_Str"");
  RuntimeInvisibleAnnotations=fromString(""String_Node_Str"");
  RuntimeInvisibleParameterAnnotations=fromString(""String_Node_Str"");
  RuntimeInvisibleTypeAnnotations=fromString(""String_Node_Str"");
  RuntimeVisibleAnnotations=fromString(""String_Node_Str"");
  RuntimeVisibleParameterAnnotations=fromString(""String_Node_Str"");
  RuntimeVisibleTypeAnnotations=fromString(""String_Node_Str"");
  Signature=fromString(""String_Node_Str"");
  SourceFile=fromString(""String_Node_Str"");
  SourceID=fromString(""String_Node_Str"");
  StackMap=fromString(""String_Node_Str"");
  StackMapTable=fromString(""String_Node_Str"");
  Synthetic=fromString(""String_Node_Str"");
  Value=fromString(""String_Node_Str"");
  Varargs=fromString(""String_Node_Str"");
  ANNOTATION_TYPE=fromString(""String_Node_Str"");
  CONSTRUCTOR=fromString(""String_Node_Str"");
  FIELD=fromString(""String_Node_Str"");
  LOCAL_VARIABLE=fromString(""String_Node_Str"");
  METHOD=fromString(""String_Node_Str"");
  PACKAGE=fromString(""String_Node_Str"");
  PARAMETER=fromString(""String_Node_Str"");
  TYPE=fromString(""String_Node_Str"");
  TYPE_PARAMETER=fromString(""String_Node_Str"");
  TYPE_USE=fromString(""String_Node_Str"");
  CLASS=fromString(""String_Node_Str"");
  RUNTIME=fromString(""String_Node_Str"");
  SOURCE=fromString(""String_Node_Str"");
  T=fromString(""String_Node_Str"");
  deprecated=fromString(""String_Node_Str"");
  ex=fromString(""String_Node_Str"");
  package_info=fromString(""String_Node_Str"");
  BootstrapMethods=fromString(""String_Node_Str"");
}","public Names(Context context){
  Options options=Options.instance(context);
  table=createTable(options);
  asterisk=fromString(""String_Node_Str"");
  comma=fromString(""String_Node_Str"");
  empty=fromString(""String_Node_Str"");
  hyphen=fromString(""String_Node_Str"");
  one=fromString(""String_Node_Str"");
  period=fromString(""String_Node_Str"");
  semicolon=fromString(""String_Node_Str"");
  slash=fromString(""String_Node_Str"");
  slashequals=fromString(""String_Node_Str"");
  _class=fromString(""String_Node_Str"");
  _default=fromString(""String_Node_Str"");
  _super=fromString(""String_Node_Str"");
  _this=fromString(""String_Node_Str"");
  _name=fromString(""String_Node_Str"");
  addSuppressed=fromString(""String_Node_Str"");
  any=fromString(""String_Node_Str"");
  append=fromString(""String_Node_Str"");
  clinit=fromString(""String_Node_Str"");
  clone=fromString(""String_Node_Str"");
  close=fromString(""String_Node_Str"");
  compareTo=fromString(""String_Node_Str"");
  desiredAssertionStatus=fromString(""String_Node_Str"");
  equals=fromString(""String_Node_Str"");
  error=fromString(""String_Node_Str"");
  family=fromString(""String_Node_Str"");
  finalize=fromString(""String_Node_Str"");
  forName=fromString(""String_Node_Str"");
  getClass=fromString(""String_Node_Str"");
  getClassLoader=fromString(""String_Node_Str"");
  getComponentType=fromString(""String_Node_Str"");
  getDeclaringClass=fromString(""String_Node_Str"");
  getMessage=fromString(""String_Node_Str"");
  hasNext=fromString(""String_Node_Str"");
  hashCode=fromString(""String_Node_Str"");
  init=fromString(""String_Node_Str"");
  initCause=fromString(""String_Node_Str"");
  iterator=fromString(""String_Node_Str"");
  length=fromString(""String_Node_Str"");
  next=fromString(""String_Node_Str"");
  ordinal=fromString(""String_Node_Str"");
  serialVersionUID=fromString(""String_Node_Str"");
  toString=fromString(""String_Node_Str"");
  value=fromString(""String_Node_Str"");
  valueOf=fromString(""String_Node_Str"");
  values=fromString(""String_Node_Str"");
  java_io_Serializable=fromString(""String_Node_Str"");
  java_lang_AutoCloseable=fromString(""String_Node_Str"");
  java_lang_Class=fromString(""String_Node_Str"");
  java_lang_Cloneable=fromString(""String_Node_Str"");
  java_lang_Enum=fromString(""String_Node_Str"");
  java_lang_Object=fromString(""String_Node_Str"");
  java_lang_invoke_MethodHandle=fromString(""String_Node_Str"");
  Array=fromString(""String_Node_Str"");
  Bound=fromString(""String_Node_Str"");
  Method=fromString(""String_Node_Str"");
  java_lang=fromString(""String_Node_Str"");
  Annotation=fromString(""String_Node_Str"");
  AnnotationDefault=fromString(""String_Node_Str"");
  BootstrapMethods=fromString(""String_Node_Str"");
  Bridge=fromString(""String_Node_Str"");
  CharacterRangeTable=fromString(""String_Node_Str"");
  Code=fromString(""String_Node_Str"");
  CompilationID=fromString(""String_Node_Str"");
  ConstantValue=fromString(""String_Node_Str"");
  Deprecated=fromString(""String_Node_Str"");
  EnclosingMethod=fromString(""String_Node_Str"");
  Enum=fromString(""String_Node_Str"");
  Exceptions=fromString(""String_Node_Str"");
  InnerClasses=fromString(""String_Node_Str"");
  LineNumberTable=fromString(""String_Node_Str"");
  LocalVariableTable=fromString(""String_Node_Str"");
  LocalVariableTypeTable=fromString(""String_Node_Str"");
  RuntimeInvisibleAnnotations=fromString(""String_Node_Str"");
  RuntimeInvisibleParameterAnnotations=fromString(""String_Node_Str"");
  RuntimeInvisibleTypeAnnotations=fromString(""String_Node_Str"");
  RuntimeVisibleAnnotations=fromString(""String_Node_Str"");
  RuntimeVisibleParameterAnnotations=fromString(""String_Node_Str"");
  RuntimeVisibleTypeAnnotations=fromString(""String_Node_Str"");
  Signature=fromString(""String_Node_Str"");
  SourceFile=fromString(""String_Node_Str"");
  SourceID=fromString(""String_Node_Str"");
  StackMap=fromString(""String_Node_Str"");
  StackMapTable=fromString(""String_Node_Str"");
  Synthetic=fromString(""String_Node_Str"");
  Value=fromString(""String_Node_Str"");
  Varargs=fromString(""String_Node_Str"");
  ANNOTATION_TYPE=fromString(""String_Node_Str"");
  CONSTRUCTOR=fromString(""String_Node_Str"");
  FIELD=fromString(""String_Node_Str"");
  LOCAL_VARIABLE=fromString(""String_Node_Str"");
  METHOD=fromString(""String_Node_Str"");
  PACKAGE=fromString(""String_Node_Str"");
  PARAMETER=fromString(""String_Node_Str"");
  TYPE=fromString(""String_Node_Str"");
  TYPE_PARAMETER=fromString(""String_Node_Str"");
  TYPE_USE=fromString(""String_Node_Str"");
  CLASS=fromString(""String_Node_Str"");
  RUNTIME=fromString(""String_Node_Str"");
  SOURCE=fromString(""String_Node_Str"");
  T=fromString(""String_Node_Str"");
  deprecated=fromString(""String_Node_Str"");
  ex=fromString(""String_Node_Str"");
  package_info=fromString(""String_Node_Str"");
}"
37181,"public Iterator<TypeSymbol> iterator(){
  return new Iterator<TypeSymbol>(){
    List<TypeSymbol> seen=List.nil();
    TypeSymbol currentSym=getSymbol(intype);
    public boolean hasNext(){
      return currentSym != null;
    }
    public TypeSymbol next(){
      TypeSymbol prevSym=currentSym;
      currentSym=getSymbol(types.supertype(currentSym.type));
      return prevSym;
    }
    public void remove(){
      throw new UnsupportedOperationException(""String_Node_Str"");
    }
    TypeSymbol getSymbol(    Type intype){
      if (intype.tag != CLASS && intype.tag != TYPEVAR) {
        return null;
      }
      while (intype.tag == TYPEVAR)       intype=intype.getUpperBound();
      if (seen.contains(intype.tsym)) {
        return null;
      }
      seen=seen.prepend(intype.tsym);
      return intype.tsym;
    }
  }
;
}","public Iterator<TypeSymbol> iterator(){
  return new Iterator<TypeSymbol>(){
    List<TypeSymbol> seen=List.nil();
    TypeSymbol currentSym=symbolFor(intype);
    TypeSymbol prevSym=null;
    public boolean hasNext(){
      if (currentSym == syms.noSymbol) {
        currentSym=symbolFor(types.supertype(prevSym.type));
      }
      return currentSym != null;
    }
    public TypeSymbol next(){
      prevSym=currentSym;
      currentSym=syms.noSymbol;
      Assert.check(prevSym != null || prevSym != syms.noSymbol);
      return prevSym;
    }
    public void remove(){
      throw new UnsupportedOperationException();
    }
    TypeSymbol symbolFor(    Type t){
      if (t.tag != CLASS && t.tag != TYPEVAR) {
        return null;
      }
      while (t.tag == TYPEVAR)       t=t.getUpperBound();
      if (seen.contains(t.tsym)) {
        return null;
      }
      seen=seen.prepend(t.tsym);
      return t.tsym;
    }
  }
;
}"
37182,"public boolean hasNext(){
  return currentSym != null;
}","public boolean hasNext(){
  if (currentSym == syms.noSymbol) {
    currentSym=symbolFor(types.supertype(prevSym.type));
  }
  return currentSym != null;
}"
37183,"public TypeSymbol next(){
  TypeSymbol prevSym=currentSym;
  currentSym=getSymbol(types.supertype(currentSym.type));
  return prevSym;
}","public TypeSymbol next(){
  prevSym=currentSym;
  currentSym=syms.noSymbol;
  Assert.check(prevSym != null || prevSym != syms.noSymbol);
  return prevSym;
}"
37184,"public void remove(){
  throw new UnsupportedOperationException(""String_Node_Str"");
}","public void remove(){
  throw new UnsupportedOperationException();
}"
37185,"/** 
 * Return an Iterable object to scan the superclasses of a given type. It's crucial that the scan is done lazily, as we don't want to accidentally access more supertypes than strictly needed (as this could trigger completion errors if some of the not-needed supertypes are missing/ill-formed).
 */
Iterable<TypeSymbol> superclasses(final Type intype){
  return new Iterable<TypeSymbol>(){
    public Iterator<TypeSymbol> iterator(){
      return new Iterator<TypeSymbol>(){
        List<TypeSymbol> seen=List.nil();
        TypeSymbol currentSym=getSymbol(intype);
        public boolean hasNext(){
          return currentSym != null;
        }
        public TypeSymbol next(){
          TypeSymbol prevSym=currentSym;
          currentSym=getSymbol(types.supertype(currentSym.type));
          return prevSym;
        }
        public void remove(){
          throw new UnsupportedOperationException(""String_Node_Str"");
        }
        TypeSymbol getSymbol(        Type intype){
          if (intype.tag != CLASS && intype.tag != TYPEVAR) {
            return null;
          }
          while (intype.tag == TYPEVAR)           intype=intype.getUpperBound();
          if (seen.contains(intype.tsym)) {
            return null;
          }
          seen=seen.prepend(intype.tsym);
          return intype.tsym;
        }
      }
;
    }
  }
;
}","/** 
 * Return an Iterable object to scan the superclasses of a given type. It's crucial that the scan is done lazily, as we don't want to accidentally access more supertypes than strictly needed (as this could trigger completion errors if some of the not-needed supertypes are missing/ill-formed).
 */
Iterable<TypeSymbol> superclasses(final Type intype){
  return new Iterable<TypeSymbol>(){
    public Iterator<TypeSymbol> iterator(){
      return new Iterator<TypeSymbol>(){
        List<TypeSymbol> seen=List.nil();
        TypeSymbol currentSym=symbolFor(intype);
        TypeSymbol prevSym=null;
        public boolean hasNext(){
          if (currentSym == syms.noSymbol) {
            currentSym=symbolFor(types.supertype(prevSym.type));
          }
          return currentSym != null;
        }
        public TypeSymbol next(){
          prevSym=currentSym;
          currentSym=syms.noSymbol;
          Assert.check(prevSym != null || prevSym != syms.noSymbol);
          return prevSym;
        }
        public void remove(){
          throw new UnsupportedOperationException();
        }
        TypeSymbol symbolFor(        Type t){
          if (t.tag != CLASS && t.tag != TYPEVAR) {
            return null;
          }
          while (t.tag == TYPEVAR)           t=t.getUpperBound();
          if (seen.contains(t.tsym)) {
            return null;
          }
          seen=seen.prepend(t.tsym);
          return t.tsym;
        }
      }
;
    }
  }
;
}"
37186,"private Symbol findMethod(Env<AttrContext> env,Type site,Name name,List<Type> argtypes,List<Type> typeargtypes,Type intype,Symbol bestSoFar,boolean allowBoxing,boolean useVarargs,boolean operator){
  boolean abstractOk=true;
  List<Type> itypes=List.nil();
  for (  TypeSymbol s : superclasses(intype)) {
    bestSoFar=lookupMethod(env,site,name,argtypes,typeargtypes,s.members(),bestSoFar,allowBoxing,useVarargs,operator,true);
    abstractOk&=excludeAbstractsFilter.accepts(s);
    if (abstractOk) {
      for (      Type itype : types.interfaces(s.type)) {
        itypes=types.union(types.closure(itype),itypes);
      }
    }
    if (name == names.init)     break;
  }
  Symbol concrete=bestSoFar.kind < ERR && (bestSoFar.flags() & ABSTRACT) == 0 ? bestSoFar : methodNotFound;
  if (name != names.init) {
    for (    Type itype : itypes) {
      if (!itype.isInterface())       continue;
      bestSoFar=lookupMethod(env,site,name,argtypes,typeargtypes,itype.tsym.members(),bestSoFar,allowBoxing,useVarargs,operator,true);
      if (concrete != bestSoFar && concrete.kind < ERR && bestSoFar.kind < ERR && types.isSubSignature(concrete.type,bestSoFar.type)) {
        bestSoFar=concrete;
      }
    }
  }
  return bestSoFar;
}","private Symbol findMethod(Env<AttrContext> env,Type site,Name name,List<Type> argtypes,List<Type> typeargtypes,Type intype,Symbol bestSoFar,boolean allowBoxing,boolean useVarargs,boolean operator){
  boolean abstractOk=true;
  List<Type> itypes=List.nil();
  for (  TypeSymbol s : superclasses(intype)) {
    bestSoFar=lookupMethod(env,site,name,argtypes,typeargtypes,s.members(),bestSoFar,allowBoxing,useVarargs,operator,true);
    abstractOk&=(s.flags() & (ABSTRACT | INTERFACE | ENUM)) != 0;
    if (abstractOk) {
      for (      Type itype : types.interfaces(s.type)) {
        itypes=types.union(types.closure(itype),itypes);
      }
    }
    if (name == names.init)     break;
  }
  Symbol concrete=bestSoFar.kind < ERR && (bestSoFar.flags() & ABSTRACT) == 0 ? bestSoFar : methodNotFound;
  if (name != names.init) {
    for (    Type itype : itypes) {
      if (!itype.isInterface())       continue;
      bestSoFar=lookupMethod(env,site,name,argtypes,typeargtypes,itype.tsym.members(),bestSoFar,allowBoxing,useVarargs,operator,true);
      if (concrete != bestSoFar && concrete.kind < ERR && bestSoFar.kind < ERR && types.isSubSignature(concrete.type,bestSoFar.type)) {
        bestSoFar=concrete;
      }
    }
  }
  return bestSoFar;
}"
37187,"public boolean accepts(Name n){
  return n == names.init;
}","public boolean accepts(Name n){
  return n == n.table.names.init;
}"
37188,"public MethodHandle(int refKind,Symbol refSym,Names names){
  this.refKind=refKind;
  this.refSym=refSym;
  this.names=names;
  checkConsistent();
}","public MethodHandle(int refKind,Symbol refSym){
  this.refKind=refKind;
  this.refSym=refSym;
  checkConsistent();
}"
37189,"public Names(Context context){
  Options options=Options.instance(context);
  table=createTable(options);
  asterisk=fromString(""String_Node_Str"");
  comma=fromString(""String_Node_Str"");
  empty=fromString(""String_Node_Str"");
  hyphen=fromString(""String_Node_Str"");
  one=fromString(""String_Node_Str"");
  period=fromString(""String_Node_Str"");
  semicolon=fromString(""String_Node_Str"");
  slash=fromString(""String_Node_Str"");
  slashequals=fromString(""String_Node_Str"");
  _class=fromString(""String_Node_Str"");
  _default=fromString(""String_Node_Str"");
  _super=fromString(""String_Node_Str"");
  _this=fromString(""String_Node_Str"");
  _name=fromString(""String_Node_Str"");
  addSuppressed=fromString(""String_Node_Str"");
  any=fromString(""String_Node_Str"");
  append=fromString(""String_Node_Str"");
  clinit=fromString(""String_Node_Str"");
  clone=fromString(""String_Node_Str"");
  close=fromString(""String_Node_Str"");
  compareTo=fromString(""String_Node_Str"");
  desiredAssertionStatus=fromString(""String_Node_Str"");
  equals=fromString(""String_Node_Str"");
  error=fromString(""String_Node_Str"");
  family=fromString(""String_Node_Str"");
  finalize=fromString(""String_Node_Str"");
  forName=fromString(""String_Node_Str"");
  getClass=fromString(""String_Node_Str"");
  getClassLoader=fromString(""String_Node_Str"");
  getComponentType=fromString(""String_Node_Str"");
  getDeclaringClass=fromString(""String_Node_Str"");
  getMessage=fromString(""String_Node_Str"");
  hasNext=fromString(""String_Node_Str"");
  hashCode=fromString(""String_Node_Str"");
  init=fromString(""String_Node_Str"");
  initCause=fromString(""String_Node_Str"");
  iterator=fromString(""String_Node_Str"");
  length=fromString(""String_Node_Str"");
  next=fromString(""String_Node_Str"");
  ordinal=fromString(""String_Node_Str"");
  serialVersionUID=fromString(""String_Node_Str"");
  toString=fromString(""String_Node_Str"");
  value=fromString(""String_Node_Str"");
  valueOf=fromString(""String_Node_Str"");
  values=fromString(""String_Node_Str"");
  java_io_Serializable=fromString(""String_Node_Str"");
  java_lang_AutoCloseable=fromString(""String_Node_Str"");
  java_lang_Class=fromString(""String_Node_Str"");
  java_lang_Cloneable=fromString(""String_Node_Str"");
  java_lang_Enum=fromString(""String_Node_Str"");
  java_lang_Object=fromString(""String_Node_Str"");
  java_lang_invoke_MethodHandle=fromString(""String_Node_Str"");
  Array=fromString(""String_Node_Str"");
  Bound=fromString(""String_Node_Str"");
  Method=fromString(""String_Node_Str"");
  java_lang=fromString(""String_Node_Str"");
  Annotation=fromString(""String_Node_Str"");
  AnnotationDefault=fromString(""String_Node_Str"");
  Bridge=fromString(""String_Node_Str"");
  CharacterRangeTable=fromString(""String_Node_Str"");
  Code=fromString(""String_Node_Str"");
  CompilationID=fromString(""String_Node_Str"");
  ConstantValue=fromString(""String_Node_Str"");
  Deprecated=fromString(""String_Node_Str"");
  EnclosingMethod=fromString(""String_Node_Str"");
  Enum=fromString(""String_Node_Str"");
  Exceptions=fromString(""String_Node_Str"");
  InnerClasses=fromString(""String_Node_Str"");
  LineNumberTable=fromString(""String_Node_Str"");
  LocalVariableTable=fromString(""String_Node_Str"");
  LocalVariableTypeTable=fromString(""String_Node_Str"");
  RuntimeInvisibleAnnotations=fromString(""String_Node_Str"");
  RuntimeInvisibleParameterAnnotations=fromString(""String_Node_Str"");
  RuntimeInvisibleTypeAnnotations=fromString(""String_Node_Str"");
  RuntimeVisibleAnnotations=fromString(""String_Node_Str"");
  RuntimeVisibleParameterAnnotations=fromString(""String_Node_Str"");
  RuntimeVisibleTypeAnnotations=fromString(""String_Node_Str"");
  Signature=fromString(""String_Node_Str"");
  SourceFile=fromString(""String_Node_Str"");
  SourceID=fromString(""String_Node_Str"");
  StackMap=fromString(""String_Node_Str"");
  StackMapTable=fromString(""String_Node_Str"");
  Synthetic=fromString(""String_Node_Str"");
  Value=fromString(""String_Node_Str"");
  Varargs=fromString(""String_Node_Str"");
  ANNOTATION_TYPE=fromString(""String_Node_Str"");
  CONSTRUCTOR=fromString(""String_Node_Str"");
  FIELD=fromString(""String_Node_Str"");
  LOCAL_VARIABLE=fromString(""String_Node_Str"");
  METHOD=fromString(""String_Node_Str"");
  PACKAGE=fromString(""String_Node_Str"");
  PARAMETER=fromString(""String_Node_Str"");
  TYPE=fromString(""String_Node_Str"");
  TYPE_PARAMETER=fromString(""String_Node_Str"");
  TYPE_USE=fromString(""String_Node_Str"");
  CLASS=fromString(""String_Node_Str"");
  RUNTIME=fromString(""String_Node_Str"");
  SOURCE=fromString(""String_Node_Str"");
  T=fromString(""String_Node_Str"");
  deprecated=fromString(""String_Node_Str"");
  ex=fromString(""String_Node_Str"");
  package_info=fromString(""String_Node_Str"");
  BootstrapMethods=fromString(""String_Node_Str"");
}","public Names(Context context){
  Options options=Options.instance(context);
  table=createTable(options);
  asterisk=fromString(""String_Node_Str"");
  comma=fromString(""String_Node_Str"");
  empty=fromString(""String_Node_Str"");
  hyphen=fromString(""String_Node_Str"");
  one=fromString(""String_Node_Str"");
  period=fromString(""String_Node_Str"");
  semicolon=fromString(""String_Node_Str"");
  slash=fromString(""String_Node_Str"");
  slashequals=fromString(""String_Node_Str"");
  _class=fromString(""String_Node_Str"");
  _default=fromString(""String_Node_Str"");
  _super=fromString(""String_Node_Str"");
  _this=fromString(""String_Node_Str"");
  _name=fromString(""String_Node_Str"");
  addSuppressed=fromString(""String_Node_Str"");
  any=fromString(""String_Node_Str"");
  append=fromString(""String_Node_Str"");
  clinit=fromString(""String_Node_Str"");
  clone=fromString(""String_Node_Str"");
  close=fromString(""String_Node_Str"");
  compareTo=fromString(""String_Node_Str"");
  desiredAssertionStatus=fromString(""String_Node_Str"");
  equals=fromString(""String_Node_Str"");
  error=fromString(""String_Node_Str"");
  family=fromString(""String_Node_Str"");
  finalize=fromString(""String_Node_Str"");
  forName=fromString(""String_Node_Str"");
  getClass=fromString(""String_Node_Str"");
  getClassLoader=fromString(""String_Node_Str"");
  getComponentType=fromString(""String_Node_Str"");
  getDeclaringClass=fromString(""String_Node_Str"");
  getMessage=fromString(""String_Node_Str"");
  hasNext=fromString(""String_Node_Str"");
  hashCode=fromString(""String_Node_Str"");
  init=fromString(""String_Node_Str"");
  initCause=fromString(""String_Node_Str"");
  iterator=fromString(""String_Node_Str"");
  length=fromString(""String_Node_Str"");
  next=fromString(""String_Node_Str"");
  ordinal=fromString(""String_Node_Str"");
  serialVersionUID=fromString(""String_Node_Str"");
  toString=fromString(""String_Node_Str"");
  value=fromString(""String_Node_Str"");
  valueOf=fromString(""String_Node_Str"");
  values=fromString(""String_Node_Str"");
  java_io_Serializable=fromString(""String_Node_Str"");
  java_lang_AutoCloseable=fromString(""String_Node_Str"");
  java_lang_Class=fromString(""String_Node_Str"");
  java_lang_Cloneable=fromString(""String_Node_Str"");
  java_lang_Enum=fromString(""String_Node_Str"");
  java_lang_Object=fromString(""String_Node_Str"");
  java_lang_invoke_MethodHandle=fromString(""String_Node_Str"");
  Array=fromString(""String_Node_Str"");
  Bound=fromString(""String_Node_Str"");
  Method=fromString(""String_Node_Str"");
  java_lang=fromString(""String_Node_Str"");
  Annotation=fromString(""String_Node_Str"");
  AnnotationDefault=fromString(""String_Node_Str"");
  BootstrapMethods=fromString(""String_Node_Str"");
  Bridge=fromString(""String_Node_Str"");
  CharacterRangeTable=fromString(""String_Node_Str"");
  Code=fromString(""String_Node_Str"");
  CompilationID=fromString(""String_Node_Str"");
  ConstantValue=fromString(""String_Node_Str"");
  Deprecated=fromString(""String_Node_Str"");
  EnclosingMethod=fromString(""String_Node_Str"");
  Enum=fromString(""String_Node_Str"");
  Exceptions=fromString(""String_Node_Str"");
  InnerClasses=fromString(""String_Node_Str"");
  LineNumberTable=fromString(""String_Node_Str"");
  LocalVariableTable=fromString(""String_Node_Str"");
  LocalVariableTypeTable=fromString(""String_Node_Str"");
  RuntimeInvisibleAnnotations=fromString(""String_Node_Str"");
  RuntimeInvisibleParameterAnnotations=fromString(""String_Node_Str"");
  RuntimeInvisibleTypeAnnotations=fromString(""String_Node_Str"");
  RuntimeVisibleAnnotations=fromString(""String_Node_Str"");
  RuntimeVisibleParameterAnnotations=fromString(""String_Node_Str"");
  RuntimeVisibleTypeAnnotations=fromString(""String_Node_Str"");
  Signature=fromString(""String_Node_Str"");
  SourceFile=fromString(""String_Node_Str"");
  SourceID=fromString(""String_Node_Str"");
  StackMap=fromString(""String_Node_Str"");
  StackMapTable=fromString(""String_Node_Str"");
  Synthetic=fromString(""String_Node_Str"");
  Value=fromString(""String_Node_Str"");
  Varargs=fromString(""String_Node_Str"");
  ANNOTATION_TYPE=fromString(""String_Node_Str"");
  CONSTRUCTOR=fromString(""String_Node_Str"");
  FIELD=fromString(""String_Node_Str"");
  LOCAL_VARIABLE=fromString(""String_Node_Str"");
  METHOD=fromString(""String_Node_Str"");
  PACKAGE=fromString(""String_Node_Str"");
  PARAMETER=fromString(""String_Node_Str"");
  TYPE=fromString(""String_Node_Str"");
  TYPE_PARAMETER=fromString(""String_Node_Str"");
  TYPE_USE=fromString(""String_Node_Str"");
  CLASS=fromString(""String_Node_Str"");
  RUNTIME=fromString(""String_Node_Str"");
  SOURCE=fromString(""String_Node_Str"");
  T=fromString(""String_Node_Str"");
  deprecated=fromString(""String_Node_Str"");
  ex=fromString(""String_Node_Str"");
  package_info=fromString(""String_Node_Str"");
}"
37190,"/** 
 * Return the first sentence of the comment as an array of tags. Includes inline tags (i.e. {&#64link <i>reference</i>} tags)  but not block tags. Each section of plain text is represented as a   {@link Tag}of   {@linkplain Tag#kind() kind} ""Text"".Inline tags are represented as a  {@link SeeTag} of kind ""@see""and name ""@link"". <p> If the locale is English language, the first sentence is determined by the rules described in the Java Language Specification (first version): &quot;This sentence ends at the first period that is followed by a blank, tab, or line terminator or at the first tagline.&quot;, in addition a line will be terminated by block HTML tags: &lt;p&gt;  &lt;/p&gt;  &lt;h1&gt; &lt;h2&gt;  &lt;h3&gt; &lt;h4&gt;  &lt;h5&gt;  &lt;h6&gt; &lt;hr&gt;  &lt;pre&gt;  or &lt;/pre&gt;. If the locale is not English, the sentence end will be determined by {@link BreakIterator#getSentenceInstance(Locale)}.
 * @return an array of {@link Tag}s representing the first sentence of the comment
 */
Tag[] firstSentenceTags();","/** 
 * Return the first sentence of the comment as an array of tags. Includes inline tags (i.e. {&#64;link <i>reference</i>} tags)  but not block tags. Each section of plain text is represented as a   {@link Tag}of   {@linkplain Tag#kind() kind} ""Text"".Inline tags are represented as a  {@link SeeTag} of kind ""@see""and name ""@link"". <p> If the locale is English language, the first sentence is determined by the rules described in the Java Language Specification (first version): &quot;This sentence ends at the first period that is followed by a blank, tab, or line terminator or at the first tagline.&quot;, in addition a line will be terminated by block HTML tags: &lt;p&gt;  &lt;/p&gt;  &lt;h1&gt; &lt;h2&gt;  &lt;h3&gt; &lt;h4&gt;  &lt;h5&gt;  &lt;h6&gt; &lt;hr&gt;  &lt;pre&gt;  or &lt;/pre&gt;. If the locale is not English, the sentence end will be determined by {@link BreakIterator#getSentenceInstance(Locale)}.
 * @return an array of {@link Tag}s representing the first sentence of the comment
 */
Tag[] firstSentenceTags();"
37191,"/** 
 * Return comment as an array of tags. Includes inline tags (i.e. {&#64link <i>reference</i>} tags)  but not block tags. Each section of plain text is represented as a   {@link Tag}of   {@linkplain Tag#kind() kind} ""Text"".Inline tags are represented as a  {@link SeeTag} of kind ""@see""and name ""@link"".
 * @return an array of {@link Tag}s representing the comment
 */
Tag[] inlineTags();","/** 
 * Return comment as an array of tags. Includes inline tags (i.e. {&#64;link <i>reference</i>} tags)  but not block tags. Each section of plain text is represented as a   {@link Tag}of   {@linkplain Tag#kind() kind} ""Text"".Inline tags are represented as a  {@link SeeTag} of kind ""@see""and name ""@link"".
 * @return an array of {@link Tag}s representing the comment
 */
Tag[] inlineTags();"
37192,"/** 
 * Return the param tags in this method, excluding the type parameter tags.
 * @return an array of ParamTag containing all <code>&#64param</code> tagscorresponding to the parameters of this method.
 */
ParamTag[] paramTags();","/** 
 * Return the param tags in this method, excluding the type parameter tags.
 * @return an array of ParamTag containing all <code>&#64;param</code> tagscorresponding to the parameters of this method.
 */
ParamTag[] paramTags();"
37193,"/** 
 * Return the type parameter tags in this method.
 * @return an array of ParamTag containing all <code>&#64param</code> tagscorresponding to the type parameters of this method.
 * @since 1.5
 */
ParamTag[] typeParamTags();","/** 
 * Return the type parameter tags in this method.
 * @return an array of ParamTag containing all <code>&#64;param</code> tagscorresponding to the type parameters of this method.
 * @since 1.5
 */
ParamTag[] typeParamTags();"
37194,"/** 
 * Return the throws tags in this method.
 * @return an array of ThrowTag containing all <code>&#64exception</code>and <code>&#64throws</code> tags.
 */
ThrowsTag[] throwsTags();","/** 
 * Return the throws tags in this method.
 * @return an array of ThrowTag containing all <code>&#64;exception</code>and <code>&#64;throws</code> tags.
 */
ThrowsTag[] throwsTags();"
37195,"/** 
 * Return the first sentence of the comment as an array of tags. Includes inline tags (i.e. {&#64link <i>reference</i>} tags)  but not block tags. Each section of plain text is represented as a   {@link Tag}of kind ""Text"". Inline tags are represented as a   {@link SeeTag} of kind ""@link"".If the locale is English language, the first sentence is determined by the rules described in the Java Language Specification (first version): &quot;This sentence ends at the first period that is followed by a blank, tab, or line terminator or at the first tagline.&quot;, in addition a line will be terminated by paragraph and section terminating HTML tags: &lt;p&gt;  &lt;/p&gt;  &lt;h1&gt; &lt;h2&gt;  &lt;h3&gt; &lt;h4&gt;  &lt;h5&gt;  &lt;h6&gt; &lt;hr&gt;  &lt;pre&gt;  or &lt;/pre&gt;. If the locale is not English, the sentence end will be determined by {@link BreakIterator#getSentenceInstance(Locale)}.
 * @return an array of {@link Tag} objects representing thefirst sentence of the comment
 */
Tag[] firstSentenceTags();","/** 
 * Return the first sentence of the comment as an array of tags. Includes inline tags (i.e. {&#64;link <i>reference</i>} tags)  but not block tags. Each section of plain text is represented as a   {@link Tag}of kind ""Text"". Inline tags are represented as a   {@link SeeTag} of kind ""@link"".If the locale is English language, the first sentence is determined by the rules described in the Java Language Specification (first version): &quot;This sentence ends at the first period that is followed by a blank, tab, or line terminator or at the first tagline.&quot;, in addition a line will be terminated by paragraph and section terminating HTML tags: &lt;p&gt;  &lt;/p&gt;  &lt;h1&gt; &lt;h2&gt;  &lt;h3&gt; &lt;h4&gt;  &lt;h5&gt;  &lt;h6&gt; &lt;hr&gt;  &lt;pre&gt;  or &lt;/pre&gt;. If the locale is not English, the sentence end will be determined by {@link BreakIterator#getSentenceInstance(Locale)}.
 * @return an array of {@link Tag} objects representing thefirst sentence of the comment
 */
Tag[] firstSentenceTags();"
37196,"/** 
 * Find the start position of a line.
 * @param line line number (beginning at 1)
 * @return     position of first character in line
 * @throws IndexOutOfBoundsException if <tt>lineNumber < 1</tt> if <tt>lineNumber > no. of lines</tt>
 */
long getStartPosition(long line);","/** 
 * Find the start position of a line.
 * @param line line number (beginning at 1)
 * @return     position of first character in line
 * @throws IndexOutOfBoundsException if  {@code lineNumber < 1}if   {@code lineNumber > no. of lines}
 */
long getStartPosition(long line);"
37197,"/** 
 * Print the heading in Html &lt;H2> format.
 * @param str The Header string.
 */
public void printIndexHeading(String str){
  h2();
  print(str);
  h2End();
}","/** 
 * Print the heading in Html   {@literal <H2>} format.
 * @param str The Header string.
 */
public void printIndexHeading(String str){
  h2();
  print(str);
  h2End();
}"
37198,"/** 
 * Suppose a piece of documentation has a relative link.  When you copy that documetation to another place such as the index or class-use page, that relative link will no longer work.  We should redirect those links so that they will work again. <p> Here is the algorithm used to fix the link: <p> &lt;relative link&gt; => docRoot + &lt;relative path to file&gt; + &lt;relative link&gt; <p> For example, suppose com.sun.javadoc.RootDoc has this link: &lt;a href=""package-summary.html""&gt;The package Page&lt;/a&gt; <p> If this link appeared in the index, we would redirect the link like this: &lt;a href=""./com/sun/javadoc/package-summary.html""&gt;The package Page&lt;/a&gt;
 * @param doc the Doc object whose documentation is being written.
 * @param text the text being written.
 * @return the text, with all the relative links redirected to work.
 */
private String redirectRelativeLinks(Doc doc,String text){
  if (doc == null || shouldNotRedirectRelativeLinks()) {
    return text;
  }
  String redirectPathFromRoot;
  if (doc instanceof ClassDoc) {
    redirectPathFromRoot=DirectoryManager.getDirectoryPath(((ClassDoc)doc).containingPackage());
  }
 else   if (doc instanceof MemberDoc) {
    redirectPathFromRoot=DirectoryManager.getDirectoryPath(((MemberDoc)doc).containingPackage());
  }
 else   if (doc instanceof PackageDoc) {
    redirectPathFromRoot=DirectoryManager.getDirectoryPath((PackageDoc)doc);
  }
 else {
    return text;
  }
  if (!redirectPathFromRoot.endsWith(DirectoryManager.URL_FILE_SEPARATOR)) {
    redirectPathFromRoot+=DirectoryManager.URL_FILE_SEPARATOR;
  }
  int end, begin=text.toLowerCase().indexOf(""String_Node_Str"");
  if (begin >= 0) {
    StringBuffer textBuff=new StringBuffer(text);
    while (begin >= 0) {
      if (textBuff.length() > begin + 2 && !Character.isWhitespace(textBuff.charAt(begin + 2))) {
        begin=textBuff.toString().toLowerCase().indexOf(""String_Node_Str"",begin + 1);
        continue;
      }
      begin=textBuff.indexOf(""String_Node_Str"",begin) + 1;
      end=textBuff.indexOf(""String_Node_Str"",begin + 1);
      if (begin == 0) {
        configuration.root.printWarning(doc.position(),configuration.getText(""String_Node_Str"",text));
        break;
      }
      if (end == -1) {
        break;
      }
      if (textBuff.substring(begin,end).indexOf(""String_Node_Str"") != -1) {
        begin=textBuff.indexOf(""String_Node_Str"",begin) + 1;
        end=textBuff.indexOf(""String_Node_Str"",begin + 1);
        if (begin == 0 || end == -1) {
          break;
        }
      }
      String relativeLink=textBuff.substring(begin,end);
      if (!(relativeLink.toLowerCase().startsWith(""String_Node_Str"") || relativeLink.toLowerCase().startsWith(""String_Node_Str"") || relativeLink.toLowerCase().startsWith(""String_Node_Str"")|| relativeLink.toLowerCase().startsWith(""String_Node_Str""))) {
        relativeLink=""String_Node_Str"" + (new DocRootTaglet()).getName() + ""String_Node_Str""+ redirectPathFromRoot+ relativeLink;
        textBuff.replace(begin,end,relativeLink);
      }
      begin=textBuff.toString().toLowerCase().indexOf(""String_Node_Str"",begin + 1);
    }
    return textBuff.toString();
  }
  return text;
}","/** 
 * Suppose a piece of documentation has a relative link.  When you copy that documetation to another place such as the index or class-use page, that relative link will no longer work.  We should redirect those links so that they will work again. <p> Here is the algorithm used to fix the link: <p>  {@literal <relative link> => docRoot + <relative path to file> + <relative link> }<p> For example, suppose com.sun.javadoc.RootDoc has this link:  {@literal <a href=""package-summary.html"">The package Page</a> }<p> If this link appeared in the index, we would redirect the link like this:  {@literal <a href=""./com/sun/javadoc/package-summary.html"">The package Page</a>}
 * @param doc the Doc object whose documentation is being written.
 * @param text the text being written.
 * @return the text, with all the relative links redirected to work.
 */
private String redirectRelativeLinks(Doc doc,String text){
  if (doc == null || shouldNotRedirectRelativeLinks()) {
    return text;
  }
  String redirectPathFromRoot;
  if (doc instanceof ClassDoc) {
    redirectPathFromRoot=DirectoryManager.getDirectoryPath(((ClassDoc)doc).containingPackage());
  }
 else   if (doc instanceof MemberDoc) {
    redirectPathFromRoot=DirectoryManager.getDirectoryPath(((MemberDoc)doc).containingPackage());
  }
 else   if (doc instanceof PackageDoc) {
    redirectPathFromRoot=DirectoryManager.getDirectoryPath((PackageDoc)doc);
  }
 else {
    return text;
  }
  if (!redirectPathFromRoot.endsWith(DirectoryManager.URL_FILE_SEPARATOR)) {
    redirectPathFromRoot+=DirectoryManager.URL_FILE_SEPARATOR;
  }
  int end, begin=text.toLowerCase().indexOf(""String_Node_Str"");
  if (begin >= 0) {
    StringBuffer textBuff=new StringBuffer(text);
    while (begin >= 0) {
      if (textBuff.length() > begin + 2 && !Character.isWhitespace(textBuff.charAt(begin + 2))) {
        begin=textBuff.toString().toLowerCase().indexOf(""String_Node_Str"",begin + 1);
        continue;
      }
      begin=textBuff.indexOf(""String_Node_Str"",begin) + 1;
      end=textBuff.indexOf(""String_Node_Str"",begin + 1);
      if (begin == 0) {
        configuration.root.printWarning(doc.position(),configuration.getText(""String_Node_Str"",text));
        break;
      }
      if (end == -1) {
        break;
      }
      if (textBuff.substring(begin,end).indexOf(""String_Node_Str"") != -1) {
        begin=textBuff.indexOf(""String_Node_Str"",begin) + 1;
        end=textBuff.indexOf(""String_Node_Str"",begin + 1);
        if (begin == 0 || end == -1) {
          break;
        }
      }
      String relativeLink=textBuff.substring(begin,end);
      if (!(relativeLink.toLowerCase().startsWith(""String_Node_Str"") || relativeLink.toLowerCase().startsWith(""String_Node_Str"") || relativeLink.toLowerCase().startsWith(""String_Node_Str"")|| relativeLink.toLowerCase().startsWith(""String_Node_Str""))) {
        relativeLink=""String_Node_Str"" + (new DocRootTaglet()).getName() + ""String_Node_Str""+ redirectPathFromRoot+ relativeLink;
        textBuff.replace(begin,end,relativeLink);
      }
      begin=textBuff.toString().toLowerCase().indexOf(""String_Node_Str"",begin + 1);
    }
    return textBuff.toString();
  }
  return text;
}"
37199,"/** 
 * Handles the &lt;ClassDoc> tag.
 * @param node the XML element that specifies which components to document
 * @param contentTree the content tree to which the documentation will be added
 */
public void buildClassDoc(XMLNode node,Content contentTree) throws Exception {
  String key;
  if (isInterface) {
    key=""String_Node_Str"";
  }
 else   if (isEnum) {
    key=""String_Node_Str"";
  }
 else {
    key=""String_Node_Str"";
  }
  contentTree=writer.getHeader(configuration.getText(key) + ""String_Node_Str"" + classDoc.name());
  Content classContentTree=writer.getClassContentHeader();
  buildChildren(node,classContentTree);
  contentTree.addContent(classContentTree);
  writer.addFooter(contentTree);
  writer.printDocument(contentTree);
  writer.close();
  copyDocFiles();
}","/** 
 * Handles the   {@literal <ClassDoc>} tag.
 * @param node the XML element that specifies which components to document
 * @param contentTree the content tree to which the documentation will be added
 */
public void buildClassDoc(XMLNode node,Content contentTree) throws Exception {
  String key;
  if (isInterface) {
    key=""String_Node_Str"";
  }
 else   if (isEnum) {
    key=""String_Node_Str"";
  }
 else {
    key=""String_Node_Str"";
  }
  contentTree=writer.getHeader(configuration.getText(key) + ""String_Node_Str"" + classDoc.name());
  Content classContentTree=writer.getClassContentHeader();
  buildChildren(node,classContentTree);
  contentTree.addContent(classContentTree);
  writer.addFooter(contentTree);
  writer.printDocument(contentTree);
  writer.close();
  copyDocFiles();
}"
37200,"/** 
 * Enter a binary operation, as above but with two opcodes, which get encoded as (opcode1 << ByteCodeTags.preShift) + opcode2.
 * @param opcode1     First opcode.
 * @param opcode2     Second opcode.
 */
private void enterBinop(String name,Type left,Type right,Type res,int opcode1,int opcode2){
  enterBinop(name,left,right,res,(opcode1 << ByteCodes.preShift) | opcode2);
}","/** 
 * Enter a binary operation, as above but with two opcodes, which get encoded as  {@code (opcode1 << ByteCodeTags.preShift) + opcode2 }.
 * @param opcode1     First opcode.
 * @param opcode2     Second opcode.
 */
private void enterBinop(String name,Type left,Type right,Type res,int opcode1,int opcode2){
  enterBinop(name,left,right,res,(opcode1 << ByteCodes.preShift) | opcode2);
}"
37201,"/** 
 * A statement of the form <pre> for ( T v : arrayexpr ) stmt; </pre> (where arrayexpr is of an array type) gets translated to <pre> for ( { arraytype #arr = arrayexpr; int #len = array.length; int #i = 0; }; #i < #len; i$++ ) { T v = arr$[#i]; stmt; } </pre> where #arr, #len, and #i are freshly named synthetic local variables.
 */
private void visitArrayForeachLoop(JCEnhancedForLoop tree){
  make_at(tree.expr.pos());
  VarSymbol arraycache=new VarSymbol(0,names.fromString(""String_Node_Str"" + target.syntheticNameChar()),tree.expr.type,currentMethodSym);
  JCStatement arraycachedef=make.VarDef(arraycache,tree.expr);
  VarSymbol lencache=new VarSymbol(0,names.fromString(""String_Node_Str"" + target.syntheticNameChar()),syms.intType,currentMethodSym);
  JCStatement lencachedef=make.VarDef(lencache,make.Select(make.Ident(arraycache),syms.lengthVar));
  VarSymbol index=new VarSymbol(0,names.fromString(""String_Node_Str"" + target.syntheticNameChar()),syms.intType,currentMethodSym);
  JCVariableDecl indexdef=make.VarDef(index,make.Literal(INT,0));
  indexdef.init.type=indexdef.type=syms.intType.constType(0);
  List<JCStatement> loopinit=List.of(arraycachedef,lencachedef,indexdef);
  JCBinary cond=makeBinary(LT,make.Ident(index),make.Ident(lencache));
  JCExpressionStatement step=make.Exec(makeUnary(PREINC,make.Ident(index)));
  Type elemtype=types.elemtype(tree.expr.type);
  JCExpression loopvarinit=make.Indexed(make.Ident(arraycache),make.Ident(index)).setType(elemtype);
  JCVariableDecl loopvardef=(JCVariableDecl)make.VarDef(tree.var.mods,tree.var.name,tree.var.vartype,loopvarinit).setType(tree.var.type);
  loopvardef.sym=tree.var.sym;
  JCBlock body=make.Block(0,List.of(loopvardef,tree.body));
  result=translate(make.ForLoop(loopinit,cond,List.of(step),body));
  patchTargets(body,tree,result);
}","/** 
 * A statement of the form <pre> for ( T v : arrayexpr ) stmt; </pre> (where arrayexpr is of an array type) gets translated to <pre>  {@code}for (  arraytype #arr = arrayexpr; int #len = array.length; int #i = 0; }; #i < #len; i$++ ) { T v = arr$[#i]; stmt; } }</pre> where #arr, #len, and #i are freshly named synthetic local variables.
 */
private void visitArrayForeachLoop(JCEnhancedForLoop tree){
  make_at(tree.expr.pos());
  VarSymbol arraycache=new VarSymbol(0,names.fromString(""String_Node_Str"" + target.syntheticNameChar()),tree.expr.type,currentMethodSym);
  JCStatement arraycachedef=make.VarDef(arraycache,tree.expr);
  VarSymbol lencache=new VarSymbol(0,names.fromString(""String_Node_Str"" + target.syntheticNameChar()),syms.intType,currentMethodSym);
  JCStatement lencachedef=make.VarDef(lencache,make.Select(make.Ident(arraycache),syms.lengthVar));
  VarSymbol index=new VarSymbol(0,names.fromString(""String_Node_Str"" + target.syntheticNameChar()),syms.intType,currentMethodSym);
  JCVariableDecl indexdef=make.VarDef(index,make.Literal(INT,0));
  indexdef.init.type=indexdef.type=syms.intType.constType(0);
  List<JCStatement> loopinit=List.of(arraycachedef,lencachedef,indexdef);
  JCBinary cond=makeBinary(LT,make.Ident(index),make.Ident(lencache));
  JCExpressionStatement step=make.Exec(makeUnary(PREINC,make.Ident(index)));
  Type elemtype=types.elemtype(tree.expr.type);
  JCExpression loopvarinit=make.Indexed(make.Ident(arraycache),make.Ident(index)).setType(elemtype);
  JCVariableDecl loopvardef=(JCVariableDecl)make.VarDef(tree.var.mods,tree.var.name,tree.var.vartype,loopvarinit).setType(tree.var.type);
  loopvardef.sym=tree.var.sym;
  JCBlock body=make.Block(0,List.of(loopvardef,tree.body));
  result=translate(make.ForLoop(loopinit,cond,List.of(step),body));
  patchTargets(body,tree,result);
}"
37202,"/** 
 * Construct a tree that represents the closest outer instance <C.this> such that the given symbol is a member of C.
 * @param pos           The source code position to be used for the tree.
 * @param sym           The accessed symbol.
 * @param preciseMatch  should we accept a type that is a subtype ofsym's owner, even if it doesn't contain sym due to hiding, overriding, or non-inheritance due to protection?
 */
JCExpression makeOwnerThis(DiagnosticPosition pos,Symbol sym,boolean preciseMatch){
  Symbol c=sym.owner;
  if (preciseMatch ? sym.isMemberOf(currentClass,types) : currentClass.isSubClass(sym.owner,types)) {
    return make.at(pos).This(c.erasure(types));
  }
 else {
    return makeOwnerThisN(pos,sym,preciseMatch);
  }
}","/** 
 * Construct a tree that represents the closest outer instance  {@code C.this} such that the given symbol is a member of C.
 * @param pos           The source code position to be used for the tree.
 * @param sym           The accessed symbol.
 * @param preciseMatch  should we accept a type that is a subtype ofsym's owner, even if it doesn't contain sym due to hiding, overriding, or non-inheritance due to protection?
 */
JCExpression makeOwnerThis(DiagnosticPosition pos,Symbol sym,boolean preciseMatch){
  Symbol c=sym.owner;
  if (preciseMatch ? sym.isMemberOf(currentClass,types) : currentClass.isSubClass(sym.owner,types)) {
    return make.at(pos).This(c.erasure(types));
  }
 else {
    return makeOwnerThisN(pos,sym,preciseMatch);
  }
}"
37203,"/** 
 * Construct a tree that represents the outer instance <C.this>. Never pick the current `this'.
 * @param pos           The source code position to be used for the tree.
 * @param c             The qualifier class.
 */
JCExpression makeOuterThis(DiagnosticPosition pos,TypeSymbol c){
  List<VarSymbol> ots=outerThisStack;
  if (ots.isEmpty()) {
    log.error(pos,""String_Node_Str"",c);
    Assert.error();
    return makeNull();
  }
  VarSymbol ot=ots.head;
  JCExpression tree=access(make.at(pos).Ident(ot));
  TypeSymbol otc=ot.type.tsym;
  while (otc != c) {
    do {
      ots=ots.tail;
      if (ots.isEmpty()) {
        log.error(pos,""String_Node_Str"",c);
        Assert.error();
        return tree;
      }
      ot=ots.head;
    }
 while (ot.owner != otc);
    if (otc.owner.kind != PCK && !otc.hasOuterInstance()) {
      chk.earlyRefError(pos,c);
      Assert.error();
      return makeNull();
    }
    tree=access(make.at(pos).Select(tree,ot));
    otc=ot.type.tsym;
  }
  return tree;
}","/** 
 * Construct a tree that represents the outer instance  {@code C.this}. Never pick the current `this'.
 * @param pos           The source code position to be used for the tree.
 * @param c             The qualifier class.
 */
JCExpression makeOuterThis(DiagnosticPosition pos,TypeSymbol c){
  List<VarSymbol> ots=outerThisStack;
  if (ots.isEmpty()) {
    log.error(pos,""String_Node_Str"",c);
    Assert.error();
    return makeNull();
  }
  VarSymbol ot=ots.head;
  JCExpression tree=access(make.at(pos).Ident(ot));
  TypeSymbol otc=ot.type.tsym;
  while (otc != c) {
    do {
      ots=ots.tail;
      if (ots.isEmpty()) {
        log.error(pos,""String_Node_Str"",c);
        Assert.error();
        return tree;
      }
      ot=ots.head;
    }
 while (ot.owner != otc);
    if (otc.owner.kind != PCK && !otc.hasOuterInstance()) {
      chk.earlyRefError(pos,c);
      Assert.error();
      return makeNull();
    }
    tree=access(make.at(pos).Select(tree,ot));
    otc=ot.type.tsym;
  }
  return tree;
}"
37204,"/** 
 * Return tree simulating the assignment <this.this$n = this$n>.
 */
JCStatement initOuterThis(int pos){
  VarSymbol rhs=outerThisStack.head;
  Assert.check(rhs.owner.kind == MTH);
  VarSymbol lhs=outerThisStack.tail.head;
  Assert.check(rhs.owner.owner == lhs.owner);
  make.at(pos);
  return make.Exec(make.Assign(make.Select(make.This(lhs.owner.erasure(types)),lhs),make.Ident(rhs)).setType(lhs.erasure(types)));
}","/** 
 * Return tree simulating the assignment   {@code this.this$n = this$n}.
 */
JCStatement initOuterThis(int pos){
  VarSymbol rhs=outerThisStack.head;
  Assert.check(rhs.owner.kind == MTH);
  VarSymbol lhs=outerThisStack.tail.head;
  Assert.check(rhs.owner.owner == lhs.owner);
  make.at(pos);
  return make.Exec(make.Assign(make.Select(make.This(lhs.owner.erasure(types)),lhs),make.Ident(rhs)).setType(lhs.erasure(types)));
}"
37205,"/** 
 * Construct a tree simulating the expression <C.this>.
 * @param pos           The source code position to be used for the tree.
 * @param c             The qualifier class.
 */
JCExpression makeThis(DiagnosticPosition pos,TypeSymbol c){
  if (currentClass == c) {
    return make.at(pos).This(c.erasure(types));
  }
 else {
    return makeOuterThis(pos,c);
  }
}","/** 
 * Construct a tree simulating the expression   {@code C.this}.
 * @param pos           The source code position to be used for the tree.
 * @param c             The qualifier class.
 */
JCExpression makeThis(DiagnosticPosition pos,TypeSymbol c){
  if (currentClass == c) {
    return make.at(pos).This(c.erasure(types));
  }
 else {
    return makeOuterThis(pos,c);
  }
}"
37206,"/** 
 * A statement of the form <pre> for ( T v : coll ) stmt ; </pre> (where coll implements Iterable<? extends T>) gets translated to <pre> for ( Iterator<? extends T> #i = coll.iterator(); #i.hasNext(); ) { T v = (T) #i.next(); stmt; } </pre> where #i is a freshly named synthetic local variable.
 */
private void visitIterableForeachLoop(JCEnhancedForLoop tree){
  make_at(tree.expr.pos());
  Type iteratorTarget=syms.objectType;
  Type iterableType=types.asSuper(types.upperBound(tree.expr.type),syms.iterableType.tsym);
  if (iterableType.getTypeArguments().nonEmpty())   iteratorTarget=types.erasure(iterableType.getTypeArguments().head);
  Type eType=tree.expr.type;
  tree.expr.type=types.erasure(eType);
  if (eType.tag == TYPEVAR && eType.getUpperBound().isCompound())   tree.expr=make.TypeCast(types.erasure(iterableType),tree.expr);
  Symbol iterator=lookupMethod(tree.expr.pos(),names.iterator,types.erasure(syms.iterableType),List.<Type>nil());
  VarSymbol itvar=new VarSymbol(0,names.fromString(""String_Node_Str"" + target.syntheticNameChar()),types.erasure(iterator.type.getReturnType()),currentMethodSym);
  JCStatement init=make.VarDef(itvar,make.App(make.Select(tree.expr,iterator)));
  Symbol hasNext=lookupMethod(tree.expr.pos(),names.hasNext,itvar.type,List.<Type>nil());
  JCMethodInvocation cond=make.App(make.Select(make.Ident(itvar),hasNext));
  Symbol next=lookupMethod(tree.expr.pos(),names.next,itvar.type,List.<Type>nil());
  JCExpression vardefinit=make.App(make.Select(make.Ident(itvar),next));
  if (tree.var.type.isPrimitive())   vardefinit=make.TypeCast(types.upperBound(iteratorTarget),vardefinit);
 else   vardefinit=make.TypeCast(tree.var.type,vardefinit);
  JCVariableDecl indexDef=(JCVariableDecl)make.VarDef(tree.var.mods,tree.var.name,tree.var.vartype,vardefinit).setType(tree.var.type);
  indexDef.sym=tree.var.sym;
  JCBlock body=make.Block(0,List.of(indexDef,tree.body));
  body.endpos=TreeInfo.endPos(tree.body);
  result=translate(make.ForLoop(List.of(init),cond,List.<JCExpressionStatement>nil(),body));
  patchTargets(body,tree,result);
}","/** 
 * A statement of the form <pre> for ( T v : coll ) stmt ; </pre> (where coll implements   {@code Iterable<? extends T>}) gets translated to <pre>  {@code}for ( Iterator<? extends T> #i = coll.iterator(); #i.hasNext(); )  T v = (T) #i.next(); stmt; } }</pre> where #i is a freshly named synthetic local variable.
 */
private void visitIterableForeachLoop(JCEnhancedForLoop tree){
  make_at(tree.expr.pos());
  Type iteratorTarget=syms.objectType;
  Type iterableType=types.asSuper(types.upperBound(tree.expr.type),syms.iterableType.tsym);
  if (iterableType.getTypeArguments().nonEmpty())   iteratorTarget=types.erasure(iterableType.getTypeArguments().head);
  Type eType=tree.expr.type;
  tree.expr.type=types.erasure(eType);
  if (eType.tag == TYPEVAR && eType.getUpperBound().isCompound())   tree.expr=make.TypeCast(types.erasure(iterableType),tree.expr);
  Symbol iterator=lookupMethod(tree.expr.pos(),names.iterator,types.erasure(syms.iterableType),List.<Type>nil());
  VarSymbol itvar=new VarSymbol(0,names.fromString(""String_Node_Str"" + target.syntheticNameChar()),types.erasure(iterator.type.getReturnType()),currentMethodSym);
  JCStatement init=make.VarDef(itvar,make.App(make.Select(tree.expr,iterator)));
  Symbol hasNext=lookupMethod(tree.expr.pos(),names.hasNext,itvar.type,List.<Type>nil());
  JCMethodInvocation cond=make.App(make.Select(make.Ident(itvar),hasNext));
  Symbol next=lookupMethod(tree.expr.pos(),names.next,itvar.type,List.<Type>nil());
  JCExpression vardefinit=make.App(make.Select(make.Ident(itvar),next));
  if (tree.var.type.isPrimitive())   vardefinit=make.TypeCast(types.upperBound(iteratorTarget),vardefinit);
 else   vardefinit=make.TypeCast(tree.var.type,vardefinit);
  JCVariableDecl indexDef=(JCVariableDecl)make.VarDef(tree.var.mods,tree.var.name,tree.var.vartype,vardefinit).setType(tree.var.type);
  indexDef.sym=tree.var.sym;
  JCBlock body=make.Block(0,List.of(indexDef,tree.body));
  body.endpos=TreeInfo.endPos(tree.body);
  result=translate(make.ForLoop(List.of(init),cond,List.<JCExpressionStatement>nil(),body));
  patchTargets(body,tree,result);
}"
37207,"/** 
 * Return tree simulating the assignment <this.name = name>, where name is the name of a free variable.
 */
JCStatement initField(int pos,Name name){
  Scope.Entry e=proxies.lookup(name);
  Symbol rhs=e.sym;
  Assert.check(rhs.owner.kind == MTH);
  Symbol lhs=e.next().sym;
  Assert.check(rhs.owner.owner == lhs.owner);
  make.at(pos);
  return make.Exec(make.Assign(make.Select(make.This(lhs.owner.erasure(types)),lhs),make.Ident(rhs)).setType(lhs.erasure(types)));
}","/** 
 * Return tree simulating the assignment   {@code this.name = name}, where name is the name of a free variable.
 */
JCStatement initField(int pos,Name name){
  Scope.Entry e=proxies.lookup(name);
  Symbol rhs=e.sym;
  Assert.check(rhs.owner.kind == MTH);
  Symbol lhs=e.next().sym;
  Assert.check(rhs.owner.owner == lhs.owner);
  make.at(pos);
  return make.Exec(make.Assign(make.Select(make.This(lhs.owner.erasure(types)),lhs),make.Ident(rhs)).setType(lhs.erasure(types)));
}"
37208,"/** 
 * A name designates an operator if it consists of a non-empty sequence of operator symbols +-~!/*%&|^<>=
 */
boolean isOperator(Name name){
  int i=0;
  while (i < name.getByteLength() && ""String_Node_Str"".indexOf(name.getByteAt(i)) >= 0)   i++;
  return i > 0 && i == name.getByteLength();
}","/** 
 * A name designates an operator if it consists of a non-empty sequence of operator symbols   {@literal +-~!/*%&|^<>= }
 */
boolean isOperator(Name name){
  int i=0;
  while (i < name.getByteLength() && ""String_Node_Str"".indexOf(name.getByteAt(i)) >= 0)   i++;
  return i > 0 && i == name.getByteLength();
}"
37209,"/** 
 * This method scans all the constructor symbol in a given class scope - assuming that the original scope contains a constructor of the kind: Foo(X x, Y y), where X,Y are class type-variables declared in Foo, a method check is executed against the modified constructor type: <X,Y>Foo<X,Y>(X x, Y y). This is crucial in order to enable diamond inference. The inferred return type of the synthetic constructor IS the inferred type for the diamond operator.
 */
private Symbol findDiamond(Env<AttrContext> env,Type site,List<Type> argtypes,List<Type> typeargtypes,boolean allowBoxing,boolean useVarargs){
  Symbol bestSoFar=methodNotFound;
  for (Scope.Entry e=site.tsym.members().lookup(names.init); e.scope != null; e=e.next()) {
    if (e.sym.kind == MTH && (e.sym.flags_field & SYNTHETIC) == 0) {
      List<Type> oldParams=e.sym.type.tag == FORALL ? ((ForAll)e.sym.type).tvars : List.<Type>nil();
      Type constrType=new ForAll(site.tsym.type.getTypeArguments().appendList(oldParams),types.createMethodTypeWithReturn(e.sym.type.asMethodType(),site));
      bestSoFar=selectBest(env,site,argtypes,typeargtypes,new MethodSymbol(e.sym.flags(),names.init,constrType,site.tsym),bestSoFar,allowBoxing,useVarargs,false);
    }
  }
  return bestSoFar;
}","/** 
 * This method scans all the constructor symbol in a given class scope - assuming that the original scope contains a constructor of the kind:  {@code Foo(X x, Y y)}, where X,Y are class type-variables declared in Foo, a method check is executed against the modified constructor type:  {@code <X,Y>Foo<X,Y>(X x, Y y)}. This is crucial in order to enable diamond inference. The inferred return type of the synthetic constructor IS the inferred type for the diamond operator.
 */
private Symbol findDiamond(Env<AttrContext> env,Type site,List<Type> argtypes,List<Type> typeargtypes,boolean allowBoxing,boolean useVarargs){
  Symbol bestSoFar=methodNotFound;
  for (Scope.Entry e=site.tsym.members().lookup(names.init); e.scope != null; e=e.next()) {
    if (e.sym.kind == MTH && (e.sym.flags_field & SYNTHETIC) == 0) {
      List<Type> oldParams=e.sym.type.tag == FORALL ? ((ForAll)e.sym.type).tvars : List.<Type>nil();
      Type constrType=new ForAll(site.tsym.type.getTypeArguments().appendList(oldParams),types.createMethodTypeWithReturn(e.sym.type.asMethodType(),site));
      bestSoFar=selectBest(env,site,argtypes,typeargtypes,new MethodSymbol(e.sym.flags(),names.init,constrType,site.tsym),bestSoFar,allowBoxing,useVarargs,false);
    }
  }
  return bestSoFar;
}"
37210,"/** 
 * Source file positions in CRT are integers in the format: line-number << LINESHIFT + column-number
 */
private int encodePosition(int pos,Position.LineMap lineMap,Log log){
  int line=lineMap.getLineNumber(pos);
  int col=lineMap.getColumnNumber(pos);
  int new_pos=Position.encodePosition(line,col);
  if (crtDebug) {
    System.out.println(""String_Node_Str"" + line + ""String_Node_Str""+ col+ ""String_Node_Str""+ new_pos);
  }
  if (new_pos == Position.NOPOS)   log.warning(pos,""String_Node_Str"",line);
  return new_pos;
}","/** 
 * Source file positions in CRT are integers in the format:  {@literal line-number << LINESHIFT + column-number }
 */
private int encodePosition(int pos,Position.LineMap lineMap,Log log){
  int line=lineMap.getLineNumber(pos);
  int col=lineMap.getColumnNumber(pos);
  int new_pos=Position.encodePosition(line,col);
  if (crtDebug) {
    System.out.println(""String_Node_Str"" + line + ""String_Node_Str""+ col+ ""String_Node_Str""+ new_pos);
  }
  if (new_pos == Position.NOPOS)   log.warning(pos,""String_Node_Str"",line);
  return new_pos;
}"
37211,"/** 
 * Return the first sentence of the comment as an array of tags. Includes inline tags (i.e. {&#64link <i>reference</i>} tags)  but not block tags. Each section of plain text is represented as a   {@link Tag}of   {@linkplain Tag#kind() kind} ""Text"".Inline tags are represented as a  {@link SeeTag} of kind ""@see""and name ""@link"". <p> If the locale is English language, the first sentence is determined by the rules described in the Java Language Specification (first version): &quot;This sentence ends at the first period that is followed by a blank, tab, or line terminator or at the first tagline.&quot;, in addition a line will be terminated by block HTML tags: &lt;p&gt;  &lt;/p&gt;  &lt;h1&gt; &lt;h2&gt;  &lt;h3&gt; &lt;h4&gt;  &lt;h5&gt;  &lt;h6&gt; &lt;hr&gt;  &lt;pre&gt;  or &lt;/pre&gt;. If the locale is not English, the sentence end will be determined by {@link BreakIterator#getSentenceInstance(Locale)}.
 * @return an array of {@link Tag}s representing the first sentence of the comment
 */
Tag[] firstSentenceTags();","/** 
 * Return the first sentence of the comment as an array of tags. Includes inline tags (i.e. {&#64;link <i>reference</i>} tags)  but not block tags. Each section of plain text is represented as a   {@link Tag}of   {@linkplain Tag#kind() kind} ""Text"".Inline tags are represented as a  {@link SeeTag} of kind ""@see""and name ""@link"". <p> If the locale is English language, the first sentence is determined by the rules described in the Java Language Specification (first version): &quot;This sentence ends at the first period that is followed by a blank, tab, or line terminator or at the first tagline.&quot;, in addition a line will be terminated by block HTML tags: &lt;p&gt;  &lt;/p&gt;  &lt;h1&gt; &lt;h2&gt;  &lt;h3&gt; &lt;h4&gt;  &lt;h5&gt;  &lt;h6&gt; &lt;hr&gt;  &lt;pre&gt;  or &lt;/pre&gt;. If the locale is not English, the sentence end will be determined by {@link BreakIterator#getSentenceInstance(Locale)}.
 * @return an array of {@link Tag}s representing the first sentence of the comment
 */
Tag[] firstSentenceTags();"
37212,"/** 
 * Return comment as an array of tags. Includes inline tags (i.e. {&#64link <i>reference</i>} tags)  but not block tags. Each section of plain text is represented as a   {@link Tag}of   {@linkplain Tag#kind() kind} ""Text"".Inline tags are represented as a  {@link SeeTag} of kind ""@see""and name ""@link"".
 * @return an array of {@link Tag}s representing the comment
 */
Tag[] inlineTags();","/** 
 * Return comment as an array of tags. Includes inline tags (i.e. {&#64;link <i>reference</i>} tags)  but not block tags. Each section of plain text is represented as a   {@link Tag}of   {@linkplain Tag#kind() kind} ""Text"".Inline tags are represented as a  {@link SeeTag} of kind ""@see""and name ""@link"".
 * @return an array of {@link Tag}s representing the comment
 */
Tag[] inlineTags();"
37213,"/** 
 * Return the param tags in this method, excluding the type parameter tags.
 * @return an array of ParamTag containing all <code>&#64param</code> tagscorresponding to the parameters of this method.
 */
ParamTag[] paramTags();","/** 
 * Return the param tags in this method, excluding the type parameter tags.
 * @return an array of ParamTag containing all <code>&#64;param</code> tagscorresponding to the parameters of this method.
 */
ParamTag[] paramTags();"
37214,"/** 
 * Return the type parameter tags in this method.
 * @return an array of ParamTag containing all <code>&#64param</code> tagscorresponding to the type parameters of this method.
 * @since 1.5
 */
ParamTag[] typeParamTags();","/** 
 * Return the type parameter tags in this method.
 * @return an array of ParamTag containing all <code>&#64;param</code> tagscorresponding to the type parameters of this method.
 * @since 1.5
 */
ParamTag[] typeParamTags();"
37215,"/** 
 * Return the throws tags in this method.
 * @return an array of ThrowTag containing all <code>&#64exception</code>and <code>&#64throws</code> tags.
 */
ThrowsTag[] throwsTags();","/** 
 * Return the throws tags in this method.
 * @return an array of ThrowTag containing all <code>&#64;exception</code>and <code>&#64;throws</code> tags.
 */
ThrowsTag[] throwsTags();"
37216,"/** 
 * Return the first sentence of the comment as an array of tags. Includes inline tags (i.e. {&#64link <i>reference</i>} tags)  but not block tags. Each section of plain text is represented as a   {@link Tag}of kind ""Text"". Inline tags are represented as a   {@link SeeTag} of kind ""@link"".If the locale is English language, the first sentence is determined by the rules described in the Java Language Specification (first version): &quot;This sentence ends at the first period that is followed by a blank, tab, or line terminator or at the first tagline.&quot;, in addition a line will be terminated by paragraph and section terminating HTML tags: &lt;p&gt;  &lt;/p&gt;  &lt;h1&gt; &lt;h2&gt;  &lt;h3&gt; &lt;h4&gt;  &lt;h5&gt;  &lt;h6&gt; &lt;hr&gt;  &lt;pre&gt;  or &lt;/pre&gt;. If the locale is not English, the sentence end will be determined by {@link BreakIterator#getSentenceInstance(Locale)}.
 * @return an array of {@link Tag} objects representing thefirst sentence of the comment
 */
Tag[] firstSentenceTags();","/** 
 * Return the first sentence of the comment as an array of tags. Includes inline tags (i.e. {&#64;link <i>reference</i>} tags)  but not block tags. Each section of plain text is represented as a   {@link Tag}of kind ""Text"". Inline tags are represented as a   {@link SeeTag} of kind ""@link"".If the locale is English language, the first sentence is determined by the rules described in the Java Language Specification (first version): &quot;This sentence ends at the first period that is followed by a blank, tab, or line terminator or at the first tagline.&quot;, in addition a line will be terminated by paragraph and section terminating HTML tags: &lt;p&gt;  &lt;/p&gt;  &lt;h1&gt; &lt;h2&gt;  &lt;h3&gt; &lt;h4&gt;  &lt;h5&gt;  &lt;h6&gt; &lt;hr&gt;  &lt;pre&gt;  or &lt;/pre&gt;. If the locale is not English, the sentence end will be determined by {@link BreakIterator#getSentenceInstance(Locale)}.
 * @return an array of {@link Tag} objects representing thefirst sentence of the comment
 */
Tag[] firstSentenceTags();"
37217,"/** 
 * Find the start position of a line.
 * @param line line number (beginning at 1)
 * @return     position of first character in line
 * @throws IndexOutOfBoundsException if <tt>lineNumber < 1</tt> if <tt>lineNumber > no. of lines</tt>
 */
long getStartPosition(long line);","/** 
 * Find the start position of a line.
 * @param line line number (beginning at 1)
 * @return     position of first character in line
 * @throws IndexOutOfBoundsException if  {@code lineNumber < 1}if   {@code lineNumber > no. of lines}
 */
long getStartPosition(long line);"
37218,"/** 
 * Print the heading in Html &lt;H2> format.
 * @param str The Header string.
 */
public void printIndexHeading(String str){
  h2();
  print(str);
  h2End();
}","/** 
 * Print the heading in Html   {@literal <H2>} format.
 * @param str The Header string.
 */
public void printIndexHeading(String str){
  h2();
  print(str);
  h2End();
}"
37219,"/** 
 * Suppose a piece of documentation has a relative link.  When you copy that documetation to another place such as the index or class-use page, that relative link will no longer work.  We should redirect those links so that they will work again. <p> Here is the algorithm used to fix the link: <p> &lt;relative link&gt; => docRoot + &lt;relative path to file&gt; + &lt;relative link&gt; <p> For example, suppose com.sun.javadoc.RootDoc has this link: &lt;a href=""package-summary.html""&gt;The package Page&lt;/a&gt; <p> If this link appeared in the index, we would redirect the link like this: &lt;a href=""./com/sun/javadoc/package-summary.html""&gt;The package Page&lt;/a&gt;
 * @param doc the Doc object whose documentation is being written.
 * @param text the text being written.
 * @return the text, with all the relative links redirected to work.
 */
private String redirectRelativeLinks(Doc doc,String text){
  if (doc == null || shouldNotRedirectRelativeLinks()) {
    return text;
  }
  String redirectPathFromRoot;
  if (doc instanceof ClassDoc) {
    redirectPathFromRoot=DirectoryManager.getDirectoryPath(((ClassDoc)doc).containingPackage());
  }
 else   if (doc instanceof MemberDoc) {
    redirectPathFromRoot=DirectoryManager.getDirectoryPath(((MemberDoc)doc).containingPackage());
  }
 else   if (doc instanceof PackageDoc) {
    redirectPathFromRoot=DirectoryManager.getDirectoryPath((PackageDoc)doc);
  }
 else {
    return text;
  }
  if (!redirectPathFromRoot.endsWith(DirectoryManager.URL_FILE_SEPARATOR)) {
    redirectPathFromRoot+=DirectoryManager.URL_FILE_SEPARATOR;
  }
  int end, begin=text.toLowerCase().indexOf(""String_Node_Str"");
  if (begin >= 0) {
    StringBuffer textBuff=new StringBuffer(text);
    while (begin >= 0) {
      if (textBuff.length() > begin + 2 && !Character.isWhitespace(textBuff.charAt(begin + 2))) {
        begin=textBuff.toString().toLowerCase().indexOf(""String_Node_Str"",begin + 1);
        continue;
      }
      begin=textBuff.indexOf(""String_Node_Str"",begin) + 1;
      end=textBuff.indexOf(""String_Node_Str"",begin + 1);
      if (begin == 0) {
        configuration.root.printWarning(doc.position(),configuration.getText(""String_Node_Str"",text));
        break;
      }
      if (end == -1) {
        break;
      }
      if (textBuff.substring(begin,end).indexOf(""String_Node_Str"") != -1) {
        begin=textBuff.indexOf(""String_Node_Str"",begin) + 1;
        end=textBuff.indexOf(""String_Node_Str"",begin + 1);
        if (begin == 0 || end == -1) {
          break;
        }
      }
      String relativeLink=textBuff.substring(begin,end);
      if (!(relativeLink.toLowerCase().startsWith(""String_Node_Str"") || relativeLink.toLowerCase().startsWith(""String_Node_Str"") || relativeLink.toLowerCase().startsWith(""String_Node_Str"")|| relativeLink.toLowerCase().startsWith(""String_Node_Str""))) {
        relativeLink=""String_Node_Str"" + (new DocRootTaglet()).getName() + ""String_Node_Str""+ redirectPathFromRoot+ relativeLink;
        textBuff.replace(begin,end,relativeLink);
      }
      begin=textBuff.toString().toLowerCase().indexOf(""String_Node_Str"",begin + 1);
    }
    return textBuff.toString();
  }
  return text;
}","/** 
 * Suppose a piece of documentation has a relative link.  When you copy that documetation to another place such as the index or class-use page, that relative link will no longer work.  We should redirect those links so that they will work again. <p> Here is the algorithm used to fix the link: <p>  {@literal <relative link> => docRoot + <relative path to file> + <relative link> }<p> For example, suppose com.sun.javadoc.RootDoc has this link:  {@literal <a href=""package-summary.html"">The package Page</a> }<p> If this link appeared in the index, we would redirect the link like this:  {@literal <a href=""./com/sun/javadoc/package-summary.html"">The package Page</a>}
 * @param doc the Doc object whose documentation is being written.
 * @param text the text being written.
 * @return the text, with all the relative links redirected to work.
 */
private String redirectRelativeLinks(Doc doc,String text){
  if (doc == null || shouldNotRedirectRelativeLinks()) {
    return text;
  }
  String redirectPathFromRoot;
  if (doc instanceof ClassDoc) {
    redirectPathFromRoot=DirectoryManager.getDirectoryPath(((ClassDoc)doc).containingPackage());
  }
 else   if (doc instanceof MemberDoc) {
    redirectPathFromRoot=DirectoryManager.getDirectoryPath(((MemberDoc)doc).containingPackage());
  }
 else   if (doc instanceof PackageDoc) {
    redirectPathFromRoot=DirectoryManager.getDirectoryPath((PackageDoc)doc);
  }
 else {
    return text;
  }
  if (!redirectPathFromRoot.endsWith(DirectoryManager.URL_FILE_SEPARATOR)) {
    redirectPathFromRoot+=DirectoryManager.URL_FILE_SEPARATOR;
  }
  int end, begin=text.toLowerCase().indexOf(""String_Node_Str"");
  if (begin >= 0) {
    StringBuffer textBuff=new StringBuffer(text);
    while (begin >= 0) {
      if (textBuff.length() > begin + 2 && !Character.isWhitespace(textBuff.charAt(begin + 2))) {
        begin=textBuff.toString().toLowerCase().indexOf(""String_Node_Str"",begin + 1);
        continue;
      }
      begin=textBuff.indexOf(""String_Node_Str"",begin) + 1;
      end=textBuff.indexOf(""String_Node_Str"",begin + 1);
      if (begin == 0) {
        configuration.root.printWarning(doc.position(),configuration.getText(""String_Node_Str"",text));
        break;
      }
      if (end == -1) {
        break;
      }
      if (textBuff.substring(begin,end).indexOf(""String_Node_Str"") != -1) {
        begin=textBuff.indexOf(""String_Node_Str"",begin) + 1;
        end=textBuff.indexOf(""String_Node_Str"",begin + 1);
        if (begin == 0 || end == -1) {
          break;
        }
      }
      String relativeLink=textBuff.substring(begin,end);
      if (!(relativeLink.toLowerCase().startsWith(""String_Node_Str"") || relativeLink.toLowerCase().startsWith(""String_Node_Str"") || relativeLink.toLowerCase().startsWith(""String_Node_Str"")|| relativeLink.toLowerCase().startsWith(""String_Node_Str""))) {
        relativeLink=""String_Node_Str"" + (new DocRootTaglet()).getName() + ""String_Node_Str""+ redirectPathFromRoot+ relativeLink;
        textBuff.replace(begin,end,relativeLink);
      }
      begin=textBuff.toString().toLowerCase().indexOf(""String_Node_Str"",begin + 1);
    }
    return textBuff.toString();
  }
  return text;
}"
37220,"/** 
 * Handles the &lt;ClassDoc> tag.
 * @param node the XML element that specifies which components to document
 * @param contentTree the content tree to which the documentation will be added
 */
public void buildClassDoc(XMLNode node,Content contentTree) throws Exception {
  String key;
  if (isInterface) {
    key=""String_Node_Str"";
  }
 else   if (isEnum) {
    key=""String_Node_Str"";
  }
 else {
    key=""String_Node_Str"";
  }
  contentTree=writer.getHeader(configuration.getText(key) + ""String_Node_Str"" + classDoc.name());
  Content classContentTree=writer.getClassContentHeader();
  buildChildren(node,classContentTree);
  contentTree.addContent(classContentTree);
  writer.addFooter(contentTree);
  writer.printDocument(contentTree);
  writer.close();
  copyDocFiles();
}","/** 
 * Handles the   {@literal <ClassDoc>} tag.
 * @param node the XML element that specifies which components to document
 * @param contentTree the content tree to which the documentation will be added
 */
public void buildClassDoc(XMLNode node,Content contentTree) throws Exception {
  String key;
  if (isInterface) {
    key=""String_Node_Str"";
  }
 else   if (isEnum) {
    key=""String_Node_Str"";
  }
 else {
    key=""String_Node_Str"";
  }
  contentTree=writer.getHeader(configuration.getText(key) + ""String_Node_Str"" + classDoc.name());
  Content classContentTree=writer.getClassContentHeader();
  buildChildren(node,classContentTree);
  contentTree.addContent(classContentTree);
  writer.addFooter(contentTree);
  writer.printDocument(contentTree);
  writer.close();
  copyDocFiles();
}"
37221,"/** 
 * Enter a binary operation, as above but with two opcodes, which get encoded as (opcode1 << ByteCodeTags.preShift) + opcode2.
 * @param opcode1     First opcode.
 * @param opcode2     Second opcode.
 */
private void enterBinop(String name,Type left,Type right,Type res,int opcode1,int opcode2){
  enterBinop(name,left,right,res,(opcode1 << ByteCodes.preShift) | opcode2);
}","/** 
 * Enter a binary operation, as above but with two opcodes, which get encoded as  {@code (opcode1 << ByteCodeTags.preShift) + opcode2 }.
 * @param opcode1     First opcode.
 * @param opcode2     Second opcode.
 */
private void enterBinop(String name,Type left,Type right,Type res,int opcode1,int opcode2){
  enterBinop(name,left,right,res,(opcode1 << ByteCodes.preShift) | opcode2);
}"
37222,"/** 
 * A statement of the form <pre> for ( T v : arrayexpr ) stmt; </pre> (where arrayexpr is of an array type) gets translated to <pre> for ( { arraytype #arr = arrayexpr; int #len = array.length; int #i = 0; }; #i < #len; i$++ ) { T v = arr$[#i]; stmt; } </pre> where #arr, #len, and #i are freshly named synthetic local variables.
 */
private void visitArrayForeachLoop(JCEnhancedForLoop tree){
  make_at(tree.expr.pos());
  VarSymbol arraycache=new VarSymbol(0,names.fromString(""String_Node_Str"" + target.syntheticNameChar()),tree.expr.type,currentMethodSym);
  JCStatement arraycachedef=make.VarDef(arraycache,tree.expr);
  VarSymbol lencache=new VarSymbol(0,names.fromString(""String_Node_Str"" + target.syntheticNameChar()),syms.intType,currentMethodSym);
  JCStatement lencachedef=make.VarDef(lencache,make.Select(make.Ident(arraycache),syms.lengthVar));
  VarSymbol index=new VarSymbol(0,names.fromString(""String_Node_Str"" + target.syntheticNameChar()),syms.intType,currentMethodSym);
  JCVariableDecl indexdef=make.VarDef(index,make.Literal(INT,0));
  indexdef.init.type=indexdef.type=syms.intType.constType(0);
  List<JCStatement> loopinit=List.of(arraycachedef,lencachedef,indexdef);
  JCBinary cond=makeBinary(LT,make.Ident(index),make.Ident(lencache));
  JCExpressionStatement step=make.Exec(makeUnary(PREINC,make.Ident(index)));
  Type elemtype=types.elemtype(tree.expr.type);
  JCExpression loopvarinit=make.Indexed(make.Ident(arraycache),make.Ident(index)).setType(elemtype);
  JCVariableDecl loopvardef=(JCVariableDecl)make.VarDef(tree.var.mods,tree.var.name,tree.var.vartype,loopvarinit).setType(tree.var.type);
  loopvardef.sym=tree.var.sym;
  JCBlock body=make.Block(0,List.of(loopvardef,tree.body));
  result=translate(make.ForLoop(loopinit,cond,List.of(step),body));
  patchTargets(body,tree,result);
}","/** 
 * A statement of the form <pre> for ( T v : arrayexpr ) stmt; </pre> (where arrayexpr is of an array type) gets translated to <pre>  {@code}for (  arraytype #arr = arrayexpr; int #len = array.length; int #i = 0; }; #i < #len; i$++ ) { T v = arr$[#i]; stmt; } }</pre> where #arr, #len, and #i are freshly named synthetic local variables.
 */
private void visitArrayForeachLoop(JCEnhancedForLoop tree){
  make_at(tree.expr.pos());
  VarSymbol arraycache=new VarSymbol(0,names.fromString(""String_Node_Str"" + target.syntheticNameChar()),tree.expr.type,currentMethodSym);
  JCStatement arraycachedef=make.VarDef(arraycache,tree.expr);
  VarSymbol lencache=new VarSymbol(0,names.fromString(""String_Node_Str"" + target.syntheticNameChar()),syms.intType,currentMethodSym);
  JCStatement lencachedef=make.VarDef(lencache,make.Select(make.Ident(arraycache),syms.lengthVar));
  VarSymbol index=new VarSymbol(0,names.fromString(""String_Node_Str"" + target.syntheticNameChar()),syms.intType,currentMethodSym);
  JCVariableDecl indexdef=make.VarDef(index,make.Literal(INT,0));
  indexdef.init.type=indexdef.type=syms.intType.constType(0);
  List<JCStatement> loopinit=List.of(arraycachedef,lencachedef,indexdef);
  JCBinary cond=makeBinary(LT,make.Ident(index),make.Ident(lencache));
  JCExpressionStatement step=make.Exec(makeUnary(PREINC,make.Ident(index)));
  Type elemtype=types.elemtype(tree.expr.type);
  JCExpression loopvarinit=make.Indexed(make.Ident(arraycache),make.Ident(index)).setType(elemtype);
  JCVariableDecl loopvardef=(JCVariableDecl)make.VarDef(tree.var.mods,tree.var.name,tree.var.vartype,loopvarinit).setType(tree.var.type);
  loopvardef.sym=tree.var.sym;
  JCBlock body=make.Block(0,List.of(loopvardef,tree.body));
  result=translate(make.ForLoop(loopinit,cond,List.of(step),body));
  patchTargets(body,tree,result);
}"
37223,"/** 
 * Construct a tree that represents the closest outer instance <C.this> such that the given symbol is a member of C.
 * @param pos           The source code position to be used for the tree.
 * @param sym           The accessed symbol.
 * @param preciseMatch  should we accept a type that is a subtype ofsym's owner, even if it doesn't contain sym due to hiding, overriding, or non-inheritance due to protection?
 */
JCExpression makeOwnerThis(DiagnosticPosition pos,Symbol sym,boolean preciseMatch){
  Symbol c=sym.owner;
  if (preciseMatch ? sym.isMemberOf(currentClass,types) : currentClass.isSubClass(sym.owner,types)) {
    return make.at(pos).This(c.erasure(types));
  }
 else {
    return makeOwnerThisN(pos,sym,preciseMatch);
  }
}","/** 
 * Construct a tree that represents the closest outer instance  {@code C.this} such that the given symbol is a member of C.
 * @param pos           The source code position to be used for the tree.
 * @param sym           The accessed symbol.
 * @param preciseMatch  should we accept a type that is a subtype ofsym's owner, even if it doesn't contain sym due to hiding, overriding, or non-inheritance due to protection?
 */
JCExpression makeOwnerThis(DiagnosticPosition pos,Symbol sym,boolean preciseMatch){
  Symbol c=sym.owner;
  if (preciseMatch ? sym.isMemberOf(currentClass,types) : currentClass.isSubClass(sym.owner,types)) {
    return make.at(pos).This(c.erasure(types));
  }
 else {
    return makeOwnerThisN(pos,sym,preciseMatch);
  }
}"
37224,"/** 
 * Construct a tree that represents the outer instance <C.this>. Never pick the current `this'.
 * @param pos           The source code position to be used for the tree.
 * @param c             The qualifier class.
 */
JCExpression makeOuterThis(DiagnosticPosition pos,TypeSymbol c){
  List<VarSymbol> ots=outerThisStack;
  if (ots.isEmpty()) {
    log.error(pos,""String_Node_Str"",c);
    Assert.error();
    return makeNull();
  }
  VarSymbol ot=ots.head;
  JCExpression tree=access(make.at(pos).Ident(ot));
  TypeSymbol otc=ot.type.tsym;
  while (otc != c) {
    do {
      ots=ots.tail;
      if (ots.isEmpty()) {
        log.error(pos,""String_Node_Str"",c);
        Assert.error();
        return tree;
      }
      ot=ots.head;
    }
 while (ot.owner != otc);
    if (otc.owner.kind != PCK && !otc.hasOuterInstance()) {
      chk.earlyRefError(pos,c);
      Assert.error();
      return makeNull();
    }
    tree=access(make.at(pos).Select(tree,ot));
    otc=ot.type.tsym;
  }
  return tree;
}","/** 
 * Construct a tree that represents the outer instance  {@code C.this}. Never pick the current `this'.
 * @param pos           The source code position to be used for the tree.
 * @param c             The qualifier class.
 */
JCExpression makeOuterThis(DiagnosticPosition pos,TypeSymbol c){
  List<VarSymbol> ots=outerThisStack;
  if (ots.isEmpty()) {
    log.error(pos,""String_Node_Str"",c);
    Assert.error();
    return makeNull();
  }
  VarSymbol ot=ots.head;
  JCExpression tree=access(make.at(pos).Ident(ot));
  TypeSymbol otc=ot.type.tsym;
  while (otc != c) {
    do {
      ots=ots.tail;
      if (ots.isEmpty()) {
        log.error(pos,""String_Node_Str"",c);
        Assert.error();
        return tree;
      }
      ot=ots.head;
    }
 while (ot.owner != otc);
    if (otc.owner.kind != PCK && !otc.hasOuterInstance()) {
      chk.earlyRefError(pos,c);
      Assert.error();
      return makeNull();
    }
    tree=access(make.at(pos).Select(tree,ot));
    otc=ot.type.tsym;
  }
  return tree;
}"
37225,"/** 
 * Return tree simulating the assignment <this.this$n = this$n>.
 */
JCStatement initOuterThis(int pos){
  VarSymbol rhs=outerThisStack.head;
  Assert.check(rhs.owner.kind == MTH);
  VarSymbol lhs=outerThisStack.tail.head;
  Assert.check(rhs.owner.owner == lhs.owner);
  make.at(pos);
  return make.Exec(make.Assign(make.Select(make.This(lhs.owner.erasure(types)),lhs),make.Ident(rhs)).setType(lhs.erasure(types)));
}","/** 
 * Return tree simulating the assignment   {@code this.this$n = this$n}.
 */
JCStatement initOuterThis(int pos){
  VarSymbol rhs=outerThisStack.head;
  Assert.check(rhs.owner.kind == MTH);
  VarSymbol lhs=outerThisStack.tail.head;
  Assert.check(rhs.owner.owner == lhs.owner);
  make.at(pos);
  return make.Exec(make.Assign(make.Select(make.This(lhs.owner.erasure(types)),lhs),make.Ident(rhs)).setType(lhs.erasure(types)));
}"
37226,"/** 
 * Construct a tree simulating the expression <C.this>.
 * @param pos           The source code position to be used for the tree.
 * @param c             The qualifier class.
 */
JCExpression makeThis(DiagnosticPosition pos,TypeSymbol c){
  if (currentClass == c) {
    return make.at(pos).This(c.erasure(types));
  }
 else {
    return makeOuterThis(pos,c);
  }
}","/** 
 * Construct a tree simulating the expression   {@code C.this}.
 * @param pos           The source code position to be used for the tree.
 * @param c             The qualifier class.
 */
JCExpression makeThis(DiagnosticPosition pos,TypeSymbol c){
  if (currentClass == c) {
    return make.at(pos).This(c.erasure(types));
  }
 else {
    return makeOuterThis(pos,c);
  }
}"
37227,"/** 
 * A statement of the form <pre> for ( T v : coll ) stmt ; </pre> (where coll implements Iterable<? extends T>) gets translated to <pre> for ( Iterator<? extends T> #i = coll.iterator(); #i.hasNext(); ) { T v = (T) #i.next(); stmt; } </pre> where #i is a freshly named synthetic local variable.
 */
private void visitIterableForeachLoop(JCEnhancedForLoop tree){
  make_at(tree.expr.pos());
  Type iteratorTarget=syms.objectType;
  Type iterableType=types.asSuper(types.upperBound(tree.expr.type),syms.iterableType.tsym);
  if (iterableType.getTypeArguments().nonEmpty())   iteratorTarget=types.erasure(iterableType.getTypeArguments().head);
  Type eType=tree.expr.type;
  tree.expr.type=types.erasure(eType);
  if (eType.tag == TYPEVAR && eType.getUpperBound().isCompound())   tree.expr=make.TypeCast(types.erasure(iterableType),tree.expr);
  Symbol iterator=lookupMethod(tree.expr.pos(),names.iterator,types.erasure(syms.iterableType),List.<Type>nil());
  VarSymbol itvar=new VarSymbol(0,names.fromString(""String_Node_Str"" + target.syntheticNameChar()),types.erasure(iterator.type.getReturnType()),currentMethodSym);
  JCStatement init=make.VarDef(itvar,make.App(make.Select(tree.expr,iterator)));
  Symbol hasNext=lookupMethod(tree.expr.pos(),names.hasNext,itvar.type,List.<Type>nil());
  JCMethodInvocation cond=make.App(make.Select(make.Ident(itvar),hasNext));
  Symbol next=lookupMethod(tree.expr.pos(),names.next,itvar.type,List.<Type>nil());
  JCExpression vardefinit=make.App(make.Select(make.Ident(itvar),next));
  if (tree.var.type.isPrimitive())   vardefinit=make.TypeCast(types.upperBound(iteratorTarget),vardefinit);
 else   vardefinit=make.TypeCast(tree.var.type,vardefinit);
  JCVariableDecl indexDef=(JCVariableDecl)make.VarDef(tree.var.mods,tree.var.name,tree.var.vartype,vardefinit).setType(tree.var.type);
  indexDef.sym=tree.var.sym;
  JCBlock body=make.Block(0,List.of(indexDef,tree.body));
  body.endpos=TreeInfo.endPos(tree.body);
  result=translate(make.ForLoop(List.of(init),cond,List.<JCExpressionStatement>nil(),body));
  patchTargets(body,tree,result);
}","/** 
 * A statement of the form <pre> for ( T v : coll ) stmt ; </pre> (where coll implements   {@code Iterable<? extends T>}) gets translated to <pre>  {@code}for ( Iterator<? extends T> #i = coll.iterator(); #i.hasNext(); )  T v = (T) #i.next(); stmt; } }</pre> where #i is a freshly named synthetic local variable.
 */
private void visitIterableForeachLoop(JCEnhancedForLoop tree){
  make_at(tree.expr.pos());
  Type iteratorTarget=syms.objectType;
  Type iterableType=types.asSuper(types.upperBound(tree.expr.type),syms.iterableType.tsym);
  if (iterableType.getTypeArguments().nonEmpty())   iteratorTarget=types.erasure(iterableType.getTypeArguments().head);
  Type eType=tree.expr.type;
  tree.expr.type=types.erasure(eType);
  if (eType.tag == TYPEVAR && eType.getUpperBound().isCompound())   tree.expr=make.TypeCast(types.erasure(iterableType),tree.expr);
  Symbol iterator=lookupMethod(tree.expr.pos(),names.iterator,types.erasure(syms.iterableType),List.<Type>nil());
  VarSymbol itvar=new VarSymbol(0,names.fromString(""String_Node_Str"" + target.syntheticNameChar()),types.erasure(iterator.type.getReturnType()),currentMethodSym);
  JCStatement init=make.VarDef(itvar,make.App(make.Select(tree.expr,iterator)));
  Symbol hasNext=lookupMethod(tree.expr.pos(),names.hasNext,itvar.type,List.<Type>nil());
  JCMethodInvocation cond=make.App(make.Select(make.Ident(itvar),hasNext));
  Symbol next=lookupMethod(tree.expr.pos(),names.next,itvar.type,List.<Type>nil());
  JCExpression vardefinit=make.App(make.Select(make.Ident(itvar),next));
  if (tree.var.type.isPrimitive())   vardefinit=make.TypeCast(types.upperBound(iteratorTarget),vardefinit);
 else   vardefinit=make.TypeCast(tree.var.type,vardefinit);
  JCVariableDecl indexDef=(JCVariableDecl)make.VarDef(tree.var.mods,tree.var.name,tree.var.vartype,vardefinit).setType(tree.var.type);
  indexDef.sym=tree.var.sym;
  JCBlock body=make.Block(0,List.of(indexDef,tree.body));
  body.endpos=TreeInfo.endPos(tree.body);
  result=translate(make.ForLoop(List.of(init),cond,List.<JCExpressionStatement>nil(),body));
  patchTargets(body,tree,result);
}"
37228,"/** 
 * Return tree simulating the assignment <this.name = name>, where name is the name of a free variable.
 */
JCStatement initField(int pos,Name name){
  Scope.Entry e=proxies.lookup(name);
  Symbol rhs=e.sym;
  Assert.check(rhs.owner.kind == MTH);
  Symbol lhs=e.next().sym;
  Assert.check(rhs.owner.owner == lhs.owner);
  make.at(pos);
  return make.Exec(make.Assign(make.Select(make.This(lhs.owner.erasure(types)),lhs),make.Ident(rhs)).setType(lhs.erasure(types)));
}","/** 
 * Return tree simulating the assignment   {@code this.name = name}, where name is the name of a free variable.
 */
JCStatement initField(int pos,Name name){
  Scope.Entry e=proxies.lookup(name);
  Symbol rhs=e.sym;
  Assert.check(rhs.owner.kind == MTH);
  Symbol lhs=e.next().sym;
  Assert.check(rhs.owner.owner == lhs.owner);
  make.at(pos);
  return make.Exec(make.Assign(make.Select(make.This(lhs.owner.erasure(types)),lhs),make.Ident(rhs)).setType(lhs.erasure(types)));
}"
37229,"/** 
 * A name designates an operator if it consists of a non-empty sequence of operator symbols +-~!/*%&|^<>=
 */
boolean isOperator(Name name){
  int i=0;
  while (i < name.getByteLength() && ""String_Node_Str"".indexOf(name.getByteAt(i)) >= 0)   i++;
  return i > 0 && i == name.getByteLength();
}","/** 
 * A name designates an operator if it consists of a non-empty sequence of operator symbols   {@literal +-~!/*%&|^<>= }
 */
boolean isOperator(Name name){
  int i=0;
  while (i < name.getByteLength() && ""String_Node_Str"".indexOf(name.getByteAt(i)) >= 0)   i++;
  return i > 0 && i == name.getByteLength();
}"
37230,"/** 
 * This method scans all the constructor symbol in a given class scope - assuming that the original scope contains a constructor of the kind: Foo(X x, Y y), where X,Y are class type-variables declared in Foo, a method check is executed against the modified constructor type: <X,Y>Foo<X,Y>(X x, Y y). This is crucial in order to enable diamond inference. The inferred return type of the synthetic constructor IS the inferred type for the diamond operator.
 */
private Symbol findDiamond(Env<AttrContext> env,Type site,List<Type> argtypes,List<Type> typeargtypes,boolean allowBoxing,boolean useVarargs){
  Symbol bestSoFar=methodNotFound;
  for (Scope.Entry e=site.tsym.members().lookup(names.init); e.scope != null; e=e.next()) {
    if (e.sym.kind == MTH && (e.sym.flags_field & SYNTHETIC) == 0) {
      List<Type> oldParams=e.sym.type.tag == FORALL ? ((ForAll)e.sym.type).tvars : List.<Type>nil();
      Type constrType=new ForAll(site.tsym.type.getTypeArguments().appendList(oldParams),types.createMethodTypeWithReturn(e.sym.type.asMethodType(),site));
      bestSoFar=selectBest(env,site,argtypes,typeargtypes,new MethodSymbol(e.sym.flags(),names.init,constrType,site.tsym),bestSoFar,allowBoxing,useVarargs,false);
    }
  }
  return bestSoFar;
}","/** 
 * This method scans all the constructor symbol in a given class scope - assuming that the original scope contains a constructor of the kind:  {@code Foo(X x, Y y)}, where X,Y are class type-variables declared in Foo, a method check is executed against the modified constructor type:  {@code <X,Y>Foo<X,Y>(X x, Y y)}. This is crucial in order to enable diamond inference. The inferred return type of the synthetic constructor IS the inferred type for the diamond operator.
 */
private Symbol findDiamond(Env<AttrContext> env,Type site,List<Type> argtypes,List<Type> typeargtypes,boolean allowBoxing,boolean useVarargs){
  Symbol bestSoFar=methodNotFound;
  for (Scope.Entry e=site.tsym.members().lookup(names.init); e.scope != null; e=e.next()) {
    if (e.sym.kind == MTH && (e.sym.flags_field & SYNTHETIC) == 0) {
      List<Type> oldParams=e.sym.type.tag == FORALL ? ((ForAll)e.sym.type).tvars : List.<Type>nil();
      Type constrType=new ForAll(site.tsym.type.getTypeArguments().appendList(oldParams),types.createMethodTypeWithReturn(e.sym.type.asMethodType(),site));
      bestSoFar=selectBest(env,site,argtypes,typeargtypes,new MethodSymbol(e.sym.flags(),names.init,constrType,site.tsym),bestSoFar,allowBoxing,useVarargs,false);
    }
  }
  return bestSoFar;
}"
37231,"/** 
 * Source file positions in CRT are integers in the format: line-number << LINESHIFT + column-number
 */
private int encodePosition(int pos,Position.LineMap lineMap,Log log){
  int line=lineMap.getLineNumber(pos);
  int col=lineMap.getColumnNumber(pos);
  int new_pos=Position.encodePosition(line,col);
  if (crtDebug) {
    System.out.println(""String_Node_Str"" + line + ""String_Node_Str""+ col+ ""String_Node_Str""+ new_pos);
  }
  if (new_pos == Position.NOPOS)   log.warning(pos,""String_Node_Str"",line);
  return new_pos;
}","/** 
 * Source file positions in CRT are integers in the format:  {@literal line-number << LINESHIFT + column-number }
 */
private int encodePosition(int pos,Position.LineMap lineMap,Log log){
  int line=lineMap.getLineNumber(pos);
  int col=lineMap.getColumnNumber(pos);
  int new_pos=Position.encodePosition(line,col);
  if (crtDebug) {
    System.out.println(""String_Node_Str"" + line + ""String_Node_Str""+ col+ ""String_Node_Str""+ new_pos);
  }
  if (new_pos == Position.NOPOS)   log.warning(pos,""String_Node_Str"",line);
  return new_pos;
}"
37232,"public synchronized int getNumDeactivated() throws RemoteException {
  return (num_deactivated);
}","public synchronized int getNumDeactivated() throws RemoteException {
  return num_deactivated;
}"
37233,"public static void main(String[] args){
  Registry registry;
  System.err.println(""String_Node_Str"");
  TestLibrary.suggestSecurityManager(""String_Node_Str"");
  RMID rmid=null;
  try {
    RMID.removeLog();
    rmid=RMID.createRMID();
    rmid.start();
    final Properties p=new Properties();
    p.put(""String_Node_Str"",TestParams.defaultGroupPolicy);
    p.put(""String_Node_Str"",TestParams.defaultSecurityManager);
    Thread t=new Thread(){
      public void run(){
        try {
          System.err.println(""String_Node_Str"");
          ActivationGroupDesc groupDesc=new ActivationGroupDesc(p,null);
          ActivationSystem system=ActivationGroup.getSystem();
          ActivationGroupID groupID=system.registerGroup(groupDesc);
          ActivateMe[] obj=new ActivateMe[NUM_OBJECTS];
          for (int i=0; i < NUM_OBJECTS; i++) {
            System.err.println(""String_Node_Str"" + i);
            ActivationDesc desc=new ActivationDesc(groupID,""String_Node_Str"",null,null);
            System.err.println(""String_Node_Str"" + i);
            obj[i]=(ActivateMe)Activatable.register(desc);
            System.err.println(""String_Node_Str"" + i);
            obj[i].ping();
          }
          lastResortExitObj=obj[0];
          System.err.println(""String_Node_Str"");
          system.unregisterGroup(groupID);
          try {
            System.err.println(""String_Node_Str"");
            system.getActivationGroupDesc(groupID);
            error=""String_Node_Str"";
          }
 catch (          UnknownGroupException e) {
            System.err.println(""String_Node_Str"" + ""String_Node_Str"");
          }
          for (int i=0; i < NUM_OBJECTS; i++) {
            System.err.println(""String_Node_Str"" + i);
            obj[i].shutdown();
            obj[i]=null;
          }
          lastResortExitObj=null;
        }
 catch (        Exception e) {
          exception=e;
        }
        done=true;
      }
    }
;
    t.start();
    t.join(120000);
    if (exception != null) {
      TestLibrary.bomb(""String_Node_Str"",exception);
    }
 else     if (error != null) {
      TestLibrary.bomb(error,null);
    }
 else     if (!done) {
      TestLibrary.bomb(""String_Node_Str"",null);
    }
 else {
      System.err.println(""String_Node_Str"");
    }
  }
 catch (  Exception e) {
    TestLibrary.bomb(""String_Node_Str"",e);
  }
 finally {
    if (lastResortExitObj != null) {
      try {
        lastResortExitObj.justGoAway();
      }
 catch (      Exception munch) {
      }
    }
    try {
      registry=TestLibrary.createRegistryOnUnusedPort();
      registryPort=TestLibrary.getRegistryPort(registry);
      Callback robj=new Callback();
      registry.bind(""String_Node_Str"",robj);
      int maxwait=30;
      int nd=robj.getNumDeactivated();
      while ((nd < NUM_OBJECTS) && (maxwait > 0)) {
        System.err.println(""String_Node_Str"" + nd);
        try {
          Thread.sleep(1000);
        }
 catch (        InterruptedException ie) {
        }
        maxwait--;
        nd=robj.getNumDeactivated();
      }
    }
 catch (    Exception ce) {
      System.err.println(""String_Node_Str"" + ce);
      ce.printStackTrace();
    }
    ActivationLibrary.rmidCleanup(rmid);
  }
}","public static void main(String[] args) throws RemoteException {
  System.err.println(""String_Node_Str"");
  TestLibrary.suggestSecurityManager(""String_Node_Str"");
  RMID rmid=null;
  Registry registry=TestLibrary.createRegistryOnUnusedPort();
  registryPort=TestLibrary.getRegistryPort(registry);
  Callback robj=new Callback();
  registry.rebind(""String_Node_Str"",robj);
  try {
    RMID.removeLog();
    rmid=RMID.createRMID();
    rmid.start();
    final Properties p=new Properties();
    p.put(""String_Node_Str"",TestParams.defaultGroupPolicy);
    p.put(""String_Node_Str"",TestParams.defaultSecurityManager);
    p.put(""String_Node_Str"",Integer.toString(registryPort));
    Thread t=new Thread(){
      public void run(){
        try {
          System.err.println(""String_Node_Str"");
          ActivationGroupDesc groupDesc=new ActivationGroupDesc(p,null);
          ActivationSystem system=ActivationGroup.getSystem();
          ActivationGroupID groupID=system.registerGroup(groupDesc);
          ActivateMe[] obj=new ActivateMe[NUM_OBJECTS];
          for (int i=0; i < NUM_OBJECTS; i++) {
            System.err.println(""String_Node_Str"" + i);
            ActivationDesc desc=new ActivationDesc(groupID,""String_Node_Str"",null,null);
            System.err.println(""String_Node_Str"" + i);
            obj[i]=(ActivateMe)Activatable.register(desc);
            System.err.println(""String_Node_Str"" + i);
            obj[i].ping();
          }
          lastResortExitObj=obj[0];
          System.err.println(""String_Node_Str"");
          system.unregisterGroup(groupID);
          try {
            System.err.println(""String_Node_Str"");
            system.getActivationGroupDesc(groupID);
            error=""String_Node_Str"";
          }
 catch (          UnknownGroupException e) {
            System.err.println(""String_Node_Str"" + ""String_Node_Str"");
          }
          for (int i=0; i < NUM_OBJECTS; i++) {
            System.err.println(""String_Node_Str"" + i);
            obj[i].shutdown();
            obj[i]=null;
          }
          lastResortExitObj=null;
        }
 catch (        Exception e) {
          exception=e;
        }
        done=true;
      }
    }
;
    t.start();
    t.join(120000);
    if (exception != null) {
      TestLibrary.bomb(""String_Node_Str"",exception);
    }
 else     if (error != null) {
      TestLibrary.bomb(error,null);
    }
 else     if (!done) {
      TestLibrary.bomb(""String_Node_Str"",null);
    }
 else {
      System.err.println(""String_Node_Str"");
    }
  }
 catch (  Exception e) {
    TestLibrary.bomb(""String_Node_Str"",e);
  }
 finally {
    if (lastResortExitObj != null) {
      try {
        lastResortExitObj.justGoAway();
      }
 catch (      Exception munch) {
      }
    }
    try {
      int maxwait=30;
      int nd=robj.getNumDeactivated();
      while ((nd < NUM_OBJECTS) && (maxwait > 0)) {
        System.err.println(""String_Node_Str"" + nd);
        try {
          Thread.sleep(1000);
        }
 catch (        InterruptedException ie) {
        }
        maxwait--;
        nd=robj.getNumDeactivated();
      }
    }
 catch (    Exception ce) {
      System.err.println(""String_Node_Str"" + ce);
      ce.printStackTrace();
    }
    ActivationLibrary.rmidCleanup(rmid);
  }
}"
37234,"public void inc() throws RemoteException {
  incNumDeactivated();
}","public synchronized void inc() throws RemoteException {
  num_deactivated++;
}"
37235,"public synchronized int getNumDeactivated() throws RemoteException {
  return (num_deactivated);
}","public synchronized int getNumDeactivated() throws RemoteException {
  return num_deactivated;
}"
37236,"public static void main(String[] args){
  Registry registry;
  System.err.println(""String_Node_Str"");
  TestLibrary.suggestSecurityManager(""String_Node_Str"");
  RMID rmid=null;
  try {
    RMID.removeLog();
    rmid=RMID.createRMID();
    rmid.start();
    final Properties p=new Properties();
    p.put(""String_Node_Str"",TestParams.defaultGroupPolicy);
    p.put(""String_Node_Str"",TestParams.defaultSecurityManager);
    Thread t=new Thread(){
      public void run(){
        try {
          System.err.println(""String_Node_Str"");
          ActivationGroupDesc groupDesc=new ActivationGroupDesc(p,null);
          ActivationSystem system=ActivationGroup.getSystem();
          ActivationGroupID groupID=system.registerGroup(groupDesc);
          ActivateMe[] obj=new ActivateMe[NUM_OBJECTS];
          for (int i=0; i < NUM_OBJECTS; i++) {
            System.err.println(""String_Node_Str"" + i);
            ActivationDesc desc=new ActivationDesc(groupID,""String_Node_Str"",null,null);
            System.err.println(""String_Node_Str"" + i);
            obj[i]=(ActivateMe)Activatable.register(desc);
            System.err.println(""String_Node_Str"" + i);
            obj[i].ping();
          }
          lastResortExitObj=obj[0];
          System.err.println(""String_Node_Str"");
          system.unregisterGroup(groupID);
          try {
            System.err.println(""String_Node_Str"");
            system.getActivationGroupDesc(groupID);
            error=""String_Node_Str"";
          }
 catch (          UnknownGroupException e) {
            System.err.println(""String_Node_Str"" + ""String_Node_Str"");
          }
          for (int i=0; i < NUM_OBJECTS; i++) {
            System.err.println(""String_Node_Str"" + i);
            obj[i].shutdown();
            obj[i]=null;
          }
          lastResortExitObj=null;
        }
 catch (        Exception e) {
          exception=e;
        }
        done=true;
      }
    }
;
    t.start();
    t.join(120000);
    if (exception != null) {
      TestLibrary.bomb(""String_Node_Str"",exception);
    }
 else     if (error != null) {
      TestLibrary.bomb(error,null);
    }
 else     if (!done) {
      TestLibrary.bomb(""String_Node_Str"",null);
    }
 else {
      System.err.println(""String_Node_Str"");
    }
  }
 catch (  Exception e) {
    TestLibrary.bomb(""String_Node_Str"",e);
  }
 finally {
    if (lastResortExitObj != null) {
      try {
        lastResortExitObj.justGoAway();
      }
 catch (      Exception munch) {
      }
    }
    try {
      registry=TestLibrary.createRegistryOnUnusedPort();
      registryPort=TestLibrary.getRegistryPort(registry);
      Callback robj=new Callback();
      registry.bind(""String_Node_Str"",robj);
      int maxwait=30;
      int nd=robj.getNumDeactivated();
      while ((nd < NUM_OBJECTS) && (maxwait > 0)) {
        System.err.println(""String_Node_Str"" + nd);
        try {
          Thread.sleep(1000);
        }
 catch (        InterruptedException ie) {
        }
        maxwait--;
        nd=robj.getNumDeactivated();
      }
    }
 catch (    Exception ce) {
      System.err.println(""String_Node_Str"" + ce);
      ce.printStackTrace();
    }
    ActivationLibrary.rmidCleanup(rmid);
  }
}","public static void main(String[] args) throws RemoteException {
  System.err.println(""String_Node_Str"");
  TestLibrary.suggestSecurityManager(""String_Node_Str"");
  RMID rmid=null;
  Registry registry=TestLibrary.createRegistryOnUnusedPort();
  registryPort=TestLibrary.getRegistryPort(registry);
  Callback robj=new Callback();
  registry.rebind(""String_Node_Str"",robj);
  try {
    RMID.removeLog();
    rmid=RMID.createRMID();
    rmid.start();
    final Properties p=new Properties();
    p.put(""String_Node_Str"",TestParams.defaultGroupPolicy);
    p.put(""String_Node_Str"",TestParams.defaultSecurityManager);
    p.put(""String_Node_Str"",Integer.toString(registryPort));
    Thread t=new Thread(){
      public void run(){
        try {
          System.err.println(""String_Node_Str"");
          ActivationGroupDesc groupDesc=new ActivationGroupDesc(p,null);
          ActivationSystem system=ActivationGroup.getSystem();
          ActivationGroupID groupID=system.registerGroup(groupDesc);
          ActivateMe[] obj=new ActivateMe[NUM_OBJECTS];
          for (int i=0; i < NUM_OBJECTS; i++) {
            System.err.println(""String_Node_Str"" + i);
            ActivationDesc desc=new ActivationDesc(groupID,""String_Node_Str"",null,null);
            System.err.println(""String_Node_Str"" + i);
            obj[i]=(ActivateMe)Activatable.register(desc);
            System.err.println(""String_Node_Str"" + i);
            obj[i].ping();
          }
          lastResortExitObj=obj[0];
          System.err.println(""String_Node_Str"");
          system.unregisterGroup(groupID);
          try {
            System.err.println(""String_Node_Str"");
            system.getActivationGroupDesc(groupID);
            error=""String_Node_Str"";
          }
 catch (          UnknownGroupException e) {
            System.err.println(""String_Node_Str"" + ""String_Node_Str"");
          }
          for (int i=0; i < NUM_OBJECTS; i++) {
            System.err.println(""String_Node_Str"" + i);
            obj[i].shutdown();
            obj[i]=null;
          }
          lastResortExitObj=null;
        }
 catch (        Exception e) {
          exception=e;
        }
        done=true;
      }
    }
;
    t.start();
    t.join(120000);
    if (exception != null) {
      TestLibrary.bomb(""String_Node_Str"",exception);
    }
 else     if (error != null) {
      TestLibrary.bomb(error,null);
    }
 else     if (!done) {
      TestLibrary.bomb(""String_Node_Str"",null);
    }
 else {
      System.err.println(""String_Node_Str"");
    }
  }
 catch (  Exception e) {
    TestLibrary.bomb(""String_Node_Str"",e);
  }
 finally {
    if (lastResortExitObj != null) {
      try {
        lastResortExitObj.justGoAway();
      }
 catch (      Exception munch) {
      }
    }
    try {
      int maxwait=30;
      int nd=robj.getNumDeactivated();
      while ((nd < NUM_OBJECTS) && (maxwait > 0)) {
        System.err.println(""String_Node_Str"" + nd);
        try {
          Thread.sleep(1000);
        }
 catch (        InterruptedException ie) {
        }
        maxwait--;
        nd=robj.getNumDeactivated();
      }
    }
 catch (    Exception ce) {
      System.err.println(""String_Node_Str"" + ce);
      ce.printStackTrace();
    }
    ActivationLibrary.rmidCleanup(rmid);
  }
}"
37237,"public void inc() throws RemoteException {
  incNumDeactivated();
}","public synchronized void inc() throws RemoteException {
  num_deactivated++;
}"
37238,"public String[] bases(String repId){
  String[] results=null;
  if (bases == null)   bases=new Hashtable();
 else   results=(String[])bases.get(repId);
  if (results == null && connectedCodeBase()) {
    results=delegate.bases(repId);
    if (results != null)     bases.put(repId,results);
  }
  return results;
}","public synchronized String[] bases(String repId){
  String[] results=null;
  if (bases == null)   bases=new Hashtable();
 else   results=(String[])bases.get(repId);
  if (results == null && connectedCodeBase()) {
    results=delegate.bases(repId);
    if (results != null)     bases.put(repId,results);
  }
  return results;
}"
37239,"public FullValueDescription[] metas(String[] repIds){
  FullValueDescription[] results=new FullValueDescription[repIds.length];
  for (int i=0; i < results.length; i++)   results[i]=meta(repIds[i]);
  return results;
}","public synchronized FullValueDescription[] metas(String[] repIds){
  FullValueDescription[] results=new FullValueDescription[repIds.length];
  for (int i=0; i < results.length; i++)   results[i]=meta(repIds[i]);
  return results;
}"
37240,"private boolean connectedCodeBase(){
  if (delegate != null)   return true;
  if (conn.getCodeBaseIOR() == null) {
    if (conn.getBroker().transportDebugFlag)     conn.dprint(""String_Node_Str"" + conn);
    return false;
  }
synchronized (this) {
    if (delegate != null)     return true;
    delegate=(CodeBase)CachedCodeBase.iorToCodeBaseObjMap.get(conn.getCodeBaseIOR());
    if (delegate != null)     return true;
    delegate=CodeBaseHelper.narrow(getObjectFromIOR());
    CachedCodeBase.iorToCodeBaseObjMap.put(conn.getCodeBaseIOR(),delegate);
  }
  return true;
}","private synchronized boolean connectedCodeBase(){
  if (delegate != null)   return true;
  if (conn.getCodeBaseIOR() == null) {
    if (conn.getBroker().transportDebugFlag)     conn.dprint(""String_Node_Str"" + conn);
    return false;
  }
synchronized (iorMapLock) {
    if (delegate != null)     return true;
    delegate=CachedCodeBase.iorMap.get(conn.getCodeBaseIOR());
    if (delegate != null)     return true;
    delegate=CodeBaseHelper.narrow(getObjectFromIOR());
    CachedCodeBase.iorMap.put(conn.getCodeBaseIOR(),delegate);
  }
  return true;
}"
37241,"public FullValueDescription meta(String repId){
  FullValueDescription result=null;
  if (fvds == null)   fvds=new Hashtable();
 else   result=(FullValueDescription)fvds.get(repId);
  if (result == null && connectedCodeBase()) {
    result=delegate.meta(repId);
    if (result != null)     fvds.put(repId,result);
  }
  return result;
}","public synchronized FullValueDescription meta(String repId){
  FullValueDescription result=null;
  if (fvds == null)   fvds=new Hashtable();
 else   result=(FullValueDescription)fvds.get(repId);
  if (result == null && connectedCodeBase()) {
    result=delegate.meta(repId);
    if (result != null)     fvds.put(repId,result);
  }
  return result;
}"
37242,"public String implementation(String repId){
  String urlResult=null;
  if (implementations == null)   implementations=new Hashtable();
 else   urlResult=(String)implementations.get(repId);
  if (urlResult == null && connectedCodeBase()) {
    urlResult=delegate.implementation(repId);
    if (urlResult != null)     implementations.put(repId,urlResult);
  }
  return urlResult;
}","public synchronized String implementation(String repId){
  String urlResult=null;
  if (implementations == null)   implementations=new Hashtable();
 else   urlResult=(String)implementations.get(repId);
  if (urlResult == null && connectedCodeBase()) {
    urlResult=delegate.implementation(repId);
    if (urlResult != null)     implementations.put(repId,urlResult);
  }
  return urlResult;
}"
37243,"public String[] implementations(String[] repIds){
  String[] urlResults=new String[repIds.length];
  for (int i=0; i < urlResults.length; i++)   urlResults[i]=implementation(repIds[i]);
  return urlResults;
}","public synchronized String[] implementations(String[] repIds){
  String[] urlResults=new String[repIds.length];
  for (int i=0; i < urlResults.length; i++)   urlResults[i]=implementation(repIds[i]);
  return urlResults;
}"
37244,"public String[] bases(String repId){
  String[] results=null;
  if (bases == null)   bases=new Hashtable();
 else   results=(String[])bases.get(repId);
  if (results == null && connectedCodeBase()) {
    results=delegate.bases(repId);
    if (results != null)     bases.put(repId,results);
  }
  return results;
}","public synchronized String[] bases(String repId){
  String[] results=null;
  if (bases == null)   bases=new Hashtable();
 else   results=(String[])bases.get(repId);
  if (results == null && connectedCodeBase()) {
    results=delegate.bases(repId);
    if (results != null)     bases.put(repId,results);
  }
  return results;
}"
37245,"public FullValueDescription[] metas(String[] repIds){
  FullValueDescription[] results=new FullValueDescription[repIds.length];
  for (int i=0; i < results.length; i++)   results[i]=meta(repIds[i]);
  return results;
}","public synchronized FullValueDescription[] metas(String[] repIds){
  FullValueDescription[] results=new FullValueDescription[repIds.length];
  for (int i=0; i < results.length; i++)   results[i]=meta(repIds[i]);
  return results;
}"
37246,"private boolean connectedCodeBase(){
  if (delegate != null)   return true;
  if (conn.getCodeBaseIOR() == null) {
    if (conn.getBroker().transportDebugFlag)     conn.dprint(""String_Node_Str"" + conn);
    return false;
  }
synchronized (this) {
    if (delegate != null)     return true;
    delegate=(CodeBase)CachedCodeBase.iorToCodeBaseObjMap.get(conn.getCodeBaseIOR());
    if (delegate != null)     return true;
    delegate=CodeBaseHelper.narrow(getObjectFromIOR());
    CachedCodeBase.iorToCodeBaseObjMap.put(conn.getCodeBaseIOR(),delegate);
  }
  return true;
}","private synchronized boolean connectedCodeBase(){
  if (delegate != null)   return true;
  if (conn.getCodeBaseIOR() == null) {
    if (conn.getBroker().transportDebugFlag)     conn.dprint(""String_Node_Str"" + conn);
    return false;
  }
synchronized (iorMapLock) {
    if (delegate != null)     return true;
    delegate=CachedCodeBase.iorMap.get(conn.getCodeBaseIOR());
    if (delegate != null)     return true;
    delegate=CodeBaseHelper.narrow(getObjectFromIOR());
    CachedCodeBase.iorMap.put(conn.getCodeBaseIOR(),delegate);
  }
  return true;
}"
37247,"public FullValueDescription meta(String repId){
  FullValueDescription result=null;
  if (fvds == null)   fvds=new Hashtable();
 else   result=(FullValueDescription)fvds.get(repId);
  if (result == null && connectedCodeBase()) {
    result=delegate.meta(repId);
    if (result != null)     fvds.put(repId,result);
  }
  return result;
}","public synchronized FullValueDescription meta(String repId){
  FullValueDescription result=null;
  if (fvds == null)   fvds=new Hashtable();
 else   result=(FullValueDescription)fvds.get(repId);
  if (result == null && connectedCodeBase()) {
    result=delegate.meta(repId);
    if (result != null)     fvds.put(repId,result);
  }
  return result;
}"
37248,"public String implementation(String repId){
  String urlResult=null;
  if (implementations == null)   implementations=new Hashtable();
 else   urlResult=(String)implementations.get(repId);
  if (urlResult == null && connectedCodeBase()) {
    urlResult=delegate.implementation(repId);
    if (urlResult != null)     implementations.put(repId,urlResult);
  }
  return urlResult;
}","public synchronized String implementation(String repId){
  String urlResult=null;
  if (implementations == null)   implementations=new Hashtable();
 else   urlResult=(String)implementations.get(repId);
  if (urlResult == null && connectedCodeBase()) {
    urlResult=delegate.implementation(repId);
    if (urlResult != null)     implementations.put(repId,urlResult);
  }
  return urlResult;
}"
37249,"public String[] implementations(String[] repIds){
  String[] urlResults=new String[repIds.length];
  for (int i=0; i < urlResults.length; i++)   urlResults[i]=implementation(repIds[i]);
  return urlResults;
}","public synchronized String[] implementations(String[] repIds){
  String[] urlResults=new String[repIds.length];
  for (int i=0; i < urlResults.length; i++)   urlResults[i]=implementation(repIds[i]);
  return urlResults;
}"
37250,"private static void executeCommandForPid(String pid,String command) throws AttachNotSupportedException, IOException, UnsupportedEncodingException {
  VirtualMachine vm=VirtualMachine.attach(pid);
  HotSpotVirtualMachine hvm=(HotSpotVirtualMachine)vm;
  try (InputStream in=hvm.executeJCmd(command)){
    byte b[]=new byte[256];
    int n;
    do {
      n=in.read(b);
      if (n > 0) {
        String s=new String(b,0,n,""String_Node_Str"");
        System.out.print(s);
      }
    }
 while (n > 0);
  }
   vm.detach();
}","private static void executeCommandForPid(String pid,String command) throws AttachNotSupportedException, IOException, UnsupportedEncodingException {
  VirtualMachine vm=VirtualMachine.attach(pid);
  HotSpotVirtualMachine hvm=(HotSpotVirtualMachine)vm;
  String lines[]=command.split(""String_Node_Str"");
  for (  String line : lines) {
    try (InputStream in=hvm.executeJCmd(line)){
      byte b[]=new byte[256];
      int n;
      do {
        n=in.read(b);
        if (n > 0) {
          String s=new String(b,0,n,""String_Node_Str"");
          System.out.print(s);
        }
      }
 while (n > 0);
    }
   }
  vm.detach();
}"
37251,"private static void executeCommandForPid(String pid,String command) throws AttachNotSupportedException, IOException, UnsupportedEncodingException {
  VirtualMachine vm=VirtualMachine.attach(pid);
  HotSpotVirtualMachine hvm=(HotSpotVirtualMachine)vm;
  try (InputStream in=hvm.executeJCmd(command)){
    byte b[]=new byte[256];
    int n;
    do {
      n=in.read(b);
      if (n > 0) {
        String s=new String(b,0,n,""String_Node_Str"");
        System.out.print(s);
      }
    }
 while (n > 0);
  }
   vm.detach();
}","private static void executeCommandForPid(String pid,String command) throws AttachNotSupportedException, IOException, UnsupportedEncodingException {
  VirtualMachine vm=VirtualMachine.attach(pid);
  HotSpotVirtualMachine hvm=(HotSpotVirtualMachine)vm;
  String lines[]=command.split(""String_Node_Str"");
  for (  String line : lines) {
    try (InputStream in=hvm.executeJCmd(line)){
      byte b[]=new byte[256];
      int n;
      do {
        n=in.read(b);
        if (n > 0) {
          String s=new String(b,0,n,""String_Node_Str"");
          System.out.print(s);
        }
      }
 while (n > 0);
    }
   }
  vm.detach();
}"
37252,"protected void close(){
  if (fd != null || fd1 != null) {
    datagramSocketClose();
    fd=null;
    fd1=null;
  }
}","protected void close(){
  if (fd != null || fd1 != null) {
    datagramSocketClose();
    ResourceManager.afterUdpClose();
    fd=null;
    fd1=null;
  }
}"
37253,"protected void close(){
  if (fd != null || fd1 != null) {
    datagramSocketClose();
    fd=null;
    fd1=null;
  }
}","protected void close(){
  if (fd != null || fd1 != null) {
    datagramSocketClose();
    ResourceManager.afterUdpClose();
    fd=null;
    fd1=null;
  }
}"
37254,"public Log make(){
  return Bark.instance(context);
}","public Log make(Context c){
  return Bark.instance(c);
}"
37255,"/** 
 * Preregisters factories to create and use a Bark object for use as both a Log and a Bark.
 */
public static void preRegister(final Context context){
  context.put(barkKey,new Context.Factory<Bark>(){
    public Bark make(){
      return new Bark(context);
    }
  }
);
  context.put(Log.logKey,new Context.Factory<Log>(){
    public Log make(){
      return Bark.instance(context);
    }
  }
);
}","/** 
 * Preregisters factories to create and use a Bark object for use as both a Log and a Bark.
 */
public static void preRegister(Context context){
  context.put(barkKey,new Context.Factory<Bark>(){
    public Bark make(    Context c){
      return new Bark(c);
    }
  }
);
  context.put(Log.logKey,new Context.Factory<Log>(){
    public Log make(    Context c){
      return Bark.instance(c);
    }
  }
);
}"
37256,"/** 
 * Register that a compilation is about to start.
 */
void beginContext(final Context context){
  if (compilationInProgress)   throw new IllegalStateException(""String_Node_Str"");
  compilationInProgress=true;
  final JavaFileManager givenFileManager=context.get(JavaFileManager.class);
  context.put(JavaFileManager.class,(JavaFileManager)null);
  context.put(JavaFileManager.class,new Context.Factory<JavaFileManager>(){
    public JavaFileManager make(){
      if (givenFileManager != null) {
        context.put(JavaFileManager.class,givenFileManager);
        return givenFileManager;
      }
 else {
        return new JavacFileManager(context,true,null);
      }
    }
  }
);
}","/** 
 * Register that a compilation is about to start.
 */
void beginContext(Context context){
  if (compilationInProgress)   throw new IllegalStateException(""String_Node_Str"");
  compilationInProgress=true;
  final JavaFileManager givenFileManager=context.get(JavaFileManager.class);
  context.put(JavaFileManager.class,(JavaFileManager)null);
  context.put(JavaFileManager.class,new Context.Factory<JavaFileManager>(){
    public JavaFileManager make(    Context c){
      if (givenFileManager != null) {
        c.put(JavaFileManager.class,givenFileManager);
        return givenFileManager;
      }
 else {
        return new JavacFileManager(c,true,null);
      }
    }
  }
);
}"
37257,"public JavaFileManager make(){
  if (givenFileManager != null) {
    context.put(JavaFileManager.class,givenFileManager);
    return givenFileManager;
  }
 else {
    return new JavacFileManager(context,true,null);
  }
}","public JavaFileManager make(Context c){
  if (givenFileManager != null) {
    c.put(JavaFileManager.class,givenFileManager);
    return givenFileManager;
  }
 else {
    return new JavacFileManager(c,true,null);
  }
}"
37258,"public FSInfo make(){
  FSInfo instance=new CacheFSInfo();
  context.put(FSInfo.class,instance);
  return instance;
}","public FSInfo make(Context c){
  FSInfo instance=new CacheFSInfo();
  c.put(FSInfo.class,instance);
  return instance;
}"
37259,"/** 
 * Register a Context.Factory to create a singleton CacheFSInfo.
 */
public static void preRegister(final Context context){
  context.put(FSInfo.class,new Context.Factory<FSInfo>(){
    public FSInfo make(){
      FSInfo instance=new CacheFSInfo();
      context.put(FSInfo.class,instance);
      return instance;
    }
  }
);
}","/** 
 * Register a Context.Factory to create a CacheFSInfo.
 */
public static void preRegister(Context context){
  context.put(FSInfo.class,new Context.Factory<FSInfo>(){
    public FSInfo make(    Context c){
      FSInfo instance=new CacheFSInfo();
      c.put(FSInfo.class,instance);
      return instance;
    }
  }
);
}"
37260,"/** 
 * Register a Context.Factory to create a JavacFileManager.
 */
public static void preRegister(final Context context){
  context.put(JavaFileManager.class,new Context.Factory<JavaFileManager>(){
    public JavaFileManager make(){
      return new JavacFileManager(context,true,null);
    }
  }
);
}","/** 
 * Register a Context.Factory to create a JavacFileManager.
 */
public static void preRegister(Context context){
  context.put(JavaFileManager.class,new Context.Factory<JavaFileManager>(){
    public JavaFileManager make(    Context c){
      return new JavacFileManager(c,true,null);
    }
  }
);
}"
37261,"public JavaFileManager make(){
  return new JavacFileManager(context,true,null);
}","public JavaFileManager make(Context c){
  return new JavacFileManager(c,true,null);
}"
37262,"/** 
 * Construct a new compiler using a shared context.
 */
public JavaCompiler(final Context context){
  this.context=context;
  context.put(compilerKey,this);
  if (context.get(JavaFileManager.class) == null)   JavacFileManager.preRegister(context);
  names=Names.instance(context);
  log=Log.instance(context);
  diagFactory=JCDiagnostic.Factory.instance(context);
  reader=ClassReader.instance(context);
  make=TreeMaker.instance(context);
  writer=ClassWriter.instance(context);
  enter=Enter.instance(context);
  todo=Todo.instance(context);
  fileManager=context.get(JavaFileManager.class);
  parserFactory=ParserFactory.instance(context);
  try {
    syms=Symtab.instance(context);
  }
 catch (  CompletionFailure ex) {
    log.error(""String_Node_Str"",ex.sym,ex.getDetailValue());
    if (ex instanceof ClassReader.BadClassFile)     throw new Abort();
  }
  source=Source.instance(context);
  attr=Attr.instance(context);
  chk=Check.instance(context);
  gen=Gen.instance(context);
  flow=Flow.instance(context);
  transTypes=TransTypes.instance(context);
  lower=Lower.instance(context);
  annotate=Annotate.instance(context);
  types=Types.instance(context);
  taskListener=context.get(TaskListener.class);
  reader.sourceCompleter=this;
  Options options=Options.instance(context);
  verbose=options.isSet(VERBOSE);
  sourceOutput=options.isSet(PRINTSOURCE);
  stubOutput=options.isSet(""String_Node_Str"");
  relax=options.isSet(""String_Node_Str"");
  printFlat=options.isSet(""String_Node_Str"");
  attrParseOnly=options.isSet(""String_Node_Str"");
  encoding=options.get(ENCODING);
  lineDebugInfo=options.isUnset(G_CUSTOM) || options.isSet(G_CUSTOM,""String_Node_Str"");
  genEndPos=options.isSet(XJCOV) || context.get(DiagnosticListener.class) != null;
  devVerbose=options.isSet(""String_Node_Str"");
  processPcks=options.isSet(""String_Node_Str"");
  werror=options.isSet(WERROR);
  if (source.compareTo(Source.DEFAULT) < 0) {
    if (options.isUnset(XLINT_CUSTOM,""String_Node_Str"" + LintCategory.OPTIONS.option)) {
      if (fileManager instanceof BaseFileManager) {
        if (((BaseFileManager)fileManager).isDefaultBootClassPath())         log.warning(LintCategory.OPTIONS,""String_Node_Str"",source.name);
      }
    }
  }
  verboseCompilePolicy=options.isSet(""String_Node_Str"");
  if (attrParseOnly)   compilePolicy=CompilePolicy.ATTR_ONLY;
 else   compilePolicy=CompilePolicy.decode(options.get(""String_Node_Str""));
  implicitSourcePolicy=ImplicitSourcePolicy.decode(options.get(""String_Node_Str""));
  completionFailureName=options.isSet(""String_Node_Str"") ? names.fromString(options.get(""String_Node_Str"")) : null;
  shouldStopPolicy=options.isSet(""String_Node_Str"") ? CompileState.valueOf(options.get(""String_Node_Str"")) : null;
  if (options.isUnset(""String_Node_Str""))   log.setDiagnosticFormatter(RichDiagnosticFormatter.instance(context));
}","/** 
 * Construct a new compiler using a shared context.
 */
public JavaCompiler(Context context){
  this.context=context;
  context.put(compilerKey,this);
  if (context.get(JavaFileManager.class) == null)   JavacFileManager.preRegister(context);
  names=Names.instance(context);
  log=Log.instance(context);
  diagFactory=JCDiagnostic.Factory.instance(context);
  reader=ClassReader.instance(context);
  make=TreeMaker.instance(context);
  writer=ClassWriter.instance(context);
  enter=Enter.instance(context);
  todo=Todo.instance(context);
  fileManager=context.get(JavaFileManager.class);
  parserFactory=ParserFactory.instance(context);
  try {
    syms=Symtab.instance(context);
  }
 catch (  CompletionFailure ex) {
    log.error(""String_Node_Str"",ex.sym,ex.getDetailValue());
    if (ex instanceof ClassReader.BadClassFile)     throw new Abort();
  }
  source=Source.instance(context);
  attr=Attr.instance(context);
  chk=Check.instance(context);
  gen=Gen.instance(context);
  flow=Flow.instance(context);
  transTypes=TransTypes.instance(context);
  lower=Lower.instance(context);
  annotate=Annotate.instance(context);
  types=Types.instance(context);
  taskListener=context.get(TaskListener.class);
  reader.sourceCompleter=this;
  Options options=Options.instance(context);
  verbose=options.isSet(VERBOSE);
  sourceOutput=options.isSet(PRINTSOURCE);
  stubOutput=options.isSet(""String_Node_Str"");
  relax=options.isSet(""String_Node_Str"");
  printFlat=options.isSet(""String_Node_Str"");
  attrParseOnly=options.isSet(""String_Node_Str"");
  encoding=options.get(ENCODING);
  lineDebugInfo=options.isUnset(G_CUSTOM) || options.isSet(G_CUSTOM,""String_Node_Str"");
  genEndPos=options.isSet(XJCOV) || context.get(DiagnosticListener.class) != null;
  devVerbose=options.isSet(""String_Node_Str"");
  processPcks=options.isSet(""String_Node_Str"");
  werror=options.isSet(WERROR);
  if (source.compareTo(Source.DEFAULT) < 0) {
    if (options.isUnset(XLINT_CUSTOM,""String_Node_Str"" + LintCategory.OPTIONS.option)) {
      if (fileManager instanceof BaseFileManager) {
        if (((BaseFileManager)fileManager).isDefaultBootClassPath())         log.warning(LintCategory.OPTIONS,""String_Node_Str"",source.name);
      }
    }
  }
  verboseCompilePolicy=options.isSet(""String_Node_Str"");
  if (attrParseOnly)   compilePolicy=CompilePolicy.ATTR_ONLY;
 else   compilePolicy=CompilePolicy.decode(options.get(""String_Node_Str""));
  implicitSourcePolicy=ImplicitSourcePolicy.decode(options.get(""String_Node_Str""));
  completionFailureName=options.isSet(""String_Node_Str"") ? names.fromString(options.get(""String_Node_Str"")) : null;
  shouldStopPolicy=options.isSet(""String_Node_Str"") ? CompileState.valueOf(options.get(""String_Node_Str"")) : null;
  if (options.isUnset(""String_Node_Str""))   log.setDiagnosticFormatter(RichDiagnosticFormatter.instance(context));
}"
37263,"/** 
 * Get the context for the next round of processing. Important values are propogated from round to round; other values are implicitly reset.
 */
private Context nextContext(){
  Context next=new Context();
  Options options=Options.instance(context);
  Assert.checkNonNull(options);
  next.put(Options.optionsKey,options);
  PrintWriter out=context.get(Log.outKey);
  Assert.checkNonNull(out);
  next.put(Log.outKey,out);
  final boolean shareNames=true;
  if (shareNames) {
    Names names=Names.instance(context);
    Assert.checkNonNull(names);
    next.put(Names.namesKey,names);
  }
  DiagnosticListener<?> dl=context.get(DiagnosticListener.class);
  if (dl != null)   next.put(DiagnosticListener.class,dl);
  TaskListener tl=context.get(TaskListener.class);
  if (tl != null)   next.put(TaskListener.class,tl);
  FSInfo fsInfo=context.get(FSInfo.class);
  if (fsInfo != null)   next.put(FSInfo.class,fsInfo);
  JavaFileManager jfm=context.get(JavaFileManager.class);
  Assert.checkNonNull(jfm);
  next.put(JavaFileManager.class,jfm);
  if (jfm instanceof JavacFileManager) {
    ((JavacFileManager)jfm).setContext(next);
  }
  Names names=Names.instance(context);
  Assert.checkNonNull(names);
  next.put(Names.namesKey,names);
  Keywords keywords=Keywords.instance(context);
  Assert.checkNonNull(keywords);
  next.put(Keywords.keywordsKey,keywords);
  JavaCompiler oldCompiler=JavaCompiler.instance(context);
  JavaCompiler nextCompiler=JavaCompiler.instance(next);
  nextCompiler.initRound(oldCompiler);
  filer.newRound(next);
  messager.newRound(next);
  elementUtils.setContext(next);
  typeUtils.setContext(next);
  JavacTaskImpl task=context.get(JavacTaskImpl.class);
  if (task != null) {
    next.put(JavacTaskImpl.class,task);
    task.updateContext(next);
  }
  JavacTrees trees=context.get(JavacTrees.class);
  if (trees != null) {
    next.put(JavacTrees.class,trees);
    trees.updateContext(next);
  }
  context.clear();
  return next;
}","/** 
 * Get the context for the next round of processing. Important values are propogated from round to round; other values are implicitly reset.
 */
private Context nextContext(){
  Context next=new Context(context);
  Options options=Options.instance(context);
  Assert.checkNonNull(options);
  next.put(Options.optionsKey,options);
  PrintWriter out=context.get(Log.outKey);
  Assert.checkNonNull(out);
  next.put(Log.outKey,out);
  final boolean shareNames=true;
  if (shareNames) {
    Names names=Names.instance(context);
    Assert.checkNonNull(names);
    next.put(Names.namesKey,names);
  }
  DiagnosticListener<?> dl=context.get(DiagnosticListener.class);
  if (dl != null)   next.put(DiagnosticListener.class,dl);
  TaskListener tl=context.get(TaskListener.class);
  if (tl != null)   next.put(TaskListener.class,tl);
  FSInfo fsInfo=context.get(FSInfo.class);
  if (fsInfo != null)   next.put(FSInfo.class,fsInfo);
  JavaFileManager jfm=context.get(JavaFileManager.class);
  Assert.checkNonNull(jfm);
  next.put(JavaFileManager.class,jfm);
  if (jfm instanceof JavacFileManager) {
    ((JavacFileManager)jfm).setContext(next);
  }
  Names names=Names.instance(context);
  Assert.checkNonNull(names);
  next.put(Names.namesKey,names);
  Keywords keywords=Keywords.instance(context);
  Assert.checkNonNull(keywords);
  next.put(Keywords.keywordsKey,keywords);
  JavaCompiler oldCompiler=JavaCompiler.instance(context);
  JavaCompiler nextCompiler=JavaCompiler.instance(next);
  nextCompiler.initRound(oldCompiler);
  filer.newRound(next);
  messager.newRound(next);
  elementUtils.setContext(next);
  typeUtils.setContext(next);
  JavacTaskImpl task=context.get(JavacTaskImpl.class);
  if (task != null) {
    next.put(JavacTaskImpl.class,task);
    task.updateContext(next);
  }
  JavacTrees trees=context.get(JavacTrees.class);
  if (trees != null) {
    next.put(JavacTrees.class,trees);
    trees.updateContext(next);
  }
  context.clear();
  return next;
}"
37264,"public Context(){
}","public Context(Context prev){
  kt.putAll(prev.kt);
  ft.putAll(prev.ft);
  ht.putAll(prev.ft);
}"
37265,"public void clear(){
  ht=null;
  kt=null;
}","public void clear(){
  ht=null;
  kt=null;
  ft=null;
}"
37266,T make();,T make(Context c);
37267,"public ClassReader make(){
  return new JavadocClassReader(context);
}","public ClassReader make(Context c){
  return new JavadocClassReader(c);
}"
37268,"public static void preRegister(final Context context){
  context.put(classReaderKey,new Context.Factory<ClassReader>(){
    public ClassReader make(){
      return new JavadocClassReader(context);
    }
  }
);
}","public static void preRegister(Context context){
  context.put(classReaderKey,new Context.Factory<ClassReader>(){
    public ClassReader make(    Context c){
      return new JavadocClassReader(c);
    }
  }
);
}"
37269,"public Enter make(){
  return new JavadocEnter(context);
}","public Enter make(Context c){
  return new JavadocEnter(c);
}"
37270,"public static void preRegister(final Context context){
  context.put(enterKey,new Context.Factory<Enter>(){
    public Enter make(){
      return new JavadocEnter(context);
    }
  }
);
}","public static void preRegister(Context context){
  context.put(enterKey,new Context.Factory<Enter>(){
    public Enter make(    Context c){
      return new JavadocEnter(c);
    }
  }
);
}"
37271,"public MemberEnter make(){
  return new JavadocMemberEnter(context);
}","public MemberEnter make(Context c){
  return new JavadocMemberEnter(c);
}"
37272,"public static void preRegister(final Context context){
  context.put(memberEnterKey,new Context.Factory<MemberEnter>(){
    public MemberEnter make(){
      return new JavadocMemberEnter(context);
    }
  }
);
}","public static void preRegister(Context context){
  context.put(memberEnterKey,new Context.Factory<MemberEnter>(){
    public MemberEnter make(    Context c){
      return new JavadocMemberEnter(c);
    }
  }
);
}"
37273,"public Todo make(){
  return new JavadocTodo(context);
}","public Todo make(Context c){
  return new JavadocTodo(c);
}"
37274,"public static void preRegister(final Context context){
  context.put(todoKey,new Context.Factory<Todo>(){
    public Todo make(){
      return new JavadocTodo(context);
    }
  }
);
}","public static void preRegister(Context context){
  context.put(todoKey,new Context.Factory<Todo>(){
    public Todo make(    Context c){
      return new JavadocTodo(c);
    }
  }
);
}"
37275,"public Log make(){
  return new Messager(context,programName,errWriter,warnWriter,noticeWriter);
}","public Log make(Context c){
  return new Messager(c,programName,errWriter,warnWriter,noticeWriter);
}"
37276,"public static void preRegister(final Context context,final String programName,final PrintWriter errWriter,final PrintWriter warnWriter,final PrintWriter noticeWriter){
  context.put(logKey,new Context.Factory<Log>(){
    public Log make(){
      return new Messager(context,programName,errWriter,warnWriter,noticeWriter);
    }
  }
);
}","public static void preRegister(Context context,final String programName,final PrintWriter errWriter,final PrintWriter warnWriter,final PrintWriter noticeWriter){
  context.put(logKey,new Context.Factory<Log>(){
    public Log make(    Context c){
      return new Messager(c,programName,errWriter,warnWriter,noticeWriter);
    }
  }
);
}"
37277,"public JavacMessages make(){
  return new ArgTypeMessages(c){
    @Override public String getLocalizedString(    Locale l,    String key,    Object... args){
      return getKeyArgsString(key,args);
    }
  }
;
}","public JavacMessages make(Context c){
  return new ArgTypeMessages(c){
    @Override public String getLocalizedString(    Locale l,    String key,    Object... args){
      return getKeyArgsString(key,args);
    }
  }
;
}"
37278,"static void preRegister(final Context c){
  c.put(JavacMessages.messagesKey,new Context.Factory<JavacMessages>(){
    public JavacMessages make(){
      return new ArgTypeMessages(c){
        @Override public String getLocalizedString(        Locale l,        String key,        Object... args){
          return getKeyArgsString(key,args);
        }
      }
;
    }
  }
);
}","static void preRegister(Context context){
  context.put(JavacMessages.messagesKey,new Context.Factory<JavacMessages>(){
    public JavacMessages make(    Context c){
      return new ArgTypeMessages(c){
        @Override public String getLocalizedString(        Locale l,        String key,        Object... args){
          return getKeyArgsString(key,args);
        }
      }
;
    }
  }
);
}"
37279,"public JavacMessages make(){
  return new MessageTracker(c){
    @Override public String getLocalizedString(    Locale l,    String key,    Object... args){
      keys.add(key);
      return super.getLocalizedString(l,key,args);
    }
  }
;
}","public JavacMessages make(Context c){
  return new MessageTracker(c){
    @Override public String getLocalizedString(    Locale l,    String key,    Object... args){
      keys.add(key);
      return super.getLocalizedString(l,key,args);
    }
  }
;
}"
37280,"static void preRegister(final Context c,final Set<String> keys){
  if (keys != null) {
    c.put(JavacMessages.messagesKey,new Context.Factory<JavacMessages>(){
      public JavacMessages make(){
        return new MessageTracker(c){
          @Override public String getLocalizedString(          Locale l,          String key,          Object... args){
            keys.add(key);
            return super.getLocalizedString(l,key,args);
          }
        }
;
      }
    }
);
  }
}","static void preRegister(Context c,final Set<String> keys){
  if (keys != null) {
    c.put(JavacMessages.messagesKey,new Context.Factory<JavacMessages>(){
      public JavacMessages make(      Context c){
        return new MessageTracker(c){
          @Override public String getLocalizedString(          Locale l,          String key,          Object... args){
            keys.add(key);
            return super.getLocalizedString(l,key,args);
          }
        }
;
      }
    }
);
  }
}"
37281,"public Log make(){
  return Bark.instance(context);
}","public Log make(Context c){
  return Bark.instance(c);
}"
37282,"/** 
 * Preregisters factories to create and use a Bark object for use as both a Log and a Bark.
 */
public static void preRegister(final Context context){
  context.put(barkKey,new Context.Factory<Bark>(){
    public Bark make(){
      return new Bark(context);
    }
  }
);
  context.put(Log.logKey,new Context.Factory<Log>(){
    public Log make(){
      return Bark.instance(context);
    }
  }
);
}","/** 
 * Preregisters factories to create and use a Bark object for use as both a Log and a Bark.
 */
public static void preRegister(Context context){
  context.put(barkKey,new Context.Factory<Bark>(){
    public Bark make(    Context c){
      return new Bark(c);
    }
  }
);
  context.put(Log.logKey,new Context.Factory<Log>(){
    public Log make(    Context c){
      return Bark.instance(c);
    }
  }
);
}"
37283,"/** 
 * Register that a compilation is about to start.
 */
void beginContext(final Context context){
  if (compilationInProgress)   throw new IllegalStateException(""String_Node_Str"");
  compilationInProgress=true;
  final JavaFileManager givenFileManager=context.get(JavaFileManager.class);
  context.put(JavaFileManager.class,(JavaFileManager)null);
  context.put(JavaFileManager.class,new Context.Factory<JavaFileManager>(){
    public JavaFileManager make(){
      if (givenFileManager != null) {
        context.put(JavaFileManager.class,givenFileManager);
        return givenFileManager;
      }
 else {
        return new JavacFileManager(context,true,null);
      }
    }
  }
);
}","/** 
 * Register that a compilation is about to start.
 */
void beginContext(Context context){
  if (compilationInProgress)   throw new IllegalStateException(""String_Node_Str"");
  compilationInProgress=true;
  final JavaFileManager givenFileManager=context.get(JavaFileManager.class);
  context.put(JavaFileManager.class,(JavaFileManager)null);
  context.put(JavaFileManager.class,new Context.Factory<JavaFileManager>(){
    public JavaFileManager make(    Context c){
      if (givenFileManager != null) {
        c.put(JavaFileManager.class,givenFileManager);
        return givenFileManager;
      }
 else {
        return new JavacFileManager(c,true,null);
      }
    }
  }
);
}"
37284,"public JavaFileManager make(){
  if (givenFileManager != null) {
    context.put(JavaFileManager.class,givenFileManager);
    return givenFileManager;
  }
 else {
    return new JavacFileManager(context,true,null);
  }
}","public JavaFileManager make(Context c){
  if (givenFileManager != null) {
    c.put(JavaFileManager.class,givenFileManager);
    return givenFileManager;
  }
 else {
    return new JavacFileManager(c,true,null);
  }
}"
37285,"public FSInfo make(){
  FSInfo instance=new CacheFSInfo();
  context.put(FSInfo.class,instance);
  return instance;
}","public FSInfo make(Context c){
  FSInfo instance=new CacheFSInfo();
  c.put(FSInfo.class,instance);
  return instance;
}"
37286,"/** 
 * Register a Context.Factory to create a singleton CacheFSInfo.
 */
public static void preRegister(final Context context){
  context.put(FSInfo.class,new Context.Factory<FSInfo>(){
    public FSInfo make(){
      FSInfo instance=new CacheFSInfo();
      context.put(FSInfo.class,instance);
      return instance;
    }
  }
);
}","/** 
 * Register a Context.Factory to create a CacheFSInfo.
 */
public static void preRegister(Context context){
  context.put(FSInfo.class,new Context.Factory<FSInfo>(){
    public FSInfo make(    Context c){
      FSInfo instance=new CacheFSInfo();
      c.put(FSInfo.class,instance);
      return instance;
    }
  }
);
}"
37287,"/** 
 * Register a Context.Factory to create a JavacFileManager.
 */
public static void preRegister(final Context context){
  context.put(JavaFileManager.class,new Context.Factory<JavaFileManager>(){
    public JavaFileManager make(){
      return new JavacFileManager(context,true,null);
    }
  }
);
}","/** 
 * Register a Context.Factory to create a JavacFileManager.
 */
public static void preRegister(Context context){
  context.put(JavaFileManager.class,new Context.Factory<JavaFileManager>(){
    public JavaFileManager make(    Context c){
      return new JavacFileManager(c,true,null);
    }
  }
);
}"
37288,"public JavaFileManager make(){
  return new JavacFileManager(context,true,null);
}","public JavaFileManager make(Context c){
  return new JavacFileManager(c,true,null);
}"
37289,"/** 
 * Construct a new compiler using a shared context.
 */
public JavaCompiler(final Context context){
  this.context=context;
  context.put(compilerKey,this);
  if (context.get(JavaFileManager.class) == null)   JavacFileManager.preRegister(context);
  names=Names.instance(context);
  log=Log.instance(context);
  diagFactory=JCDiagnostic.Factory.instance(context);
  reader=ClassReader.instance(context);
  make=TreeMaker.instance(context);
  writer=ClassWriter.instance(context);
  enter=Enter.instance(context);
  todo=Todo.instance(context);
  fileManager=context.get(JavaFileManager.class);
  parserFactory=ParserFactory.instance(context);
  try {
    syms=Symtab.instance(context);
  }
 catch (  CompletionFailure ex) {
    log.error(""String_Node_Str"",ex.sym,ex.getDetailValue());
    if (ex instanceof ClassReader.BadClassFile)     throw new Abort();
  }
  source=Source.instance(context);
  attr=Attr.instance(context);
  chk=Check.instance(context);
  gen=Gen.instance(context);
  flow=Flow.instance(context);
  transTypes=TransTypes.instance(context);
  lower=Lower.instance(context);
  annotate=Annotate.instance(context);
  types=Types.instance(context);
  taskListener=context.get(TaskListener.class);
  reader.sourceCompleter=this;
  Options options=Options.instance(context);
  verbose=options.isSet(VERBOSE);
  sourceOutput=options.isSet(PRINTSOURCE);
  stubOutput=options.isSet(""String_Node_Str"");
  relax=options.isSet(""String_Node_Str"");
  printFlat=options.isSet(""String_Node_Str"");
  attrParseOnly=options.isSet(""String_Node_Str"");
  encoding=options.get(ENCODING);
  lineDebugInfo=options.isUnset(G_CUSTOM) || options.isSet(G_CUSTOM,""String_Node_Str"");
  genEndPos=options.isSet(XJCOV) || context.get(DiagnosticListener.class) != null;
  devVerbose=options.isSet(""String_Node_Str"");
  processPcks=options.isSet(""String_Node_Str"");
  werror=options.isSet(WERROR);
  if (source.compareTo(Source.DEFAULT) < 0) {
    if (options.isUnset(XLINT_CUSTOM,""String_Node_Str"" + LintCategory.OPTIONS.option)) {
      if (fileManager instanceof BaseFileManager) {
        if (((BaseFileManager)fileManager).isDefaultBootClassPath())         log.warning(LintCategory.OPTIONS,""String_Node_Str"",source.name);
      }
    }
  }
  verboseCompilePolicy=options.isSet(""String_Node_Str"");
  if (attrParseOnly)   compilePolicy=CompilePolicy.ATTR_ONLY;
 else   compilePolicy=CompilePolicy.decode(options.get(""String_Node_Str""));
  implicitSourcePolicy=ImplicitSourcePolicy.decode(options.get(""String_Node_Str""));
  completionFailureName=options.isSet(""String_Node_Str"") ? names.fromString(options.get(""String_Node_Str"")) : null;
  shouldStopPolicy=options.isSet(""String_Node_Str"") ? CompileState.valueOf(options.get(""String_Node_Str"")) : null;
  if (options.isUnset(""String_Node_Str""))   log.setDiagnosticFormatter(RichDiagnosticFormatter.instance(context));
}","/** 
 * Construct a new compiler using a shared context.
 */
public JavaCompiler(Context context){
  this.context=context;
  context.put(compilerKey,this);
  if (context.get(JavaFileManager.class) == null)   JavacFileManager.preRegister(context);
  names=Names.instance(context);
  log=Log.instance(context);
  diagFactory=JCDiagnostic.Factory.instance(context);
  reader=ClassReader.instance(context);
  make=TreeMaker.instance(context);
  writer=ClassWriter.instance(context);
  enter=Enter.instance(context);
  todo=Todo.instance(context);
  fileManager=context.get(JavaFileManager.class);
  parserFactory=ParserFactory.instance(context);
  try {
    syms=Symtab.instance(context);
  }
 catch (  CompletionFailure ex) {
    log.error(""String_Node_Str"",ex.sym,ex.getDetailValue());
    if (ex instanceof ClassReader.BadClassFile)     throw new Abort();
  }
  source=Source.instance(context);
  attr=Attr.instance(context);
  chk=Check.instance(context);
  gen=Gen.instance(context);
  flow=Flow.instance(context);
  transTypes=TransTypes.instance(context);
  lower=Lower.instance(context);
  annotate=Annotate.instance(context);
  types=Types.instance(context);
  taskListener=context.get(TaskListener.class);
  reader.sourceCompleter=this;
  Options options=Options.instance(context);
  verbose=options.isSet(VERBOSE);
  sourceOutput=options.isSet(PRINTSOURCE);
  stubOutput=options.isSet(""String_Node_Str"");
  relax=options.isSet(""String_Node_Str"");
  printFlat=options.isSet(""String_Node_Str"");
  attrParseOnly=options.isSet(""String_Node_Str"");
  encoding=options.get(ENCODING);
  lineDebugInfo=options.isUnset(G_CUSTOM) || options.isSet(G_CUSTOM,""String_Node_Str"");
  genEndPos=options.isSet(XJCOV) || context.get(DiagnosticListener.class) != null;
  devVerbose=options.isSet(""String_Node_Str"");
  processPcks=options.isSet(""String_Node_Str"");
  werror=options.isSet(WERROR);
  if (source.compareTo(Source.DEFAULT) < 0) {
    if (options.isUnset(XLINT_CUSTOM,""String_Node_Str"" + LintCategory.OPTIONS.option)) {
      if (fileManager instanceof BaseFileManager) {
        if (((BaseFileManager)fileManager).isDefaultBootClassPath())         log.warning(LintCategory.OPTIONS,""String_Node_Str"",source.name);
      }
    }
  }
  verboseCompilePolicy=options.isSet(""String_Node_Str"");
  if (attrParseOnly)   compilePolicy=CompilePolicy.ATTR_ONLY;
 else   compilePolicy=CompilePolicy.decode(options.get(""String_Node_Str""));
  implicitSourcePolicy=ImplicitSourcePolicy.decode(options.get(""String_Node_Str""));
  completionFailureName=options.isSet(""String_Node_Str"") ? names.fromString(options.get(""String_Node_Str"")) : null;
  shouldStopPolicy=options.isSet(""String_Node_Str"") ? CompileState.valueOf(options.get(""String_Node_Str"")) : null;
  if (options.isUnset(""String_Node_Str""))   log.setDiagnosticFormatter(RichDiagnosticFormatter.instance(context));
}"
37290,"/** 
 * Get the context for the next round of processing. Important values are propogated from round to round; other values are implicitly reset.
 */
private Context nextContext(){
  Context next=new Context();
  Options options=Options.instance(context);
  Assert.checkNonNull(options);
  next.put(Options.optionsKey,options);
  PrintWriter out=context.get(Log.outKey);
  Assert.checkNonNull(out);
  next.put(Log.outKey,out);
  final boolean shareNames=true;
  if (shareNames) {
    Names names=Names.instance(context);
    Assert.checkNonNull(names);
    next.put(Names.namesKey,names);
  }
  DiagnosticListener<?> dl=context.get(DiagnosticListener.class);
  if (dl != null)   next.put(DiagnosticListener.class,dl);
  TaskListener tl=context.get(TaskListener.class);
  if (tl != null)   next.put(TaskListener.class,tl);
  FSInfo fsInfo=context.get(FSInfo.class);
  if (fsInfo != null)   next.put(FSInfo.class,fsInfo);
  JavaFileManager jfm=context.get(JavaFileManager.class);
  Assert.checkNonNull(jfm);
  next.put(JavaFileManager.class,jfm);
  if (jfm instanceof JavacFileManager) {
    ((JavacFileManager)jfm).setContext(next);
  }
  Names names=Names.instance(context);
  Assert.checkNonNull(names);
  next.put(Names.namesKey,names);
  Keywords keywords=Keywords.instance(context);
  Assert.checkNonNull(keywords);
  next.put(Keywords.keywordsKey,keywords);
  JavaCompiler oldCompiler=JavaCompiler.instance(context);
  JavaCompiler nextCompiler=JavaCompiler.instance(next);
  nextCompiler.initRound(oldCompiler);
  filer.newRound(next);
  messager.newRound(next);
  elementUtils.setContext(next);
  typeUtils.setContext(next);
  JavacTaskImpl task=context.get(JavacTaskImpl.class);
  if (task != null) {
    next.put(JavacTaskImpl.class,task);
    task.updateContext(next);
  }
  JavacTrees trees=context.get(JavacTrees.class);
  if (trees != null) {
    next.put(JavacTrees.class,trees);
    trees.updateContext(next);
  }
  context.clear();
  return next;
}","/** 
 * Get the context for the next round of processing. Important values are propogated from round to round; other values are implicitly reset.
 */
private Context nextContext(){
  Context next=new Context(context);
  Options options=Options.instance(context);
  Assert.checkNonNull(options);
  next.put(Options.optionsKey,options);
  PrintWriter out=context.get(Log.outKey);
  Assert.checkNonNull(out);
  next.put(Log.outKey,out);
  final boolean shareNames=true;
  if (shareNames) {
    Names names=Names.instance(context);
    Assert.checkNonNull(names);
    next.put(Names.namesKey,names);
  }
  DiagnosticListener<?> dl=context.get(DiagnosticListener.class);
  if (dl != null)   next.put(DiagnosticListener.class,dl);
  TaskListener tl=context.get(TaskListener.class);
  if (tl != null)   next.put(TaskListener.class,tl);
  FSInfo fsInfo=context.get(FSInfo.class);
  if (fsInfo != null)   next.put(FSInfo.class,fsInfo);
  JavaFileManager jfm=context.get(JavaFileManager.class);
  Assert.checkNonNull(jfm);
  next.put(JavaFileManager.class,jfm);
  if (jfm instanceof JavacFileManager) {
    ((JavacFileManager)jfm).setContext(next);
  }
  Names names=Names.instance(context);
  Assert.checkNonNull(names);
  next.put(Names.namesKey,names);
  Keywords keywords=Keywords.instance(context);
  Assert.checkNonNull(keywords);
  next.put(Keywords.keywordsKey,keywords);
  JavaCompiler oldCompiler=JavaCompiler.instance(context);
  JavaCompiler nextCompiler=JavaCompiler.instance(next);
  nextCompiler.initRound(oldCompiler);
  filer.newRound(next);
  messager.newRound(next);
  elementUtils.setContext(next);
  typeUtils.setContext(next);
  JavacTaskImpl task=context.get(JavacTaskImpl.class);
  if (task != null) {
    next.put(JavacTaskImpl.class,task);
    task.updateContext(next);
  }
  JavacTrees trees=context.get(JavacTrees.class);
  if (trees != null) {
    next.put(JavacTrees.class,trees);
    trees.updateContext(next);
  }
  context.clear();
  return next;
}"
37291,"public Context(){
}","public Context(Context prev){
  kt.putAll(prev.kt);
  ft.putAll(prev.ft);
  ht.putAll(prev.ft);
}"
37292,"public void clear(){
  ht=null;
  kt=null;
}","public void clear(){
  ht=null;
  kt=null;
  ft=null;
}"
37293,T make();,T make(Context c);
37294,"public ClassReader make(){
  return new JavadocClassReader(context);
}","public ClassReader make(Context c){
  return new JavadocClassReader(c);
}"
37295,"public static void preRegister(final Context context){
  context.put(classReaderKey,new Context.Factory<ClassReader>(){
    public ClassReader make(){
      return new JavadocClassReader(context);
    }
  }
);
}","public static void preRegister(Context context){
  context.put(classReaderKey,new Context.Factory<ClassReader>(){
    public ClassReader make(    Context c){
      return new JavadocClassReader(c);
    }
  }
);
}"
37296,"public Enter make(){
  return new JavadocEnter(context);
}","public Enter make(Context c){
  return new JavadocEnter(c);
}"
37297,"public static void preRegister(final Context context){
  context.put(enterKey,new Context.Factory<Enter>(){
    public Enter make(){
      return new JavadocEnter(context);
    }
  }
);
}","public static void preRegister(Context context){
  context.put(enterKey,new Context.Factory<Enter>(){
    public Enter make(    Context c){
      return new JavadocEnter(c);
    }
  }
);
}"
37298,"public MemberEnter make(){
  return new JavadocMemberEnter(context);
}","public MemberEnter make(Context c){
  return new JavadocMemberEnter(c);
}"
37299,"public static void preRegister(final Context context){
  context.put(memberEnterKey,new Context.Factory<MemberEnter>(){
    public MemberEnter make(){
      return new JavadocMemberEnter(context);
    }
  }
);
}","public static void preRegister(Context context){
  context.put(memberEnterKey,new Context.Factory<MemberEnter>(){
    public MemberEnter make(    Context c){
      return new JavadocMemberEnter(c);
    }
  }
);
}"
37300,"public Todo make(){
  return new JavadocTodo(context);
}","public Todo make(Context c){
  return new JavadocTodo(c);
}"
37301,"public static void preRegister(final Context context){
  context.put(todoKey,new Context.Factory<Todo>(){
    public Todo make(){
      return new JavadocTodo(context);
    }
  }
);
}","public static void preRegister(Context context){
  context.put(todoKey,new Context.Factory<Todo>(){
    public Todo make(    Context c){
      return new JavadocTodo(c);
    }
  }
);
}"
37302,"public Log make(){
  return new Messager(context,programName,errWriter,warnWriter,noticeWriter);
}","public Log make(Context c){
  return new Messager(c,programName,errWriter,warnWriter,noticeWriter);
}"
37303,"public static void preRegister(final Context context,final String programName,final PrintWriter errWriter,final PrintWriter warnWriter,final PrintWriter noticeWriter){
  context.put(logKey,new Context.Factory<Log>(){
    public Log make(){
      return new Messager(context,programName,errWriter,warnWriter,noticeWriter);
    }
  }
);
}","public static void preRegister(Context context,final String programName,final PrintWriter errWriter,final PrintWriter warnWriter,final PrintWriter noticeWriter){
  context.put(logKey,new Context.Factory<Log>(){
    public Log make(    Context c){
      return new Messager(c,programName,errWriter,warnWriter,noticeWriter);
    }
  }
);
}"
37304,"public JavacMessages make(){
  return new ArgTypeMessages(c){
    @Override public String getLocalizedString(    Locale l,    String key,    Object... args){
      return getKeyArgsString(key,args);
    }
  }
;
}","public JavacMessages make(Context c){
  return new ArgTypeMessages(c){
    @Override public String getLocalizedString(    Locale l,    String key,    Object... args){
      return getKeyArgsString(key,args);
    }
  }
;
}"
37305,"static void preRegister(final Context c){
  c.put(JavacMessages.messagesKey,new Context.Factory<JavacMessages>(){
    public JavacMessages make(){
      return new ArgTypeMessages(c){
        @Override public String getLocalizedString(        Locale l,        String key,        Object... args){
          return getKeyArgsString(key,args);
        }
      }
;
    }
  }
);
}","static void preRegister(Context context){
  context.put(JavacMessages.messagesKey,new Context.Factory<JavacMessages>(){
    public JavacMessages make(    Context c){
      return new ArgTypeMessages(c){
        @Override public String getLocalizedString(        Locale l,        String key,        Object... args){
          return getKeyArgsString(key,args);
        }
      }
;
    }
  }
);
}"
37306,"public JavacMessages make(){
  return new MessageTracker(c){
    @Override public String getLocalizedString(    Locale l,    String key,    Object... args){
      keys.add(key);
      return super.getLocalizedString(l,key,args);
    }
  }
;
}","public JavacMessages make(Context c){
  return new MessageTracker(c){
    @Override public String getLocalizedString(    Locale l,    String key,    Object... args){
      keys.add(key);
      return super.getLocalizedString(l,key,args);
    }
  }
;
}"
37307,"static void preRegister(final Context c,final Set<String> keys){
  if (keys != null) {
    c.put(JavacMessages.messagesKey,new Context.Factory<JavacMessages>(){
      public JavacMessages make(){
        return new MessageTracker(c){
          @Override public String getLocalizedString(          Locale l,          String key,          Object... args){
            keys.add(key);
            return super.getLocalizedString(l,key,args);
          }
        }
;
      }
    }
);
  }
}","static void preRegister(Context c,final Set<String> keys){
  if (keys != null) {
    c.put(JavacMessages.messagesKey,new Context.Factory<JavacMessages>(){
      public JavacMessages make(      Context c){
        return new MessageTracker(c){
          @Override public String getLocalizedString(          Locale l,          String key,          Object... args){
            keys.add(key);
            return super.getLocalizedString(l,key,args);
          }
        }
;
      }
    }
);
  }
}"
37308,"public Entry next(){
  Entry e=super.shadowed;
  while (e.scope != null && (e.sym.name != sym.name || e.sym.owner != e.scope.owner))   e=e.shadowed;
  return e;
}","public Entry next(){
  Entry e=super.shadowed;
  while (isBogus())   e=e.shadowed;
  return e;
}"
37309,"protected Scope(Symbol owner,ScopeCounter scopeCounter){
  this(null,owner,new Entry[INITIAL_SIZE],scopeCounter);
  for (int i=0; i < INITIAL_SIZE; i++)   table[i]=sentinel;
}","protected Scope(Symbol owner,ScopeCounter scopeCounter){
  this(null,owner,new Entry[INITIAL_SIZE],scopeCounter);
}"
37310,"public Entry next(){
  Entry e=super.shadowed;
  while (e.scope != null && (e.sym.name != sym.name || e.sym.owner != e.scope.owner))   e=e.shadowed;
  return e;
}","public Entry next(){
  Entry e=super.shadowed;
  while (isBogus())   e=e.shadowed;
  return e;
}"
37311,"protected Scope(Symbol owner,ScopeCounter scopeCounter){
  this(null,owner,new Entry[INITIAL_SIZE],scopeCounter);
  for (int i=0; i < INITIAL_SIZE; i++)   table[i]=sentinel;
}","protected Scope(Symbol owner,ScopeCounter scopeCounter){
  this(null,owner,new Entry[INITIAL_SIZE],scopeCounter);
}"
37312,"protected Scope(Symbol owner,ScopeCounter scopeCounter){
  this(null,owner,new Entry[INITIAL_SIZE],scopeCounter);
}","protected Scope(Symbol owner,ScopeCounter scopeCounter){
  this(null,owner,new Entry[INITIAL_SIZE],scopeCounter);
  for (int i=0; i < INITIAL_SIZE; i++)   table[i]=sentinel;
}"
37313,"protected Scope(Symbol owner,ScopeCounter scopeCounter){
  this(null,owner,new Entry[INITIAL_SIZE],scopeCounter);
}","protected Scope(Symbol owner,ScopeCounter scopeCounter){
  this(null,owner,new Entry[INITIAL_SIZE],scopeCounter);
  for (int i=0; i < INITIAL_SIZE; i++)   table[i]=sentinel;
}"
37314,"@Override public void write(int b) throws IOException {
  size++;
}","@Override public void write(int b){
  size++;
}"
37315,"public int byteLength(){
class SizeOutputStream extends OutputStream {
    @Override public void write(    int b) throws IOException {
      size++;
    }
    int size;
  }
  SizeOutputStream sizeOut=new SizeOutputStream();
  DataOutputStream out=new DataOutputStream(sizeOut);
  try {
    out.writeUTF(value);
  }
 catch (  IOException ignore) {
  }
  return 1 + sizeOut.size;
}","public int byteLength(){
class SizeOutputStream extends OutputStream {
    @Override public void write(    int b){
      size++;
    }
    int size;
  }
  SizeOutputStream sizeOut=new SizeOutputStream();
  DataOutputStream out=new DataOutputStream(sizeOut);
  try {
    out.writeUTF(value);
  }
 catch (  IOException ignore) {
  }
  return 1 + sizeOut.size;
}"
37316,"/** 
 * Constructor
 * @param context      Context for this javadoc instance.
 */
private DocEnv(Context context){
  context.put(docEnvKey,this);
  messager=Messager.instance0(context);
  syms=Symtab.instance(context);
  reader=JavadocClassReader.instance0(context);
  enter=JavadocEnter.instance0(context);
  attr=Attr.instance(context);
  names=Names.instance(context);
  externalizableSym=reader.enterClass(names.fromString(""String_Node_Str""));
  chk=Check.instance(context);
  types=Types.instance(context);
  fileManager=context.get(JavaFileManager.class);
  this.doclocale=new DocLocale(this,""String_Node_Str"",breakiterator);
}","/** 
 * Constructor
 * @param context      Context for this javadoc instance.
 */
private DocEnv(Context context){
  context.put(docEnvKey,this);
  messager=Messager.instance0(context);
  syms=Symtab.instance(context);
  reader=JavadocClassReader.instance0(context);
  enter=JavadocEnter.instance0(context);
  names=Names.instance(context);
  externalizableSym=reader.enterClass(names.fromString(""String_Node_Str""));
  chk=Check.instance(context);
  types=Types.instance(context);
  fileManager=context.get(JavaFileManager.class);
  this.doclocale=new DocLocale(this,""String_Node_Str"",breakiterator);
}"
37317,"@Override public void write(int b) throws IOException {
  size++;
}","@Override public void write(int b){
  size++;
}"
37318,"public int byteLength(){
class SizeOutputStream extends OutputStream {
    @Override public void write(    int b) throws IOException {
      size++;
    }
    int size;
  }
  SizeOutputStream sizeOut=new SizeOutputStream();
  DataOutputStream out=new DataOutputStream(sizeOut);
  try {
    out.writeUTF(value);
  }
 catch (  IOException ignore) {
  }
  return 1 + sizeOut.size;
}","public int byteLength(){
class SizeOutputStream extends OutputStream {
    @Override public void write(    int b){
      size++;
    }
    int size;
  }
  SizeOutputStream sizeOut=new SizeOutputStream();
  DataOutputStream out=new DataOutputStream(sizeOut);
  try {
    out.writeUTF(value);
  }
 catch (  IOException ignore) {
  }
  return 1 + sizeOut.size;
}"
37319,"/** 
 * Constructor
 * @param context      Context for this javadoc instance.
 */
private DocEnv(Context context){
  context.put(docEnvKey,this);
  messager=Messager.instance0(context);
  syms=Symtab.instance(context);
  reader=JavadocClassReader.instance0(context);
  enter=JavadocEnter.instance0(context);
  attr=Attr.instance(context);
  names=Names.instance(context);
  externalizableSym=reader.enterClass(names.fromString(""String_Node_Str""));
  chk=Check.instance(context);
  types=Types.instance(context);
  fileManager=context.get(JavaFileManager.class);
  this.doclocale=new DocLocale(this,""String_Node_Str"",breakiterator);
}","/** 
 * Constructor
 * @param context      Context for this javadoc instance.
 */
private DocEnv(Context context){
  context.put(docEnvKey,this);
  messager=Messager.instance0(context);
  syms=Symtab.instance(context);
  reader=JavadocClassReader.instance0(context);
  enter=JavadocEnter.instance0(context);
  names=Names.instance(context);
  externalizableSym=reader.enterClass(names.fromString(""String_Node_Str""));
  chk=Check.instance(context);
  types=Types.instance(context);
  fileManager=context.get(JavaFileManager.class);
  this.doclocale=new DocLocale(this,""String_Node_Str"",breakiterator);
}"
37320,"/** 
 * Default class enter visitor method: do nothing.
 */
public void visitTree(JCTree tree){
  result=null;
}","/** 
 * Default class enter visitor method: do nothing.
 */
@Override public void visitTree(JCTree tree){
  result=null;
}"
37321,"public void visitClassDef(JCClassDecl tree){
  Symbol owner=env.info.scope.owner;
  Scope enclScope=enterScope(env);
  ClassSymbol c;
  if (owner.kind == PCK) {
    PackageSymbol packge=(PackageSymbol)owner;
    for (Symbol q=packge; q != null && q.kind == PCK; q=q.owner)     q.flags_field|=EXISTS;
    c=reader.enterClass(tree.name,packge);
    packge.members().enterIfAbsent(c);
    if ((tree.mods.flags & PUBLIC) != 0 && !classNameMatchesFileName(c,env)) {
      log.error(tree.pos(),""String_Node_Str"",tree.name);
    }
  }
 else {
    if (!tree.name.isEmpty() && !chk.checkUniqueClassName(tree.pos(),tree.name,enclScope)) {
      result=null;
      return;
    }
    if (owner.kind == TYP) {
      c=reader.enterClass(tree.name,(TypeSymbol)owner);
      if ((owner.flags_field & INTERFACE) != 0) {
        tree.mods.flags|=PUBLIC | STATIC;
      }
    }
 else {
      c=reader.defineClass(tree.name,owner);
      c.flatname=chk.localClassName(c);
      if (!c.name.isEmpty())       chk.checkTransparentClass(tree.pos(),c,env.info.scope);
    }
  }
  tree.sym=c;
  if (chk.compiled.get(c.flatname) != null) {
    duplicateClass(tree.pos(),c);
    result=types.createErrorType(tree.name,(TypeSymbol)owner,Type.noType);
    tree.sym=(ClassSymbol)result.tsym;
    return;
  }
  chk.compiled.put(c.flatname,c);
  enclScope.enter(c);
  Env<AttrContext> localEnv=classEnv(tree,env);
  typeEnvs.put(c,localEnv);
  c.completer=memberEnter;
  c.flags_field=chk.checkFlags(tree.pos(),tree.mods.flags,c,tree);
  c.sourcefile=env.toplevel.sourcefile;
  c.members_field=new Scope(c);
  ClassType ct=(ClassType)c.type;
  if (owner.kind != PCK && (c.flags_field & STATIC) == 0) {
    Symbol owner1=owner;
    while ((owner1.kind & (VAR | MTH)) != 0 && (owner1.flags_field & STATIC) == 0) {
      owner1=owner1.owner;
    }
    if (owner1.kind == TYP) {
      ct.setEnclosingType(owner1.type);
    }
  }
  ct.typarams_field=classEnter(tree.typarams,localEnv);
  if (!c.isLocal() && uncompleted != null)   uncompleted.append(c);
  classEnter(tree.defs,localEnv);
  result=c.type;
}","@Override public void visitClassDef(JCClassDecl tree){
  Symbol owner=env.info.scope.owner;
  Scope enclScope=enterScope(env);
  ClassSymbol c;
  if (owner.kind == PCK) {
    PackageSymbol packge=(PackageSymbol)owner;
    for (Symbol q=packge; q != null && q.kind == PCK; q=q.owner)     q.flags_field|=EXISTS;
    c=reader.enterClass(tree.name,packge);
    packge.members().enterIfAbsent(c);
    if ((tree.mods.flags & PUBLIC) != 0 && !classNameMatchesFileName(c,env)) {
      log.error(tree.pos(),""String_Node_Str"",tree.name);
    }
  }
 else {
    if (!tree.name.isEmpty() && !chk.checkUniqueClassName(tree.pos(),tree.name,enclScope)) {
      result=null;
      return;
    }
    if (owner.kind == TYP) {
      c=reader.enterClass(tree.name,(TypeSymbol)owner);
      if ((owner.flags_field & INTERFACE) != 0) {
        tree.mods.flags|=PUBLIC | STATIC;
      }
    }
 else {
      c=reader.defineClass(tree.name,owner);
      c.flatname=chk.localClassName(c);
      if (!c.name.isEmpty())       chk.checkTransparentClass(tree.pos(),c,env.info.scope);
    }
  }
  tree.sym=c;
  if (chk.compiled.get(c.flatname) != null) {
    duplicateClass(tree.pos(),c);
    result=types.createErrorType(tree.name,(TypeSymbol)owner,Type.noType);
    tree.sym=(ClassSymbol)result.tsym;
    return;
  }
  chk.compiled.put(c.flatname,c);
  enclScope.enter(c);
  Env<AttrContext> localEnv=classEnv(tree,env);
  typeEnvs.put(c,localEnv);
  c.completer=memberEnter;
  c.flags_field=chk.checkFlags(tree.pos(),tree.mods.flags,c,tree);
  c.sourcefile=env.toplevel.sourcefile;
  c.members_field=new Scope(c);
  ClassType ct=(ClassType)c.type;
  if (owner.kind != PCK && (c.flags_field & STATIC) == 0) {
    Symbol owner1=owner;
    while ((owner1.kind & (VAR | MTH)) != 0 && (owner1.flags_field & STATIC) == 0) {
      owner1=owner1.owner;
    }
    if (owner1.kind == TYP) {
      ct.setEnclosingType(owner1.type);
    }
  }
  ct.typarams_field=classEnter(tree.typarams,localEnv);
  if (!c.isLocal() && uncompleted != null)   uncompleted.append(c);
  classEnter(tree.defs,localEnv);
  result=c.type;
}"
37322,"public void visitTopLevel(JCCompilationUnit tree){
  JavaFileObject prev=log.useSource(tree.sourcefile);
  boolean addEnv=false;
  boolean isPkgInfo=tree.sourcefile.isNameCompatible(""String_Node_Str"",JavaFileObject.Kind.SOURCE);
  if (tree.pid != null) {
    tree.packge=reader.enterPackage(TreeInfo.fullName(tree.pid));
    if (tree.packageAnnotations.nonEmpty()) {
      if (isPkgInfo) {
        addEnv=true;
      }
 else {
        log.error(tree.packageAnnotations.head.pos(),""String_Node_Str"");
      }
    }
  }
 else {
    tree.packge=syms.unnamedPackage;
  }
  tree.packge.complete();
  Env<AttrContext> env=topLevelEnv(tree);
  if (isPkgInfo) {
    Env<AttrContext> env0=typeEnvs.get(tree.packge);
    if (env0 == null) {
      typeEnvs.put(tree.packge,env);
    }
 else {
      JCCompilationUnit tree0=env0.toplevel;
      if (!fileManager.isSameFile(tree.sourcefile,tree0.sourcefile)) {
        log.warning(tree.pid != null ? tree.pid.pos() : null,""String_Node_Str"",tree.packge);
        if (addEnv || (tree0.packageAnnotations.isEmpty() && tree.docComments != null && tree.docComments.get(tree) != null)) {
          typeEnvs.put(tree.packge,env);
        }
      }
    }
    for (Symbol q=tree.packge; q != null && q.kind == PCK; q=q.owner)     q.flags_field|=EXISTS;
    Name name=names.package_info;
    ClassSymbol c=reader.enterClass(name,tree.packge);
    c.flatname=names.fromString(tree.packge + ""String_Node_Str"" + name);
    c.sourcefile=tree.sourcefile;
    c.completer=null;
    c.members_field=new Scope(c);
    tree.packge.package_info=c;
  }
  classEnter(tree.defs,env);
  if (addEnv) {
    todo.append(env);
  }
  log.useSource(prev);
  result=null;
}","@Override public void visitTopLevel(JCCompilationUnit tree){
  JavaFileObject prev=log.useSource(tree.sourcefile);
  boolean addEnv=false;
  boolean isPkgInfo=tree.sourcefile.isNameCompatible(""String_Node_Str"",JavaFileObject.Kind.SOURCE);
  if (tree.pid != null) {
    tree.packge=reader.enterPackage(TreeInfo.fullName(tree.pid));
    if (tree.packageAnnotations.nonEmpty()) {
      if (isPkgInfo) {
        addEnv=true;
      }
 else {
        log.error(tree.packageAnnotations.head.pos(),""String_Node_Str"");
      }
    }
  }
 else {
    tree.packge=syms.unnamedPackage;
  }
  tree.packge.complete();
  Env<AttrContext> topEnv=topLevelEnv(tree);
  if (isPkgInfo) {
    Env<AttrContext> env0=typeEnvs.get(tree.packge);
    if (env0 == null) {
      typeEnvs.put(tree.packge,topEnv);
    }
 else {
      JCCompilationUnit tree0=env0.toplevel;
      if (!fileManager.isSameFile(tree.sourcefile,tree0.sourcefile)) {
        log.warning(tree.pid != null ? tree.pid.pos() : null,""String_Node_Str"",tree.packge);
        if (addEnv || (tree0.packageAnnotations.isEmpty() && tree.docComments != null && tree.docComments.get(tree) != null)) {
          typeEnvs.put(tree.packge,topEnv);
        }
      }
    }
    for (Symbol q=tree.packge; q != null && q.kind == PCK; q=q.owner)     q.flags_field|=EXISTS;
    Name name=names.package_info;
    ClassSymbol c=reader.enterClass(name,tree.packge);
    c.flatname=names.fromString(tree.packge + ""String_Node_Str"" + name);
    c.sourcefile=tree.sourcefile;
    c.completer=null;
    c.members_field=new Scope(c);
    tree.packge.package_info=c;
  }
  classEnter(tree.defs,topEnv);
  if (addEnv) {
    todo.append(topEnv);
  }
  log.useSource(prev);
  result=null;
}"
37323,"/** 
 * Class enter visitor method for type parameters. Enter a symbol for type parameter in local scope, after checking that it is unique.
 */
public void visitTypeParameter(JCTypeParameter tree){
  TypeVar a=(tree.type != null) ? (TypeVar)tree.type : new TypeVar(tree.name,env.info.scope.owner,syms.botType);
  tree.type=a;
  if (chk.checkUnique(tree.pos(),a.tsym,env.info.scope)) {
    env.info.scope.enter(a.tsym);
  }
  result=a;
}","/** 
 * Class enter visitor method for type parameters. Enter a symbol for type parameter in local scope, after checking that it is unique.
 */
@Override public void visitTypeParameter(JCTypeParameter tree){
  TypeVar a=(tree.type != null) ? (TypeVar)tree.type : new TypeVar(tree.name,env.info.scope.owner,syms.botType);
  tree.type=a;
  if (chk.checkUnique(tree.pos(),a.tsym,env.info.scope)) {
    env.info.scope.enter(a.tsym);
  }
  result=a;
}"
37324,"/** 
 * Main method: enter one class from a list of toplevel trees and place the rest on uncompleted for later processing.
 * @param trees      The list of trees to be processed.
 * @param c          The class symbol to be processed.
 */
public void complete(List<JCCompilationUnit> trees,ClassSymbol c){
  annotate.enterStart();
  ListBuffer<ClassSymbol> prevUncompleted=uncompleted;
  if (memberEnter.completionEnabled)   uncompleted=new ListBuffer<ClassSymbol>();
  try {
    classEnter(trees,null);
    if (memberEnter.completionEnabled) {
      while (uncompleted.nonEmpty()) {
        ClassSymbol clazz=uncompleted.next();
        if (c == null || c == clazz || prevUncompleted == null)         clazz.complete();
 else         prevUncompleted.append(clazz);
      }
      for (      JCCompilationUnit tree : trees) {
        if (tree.starImportScope.elems == null) {
          JavaFileObject prev=log.useSource(tree.sourcefile);
          Env<AttrContext> env=typeEnvs.get(tree);
          if (env == null)           env=topLevelEnv(tree);
          memberEnter.memberEnter(tree,env);
          log.useSource(prev);
        }
      }
    }
  }
  finally {
    uncompleted=prevUncompleted;
    annotate.enterDone();
  }
}","/** 
 * Main method: enter one class from a list of toplevel trees and place the rest on uncompleted for later processing.
 * @param trees      The list of trees to be processed.
 * @param c          The class symbol to be processed.
 */
public void complete(List<JCCompilationUnit> trees,ClassSymbol c){
  annotate.enterStart();
  ListBuffer<ClassSymbol> prevUncompleted=uncompleted;
  if (memberEnter.completionEnabled)   uncompleted=new ListBuffer<ClassSymbol>();
  try {
    classEnter(trees,null);
    if (memberEnter.completionEnabled) {
      while (uncompleted.nonEmpty()) {
        ClassSymbol clazz=uncompleted.next();
        if (c == null || c == clazz || prevUncompleted == null)         clazz.complete();
 else         prevUncompleted.append(clazz);
      }
      for (      JCCompilationUnit tree : trees) {
        if (tree.starImportScope.elems == null) {
          JavaFileObject prev=log.useSource(tree.sourcefile);
          Env<AttrContext> topEnv=topLevelEnv(tree);
          memberEnter.memberEnter(tree,topEnv);
          log.useSource(prev);
        }
      }
    }
  }
  finally {
    uncompleted=prevUncompleted;
    annotate.enterDone();
  }
}"
37325,"public void visitNewArray(JCNewArray tree){
  tree.elemtype=translate(tree.elemtype,null);
  translate(tree.dims,syms.intType);
  tree.elems=translate(tree.elems,(tree.type == null) ? null : erasure(types.elemtype(tree.type)));
  tree.type=erasure(tree.type);
  result=tree;
}","public void visitNewArray(JCNewArray tree){
  tree.elemtype=translate(tree.elemtype,null);
  translate(tree.dims,syms.intType);
  if (tree.type != null) {
    tree.elems=translate(tree.elems,erasure(types.elemtype(tree.type)));
    tree.type=erasure(tree.type);
  }
 else {
    tree.elems=translate(tree.elems,null);
  }
  result=tree;
}"
37326,"/** 
 * Default class enter visitor method: do nothing.
 */
public void visitTree(JCTree tree){
  result=null;
}","/** 
 * Default class enter visitor method: do nothing.
 */
@Override public void visitTree(JCTree tree){
  result=null;
}"
37327,"public void visitClassDef(JCClassDecl tree){
  Symbol owner=env.info.scope.owner;
  Scope enclScope=enterScope(env);
  ClassSymbol c;
  if (owner.kind == PCK) {
    PackageSymbol packge=(PackageSymbol)owner;
    for (Symbol q=packge; q != null && q.kind == PCK; q=q.owner)     q.flags_field|=EXISTS;
    c=reader.enterClass(tree.name,packge);
    packge.members().enterIfAbsent(c);
    if ((tree.mods.flags & PUBLIC) != 0 && !classNameMatchesFileName(c,env)) {
      log.error(tree.pos(),""String_Node_Str"",tree.name);
    }
  }
 else {
    if (!tree.name.isEmpty() && !chk.checkUniqueClassName(tree.pos(),tree.name,enclScope)) {
      result=null;
      return;
    }
    if (owner.kind == TYP) {
      c=reader.enterClass(tree.name,(TypeSymbol)owner);
      if ((owner.flags_field & INTERFACE) != 0) {
        tree.mods.flags|=PUBLIC | STATIC;
      }
    }
 else {
      c=reader.defineClass(tree.name,owner);
      c.flatname=chk.localClassName(c);
      if (!c.name.isEmpty())       chk.checkTransparentClass(tree.pos(),c,env.info.scope);
    }
  }
  tree.sym=c;
  if (chk.compiled.get(c.flatname) != null) {
    duplicateClass(tree.pos(),c);
    result=types.createErrorType(tree.name,(TypeSymbol)owner,Type.noType);
    tree.sym=(ClassSymbol)result.tsym;
    return;
  }
  chk.compiled.put(c.flatname,c);
  enclScope.enter(c);
  Env<AttrContext> localEnv=classEnv(tree,env);
  typeEnvs.put(c,localEnv);
  c.completer=memberEnter;
  c.flags_field=chk.checkFlags(tree.pos(),tree.mods.flags,c,tree);
  c.sourcefile=env.toplevel.sourcefile;
  c.members_field=new Scope(c);
  ClassType ct=(ClassType)c.type;
  if (owner.kind != PCK && (c.flags_field & STATIC) == 0) {
    Symbol owner1=owner;
    while ((owner1.kind & (VAR | MTH)) != 0 && (owner1.flags_field & STATIC) == 0) {
      owner1=owner1.owner;
    }
    if (owner1.kind == TYP) {
      ct.setEnclosingType(owner1.type);
    }
  }
  ct.typarams_field=classEnter(tree.typarams,localEnv);
  if (!c.isLocal() && uncompleted != null)   uncompleted.append(c);
  classEnter(tree.defs,localEnv);
  result=c.type;
}","@Override public void visitClassDef(JCClassDecl tree){
  Symbol owner=env.info.scope.owner;
  Scope enclScope=enterScope(env);
  ClassSymbol c;
  if (owner.kind == PCK) {
    PackageSymbol packge=(PackageSymbol)owner;
    for (Symbol q=packge; q != null && q.kind == PCK; q=q.owner)     q.flags_field|=EXISTS;
    c=reader.enterClass(tree.name,packge);
    packge.members().enterIfAbsent(c);
    if ((tree.mods.flags & PUBLIC) != 0 && !classNameMatchesFileName(c,env)) {
      log.error(tree.pos(),""String_Node_Str"",tree.name);
    }
  }
 else {
    if (!tree.name.isEmpty() && !chk.checkUniqueClassName(tree.pos(),tree.name,enclScope)) {
      result=null;
      return;
    }
    if (owner.kind == TYP) {
      c=reader.enterClass(tree.name,(TypeSymbol)owner);
      if ((owner.flags_field & INTERFACE) != 0) {
        tree.mods.flags|=PUBLIC | STATIC;
      }
    }
 else {
      c=reader.defineClass(tree.name,owner);
      c.flatname=chk.localClassName(c);
      if (!c.name.isEmpty())       chk.checkTransparentClass(tree.pos(),c,env.info.scope);
    }
  }
  tree.sym=c;
  if (chk.compiled.get(c.flatname) != null) {
    duplicateClass(tree.pos(),c);
    result=types.createErrorType(tree.name,(TypeSymbol)owner,Type.noType);
    tree.sym=(ClassSymbol)result.tsym;
    return;
  }
  chk.compiled.put(c.flatname,c);
  enclScope.enter(c);
  Env<AttrContext> localEnv=classEnv(tree,env);
  typeEnvs.put(c,localEnv);
  c.completer=memberEnter;
  c.flags_field=chk.checkFlags(tree.pos(),tree.mods.flags,c,tree);
  c.sourcefile=env.toplevel.sourcefile;
  c.members_field=new Scope(c);
  ClassType ct=(ClassType)c.type;
  if (owner.kind != PCK && (c.flags_field & STATIC) == 0) {
    Symbol owner1=owner;
    while ((owner1.kind & (VAR | MTH)) != 0 && (owner1.flags_field & STATIC) == 0) {
      owner1=owner1.owner;
    }
    if (owner1.kind == TYP) {
      ct.setEnclosingType(owner1.type);
    }
  }
  ct.typarams_field=classEnter(tree.typarams,localEnv);
  if (!c.isLocal() && uncompleted != null)   uncompleted.append(c);
  classEnter(tree.defs,localEnv);
  result=c.type;
}"
37328,"public void visitTopLevel(JCCompilationUnit tree){
  JavaFileObject prev=log.useSource(tree.sourcefile);
  boolean addEnv=false;
  boolean isPkgInfo=tree.sourcefile.isNameCompatible(""String_Node_Str"",JavaFileObject.Kind.SOURCE);
  if (tree.pid != null) {
    tree.packge=reader.enterPackage(TreeInfo.fullName(tree.pid));
    if (tree.packageAnnotations.nonEmpty()) {
      if (isPkgInfo) {
        addEnv=true;
      }
 else {
        log.error(tree.packageAnnotations.head.pos(),""String_Node_Str"");
      }
    }
  }
 else {
    tree.packge=syms.unnamedPackage;
  }
  tree.packge.complete();
  Env<AttrContext> env=topLevelEnv(tree);
  if (isPkgInfo) {
    Env<AttrContext> env0=typeEnvs.get(tree.packge);
    if (env0 == null) {
      typeEnvs.put(tree.packge,env);
    }
 else {
      JCCompilationUnit tree0=env0.toplevel;
      if (!fileManager.isSameFile(tree.sourcefile,tree0.sourcefile)) {
        log.warning(tree.pid != null ? tree.pid.pos() : null,""String_Node_Str"",tree.packge);
        if (addEnv || (tree0.packageAnnotations.isEmpty() && tree.docComments != null && tree.docComments.get(tree) != null)) {
          typeEnvs.put(tree.packge,env);
        }
      }
    }
    for (Symbol q=tree.packge; q != null && q.kind == PCK; q=q.owner)     q.flags_field|=EXISTS;
    Name name=names.package_info;
    ClassSymbol c=reader.enterClass(name,tree.packge);
    c.flatname=names.fromString(tree.packge + ""String_Node_Str"" + name);
    c.sourcefile=tree.sourcefile;
    c.completer=null;
    c.members_field=new Scope(c);
    tree.packge.package_info=c;
  }
  classEnter(tree.defs,env);
  if (addEnv) {
    todo.append(env);
  }
  log.useSource(prev);
  result=null;
}","@Override public void visitTopLevel(JCCompilationUnit tree){
  JavaFileObject prev=log.useSource(tree.sourcefile);
  boolean addEnv=false;
  boolean isPkgInfo=tree.sourcefile.isNameCompatible(""String_Node_Str"",JavaFileObject.Kind.SOURCE);
  if (tree.pid != null) {
    tree.packge=reader.enterPackage(TreeInfo.fullName(tree.pid));
    if (tree.packageAnnotations.nonEmpty()) {
      if (isPkgInfo) {
        addEnv=true;
      }
 else {
        log.error(tree.packageAnnotations.head.pos(),""String_Node_Str"");
      }
    }
  }
 else {
    tree.packge=syms.unnamedPackage;
  }
  tree.packge.complete();
  Env<AttrContext> topEnv=topLevelEnv(tree);
  if (isPkgInfo) {
    Env<AttrContext> env0=typeEnvs.get(tree.packge);
    if (env0 == null) {
      typeEnvs.put(tree.packge,topEnv);
    }
 else {
      JCCompilationUnit tree0=env0.toplevel;
      if (!fileManager.isSameFile(tree.sourcefile,tree0.sourcefile)) {
        log.warning(tree.pid != null ? tree.pid.pos() : null,""String_Node_Str"",tree.packge);
        if (addEnv || (tree0.packageAnnotations.isEmpty() && tree.docComments != null && tree.docComments.get(tree) != null)) {
          typeEnvs.put(tree.packge,topEnv);
        }
      }
    }
    for (Symbol q=tree.packge; q != null && q.kind == PCK; q=q.owner)     q.flags_field|=EXISTS;
    Name name=names.package_info;
    ClassSymbol c=reader.enterClass(name,tree.packge);
    c.flatname=names.fromString(tree.packge + ""String_Node_Str"" + name);
    c.sourcefile=tree.sourcefile;
    c.completer=null;
    c.members_field=new Scope(c);
    tree.packge.package_info=c;
  }
  classEnter(tree.defs,topEnv);
  if (addEnv) {
    todo.append(topEnv);
  }
  log.useSource(prev);
  result=null;
}"
37329,"/** 
 * Class enter visitor method for type parameters. Enter a symbol for type parameter in local scope, after checking that it is unique.
 */
public void visitTypeParameter(JCTypeParameter tree){
  TypeVar a=(tree.type != null) ? (TypeVar)tree.type : new TypeVar(tree.name,env.info.scope.owner,syms.botType);
  tree.type=a;
  if (chk.checkUnique(tree.pos(),a.tsym,env.info.scope)) {
    env.info.scope.enter(a.tsym);
  }
  result=a;
}","/** 
 * Class enter visitor method for type parameters. Enter a symbol for type parameter in local scope, after checking that it is unique.
 */
@Override public void visitTypeParameter(JCTypeParameter tree){
  TypeVar a=(tree.type != null) ? (TypeVar)tree.type : new TypeVar(tree.name,env.info.scope.owner,syms.botType);
  tree.type=a;
  if (chk.checkUnique(tree.pos(),a.tsym,env.info.scope)) {
    env.info.scope.enter(a.tsym);
  }
  result=a;
}"
37330,"/** 
 * Main method: enter one class from a list of toplevel trees and place the rest on uncompleted for later processing.
 * @param trees      The list of trees to be processed.
 * @param c          The class symbol to be processed.
 */
public void complete(List<JCCompilationUnit> trees,ClassSymbol c){
  annotate.enterStart();
  ListBuffer<ClassSymbol> prevUncompleted=uncompleted;
  if (memberEnter.completionEnabled)   uncompleted=new ListBuffer<ClassSymbol>();
  try {
    classEnter(trees,null);
    if (memberEnter.completionEnabled) {
      while (uncompleted.nonEmpty()) {
        ClassSymbol clazz=uncompleted.next();
        if (c == null || c == clazz || prevUncompleted == null)         clazz.complete();
 else         prevUncompleted.append(clazz);
      }
      for (      JCCompilationUnit tree : trees) {
        if (tree.starImportScope.elems == null) {
          JavaFileObject prev=log.useSource(tree.sourcefile);
          Env<AttrContext> env=typeEnvs.get(tree);
          if (env == null)           env=topLevelEnv(tree);
          memberEnter.memberEnter(tree,env);
          log.useSource(prev);
        }
      }
    }
  }
  finally {
    uncompleted=prevUncompleted;
    annotate.enterDone();
  }
}","/** 
 * Main method: enter one class from a list of toplevel trees and place the rest on uncompleted for later processing.
 * @param trees      The list of trees to be processed.
 * @param c          The class symbol to be processed.
 */
public void complete(List<JCCompilationUnit> trees,ClassSymbol c){
  annotate.enterStart();
  ListBuffer<ClassSymbol> prevUncompleted=uncompleted;
  if (memberEnter.completionEnabled)   uncompleted=new ListBuffer<ClassSymbol>();
  try {
    classEnter(trees,null);
    if (memberEnter.completionEnabled) {
      while (uncompleted.nonEmpty()) {
        ClassSymbol clazz=uncompleted.next();
        if (c == null || c == clazz || prevUncompleted == null)         clazz.complete();
 else         prevUncompleted.append(clazz);
      }
      for (      JCCompilationUnit tree : trees) {
        if (tree.starImportScope.elems == null) {
          JavaFileObject prev=log.useSource(tree.sourcefile);
          Env<AttrContext> topEnv=topLevelEnv(tree);
          memberEnter.memberEnter(tree,topEnv);
          log.useSource(prev);
        }
      }
    }
  }
  finally {
    uncompleted=prevUncompleted;
    annotate.enterDone();
  }
}"
37331,"public void visitNewArray(JCNewArray tree){
  tree.elemtype=translate(tree.elemtype,null);
  translate(tree.dims,syms.intType);
  tree.elems=translate(tree.elems,(tree.type == null) ? null : erasure(types.elemtype(tree.type)));
  tree.type=erasure(tree.type);
  result=tree;
}","public void visitNewArray(JCNewArray tree){
  tree.elemtype=translate(tree.elemtype,null);
  translate(tree.dims,syms.intType);
  if (tree.type != null) {
    tree.elems=translate(tree.elems,erasure(types.elemtype(tree.type)));
    tree.type=erasure(tree.type);
  }
 else {
    tree.elems=translate(tree.elems,null);
  }
  result=tree;
}"
37332,"/** 
 * A KindName representing a given symbol
 */
public static KindName kindName(Symbol sym){
switch (sym.getKind()) {
case PACKAGE:
    return KindName.PACKAGE;
case ENUM:
case ANNOTATION_TYPE:
case INTERFACE:
case CLASS:
  return KindName.CLASS;
case TYPE_PARAMETER:
return KindName.TYPEVAR;
case ENUM_CONSTANT:
case FIELD:
case PARAMETER:
case LOCAL_VARIABLE:
case EXCEPTION_PARAMETER:
return KindName.VAR;
case METHOD:
case CONSTRUCTOR:
case STATIC_INIT:
case INSTANCE_INIT:
return KindName.METHOD;
default :
if (sym.kind == VAL) return KindName.VAL;
 else throw new AssertionError(""String_Node_Str"" + sym.getKind());
}
}","/** 
 * A KindName representing a given symbol
 */
public static KindName kindName(Symbol sym){
switch (sym.getKind()) {
case PACKAGE:
    return KindName.PACKAGE;
case ENUM:
  return KindName.ENUM;
case ANNOTATION_TYPE:
case CLASS:
return KindName.CLASS;
case INTERFACE:
return KindName.INTERFACE;
case TYPE_PARAMETER:
return KindName.TYPEVAR;
case ENUM_CONSTANT:
case FIELD:
case PARAMETER:
case LOCAL_VARIABLE:
case EXCEPTION_PARAMETER:
return KindName.VAR;
case CONSTRUCTOR:
return KindName.CONSTRUCTOR;
case METHOD:
case STATIC_INIT:
case INSTANCE_INIT:
return KindName.METHOD;
default :
if (sym.kind == VAL) return KindName.VAL;
 else throw new AssertionError(""String_Node_Str"" + sym.getKind());
}
}"
37333,"/** 
 * A KindName representing a given symbol
 */
public static KindName kindName(Symbol sym){
switch (sym.getKind()) {
case PACKAGE:
    return KindName.PACKAGE;
case ENUM:
case ANNOTATION_TYPE:
case INTERFACE:
case CLASS:
  return KindName.CLASS;
case TYPE_PARAMETER:
return KindName.TYPEVAR;
case ENUM_CONSTANT:
case FIELD:
case PARAMETER:
case LOCAL_VARIABLE:
case EXCEPTION_PARAMETER:
return KindName.VAR;
case METHOD:
case CONSTRUCTOR:
case STATIC_INIT:
case INSTANCE_INIT:
return KindName.METHOD;
default :
if (sym.kind == VAL) return KindName.VAL;
 else throw new AssertionError(""String_Node_Str"" + sym.getKind());
}
}","/** 
 * A KindName representing a given symbol
 */
public static KindName kindName(Symbol sym){
switch (sym.getKind()) {
case PACKAGE:
    return KindName.PACKAGE;
case ENUM:
  return KindName.ENUM;
case ANNOTATION_TYPE:
case CLASS:
return KindName.CLASS;
case INTERFACE:
return KindName.INTERFACE;
case TYPE_PARAMETER:
return KindName.TYPEVAR;
case ENUM_CONSTANT:
case FIELD:
case PARAMETER:
case LOCAL_VARIABLE:
case EXCEPTION_PARAMETER:
return KindName.VAR;
case CONSTRUCTOR:
return KindName.CONSTRUCTOR;
case METHOD:
case STATIC_INIT:
case INSTANCE_INIT:
return KindName.METHOD;
default :
if (sym.kind == VAL) return KindName.VAL;
 else throw new AssertionError(""String_Node_Str"" + sym.getKind());
}
}"
37334,"/** 
 * The number of errors reported so far.
 */
public int errorCount(){
  if (delegateCompiler != null && delegateCompiler != this)   return delegateCompiler.errorCount();
 else   return log.nerrors;
}","/** 
 * The number of errors reported so far.
 */
public int errorCount(){
  if (delegateCompiler != null && delegateCompiler != this)   return delegateCompiler.errorCount();
 else {
    if (werror && log.nerrors == 0 && log.nwarnings > 0) {
      log.error(""String_Node_Str"");
    }
  }
  return log.nerrors;
}"
37335,"/** 
 * Construct a new compiler using a shared context.
 */
public JavaCompiler(final Context context){
  this.context=context;
  context.put(compilerKey,this);
  if (context.get(JavaFileManager.class) == null)   JavacFileManager.preRegister(context);
  names=Names.instance(context);
  log=Log.instance(context);
  diagFactory=JCDiagnostic.Factory.instance(context);
  reader=ClassReader.instance(context);
  make=TreeMaker.instance(context);
  writer=ClassWriter.instance(context);
  enter=Enter.instance(context);
  todo=Todo.instance(context);
  fileManager=context.get(JavaFileManager.class);
  parserFactory=ParserFactory.instance(context);
  try {
    syms=Symtab.instance(context);
  }
 catch (  CompletionFailure ex) {
    log.error(""String_Node_Str"",ex.sym,ex.getDetailValue());
    if (ex instanceof ClassReader.BadClassFile)     throw new Abort();
  }
  source=Source.instance(context);
  attr=Attr.instance(context);
  chk=Check.instance(context);
  gen=Gen.instance(context);
  flow=Flow.instance(context);
  transTypes=TransTypes.instance(context);
  lower=Lower.instance(context);
  annotate=Annotate.instance(context);
  types=Types.instance(context);
  taskListener=context.get(TaskListener.class);
  reader.sourceCompleter=this;
  Options options=Options.instance(context);
  verbose=options.get(""String_Node_Str"") != null;
  sourceOutput=options.get(""String_Node_Str"") != null;
  stubOutput=options.get(""String_Node_Str"") != null;
  relax=options.get(""String_Node_Str"") != null;
  printFlat=options.get(""String_Node_Str"") != null;
  attrParseOnly=options.get(""String_Node_Str"") != null;
  encoding=options.get(""String_Node_Str"");
  lineDebugInfo=options.get(""String_Node_Str"") == null || options.get(""String_Node_Str"") != null;
  genEndPos=options.get(""String_Node_Str"") != null || context.get(DiagnosticListener.class) != null;
  devVerbose=options.get(""String_Node_Str"") != null;
  processPcks=options.get(""String_Node_Str"") != null;
  verboseCompilePolicy=options.get(""String_Node_Str"") != null;
  if (attrParseOnly)   compilePolicy=CompilePolicy.ATTR_ONLY;
 else   compilePolicy=CompilePolicy.decode(options.get(""String_Node_Str""));
  implicitSourcePolicy=ImplicitSourcePolicy.decode(options.get(""String_Node_Str""));
  completionFailureName=(options.get(""String_Node_Str"") != null) ? names.fromString(options.get(""String_Node_Str"")) : null;
}","/** 
 * Construct a new compiler using a shared context.
 */
public JavaCompiler(final Context context){
  this.context=context;
  context.put(compilerKey,this);
  if (context.get(JavaFileManager.class) == null)   JavacFileManager.preRegister(context);
  names=Names.instance(context);
  log=Log.instance(context);
  diagFactory=JCDiagnostic.Factory.instance(context);
  reader=ClassReader.instance(context);
  make=TreeMaker.instance(context);
  writer=ClassWriter.instance(context);
  enter=Enter.instance(context);
  todo=Todo.instance(context);
  fileManager=context.get(JavaFileManager.class);
  parserFactory=ParserFactory.instance(context);
  try {
    syms=Symtab.instance(context);
  }
 catch (  CompletionFailure ex) {
    log.error(""String_Node_Str"",ex.sym,ex.getDetailValue());
    if (ex instanceof ClassReader.BadClassFile)     throw new Abort();
  }
  source=Source.instance(context);
  attr=Attr.instance(context);
  chk=Check.instance(context);
  gen=Gen.instance(context);
  flow=Flow.instance(context);
  transTypes=TransTypes.instance(context);
  lower=Lower.instance(context);
  annotate=Annotate.instance(context);
  types=Types.instance(context);
  taskListener=context.get(TaskListener.class);
  reader.sourceCompleter=this;
  Options options=Options.instance(context);
  verbose=options.get(""String_Node_Str"") != null;
  sourceOutput=options.get(""String_Node_Str"") != null;
  stubOutput=options.get(""String_Node_Str"") != null;
  relax=options.get(""String_Node_Str"") != null;
  printFlat=options.get(""String_Node_Str"") != null;
  attrParseOnly=options.get(""String_Node_Str"") != null;
  encoding=options.get(""String_Node_Str"");
  lineDebugInfo=options.get(""String_Node_Str"") == null || options.get(""String_Node_Str"") != null;
  genEndPos=options.get(""String_Node_Str"") != null || context.get(DiagnosticListener.class) != null;
  devVerbose=options.get(""String_Node_Str"") != null;
  processPcks=options.get(""String_Node_Str"") != null;
  werror=options.get(""String_Node_Str"") != null;
  verboseCompilePolicy=options.get(""String_Node_Str"") != null;
  if (attrParseOnly)   compilePolicy=CompilePolicy.ATTR_ONLY;
 else   compilePolicy=CompilePolicy.decode(options.get(""String_Node_Str""));
  implicitSourcePolicy=ImplicitSourcePolicy.decode(options.get(""String_Node_Str""));
  completionFailureName=(options.get(""String_Node_Str"") != null) ? names.fromString(options.get(""String_Node_Str"")) : null;
}"
37336,"/** 
 * Programmatic interface for main function.
 * @param args    The command line parameters.
 */
public int compile(String[] args,Context context,List<JavaFileObject> fileObjects,Iterable<? extends Processor> processors){
  if (options == null)   options=Options.instance(context);
  filenames=new ListBuffer<File>();
  classnames=new ListBuffer<String>();
  JavaCompiler comp=null;
  try {
    if (args.length == 0 && fileObjects.isEmpty()) {
      help();
      return EXIT_CMDERR;
    }
    List<File> files;
    try {
      files=processArgs(CommandLine.parse(args));
      if (files == null) {
        return EXIT_CMDERR;
      }
 else       if (files.isEmpty() && fileObjects.isEmpty() && classnames.isEmpty()) {
        if (options.get(""String_Node_Str"") != null || options.get(""String_Node_Str"") != null || options.get(""String_Node_Str"") != null || options.get(""String_Node_Str"") != null)         return EXIT_OK;
        error(""String_Node_Str"");
        return EXIT_CMDERR;
      }
    }
 catch (    java.io.FileNotFoundException e) {
      Log.printLines(out,ownName + ""String_Node_Str"" + getLocalizedString(""String_Node_Str"",e.getMessage()));
      return EXIT_SYSERR;
    }
    boolean forceStdOut=options.get(""String_Node_Str"") != null;
    if (forceStdOut) {
      out.flush();
      out=new PrintWriter(System.out,true);
    }
    context.put(Log.outKey,out);
    boolean batchMode=(options.get(""String_Node_Str"") == null && System.getProperty(""String_Node_Str"") == null);
    if (batchMode)     CacheFSInfo.preRegister(context);
    fileManager=context.get(JavaFileManager.class);
    comp=JavaCompiler.instance(context);
    if (comp == null)     return EXIT_SYSERR;
    Log log=Log.instance(context);
    if (!files.isEmpty()) {
      comp=JavaCompiler.instance(context);
      List<JavaFileObject> otherFiles=List.nil();
      JavacFileManager dfm=(JavacFileManager)fileManager;
      for (      JavaFileObject fo : dfm.getJavaFileObjectsFromFiles(files))       otherFiles=otherFiles.prepend(fo);
      for (      JavaFileObject fo : otherFiles)       fileObjects=fileObjects.prepend(fo);
    }
    comp.compile(fileObjects,classnames.toList(),processors);
    if (log.expectDiagKeys != null) {
      if (log.expectDiagKeys.size() == 0) {
        Log.printLines(log.noticeWriter,""String_Node_Str"");
        return EXIT_OK;
      }
 else {
        Log.printLines(log.noticeWriter,""String_Node_Str"" + log.expectDiagKeys);
        return EXIT_ERROR;
      }
    }
    if (comp.errorCount() != 0 || options.get(""String_Node_Str"") != null && comp.warningCount() != 0)     return EXIT_ERROR;
  }
 catch (  IOException ex) {
    ioMessage(ex);
    return EXIT_SYSERR;
  }
catch (  OutOfMemoryError ex) {
    resourceMessage(ex);
    return EXIT_SYSERR;
  }
catch (  StackOverflowError ex) {
    resourceMessage(ex);
    return EXIT_SYSERR;
  }
catch (  FatalError ex) {
    feMessage(ex);
    return EXIT_SYSERR;
  }
catch (  AnnotationProcessingError ex) {
    apMessage(ex);
    return EXIT_SYSERR;
  }
catch (  ClientCodeException ex) {
    throw new RuntimeException(ex.getCause());
  }
catch (  PropagatedException ex) {
    throw ex.getCause();
  }
catch (  Throwable ex) {
    if (comp == null || comp.errorCount() == 0 || options == null || options.get(""String_Node_Str"") != null)     bugMessage(ex);
    return EXIT_ABNORMAL;
  }
 finally {
    if (comp != null)     comp.close();
    filenames=null;
    options=null;
  }
  return EXIT_OK;
}","/** 
 * Programmatic interface for main function.
 * @param args    The command line parameters.
 */
public int compile(String[] args,Context context,List<JavaFileObject> fileObjects,Iterable<? extends Processor> processors){
  if (options == null)   options=Options.instance(context);
  filenames=new ListBuffer<File>();
  classnames=new ListBuffer<String>();
  JavaCompiler comp=null;
  try {
    if (args.length == 0 && fileObjects.isEmpty()) {
      help();
      return EXIT_CMDERR;
    }
    List<File> files;
    try {
      files=processArgs(CommandLine.parse(args));
      if (files == null) {
        return EXIT_CMDERR;
      }
 else       if (files.isEmpty() && fileObjects.isEmpty() && classnames.isEmpty()) {
        if (options.get(""String_Node_Str"") != null || options.get(""String_Node_Str"") != null || options.get(""String_Node_Str"") != null || options.get(""String_Node_Str"") != null)         return EXIT_OK;
        error(""String_Node_Str"");
        return EXIT_CMDERR;
      }
    }
 catch (    java.io.FileNotFoundException e) {
      Log.printLines(out,ownName + ""String_Node_Str"" + getLocalizedString(""String_Node_Str"",e.getMessage()));
      return EXIT_SYSERR;
    }
    boolean forceStdOut=options.get(""String_Node_Str"") != null;
    if (forceStdOut) {
      out.flush();
      out=new PrintWriter(System.out,true);
    }
    context.put(Log.outKey,out);
    boolean batchMode=(options.get(""String_Node_Str"") == null && System.getProperty(""String_Node_Str"") == null);
    if (batchMode)     CacheFSInfo.preRegister(context);
    fileManager=context.get(JavaFileManager.class);
    comp=JavaCompiler.instance(context);
    if (comp == null)     return EXIT_SYSERR;
    Log log=Log.instance(context);
    if (!files.isEmpty()) {
      comp=JavaCompiler.instance(context);
      List<JavaFileObject> otherFiles=List.nil();
      JavacFileManager dfm=(JavacFileManager)fileManager;
      for (      JavaFileObject fo : dfm.getJavaFileObjectsFromFiles(files))       otherFiles=otherFiles.prepend(fo);
      for (      JavaFileObject fo : otherFiles)       fileObjects=fileObjects.prepend(fo);
    }
    comp.compile(fileObjects,classnames.toList(),processors);
    if (log.expectDiagKeys != null) {
      if (log.expectDiagKeys.size() == 0) {
        Log.printLines(log.noticeWriter,""String_Node_Str"");
        return EXIT_OK;
      }
 else {
        Log.printLines(log.noticeWriter,""String_Node_Str"" + log.expectDiagKeys);
        return EXIT_ERROR;
      }
    }
    if (comp.errorCount() != 0)     return EXIT_ERROR;
  }
 catch (  IOException ex) {
    ioMessage(ex);
    return EXIT_SYSERR;
  }
catch (  OutOfMemoryError ex) {
    resourceMessage(ex);
    return EXIT_SYSERR;
  }
catch (  StackOverflowError ex) {
    resourceMessage(ex);
    return EXIT_SYSERR;
  }
catch (  FatalError ex) {
    feMessage(ex);
    return EXIT_SYSERR;
  }
catch (  AnnotationProcessingError ex) {
    apMessage(ex);
    return EXIT_SYSERR;
  }
catch (  ClientCodeException ex) {
    throw new RuntimeException(ex.getCause());
  }
catch (  PropagatedException ex) {
    throw ex.getCause();
  }
catch (  Throwable ex) {
    if (comp == null || comp.errorCount() == 0 || options == null || options.get(""String_Node_Str"") != null)     bugMessage(ex);
    return EXIT_ABNORMAL;
  }
 finally {
    if (comp != null)     comp.close();
    filenames=null;
    options=null;
  }
  return EXIT_OK;
}"
37337,"/** 
 * Get all the recognized options.
 * @param helper an {@code OptionHelper} to help when processing options
 * @return an array of options
 */
public static Option[] getAll(final OptionHelper helper){
  return new Option[]{new Option(G,""String_Node_Str""),new Option(G_NONE,""String_Node_Str""){
    @Override public boolean process(    Options options,    String option){
      options.put(""String_Node_Str"",""String_Node_Str"");
      return false;
    }
  }
,new Option(G_CUSTOM,""String_Node_Str"",Option.ChoiceKind.ANYOF,""String_Node_Str"",""String_Node_Str"",""String_Node_Str""),new XOption(XLINT,""String_Node_Str""),new XOption(XLINT_CUSTOM,""String_Node_Str"",Option.ChoiceKind.ANYOF,getXLintChoices()),new Option(NOWARN,""String_Node_Str""){
    @Override public boolean process(    Options options,    String option){
      options.put(""String_Node_Str"",option);
      return false;
    }
  }
,new Option(VERBOSE,""String_Node_Str""),new Option(DEPRECATION,""String_Node_Str""){
    @Override public boolean process(    Options options,    String option){
      options.put(""String_Node_Str"",option);
      return false;
    }
  }
,new Option(CLASSPATH,""String_Node_Str"",""String_Node_Str""),new Option(CP,""String_Node_Str"",""String_Node_Str""){
    @Override public boolean process(    Options options,    String option,    String arg){
      return super.process(options,""String_Node_Str"",arg);
    }
  }
,new Option(SOURCEPATH,""String_Node_Str"",""String_Node_Str""),new Option(BOOTCLASSPATH,""String_Node_Str"",""String_Node_Str""){
    @Override public boolean process(    Options options,    String option,    String arg){
      options.remove(""String_Node_Str"");
      options.remove(""String_Node_Str"");
      return super.process(options,option,arg);
    }
  }
,new XOption(XBOOTCLASSPATH_PREPEND,""String_Node_Str"",""String_Node_Str""),new XOption(XBOOTCLASSPATH_APPEND,""String_Node_Str"",""String_Node_Str""),new XOption(XBOOTCLASSPATH,""String_Node_Str"",""String_Node_Str""){
    @Override public boolean process(    Options options,    String option,    String arg){
      options.remove(""String_Node_Str"");
      options.remove(""String_Node_Str"");
      return super.process(options,""String_Node_Str"",arg);
    }
  }
,new Option(EXTDIRS,""String_Node_Str"",""String_Node_Str""),new XOption(DJAVA_EXT_DIRS,""String_Node_Str"",""String_Node_Str""){
    @Override public boolean process(    Options options,    String option,    String arg){
      return super.process(options,""String_Node_Str"",arg);
    }
  }
,new Option(ENDORSEDDIRS,""String_Node_Str"",""String_Node_Str""),new XOption(DJAVA_ENDORSED_DIRS,""String_Node_Str"",""String_Node_Str""){
    @Override public boolean process(    Options options,    String option,    String arg){
      return super.process(options,""String_Node_Str"",arg);
    }
  }
,new Option(PROC,""String_Node_Str"",Option.ChoiceKind.ONEOF,""String_Node_Str"",""String_Node_Str""),new Option(PROCESSOR,""String_Node_Str"",""String_Node_Str""),new Option(PROCESSORPATH,""String_Node_Str"",""String_Node_Str""),new Option(D,""String_Node_Str"",""String_Node_Str""),new Option(S,""String_Node_Str"",""String_Node_Str""),new Option(IMPLICIT,""String_Node_Str"",Option.ChoiceKind.ONEOF,""String_Node_Str"",""String_Node_Str""),new Option(ENCODING,""String_Node_Str"",""String_Node_Str""),new Option(SOURCE,""String_Node_Str"",""String_Node_Str""){
    @Override public boolean process(    Options options,    String option,    String operand){
      Source source=Source.lookup(operand);
      if (source == null) {
        helper.error(""String_Node_Str"",operand);
        return true;
      }
      return super.process(options,option,operand);
    }
  }
,new Option(TARGET,""String_Node_Str"",""String_Node_Str""){
    @Override public boolean process(    Options options,    String option,    String operand){
      Target target=Target.lookup(operand);
      if (target == null) {
        helper.error(""String_Node_Str"",operand);
        return true;
      }
      return super.process(options,option,operand);
    }
  }
,new Option(VERSION,""String_Node_Str""){
    @Override public boolean process(    Options options,    String option){
      helper.printVersion();
      return super.process(options,option);
    }
  }
,new HiddenOption(FULLVERSION){
    @Override public boolean process(    Options options,    String option){
      helper.printFullVersion();
      return super.process(options,option);
    }
  }
,new Option(HELP,""String_Node_Str""){
    @Override public boolean process(    Options options,    String option){
      helper.printHelp();
      return super.process(options,option);
    }
  }
,new Option(A,""String_Node_Str"",""String_Node_Str""){
    @Override String helpSynopsis(){
      hasSuffix=true;
      return super.helpSynopsis();
    }
    @Override public boolean matches(    String arg){
      return arg.startsWith(""String_Node_Str"");
    }
    @Override public boolean hasArg(){
      return false;
    }
    @Override public boolean process(    Options options,    String option){
      int argLength=option.length();
      if (argLength == 2) {
        helper.error(""String_Node_Str"");
        return true;
      }
      int sepIndex=option.indexOf('=');
      String key=option.substring(2,(sepIndex != -1 ? sepIndex : argLength));
      if (!JavacProcessingEnvironment.isValidOptionName(key)) {
        helper.error(""String_Node_Str"",option);
        return true;
      }
      return process(options,option,option);
    }
  }
,new Option(X,""String_Node_Str""){
    @Override public boolean process(    Options options,    String option){
      helper.printXhelp();
      return super.process(options,option);
    }
  }
,new Option(J,""String_Node_Str"",""String_Node_Str""){
    @Override String helpSynopsis(){
      hasSuffix=true;
      return super.helpSynopsis();
    }
    @Override public boolean process(    Options options,    String option){
      throw new AssertionError(""String_Node_Str"");
    }
  }
,new HiddenOption(MOREINFO){
    @Override public boolean process(    Options options,    String option){
      Type.moreInfo=true;
      return super.process(options,option);
    }
  }
,new HiddenOption(WERROR),new HiddenOption(COMPLEXINFERENCE),new HiddenOption(PROMPT),new HiddenOption(DOE),new HiddenOption(PRINTSOURCE),new HiddenOption(WARNUNCHECKED){
    @Override public boolean process(    Options options,    String option){
      options.put(""String_Node_Str"",option);
      return false;
    }
  }
,new XOption(XMAXERRS,""String_Node_Str"",""String_Node_Str""),new XOption(XMAXWARNS,""String_Node_Str"",""String_Node_Str""),new XOption(XSTDOUT,""String_Node_Str"",""String_Node_Str""){
    @Override public boolean process(    Options options,    String option,    String arg){
      try {
        helper.setOut(new PrintWriter(new FileWriter(arg),true));
      }
 catch (      java.io.IOException e) {
        helper.error(""String_Node_Str"",arg,e);
        return true;
      }
      return super.process(options,option,arg);
    }
  }
,new XOption(XPRINT,""String_Node_Str""),new XOption(XPRINTROUNDS,""String_Node_Str""),new XOption(XPRINTPROCESSORINFO,""String_Node_Str""),new XOption(XPREFER,""String_Node_Str"",Option.ChoiceKind.ONEOF,""String_Node_Str"",""String_Node_Str""),new HiddenOption(O),new HiddenOption(XJCOV),new HiddenOption(XD){
    String s;
    @Override public boolean matches(    String s){
      this.s=s;
      return s.startsWith(name.optionName);
    }
    @Override public boolean process(    Options options,    String option){
      s=s.substring(name.optionName.length());
      int eq=s.indexOf('=');
      String key=(eq < 0) ? s : s.substring(0,eq);
      String value=(eq < 0) ? s : s.substring(eq + 1);
      options.put(key,value);
      return false;
    }
  }
,new HiddenOption(SOURCEFILE){
    String s;
    @Override public boolean matches(    String s){
      this.s=s;
      return s.endsWith(""String_Node_Str"") || SourceVersion.isName(s);
    }
    @Override public boolean process(    Options options,    String option){
      if (s.endsWith(""String_Node_Str"")) {
        File f=new File(s);
        if (!f.exists()) {
          helper.error(""String_Node_Str"",f);
          return true;
        }
        if (!f.isFile()) {
          helper.error(""String_Node_Str"",f);
          return true;
        }
        helper.addFile(f);
      }
 else       helper.addClassName(s);
      return false;
    }
  }
};
}","/** 
 * Get all the recognized options.
 * @param helper an {@code OptionHelper} to help when processing options
 * @return an array of options
 */
public static Option[] getAll(final OptionHelper helper){
  return new Option[]{new Option(G,""String_Node_Str""),new Option(G_NONE,""String_Node_Str""){
    @Override public boolean process(    Options options,    String option){
      options.put(""String_Node_Str"",""String_Node_Str"");
      return false;
    }
  }
,new Option(G_CUSTOM,""String_Node_Str"",Option.ChoiceKind.ANYOF,""String_Node_Str"",""String_Node_Str"",""String_Node_Str""),new XOption(XLINT,""String_Node_Str""),new XOption(XLINT_CUSTOM,""String_Node_Str"",Option.ChoiceKind.ANYOF,getXLintChoices()),new Option(NOWARN,""String_Node_Str""){
    @Override public boolean process(    Options options,    String option){
      options.put(""String_Node_Str"",option);
      return false;
    }
  }
,new Option(VERBOSE,""String_Node_Str""),new Option(DEPRECATION,""String_Node_Str""){
    @Override public boolean process(    Options options,    String option){
      options.put(""String_Node_Str"",option);
      return false;
    }
  }
,new Option(CLASSPATH,""String_Node_Str"",""String_Node_Str""),new Option(CP,""String_Node_Str"",""String_Node_Str""){
    @Override public boolean process(    Options options,    String option,    String arg){
      return super.process(options,""String_Node_Str"",arg);
    }
  }
,new Option(SOURCEPATH,""String_Node_Str"",""String_Node_Str""),new Option(BOOTCLASSPATH,""String_Node_Str"",""String_Node_Str""){
    @Override public boolean process(    Options options,    String option,    String arg){
      options.remove(""String_Node_Str"");
      options.remove(""String_Node_Str"");
      return super.process(options,option,arg);
    }
  }
,new XOption(XBOOTCLASSPATH_PREPEND,""String_Node_Str"",""String_Node_Str""),new XOption(XBOOTCLASSPATH_APPEND,""String_Node_Str"",""String_Node_Str""),new XOption(XBOOTCLASSPATH,""String_Node_Str"",""String_Node_Str""){
    @Override public boolean process(    Options options,    String option,    String arg){
      options.remove(""String_Node_Str"");
      options.remove(""String_Node_Str"");
      return super.process(options,""String_Node_Str"",arg);
    }
  }
,new Option(EXTDIRS,""String_Node_Str"",""String_Node_Str""),new XOption(DJAVA_EXT_DIRS,""String_Node_Str"",""String_Node_Str""){
    @Override public boolean process(    Options options,    String option,    String arg){
      return super.process(options,""String_Node_Str"",arg);
    }
  }
,new Option(ENDORSEDDIRS,""String_Node_Str"",""String_Node_Str""),new XOption(DJAVA_ENDORSED_DIRS,""String_Node_Str"",""String_Node_Str""){
    @Override public boolean process(    Options options,    String option,    String arg){
      return super.process(options,""String_Node_Str"",arg);
    }
  }
,new Option(PROC,""String_Node_Str"",Option.ChoiceKind.ONEOF,""String_Node_Str"",""String_Node_Str""),new Option(PROCESSOR,""String_Node_Str"",""String_Node_Str""),new Option(PROCESSORPATH,""String_Node_Str"",""String_Node_Str""),new Option(D,""String_Node_Str"",""String_Node_Str""),new Option(S,""String_Node_Str"",""String_Node_Str""),new Option(IMPLICIT,""String_Node_Str"",Option.ChoiceKind.ONEOF,""String_Node_Str"",""String_Node_Str""),new Option(ENCODING,""String_Node_Str"",""String_Node_Str""),new Option(SOURCE,""String_Node_Str"",""String_Node_Str""){
    @Override public boolean process(    Options options,    String option,    String operand){
      Source source=Source.lookup(operand);
      if (source == null) {
        helper.error(""String_Node_Str"",operand);
        return true;
      }
      return super.process(options,option,operand);
    }
  }
,new Option(TARGET,""String_Node_Str"",""String_Node_Str""){
    @Override public boolean process(    Options options,    String option,    String operand){
      Target target=Target.lookup(operand);
      if (target == null) {
        helper.error(""String_Node_Str"",operand);
        return true;
      }
      return super.process(options,option,operand);
    }
  }
,new Option(VERSION,""String_Node_Str""){
    @Override public boolean process(    Options options,    String option){
      helper.printVersion();
      return super.process(options,option);
    }
  }
,new HiddenOption(FULLVERSION){
    @Override public boolean process(    Options options,    String option){
      helper.printFullVersion();
      return super.process(options,option);
    }
  }
,new Option(HELP,""String_Node_Str""){
    @Override public boolean process(    Options options,    String option){
      helper.printHelp();
      return super.process(options,option);
    }
  }
,new Option(A,""String_Node_Str"",""String_Node_Str""){
    @Override String helpSynopsis(){
      hasSuffix=true;
      return super.helpSynopsis();
    }
    @Override public boolean matches(    String arg){
      return arg.startsWith(""String_Node_Str"");
    }
    @Override public boolean hasArg(){
      return false;
    }
    @Override public boolean process(    Options options,    String option){
      int argLength=option.length();
      if (argLength == 2) {
        helper.error(""String_Node_Str"");
        return true;
      }
      int sepIndex=option.indexOf('=');
      String key=option.substring(2,(sepIndex != -1 ? sepIndex : argLength));
      if (!JavacProcessingEnvironment.isValidOptionName(key)) {
        helper.error(""String_Node_Str"",option);
        return true;
      }
      return process(options,option,option);
    }
  }
,new Option(X,""String_Node_Str""){
    @Override public boolean process(    Options options,    String option){
      helper.printXhelp();
      return super.process(options,option);
    }
  }
,new Option(J,""String_Node_Str"",""String_Node_Str""){
    @Override String helpSynopsis(){
      hasSuffix=true;
      return super.helpSynopsis();
    }
    @Override public boolean process(    Options options,    String option){
      throw new AssertionError(""String_Node_Str"");
    }
  }
,new HiddenOption(MOREINFO){
    @Override public boolean process(    Options options,    String option){
      Type.moreInfo=true;
      return super.process(options,option);
    }
  }
,new Option(WERROR,""String_Node_Str""),new HiddenOption(COMPLEXINFERENCE),new HiddenOption(PROMPT),new HiddenOption(DOE),new HiddenOption(PRINTSOURCE),new HiddenOption(WARNUNCHECKED){
    @Override public boolean process(    Options options,    String option){
      options.put(""String_Node_Str"",option);
      return false;
    }
  }
,new XOption(XMAXERRS,""String_Node_Str"",""String_Node_Str""),new XOption(XMAXWARNS,""String_Node_Str"",""String_Node_Str""),new XOption(XSTDOUT,""String_Node_Str"",""String_Node_Str""){
    @Override public boolean process(    Options options,    String option,    String arg){
      try {
        helper.setOut(new PrintWriter(new FileWriter(arg),true));
      }
 catch (      java.io.IOException e) {
        helper.error(""String_Node_Str"",arg,e);
        return true;
      }
      return super.process(options,option,arg);
    }
  }
,new XOption(XPRINT,""String_Node_Str""),new XOption(XPRINTROUNDS,""String_Node_Str""),new XOption(XPRINTPROCESSORINFO,""String_Node_Str""),new XOption(XPREFER,""String_Node_Str"",Option.ChoiceKind.ONEOF,""String_Node_Str"",""String_Node_Str""),new HiddenOption(O),new HiddenOption(XJCOV),new HiddenOption(XD){
    String s;
    @Override public boolean matches(    String s){
      this.s=s;
      return s.startsWith(name.optionName);
    }
    @Override public boolean process(    Options options,    String option){
      s=s.substring(name.optionName.length());
      int eq=s.indexOf('=');
      String key=(eq < 0) ? s : s.substring(0,eq);
      String value=(eq < 0) ? s : s.substring(eq + 1);
      options.put(key,value);
      return false;
    }
  }
,new HiddenOption(SOURCEFILE){
    String s;
    @Override public boolean matches(    String s){
      this.s=s;
      return s.endsWith(""String_Node_Str"") || SourceVersion.isName(s);
    }
    @Override public boolean process(    Options options,    String option){
      if (s.endsWith(""String_Node_Str"")) {
        File f=new File(s);
        if (!f.exists()) {
          helper.error(""String_Node_Str"",f);
          return true;
        }
        if (!f.isFile()) {
          helper.error(""String_Node_Str"",f);
          return true;
        }
        helper.addFile(f);
      }
 else       helper.addClassName(s);
      return false;
    }
  }
};
}"
37338,"/** 
 * The number of errors reported so far.
 */
public int errorCount(){
  if (delegateCompiler != null && delegateCompiler != this)   return delegateCompiler.errorCount();
 else   return log.nerrors;
}","/** 
 * The number of errors reported so far.
 */
public int errorCount(){
  if (delegateCompiler != null && delegateCompiler != this)   return delegateCompiler.errorCount();
 else {
    if (werror && log.nerrors == 0 && log.nwarnings > 0) {
      log.error(""String_Node_Str"");
    }
  }
  return log.nerrors;
}"
37339,"/** 
 * Construct a new compiler using a shared context.
 */
public JavaCompiler(final Context context){
  this.context=context;
  context.put(compilerKey,this);
  if (context.get(JavaFileManager.class) == null)   JavacFileManager.preRegister(context);
  names=Names.instance(context);
  log=Log.instance(context);
  diagFactory=JCDiagnostic.Factory.instance(context);
  reader=ClassReader.instance(context);
  make=TreeMaker.instance(context);
  writer=ClassWriter.instance(context);
  enter=Enter.instance(context);
  todo=Todo.instance(context);
  fileManager=context.get(JavaFileManager.class);
  parserFactory=ParserFactory.instance(context);
  try {
    syms=Symtab.instance(context);
  }
 catch (  CompletionFailure ex) {
    log.error(""String_Node_Str"",ex.sym,ex.getDetailValue());
    if (ex instanceof ClassReader.BadClassFile)     throw new Abort();
  }
  source=Source.instance(context);
  attr=Attr.instance(context);
  chk=Check.instance(context);
  gen=Gen.instance(context);
  flow=Flow.instance(context);
  transTypes=TransTypes.instance(context);
  lower=Lower.instance(context);
  annotate=Annotate.instance(context);
  types=Types.instance(context);
  taskListener=context.get(TaskListener.class);
  reader.sourceCompleter=this;
  Options options=Options.instance(context);
  verbose=options.get(""String_Node_Str"") != null;
  sourceOutput=options.get(""String_Node_Str"") != null;
  stubOutput=options.get(""String_Node_Str"") != null;
  relax=options.get(""String_Node_Str"") != null;
  printFlat=options.get(""String_Node_Str"") != null;
  attrParseOnly=options.get(""String_Node_Str"") != null;
  encoding=options.get(""String_Node_Str"");
  lineDebugInfo=options.get(""String_Node_Str"") == null || options.get(""String_Node_Str"") != null;
  genEndPos=options.get(""String_Node_Str"") != null || context.get(DiagnosticListener.class) != null;
  devVerbose=options.get(""String_Node_Str"") != null;
  processPcks=options.get(""String_Node_Str"") != null;
  verboseCompilePolicy=options.get(""String_Node_Str"") != null;
  if (attrParseOnly)   compilePolicy=CompilePolicy.ATTR_ONLY;
 else   compilePolicy=CompilePolicy.decode(options.get(""String_Node_Str""));
  implicitSourcePolicy=ImplicitSourcePolicy.decode(options.get(""String_Node_Str""));
  completionFailureName=(options.get(""String_Node_Str"") != null) ? names.fromString(options.get(""String_Node_Str"")) : null;
}","/** 
 * Construct a new compiler using a shared context.
 */
public JavaCompiler(final Context context){
  this.context=context;
  context.put(compilerKey,this);
  if (context.get(JavaFileManager.class) == null)   JavacFileManager.preRegister(context);
  names=Names.instance(context);
  log=Log.instance(context);
  diagFactory=JCDiagnostic.Factory.instance(context);
  reader=ClassReader.instance(context);
  make=TreeMaker.instance(context);
  writer=ClassWriter.instance(context);
  enter=Enter.instance(context);
  todo=Todo.instance(context);
  fileManager=context.get(JavaFileManager.class);
  parserFactory=ParserFactory.instance(context);
  try {
    syms=Symtab.instance(context);
  }
 catch (  CompletionFailure ex) {
    log.error(""String_Node_Str"",ex.sym,ex.getDetailValue());
    if (ex instanceof ClassReader.BadClassFile)     throw new Abort();
  }
  source=Source.instance(context);
  attr=Attr.instance(context);
  chk=Check.instance(context);
  gen=Gen.instance(context);
  flow=Flow.instance(context);
  transTypes=TransTypes.instance(context);
  lower=Lower.instance(context);
  annotate=Annotate.instance(context);
  types=Types.instance(context);
  taskListener=context.get(TaskListener.class);
  reader.sourceCompleter=this;
  Options options=Options.instance(context);
  verbose=options.get(""String_Node_Str"") != null;
  sourceOutput=options.get(""String_Node_Str"") != null;
  stubOutput=options.get(""String_Node_Str"") != null;
  relax=options.get(""String_Node_Str"") != null;
  printFlat=options.get(""String_Node_Str"") != null;
  attrParseOnly=options.get(""String_Node_Str"") != null;
  encoding=options.get(""String_Node_Str"");
  lineDebugInfo=options.get(""String_Node_Str"") == null || options.get(""String_Node_Str"") != null;
  genEndPos=options.get(""String_Node_Str"") != null || context.get(DiagnosticListener.class) != null;
  devVerbose=options.get(""String_Node_Str"") != null;
  processPcks=options.get(""String_Node_Str"") != null;
  werror=options.get(""String_Node_Str"") != null;
  verboseCompilePolicy=options.get(""String_Node_Str"") != null;
  if (attrParseOnly)   compilePolicy=CompilePolicy.ATTR_ONLY;
 else   compilePolicy=CompilePolicy.decode(options.get(""String_Node_Str""));
  implicitSourcePolicy=ImplicitSourcePolicy.decode(options.get(""String_Node_Str""));
  completionFailureName=(options.get(""String_Node_Str"") != null) ? names.fromString(options.get(""String_Node_Str"")) : null;
}"
37340,"/** 
 * Programmatic interface for main function.
 * @param args    The command line parameters.
 */
public int compile(String[] args,Context context,List<JavaFileObject> fileObjects,Iterable<? extends Processor> processors){
  if (options == null)   options=Options.instance(context);
  filenames=new ListBuffer<File>();
  classnames=new ListBuffer<String>();
  JavaCompiler comp=null;
  try {
    if (args.length == 0 && fileObjects.isEmpty()) {
      help();
      return EXIT_CMDERR;
    }
    List<File> files;
    try {
      files=processArgs(CommandLine.parse(args));
      if (files == null) {
        return EXIT_CMDERR;
      }
 else       if (files.isEmpty() && fileObjects.isEmpty() && classnames.isEmpty()) {
        if (options.get(""String_Node_Str"") != null || options.get(""String_Node_Str"") != null || options.get(""String_Node_Str"") != null || options.get(""String_Node_Str"") != null)         return EXIT_OK;
        error(""String_Node_Str"");
        return EXIT_CMDERR;
      }
    }
 catch (    java.io.FileNotFoundException e) {
      Log.printLines(out,ownName + ""String_Node_Str"" + getLocalizedString(""String_Node_Str"",e.getMessage()));
      return EXIT_SYSERR;
    }
    boolean forceStdOut=options.get(""String_Node_Str"") != null;
    if (forceStdOut) {
      out.flush();
      out=new PrintWriter(System.out,true);
    }
    context.put(Log.outKey,out);
    boolean batchMode=(options.get(""String_Node_Str"") == null && System.getProperty(""String_Node_Str"") == null);
    if (batchMode)     CacheFSInfo.preRegister(context);
    fileManager=context.get(JavaFileManager.class);
    comp=JavaCompiler.instance(context);
    if (comp == null)     return EXIT_SYSERR;
    Log log=Log.instance(context);
    if (!files.isEmpty()) {
      comp=JavaCompiler.instance(context);
      List<JavaFileObject> otherFiles=List.nil();
      JavacFileManager dfm=(JavacFileManager)fileManager;
      for (      JavaFileObject fo : dfm.getJavaFileObjectsFromFiles(files))       otherFiles=otherFiles.prepend(fo);
      for (      JavaFileObject fo : otherFiles)       fileObjects=fileObjects.prepend(fo);
    }
    comp.compile(fileObjects,classnames.toList(),processors);
    if (log.expectDiagKeys != null) {
      if (log.expectDiagKeys.size() == 0) {
        Log.printLines(log.noticeWriter,""String_Node_Str"");
        return EXIT_OK;
      }
 else {
        Log.printLines(log.noticeWriter,""String_Node_Str"" + log.expectDiagKeys);
        return EXIT_ERROR;
      }
    }
    if (comp.errorCount() != 0 || options.get(""String_Node_Str"") != null && comp.warningCount() != 0)     return EXIT_ERROR;
  }
 catch (  IOException ex) {
    ioMessage(ex);
    return EXIT_SYSERR;
  }
catch (  OutOfMemoryError ex) {
    resourceMessage(ex);
    return EXIT_SYSERR;
  }
catch (  StackOverflowError ex) {
    resourceMessage(ex);
    return EXIT_SYSERR;
  }
catch (  FatalError ex) {
    feMessage(ex);
    return EXIT_SYSERR;
  }
catch (  AnnotationProcessingError ex) {
    apMessage(ex);
    return EXIT_SYSERR;
  }
catch (  ClientCodeException ex) {
    throw new RuntimeException(ex.getCause());
  }
catch (  PropagatedException ex) {
    throw ex.getCause();
  }
catch (  Throwable ex) {
    if (comp == null || comp.errorCount() == 0 || options == null || options.get(""String_Node_Str"") != null)     bugMessage(ex);
    return EXIT_ABNORMAL;
  }
 finally {
    if (comp != null)     comp.close();
    filenames=null;
    options=null;
  }
  return EXIT_OK;
}","/** 
 * Programmatic interface for main function.
 * @param args    The command line parameters.
 */
public int compile(String[] args,Context context,List<JavaFileObject> fileObjects,Iterable<? extends Processor> processors){
  if (options == null)   options=Options.instance(context);
  filenames=new ListBuffer<File>();
  classnames=new ListBuffer<String>();
  JavaCompiler comp=null;
  try {
    if (args.length == 0 && fileObjects.isEmpty()) {
      help();
      return EXIT_CMDERR;
    }
    List<File> files;
    try {
      files=processArgs(CommandLine.parse(args));
      if (files == null) {
        return EXIT_CMDERR;
      }
 else       if (files.isEmpty() && fileObjects.isEmpty() && classnames.isEmpty()) {
        if (options.get(""String_Node_Str"") != null || options.get(""String_Node_Str"") != null || options.get(""String_Node_Str"") != null || options.get(""String_Node_Str"") != null)         return EXIT_OK;
        error(""String_Node_Str"");
        return EXIT_CMDERR;
      }
    }
 catch (    java.io.FileNotFoundException e) {
      Log.printLines(out,ownName + ""String_Node_Str"" + getLocalizedString(""String_Node_Str"",e.getMessage()));
      return EXIT_SYSERR;
    }
    boolean forceStdOut=options.get(""String_Node_Str"") != null;
    if (forceStdOut) {
      out.flush();
      out=new PrintWriter(System.out,true);
    }
    context.put(Log.outKey,out);
    boolean batchMode=(options.get(""String_Node_Str"") == null && System.getProperty(""String_Node_Str"") == null);
    if (batchMode)     CacheFSInfo.preRegister(context);
    fileManager=context.get(JavaFileManager.class);
    comp=JavaCompiler.instance(context);
    if (comp == null)     return EXIT_SYSERR;
    Log log=Log.instance(context);
    if (!files.isEmpty()) {
      comp=JavaCompiler.instance(context);
      List<JavaFileObject> otherFiles=List.nil();
      JavacFileManager dfm=(JavacFileManager)fileManager;
      for (      JavaFileObject fo : dfm.getJavaFileObjectsFromFiles(files))       otherFiles=otherFiles.prepend(fo);
      for (      JavaFileObject fo : otherFiles)       fileObjects=fileObjects.prepend(fo);
    }
    comp.compile(fileObjects,classnames.toList(),processors);
    if (log.expectDiagKeys != null) {
      if (log.expectDiagKeys.size() == 0) {
        Log.printLines(log.noticeWriter,""String_Node_Str"");
        return EXIT_OK;
      }
 else {
        Log.printLines(log.noticeWriter,""String_Node_Str"" + log.expectDiagKeys);
        return EXIT_ERROR;
      }
    }
    if (comp.errorCount() != 0)     return EXIT_ERROR;
  }
 catch (  IOException ex) {
    ioMessage(ex);
    return EXIT_SYSERR;
  }
catch (  OutOfMemoryError ex) {
    resourceMessage(ex);
    return EXIT_SYSERR;
  }
catch (  StackOverflowError ex) {
    resourceMessage(ex);
    return EXIT_SYSERR;
  }
catch (  FatalError ex) {
    feMessage(ex);
    return EXIT_SYSERR;
  }
catch (  AnnotationProcessingError ex) {
    apMessage(ex);
    return EXIT_SYSERR;
  }
catch (  ClientCodeException ex) {
    throw new RuntimeException(ex.getCause());
  }
catch (  PropagatedException ex) {
    throw ex.getCause();
  }
catch (  Throwable ex) {
    if (comp == null || comp.errorCount() == 0 || options == null || options.get(""String_Node_Str"") != null)     bugMessage(ex);
    return EXIT_ABNORMAL;
  }
 finally {
    if (comp != null)     comp.close();
    filenames=null;
    options=null;
  }
  return EXIT_OK;
}"
37341,"/** 
 * Get all the recognized options.
 * @param helper an {@code OptionHelper} to help when processing options
 * @return an array of options
 */
public static Option[] getAll(final OptionHelper helper){
  return new Option[]{new Option(G,""String_Node_Str""),new Option(G_NONE,""String_Node_Str""){
    @Override public boolean process(    Options options,    String option){
      options.put(""String_Node_Str"",""String_Node_Str"");
      return false;
    }
  }
,new Option(G_CUSTOM,""String_Node_Str"",Option.ChoiceKind.ANYOF,""String_Node_Str"",""String_Node_Str"",""String_Node_Str""),new XOption(XLINT,""String_Node_Str""),new XOption(XLINT_CUSTOM,""String_Node_Str"",Option.ChoiceKind.ANYOF,getXLintChoices()),new Option(NOWARN,""String_Node_Str""){
    @Override public boolean process(    Options options,    String option){
      options.put(""String_Node_Str"",option);
      return false;
    }
  }
,new Option(VERBOSE,""String_Node_Str""),new Option(DEPRECATION,""String_Node_Str""){
    @Override public boolean process(    Options options,    String option){
      options.put(""String_Node_Str"",option);
      return false;
    }
  }
,new Option(CLASSPATH,""String_Node_Str"",""String_Node_Str""),new Option(CP,""String_Node_Str"",""String_Node_Str""){
    @Override public boolean process(    Options options,    String option,    String arg){
      return super.process(options,""String_Node_Str"",arg);
    }
  }
,new Option(SOURCEPATH,""String_Node_Str"",""String_Node_Str""),new Option(BOOTCLASSPATH,""String_Node_Str"",""String_Node_Str""){
    @Override public boolean process(    Options options,    String option,    String arg){
      options.remove(""String_Node_Str"");
      options.remove(""String_Node_Str"");
      return super.process(options,option,arg);
    }
  }
,new XOption(XBOOTCLASSPATH_PREPEND,""String_Node_Str"",""String_Node_Str""),new XOption(XBOOTCLASSPATH_APPEND,""String_Node_Str"",""String_Node_Str""),new XOption(XBOOTCLASSPATH,""String_Node_Str"",""String_Node_Str""){
    @Override public boolean process(    Options options,    String option,    String arg){
      options.remove(""String_Node_Str"");
      options.remove(""String_Node_Str"");
      return super.process(options,""String_Node_Str"",arg);
    }
  }
,new Option(EXTDIRS,""String_Node_Str"",""String_Node_Str""),new XOption(DJAVA_EXT_DIRS,""String_Node_Str"",""String_Node_Str""){
    @Override public boolean process(    Options options,    String option,    String arg){
      return super.process(options,""String_Node_Str"",arg);
    }
  }
,new Option(ENDORSEDDIRS,""String_Node_Str"",""String_Node_Str""),new XOption(DJAVA_ENDORSED_DIRS,""String_Node_Str"",""String_Node_Str""){
    @Override public boolean process(    Options options,    String option,    String arg){
      return super.process(options,""String_Node_Str"",arg);
    }
  }
,new Option(PROC,""String_Node_Str"",Option.ChoiceKind.ONEOF,""String_Node_Str"",""String_Node_Str""),new Option(PROCESSOR,""String_Node_Str"",""String_Node_Str""),new Option(PROCESSORPATH,""String_Node_Str"",""String_Node_Str""),new Option(D,""String_Node_Str"",""String_Node_Str""),new Option(S,""String_Node_Str"",""String_Node_Str""),new Option(IMPLICIT,""String_Node_Str"",Option.ChoiceKind.ONEOF,""String_Node_Str"",""String_Node_Str""),new Option(ENCODING,""String_Node_Str"",""String_Node_Str""),new Option(SOURCE,""String_Node_Str"",""String_Node_Str""){
    @Override public boolean process(    Options options,    String option,    String operand){
      Source source=Source.lookup(operand);
      if (source == null) {
        helper.error(""String_Node_Str"",operand);
        return true;
      }
      return super.process(options,option,operand);
    }
  }
,new Option(TARGET,""String_Node_Str"",""String_Node_Str""){
    @Override public boolean process(    Options options,    String option,    String operand){
      Target target=Target.lookup(operand);
      if (target == null) {
        helper.error(""String_Node_Str"",operand);
        return true;
      }
      return super.process(options,option,operand);
    }
  }
,new Option(VERSION,""String_Node_Str""){
    @Override public boolean process(    Options options,    String option){
      helper.printVersion();
      return super.process(options,option);
    }
  }
,new HiddenOption(FULLVERSION){
    @Override public boolean process(    Options options,    String option){
      helper.printFullVersion();
      return super.process(options,option);
    }
  }
,new Option(HELP,""String_Node_Str""){
    @Override public boolean process(    Options options,    String option){
      helper.printHelp();
      return super.process(options,option);
    }
  }
,new Option(A,""String_Node_Str"",""String_Node_Str""){
    @Override String helpSynopsis(){
      hasSuffix=true;
      return super.helpSynopsis();
    }
    @Override public boolean matches(    String arg){
      return arg.startsWith(""String_Node_Str"");
    }
    @Override public boolean hasArg(){
      return false;
    }
    @Override public boolean process(    Options options,    String option){
      int argLength=option.length();
      if (argLength == 2) {
        helper.error(""String_Node_Str"");
        return true;
      }
      int sepIndex=option.indexOf('=');
      String key=option.substring(2,(sepIndex != -1 ? sepIndex : argLength));
      if (!JavacProcessingEnvironment.isValidOptionName(key)) {
        helper.error(""String_Node_Str"",option);
        return true;
      }
      return process(options,option,option);
    }
  }
,new Option(X,""String_Node_Str""){
    @Override public boolean process(    Options options,    String option){
      helper.printXhelp();
      return super.process(options,option);
    }
  }
,new Option(J,""String_Node_Str"",""String_Node_Str""){
    @Override String helpSynopsis(){
      hasSuffix=true;
      return super.helpSynopsis();
    }
    @Override public boolean process(    Options options,    String option){
      throw new AssertionError(""String_Node_Str"");
    }
  }
,new HiddenOption(MOREINFO){
    @Override public boolean process(    Options options,    String option){
      Type.moreInfo=true;
      return super.process(options,option);
    }
  }
,new HiddenOption(WERROR),new HiddenOption(COMPLEXINFERENCE),new HiddenOption(PROMPT),new HiddenOption(DOE),new HiddenOption(PRINTSOURCE),new HiddenOption(WARNUNCHECKED){
    @Override public boolean process(    Options options,    String option){
      options.put(""String_Node_Str"",option);
      return false;
    }
  }
,new XOption(XMAXERRS,""String_Node_Str"",""String_Node_Str""),new XOption(XMAXWARNS,""String_Node_Str"",""String_Node_Str""),new XOption(XSTDOUT,""String_Node_Str"",""String_Node_Str""){
    @Override public boolean process(    Options options,    String option,    String arg){
      try {
        helper.setOut(new PrintWriter(new FileWriter(arg),true));
      }
 catch (      java.io.IOException e) {
        helper.error(""String_Node_Str"",arg,e);
        return true;
      }
      return super.process(options,option,arg);
    }
  }
,new XOption(XPRINT,""String_Node_Str""),new XOption(XPRINTROUNDS,""String_Node_Str""),new XOption(XPRINTPROCESSORINFO,""String_Node_Str""),new XOption(XPREFER,""String_Node_Str"",Option.ChoiceKind.ONEOF,""String_Node_Str"",""String_Node_Str""),new HiddenOption(O),new HiddenOption(XJCOV),new HiddenOption(XD){
    String s;
    @Override public boolean matches(    String s){
      this.s=s;
      return s.startsWith(name.optionName);
    }
    @Override public boolean process(    Options options,    String option){
      s=s.substring(name.optionName.length());
      int eq=s.indexOf('=');
      String key=(eq < 0) ? s : s.substring(0,eq);
      String value=(eq < 0) ? s : s.substring(eq + 1);
      options.put(key,value);
      return false;
    }
  }
,new HiddenOption(SOURCEFILE){
    String s;
    @Override public boolean matches(    String s){
      this.s=s;
      return s.endsWith(""String_Node_Str"") || SourceVersion.isName(s);
    }
    @Override public boolean process(    Options options,    String option){
      if (s.endsWith(""String_Node_Str"")) {
        File f=new File(s);
        if (!f.exists()) {
          helper.error(""String_Node_Str"",f);
          return true;
        }
        if (!f.isFile()) {
          helper.error(""String_Node_Str"",f);
          return true;
        }
        helper.addFile(f);
      }
 else       helper.addClassName(s);
      return false;
    }
  }
};
}","/** 
 * Get all the recognized options.
 * @param helper an {@code OptionHelper} to help when processing options
 * @return an array of options
 */
public static Option[] getAll(final OptionHelper helper){
  return new Option[]{new Option(G,""String_Node_Str""),new Option(G_NONE,""String_Node_Str""){
    @Override public boolean process(    Options options,    String option){
      options.put(""String_Node_Str"",""String_Node_Str"");
      return false;
    }
  }
,new Option(G_CUSTOM,""String_Node_Str"",Option.ChoiceKind.ANYOF,""String_Node_Str"",""String_Node_Str"",""String_Node_Str""),new XOption(XLINT,""String_Node_Str""),new XOption(XLINT_CUSTOM,""String_Node_Str"",Option.ChoiceKind.ANYOF,getXLintChoices()),new Option(NOWARN,""String_Node_Str""){
    @Override public boolean process(    Options options,    String option){
      options.put(""String_Node_Str"",option);
      return false;
    }
  }
,new Option(VERBOSE,""String_Node_Str""),new Option(DEPRECATION,""String_Node_Str""){
    @Override public boolean process(    Options options,    String option){
      options.put(""String_Node_Str"",option);
      return false;
    }
  }
,new Option(CLASSPATH,""String_Node_Str"",""String_Node_Str""),new Option(CP,""String_Node_Str"",""String_Node_Str""){
    @Override public boolean process(    Options options,    String option,    String arg){
      return super.process(options,""String_Node_Str"",arg);
    }
  }
,new Option(SOURCEPATH,""String_Node_Str"",""String_Node_Str""),new Option(BOOTCLASSPATH,""String_Node_Str"",""String_Node_Str""){
    @Override public boolean process(    Options options,    String option,    String arg){
      options.remove(""String_Node_Str"");
      options.remove(""String_Node_Str"");
      return super.process(options,option,arg);
    }
  }
,new XOption(XBOOTCLASSPATH_PREPEND,""String_Node_Str"",""String_Node_Str""),new XOption(XBOOTCLASSPATH_APPEND,""String_Node_Str"",""String_Node_Str""),new XOption(XBOOTCLASSPATH,""String_Node_Str"",""String_Node_Str""){
    @Override public boolean process(    Options options,    String option,    String arg){
      options.remove(""String_Node_Str"");
      options.remove(""String_Node_Str"");
      return super.process(options,""String_Node_Str"",arg);
    }
  }
,new Option(EXTDIRS,""String_Node_Str"",""String_Node_Str""),new XOption(DJAVA_EXT_DIRS,""String_Node_Str"",""String_Node_Str""){
    @Override public boolean process(    Options options,    String option,    String arg){
      return super.process(options,""String_Node_Str"",arg);
    }
  }
,new Option(ENDORSEDDIRS,""String_Node_Str"",""String_Node_Str""),new XOption(DJAVA_ENDORSED_DIRS,""String_Node_Str"",""String_Node_Str""){
    @Override public boolean process(    Options options,    String option,    String arg){
      return super.process(options,""String_Node_Str"",arg);
    }
  }
,new Option(PROC,""String_Node_Str"",Option.ChoiceKind.ONEOF,""String_Node_Str"",""String_Node_Str""),new Option(PROCESSOR,""String_Node_Str"",""String_Node_Str""),new Option(PROCESSORPATH,""String_Node_Str"",""String_Node_Str""),new Option(D,""String_Node_Str"",""String_Node_Str""),new Option(S,""String_Node_Str"",""String_Node_Str""),new Option(IMPLICIT,""String_Node_Str"",Option.ChoiceKind.ONEOF,""String_Node_Str"",""String_Node_Str""),new Option(ENCODING,""String_Node_Str"",""String_Node_Str""),new Option(SOURCE,""String_Node_Str"",""String_Node_Str""){
    @Override public boolean process(    Options options,    String option,    String operand){
      Source source=Source.lookup(operand);
      if (source == null) {
        helper.error(""String_Node_Str"",operand);
        return true;
      }
      return super.process(options,option,operand);
    }
  }
,new Option(TARGET,""String_Node_Str"",""String_Node_Str""){
    @Override public boolean process(    Options options,    String option,    String operand){
      Target target=Target.lookup(operand);
      if (target == null) {
        helper.error(""String_Node_Str"",operand);
        return true;
      }
      return super.process(options,option,operand);
    }
  }
,new Option(VERSION,""String_Node_Str""){
    @Override public boolean process(    Options options,    String option){
      helper.printVersion();
      return super.process(options,option);
    }
  }
,new HiddenOption(FULLVERSION){
    @Override public boolean process(    Options options,    String option){
      helper.printFullVersion();
      return super.process(options,option);
    }
  }
,new Option(HELP,""String_Node_Str""){
    @Override public boolean process(    Options options,    String option){
      helper.printHelp();
      return super.process(options,option);
    }
  }
,new Option(A,""String_Node_Str"",""String_Node_Str""){
    @Override String helpSynopsis(){
      hasSuffix=true;
      return super.helpSynopsis();
    }
    @Override public boolean matches(    String arg){
      return arg.startsWith(""String_Node_Str"");
    }
    @Override public boolean hasArg(){
      return false;
    }
    @Override public boolean process(    Options options,    String option){
      int argLength=option.length();
      if (argLength == 2) {
        helper.error(""String_Node_Str"");
        return true;
      }
      int sepIndex=option.indexOf('=');
      String key=option.substring(2,(sepIndex != -1 ? sepIndex : argLength));
      if (!JavacProcessingEnvironment.isValidOptionName(key)) {
        helper.error(""String_Node_Str"",option);
        return true;
      }
      return process(options,option,option);
    }
  }
,new Option(X,""String_Node_Str""){
    @Override public boolean process(    Options options,    String option){
      helper.printXhelp();
      return super.process(options,option);
    }
  }
,new Option(J,""String_Node_Str"",""String_Node_Str""){
    @Override String helpSynopsis(){
      hasSuffix=true;
      return super.helpSynopsis();
    }
    @Override public boolean process(    Options options,    String option){
      throw new AssertionError(""String_Node_Str"");
    }
  }
,new HiddenOption(MOREINFO){
    @Override public boolean process(    Options options,    String option){
      Type.moreInfo=true;
      return super.process(options,option);
    }
  }
,new Option(WERROR,""String_Node_Str""),new HiddenOption(COMPLEXINFERENCE),new HiddenOption(PROMPT),new HiddenOption(DOE),new HiddenOption(PRINTSOURCE),new HiddenOption(WARNUNCHECKED){
    @Override public boolean process(    Options options,    String option){
      options.put(""String_Node_Str"",option);
      return false;
    }
  }
,new XOption(XMAXERRS,""String_Node_Str"",""String_Node_Str""),new XOption(XMAXWARNS,""String_Node_Str"",""String_Node_Str""),new XOption(XSTDOUT,""String_Node_Str"",""String_Node_Str""){
    @Override public boolean process(    Options options,    String option,    String arg){
      try {
        helper.setOut(new PrintWriter(new FileWriter(arg),true));
      }
 catch (      java.io.IOException e) {
        helper.error(""String_Node_Str"",arg,e);
        return true;
      }
      return super.process(options,option,arg);
    }
  }
,new XOption(XPRINT,""String_Node_Str""),new XOption(XPRINTROUNDS,""String_Node_Str""),new XOption(XPRINTPROCESSORINFO,""String_Node_Str""),new XOption(XPREFER,""String_Node_Str"",Option.ChoiceKind.ONEOF,""String_Node_Str"",""String_Node_Str""),new HiddenOption(O),new HiddenOption(XJCOV),new HiddenOption(XD){
    String s;
    @Override public boolean matches(    String s){
      this.s=s;
      return s.startsWith(name.optionName);
    }
    @Override public boolean process(    Options options,    String option){
      s=s.substring(name.optionName.length());
      int eq=s.indexOf('=');
      String key=(eq < 0) ? s : s.substring(0,eq);
      String value=(eq < 0) ? s : s.substring(eq + 1);
      options.put(key,value);
      return false;
    }
  }
,new HiddenOption(SOURCEFILE){
    String s;
    @Override public boolean matches(    String s){
      this.s=s;
      return s.endsWith(""String_Node_Str"") || SourceVersion.isName(s);
    }
    @Override public boolean process(    Options options,    String option){
      if (s.endsWith(""String_Node_Str"")) {
        File f=new File(s);
        if (!f.exists()) {
          helper.error(""String_Node_Str"",f);
          return true;
        }
        if (!f.isFile()) {
          helper.error(""String_Node_Str"",f);
          return true;
        }
        helper.addFile(f);
      }
 else       helper.addClassName(s);
      return false;
    }
  }
};
}"
37342,"/** 
 * Initializes an APRep object.
 * @param encoding a single DER-encoded value.
 * @exception Asn1Exception if an error occurs while decoding an ASN1 encoded data.
 * @exception IOException if an I/O error occurs while reading encoded data.
 * @exception KrbApErrException if the value read from the DER-encoded datastream does not match the pre-defined value.
 */
private void init(DerValue encoding) throws Asn1Exception, KrbApErrException, IOException {
  if (((encoding.getTag() & (byte)(0x1F)) != Krb5.KRB_AP_REP) || (encoding.isApplication() != true) || (encoding.isConstructed() != true))   throw new Asn1Exception(Krb5.ASN1_BAD_ID);
  DerValue der=encoding.getData().getDerValue();
  if (der.getTag() != DerValue.tag_Sequence)   throw new Asn1Exception(Krb5.ASN1_BAD_ID);
  DerValue subDer=der.getData().getDerValue();
  if ((subDer.getTag() & (byte)0x1F) != (byte)0x00)   throw new Asn1Exception(Krb5.ASN1_BAD_ID);
  pvno=subDer.getData().getBigInteger().intValue();
  if (pvno != Krb5.PVNO)   throw new KrbApErrException(Krb5.KRB_AP_ERR_BADVERSION);
  subDer=der.getData().getDerValue();
  if ((subDer.getTag() & (byte)0x1F) != (byte)0x01)   throw new Asn1Exception(Krb5.ASN1_BAD_ID);
  msgType=subDer.getData().getBigInteger().intValue();
  if (msgType != Krb5.KRB_AP_REP)   throw new KrbApErrException(Krb5.KRB_AP_ERR_MSG_TYPE);
  encPart=EncryptedData.parse(der.getData(),(byte)0x02,false);
  if (der.getData().available() > 0)   throw new Asn1Exception(Krb5.ASN1_BAD_ID);
}","/** 
 * Initializes an APRep object.
 * @param encoding a single DER-encoded value.
 * @exception Asn1Exception if an error occurs while decoding an ASN1 encoded data.
 * @exception IOException if an I/O error occurs while reading encoded data.
 * @exception KrbApErrException if the value read from the DER-encoded datastream does not match the pre-defined value.
 */
private void init(DerValue encoding) throws Asn1Exception, KrbApErrException, IOException {
  if (((encoding.getTag() & (byte)(0x1F)) != Krb5.KRB_AP_REP) || (encoding.isApplication() != true) || (encoding.isConstructed() != true)) {
    throw new Asn1Exception(Krb5.ASN1_BAD_ID);
  }
  DerValue der=encoding.getData().getDerValue();
  if (der.getTag() != DerValue.tag_Sequence) {
    throw new Asn1Exception(Krb5.ASN1_BAD_ID);
  }
  DerValue subDer=der.getData().getDerValue();
  if ((subDer.getTag() & (byte)0x1F) != (byte)0x00) {
    throw new Asn1Exception(Krb5.ASN1_BAD_ID);
  }
  pvno=subDer.getData().getBigInteger().intValue();
  if (pvno != Krb5.PVNO) {
    throw new KrbApErrException(Krb5.KRB_AP_ERR_BADVERSION);
  }
  subDer=der.getData().getDerValue();
  if ((subDer.getTag() & (byte)0x1F) != (byte)0x01) {
    throw new Asn1Exception(Krb5.ASN1_BAD_ID);
  }
  msgType=subDer.getData().getBigInteger().intValue();
  if (msgType != Krb5.KRB_AP_REP) {
    throw new KrbApErrException(Krb5.KRB_AP_ERR_MSG_TYPE);
  }
  encPart=EncryptedData.parse(der.getData(),(byte)0x02,false);
  if (der.getData().available() > 0) {
    throw new Asn1Exception(Krb5.ASN1_BAD_ID);
  }
}"
37343,"/** 
 * Initializes an APRep object.
 * @param encoding a single DER-encoded value.
 * @exception Asn1Exception if an error occurs while decoding an ASN1 encoded data.
 * @exception IOException if an I/O error occurs while reading encoded data.
 * @exception KrbApErrException if the value read from the DER-encoded datastream does not match the pre-defined value.
 */
private void init(DerValue encoding) throws Asn1Exception, KrbApErrException, IOException {
  if (((encoding.getTag() & (byte)(0x1F)) != Krb5.KRB_AP_REP) || (encoding.isApplication() != true) || (encoding.isConstructed() != true))   throw new Asn1Exception(Krb5.ASN1_BAD_ID);
  DerValue der=encoding.getData().getDerValue();
  if (der.getTag() != DerValue.tag_Sequence)   throw new Asn1Exception(Krb5.ASN1_BAD_ID);
  DerValue subDer=der.getData().getDerValue();
  if ((subDer.getTag() & (byte)0x1F) != (byte)0x00)   throw new Asn1Exception(Krb5.ASN1_BAD_ID);
  pvno=subDer.getData().getBigInteger().intValue();
  if (pvno != Krb5.PVNO)   throw new KrbApErrException(Krb5.KRB_AP_ERR_BADVERSION);
  subDer=der.getData().getDerValue();
  if ((subDer.getTag() & (byte)0x1F) != (byte)0x01)   throw new Asn1Exception(Krb5.ASN1_BAD_ID);
  msgType=subDer.getData().getBigInteger().intValue();
  if (msgType != Krb5.KRB_AP_REP)   throw new KrbApErrException(Krb5.KRB_AP_ERR_MSG_TYPE);
  encPart=EncryptedData.parse(der.getData(),(byte)0x02,false);
  if (der.getData().available() > 0)   throw new Asn1Exception(Krb5.ASN1_BAD_ID);
}","/** 
 * Initializes an APRep object.
 * @param encoding a single DER-encoded value.
 * @exception Asn1Exception if an error occurs while decoding an ASN1 encoded data.
 * @exception IOException if an I/O error occurs while reading encoded data.
 * @exception KrbApErrException if the value read from the DER-encoded datastream does not match the pre-defined value.
 */
private void init(DerValue encoding) throws Asn1Exception, KrbApErrException, IOException {
  if (((encoding.getTag() & (byte)(0x1F)) != Krb5.KRB_AP_REP) || (encoding.isApplication() != true) || (encoding.isConstructed() != true)) {
    throw new Asn1Exception(Krb5.ASN1_BAD_ID);
  }
  DerValue der=encoding.getData().getDerValue();
  if (der.getTag() != DerValue.tag_Sequence) {
    throw new Asn1Exception(Krb5.ASN1_BAD_ID);
  }
  DerValue subDer=der.getData().getDerValue();
  if ((subDer.getTag() & (byte)0x1F) != (byte)0x00) {
    throw new Asn1Exception(Krb5.ASN1_BAD_ID);
  }
  pvno=subDer.getData().getBigInteger().intValue();
  if (pvno != Krb5.PVNO) {
    throw new KrbApErrException(Krb5.KRB_AP_ERR_BADVERSION);
  }
  subDer=der.getData().getDerValue();
  if ((subDer.getTag() & (byte)0x1F) != (byte)0x01) {
    throw new Asn1Exception(Krb5.ASN1_BAD_ID);
  }
  msgType=subDer.getData().getBigInteger().intValue();
  if (msgType != Krb5.KRB_AP_REP) {
    throw new KrbApErrException(Krb5.KRB_AP_ERR_MSG_TYPE);
  }
  encPart=EncryptedData.parse(der.getData(),(byte)0x02,false);
  if (der.getData().available() > 0) {
    throw new Asn1Exception(Krb5.ASN1_BAD_ID);
  }
}"
37344,"/** 
 * Validates a user input based on the field's value transformer and its validation rules. Also considers the   {@code required} flag. This methoddirectly updates the  {@code valid} property.
 * @return Returns whether the user input is a valid value or not.
 */
public boolean validate(){
  String newValue=userInput.getValue();
  if (!validateRequired(newValue)) {
    if (isI18N() && requiredErrorKey.get() != null) {
      errorMessageKeys.setAll(requiredErrorKey.get());
    }
 else     if (requiredError.get() != null) {
      errorMessages.setAll(requiredError.get());
    }
    valid.set(false);
    return false;
  }
  V transformedValue;
  try {
    transformedValue=valueTransformer.transform(newValue);
  }
 catch (  Exception e) {
    if (isI18N() && !formatErrorKey.get().isEmpty()) {
      errorMessageKeys.setAll(formatErrorKey.get());
    }
 else     if (!formatError.get().isEmpty()) {
      errorMessages.setAll(formatError.get());
    }
    valid.set(false);
    return false;
  }
  List<String> errorMessages=validators.stream().map(v -> v.validate(transformedValue)).filter(r -> !r.getResult()).map(ValidationResult::getErrorMessage).collect(Collectors.toList());
  if (isI18N()) {
    errorMessageKeys.setAll(errorMessages);
  }
 else {
    this.errorMessages.setAll(errorMessages);
  }
  if (errorMessages.size() > 0) {
    valid.set(false);
    return false;
  }
  valid.set(true);
  return true;
}","/** 
 * Validates a user input based on the field's value transformer and its validation rules. Also considers the   {@code required} flag. This methoddirectly updates the  {@code valid} property.
 * @return Returns whether the user input is a valid value or not.
 */
public boolean validate(){
  String newValue=userInput.getValue();
  if (!validateRequired(newValue)) {
    if (isI18N() && !requiredErrorKey.get().isEmpty()) {
      errorMessageKeys.setAll(requiredErrorKey.get());
    }
 else     if (!requiredError.get().isEmpty()) {
      errorMessages.setAll(requiredError.get());
    }
    valid.set(false);
    return false;
  }
  V transformedValue;
  try {
    transformedValue=valueTransformer.transform(newValue);
  }
 catch (  Exception e) {
    if (isI18N() && !formatErrorKey.get().isEmpty()) {
      errorMessageKeys.setAll(formatErrorKey.get());
    }
 else     if (!formatError.get().isEmpty()) {
      errorMessages.setAll(formatError.get());
    }
    valid.set(false);
    return false;
  }
  List<String> errorMessages=validators.stream().map(v -> v.validate(transformedValue)).filter(r -> !r.getResult()).map(ValidationResult::getErrorMessage).collect(Collectors.toList());
  if (isI18N()) {
    errorMessageKeys.setAll(errorMessages);
  }
 else {
    this.errorMessages.setAll(errorMessages);
  }
  if (errorMessages.size() > 0) {
    valid.set(false);
    return false;
  }
  valid.set(true);
  return true;
}"
37345,"/** 
 * Binds the given items and selection property with the corresponding fields.
 * @param itemsBinding The items property to be bound with.
 * @param selectionBinding The selection property to be bound with.
 * @return Returns the current field to allow for chaining.
 */
public SingleSelectionField<V> bind(ListProperty<V> itemsBinding,ObjectProperty<V> selectionBinding){
  items.bindBidirectional(itemsBinding);
  persistentSelection.unbindBidirectional(selectionBinding);
  return this;
}","/** 
 * Binds the given items and selection property with the corresponding fields.
 * @param itemsBinding The items property to be bound with.
 * @param selectionBinding The selection property to be bound with.
 * @return Returns the current field to allow for chaining.
 */
public SingleSelectionField<V> bind(ListProperty<V> itemsBinding,ObjectProperty<V> selectionBinding){
  items.bindBidirectional(itemsBinding);
  persistentSelection.bindBidirectional(selectionBinding);
  return this;
}"
37346,"/** 
 * Binds the given items and selection property with the corresponding fields.
 * @param itemsBinding The items property to be bound with.
 * @param selectionBinding The selection property to be bound with.
 * @return Returns the current field to allow for chaining.
 */
public MultiSelectionField<V> bind(ListProperty<V> itemsBinding,ListProperty<V> selectionBinding){
  items.bindBidirectional(itemsBinding);
  selection.bindBidirectional(selectionBinding);
  selectionBinding.addListener(externalBindingListener);
  return this;
}","/** 
 * Binds the given items and selection property with the corresponding fields.
 * @param itemsBinding The items property to be bound with.
 * @param selectionBinding The selection property to be bound with.
 * @return Returns the current field to allow for chaining.
 */
public MultiSelectionField<V> bind(ListProperty<V> itemsBinding,ListProperty<V> selectionBinding){
  items.bindBidirectional(itemsBinding);
  selection.bindBidirectional(selectionBinding);
  return this;
}"
37347,"/** 
 * Unbinds the given items and selection property with the corresponding fields.
 * @param itemsBinding The items property to be unbound with.
 * @param selectionBinding The selection property to be unbound with.
 * @return Returns the current field to allow for chaining.
 */
public MultiSelectionField<V> unbind(ListProperty<V> itemsBinding,ListProperty<V> selectionBinding){
  items.unbindBidirectional(itemsBinding);
  selection.unbindBidirectional(selectionBinding);
  selectionBinding.removeListener(externalBindingListener);
  return this;
}","/** 
 * Unbinds the given items and selection property with the corresponding fields.
 * @param itemsBinding The items property to be unbound with.
 * @param selectionBinding The selection property to be unbound with.
 * @return Returns the current field to allow for chaining.
 */
public MultiSelectionField<V> unbind(ListProperty<V> itemsBinding,ListProperty<V> selectionBinding){
  items.unbindBidirectional(itemsBinding);
  selection.unbindBidirectional(selectionBinding);
  return this;
}"
37348,"/** 
 * Binds the given items and selection property with the corresponding fields.
 * @param itemsBinding The items property to be bound with.
 * @param selectionBinding The selection property to be bound with.
 * @return Returns the current field to allow for chaining.
 */
public SingleSelectionField<V> bind(ListProperty<V> itemsBinding,ObjectProperty<V> selectionBinding){
  items.bindBidirectional(itemsBinding);
  selection.bindBidirectional(selectionBinding);
  selectionBinding.addListener(externalBindingListener);
  return this;
}","/** 
 * Binds the given items and selection property with the corresponding fields.
 * @param itemsBinding The items property to be bound with.
 * @param selectionBinding The selection property to be bound with.
 * @return Returns the current field to allow for chaining.
 */
public SingleSelectionField<V> bind(ListProperty<V> itemsBinding,ObjectProperty<V> selectionBinding){
  items.bindBidirectional(itemsBinding);
  selection.bindBidirectional(selectionBinding);
  return this;
}"
37349,"/** 
 * Unbinds the given items and selection property with the corresponding fields.
 * @param itemsBinding The items property to be unbound with.
 * @param selectionBinding The selection property to be unbound with.
 * @return Returns the current field to allow for chaining.
 */
public SingleSelectionField<V> unbind(ListProperty<V> itemsBinding,ObjectProperty<V> selectionBinding){
  items.unbindBidirectional(itemsBinding);
  selection.unbindBidirectional(selectionBinding);
  selectionBinding.removeListener(externalBindingListener);
  return this;
}","/** 
 * Unbinds the given items and selection property with the corresponding fields.
 * @param itemsBinding The items property to be unbound with.
 * @param selectionBinding The selection property to be unbound with.
 * @return Returns the current field to allow for chaining.
 */
public SingleSelectionField<V> unbind(ListProperty<V> itemsBinding,ObjectProperty<V> selectionBinding){
  items.unbindBidirectional(itemsBinding);
  selection.unbindBidirectional(selectionBinding);
  return this;
}"
37350,"/** 
 * The constructor of   {@code MultiSelectionField}.
 * @param items The property that is used to store the items of the field.
 * @param selection The list of indices of items that are to be selected.
 */
MultiSelectionField(ListProperty<V> items,List<Integer> selection){
  super(items);
  selection.forEach(i -> {
    if (i < this.items.size() && i >= 0) {
      this.selection.add(this.items.get(i));
    }
  }
);
  persistentSelection.addAll(this.selection.getValue());
  changed.bind(Bindings.createBooleanBinding(() -> !persistentSelection.equals(this.selection),persistentSelection,this.selection));
  this.persistentSelection.addListener((observable,oldValue,newValue) -> {
    if (validate()) {
      this.selection.setValue(newValue);
    }
  }
);
  items.addListener((observable,oldValue,newValue) -> {
    this.selection.clear();
    persistentSelection.clear();
  }
);
  renderer=new SimpleListViewControl<>();
}","/** 
 * The constructor of   {@code MultiSelectionField}.
 * @param items The property that is used to store the items of the field.
 * @param selection The list of indices of items that are to be selected.
 */
MultiSelectionField(ListProperty<V> items,List<Integer> selection){
  super(items);
  selection.forEach(i -> {
    if (i < this.items.size() && i >= 0) {
      this.selection.add(this.items.get(i));
    }
  }
);
  persistentSelection.addAll(this.selection.getValue());
  changed.bind(Bindings.createBooleanBinding(() -> !persistentSelection.equals(this.selection),this.selection,persistentSelection));
  this.persistentSelection.addListener((observable,oldValue,newValue) -> {
    if (validate()) {
      this.selection.setValue(newValue);
    }
  }
);
  items.addListener((observable,oldValue,newValue) -> {
    this.selection.clear();
    persistentSelection.clear();
  }
);
  renderer=new SimpleListViewControl<>();
}"
37351,"/** 
 * Binds the given items and selection property with the corresponding fields.
 * @param itemsBinding The items property to be bound with.
 * @param selectionBinding The selection property to be bound with.
 * @return Returns the current field to allow for chaining.
 */
public MultiSelectionField<V> bind(ListProperty<V> itemsBinding,ListProperty<V> selectionBinding){
  items.bindBidirectional(itemsBinding);
  persistentSelection.bindBidirectional(selectionBinding);
  return this;
}","/** 
 * Binds the given items and selection property with the corresponding fields.
 * @param itemsBinding The items property to be bound with.
 * @param selectionBinding The selection property to be bound with.
 * @return Returns the current field to allow for chaining.
 */
public MultiSelectionField<V> bind(ListProperty<V> itemsBinding,ListProperty<V> selectionBinding){
  items.bindBidirectional(itemsBinding);
  selection.bindBidirectional(selectionBinding);
  return this;
}"
37352,"/** 
 * Unbinds the given items and selection property with the corresponding fields.
 * @param itemsBinding The items property to be unbound with.
 * @param selectionBinding The selection property to be unbound with.
 * @return Returns the current field to allow for chaining.
 */
public MultiSelectionField<V> unbind(ListProperty<V> itemsBinding,ListProperty<V> selectionBinding){
  items.unbindBidirectional(itemsBinding);
  persistentSelection.unbindBidirectional(selectionBinding);
  return this;
}","/** 
 * Unbinds the given items and selection property with the corresponding fields.
 * @param itemsBinding The items property to be unbound with.
 * @param selectionBinding The selection property to be unbound with.
 * @return Returns the current field to allow for chaining.
 */
public MultiSelectionField<V> unbind(ListProperty<V> itemsBinding,ListProperty<V> selectionBinding){
  items.unbindBidirectional(itemsBinding);
  selection.unbindBidirectional(selectionBinding);
  return this;
}"
37353,"/** 
 * {@inheritDoc}
 */
boolean validateRequired(){
  return !isRequired() || selection.size() > 0;
}","/** 
 * {@inheritDoc}
 */
boolean validateRequired(){
  return !isRequired() || (isRequired() && selection.size() > 0);
}"
37354,"/** 
 * The constructor of   {@code SingleSelectionField}.
 * @param items The property that is used to store the items of the field.
 * @param selection The index of the item that is to be selected.
 */
SingleSelectionField(ListProperty<V> items,int selection){
  super(items);
  if (selection < items.size() && selection >= 0) {
    this.selection.set(this.items.get(selection));
    persistentSelection.setValue(this.selection.getValue());
  }
  changed.bind(Bindings.createBooleanBinding(() -> persistentSelection.get() == null ? this.selection.get() != null : !persistentSelection.get().equals(this.selection.get()),persistentSelection,this.selection));
  this.persistentSelection.addListener((observable,oldValue,newValue) -> {
    if (validate()) {
      this.selection.setValue(newValue);
    }
  }
);
  items.addListener((observable,oldValue,newValue) -> {
    this.selection.setValue(null);
    persistentSelection.setValue(null);
  }
);
  renderer=new SimpleComboBoxControl<>();
}","/** 
 * The constructor of   {@code SingleSelectionField}.
 * @param items The property that is used to store the items of the field.
 * @param selection The index of the item that is to be selected.
 */
SingleSelectionField(ListProperty<V> items,int selection){
  super(items);
  if (selection < items.size() && selection >= 0) {
    this.selection.set(this.items.get(selection));
    persistentSelection.setValue(this.selection.getValue());
  }
  changed.bind(Bindings.createBooleanBinding(() -> persistentSelection.get() == null ? this.selection.get() != null : !persistentSelection.get().equals(this.selection.get()),this.selection,persistentSelection));
  this.persistentSelection.addListener((observable,oldValue,newValue) -> {
    if (validate()) {
      this.selection.setValue(newValue);
    }
  }
);
  items.addListener((observable,oldValue,newValue) -> {
    this.selection.setValue(null);
    persistentSelection.setValue(null);
  }
);
  renderer=new SimpleComboBoxControl<>();
}"
37355,"/** 
 * Binds the given items and selection property with the corresponding fields.
 * @param itemsBinding The items property to be bound with.
 * @param selectionBinding The selection property to be bound with.
 * @return Returns the current field to allow for chaining.
 */
public SingleSelectionField<V> bind(ListProperty<V> itemsBinding,ObjectProperty<V> selectionBinding){
  items.bindBidirectional(itemsBinding);
  persistentSelection.bindBidirectional(selectionBinding);
  return this;
}","/** 
 * Binds the given items and selection property with the corresponding fields.
 * @param itemsBinding The items property to be bound with.
 * @param selectionBinding The selection property to be bound with.
 * @return Returns the current field to allow for chaining.
 */
public SingleSelectionField<V> bind(ListProperty<V> itemsBinding,ObjectProperty<V> selectionBinding){
  items.bindBidirectional(itemsBinding);
  selection.bindBidirectional(selectionBinding);
  return this;
}"
37356,"/** 
 * Unbinds the given items and selection property with the corresponding fields.
 * @param itemsBinding The items property to be unbound with.
 * @param selectionBinding The selection property to be unbound with.
 * @return Returns the current field to allow for chaining.
 */
public SingleSelectionField<V> unbind(ListProperty<V> itemsBinding,ObjectProperty<V> selectionBinding){
  items.unbindBidirectional(itemsBinding);
  persistentSelection.unbindBidirectional(selectionBinding);
  return this;
}","/** 
 * Unbinds the given items and selection property with the corresponding fields.
 * @param itemsBinding The items property to be unbound with.
 * @param selectionBinding The selection property to be unbound with.
 * @return Returns the current field to allow for chaining.
 */
public SingleSelectionField<V> unbind(ListProperty<V> itemsBinding,ObjectProperty<V> selectionBinding){
  items.unbindBidirectional(itemsBinding);
  selection.unbindBidirectional(selectionBinding);
  return this;
}"
37357,"/** 
 * {@inheritDoc}
 */
boolean validateRequired(){
  return !isRequired() || selection.get() != null;
}","/** 
 * {@inheritDoc}
 */
boolean validateRequired(){
  return !isRequired() || (isRequired() && selection.get() != null);
}"
37358,"/** 
 * Binds the given items and selection property with the corresponding fields.
 * @param itemsBinding The items property to be bound with.
 * @param selectionBinding The selection property to be bound with.
 * @return Returns the current field to allow for chaining.
 */
public MultiSelectionField<V> bind(ListProperty<V> itemsBinding,ListProperty<V> selectionBinding){
  items.bindBidirectional(itemsBinding);
  persistentSelection.unbindBidirectional(selectionBinding);
  return this;
}","/** 
 * Binds the given items and selection property with the corresponding fields.
 * @param itemsBinding The items property to be bound with.
 * @param selectionBinding The selection property to be bound with.
 * @return Returns the current field to allow for chaining.
 */
public MultiSelectionField<V> bind(ListProperty<V> itemsBinding,ListProperty<V> selectionBinding){
  items.bindBidirectional(itemsBinding);
  persistentSelection.bindBidirectional(selectionBinding);
  return this;
}"
37359,"/** 
 * The constructor of   {@code MultiSelectionField}.
 * @param items The property that is used to store the items of the field.
 * @param selection The list of indices of items that are to be selected.
 */
MultiSelectionField(ListProperty<V> items,List<Integer> selection){
  super(items);
  selection.forEach(i -> {
    if (i < this.items.size() && i >= 0) {
      this.selection.add(this.items.get(i));
    }
  }
);
  persistentSelection.addAll(this.selection.getValue());
  changed.bind(Bindings.createBooleanBinding(() -> !persistentSelection.equals(this.selection),this.selection,persistentSelection));
  this.persistentSelection.addListener((observable,oldValue,newValue) -> {
    if (validate()) {
      this.selection.setValue(newValue);
    }
  }
);
  items.addListener((observable,oldValue,newValue) -> {
    this.selection.clear();
    persistentSelection.clear();
  }
);
  renderer=new SimpleListViewControl<>();
}","/** 
 * The constructor of   {@code MultiSelectionField}.
 * @param items The property that is used to store the items of the field.
 * @param selection The list of indices of items that are to be selected.
 */
MultiSelectionField(ListProperty<V> items,List<Integer> selection){
  super(items);
  selection.forEach(i -> {
    if (i < this.items.size() && i >= 0) {
      this.selection.add(this.items.get(i));
    }
  }
);
  persistentSelection.addAll(this.selection.getValue());
  changed.bind(Bindings.createBooleanBinding(() -> !persistentSelection.equals(this.selection),this.selection,persistentSelection));
  this.selection.addListener((observable,oldValue,newValue) -> validate());
  items.addListener((observable,oldValue,newValue) -> {
    this.selection.clear();
    persistentSelection.clear();
  }
);
  renderer=new SimpleListViewControl<>();
}"
37360,"/** 
 * The constructor of   {@code SingleSelectionField}.
 * @param items The property that is used to store the items of the field.
 * @param selection The index of the item that is to be selected.
 */
SingleSelectionField(ListProperty<V> items,int selection){
  super(items);
  if (selection < items.size() && selection >= 0) {
    this.selection.set(this.items.get(selection));
    persistentSelection.setValue(this.selection.getValue());
  }
  changed.bind(Bindings.createBooleanBinding(() -> persistentSelection.get() == null ? this.selection.get() != null : !persistentSelection.get().equals(this.selection.get()),this.selection,persistentSelection));
  this.persistentSelection.addListener((observable,oldValue,newValue) -> {
    if (validate()) {
      this.selection.setValue(newValue);
    }
  }
);
  items.addListener((observable,oldValue,newValue) -> {
    this.selection.setValue(null);
    persistentSelection.setValue(null);
  }
);
  renderer=new SimpleComboBoxControl<>();
}","/** 
 * The constructor of   {@code SingleSelectionField}.
 * @param items The property that is used to store the items of the field.
 * @param selection The index of the item that is to be selected.
 */
SingleSelectionField(ListProperty<V> items,int selection){
  super(items);
  if (selection < items.size() && selection >= 0) {
    this.selection.set(this.items.get(selection));
    persistentSelection.setValue(this.selection.getValue());
  }
  changed.bind(Bindings.createBooleanBinding(() -> persistentSelection.get() == null ? this.selection.get() != null : !persistentSelection.get().equals(this.selection.get()),this.selection,persistentSelection));
  this.selection.addListener((observable,oldValue,newValue) -> validate());
  items.addListener((observable,oldValue,newValue) -> {
    this.selection.setValue(null);
    persistentSelection.setValue(null);
  }
);
  renderer=new SimpleComboBoxControl<>();
}"
37361,"/** 
 * The constructor of   {@code SingleSelectionField}.
 * @param items The property that is used to store the items of the field.
 * @param selection The index of the item that is to be selected.
 */
SingleSelectionField(ListProperty<V> items,int selection){
  super(items);
  if (selection < items.size() && selection >= 0) {
    this.selection.set(this.items.get(selection));
    persistentSelection.setValue(this.selection.getValue());
  }
  changed.bind(Bindings.createBooleanBinding(() -> persistentSelection.get() == null ? this.selection.get() != null : !persistentSelection.get().equals(this.selection.get()),persistentSelection,this.selection));
  this.selection.addListener((observable,oldValue,newValue) -> validate());
  items.addListener((observable,oldValue,newValue) -> {
    this.selection.setValue(null);
    persistentSelection.setValue(null);
  }
);
  renderer=new SimpleComboBoxControl<>();
}","/** 
 * The constructor of   {@code SingleSelectionField}.
 * @param items The property that is used to store the items of the field.
 * @param selection The index of the item that is to be selected.
 */
SingleSelectionField(ListProperty<V> items,int selection){
  super(items);
  if (selection < items.size() && selection >= 0) {
    this.selection.set(this.items.get(selection));
    persistentSelection.setValue(this.selection.getValue());
  }
  changed.bind(Bindings.createBooleanBinding(() -> persistentSelection.get() == null ? this.selection.get() != null : !persistentSelection.get().equals(this.selection.get()),persistentSelection,this.selection));
  this.selection.addListener((observable,oldValue,newValue) -> {
    if (validate()) {
      this.selection.setValue(newValue);
    }
  }
);
  items.addListener((observable,oldValue,newValue) -> {
    this.selection.setValue(null);
    persistentSelection.setValue(null);
  }
);
  renderer=new SimpleComboBoxControl<>();
}"
37362,"/** 
 * Attach to an existing debuggee VM.
 * @param vmManager the virtual machine manager
 * @param hostName the machine where the debuggee VM is launched on
 * @param port the debug port that the debuggee VM exposed
 * @param attachTimeout the timeout when attaching to the debuggee VM
 * @return an instance of IDebugSession
 * @throws IOException when unable to attach.
 * @throws IllegalConnectorArgumentsException when one of the connector arguments is invalid.
 */
public static IDebugSession attach(VirtualMachineManager vmManager,String hostName,int port,int attachTimeout) throws IOException, IllegalConnectorArgumentsException {
  List<AttachingConnector> connectors=vmManager.attachingConnectors();
  AttachingConnector connector=connectors.get(0);
  Map<String,Argument> arguments=connector.defaultArguments();
  arguments.get(HOSTNAME).setValue(hostName);
  arguments.get(PORT).setValue(String.valueOf(port));
  arguments.get(TIMEOUT).setValue(String.valueOf(attachTimeout));
  return new DebugSession(connector.attach(arguments));
}","/** 
 * Attach to an existing debuggee VM.
 * @param vmManager the virtual machine manager
 * @param hostName the machine where the debuggee VM is launched on
 * @param port the debug port that the debuggee VM exposed
 * @param attachTimeout the timeout when attaching to the debuggee VM
 * @return an instance of IDebugSession
 * @throws IOException when unable to attach.
 * @throws IllegalConnectorArgumentsException when one of the connector arguments is invalid.
 */
public static IDebugSession attach(VirtualMachineManager vmManager,String hostName,int port,int attachTimeout) throws IOException, IllegalConnectorArgumentsException {
  List<AttachingConnector> connectors=vmManager.attachingConnectors();
  AttachingConnector connector=connectors.get(0);
  final String SUN_ATTACH_CONNECTOR=""String_Node_Str"";
  for (  AttachingConnector con : connectors) {
    if (con.getClass().getName().equals(SUN_ATTACH_CONNECTOR)) {
      connector=con;
      break;
    }
  }
  Map<String,Argument> arguments=connector.defaultArguments();
  arguments.get(HOSTNAME).setValue(hostName);
  arguments.get(PORT).setValue(String.valueOf(port));
  arguments.get(TIMEOUT).setValue(String.valueOf(attachTimeout));
  return new DebugSession(connector.attach(arguments));
}"
37363,"private void ensureDebugTarget(VirtualMachine vm,ThreadReference thread,int depth){
  if (debugTarget == null) {
    if (project == null) {
      String projectName=(String)options.get(Constants.PROJECT_NAME);
      if (StringUtils.isBlank(projectName)) {
        findJavaProjectByStackFrame(thread,depth);
      }
 else {
        IJavaProject javaProject=JdtUtils.getJavaProject(projectName);
        if (javaProject == null) {
          throw new IllegalStateException(String.format(""String_Node_Str"",projectName));
        }
        project=javaProject;
      }
    }
    if (launch == null) {
      launch=createILaunchMock(project);
    }
    debugTarget=new JDIDebugTarget(launch,vm,""String_Node_Str"",false,false,null,false){
      @Override protected synchronized void initialize(){
      }
    }
;
  }
}","private void ensureDebugTarget(VirtualMachine vm,ThreadReference thread,int depth){
  if (debugTarget == null) {
    if (project == null) {
      String projectName=(String)options.get(Constants.PROJECT_NAME);
      if (StringUtils.isBlank(projectName)) {
        project=findJavaProjectByStackFrame(thread,depth);
      }
 else {
        IJavaProject javaProject=JdtUtils.getJavaProject(projectName);
        if (javaProject == null) {
          throw new IllegalStateException(String.format(""String_Node_Str"",projectName));
        }
        project=javaProject;
      }
    }
    if (launch == null) {
      launch=createILaunchMock(project);
    }
    debugTarget=new JDIDebugTarget(launch,vm,""String_Node_Str"",false,false,null,false){
      @Override protected synchronized void initialize(){
      }
    }
;
  }
}"
37364,"/** 
 * Prepare a list of java project candidates in workspace which contains the main class.
 * @param mainclass the main class specified by launch.json for finding project candidates
 */
private void initializeProjectCandidates(String mainclass){
  IWorkspaceRoot root=ResourcesPlugin.getWorkspace().getRoot();
  List<IJavaProject> projects=Arrays.stream(root.getProjects()).map(JdtUtils::getJavaProject).filter(p -> {
    try {
      return p != null && p.hasBuildState();
    }
 catch (    Exception e) {
    }
    return false;
  }
).collect(Collectors.toList());
  if (projects.size() > 1 && StringUtils.isNotBlank(mainclass)) {
    projects=Arrays.stream(root.getProjects()).map(JdtUtils::getJavaProject).filter(p -> {
      try {
        return p.findType(mainclass) != null;
      }
 catch (      JavaModelException e) {
      }
      return false;
    }
).collect(Collectors.toList());
    visitedClassNames.add(mainclass);
  }
  if (projects.size() == 1) {
    project=projects.get(0);
  }
  projectCandidates=projects;
}","/** 
 * Prepare a list of java project candidates in workspace which contains the main class.
 * @param mainclass the main class specified by launch.json for finding project candidates
 */
private void initializeProjectCandidates(String mainclass){
  IWorkspaceRoot root=ResourcesPlugin.getWorkspace().getRoot();
  projectCandidates=Arrays.stream(root.getProjects()).map(JdtUtils::getJavaProject).filter(p -> {
    try {
      return p != null && p.hasBuildState();
    }
 catch (    Exception e) {
    }
    return false;
  }
).collect(Collectors.toList());
  if (StringUtils.isNotBlank(mainclass)) {
    filterProjectCandidatesByClass(mainclass);
  }
}"
37365,"private void findJavaProjectByStackFrame(ThreadReference thread,int depth){
  if (projectCandidates == null) {
    initializeProjectCandidates((String)options.get(Constants.MAIN_CLASS));
    if (project != null) {
      return;
    }
  }
  if (projectCandidates.size() == 0) {
    logger.severe(""String_Node_Str"");
    throw new IllegalStateException(""String_Node_Str"");
  }
  try {
    StackFrame sf=thread.frame(depth);
    String typeName=sf.location().method().declaringType().name();
    List<IJavaProject> validProjects=visitedClassNames.contains(typeName) ? projectCandidates : projectCandidates.stream().filter(p -> {
      try {
        return !visitedClassNames.contains(typeName) && p.findType(typeName) != null;
      }
 catch (      Exception e) {
      }
      return false;
    }
).collect(Collectors.toList());
    visitedClassNames.add(typeName);
    if (validProjects.size() == 1) {
      project=validProjects.get(0);
    }
 else     if (validProjects.size() == 0) {
      logger.severe(""String_Node_Str"");
      throw new IllegalStateException(""String_Node_Str"");
    }
 else {
      projectCandidates=validProjects;
      logger.severe(""String_Node_Str"");
      throw new IllegalStateException(""String_Node_Str"");
    }
  }
 catch (  Exception ex) {
  }
  logger.severe(""String_Node_Str"");
  throw new IllegalStateException(""String_Node_Str"");
}","private IJavaProject findJavaProjectByStackFrame(ThreadReference thread,int depth){
  if (projectCandidates == null) {
    initializeProjectCandidates((String)options.get(Constants.MAIN_CLASS));
  }
  if (projectCandidates.size() == 0) {
    logger.severe(""String_Node_Str"");
    throw new IllegalStateException(""String_Node_Str"");
  }
  try {
    StackFrame sf=thread.frame(depth);
    String typeName=sf.location().method().declaringType().name();
    filterProjectCandidatesByClass(typeName);
  }
 catch (  Exception ex) {
    logger.severe(""String_Node_Str"" + ex.getMessage());
    throw new IllegalStateException(""String_Node_Str"");
  }
  if (projectCandidates.size() == 1) {
    return projectCandidates.get(0);
  }
  if (projectCandidates.size() == 0) {
    logger.severe(""String_Node_Str"");
    throw new IllegalStateException(""String_Node_Str"");
  }
 else {
    logger.severe(""String_Node_Str"");
    throw new IllegalStateException(""String_Node_Str"");
  }
}"
37366,"private static String getFileURI(IResource resource){
  URI uri=resource.getLocationURI();
  if (uri != null) {
    String uriString=uri.toString();
    return uriString.replaceFirst(""String_Node_Str"",""String_Node_Str"");
  }
  return null;
}","private static String getFileURI(IResource resource){
  URI uri=resource.getLocationURI();
  if (uri != null) {
    String uriString=uri.toASCIIString();
    return uriString.replaceFirst(""String_Node_Str"",""String_Node_Str"");
  }
  return null;
}"
37367,"@Override public void setExceptionBreakpoints(boolean notifyCaught,boolean notifyUncaught){
  EventRequestManager manager=vm.eventRequestManager();
  ArrayList<ExceptionRequest> legacy=new ArrayList<>(manager.exceptionRequests());
  manager.deleteEventRequests(legacy);
  if (notifyCaught || notifyUncaught) {
    ExceptionRequest request=manager.createExceptionRequest(null,notifyCaught,notifyUncaught);
    request.setSuspendPolicy(EventRequest.SUSPEND_EVENT_THREAD);
    request.enable();
  }
}","@Override public void setExceptionBreakpoints(boolean notifyCaught,boolean notifyUncaught){
  EventRequestManager manager=vm.eventRequestManager();
  ArrayList<ExceptionRequest> legacy=new ArrayList<>(manager.exceptionRequests());
  manager.deleteEventRequests(legacy);
  if (notifyCaught || notifyUncaught) {
    vm.allThreads();
    ExceptionRequest request=manager.createExceptionRequest(null,notifyCaught,notifyUncaught);
    request.setSuspendPolicy(EventRequest.SUSPEND_EVENT_THREAD);
    request.enable();
  }
}"
37368,"private void handleDebugEvent(DebugEvent debugEvent,IDebugSession debugSession,IDebugAdapterContext context){
  Event event=debugEvent.event;
  boolean isImportantEvent=true;
  if (event instanceof VMStartEvent) {
    if (context.isVmStopOnEntry()) {
      DebugUtility.stopOnEntry(debugSession,context.getMainClass()).thenAccept(threadId -> {
        context.getProtocolServer().sendEvent(new Events.StoppedEvent(""String_Node_Str"",threadId));
      }
);
    }
  }
 else   if (event instanceof VMDeathEvent) {
    context.setVmTerminated();
    context.getProtocolServer().sendEvent(new Events.ExitedEvent(0));
  }
 else   if (event instanceof VMDisconnectEvent) {
    context.setVmTerminated();
    context.getProtocolServer().sendEvent(new Events.TerminatedEvent());
    try {
      debugSession.getEventHub().close();
    }
 catch (    Exception e) {
    }
  }
 else   if (event instanceof ThreadStartEvent) {
    ThreadReference startThread=((ThreadStartEvent)event).thread();
    Events.ThreadEvent threadEvent=new Events.ThreadEvent(""String_Node_Str"",startThread.uniqueID());
    context.getProtocolServer().sendEvent(threadEvent);
  }
 else   if (event instanceof ThreadDeathEvent) {
    ThreadReference deathThread=((ThreadDeathEvent)event).thread();
    Events.ThreadEvent threadDeathEvent=new Events.ThreadEvent(""String_Node_Str"",deathThread.uniqueID());
    context.getProtocolServer().sendEvent(threadDeathEvent);
  }
 else   if (event instanceof BreakpointEvent) {
  }
 else   if (event instanceof ExceptionEvent) {
    ThreadReference thread=((ExceptionEvent)event).thread();
    ThreadReference bpThread=((BreakpointEvent)event).thread();
    IEvaluationProvider engine=context.getProvider(IEvaluationProvider.class);
    if (engine.isInEvaluation(bpThread)) {
      return;
    }
    context.getProtocolServer().sendEvent(new Events.StoppedEvent(""String_Node_Str"",thread.uniqueID()));
    debugEvent.shouldResume=false;
  }
 else {
    isImportantEvent=false;
  }
  if (isImportantEvent) {
    UsageDataSession.recordEvent(event);
  }
}","private void handleDebugEvent(DebugEvent debugEvent,IDebugSession debugSession,IDebugAdapterContext context){
  Event event=debugEvent.event;
  boolean isImportantEvent=true;
  if (event instanceof VMStartEvent) {
    if (context.isVmStopOnEntry()) {
      DebugUtility.stopOnEntry(debugSession,context.getMainClass()).thenAccept(threadId -> {
        context.getProtocolServer().sendEvent(new Events.StoppedEvent(""String_Node_Str"",threadId));
      }
);
    }
  }
 else   if (event instanceof VMDeathEvent) {
    context.setVmTerminated();
    context.getProtocolServer().sendEvent(new Events.ExitedEvent(0));
  }
 else   if (event instanceof VMDisconnectEvent) {
    context.setVmTerminated();
    context.getProtocolServer().sendEvent(new Events.TerminatedEvent());
    try {
      debugSession.getEventHub().close();
    }
 catch (    Exception e) {
    }
  }
 else   if (event instanceof ThreadStartEvent) {
    ThreadReference startThread=((ThreadStartEvent)event).thread();
    Events.ThreadEvent threadEvent=new Events.ThreadEvent(""String_Node_Str"",startThread.uniqueID());
    context.getProtocolServer().sendEvent(threadEvent);
  }
 else   if (event instanceof ThreadDeathEvent) {
    ThreadReference deathThread=((ThreadDeathEvent)event).thread();
    Events.ThreadEvent threadDeathEvent=new Events.ThreadEvent(""String_Node_Str"",deathThread.uniqueID());
    context.getProtocolServer().sendEvent(threadDeathEvent);
  }
 else   if (event instanceof BreakpointEvent) {
  }
 else   if (event instanceof ExceptionEvent) {
    ThreadReference thread=((ExceptionEvent)event).thread();
    ThreadReference bpThread=((ExceptionEvent)event).thread();
    IEvaluationProvider engine=context.getProvider(IEvaluationProvider.class);
    if (engine.isInEvaluation(bpThread)) {
      return;
    }
    context.getProtocolServer().sendEvent(new Events.StoppedEvent(""String_Node_Str"",thread.uniqueID()));
    debugEvent.shouldResume=false;
  }
 else {
    isImportantEvent=false;
  }
  if (isImportantEvent) {
    UsageDataSession.recordEvent(event);
  }
}"
37369,"/** 
 * Launches a debuggee in suspend mode.
 * @param vmManager the virtual machine manager.
 * @param mainClass the main class.
 * @param programArguments the program arguments.
 * @param vmArguments the vm arguments.
 * @param modulePaths the module paths.
 * @param classPaths the class paths.
 * @param cwd the working directory of the program.
 * @param envVars array of strings, each element of which has environment variable settings in the format name=value. or null if the subprocess should inherit the environment of the current process.
 * @return an instance of IDebugSession.
 * @throws IOException when unable to launch.
 * @throws IllegalConnectorArgumentsException when one of the arguments is invalid.
 * @throws VMStartException when the debuggee was successfully launched, but terminated with an error before a connection could be established.
 */
public static IDebugSession launch(VirtualMachineManager vmManager,String mainClass,String programArguments,String vmArguments,String modulePaths,String classPaths,String cwd,String[] envVars) throws IOException, IllegalConnectorArgumentsException, VMStartException {
  List<LaunchingConnector> connectors=vmManager.launchingConnectors();
  LaunchingConnector connector=connectors.get(0);
  Map<String,Argument> arguments=connector.defaultArguments();
  arguments.get(SUSPEND).setValue(""String_Node_Str"");
  String options=""String_Node_Str"";
  if (StringUtils.isNotBlank(vmArguments)) {
    options=vmArguments;
  }
  if (StringUtils.isNotBlank(modulePaths)) {
    options+=""String_Node_Str"" + modulePaths + ""String_Node_Str"";
  }
  if (StringUtils.isNotBlank(classPaths)) {
    options+=""String_Node_Str"" + classPaths + ""String_Node_Str"";
  }
  arguments.get(OPTIONS).setValue(options);
  String[] mainClasses=mainClass.split(""String_Node_Str"");
  if (StringUtils.isNotBlank(modulePaths) || mainClasses.length == 2) {
    mainClass=""String_Node_Str"" + mainClass;
  }
  if (StringUtils.isNotBlank(programArguments)) {
    mainClass+=""String_Node_Str"" + programArguments;
  }
  arguments.get(MAIN).setValue(mainClass);
  if (arguments.get(CWD) != null) {
    arguments.get(CWD).setValue(cwd);
  }
  if (arguments.get(ENV) != null) {
    arguments.get(ENV).setValue(encodeArrayArgument(envVars));
  }
  VirtualMachine vm=connector.launch(arguments);
  vm.version();
  return new DebugSession(vm);
}","/** 
 * Launches a debuggee in suspend mode.
 * @param vmManager the virtual machine manager.
 * @param mainClass the main class.
 * @param programArguments the program arguments.
 * @param vmArguments the vm arguments.
 * @param modulePaths the module paths.
 * @param classPaths the class paths.
 * @param cwd the working directory of the program.
 * @param envVars array of strings, each element of which has environment variable settings in the format name=value. or null if the subprocess should inherit the environment of the current process.
 * @return an instance of IDebugSession.
 * @throws IOException when unable to launch.
 * @throws IllegalConnectorArgumentsException when one of the arguments is invalid.
 * @throws VMStartException when the debuggee was successfully launched, but terminated with an error before a connection could be established.
 */
public static IDebugSession launch(VirtualMachineManager vmManager,String mainClass,String programArguments,String vmArguments,String modulePaths,String classPaths,String cwd,String[] envVars) throws IOException, IllegalConnectorArgumentsException, VMStartException {
  List<LaunchingConnector> connectors=vmManager.launchingConnectors();
  LaunchingConnector connector=connectors.get(0);
  final String SUN_LAUNCHING_CONNECTOR=""String_Node_Str"";
  for (  LaunchingConnector con : connectors) {
    if (con.getClass().getName().equals(SUN_LAUNCHING_CONNECTOR)) {
      connector=con;
      break;
    }
  }
  Map<String,Argument> arguments=connector.defaultArguments();
  arguments.get(SUSPEND).setValue(""String_Node_Str"");
  String options=""String_Node_Str"";
  if (StringUtils.isNotBlank(vmArguments)) {
    options=vmArguments;
  }
  if (StringUtils.isNotBlank(modulePaths)) {
    options+=""String_Node_Str"" + modulePaths + ""String_Node_Str"";
  }
  if (StringUtils.isNotBlank(classPaths)) {
    options+=""String_Node_Str"" + classPaths + ""String_Node_Str"";
  }
  arguments.get(OPTIONS).setValue(options);
  String[] mainClasses=mainClass.split(""String_Node_Str"");
  if (StringUtils.isNotBlank(modulePaths) || mainClasses.length == 2) {
    mainClass=""String_Node_Str"" + mainClass;
  }
  if (StringUtils.isNotBlank(programArguments)) {
    mainClass+=""String_Node_Str"" + programArguments;
  }
  arguments.get(MAIN).setValue(mainClass);
  if (arguments.get(CWD) != null) {
    arguments.get(CWD).setValue(cwd);
  }
  if (arguments.get(ENV) != null) {
    arguments.get(ENV).setValue(encodeArrayArgument(envVars));
  }
  VirtualMachine vm=connector.launch(arguments);
  vm.version();
  return new DebugSession(vm);
}"
37370,"private static CompletableFuture<Location> step(ThreadReference thread,IEventHub eventHub,int stepSize,int stepDepth){
  CompletableFuture<Location> future=new CompletableFuture<>();
  StepRequest request=thread.virtualMachine().eventRequestManager().createStepRequest(thread,stepSize,stepDepth);
  eventHub.stepEvents().filter(debugEvent -> request.equals(debugEvent.event.request())).take(1).subscribe(debugEvent -> {
    StepEvent event=(StepEvent)debugEvent.event;
    future.complete(event.location());
    thread.virtualMachine().eventRequestManager().deleteEventRequest(request);
  }
);
  request.setSuspendPolicy(EventRequest.SUSPEND_EVENT_THREAD);
  request.addCountFilter(1);
  request.enable();
  thread.resume();
  return future;
}","private static CompletableFuture<Location> step(ThreadReference thread,IEventHub eventHub,int stepSize,int stepDepth){
  CompletableFuture<Location> future=new CompletableFuture<>();
  StepRequest request=thread.virtualMachine().eventRequestManager().createStepRequest(thread,stepSize,stepDepth);
  eventHub.stepEvents().filter(debugEvent -> request.equals(debugEvent.event.request())).take(1).subscribe(debugEvent -> {
    StepEvent event=(StepEvent)debugEvent.event;
    future.complete(event.location());
    deleteEventRequestSafely(thread.virtualMachine().eventRequestManager(),request);
  }
);
  request.setSuspendPolicy(EventRequest.SUSPEND_EVENT_THREAD);
  request.addCountFilter(1);
  request.enable();
  thread.resume();
  return future;
}"
37371,"private void handleDebugEvent(DebugEvent debugEvent,IDebugSession debugSession,IDebugAdapterContext context){
  Event event=debugEvent.event;
  boolean isImportantEvent=true;
  MethodEntryRequest request=null;
  if (event instanceof VMStartEvent) {
    if (context.isVmStopOnEntry()) {
      EventRequestManager manager=debugSession.getVM().eventRequestManager();
      request=manager.createMethodEntryRequest();
      request.addClassFilter(context.getMainClass());
      request.setSuspendPolicy(EventRequest.SUSPEND_EVENT_THREAD);
      request.enable();
    }
  }
 else   if (event instanceof MethodEntryEvent) {
    Method method=((MethodEntryEvent)event).method();
    if (method.name().equals(""String_Node_Str"") && method.isStatic() && method.isPublic()&& method.signature().equals(""String_Node_Str"")) {
      ThreadReference bpThread=((MethodEntryEvent)event).thread();
      context.sendEvent(new Events.StoppedEvent(""String_Node_Str"",bpThread.uniqueID()));
      debugEvent.shouldResume=false;
      if (request != null) {
        request.disable();
      }
    }
  }
 else   if (event instanceof VMDeathEvent) {
    context.setVmTerminated();
    context.sendEvent(new Events.ExitedEvent(0));
  }
 else   if (event instanceof VMDisconnectEvent) {
    context.setVmTerminated();
    context.sendEvent(new Events.TerminatedEvent());
    try {
      debugSession.getEventHub().close();
    }
 catch (    Exception e) {
    }
  }
 else   if (event instanceof ThreadStartEvent) {
    ThreadReference startThread=((ThreadStartEvent)event).thread();
    Events.ThreadEvent threadEvent=new Events.ThreadEvent(""String_Node_Str"",startThread.uniqueID());
    context.sendEvent(threadEvent);
  }
 else   if (event instanceof ThreadDeathEvent) {
    ThreadReference deathThread=((ThreadDeathEvent)event).thread();
    Events.ThreadEvent threadDeathEvent=new Events.ThreadEvent(""String_Node_Str"",deathThread.uniqueID());
    context.sendEvent(threadDeathEvent);
  }
 else   if (event instanceof BreakpointEvent) {
    if (debugEvent.eventSet.size() > 1 && debugEvent.eventSet.stream().anyMatch(t -> t instanceof StepEvent)) {
    }
 else {
      ThreadReference bpThread=((BreakpointEvent)event).thread();
      context.sendEvent(new Events.StoppedEvent(""String_Node_Str"",bpThread.uniqueID()));
      debugEvent.shouldResume=false;
    }
  }
 else   if (event instanceof StepEvent) {
    ThreadReference stepThread=((StepEvent)event).thread();
    context.sendEvent(new Events.StoppedEvent(""String_Node_Str"",stepThread.uniqueID()));
    debugEvent.shouldResume=false;
  }
 else   if (event instanceof ExceptionEvent) {
    ThreadReference thread=((ExceptionEvent)event).thread();
    context.sendEvent(new Events.StoppedEvent(""String_Node_Str"",thread.uniqueID()));
    debugEvent.shouldResume=false;
  }
 else {
    isImportantEvent=false;
  }
  if (isImportantEvent) {
    UsageDataSession.recordEvent(event);
  }
}","private void handleDebugEvent(DebugEvent debugEvent,IDebugSession debugSession,IDebugAdapterContext context){
  Event event=debugEvent.event;
  boolean isImportantEvent=true;
  if (event instanceof VMStartEvent) {
    if (context.isVmStopOnEntry()) {
      DebugUtility.stopOnEntry(debugSession,context.getMainClass()).thenAccept(threadId -> {
        context.sendEvent(new Events.StoppedEvent(""String_Node_Str"",threadId));
      }
);
    }
  }
 else   if (event instanceof VMDeathEvent) {
    context.setVmTerminated();
    context.sendEvent(new Events.ExitedEvent(0));
  }
 else   if (event instanceof VMDisconnectEvent) {
    context.setVmTerminated();
    context.sendEvent(new Events.TerminatedEvent());
    try {
      debugSession.getEventHub().close();
    }
 catch (    Exception e) {
    }
  }
 else   if (event instanceof ThreadStartEvent) {
    ThreadReference startThread=((ThreadStartEvent)event).thread();
    Events.ThreadEvent threadEvent=new Events.ThreadEvent(""String_Node_Str"",startThread.uniqueID());
    context.sendEvent(threadEvent);
  }
 else   if (event instanceof ThreadDeathEvent) {
    ThreadReference deathThread=((ThreadDeathEvent)event).thread();
    Events.ThreadEvent threadDeathEvent=new Events.ThreadEvent(""String_Node_Str"",deathThread.uniqueID());
    context.sendEvent(threadDeathEvent);
  }
 else   if (event instanceof BreakpointEvent) {
    if (debugEvent.eventSet.size() > 1 && debugEvent.eventSet.stream().anyMatch(t -> t instanceof StepEvent)) {
    }
 else {
      ThreadReference bpThread=((BreakpointEvent)event).thread();
      context.sendEvent(new Events.StoppedEvent(""String_Node_Str"",bpThread.uniqueID()));
      debugEvent.shouldResume=false;
    }
  }
 else   if (event instanceof StepEvent) {
    ThreadReference stepThread=((StepEvent)event).thread();
    context.sendEvent(new Events.StoppedEvent(""String_Node_Str"",stepThread.uniqueID()));
    debugEvent.shouldResume=false;
  }
 else   if (event instanceof ExceptionEvent) {
    ThreadReference thread=((ExceptionEvent)event).thread();
    context.sendEvent(new Events.StoppedEvent(""String_Node_Str"",thread.uniqueID()));
    debugEvent.shouldResume=false;
  }
 else {
    isImportantEvent=false;
  }
  if (isImportantEvent) {
    UsageDataSession.recordEvent(event);
  }
}"
37372,"@Override public void handle(Command command,Arguments arguments,Response response,IDebugAdapterContext context){
  LaunchArguments launchArguments=(LaunchArguments)arguments;
  if (StringUtils.isBlank(launchArguments.mainClass) || (ArrayUtils.isEmpty(launchArguments.modulePaths) && ArrayUtils.isEmpty(launchArguments.classPaths))) {
    AdapterUtils.setErrorResponse(response,ErrorCode.ARGUMENT_MISSING,String.format(""String_Node_Str""));
    return;
  }
  context.setAttached(false);
  context.setSourcePaths(launchArguments.sourcePaths);
  if (StringUtils.isBlank(launchArguments.encoding)) {
    context.setDebuggeeEncoding(StandardCharsets.UTF_8);
  }
 else {
    if (!Charset.isSupported(launchArguments.encoding)) {
      AdapterUtils.setErrorResponse(response,ErrorCode.INVALID_ENCODING,String.format(""String_Node_Str""));
      return;
    }
    context.setDebuggeeEncoding(Charset.forName(launchArguments.encoding));
  }
  if (StringUtils.isBlank(launchArguments.vmArgs)) {
    launchArguments.vmArgs=String.format(""String_Node_Str"",context.getDebuggeeEncoding().name());
  }
 else {
    launchArguments.vmArgs=String.format(""String_Node_Str"",launchArguments.vmArgs,context.getDebuggeeEncoding().name());
  }
  IVirtualMachineManagerProvider vmProvider=context.getProvider(IVirtualMachineManagerProvider.class);
  String[] envVars=null;
  if (launchArguments.env != null && !launchArguments.env.isEmpty()) {
    Map<String,String> environment=new HashMap<>(System.getenv());
    List<String> duplicated=new ArrayList<>();
    for (    Entry<String,String> entry : launchArguments.env.entrySet()) {
      if (environment.containsKey(entry.getKey())) {
        duplicated.add(entry.getKey());
      }
      environment.put(entry.getKey(),entry.getValue());
    }
    if (!duplicated.isEmpty()) {
      logger.warning(String.format(""String_Node_Str"" + ""String_Node_Str"",String.join(""String_Node_Str"",duplicated)));
    }
    envVars=new String[environment.size()];
    int i=0;
    for (    Entry<String,String> entry : environment.entrySet()) {
      envVars[i++]=entry.getKey() + ""String_Node_Str"" + entry.getValue();
    }
  }
  try {
    StringBuilder launchLogs=new StringBuilder();
    launchLogs.append(""String_Node_Str"");
    launchLogs.append(String.format(""String_Node_Str"",launchArguments.mainClass));
    launchLogs.append(String.format(""String_Node_Str"",launchArguments.args));
    launchLogs.append(String.format(""String_Node_Str"",StringUtils.join(launchArguments.modulePaths,File.pathSeparator)));
    launchLogs.append(String.format(""String_Node_Str"",StringUtils.join(launchArguments.classPaths,File.pathSeparator)));
    launchLogs.append(String.format(""String_Node_Str"",launchArguments.vmArgs));
    logger.info(launchLogs.toString());
    IDebugSession debugSession=DebugUtility.launch(vmProvider.getVirtualMachineManager(),launchArguments.mainClass,launchArguments.args,launchArguments.vmArgs,Arrays.asList(launchArguments.modulePaths),Arrays.asList(launchArguments.classPaths),launchArguments.cwd,envVars);
    context.setDebugSession(debugSession);
    context.setVmStopOnEntry(launchArguments.stopOnEntry);
    context.setMainClass(launchArguments.mainClass);
    logger.info(""String_Node_Str"");
    ProcessConsole debuggeeConsole=new ProcessConsole(debugSession.process(),""String_Node_Str"",context.getDebuggeeEncoding());
    debuggeeConsole.onStdout((output) -> {
      context.sendEvent(Events.OutputEvent.createStdoutOutput(output));
    }
);
    debuggeeConsole.onStderr((err) -> {
      context.sendEvent(Events.OutputEvent.createStderrOutput(err));
    }
);
    debuggeeConsole.start();
  }
 catch (  IOException|IllegalConnectorArgumentsException|VMStartException e) {
    AdapterUtils.setErrorResponse(response,ErrorCode.LAUNCH_FAILURE,String.format(""String_Node_Str"",e.toString()));
  }
  ISourceLookUpProvider sourceProvider=context.getProvider(ISourceLookUpProvider.class);
  Map<String,Object> options=new HashMap<>();
  options.put(Constants.DEBUGGEE_ENCODING,context.getDebuggeeEncoding());
  if (launchArguments.projectName != null) {
    options.put(Constants.PROJECTNAME,launchArguments.projectName);
  }
  sourceProvider.initialize(context.getDebugSession(),options);
}","@Override public void handle(Command command,Arguments arguments,Response response,IDebugAdapterContext context){
  LaunchArguments launchArguments=(LaunchArguments)arguments;
  if (StringUtils.isBlank(launchArguments.mainClass) || (ArrayUtils.isEmpty(launchArguments.modulePaths) && ArrayUtils.isEmpty(launchArguments.classPaths))) {
    AdapterUtils.setErrorResponse(response,ErrorCode.ARGUMENT_MISSING,String.format(""String_Node_Str""));
    return;
  }
  context.setAttached(false);
  context.setSourcePaths(launchArguments.sourcePaths);
  if (StringUtils.isBlank(launchArguments.encoding)) {
    context.setDebuggeeEncoding(StandardCharsets.UTF_8);
  }
 else {
    if (!Charset.isSupported(launchArguments.encoding)) {
      AdapterUtils.setErrorResponse(response,ErrorCode.INVALID_ENCODING,String.format(""String_Node_Str""));
      return;
    }
    context.setDebuggeeEncoding(Charset.forName(launchArguments.encoding));
  }
  if (StringUtils.isBlank(launchArguments.vmArgs)) {
    launchArguments.vmArgs=String.format(""String_Node_Str"",context.getDebuggeeEncoding().name());
  }
 else {
    launchArguments.vmArgs=String.format(""String_Node_Str"",launchArguments.vmArgs,context.getDebuggeeEncoding().name());
  }
  IVirtualMachineManagerProvider vmProvider=context.getProvider(IVirtualMachineManagerProvider.class);
  String[] envVars=null;
  if (launchArguments.env != null && !launchArguments.env.isEmpty()) {
    Map<String,String> environment=new HashMap<>(System.getenv());
    List<String> duplicated=new ArrayList<>();
    for (    Entry<String,String> entry : launchArguments.env.entrySet()) {
      if (environment.containsKey(entry.getKey())) {
        duplicated.add(entry.getKey());
      }
      environment.put(entry.getKey(),entry.getValue());
    }
    if (!duplicated.isEmpty()) {
      logger.warning(String.format(""String_Node_Str"" + ""String_Node_Str"",String.join(""String_Node_Str"",duplicated)));
    }
    envVars=new String[environment.size()];
    int i=0;
    for (    Entry<String,String> entry : environment.entrySet()) {
      envVars[i++]=entry.getKey() + ""String_Node_Str"" + entry.getValue();
    }
  }
  try {
    StringBuilder launchLogs=new StringBuilder();
    launchLogs.append(""String_Node_Str"");
    launchLogs.append(String.format(""String_Node_Str"",launchArguments.mainClass));
    launchLogs.append(String.format(""String_Node_Str"",launchArguments.args));
    launchLogs.append(String.format(""String_Node_Str"",StringUtils.join(launchArguments.modulePaths,File.pathSeparator)));
    launchLogs.append(String.format(""String_Node_Str"",StringUtils.join(launchArguments.classPaths,File.pathSeparator)));
    launchLogs.append(String.format(""String_Node_Str"",launchArguments.vmArgs));
    logger.info(launchLogs.toString());
    IDebugSession debugSession=DebugUtility.launch(vmProvider.getVirtualMachineManager(),launchArguments.mainClass,launchArguments.args,launchArguments.vmArgs,Arrays.asList(launchArguments.modulePaths),Arrays.asList(launchArguments.classPaths),launchArguments.cwd,envVars);
    context.setDebugSession(debugSession);
    context.setVmStopOnEntry(launchArguments.stopOnEntry);
    context.setMainClass(parseMainClassWithoutModuleName(launchArguments.mainClass));
    logger.info(""String_Node_Str"");
    ProcessConsole debuggeeConsole=new ProcessConsole(debugSession.process(),""String_Node_Str"",context.getDebuggeeEncoding());
    debuggeeConsole.onStdout((output) -> {
      context.sendEvent(Events.OutputEvent.createStdoutOutput(output));
    }
);
    debuggeeConsole.onStderr((err) -> {
      context.sendEvent(Events.OutputEvent.createStderrOutput(err));
    }
);
    debuggeeConsole.start();
  }
 catch (  IOException|IllegalConnectorArgumentsException|VMStartException e) {
    AdapterUtils.setErrorResponse(response,ErrorCode.LAUNCH_FAILURE,String.format(""String_Node_Str"",e.toString()));
  }
  ISourceLookUpProvider sourceProvider=context.getProvider(ISourceLookUpProvider.class);
  Map<String,Object> options=new HashMap<>();
  options.put(Constants.DEBUGGEE_ENCODING,context.getDebuggeeEncoding());
  if (launchArguments.projectName != null) {
    options.put(Constants.PROJECTNAME,launchArguments.projectName);
  }
  sourceProvider.initialize(context.getDebugSession(),options);
}"
37373,"/** 
 * Decode the encoded string to the original string array by the rules defined in encodeArrayArgument.
 * @param argument the encoded string
 * @return the original string array argument
 */
public static String[] decodeArrayArgument(String argument){
  if (argument == null) {
    return new String[0];
  }
  List<String> result=new ArrayList<>();
  String[] splits=argument.split(""String_Node_Str"");
  for (  String split : splits) {
    try {
      result.add(URLDecoder.decode(split,StandardCharsets.UTF_8.name()));
    }
 catch (    UnsupportedEncodingException e) {
    }
  }
  return result.toArray(new String[0]);
}","/** 
 * Decode the encoded string to the original string array by the rules defined in encodeArrayArgument.
 * @param argument the encoded string
 * @return the original string array argument
 */
public static String[] decodeArrayArgument(String argument){
  if (argument == null) {
    return null;
  }
  List<String> result=new ArrayList<>();
  String[] splits=argument.split(""String_Node_Str"");
  for (  String split : splits) {
    try {
      result.add(URLDecoder.decode(split,StandardCharsets.UTF_8.name()));
    }
 catch (    UnsupportedEncodingException e) {
    }
  }
  return result.toArray(new String[0]);
}"
37374,"private List<ResolutionItem> resolveMainClassCore() throws CoreException {
  IJavaSearchScope searchScope=SearchEngine.createWorkspaceScope();
  SearchPattern pattern=SearchPattern.createPattern(""String_Node_Str"",IJavaSearchConstants.METHOD,IJavaSearchConstants.DECLARATIONS,SearchPattern.R_CASE_SENSITIVE | SearchPattern.R_EXACT_MATCH);
  ArrayList<ResolutionItem> res=new ArrayList<>();
  SearchRequestor requestor=new SearchRequestor(){
    @Override public void acceptSearchMatch(    SearchMatch match){
      Object element=match.getElement();
      if (element instanceof IMethod) {
        IMethod method=(IMethod)element;
        try {
          if (method.isMainMethod()) {
            IResource resource=method.getResource();
            if (resource != null) {
              IProject project=resource.getProject();
              if (project != null) {
                String mainClass=method.getDeclaringType().getFullyQualifiedName();
                IJavaProject javaProject=JdtUtils.getJavaProject(project);
                if (javaProject != null) {
                  String moduleName=JdtUtils.getModuleName(javaProject);
                  if (moduleName != null) {
                    mainClass=moduleName + ""String_Node_Str"" + mainClass;
                  }
                }
                String projectName=ProjectsManager.DEFAULT_PROJECT_NAME.equals(project.getName()) ? null : project.getName();
                res.add(new ResolutionItem(mainClass,projectName));
              }
            }
          }
        }
 catch (        JavaModelException e) {
        }
      }
    }
  }
;
  SearchEngine searchEngine=new SearchEngine();
  try {
    searchEngine.search(pattern,new SearchParticipant[]{SearchEngine.getDefaultSearchParticipant()},searchScope,requestor,null);
  }
 catch (  Exception e) {
  }
  return res.stream().distinct().collect(Collectors.toList());
}","private List<ResolutionItem> resolveMainClassCore() throws CoreException {
  IJavaSearchScope searchScope=SearchEngine.createWorkspaceScope();
  SearchPattern pattern=SearchPattern.createPattern(""String_Node_Str"",IJavaSearchConstants.METHOD,IJavaSearchConstants.DECLARATIONS,SearchPattern.R_CASE_SENSITIVE | SearchPattern.R_EXACT_MATCH);
  ArrayList<ResolutionItem> res=new ArrayList<>();
  SearchRequestor requestor=new SearchRequestor(){
    @Override public void acceptSearchMatch(    SearchMatch match){
      Object element=match.getElement();
      if (element instanceof IMethod) {
        IMethod method=(IMethod)element;
        try {
          if (method.isMainMethod()) {
            IResource resource=method.getResource();
            if (resource != null) {
              IProject project=resource.getProject();
              if (project != null) {
                String mainClass=method.getDeclaringType().getFullyQualifiedName();
                IJavaProject javaProject=JdtUtils.getJavaProject(project);
                if (javaProject != null) {
                  String moduleName=JdtUtils.getModuleName(javaProject);
                  if (moduleName != null) {
                    mainClass=moduleName + ""String_Node_Str"" + mainClass;
                  }
                }
                String projectName=ProjectsManager.DEFAULT_PROJECT_NAME.equals(project.getName()) ? null : project.getName();
                res.add(new ResolutionItem(mainClass,projectName));
              }
            }
          }
        }
 catch (        JavaModelException e) {
        }
      }
    }
  }
;
  SearchEngine searchEngine=new SearchEngine();
  try {
    searchEngine.search(pattern,new SearchParticipant[]{SearchEngine.getDefaultSearchParticipant()},searchScope,requestor,null);
  }
 catch (  Exception e) {
    logger.log(Level.SEVERE,String.format(""String_Node_Str"",e.toString()),e);
  }
  return res.stream().distinct().collect(Collectors.toList());
}"
37375,"@Override public CompletableFuture<List<String>> redefineClasses(){
  return CompletableFuture.supplyAsync(() -> {
    List<String> classNames=new ArrayList();
synchronized (this) {
      classNames.addAll(deltaClassNames);
      doHotCodeReplace(deltaResources,deltaClassNames);
      deltaResources.clear();
      deltaClassNames.clear();
    }
    return classNames;
  }
);
}","@Override public CompletableFuture<List<String>> redefineClasses(){
  return CompletableFuture.supplyAsync(() -> {
    List<String> classNames=new ArrayList<>();
synchronized (this) {
      classNames.addAll(deltaClassNames);
      doHotCodeReplace(deltaResources,deltaClassNames);
      deltaResources.clear();
      deltaClassNames.clear();
    }
    return classNames;
  }
);
}"
37376,"private boolean containsObsoleteMethods() throws DebugException {
  List<ThreadReference> threads=currentDebugSession.getAllThreads();
  for (  ThreadReference thread : threads) {
    if (!thread.isSuspended()) {
      continue;
    }
    List<StackFrame> frames=getStackFrames(thread,false);
    if (frames == null || frames.isEmpty()) {
      continue;
    }
    for (    StackFrame frame : frames) {
      if (StackFrameUtility.isObsolete(frame)) {
        return true;
      }
    }
  }
  return false;
}","private boolean containsObsoleteMethods() throws DebugException {
  List<ThreadReference> threads=currentDebugSession.getAllThreads();
  for (  ThreadReference thread : threads) {
    if (!thread.isSuspended()) {
      continue;
    }
    List<StackFrame> frames=getStackFrames(thread,true);
    if (frames == null || frames.isEmpty()) {
      continue;
    }
    for (    StackFrame frame : frames) {
      if (StackFrameUtility.isObsolete(frame)) {
        return true;
      }
    }
  }
  return false;
}"
37377,"@Override public void setExceptionBreakpoints(boolean notifyCaught,boolean notifyUncaught){
  EventRequestManager manager=vm.eventRequestManager();
  ArrayList<ExceptionRequest> legacy=new ArrayList<>(manager.exceptionRequests());
  manager.deleteEventRequests(legacy);
  ExceptionRequest request=manager.createExceptionRequest(null,notifyCaught,notifyUncaught);
  request.setSuspendPolicy(EventRequest.SUSPEND_EVENT_THREAD);
  request.enable();
}","@Override public void setExceptionBreakpoints(boolean notifyCaught,boolean notifyUncaught){
  EventRequestManager manager=vm.eventRequestManager();
  ArrayList<ExceptionRequest> legacy=new ArrayList<>(manager.exceptionRequests());
  manager.deleteEventRequests(legacy);
  if (notifyCaught || notifyUncaught) {
    ExceptionRequest request=manager.createExceptionRequest(null,notifyCaught,notifyUncaught);
    request.setSuspendPolicy(EventRequest.SUSPEND_EVENT_THREAD);
    request.enable();
  }
}"
37378,"/** 
 * Pop a StackFrame from its thread.
 * @param frame the StackFrame will be popped
 * @return true if succeeded
 */
public static boolean pop(StackFrame frame){
  try {
    frame.thread().popFrames(frame);
  }
 catch (  IncompatibleThreadStateException e) {
    return false;
  }
  return true;
}","/** 
 * Pop a StackFrame from its thread.
 * @param frame the StackFrame will be popped
 */
public static void pop(StackFrame frame) throws DebugException {
  try {
    frame.thread().popFrames(frame);
  }
 catch (  IncompatibleThreadStateException|InvalidStackFrameException e) {
    throw new DebugException(e.getMessage(),e);
  }
}"
37379,"/** 
 * Get java project from type.
 * @param typeFullyQualifiedName fully qualified name of type
 * @return java project
 * @throws CoreException CoreException
 */
private static List<IJavaProject> getJavaProjectFromType(String typeFullyQualifiedName) throws CoreException {
  SearchPattern pattern=SearchPattern.createPattern(typeFullyQualifiedName,IJavaSearchConstants.TYPE,IJavaSearchConstants.DECLARATIONS,SearchPattern.R_EXACT_MATCH);
  IJavaSearchScope scope=SearchEngine.createWorkspaceScope();
  ArrayList<IJavaProject> projects=new ArrayList<>();
  SearchRequestor requestor=new SearchRequestor(){
    @Override public void acceptSearchMatch(    SearchMatch match){
      Object element=match.getElement();
      if (element instanceof IJavaElement) {
        projects.add(((IJavaElement)element).getJavaProject());
      }
    }
  }
;
  SearchEngine searchEngine=new SearchEngine();
  searchEngine.search(pattern,new SearchParticipant[]{SearchEngine.getDefaultSearchParticipant()},scope,requestor,null);
  return projects;
}","/** 
 * Get java project from type.
 * @param typeFullyQualifiedName fully qualified name of type
 * @return java project
 * @throws CoreException CoreException
 */
private static List<IJavaProject> getJavaProjectFromType(String typeFullyQualifiedName) throws CoreException {
  SearchPattern pattern=SearchPattern.createPattern(typeFullyQualifiedName,IJavaSearchConstants.TYPE,IJavaSearchConstants.DECLARATIONS,SearchPattern.R_EXACT_MATCH);
  IJavaSearchScope scope=SearchEngine.createWorkspaceScope();
  ArrayList<IJavaProject> projects=new ArrayList<>();
  SearchRequestor requestor=new SearchRequestor(){
    @Override public void acceptSearchMatch(    SearchMatch match){
      Object element=match.getElement();
      if (element instanceof IJavaElement) {
        projects.add(((IJavaElement)element).getJavaProject());
      }
    }
  }
;
  SearchEngine searchEngine=new SearchEngine();
  searchEngine.search(pattern,new SearchParticipant[]{SearchEngine.getDefaultSearchParticipant()},scope,requestor,null);
  return projects.stream().distinct().collect(Collectors.toList());
}"
37380,"@Override public Object getProperty(Object key){
  return this.propertyMap.get(key);
}","@Override public Object getProperty(Object key){
  return propertyMap.get(key);
}"
37381,"private List<BreakpointRequest> createBreakpointRequests(List<ReferenceType> refTypes,int lineNumber,int hitCount){
  List<Location> locations=collectLocations(refTypes,lineNumber);
  List<Location> existingLocations=new ArrayList<Location>(requests.size());
  Observable.fromIterable(requests).filter(request -> request instanceof BreakpointRequest).map(request -> ((BreakpointRequest)request).location()).toList().subscribe(list -> {
    existingLocations.addAll(list);
  }
);
  List<Location> newLocations=new ArrayList<Location>(locations.size());
  Observable.fromIterable(locations).filter(location -> !existingLocations.contains(location)).toList().subscribe(list -> {
    newLocations.addAll(list);
  }
);
  List<BreakpointRequest> newRequests=new ArrayList<BreakpointRequest>(newLocations.size());
  newLocations.forEach(location -> {
    BreakpointRequest request=vm.eventRequestManager().createBreakpointRequest(location);
    request.setSuspendPolicy(BreakpointRequest.SUSPEND_EVENT_THREAD);
    if (hitCount > 0) {
      request.addCountFilter(hitCount);
    }
    request.enable();
    newRequests.add(request);
  }
);
  return newRequests;
}","private List<BreakpointRequest> createBreakpointRequests(List<ReferenceType> refTypes,int lineNumber,int hitCount){
  List<Location> locations=collectLocations(refTypes,lineNumber);
  List<Location> existingLocations=new ArrayList<>(requests.size());
  Observable.fromIterable(requests).filter(request -> request instanceof BreakpointRequest).map(request -> ((BreakpointRequest)request).location()).toList().subscribe(list -> {
    existingLocations.addAll(list);
  }
);
  List<Location> newLocations=new ArrayList<>(locations.size());
  Observable.fromIterable(locations).filter(location -> !existingLocations.contains(location)).toList().subscribe(list -> {
    newLocations.addAll(list);
  }
);
  List<BreakpointRequest> newRequests=new ArrayList<>(newLocations.size());
  newLocations.forEach(location -> {
    try {
      BreakpointRequest request=vm.eventRequestManager().createBreakpointRequest(location);
      request.setSuspendPolicy(BreakpointRequest.SUSPEND_EVENT_THREAD);
      if (hitCount > 0) {
        request.addCountFilter(hitCount);
      }
      request.enable();
      newRequests.add(request);
    }
 catch (    VMDisconnectedException ex) {
    }
  }
);
  return newRequests;
}"
37382,"@Override public void putProperty(Object key,Object value){
  this.propertyMap.put(key,value);
}","@Override public void putProperty(Object key,Object value){
  propertyMap.put(key,value);
}"
37383,"@Override public CompletableFuture<IBreakpoint> install(){
  ClassPrepareRequest classPrepareRequest=vm.eventRequestManager().createClassPrepareRequest();
  classPrepareRequest.addClassFilter(className);
  classPrepareRequest.enable();
  requests.add(classPrepareRequest);
  ClassPrepareRequest localClassPrepareRequest=vm.eventRequestManager().createClassPrepareRequest();
  localClassPrepareRequest.addClassFilter(className + ""String_Node_Str"");
  localClassPrepareRequest.enable();
  requests.add(localClassPrepareRequest);
  CompletableFuture<IBreakpoint> future=new CompletableFuture<IBreakpoint>();
  Disposable subscription=eventHub.events().filter(debugEvent -> debugEvent.event instanceof ClassPrepareEvent && (classPrepareRequest.equals(debugEvent.event.request()) || localClassPrepareRequest.equals(debugEvent.event.request()))).subscribe(debugEvent -> {
    ClassPrepareEvent event=(ClassPrepareEvent)debugEvent.event;
    List<BreakpointRequest> newRequests=createBreakpointRequests(event.referenceType(),lineNumber,hitCount);
    requests.addAll(newRequests);
    if (!newRequests.isEmpty() && !future.isDone()) {
      this.putProperty(""String_Node_Str"",true);
      future.complete(this);
    }
  }
);
  subscriptions.add(subscription);
  List<ReferenceType> refTypes=vm.classesByName(className);
  List<BreakpointRequest> newRequests=createBreakpointRequests(refTypes,lineNumber,hitCount);
  requests.addAll(newRequests);
  if (!newRequests.isEmpty() && !future.isDone()) {
    this.putProperty(""String_Node_Str"",true);
    future.complete(this);
  }
  return future;
}","@Override public CompletableFuture<IBreakpoint> install(){
  ClassPrepareRequest classPrepareRequest=vm.eventRequestManager().createClassPrepareRequest();
  classPrepareRequest.addClassFilter(className);
  classPrepareRequest.enable();
  requests.add(classPrepareRequest);
  ClassPrepareRequest localClassPrepareRequest=vm.eventRequestManager().createClassPrepareRequest();
  localClassPrepareRequest.addClassFilter(className + ""String_Node_Str"");
  localClassPrepareRequest.enable();
  requests.add(localClassPrepareRequest);
  CompletableFuture<IBreakpoint> future=new CompletableFuture<>();
  Disposable subscription=eventHub.events().filter(debugEvent -> debugEvent.event instanceof ClassPrepareEvent && (classPrepareRequest.equals(debugEvent.event.request()) || localClassPrepareRequest.equals(debugEvent.event.request()))).subscribe(debugEvent -> {
    ClassPrepareEvent event=(ClassPrepareEvent)debugEvent.event;
    List<BreakpointRequest> newRequests=createBreakpointRequests(event.referenceType(),lineNumber,hitCount);
    requests.addAll(newRequests);
    if (!newRequests.isEmpty() && !future.isDone()) {
      this.putProperty(""String_Node_Str"",true);
      future.complete(this);
    }
  }
);
  subscriptions.add(subscription);
  List<ReferenceType> refTypes=vm.classesByName(className);
  List<BreakpointRequest> newRequests=createBreakpointRequests(refTypes,lineNumber,hitCount);
  requests.addAll(newRequests);
  if (!newRequests.isEmpty() && !future.isDone()) {
    this.putProperty(""String_Node_Str"",true);
    future.complete(this);
  }
  return future;
}"
37384,"private static List<Location> collectLocations(List<ReferenceType> refTypes,int lineNumber){
  List<Location> locations=new ArrayList<Location>();
  refTypes.forEach(refType -> {
    locations.addAll(collectLocations(refType,lineNumber));
    locations.addAll(collectLocations(refType.nestedTypes(),lineNumber));
  }
);
  return locations;
}","private static List<Location> collectLocations(List<ReferenceType> refTypes,int lineNumber){
  List<Location> locations=new ArrayList<>();
  try {
    refTypes.forEach(refType -> {
      locations.addAll(collectLocations(refType,lineNumber));
      locations.addAll(collectLocations(refType.nestedTypes(),lineNumber));
    }
);
  }
 catch (  VMDisconnectedException ex) {
  }
  return locations;
}"
37385,"@Override public void resume(){
  for (  ThreadReference tr : DebugUtility.getAllThreadsSafely(this)) {
    while (tr.suspendCount() > 1) {
      tr.resume();
    }
  }
  vm.resume();
}","@Override public void resume(){
  for (  ThreadReference tr : DebugUtility.getAllThreadsSafely(this)) {
    while (!tr.isCollected() && tr.suspendCount() > 1) {
      tr.resume();
    }
  }
  vm.resume();
}"
37386,"@Override public IBreakpoint createBreakpoint(String className,int lineNumber,int hitCount){
  return new Breakpoint(this.vm,this.eventHub(),className,lineNumber,hitCount);
}","@Override public IBreakpoint createBreakpoint(String className,int lineNumber,int hitCount){
  return new Breakpoint(vm,this.eventHub(),className,lineNumber,hitCount);
}"
37387,"@Override public void setExceptionBreakpoints(boolean notifyCaught,boolean notifyUncaught){
  EventRequestManager manager=vm.eventRequestManager();
  ArrayList<ExceptionRequest> legacy=new ArrayList<ExceptionRequest>(manager.exceptionRequests());
  manager.deleteEventRequests(legacy);
  ExceptionRequest request=manager.createExceptionRequest(null,notifyCaught,notifyUncaught);
  request.setSuspendPolicy(EventRequest.SUSPEND_EVENT_THREAD);
  request.enable();
}","@Override public void setExceptionBreakpoints(boolean notifyCaught,boolean notifyUncaught){
  EventRequestManager manager=vm.eventRequestManager();
  ArrayList<ExceptionRequest> legacy=new ArrayList<>(manager.exceptionRequests());
  manager.deleteEventRequests(legacy);
  ExceptionRequest request=manager.createExceptionRequest(null,notifyCaught,notifyUncaught);
  request.setSuspendPolicy(EventRequest.SUSPEND_EVENT_THREAD);
  request.enable();
}"
37388,"/** 
 * Resume the thread the times as it has been suspended.
 * @param thread the thread reference
 */
public static void resumeThread(ThreadReference thread){
  if (thread == null) {
    return;
  }
  int suspends=thread.suspendCount();
  for (int i=0; i < suspends; i++) {
    thread.resume();
  }
}","/** 
 * Resume the thread the times as it has been suspended.
 * @param thread the thread reference
 */
public static void resumeThread(ThreadReference thread){
  if (thread == null || thread.isCollected()) {
    return;
  }
  try {
    int suspends=thread.suspendCount();
    for (int i=0; i < suspends; i++) {
      thread.resume();
    }
  }
 catch (  ObjectCollectedException ex) {
  }
}"
37389,"/** 
 * Get the ThreadReference instance by the thread id.
 * @param debugSession the debug session
 * @param threadId the thread id
 * @return the ThreadReference instance
 */
public static ThreadReference getThread(IDebugSession debugSession,long threadId){
  for (  ThreadReference thread : getAllThreadsSafely(debugSession)) {
    if (thread.uniqueID() == threadId) {
      return thread;
    }
  }
  return null;
}","/** 
 * Get the ThreadReference instance by the thread id.
 * @param debugSession the debug session
 * @param threadId the thread id
 * @return the ThreadReference instance
 */
public static ThreadReference getThread(IDebugSession debugSession,long threadId){
  for (  ThreadReference thread : getAllThreadsSafely(debugSession)) {
    if (thread.uniqueID() == threadId && !thread.isCollected()) {
      return thread;
    }
  }
  return null;
}"
37390,"private static CompletableFuture<Location> step(ThreadReference thread,IEventHub eventHub,int stepSize,int stepDepth){
  CompletableFuture<Location> future=new CompletableFuture<Location>();
  StepRequest request=thread.virtualMachine().eventRequestManager().createStepRequest(thread,stepSize,stepDepth);
  eventHub.stepEvents().filter(debugEvent -> request.equals(debugEvent.event.request())).take(1).subscribe(debugEvent -> {
    StepEvent event=(StepEvent)debugEvent.event;
    future.complete(event.location());
    thread.virtualMachine().eventRequestManager().deleteEventRequest(request);
  }
);
  request.setSuspendPolicy(EventRequest.SUSPEND_EVENT_THREAD);
  request.addCountFilter(1);
  request.enable();
  thread.resume();
  return future;
}","private static CompletableFuture<Location> step(ThreadReference thread,IEventHub eventHub,int stepSize,int stepDepth){
  CompletableFuture<Location> future=new CompletableFuture<>();
  StepRequest request=thread.virtualMachine().eventRequestManager().createStepRequest(thread,stepSize,stepDepth);
  eventHub.stepEvents().filter(debugEvent -> request.equals(debugEvent.event.request())).take(1).subscribe(debugEvent -> {
    StepEvent event=(StepEvent)debugEvent.event;
    future.complete(event.location());
    thread.virtualMachine().eventRequestManager().deleteEventRequest(request);
  }
);
  request.setSuspendPolicy(EventRequest.SUSPEND_EVENT_THREAD);
  request.addCountFilter(1);
  request.enable();
  thread.resume();
  return future;
}"
37391,"/** 
 * Constructor.
 */
public DebugAdapter(BiConsumer<Events.DebugEvent,Boolean> consumer,IProviderContext providerContext){
  this.eventConsumer=consumer;
  this.providerContext=providerContext;
  this.debugContext=new DebugAdapterContext(this);
  this.requestHandlers=new HashMap<>();
  initialize();
}","/** 
 * Constructor.
 */
public DebugAdapter(BiConsumer<Events.DebugEvent,Boolean> consumer,IProviderContext providerContext){
  eventConsumer=consumer;
  this.providerContext=providerContext;
  debugContext=new DebugAdapterContext(this);
  requestHandlers=new HashMap<>();
  initialize();
}"
37392,"/** 
 * Send event to DA immediately.
 * @see ProtocolServer#sendEvent(String,Object)
 */
public void sendEvent(Events.DebugEvent event){
  this.eventConsumer.accept(event,false);
}","/** 
 * Send event to DA immediately.
 * @see ProtocolServer#sendEvent(String,Object)
 */
public void sendEvent(Events.DebugEvent event){
  eventConsumer.accept(event,false);
}"
37393,"@Override public Messages.Response dispatchRequest(Messages.Request request){
  Messages.Response response=new Messages.Response();
  response.request_seq=request.seq;
  response.command=request.command;
  response.success=true;
  Command command=Command.parse(request.command);
  Arguments cmdArgs=JsonUtils.fromJson(request.arguments,command.getArgumentType());
  try {
    List<IDebugRequestHandler> handlers=requestHandlers.get(command);
    if (handlers != null && !handlers.isEmpty()) {
      for (      IDebugRequestHandler handler : handlers) {
        handler.handle(command,cmdArgs,response,this.debugContext);
      }
    }
 else {
      AdapterUtils.setErrorResponse(response,ErrorCode.UNRECOGNIZED_REQUEST_FAILURE,String.format(""String_Node_Str"",request.command));
    }
  }
 catch (  Exception e) {
    logger.log(Level.SEVERE,String.format(""String_Node_Str"",e.toString()),e);
    AdapterUtils.setErrorResponse(response,ErrorCode.UNKNOWN_FAILURE,e.getMessage() != null ? e.getMessage() : e.toString());
  }
  return response;
}","@Override public Messages.Response dispatchRequest(Messages.Request request){
  Messages.Response response=new Messages.Response();
  response.request_seq=request.seq;
  response.command=request.command;
  response.success=true;
  Command command=Command.parse(request.command);
  Arguments cmdArgs=JsonUtils.fromJson(request.arguments,command.getArgumentType());
  try {
    if (debugContext.isVmTerminated()) {
      AdapterUtils.setErrorResponse(response,ErrorCode.VM_TERMINATED,String.format(""String_Node_Str"",request.command));
      return response;
    }
    List<IDebugRequestHandler> handlers=requestHandlers.get(command);
    if (handlers != null && !handlers.isEmpty()) {
      for (      IDebugRequestHandler handler : handlers) {
        handler.handle(command,cmdArgs,response,debugContext);
      }
    }
 else {
      AdapterUtils.setErrorResponse(response,ErrorCode.UNRECOGNIZED_REQUEST_FAILURE,String.format(""String_Node_Str"",request.command));
    }
  }
 catch (  Exception e) {
    logger.log(Level.SEVERE,String.format(""String_Node_Str"",e.toString()),e);
    AdapterUtils.setErrorResponse(response,ErrorCode.UNKNOWN_FAILURE,e.getMessage() != null ? e.getMessage() : e.toString());
  }
  return response;
}"
37394,"/** 
 * Send event to DA after the current dispatching request is resolved.
 * @see ProtocolServer#sendEventLater(String,Object)
 */
public void sendEventLater(Events.DebugEvent event){
  this.eventConsumer.accept(event,true);
}","/** 
 * Send event to DA after the current dispatching request is resolved.
 * @see ProtocolServer#sendEventLater(String,Object)
 */
public void sendEventLater(Events.DebugEvent event){
  eventConsumer.accept(event,true);
}"
37395,"/** 
 * Adds breakpoints to breakpoint manager. Deletes all breakpoints that are no longer listed. In the case of modified source, delete everything.
 * @param source source path of breakpoints
 * @param breakpoints full list of breakpoints that locates in this source file
 * @param sourceModified the source file are modified or not.
 * @return the full breakpoint list that locates in the source file
 */
public IBreakpoint[] setBreakpoints(String source,IBreakpoint[] breakpoints,boolean sourceModified){
  List<IBreakpoint> result=new ArrayList<>();
  HashMap<String,IBreakpoint> breakpointMap=this.sourceToBreakpoints.get(source);
  if (sourceModified && breakpointMap != null) {
    for (    IBreakpoint bp : breakpointMap.values()) {
      try {
        bp.close();
      }
 catch (      Exception e) {
        logger.severe(String.format(""String_Node_Str"",e));
      }
      this.breakpoints.remove(bp);
    }
    this.sourceToBreakpoints.put(source,null);
    breakpointMap=null;
  }
  if (breakpointMap == null) {
    breakpointMap=new HashMap<>();
    this.sourceToBreakpoints.put(source,breakpointMap);
  }
  List<IBreakpoint> toAdd=new ArrayList<>();
  List<Integer> visitedLineNumbers=new ArrayList<>();
  for (  IBreakpoint breakpoint : breakpoints) {
    IBreakpoint existed=breakpointMap.get(String.valueOf(breakpoint.lineNumber()));
    if (existed != null) {
      result.add(existed);
      visitedLineNumbers.add(existed.lineNumber());
      continue;
    }
 else {
      result.add(breakpoint);
    }
    toAdd.add(breakpoint);
  }
  List<IBreakpoint> toRemove=new ArrayList<>();
  for (  IBreakpoint breakpoint : breakpointMap.values()) {
    if (!visitedLineNumbers.contains(breakpoint.lineNumber())) {
      toRemove.add(breakpoint);
    }
  }
  removeBreakpointsInternally(source,toRemove.toArray(new IBreakpoint[0]));
  addBreakpointsInternally(source,toAdd.toArray(new IBreakpoint[0]));
  return result.toArray(new IBreakpoint[0]);
}","/** 
 * Adds breakpoints to breakpoint manager. Deletes all breakpoints that are no longer listed. In the case of modified source, delete everything.
 * @param source source path of breakpoints
 * @param breakpoints full list of breakpoints that locates in this source file
 * @param sourceModified the source file are modified or not.
 * @return the full breakpoint list that locates in the source file
 */
public IBreakpoint[] setBreakpoints(String source,IBreakpoint[] breakpoints,boolean sourceModified){
  List<IBreakpoint> result=new ArrayList<>();
  HashMap<String,IBreakpoint> breakpointMap=this.sourceToBreakpoints.get(source);
  if (sourceModified && breakpointMap != null) {
    for (    IBreakpoint bp : breakpointMap.values()) {
      try {
        bp.close();
      }
 catch (      Exception e) {
        logger.log(Level.SEVERE,String.format(""String_Node_Str"",e.toString()),e);
      }
      this.breakpoints.remove(bp);
    }
    this.sourceToBreakpoints.put(source,null);
    breakpointMap=null;
  }
  if (breakpointMap == null) {
    breakpointMap=new HashMap<>();
    this.sourceToBreakpoints.put(source,breakpointMap);
  }
  List<IBreakpoint> toAdd=new ArrayList<>();
  List<Integer> visitedLineNumbers=new ArrayList<>();
  for (  IBreakpoint breakpoint : breakpoints) {
    IBreakpoint existed=breakpointMap.get(String.valueOf(breakpoint.lineNumber()));
    if (existed != null) {
      result.add(existed);
      visitedLineNumbers.add(existed.lineNumber());
      continue;
    }
 else {
      result.add(breakpoint);
    }
    toAdd.add(breakpoint);
  }
  List<IBreakpoint> toRemove=new ArrayList<>();
  for (  IBreakpoint breakpoint : breakpointMap.values()) {
    if (!visitedLineNumbers.contains(breakpoint.lineNumber())) {
      toRemove.add(breakpoint);
    }
  }
  removeBreakpointsInternally(source,toRemove.toArray(new IBreakpoint[0]));
  addBreakpointsInternally(source,toAdd.toArray(new IBreakpoint[0]));
  return result.toArray(new IBreakpoint[0]);
}"
37396,"/** 
 * Removes the specified breakpoints from breakpoint manager.
 */
private void removeBreakpointsInternally(String source,IBreakpoint[] breakpoints){
  Map<String,IBreakpoint> breakpointMap=this.sourceToBreakpoints.get(source);
  if (breakpointMap == null || breakpointMap.isEmpty() || breakpoints.length == 0) {
    return;
  }
  for (  IBreakpoint breakpoint : breakpoints) {
    if (this.breakpoints.contains(breakpoint)) {
      try {
        breakpoint.close();
        this.breakpoints.remove(breakpoint);
        breakpointMap.remove(String.valueOf(breakpoint.lineNumber()));
      }
 catch (      Exception e) {
        logger.severe(String.format(""String_Node_Str"",e));
      }
    }
  }
}","/** 
 * Removes the specified breakpoints from breakpoint manager.
 */
private void removeBreakpointsInternally(String source,IBreakpoint[] breakpoints){
  Map<String,IBreakpoint> breakpointMap=this.sourceToBreakpoints.get(source);
  if (breakpointMap == null || breakpointMap.isEmpty() || breakpoints.length == 0) {
    return;
  }
  for (  IBreakpoint breakpoint : breakpoints) {
    if (this.breakpoints.contains(breakpoint)) {
      try {
        breakpoint.close();
        this.breakpoints.remove(breakpoint);
        breakpointMap.remove(String.valueOf(breakpoint.lineNumber()));
      }
 catch (      Exception e) {
        logger.log(Level.SEVERE,String.format(""String_Node_Str"",e.toString()),e);
      }
    }
  }
}"
37397,"@Override public Messages.Response dispatchRequest(Messages.Request request){
  Messages.Response response=new Messages.Response();
  response.request_seq=request.seq;
  response.command=request.command;
  response.success=true;
  Command command=Command.parse(request.command);
  Arguments cmdArgs=JsonUtils.fromJson(request.arguments,command.getArgumentType());
  try {
    List<IDebugRequestHandler> handlers=requestHandlers.get(command);
    if (handlers != null && !handlers.isEmpty()) {
      for (      IDebugRequestHandler handler : handlers) {
        handler.handle(command,cmdArgs,response,this.debugContext);
      }
    }
 else {
      AdapterUtils.setErrorResponse(response,ErrorCode.UNRECOGNIZED_REQUEST_FAILURE,String.format(""String_Node_Str"",request.command));
    }
  }
 catch (  Exception e) {
    logger.severe(String.format(""String_Node_Str"",e.toString()));
    AdapterUtils.setErrorResponse(response,ErrorCode.UNKNOWN_FAILURE,e.getMessage() != null ? e.getMessage() : e.toString());
  }
  return response;
}","@Override public Messages.Response dispatchRequest(Messages.Request request){
  Messages.Response response=new Messages.Response();
  response.request_seq=request.seq;
  response.command=request.command;
  response.success=true;
  Command command=Command.parse(request.command);
  Arguments cmdArgs=JsonUtils.fromJson(request.arguments,command.getArgumentType());
  try {
    List<IDebugRequestHandler> handlers=requestHandlers.get(command);
    if (handlers != null && !handlers.isEmpty()) {
      for (      IDebugRequestHandler handler : handlers) {
        handler.handle(command,cmdArgs,response,this.debugContext);
      }
    }
 else {
      AdapterUtils.setErrorResponse(response,ErrorCode.UNRECOGNIZED_REQUEST_FAILURE,String.format(""String_Node_Str"",request.command));
    }
  }
 catch (  Exception e) {
    logger.log(Level.SEVERE,String.format(""String_Node_Str"",e.toString()),e);
    AdapterUtils.setErrorResponse(response,ErrorCode.UNKNOWN_FAILURE,e.getMessage() != null ? e.getMessage() : e.toString());
  }
  return response;
}"
37398,"/** 
 * A while-loop to parse input data and send output data constantly.
 */
public void start(){
  char[] buffer=new char[BUFFER_SIZE];
  try {
    while (!this.terminateSession) {
      int read=this.reader.read(buffer,0,BUFFER_SIZE);
      if (read == -1) {
        break;
      }
      this.rawData.append(new String(buffer,0,read).getBytes(PROTOCOL_ENCODING));
      this.processData();
    }
  }
 catch (  IOException e) {
    logger.severe(String.format(""String_Node_Str"",e));
  }
}","/** 
 * A while-loop to parse input data and send output data constantly.
 */
public void start(){
  char[] buffer=new char[BUFFER_SIZE];
  try {
    while (!this.terminateSession) {
      int read=this.reader.read(buffer,0,BUFFER_SIZE);
      if (read == -1) {
        break;
      }
      this.rawData.append(new String(buffer,0,read).getBytes(PROTOCOL_ENCODING));
      this.processData();
    }
  }
 catch (  IOException e) {
    logger.log(Level.SEVERE,String.format(""String_Node_Str"",e.toString()),e);
  }
}"
37399,"private void sendMessage(Messages.ProtocolMessage message){
  message.seq=this.sequenceNumber.getAndIncrement();
  String jsonMessage=JsonUtils.toJson(message);
  byte[] jsonBytes=jsonMessage.getBytes(PROTOCOL_ENCODING);
  String header=String.format(""String_Node_Str"",jsonBytes.length,TWO_CRLF);
  byte[] headerBytes=header.getBytes(PROTOCOL_ENCODING);
  byte[] data=new byte[headerBytes.length + jsonBytes.length];
  System.arraycopy(headerBytes,0,data,0,headerBytes.length);
  System.arraycopy(jsonBytes,0,data,headerBytes.length,jsonBytes.length);
  String utf8Data=new String(data,PROTOCOL_ENCODING);
  try {
    logger.info(""String_Node_Str"" + new String(data));
    this.writer.write(utf8Data);
    this.writer.flush();
  }
 catch (  IOException e) {
    logger.severe(String.format(""String_Node_Str"",e));
  }
}","private void sendMessage(Messages.ProtocolMessage message){
  message.seq=this.sequenceNumber.getAndIncrement();
  String jsonMessage=JsonUtils.toJson(message);
  byte[] jsonBytes=jsonMessage.getBytes(PROTOCOL_ENCODING);
  String header=String.format(""String_Node_Str"",jsonBytes.length,TWO_CRLF);
  byte[] headerBytes=header.getBytes(PROTOCOL_ENCODING);
  byte[] data=new byte[headerBytes.length + jsonBytes.length];
  System.arraycopy(headerBytes,0,data,0,headerBytes.length);
  System.arraycopy(jsonBytes,0,data,headerBytes.length,jsonBytes.length);
  String utf8Data=new String(data,PROTOCOL_ENCODING);
  try {
    logger.info(""String_Node_Str"" + new String(data));
    this.writer.write(utf8Data);
    this.writer.flush();
  }
 catch (  IOException e) {
    logger.log(Level.SEVERE,String.format(""String_Node_Str"",e.toString()),e);
  }
}"
37400,"private void dispatchRequest(String request){
  try {
    logger.info(""String_Node_Str"" + request);
    Messages.Request message=JsonUtils.fromJson(request,Messages.Request.class);
    if (message.type.equals(""String_Node_Str"")) {
synchronized (this) {
        this.isDispatchingData=true;
      }
      try {
        Messages.Response response=this.debugAdapter.dispatchRequest(message);
        if (message.command.equals(""String_Node_Str"")) {
          this.stop();
        }
        sendMessage(response);
      }
 catch (      Exception e) {
        logger.severe(String.format(""String_Node_Str"",e));
      }
    }
  }
  finally {
synchronized (this) {
      this.isDispatchingData=false;
    }
    while (this.eventQueue.peek() != null) {
      sendMessage(this.eventQueue.poll());
    }
  }
}","private void dispatchRequest(String request){
  try {
    logger.info(""String_Node_Str"" + request);
    Messages.Request message=JsonUtils.fromJson(request,Messages.Request.class);
    if (message.type.equals(""String_Node_Str"")) {
synchronized (this) {
        this.isDispatchingData=true;
      }
      try {
        Messages.Response response=this.debugAdapter.dispatchRequest(message);
        if (message.command.equals(""String_Node_Str"")) {
          this.stop();
        }
        sendMessage(response);
      }
 catch (      Exception e) {
        logger.log(Level.SEVERE,String.format(""String_Node_Str"",e.toString()),e);
      }
    }
  }
  finally {
synchronized (this) {
      this.isDispatchingData=false;
    }
    while (this.eventQueue.peek() != null) {
      sendMessage(this.eventQueue.poll());
    }
  }
}"
37401,"/** 
 * Gets the server port.
 */
public synchronized int getPort(){
  if (this.serverSocket != null) {
    return this.serverSocket.getLocalPort();
  }
  return -1;
}","/** 
 * Gets the server port.
 */
@Override public synchronized int getPort(){
  if (this.serverSocket != null) {
    return this.serverSocket.getLocalPort();
  }
  return -1;
}"
37402,"private synchronized void closeServerSocket(){
  if (serverSocket != null) {
    try {
      logger.info(""String_Node_Str"" + serverSocket.getLocalPort());
      serverSocket.close();
    }
 catch (    IOException e) {
      logger.severe(String.format(""String_Node_Str"",e));
    }
  }
  serverSocket=null;
}","private synchronized void closeServerSocket(){
  if (serverSocket != null) {
    try {
      logger.info(""String_Node_Str"" + serverSocket.getLocalPort());
      serverSocket.close();
    }
 catch (    IOException e) {
      logger.log(Level.SEVERE,String.format(""String_Node_Str"",e.toString()),e);
    }
  }
  serverSocket=null;
}"
37403,"public synchronized void stop(){
  closeServerSocket();
  shutdownConnectionPool(true);
}","@Override public synchronized void stop(){
  closeServerSocket();
  shutdownConnectionPool(true);
}"
37404,"/** 
 * Starts the server if it's not started yet.
 */
public synchronized void start(){
  if (this.serverSocket != null && !this.isStarted) {
    this.isStarted=true;
    this.executor=new ThreadPoolExecutor(0,100,30L,TimeUnit.SECONDS,new SynchronousQueue<Runnable>());
    new Thread(new Runnable(){
      @Override public void run(){
        while (true) {
          try {
            Socket connection=serverSocket.accept();
            executor.submit(createConnectionTask(connection));
          }
 catch (          IOException e1) {
            logger.severe(String.format(""String_Node_Str"",e1));
            closeServerSocket();
            shutdownConnectionPool(false);
            return;
          }
        }
      }
    }
,""String_Node_Str"").start();
  }
}","/** 
 * Starts the server if it's not started yet.
 */
@Override public synchronized void start(){
  if (this.serverSocket != null && !this.isStarted) {
    this.isStarted=true;
    this.executor=new ThreadPoolExecutor(0,100,30L,TimeUnit.SECONDS,new SynchronousQueue<Runnable>());
    new Thread(new Runnable(){
      @Override public void run(){
        while (true) {
          try {
            Socket connection=serverSocket.accept();
            executor.submit(createConnectionTask(connection));
          }
 catch (          IOException e) {
            logger.log(Level.SEVERE,String.format(""String_Node_Str"",e.toString()),e);
            closeServerSocket();
            shutdownConnectionPool(false);
            return;
          }
        }
      }
    }
,""String_Node_Str"").start();
  }
}"
37405,"private Runnable createConnectionTask(Socket connection){
  return new Runnable(){
    public void run(){
      try {
        ProtocolServer protocolServer=new ProtocolServer(connection.getInputStream(),connection.getOutputStream(),JdtProviderContextFactory.createProviderContext());
        protocolServer.start();
      }
 catch (      IOException e) {
        logger.severe(String.format(""String_Node_Str"",e));
      }
 finally {
        logger.info(""String_Node_Str"");
      }
    }
  }
;
}","private Runnable createConnectionTask(Socket connection){
  return new Runnable(){
    @Override public void run(){
      try {
        ProtocolServer protocolServer=new ProtocolServer(connection.getInputStream(),connection.getOutputStream(),JdtProviderContextFactory.createProviderContext());
        protocolServer.start();
      }
 catch (      IOException e) {
        logger.log(Level.SEVERE,String.format(""String_Node_Str"",e.toString()),e);
      }
 finally {
        logger.info(""String_Node_Str"");
      }
    }
  }
;
}"
37406,"public void run(){
  try {
    ProtocolServer protocolServer=new ProtocolServer(connection.getInputStream(),connection.getOutputStream(),JdtProviderContextFactory.createProviderContext());
    protocolServer.start();
  }
 catch (  IOException e) {
    logger.severe(String.format(""String_Node_Str"",e));
  }
 finally {
    logger.info(""String_Node_Str"");
  }
}","@Override public void run(){
  try {
    ProtocolServer protocolServer=new ProtocolServer(connection.getInputStream(),connection.getOutputStream(),JdtProviderContextFactory.createProviderContext());
    protocolServer.start();
  }
 catch (  IOException e) {
    logger.log(Level.SEVERE,String.format(""String_Node_Str"",e.toString()),e);
  }
 finally {
    logger.info(""String_Node_Str"");
  }
}"
37407,"private JavaDebugServer(){
  try {
    this.serverSocket=new ServerSocket(0,1);
  }
 catch (  IOException e) {
    logger.severe(String.format(""String_Node_Str"",e));
  }
}","private JavaDebugServer(){
  try {
    this.serverSocket=new ServerSocket(0,1);
  }
 catch (  IOException e) {
    logger.log(Level.SEVERE,String.format(""String_Node_Str"",e.toString()),e);
  }
}"
37408,"private String searchDeclarationFileByFqn(String fullyQualifiedName){
  String projectName=(String)context.get(Constants.PROJECTNAME);
  try {
    IJavaSearchScope searchScope=projectName != null ? createSearchScope(getJavaProjectFromName(projectName)) : SearchEngine.createWorkspaceScope();
    SearchPattern pattern=SearchPattern.createPattern(fullyQualifiedName,IJavaSearchConstants.TYPE,IJavaSearchConstants.DECLARATIONS,SearchPattern.R_EXACT_MATCH);
    ArrayList<String> uris=new ArrayList<String>();
    SearchRequestor requestor=new SearchRequestor(){
      @Override public void acceptSearchMatch(      SearchMatch match){
        Object element=match.getElement();
        if (element instanceof IType) {
          IType type=(IType)element;
          if (type.isBinary()) {
            try {
              if (type.getSource() != null) {
                uris.add(getFileURI(type.getClassFile()));
              }
            }
 catch (            JavaModelException e) {
            }
          }
 else {
            uris.add(getFileURI(type.getResource()));
          }
        }
      }
    }
;
    SearchEngine searchEngine=new SearchEngine();
    searchEngine.search(pattern,new SearchParticipant[]{SearchEngine.getDefaultSearchParticipant()},searchScope,requestor,null);
    return uris.size() == 0 ? null : uris.get(0);
  }
 catch (  CoreException e) {
    logger.severe(String.format(""String_Node_Str"",e));
  }
  return null;
}","private String searchDeclarationFileByFqn(String fullyQualifiedName){
  String projectName=(String)context.get(Constants.PROJECTNAME);
  try {
    IJavaSearchScope searchScope=projectName != null ? createSearchScope(getJavaProjectFromName(projectName)) : SearchEngine.createWorkspaceScope();
    SearchPattern pattern=SearchPattern.createPattern(fullyQualifiedName,IJavaSearchConstants.TYPE,IJavaSearchConstants.DECLARATIONS,SearchPattern.R_EXACT_MATCH);
    ArrayList<String> uris=new ArrayList<String>();
    SearchRequestor requestor=new SearchRequestor(){
      @Override public void acceptSearchMatch(      SearchMatch match){
        Object element=match.getElement();
        if (element instanceof IType) {
          IType type=(IType)element;
          if (type.isBinary()) {
            try {
              if (type.getSource() != null) {
                uris.add(getFileURI(type.getClassFile()));
              }
            }
 catch (            JavaModelException e) {
            }
          }
 else {
            uris.add(getFileURI(type.getResource()));
          }
        }
      }
    }
;
    SearchEngine searchEngine=new SearchEngine();
    searchEngine.search(pattern,new SearchParticipant[]{SearchEngine.getDefaultSearchParticipant()},searchScope,requestor,null);
    return uris.size() == 0 ? null : uris.get(0);
  }
 catch (  CoreException e) {
    logger.log(Level.SEVERE,String.format(""String_Node_Str"",e.toString()),e);
  }
  return null;
}"
37409,"public boolean supportsRealtimeBreakpointVerification(){
  return true;
}","@Override public boolean supportsRealtimeBreakpointVerification(){
  return true;
}"
37410,"private String getContents(IClassFile cf){
  String source=null;
  if (cf != null) {
    try {
      IBuffer buffer=cf.getBuffer();
      if (buffer != null) {
        source=buffer.getContents();
      }
      if (source == null) {
        source=disassemble(cf);
      }
    }
 catch (    JavaModelException e) {
      logger.severe(String.format(""String_Node_Str"",e));
    }
    if (source == null) {
      source=""String_Node_Str"";
    }
  }
  return source;
}","private String getContents(IClassFile cf){
  String source=null;
  if (cf != null) {
    try {
      IBuffer buffer=cf.getBuffer();
      if (buffer != null) {
        source=buffer.getContents();
      }
      if (source == null) {
        source=disassemble(cf);
      }
    }
 catch (    JavaModelException e) {
      logger.log(Level.SEVERE,String.format(""String_Node_Str"",e.toString()),e);
    }
    if (source == null) {
      source=""String_Node_Str"";
    }
  }
  return source;
}"
37411,"@Override public void handle(Command command,Arguments arguments,Response response,IDebugAdapterContext context){
  if (context.getDebugSession() == null) {
    AdapterUtils.setErrorResponse(response,ErrorCode.EMPTY_DEBUG_SESSION,""String_Node_Str"");
    return;
  }
  SetBreakpointArguments bpArguments=(SetBreakpointArguments)arguments;
  String clientPath=bpArguments.source.path;
  if (AdapterUtils.isWindows()) {
    String drivePrefix=FilenameUtils.getPrefix(clientPath);
    if (drivePrefix != null && drivePrefix.length() >= 2 && Character.isLowerCase(drivePrefix.charAt(0)) && drivePrefix.charAt(1) == ':') {
      drivePrefix=drivePrefix.substring(0,2);
      clientPath=clientPath.replaceFirst(drivePrefix,drivePrefix.toUpperCase());
    }
  }
  String sourcePath=clientPath;
  if (bpArguments.source.sourceReference != 0 && context.getSourceUri(bpArguments.source.sourceReference) != null) {
    sourcePath=context.getSourceUri(bpArguments.source.sourceReference);
  }
 else   if (StringUtils.isNotBlank(clientPath)) {
    sourcePath=AdapterUtils.convertPath(clientPath,AdapterUtils.isUri(clientPath),context.isDebuggerPathsAreUri());
  }
  if (StringUtils.isBlank(sourcePath)) {
    AdapterUtils.setErrorResponse(response,ErrorCode.SET_BREAKPOINT_FAILURE,String.format(""String_Node_Str"",bpArguments.source.path));
    return;
  }
  try {
    List<Types.Breakpoint> res=new ArrayList<>();
    IBreakpoint[] toAdds=this.convertClientBreakpointsToDebugger(sourcePath,bpArguments.breakpoints,context);
    IBreakpoint[] added=manager.setBreakpoints(sourcePath,toAdds,bpArguments.sourceModified);
    for (int i=0; i < bpArguments.breakpoints.length; i++) {
      if (toAdds[i] == added[i] && added[i].className() != null) {
        added[i].install().thenAccept(bp -> {
          Events.BreakpointEvent bpEvent=new Events.BreakpointEvent(""String_Node_Str"",this.convertDebuggerBreakpointToClient(bp,context));
          context.sendEventAsync(bpEvent);
        }
);
      }
 else       if (toAdds[i].hitCount() != added[i].hitCount() && added[i].className() != null) {
        added[i].setHitCount(toAdds[i].hitCount());
      }
      res.add(this.convertDebuggerBreakpointToClient(added[i],context));
    }
    response.body=new Responses.SetBreakpointsResponseBody(res);
  }
 catch (  DebugException e) {
    AdapterUtils.setErrorResponse(response,ErrorCode.SET_BREAKPOINT_FAILURE,String.format(""String_Node_Str"",e.toString()));
  }
}","@Override public void handle(Command command,Arguments arguments,Response response,IDebugAdapterContext context){
  if (context.getDebugSession() == null) {
    AdapterUtils.setErrorResponse(response,ErrorCode.EMPTY_DEBUG_SESSION,""String_Node_Str"");
    return;
  }
  SetBreakpointArguments bpArguments=(SetBreakpointArguments)arguments;
  String clientPath=bpArguments.source.path;
  if (AdapterUtils.isWindows()) {
    String drivePrefix=FilenameUtils.getPrefix(clientPath);
    if (drivePrefix != null && drivePrefix.length() >= 2 && Character.isLowerCase(drivePrefix.charAt(0)) && drivePrefix.charAt(1) == ':') {
      drivePrefix=drivePrefix.substring(0,2);
      clientPath=clientPath.replaceFirst(drivePrefix,drivePrefix.toUpperCase());
    }
  }
  String sourcePath=clientPath;
  if (bpArguments.source.sourceReference != 0 && context.getSourceUri(bpArguments.source.sourceReference) != null) {
    sourcePath=context.getSourceUri(bpArguments.source.sourceReference);
  }
 else   if (StringUtils.isNotBlank(clientPath)) {
    sourcePath=AdapterUtils.convertPath(clientPath,AdapterUtils.isUri(clientPath),context.isDebuggerPathsAreUri());
  }
  if (StringUtils.isBlank(sourcePath)) {
    AdapterUtils.setErrorResponse(response,ErrorCode.SET_BREAKPOINT_FAILURE,String.format(""String_Node_Str"",bpArguments.source.path));
    return;
  }
  try {
    List<Types.Breakpoint> res=new ArrayList<>();
    IBreakpoint[] toAdds=this.convertClientBreakpointsToDebugger(sourcePath,bpArguments.breakpoints,context);
    IBreakpoint[] added=manager.setBreakpoints(AdapterUtils.decodeURIComponent(sourcePath),toAdds,bpArguments.sourceModified);
    for (int i=0; i < bpArguments.breakpoints.length; i++) {
      if (toAdds[i] == added[i] && added[i].className() != null) {
        added[i].install().thenAccept(bp -> {
          Events.BreakpointEvent bpEvent=new Events.BreakpointEvent(""String_Node_Str"",this.convertDebuggerBreakpointToClient(bp,context));
          context.sendEventAsync(bpEvent);
        }
);
      }
 else       if (toAdds[i].hitCount() != added[i].hitCount() && added[i].className() != null) {
        added[i].setHitCount(toAdds[i].hitCount());
      }
      res.add(this.convertDebuggerBreakpointToClient(added[i],context));
    }
    response.body=new Responses.SetBreakpointsResponseBody(res);
  }
 catch (  DebugException e) {
    AdapterUtils.setErrorResponse(response,ErrorCode.SET_BREAKPOINT_FAILURE,String.format(""String_Node_Str"",e.toString()));
  }
}"
37412,"private List<BreakpointRequest> createBreakpointRequests(List<ReferenceType> refTypes,int lineNumber,int hitCount){
  List<Location> locations=collectLocations(refTypes,lineNumber);
  List<Location> existingLocations=new ArrayList<>(requests.size());
  Observable.fromIterable(requests).filter(request -> request instanceof BreakpointRequest).map(request -> ((BreakpointRequest)request).location()).toList().subscribe(list -> {
    existingLocations.addAll(list);
  }
);
  List<Location> newLocations=new ArrayList<>(locations.size());
  Observable.fromIterable(locations).filter(location -> !existingLocations.contains(location)).toList().subscribe(list -> {
    newLocations.addAll(list);
  }
);
  List<BreakpointRequest> newRequests=new ArrayList<>(newLocations.size());
  newLocations.forEach(location -> {
    try {
      BreakpointRequest request=vm.eventRequestManager().createBreakpointRequest(location);
      request.setSuspendPolicy(BreakpointRequest.SUSPEND_EVENT_THREAD);
      if (hitCount > 0) {
        request.addCountFilter(hitCount);
      }
      request.enable();
      newRequests.add(request);
    }
 catch (    VMDisconnectedException ex) {
    }
  }
);
  return newRequests;
}","private List<BreakpointRequest> createBreakpointRequests(List<ReferenceType> refTypes,int lineNumber,int hitCount,boolean includeNestedTypes){
  List<Location> locations=collectLocations(refTypes,lineNumber,includeNestedTypes);
  List<Location> existingLocations=new ArrayList<>(requests.size());
  Observable.fromIterable(requests).filter(request -> request instanceof BreakpointRequest).map(request -> ((BreakpointRequest)request).location()).toList().subscribe(list -> {
    existingLocations.addAll(list);
  }
);
  List<Location> newLocations=new ArrayList<>(locations.size());
  Observable.fromIterable(locations).filter(location -> !existingLocations.contains(location)).toList().subscribe(list -> {
    newLocations.addAll(list);
  }
);
  List<BreakpointRequest> newRequests=new ArrayList<>(newLocations.size());
  newLocations.forEach(location -> {
    try {
      BreakpointRequest request=vm.eventRequestManager().createBreakpointRequest(location);
      request.setSuspendPolicy(BreakpointRequest.SUSPEND_EVENT_THREAD);
      if (hitCount > 0) {
        request.addCountFilter(hitCount);
      }
      request.enable();
      newRequests.add(request);
    }
 catch (    VMDisconnectedException ex) {
    }
  }
);
  return newRequests;
}"
37413,"@Override public CompletableFuture<IBreakpoint> install(){
  ClassPrepareRequest classPrepareRequest=vm.eventRequestManager().createClassPrepareRequest();
  classPrepareRequest.addClassFilter(className);
  classPrepareRequest.enable();
  requests.add(classPrepareRequest);
  ClassPrepareRequest localClassPrepareRequest=vm.eventRequestManager().createClassPrepareRequest();
  localClassPrepareRequest.addClassFilter(className + ""String_Node_Str"");
  localClassPrepareRequest.enable();
  requests.add(localClassPrepareRequest);
  CompletableFuture<IBreakpoint> future=new CompletableFuture<>();
  Disposable subscription=eventHub.events().filter(debugEvent -> debugEvent.event instanceof ClassPrepareEvent && (classPrepareRequest.equals(debugEvent.event.request()) || localClassPrepareRequest.equals(debugEvent.event.request()))).subscribe(debugEvent -> {
    ClassPrepareEvent event=(ClassPrepareEvent)debugEvent.event;
    List<BreakpointRequest> newRequests=createBreakpointRequests(event.referenceType(),lineNumber,hitCount);
    requests.addAll(newRequests);
    if (!newRequests.isEmpty() && !future.isDone()) {
      this.putProperty(""String_Node_Str"",true);
      future.complete(this);
    }
  }
);
  subscriptions.add(subscription);
  List<ReferenceType> refTypes=vm.classesByName(className);
  List<BreakpointRequest> newRequests=createBreakpointRequests(refTypes,lineNumber,hitCount);
  requests.addAll(newRequests);
  if (!newRequests.isEmpty() && !future.isDone()) {
    this.putProperty(""String_Node_Str"",true);
    future.complete(this);
  }
  return future;
}","@Override public CompletableFuture<IBreakpoint> install(){
  ClassPrepareRequest classPrepareRequest=vm.eventRequestManager().createClassPrepareRequest();
  classPrepareRequest.addClassFilter(className);
  classPrepareRequest.enable();
  requests.add(classPrepareRequest);
  ClassPrepareRequest localClassPrepareRequest=vm.eventRequestManager().createClassPrepareRequest();
  localClassPrepareRequest.addClassFilter(className + ""String_Node_Str"");
  localClassPrepareRequest.enable();
  requests.add(localClassPrepareRequest);
  CompletableFuture<IBreakpoint> future=new CompletableFuture<>();
  Disposable subscription=eventHub.events().filter(debugEvent -> debugEvent.event instanceof ClassPrepareEvent && (classPrepareRequest.equals(debugEvent.event.request()) || localClassPrepareRequest.equals(debugEvent.event.request()))).subscribe(debugEvent -> {
    ClassPrepareEvent event=(ClassPrepareEvent)debugEvent.event;
    List<BreakpointRequest> newRequests=createBreakpointRequests(event.referenceType(),lineNumber,hitCount,false);
    requests.addAll(newRequests);
    if (!newRequests.isEmpty() && !future.isDone()) {
      this.putProperty(""String_Node_Str"",true);
      future.complete(this);
    }
  }
);
  subscriptions.add(subscription);
  List<ReferenceType> refTypes=vm.classesByName(className);
  List<BreakpointRequest> newRequests=createBreakpointRequests(refTypes,lineNumber,hitCount,true);
  requests.addAll(newRequests);
  if (!newRequests.isEmpty() && !future.isDone()) {
    this.putProperty(""String_Node_Str"",true);
    future.complete(this);
  }
  return future;
}"
37414,"private static List<Location> collectLocations(List<ReferenceType> refTypes,int lineNumber){
  List<Location> locations=new ArrayList<>();
  try {
    refTypes.forEach(refType -> {
      locations.addAll(collectLocations(refType,lineNumber));
      locations.addAll(collectLocations(refType.nestedTypes(),lineNumber));
    }
);
  }
 catch (  VMDisconnectedException ex) {
  }
  return locations;
}","private static List<Location> collectLocations(List<ReferenceType> refTypes,int lineNumber,boolean includeNestedTypes){
  List<Location> locations=new ArrayList<>();
  try {
    refTypes.forEach(refType -> {
      List<Location> newLocations=collectLocations(refType,lineNumber);
      if (!newLocations.isEmpty()) {
        locations.addAll(newLocations);
      }
 else       if (includeNestedTypes) {
        for (        ReferenceType nestedType : refType.nestedTypes()) {
          List<Location> nestedLocations=collectLocations(nestedType,lineNumber);
          if (!nestedLocations.isEmpty()) {
            locations.addAll(nestedLocations);
            break;
          }
        }
      }
    }
);
  }
 catch (  VMDisconnectedException ex) {
  }
  return locations;
}"
37415,"private Types.Source convertDebuggerSourceToClient(Location location,IDebugAdapterContext context) throws URISyntaxException {
  final String fullyQualifiedName=location.declaringType().name();
  String sourceName=""String_Node_Str"";
  String relativeSourcePath=""String_Node_Str"";
  try {
    sourceName=location.sourceName();
    relativeSourcePath=location.sourcePath();
  }
 catch (  AbsentInformationException e) {
    String enclosingType=AdapterUtils.parseEnclosingType(fullyQualifiedName);
    sourceName=enclosingType.substring(enclosingType.lastIndexOf('.') + 1) + ""String_Node_Str"";
    relativeSourcePath=enclosingType.replace('.','/') + ""String_Node_Str"";
  }
  final String finalRelativeSourcePath=relativeSourcePath;
  String uri=context.getSourceLookupCache().computeIfAbsent(fullyQualifiedName,key -> context.getProvider(ISourceLookUpProvider.class).getSourceFileURI(key,finalRelativeSourcePath));
  if (uri != null) {
    String clientPath=AdapterUtils.convertPath(uri,context.isDebuggerPathsAreUri(),context.isClientPathsAreUri());
    if (uri.startsWith(""String_Node_Str"")) {
      return new Types.Source(sourceName,clientPath,0);
    }
 else {
      return new Types.Source(sourceName,clientPath,context.createSourceReference(uri));
    }
  }
 else {
    String absoluteSourcepath=AdapterUtils.sourceLookup(context.getSourcePaths(),relativeSourcePath);
    if (absoluteSourcepath != null) {
      return new Types.Source(sourceName,absoluteSourcepath,0);
    }
 else {
      return null;
    }
  }
}","private Types.Source convertDebuggerSourceToClient(Location location,IDebugAdapterContext context) throws URISyntaxException {
  final String fullyQualifiedName=location.declaringType().name();
  String sourceName=""String_Node_Str"";
  String relativeSourcePath=""String_Node_Str"";
  try {
    sourceName=location.sourceName();
    relativeSourcePath=location.sourcePath();
  }
 catch (  AbsentInformationException e) {
    String enclosingType=AdapterUtils.parseEnclosingType(fullyQualifiedName);
    sourceName=enclosingType.substring(enclosingType.lastIndexOf('.') + 1) + ""String_Node_Str"";
    relativeSourcePath=enclosingType.replace('.','/') + ""String_Node_Str"";
  }
  final String finalRelativeSourcePath=relativeSourcePath;
  String uri=context.getSourceLookupCache().computeIfAbsent(fullyQualifiedName,key -> {
    String fromProvider=context.getProvider(ISourceLookUpProvider.class).getSourceFileURI(key,finalRelativeSourcePath);
    return StringUtils.isBlank(fromProvider) ? ""String_Node_Str"" : fromProvider;
  }
);
  if (!StringUtils.isBlank(uri)) {
    String clientPath=AdapterUtils.convertPath(uri,context.isDebuggerPathsAreUri(),context.isClientPathsAreUri());
    if (uri.startsWith(""String_Node_Str"")) {
      return new Types.Source(sourceName,clientPath,0);
    }
 else {
      return new Types.Source(sourceName,clientPath,context.createSourceReference(uri));
    }
  }
 else {
    String absoluteSourcepath=AdapterUtils.sourceLookup(context.getSourcePaths(),relativeSourcePath);
    if (absoluteSourcepath != null) {
      return new Types.Source(sourceName,absoluteSourcepath,0);
    }
 else {
      return null;
    }
  }
}"
37416,"public static String getSessionGuid(){
  return threadLocal.get().sessionGuid;
}","public static String getSessionGuid(){
  return threadLocal.get() == null ? ""String_Node_Str"" : threadLocal.get().sessionGuid;
}"
37417,"/** 
 * For a given source file and a list of line locations, return the fully qualified names of the type of the line location. If the line location points an empty line or invalid line, it returns a null fully qualified name.
 */
@Override public String[] getFullyQualifiedName(String uri,int[] lines,int[] columns) throws DebugException {
  if (uri == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (lines == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (columns == null) {
    columns=new int[lines.length];
  }
 else   if (lines.length != columns.length) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (lines.length == 0) {
    return new String[0];
  }
  final ASTParser parser=ASTParser.newParser(AST.JLS8);
  parser.setResolveBindings(true);
  parser.setBindingsRecovery(true);
  parser.setStatementsRecovery(true);
  CompilationUnit astUnit=null;
  String filePath=AdapterUtils.toPath(uri);
  if (filePath != null && Files.isRegularFile(Paths.get(filePath))) {
    Charset cs=(Charset)this.context.get(Constants.DEBUGGEE_ENCODING);
    if (cs == null) {
      cs=Charset.defaultCharset();
    }
    String source=readFile(filePath,cs);
    parser.setSource(source.toCharArray());
    astUnit=(CompilationUnit)parser.createAST(null);
  }
 else {
    ITypeRoot typeRoot=resolveClassFile(uri);
    if (typeRoot != null) {
      parser.setSource(typeRoot);
      astUnit=(CompilationUnit)parser.createAST(null);
    }
  }
  String[] fqns=new String[lines.length];
  if (astUnit != null) {
    for (int i=0; i < lines.length; i++) {
      ValidBreakpointLocationLocator locator=new ValidBreakpointLocationLocator(astUnit,lines[i],true,true);
      astUnit.accept(locator);
      if (lines[i] == locator.getLineLocation()) {
        fqns[i]=locator.getFullyQualifiedTypeName();
      }
    }
  }
  return fqns;
}","/** 
 * For a given source file and a list of line locations, return the fully qualified names of the type of the line location. If the line location points an empty line or invalid line, it returns a null fully qualified name.
 */
@Override public String[] getFullyQualifiedName(String uri,int[] lines,int[] columns) throws DebugException {
  if (uri == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (lines == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (columns == null) {
    columns=new int[lines.length];
  }
 else   if (lines.length != columns.length) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (lines.length == 0) {
    return new String[0];
  }
  final ASTParser parser=ASTParser.newParser(AST.JLS8);
  parser.setResolveBindings(true);
  parser.setBindingsRecovery(true);
  parser.setStatementsRecovery(true);
  CompilationUnit astUnit=null;
  String filePath=AdapterUtils.toPath(uri);
  if (filePath != null && Files.isRegularFile(Paths.get(filePath))) {
    Charset cs=(Charset)this.context.get(Constants.DEBUGGEE_ENCODING);
    if (cs == null) {
      cs=Charset.defaultCharset();
    }
    String source=readFile(filePath,cs);
    parser.setSource(source.toCharArray());
    parser.setEnvironment(new String[0],new String[0],null,true);
    parser.setUnitName(Paths.get(filePath).getFileName().toString());
    Map<String,String> options=JavaCore.getOptions();
    options.put(JavaCore.COMPILER_SOURCE,JavaCore.VERSION_1_8);
    options.put(JavaCore.COMPILER_CODEGEN_TARGET_PLATFORM,JavaCore.VERSION_1_8);
    options.put(JavaCore.COMPILER_COMPLIANCE,JavaCore.VERSION_1_8);
    parser.setCompilerOptions(options);
    astUnit=(CompilationUnit)parser.createAST(null);
  }
 else {
    ITypeRoot typeRoot=resolveClassFile(uri);
    if (typeRoot != null) {
      parser.setSource(typeRoot);
      astUnit=(CompilationUnit)parser.createAST(null);
    }
  }
  String[] fqns=new String[lines.length];
  if (astUnit != null) {
    for (int i=0; i < lines.length; i++) {
      ValidBreakpointLocationLocator locator=new ValidBreakpointLocationLocator(astUnit,lines[i],true,true);
      astUnit.accept(locator);
      if (lines[i] == locator.getLineLocation()) {
        fqns[i]=locator.getFullyQualifiedTypeName();
      }
    }
  }
  return fqns;
}"
37418,"/** 
 * Get the local variables of an stack frame.
 * @param stackFrame the stack frame
 * @return local variable list
 * @throws AbsentInformationException when there is any error in retrieving information
 */
public static List<Variable> listLocalVariables(StackFrame stackFrame) throws AbsentInformationException {
  List<Variable> res=new ArrayList<>();
  try {
    for (    LocalVariable localVariable : stackFrame.visibleVariables()) {
      Variable var=new Variable(localVariable.name(),stackFrame.getValue(localVariable));
      var.local=localVariable;
      res.add(var);
    }
  }
 catch (  AbsentInformationException ex) {
    if (stackFrame.location().method().isNative()) {
      return res;
    }
    int argId=0;
    try {
      List<Value> arguments=stackFrame.getArgumentValues();
      if (arguments == null) {
        return res;
      }
      for (      Value argValue : arguments) {
        Variable var=new Variable(""String_Node_Str"" + argId,argValue);
        var.argumentIndex=argId++;
        res.add(var);
      }
    }
 catch (    InternalException ex2) {
      if (ex2.errorCode() != 32) {
        throw ex;
      }
    }
  }
  return res;
}","/** 
 * Get the local variables of an stack frame.
 * @param stackFrame the stack frame
 * @return local variable list
 * @throws AbsentInformationException when there is any error in retrieving information
 */
public static List<Variable> listLocalVariables(StackFrame stackFrame) throws AbsentInformationException {
  List<Variable> res=new ArrayList<>();
  if (stackFrame.location().method().isNative()) {
    return res;
  }
  try {
    for (    LocalVariable localVariable : stackFrame.visibleVariables()) {
      Variable var=new Variable(localVariable.name(),stackFrame.getValue(localVariable));
      var.local=localVariable;
      res.add(var);
    }
  }
 catch (  AbsentInformationException ex) {
    try {
      if (stackFrame.location().method().argumentTypes().size() == 0) {
        return res;
      }
    }
 catch (    ClassNotLoadedException ex2) {
    }
    int argId=0;
    try {
      List<Value> arguments=stackFrame.getArgumentValues();
      if (arguments == null) {
        return res;
      }
      for (      Value argValue : arguments) {
        Variable var=new Variable(""String_Node_Str"" + argId,argValue);
        var.argumentIndex=argId++;
        res.add(var);
      }
    }
 catch (    InternalException ex2) {
      if (ex2.errorCode() != 32) {
        throw ex;
      }
    }
  }
  return res;
}"
37419,"@Override public void handle(Command command,Arguments arguments,Response response,IDebugAdapterContext context){
  StackTraceArguments stacktraceArgs=(StackTraceArguments)arguments;
  List<Types.StackFrame> result=new ArrayList<>();
  if (stacktraceArgs.startFrame < 0 || stacktraceArgs.levels < 0) {
    response.body=new Responses.StackTraceResponseBody(result,0);
    return;
  }
  ThreadReference thread=DebugUtility.getThread(context.getDebugSession(),stacktraceArgs.threadId);
  int totalFrames=0;
  if (thread != null) {
    try {
      totalFrames=thread.frameCount();
      if (totalFrames <= stacktraceArgs.startFrame) {
        response.body=new Responses.StackTraceResponseBody(result,totalFrames);
        return;
      }
      List<StackFrame> stackFrames=stacktraceArgs.levels == 0 ? thread.frames(stacktraceArgs.startFrame,totalFrames - stacktraceArgs.startFrame) : thread.frames(stacktraceArgs.startFrame,Math.min(totalFrames - stacktraceArgs.startFrame,stacktraceArgs.levels));
      for (int i=0; i < stacktraceArgs.levels; i++) {
        StackFrame stackFrame=stackFrames.get(stacktraceArgs.startFrame + i);
        int frameId=context.getRecyclableIdPool().addObject(stackFrame.thread().uniqueID(),new JdiObjectProxy<>(stackFrame));
        Types.StackFrame clientStackFrame=convertDebuggerStackFrameToClient(stackFrame,frameId,context);
        result.add(clientStackFrame);
      }
    }
 catch (    IncompatibleThreadStateException|IndexOutOfBoundsException|URISyntaxException|AbsentInformationException e) {
    }
  }
  response.body=new Responses.StackTraceResponseBody(result,totalFrames);
}","@Override public void handle(Command command,Arguments arguments,Response response,IDebugAdapterContext context){
  StackTraceArguments stacktraceArgs=(StackTraceArguments)arguments;
  List<Types.StackFrame> result=new ArrayList<>();
  if (stacktraceArgs.startFrame < 0 || stacktraceArgs.levels < 0) {
    response.body=new Responses.StackTraceResponseBody(result,0);
    return;
  }
  ThreadReference thread=DebugUtility.getThread(context.getDebugSession(),stacktraceArgs.threadId);
  int totalFrames=0;
  if (thread != null) {
    try {
      totalFrames=thread.frameCount();
      if (totalFrames <= stacktraceArgs.startFrame) {
        response.body=new Responses.StackTraceResponseBody(result,totalFrames);
        return;
      }
      List<StackFrame> stackFrames=stacktraceArgs.levels == 0 ? thread.frames(stacktraceArgs.startFrame,totalFrames - stacktraceArgs.startFrame) : thread.frames(stacktraceArgs.startFrame,Math.min(totalFrames - stacktraceArgs.startFrame,stacktraceArgs.levels));
      for (int i=0; i < stackFrames.size(); i++) {
        StackFrame stackFrame=stackFrames.get(i);
        int frameId=context.getRecyclableIdPool().addObject(stackFrame.thread().uniqueID(),new JdiObjectProxy<>(stackFrame));
        Types.StackFrame clientStackFrame=convertDebuggerStackFrameToClient(stackFrame,frameId,context);
        result.add(clientStackFrame);
      }
    }
 catch (    IncompatibleThreadStateException|IndexOutOfBoundsException|URISyntaxException|AbsentInformationException e) {
    }
  }
  response.body=new Responses.StackTraceResponseBody(result,totalFrames);
}"
37420,"@Override public Object executeCommand(String commandId,List<Object> arguments){
  if (DEBUG_STARTSESSION.equals(commandId)) {
  }
 else   if (RESOLVE_CLASSPATH.equals(commandId)) {
    ResolveClasspathsHandler handler=new ResolveClasspathsHandler();
    return handler.resolveClasspaths(arguments);
  }
 else   if (BUILD_WORKSPACE.equals(commandId)) {
  }
  return null;
}","@Override public Object executeCommand(String commandId,List<Object> arguments){
  if (DEBUG_STARTSESSION.equals(commandId)) {
    IDebugServer debugServer=JavaDebugServer.getInstance();
    debugServer.start();
    return debugServer.getPort();
  }
 else   if (RESOLVE_CLASSPATH.equals(commandId)) {
    ResolveClasspathsHandler handler=new ResolveClasspathsHandler();
    return handler.resolveClasspaths(arguments);
  }
 else   if (BUILD_WORKSPACE.equals(commandId)) {
  }
  return null;
}"
37421,"private String searchDeclarationFileByFqn(String fullyQualifiedName){
  return null;
}","private String searchDeclarationFileByFqn(String fullyQualifiedName){
  String projectName=(String)context.get(Constants.PROJECTNAME);
  try {
    IJavaSearchScope searchScope=projectName != null ? JDTUtils.createSearchScope(getJavaProjectFromName(projectName)) : SearchEngine.createWorkspaceScope();
    SearchPattern pattern=SearchPattern.createPattern(fullyQualifiedName,IJavaSearchConstants.TYPE,IJavaSearchConstants.DECLARATIONS,SearchPattern.R_EXACT_MATCH);
    ArrayList<String> uris=new ArrayList<String>();
    SearchRequestor requestor=new SearchRequestor(){
      @Override public void acceptSearchMatch(      SearchMatch match){
        Object element=match.getElement();
        if (element instanceof IType) {
          IType type=(IType)element;
          uris.add(type.isBinary() ? getFileURI(type.getClassFile()) : JDTUtils.getFileURI(type.getResource()));
        }
      }
    }
;
    SearchEngine searchEngine=new SearchEngine();
    searchEngine.search(pattern,new SearchParticipant[]{SearchEngine.getDefaultSearchParticipant()},searchScope,requestor,null);
    return uris.size() == 0 ? null : uris.get(0);
  }
 catch (  CoreException e) {
    Logger.logException(""String_Node_Str"",e);
  }
  return null;
}"
37422,"private String getContents(IClassFile cf){
  String source=null;
  if (cf != null) {
    try {
      IBuffer buffer=cf.getBuffer();
      if (buffer != null) {
        source=buffer.getContents();
      }
      if (source == null) {
      }
    }
 catch (    JavaModelException e) {
      Logger.logException(""String_Node_Str"",e);
    }
    if (source == null) {
      source=""String_Node_Str"";
    }
  }
  return source;
}","private String getContents(IClassFile cf){
  String source=null;
  if (cf != null) {
    try {
      IBuffer buffer=cf.getBuffer();
      if (buffer != null) {
        source=buffer.getContents();
      }
      if (source == null) {
        source=JDTUtils.disassemble(cf);
      }
    }
 catch (    JavaModelException e) {
      Logger.logException(""String_Node_Str"",e);
    }
    if (source == null) {
      source=""String_Node_Str"";
    }
  }
  return source;
}"
37423,"@Override public String getSourceContents(String uri){
  if (uri == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  return ""String_Node_Str"";
}","@Override public String getSourceContents(String uri){
  if (uri == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  IClassFile cf=JDTUtils.resolveClassFile(uri);
  return getContents(cf);
}"
37424,"/** 
 * For a given source file and a list of line locations, return the fully qualified names of the type of the line location. If the line location points an empty line or invalid line, it returns a null fully qualified name.
 */
@Override public String[] getFullyQualifiedName(String uri,int[] lines,int[] columns) throws DebugException {
  if (uri == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (lines == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (columns == null) {
    columns=new int[lines.length];
  }
 else   if (lines.length != columns.length) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  String[] fqns=new String[lines.length];
  return fqns;
}","/** 
 * For a given source file and a list of line locations, return the fully qualified names of the type of the line location. If the line location points an empty line or invalid line, it returns a null fully qualified name.
 */
@Override public String[] getFullyQualifiedName(String uri,int[] lines,int[] columns) throws DebugException {
  if (uri == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (lines == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (columns == null) {
    columns=new int[lines.length];
  }
 else   if (lines.length != columns.length) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  String[] fqns=new String[lines.length];
  ITypeRoot typeRoot=JDTUtils.resolveCompilationUnit(uri);
  if (typeRoot == null) {
    typeRoot=JDTUtils.resolveClassFile(uri);
  }
  if (typeRoot != null && lines.length > 0) {
    final ASTParser parser=ASTParser.newParser(AST.JLS8);
    parser.setResolveBindings(true);
    parser.setBindingsRecovery(true);
    parser.setStatementsRecovery(true);
    parser.setSource(typeRoot);
    CompilationUnit cunit=(CompilationUnit)parser.createAST(null);
    for (int i=0; i < lines.length; i++) {
      ValidBreakpointLocationLocator locator=new ValidBreakpointLocationLocator(cunit,lines[i],true,true);
      cunit.accept(locator);
      if (lines[i] == locator.getLineLocation()) {
        fqns[i]=locator.getFullyQualifiedTypeName();
      }
    }
  }
  return fqns;
}"
37425,"private IBreakpoint[] convertClientBreakpointsToDebugger(String sourceFile,Types.SourceBreakpoint[] sourceBreakpoints,IDebugAdapterContext context) throws DebugException {
  int[] lines=Arrays.asList(sourceBreakpoints).stream().map(sourceBreakpoint -> {
    return AdapterUtils.convertLineNumber(sourceBreakpoint.line,context.isClientLinesStartAt1(),context.isDebuggerLinesStartAt1());
  }
).mapToInt(line -> line).toArray();
  ISourceLookUpProvider sourceProvider=context.getProvider(ISourceLookUpProvider.class);
  String[] fqns=sourceProvider.getFullyQualifiedName(sourceFile,lines,null);
  IBreakpoint[] breakpoints=new IBreakpoint[lines.length];
  for (int i=0; i < lines.length; i++) {
    int hitCount=0;
    try {
      hitCount=Integer.parseInt(sourceBreakpoints[i].hitCondition);
    }
 catch (    NumberFormatException e) {
      hitCount=0;
    }
    breakpoints[i]=context.getDebugSession().createBreakpoint(fqns[i],lines[i],hitCount);
  }
  return breakpoints;
}","private IBreakpoint[] convertClientBreakpointsToDebugger(String sourceFile,Types.SourceBreakpoint[] sourceBreakpoints,IDebugAdapterContext context) throws DebugException {
  int[] lines=Arrays.asList(sourceBreakpoints).stream().map(sourceBreakpoint -> {
    return AdapterUtils.convertLineNumber(sourceBreakpoint.line,context.isClientLinesStartAt1(),context.isDebuggerLinesStartAt1());
  }
).mapToInt(line -> line).toArray();
  ISourceLookUpProvider sourceProvider=context.getProvider(ISourceLookUpProvider.class);
  String[] fqns=sourceProvider.getFullyQualifiedName(sourceFile,lines,null);
  IBreakpoint[] breakpoints=new IBreakpoint[lines.length];
  for (int i=0; i < lines.length; i++) {
    int hitCount=0;
    try {
      hitCount=Integer.parseInt(sourceBreakpoints[i].hitCondition);
    }
 catch (    NumberFormatException e) {
      hitCount=0;
    }
    breakpoints[i]=context.getDebugSession().createBreakpoint(fqns[i],lines[i],hitCount);
    if (sourceProvider.supportsRealtimeBreakpointVerification() && StringUtils.isNotBlank(fqns[i])) {
      breakpoints[i].putProperty(""String_Node_Str"",true);
    }
  }
  return breakpoints;
}"
37426,"@Override public String[] getFullyQualifiedName(String uri,int[] lines,int[] columns) throws DebugException {
  if (uri == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (lines == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (columns == null) {
    columns=new int[lines.length];
  }
 else   if (lines.length != columns.length) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  String[] fqns=new String[lines.length];
  ITypeRoot typeRoot=JDTUtils.resolveCompilationUnit(uri);
  if (typeRoot == null) {
    typeRoot=JDTUtils.resolveClassFile(uri);
  }
  for (int i=0; i < lines.length; i++) {
    String fqn=null;
    if (typeRoot != null) {
      try {
        int offset=JsonRpcHelpers.toOffset(typeRoot.getBuffer(),lines[i],columns[i]);
        IJavaElement javaElement=typeRoot.getElementAt(offset);
        if (javaElement instanceof SourceField || javaElement instanceof SourceMethod || javaElement instanceof BinaryMember) {
          IType type=((IMember)javaElement).getDeclaringType();
          fqn=type.getFullyQualifiedName();
        }
 else         if (javaElement instanceof SourceType) {
          fqn=((SourceType)javaElement).getFullyQualifiedName();
        }
      }
 catch (      JavaModelException e) {
        Logger.logException(""String_Node_Str"" + lines[i],e);
        throw new DebugException(String.format(""String_Node_Str"",lines[i],e.getMessage()),e);
      }
    }
    fqns[i]=fqn;
  }
  return fqns;
}","/** 
 * For a given source file and a list of line locations, return the fully qualified names of the type of the line location. If the line location points an empty line or invalid line, it returns a null fully qualified name.
 */
@Override public String[] getFullyQualifiedName(String uri,int[] lines,int[] columns) throws DebugException {
  if (uri == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (lines == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (columns == null) {
    columns=new int[lines.length];
  }
 else   if (lines.length != columns.length) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  String[] fqns=new String[lines.length];
  ITypeRoot typeRoot=JDTUtils.resolveCompilationUnit(uri);
  if (typeRoot == null) {
    typeRoot=JDTUtils.resolveClassFile(uri);
  }
  if (typeRoot != null && lines.length > 0) {
    final ASTParser parser=ASTParser.newParser(AST.JLS8);
    parser.setResolveBindings(true);
    parser.setBindingsRecovery(true);
    parser.setStatementsRecovery(true);
    parser.setSource(typeRoot);
    CompilationUnit cunit=(CompilationUnit)parser.createAST(null);
    for (int i=0; i < lines.length; i++) {
      ValidBreakpointLocationLocator locator=new ValidBreakpointLocationLocator(cunit,lines[i],true,true);
      cunit.accept(locator);
      if (lines[i] == locator.getLineLocation()) {
        fqns[i]=locator.getFullyQualifiedTypeName();
      }
    }
  }
  return fqns;
}"
37427,"@Override public boolean equals(Object obj){
  if (!(obj instanceof IBreakpoint)) {
    return super.equals(obj);
  }
  IBreakpoint breakpoint=(IBreakpoint)obj;
  return this.className().equals(breakpoint.className()) && this.lineNumber() == breakpoint.lineNumber();
}","@Override public boolean equals(Object obj){
  if (!(obj instanceof IBreakpoint)) {
    return super.equals(obj);
  }
  IBreakpoint breakpoint=(IBreakpoint)obj;
  return Objects.equals(this.className(),breakpoint.className()) && this.lineNumber() == breakpoint.lineNumber();
}"
37428,"private void resume(Requests.ContinueArguments arguments,Response response,IDebugAdapterContext context){
  boolean allThreadsContinued=true;
  ThreadReference thread=DebugUtility.getThread(context.getDebugSession(),arguments.threadId);
  if (thread != null) {
    allThreadsContinued=false;
    thread.resume();
    checkThreadRunningAndRecycleIds(thread,context);
  }
 else {
    context.getDebugSession().resume();
    context.getRecyclableIdPool().removeAllObjects();
  }
  response.body=new Responses.ContinueResponseBody(allThreadsContinued);
}","private void resume(Requests.ContinueArguments arguments,Response response,IDebugAdapterContext context){
  boolean allThreadsContinued=true;
  ThreadReference thread=DebugUtility.getThread(context.getDebugSession(),arguments.threadId);
  if (thread != null) {
    allThreadsContinued=false;
    DebugUtility.resumeThread(thread);
    checkThreadRunningAndRecycleIds(thread,context);
  }
 else {
    context.getDebugSession().resume();
    context.getRecyclableIdPool().removeAllObjects();
  }
  response.body=new Responses.ContinueResponseBody(allThreadsContinued);
}"
37429,"@Override public void resume(){
  vm.resume();
}","@Override public void resume(){
  vm.resume();
  for (  ThreadReference tr : DebugUtility.getAllThreadsSafely(this)) {
    DebugUtility.resumeThread(tr);
  }
}"
37430,"private Responses.ResponseBody evaluate(Requests.EvaluateArguments arguments){
  final boolean showStaticVariables=true;
  boolean showFullyQualifiedNames=true;
  Map<String,Object> options=variableFormatter.getDefaultOptions();
  if (arguments.format != null && arguments.format.hex) {
    options.put(NumericFormatter.NUMERIC_FORMAT_OPTION,NumericFormatEnum.HEX);
  }
  if (showFullyQualifiedNames) {
    options.put(SimpleTypeFormatter.QUALIFIED_CLASS_NAME_OPTION,showFullyQualifiedNames);
  }
  String expression=arguments.expression;
  if (StringUtils.isBlank(expression)) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (!simpleExprPattern.matcher(expression).matches()) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  JdiObjectProxy<StackFrame> stackFrameProxy=(JdiObjectProxy<StackFrame>)this.objectPool.getObjectById(arguments.frameId);
  if (stackFrameProxy == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  List<String> referenceExpressions=Arrays.stream(StringUtils.split(expression,'.')).filter(StringUtils::isNotBlank).map(StringUtils::trim).collect(Collectors.toList());
  Variable firstLevelValue=null;
  boolean inStaticMethod=!stackFrameProxy.getProxiedObject().location().method().isStatic();
  String firstExpression=referenceExpressions.get(0);
  if (firstExpression.equals(""String_Node_Str"") && !inStaticMethod) {
    firstLevelValue=VariableUtils.getThisVariable(stackFrameProxy.getProxiedObject());
  }
  if (firstLevelValue == null) {
    try {
      List<Variable> localVariables=VariableUtils.listLocalVariables(stackFrameProxy.getProxiedObject());
      List<Variable> matchedLocal=localVariables.stream().filter(localVariable -> localVariable.name.equals(firstExpression)).collect(Collectors.toList());
      if (!matchedLocal.isEmpty()) {
        firstLevelValue=matchedLocal.get(0);
      }
 else {
        List<Variable> staticVariables=VariableUtils.listStaticVariables(stackFrameProxy.getProxiedObject());
        List<Variable> matchedStatic=staticVariables.stream().filter(staticVariable -> staticVariable.name.equals(firstExpression)).collect(Collectors.toList());
        if (matchedStatic.isEmpty()) {
          throw new IllegalArgumentException(String.format(""String_Node_Str"",referenceExpressions.get(0)));
        }
        firstLevelValue=matchedStatic.get(0);
      }
    }
 catch (    AbsentInformationException e) {
    }
  }
  if (firstLevelValue == null) {
    throw new IllegalArgumentException(String.format(""String_Node_Str"",referenceExpressions.get(0)));
  }
  ThreadReference thread=stackFrameProxy.getProxiedObject().thread();
  Value currentValue=firstLevelValue.value;
  for (int i=1; i < referenceExpressions.size(); i++) {
    String fieldName=referenceExpressions.get(i);
    if (currentValue == null) {
      throw new NullPointerException(""String_Node_Str"");
    }
    if (currentValue instanceof PrimitiveValue) {
      throw new IllegalArgumentException(String.format(""String_Node_Str"",fieldName));
    }
    if (currentValue instanceof ArrayReference) {
      throw new IllegalArgumentException(String.format(""String_Node_Str"",fieldName));
    }
    ObjectReference obj=(ObjectReference)currentValue;
    Field field=obj.referenceType().fieldByName(fieldName);
    if (field == null) {
      throw new IllegalArgumentException(String.format(""String_Node_Str"",fieldName));
    }
    if (field.isStatic()) {
      throw new IllegalArgumentException(String.format(""String_Node_Str"",fieldName));
    }
    currentValue=obj.getValue(field);
  }
  int referenceId=0;
  if (currentValue instanceof ObjectReference && VariableUtils.hasChildren(currentValue,showStaticVariables)) {
    ThreadObjectReference threadObjectReference=new ThreadObjectReference(thread,(ObjectReference)currentValue);
    referenceId=this.objectPool.addObject(thread.uniqueID(),threadObjectReference);
  }
  int indexedVariables=0;
  if (currentValue instanceof ArrayReference) {
    indexedVariables=((ArrayReference)currentValue).length();
  }
  return new Responses.EvaluateResponseBody(variableFormatter.valueToString(currentValue,options),referenceId,variableFormatter.typeToString(currentValue == null ? null : currentValue.type(),options),indexedVariables);
}","private Responses.ResponseBody evaluate(Requests.EvaluateArguments arguments){
  final boolean showStaticVariables=true;
  boolean showFullyQualifiedNames=true;
  Map<String,Object> options=variableFormatter.getDefaultOptions();
  if (arguments.format != null && arguments.format.hex) {
    options.put(NumericFormatter.NUMERIC_FORMAT_OPTION,NumericFormatEnum.HEX);
  }
  if (showFullyQualifiedNames) {
    options.put(SimpleTypeFormatter.QUALIFIED_CLASS_NAME_OPTION,showFullyQualifiedNames);
  }
  String expression=arguments.expression;
  if (StringUtils.isBlank(expression)) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (!simpleExprPattern.matcher(expression).matches()) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  JdiObjectProxy<StackFrame> stackFrameProxy=(JdiObjectProxy<StackFrame>)this.objectPool.getObjectById(arguments.frameId);
  if (stackFrameProxy == null) {
    return new Responses.ErrorResponseBody(convertDebuggerMessageToClient(""String_Node_Str""));
  }
  List<String> referenceExpressions=Arrays.stream(StringUtils.split(expression,'.')).filter(StringUtils::isNotBlank).map(StringUtils::trim).collect(Collectors.toList());
  Variable firstLevelValue=null;
  boolean inStaticMethod=!stackFrameProxy.getProxiedObject().location().method().isStatic();
  String firstExpression=referenceExpressions.get(0);
  if (firstExpression.equals(""String_Node_Str"") && !inStaticMethod) {
    firstLevelValue=VariableUtils.getThisVariable(stackFrameProxy.getProxiedObject());
  }
  if (firstLevelValue == null) {
    try {
      List<Variable> localVariables=VariableUtils.listLocalVariables(stackFrameProxy.getProxiedObject());
      List<Variable> matchedLocal=localVariables.stream().filter(localVariable -> localVariable.name.equals(firstExpression)).collect(Collectors.toList());
      if (!matchedLocal.isEmpty()) {
        firstLevelValue=matchedLocal.get(0);
      }
 else {
        List<Variable> staticVariables=VariableUtils.listStaticVariables(stackFrameProxy.getProxiedObject());
        List<Variable> matchedStatic=staticVariables.stream().filter(staticVariable -> staticVariable.name.equals(firstExpression)).collect(Collectors.toList());
        if (matchedStatic.isEmpty()) {
          throw new IllegalArgumentException(String.format(""String_Node_Str"",referenceExpressions.get(0)));
        }
        firstLevelValue=matchedStatic.get(0);
      }
    }
 catch (    AbsentInformationException e) {
    }
  }
  if (firstLevelValue == null) {
    throw new IllegalArgumentException(String.format(""String_Node_Str"",referenceExpressions.get(0)));
  }
  ThreadReference thread=stackFrameProxy.getProxiedObject().thread();
  Value currentValue=firstLevelValue.value;
  for (int i=1; i < referenceExpressions.size(); i++) {
    String fieldName=referenceExpressions.get(i);
    if (currentValue == null) {
      throw new NullPointerException(""String_Node_Str"");
    }
    if (currentValue instanceof PrimitiveValue) {
      throw new IllegalArgumentException(String.format(""String_Node_Str"",fieldName));
    }
    if (currentValue instanceof ArrayReference) {
      throw new IllegalArgumentException(String.format(""String_Node_Str"",fieldName));
    }
    ObjectReference obj=(ObjectReference)currentValue;
    Field field=obj.referenceType().fieldByName(fieldName);
    if (field == null) {
      throw new IllegalArgumentException(String.format(""String_Node_Str"",fieldName));
    }
    if (field.isStatic()) {
      throw new IllegalArgumentException(String.format(""String_Node_Str"",fieldName));
    }
    currentValue=obj.getValue(field);
  }
  int referenceId=0;
  if (currentValue instanceof ObjectReference && VariableUtils.hasChildren(currentValue,showStaticVariables)) {
    ThreadObjectReference threadObjectReference=new ThreadObjectReference(thread,(ObjectReference)currentValue);
    referenceId=this.objectPool.addObject(thread.uniqueID(),threadObjectReference);
  }
  int indexedVariables=0;
  if (currentValue instanceof ArrayReference) {
    indexedVariables=((ArrayReference)currentValue).length();
  }
  return new Responses.EvaluateResponseBody(variableFormatter.valueToString(currentValue,options),referenceId,variableFormatter.typeToString(currentValue == null ? null : currentValue.type(),options),indexedVariables);
}"
37431,"Responses.ResponseBody variables(Requests.VariablesArguments arguments) throws AbsentInformationException {
  Map<String,Object> options=variableFormatter.getDefaultOptions();
  boolean showStaticVariables=true;
  boolean showFullyQualifiedNames=true;
  if (arguments.format != null && arguments.format.hex) {
    options.put(NumericFormatter.NUMERIC_FORMAT_OPTION,NumericFormatEnum.HEX);
  }
  if (showFullyQualifiedNames) {
    options.put(SimpleTypeFormatter.QUALIFIED_CLASS_NAME_OPTION,showFullyQualifiedNames);
  }
  List<Types.Variable> list=new ArrayList<>();
  List<Variable> variables;
  Object obj=this.objectPool.getObjectById(arguments.variablesReference);
  ThreadReference thread;
  if (obj instanceof StackFrameScope) {
    StackFrame frame=((StackFrameScope)obj).getStackFrame();
    thread=frame.thread();
    variables=VariableUtils.listLocalVariables(frame);
    Variable thisVariable=VariableUtils.getThisVariable(frame);
    if (thisVariable != null) {
      variables.add(thisVariable);
    }
    if (showStaticVariables && frame.location().method().isStatic()) {
      variables.addAll(VariableUtils.listStaticVariables(frame));
    }
  }
 else   if (obj instanceof ThreadObjectReference) {
    ObjectReference currentObj=((ThreadObjectReference)obj).getObject();
    thread=((ThreadObjectReference)obj).getThread();
    if (arguments.count > 0) {
      variables=VariableUtils.listFieldVariables(currentObj,arguments.start,arguments.count);
    }
 else {
      variables=VariableUtils.listFieldVariables(currentObj,showStaticVariables);
    }
  }
 else {
    throw new IllegalArgumentException(String.format(""String_Node_Str"",arguments.variablesReference));
  }
  Set<String> duplicateNames=getDuplicateNames(variables.stream().map(var -> var.name).collect(Collectors.toList()));
  Map<Variable,String> variableNameMap=new HashMap<>();
  if (!duplicateNames.isEmpty()) {
    Map<String,List<Variable>> duplicateVars=variables.stream().filter(var -> duplicateNames.contains(var.name)).collect(Collectors.groupingBy(var -> var.name,Collectors.toList()));
    duplicateVars.forEach((k,duplicateVariables) -> {
      Set<String> declarationTypeNames=new HashSet<>();
      boolean declarationTypeNameConflict=false;
      for (      Variable javaVariable : duplicateVariables) {
        Type declarationType=javaVariable.getDeclaringType();
        if (declarationType != null) {
          String declarationTypeName=this.variableFormatter.typeToString(declarationType,options);
          String compositeName=String.format(""String_Node_Str"",javaVariable.name,declarationTypeName);
          if (!declarationTypeNames.add(compositeName)) {
            declarationTypeNameConflict=true;
            break;
          }
          variableNameMap.put(javaVariable,compositeName);
        }
      }
      if (declarationTypeNameConflict) {
        for (        Variable javaVariable : duplicateVariables) {
          Type declarationType=javaVariable.getDeclaringType();
          if (declarationType != null) {
            variableNameMap.put(javaVariable,String.format(""String_Node_Str"",javaVariable.name,declarationType.name()));
          }
        }
      }
    }
);
  }
  for (  Variable javaVariable : variables) {
    Value value=javaVariable.value;
    String name=javaVariable.name;
    if (variableNameMap.containsKey(javaVariable)) {
      name=variableNameMap.get(javaVariable);
    }
    int referenceId=0;
    if (value instanceof ObjectReference && VariableUtils.hasChildren(value,showStaticVariables)) {
      ThreadObjectReference threadObjectReference=new ThreadObjectReference(thread,(ObjectReference)value);
      referenceId=this.objectPool.addObject(thread.uniqueID(),threadObjectReference);
    }
    Types.Variable typedVariables=new Types.Variable(name,variableFormatter.valueToString(value,options),variableFormatter.typeToString(value == null ? null : value.type(),options),referenceId,null);
    if (javaVariable.value instanceof ArrayReference) {
      typedVariables.indexedVariables=((ArrayReference)javaVariable.value).length();
    }
    list.add(typedVariables);
  }
  return new Responses.VariablesResponseBody(list);
}","Responses.ResponseBody variables(Requests.VariablesArguments arguments) throws AbsentInformationException {
  Map<String,Object> options=variableFormatter.getDefaultOptions();
  boolean showStaticVariables=true;
  boolean showFullyQualifiedNames=true;
  if (arguments.format != null && arguments.format.hex) {
    options.put(NumericFormatter.NUMERIC_FORMAT_OPTION,NumericFormatEnum.HEX);
  }
  if (showFullyQualifiedNames) {
    options.put(SimpleTypeFormatter.QUALIFIED_CLASS_NAME_OPTION,showFullyQualifiedNames);
  }
  List<Types.Variable> list=new ArrayList<>();
  List<Variable> variables;
  Object obj=this.objectPool.getObjectById(arguments.variablesReference);
  if (obj == null) {
    return new Responses.VariablesResponseBody(list);
  }
  ThreadReference thread;
  if (obj instanceof StackFrameScope) {
    StackFrame frame=((StackFrameScope)obj).getStackFrame();
    thread=frame.thread();
    variables=VariableUtils.listLocalVariables(frame);
    Variable thisVariable=VariableUtils.getThisVariable(frame);
    if (thisVariable != null) {
      variables.add(thisVariable);
    }
    if (showStaticVariables && frame.location().method().isStatic()) {
      variables.addAll(VariableUtils.listStaticVariables(frame));
    }
  }
 else   if (obj instanceof ThreadObjectReference) {
    ObjectReference currentObj=((ThreadObjectReference)obj).getObject();
    thread=((ThreadObjectReference)obj).getThread();
    if (arguments.count > 0) {
      variables=VariableUtils.listFieldVariables(currentObj,arguments.start,arguments.count);
    }
 else {
      variables=VariableUtils.listFieldVariables(currentObj,showStaticVariables);
    }
  }
 else {
    throw new IllegalArgumentException(String.format(""String_Node_Str"",arguments.variablesReference));
  }
  Set<String> duplicateNames=getDuplicateNames(variables.stream().map(var -> var.name).collect(Collectors.toList()));
  Map<Variable,String> variableNameMap=new HashMap<>();
  if (!duplicateNames.isEmpty()) {
    Map<String,List<Variable>> duplicateVars=variables.stream().filter(var -> duplicateNames.contains(var.name)).collect(Collectors.groupingBy(var -> var.name,Collectors.toList()));
    duplicateVars.forEach((k,duplicateVariables) -> {
      Set<String> declarationTypeNames=new HashSet<>();
      boolean declarationTypeNameConflict=false;
      for (      Variable javaVariable : duplicateVariables) {
        Type declarationType=javaVariable.getDeclaringType();
        if (declarationType != null) {
          String declarationTypeName=this.variableFormatter.typeToString(declarationType,options);
          String compositeName=String.format(""String_Node_Str"",javaVariable.name,declarationTypeName);
          if (!declarationTypeNames.add(compositeName)) {
            declarationTypeNameConflict=true;
            break;
          }
          variableNameMap.put(javaVariable,compositeName);
        }
      }
      if (declarationTypeNameConflict) {
        for (        Variable javaVariable : duplicateVariables) {
          Type declarationType=javaVariable.getDeclaringType();
          if (declarationType != null) {
            variableNameMap.put(javaVariable,String.format(""String_Node_Str"",javaVariable.name,declarationType.name()));
          }
        }
      }
    }
);
  }
  for (  Variable javaVariable : variables) {
    Value value=javaVariable.value;
    String name=javaVariable.name;
    if (variableNameMap.containsKey(javaVariable)) {
      name=variableNameMap.get(javaVariable);
    }
    int referenceId=0;
    if (value instanceof ObjectReference && VariableUtils.hasChildren(value,showStaticVariables)) {
      ThreadObjectReference threadObjectReference=new ThreadObjectReference(thread,(ObjectReference)value);
      referenceId=this.objectPool.addObject(thread.uniqueID(),threadObjectReference);
    }
    Types.Variable typedVariables=new Types.Variable(name,variableFormatter.valueToString(value,options),variableFormatter.typeToString(value == null ? null : value.type(),options),referenceId,null);
    if (javaVariable.value instanceof ArrayReference) {
      typedVariables.indexedVariables=((ArrayReference)javaVariable.value).length();
    }
    list.add(typedVariables);
  }
  return new Responses.VariablesResponseBody(list);
}"
37432,"Responses.ResponseBody setVariable(Requests.SetVariableArguments arguments){
  Map<String,Object> options=variableFormatter.getDefaultOptions();
  boolean showStaticVariables=true;
  boolean showFullyQualifiedNames=true;
  if (arguments.format != null && arguments.format.hex) {
    options.put(NumericFormatter.NUMERIC_FORMAT_OPTION,NumericFormatEnum.HEX);
  }
  if (showFullyQualifiedNames) {
    options.put(SimpleTypeFormatter.QUALIFIED_CLASS_NAME_OPTION,showFullyQualifiedNames);
  }
  Object obj=this.objectPool.getObjectById(arguments.variablesReference);
  ThreadReference thread;
  String name=arguments.name;
  Value newValue;
  String belongToClass=null;
  if (arguments.name.contains(""String_Node_Str"")) {
    name=arguments.name.replaceFirst(PATTERN,""String_Node_Str"");
    belongToClass=arguments.name.replaceFirst(PATTERN,""String_Node_Str"");
  }
  try {
    if (obj instanceof StackFrameScope) {
      StackFrameScope frameScope=(StackFrameScope)obj;
      thread=frameScope.getStackFrame().thread();
      newValue=handleSetValueForStackFrame(name,belongToClass,arguments.value,showStaticVariables,frameScope.getStackFrame(),options);
    }
 else     if (obj instanceof ThreadObjectReference) {
      ObjectReference currentObj=((ThreadObjectReference)obj).getObject();
      thread=((ThreadObjectReference)obj).getThread();
      newValue=handleSetValueForObject(name,belongToClass,arguments.value,currentObj,options);
    }
 else {
      throw new IllegalArgumentException(String.format(""String_Node_Str"",arguments.variablesReference));
    }
  }
 catch (  IllegalArgumentException|AbsentInformationException|InvalidTypeException|UnsupportedOperationException|ClassNotLoadedException e) {
    return new Responses.ErrorResponseBody(convertDebuggerMessageToClient(e.getMessage()));
  }
  int referenceId=getReferenceId(thread,newValue,showStaticVariables);
  int indexedVariables=0;
  if (newValue instanceof ArrayReference) {
    indexedVariables=((ArrayReference)newValue).length();
  }
  return new Responses.SetVariablesResponseBody(this.variableFormatter.typeToString(newValue == null ? null : newValue.type(),options),this.variableFormatter.valueToString(newValue,options),referenceId,indexedVariables);
}","Responses.ResponseBody setVariable(Requests.SetVariableArguments arguments){
  Map<String,Object> options=variableFormatter.getDefaultOptions();
  boolean showStaticVariables=true;
  boolean showFullyQualifiedNames=true;
  if (arguments.format != null && arguments.format.hex) {
    options.put(NumericFormatter.NUMERIC_FORMAT_OPTION,NumericFormatEnum.HEX);
  }
  if (showFullyQualifiedNames) {
    options.put(SimpleTypeFormatter.QUALIFIED_CLASS_NAME_OPTION,showFullyQualifiedNames);
  }
  Object obj=this.objectPool.getObjectById(arguments.variablesReference);
  if (obj == null) {
    return new Responses.ErrorResponseBody(convertDebuggerMessageToClient(""String_Node_Str""));
  }
  ThreadReference thread;
  String name=arguments.name;
  Value newValue;
  String belongToClass=null;
  if (arguments.name.contains(""String_Node_Str"")) {
    name=arguments.name.replaceFirst(PATTERN,""String_Node_Str"");
    belongToClass=arguments.name.replaceFirst(PATTERN,""String_Node_Str"");
  }
  try {
    if (obj instanceof StackFrameScope) {
      StackFrameScope frameScope=(StackFrameScope)obj;
      thread=frameScope.getStackFrame().thread();
      newValue=handleSetValueForStackFrame(name,belongToClass,arguments.value,showStaticVariables,frameScope.getStackFrame(),options);
    }
 else     if (obj instanceof ThreadObjectReference) {
      ObjectReference currentObj=((ThreadObjectReference)obj).getObject();
      thread=((ThreadObjectReference)obj).getThread();
      newValue=handleSetValueForObject(name,belongToClass,arguments.value,currentObj,options);
    }
 else {
      throw new IllegalArgumentException(String.format(""String_Node_Str"",arguments.variablesReference));
    }
  }
 catch (  IllegalArgumentException|AbsentInformationException|InvalidTypeException|UnsupportedOperationException|ClassNotLoadedException e) {
    return new Responses.ErrorResponseBody(convertDebuggerMessageToClient(e.getMessage()));
  }
  int referenceId=getReferenceId(thread,newValue,showStaticVariables);
  int indexedVariables=0;
  if (newValue instanceof ArrayReference) {
    indexedVariables=((ArrayReference)newValue).length();
  }
  return new Responses.SetVariablesResponseBody(this.variableFormatter.typeToString(newValue == null ? null : newValue.type(),options),this.variableFormatter.valueToString(newValue,options),referenceId,indexedVariables);
}"
37433,"@Override public String getSourceFileURI(String fullyQualifiedName,String sourcePath){
  if (fullyQualifiedName == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  String projectName=(String)context.get(Constants.PROJECTNAME);
  try {
    IJavaSearchScope searchScope=projectName != null ? JDTUtils.createSearchScope(getJavaProjectFromName(projectName)) : SearchEngine.createWorkspaceScope();
    SearchPattern pattern=SearchPattern.createPattern(fullyQualifiedName,IJavaSearchConstants.TYPE,IJavaSearchConstants.DECLARATIONS,SearchPattern.R_EXACT_MATCH);
    ArrayList<String> uris=new ArrayList<String>();
    SearchRequestor requestor=new SearchRequestor(){
      @Override public void acceptSearchMatch(      SearchMatch match){
        Object element=match.getElement();
        if (element instanceof IType) {
          IType type=(IType)element;
          uris.add(type.isBinary() ? JDTUtils.getFileURI(type.getClassFile()) : JDTUtils.getFileURI(type.getResource()));
        }
      }
    }
;
    SearchEngine searchEngine=new SearchEngine();
    searchEngine.search(pattern,new SearchParticipant[]{SearchEngine.getDefaultSearchParticipant()},searchScope,requestor,null);
    return uris.size() == 0 ? null : uris.get(0);
  }
 catch (  CoreException e) {
    Logger.logException(""String_Node_Str"",e);
  }
  return null;
}","@Override public String getSourceFileURI(String fullyQualifiedName,String sourcePath){
  if (fullyQualifiedName == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (fullyQualifiedName.indexOf(""String_Node_Str"") >= 0) {
    return searchDeclarationFileByFqn(AdapterUtils.parseEnclosingType(fullyQualifiedName));
  }
 else {
    return searchDeclarationFileByFqn(fullyQualifiedName);
  }
}"
37434,"@Override public void setExceptionBreakpoints(boolean notifyCaught,boolean notifyUncaught){
  EventRequestManager manager=vm.eventRequestManager();
  ArrayList<ExceptionRequest> legacy=new ArrayList<ExceptionRequest>(manager.exceptionRequests());
  manager.deleteEventRequests(legacy);
  ExceptionRequest request=manager.createExceptionRequest(null,notifyCaught,notifyUncaught);
  request.enable();
}","@Override public void setExceptionBreakpoints(boolean notifyCaught,boolean notifyUncaught){
  EventRequestManager manager=vm.eventRequestManager();
  ArrayList<ExceptionRequest> legacy=new ArrayList<ExceptionRequest>(manager.exceptionRequests());
  manager.deleteEventRequests(legacy);
  ExceptionRequest request=manager.createExceptionRequest(null,notifyCaught,notifyUncaught);
  request.setSuspendPolicy(EventRequest.SUSPEND_EVENT_THREAD);
  request.enable();
}"
37435,"/** 
 * Get the local variables of an stack frame.
 * @param stackFrame the stack frame
 * @return local variable list
 * @throws AbsentInformationException when there is any error in retrieving information
 */
public static List<Variable> listLocalVariables(StackFrame stackFrame) throws AbsentInformationException {
  List<Variable> res=new ArrayList<>();
  try {
    for (    LocalVariable localVariable : stackFrame.visibleVariables()) {
      Variable var=new Variable(localVariable.name(),stackFrame.getValue(localVariable));
      var.local=localVariable;
      res.add(var);
    }
  }
 catch (  AbsentInformationException ex) {
    int argId=0;
    try {
      for (      Value argValue : stackFrame.getArgumentValues()) {
        Variable var=new Variable(""String_Node_Str"" + argId,argValue);
        var.argumentIndex=argId++;
        res.add(var);
      }
    }
 catch (    InternalException ex2) {
      if (ex2.errorCode() != 32) {
        throw ex;
      }
    }
  }
  return res;
}","/** 
 * Get the local variables of an stack frame.
 * @param stackFrame the stack frame
 * @return local variable list
 * @throws AbsentInformationException when there is any error in retrieving information
 */
public static List<Variable> listLocalVariables(StackFrame stackFrame) throws AbsentInformationException {
  List<Variable> res=new ArrayList<>();
  try {
    for (    LocalVariable localVariable : stackFrame.visibleVariables()) {
      Variable var=new Variable(localVariable.name(),stackFrame.getValue(localVariable));
      var.local=localVariable;
      res.add(var);
    }
  }
 catch (  AbsentInformationException ex) {
    int argId=0;
    try {
      List<Value> arguments=stackFrame.getArgumentValues();
      if (arguments == null) {
        return res;
      }
      for (      Value argValue : arguments) {
        Variable var=new Variable(""String_Node_Str"" + argId,argValue);
        var.argumentIndex=argId++;
        res.add(var);
      }
    }
 catch (    InternalException ex2) {
      if (ex2.errorCode() != 32) {
        throw ex;
      }
    }
  }
  return res;
}"
37436,"private void checkThreadRunningAndRecycleIds(ThreadReference thread){
  if (allThreadRunning()) {
    this.variableRequestHandler.recyclableAllObject();
  }
 else {
    this.variableRequestHandler.recyclableThreads(thread);
  }
}","private void checkThreadRunningAndRecycleIds(ThreadReference thread){
  try {
    if (allThreadRunning()) {
      this.variableRequestHandler.recyclableAllObject();
    }
 else {
      this.variableRequestHandler.recyclableThreads(thread);
    }
  }
 catch (  VMDisconnectedException ex) {
    this.variableRequestHandler.recyclableAllObject();
  }
}"
37437,"/** 
 * Get the local variables of an stack frame.
 * @param stackFrame the stack frame
 * @return local variable list
 * @throws AbsentInformationException when there is any error in retrieving information
 */
public static List<Variable> listLocalVariables(StackFrame stackFrame) throws AbsentInformationException {
  List<Variable> res=new ArrayList<>();
  try {
    for (    LocalVariable localVariable : stackFrame.visibleVariables()) {
      Variable var=new Variable(localVariable.name(),stackFrame.getValue(localVariable));
      var.local=localVariable;
      res.add(var);
    }
  }
 catch (  AbsentInformationException ex) {
    int argId=0;
    try {
      List<Value> arguments=stackFrame.getArgumentValues();
      if (arguments == null) {
        return res;
      }
      for (      Value argValue : arguments) {
        Variable var=new Variable(""String_Node_Str"" + argId,argValue);
        var.argumentIndex=argId++;
        res.add(var);
      }
    }
 catch (    InternalException ex2) {
      if (ex2.errorCode() != 32) {
        throw ex;
      }
    }
  }
  return res;
}","/** 
 * Get the local variables of an stack frame.
 * @param stackFrame the stack frame
 * @return local variable list
 * @throws AbsentInformationException when there is any error in retrieving information
 */
public static List<Variable> listLocalVariables(StackFrame stackFrame) throws AbsentInformationException {
  List<Variable> res=new ArrayList<>();
  try {
    for (    LocalVariable localVariable : stackFrame.visibleVariables()) {
      Variable var=new Variable(localVariable.name(),stackFrame.getValue(localVariable));
      var.local=localVariable;
      res.add(var);
    }
  }
 catch (  AbsentInformationException ex) {
    if (stackFrame.location().method().isNative()) {
      return res;
    }
    int argId=0;
    try {
      List<Value> arguments=stackFrame.getArgumentValues();
      if (arguments == null) {
        return res;
      }
      for (      Value argValue : arguments) {
        Variable var=new Variable(""String_Node_Str"" + argId,argValue);
        var.argumentIndex=argId++;
        res.add(var);
      }
    }
 catch (    InternalException ex2) {
      if (ex2.errorCode() != 32) {
        throw ex;
      }
    }
  }
  return res;
}"
37438,"private void openUserProfile(){
  openPage(ConstantUtil.USER_PROFILE_SELF_FAKE_URL,getString(R.string.profile));
}","private void openUserProfile(){
  openPage(ConstantUtil.USER_PROFILE_SELF_FAKE_URL,getString(R.string.personal_center));
}"
37439,"private void initViews(){
  initWebView();
  initRecyclerView();
  mCommentEditText.addTextChangedListener(new TextWatcher(){
    @Override public void beforeTextChanged(    CharSequence charSequence,    int i,    int i1,    int i2){
    }
    @Override public void onTextChanged(    CharSequence charSequence,    int i,    int i1,    int i2){
    }
    @Override public void afterTextChanged(    Editable editable){
      mSubmitButton.setEnabled(!TextUtils.isEmpty(editable));
    }
  }
);
}","private void initViews(){
  initWebView();
  initRecyclerView();
  mCommentEditText.addTextChangedListener(new TextWatcher(){
    @Override public void beforeTextChanged(    CharSequence charSequence,    int i,    int i1,    int i2){
    }
    @Override public void onTextChanged(    CharSequence charSequence,    int i,    int i1,    int i2){
    }
    @Override public void afterTextChanged(    Editable editable){
      mSubmitButton.setEnabled(!TextUtils.isEmpty(editable));
    }
  }
);
  mCommentEditText.setOnFocusChangeListener(new View.OnFocusChangeListener(){
    @Override public void onFocusChange(    View v,    boolean hasFocus){
      if (hasFocus) {
        InputMethodManager imm=(InputMethodManager)getActivity().getSystemService(Context.INPUT_METHOD_SERVICE);
        imm.toggleSoftInput(InputMethodManager.SHOW_FORCED,0);
      }
 else {
        InputMethodManager imm=(InputMethodManager)getActivity().getSystemService(Context.INPUT_METHOD_SERVICE);
        imm.hideSoftInputFromWindow(v.getWindowToken(),0);
      }
    }
  }
);
  mCommentEditText.setParentView(mCommentsView);
}"
37440,"@Override public void onGetTopicListFailed(String msg){
  finishRefresh();
  if (getContext() == null) {
    return;
  }
  Toast.makeText(getActivity(),msg,Toast.LENGTH_SHORT).show();
  handleEmptyList();
}","@Override public void onGetTopicListFailed(String msg){
  finishRefresh();
  if (getContext() == null) {
    return;
  }
  mNoContentTextView.setText(R.string.no_content);
  Toast.makeText(getActivity(),msg,Toast.LENGTH_SHORT).show();
  handleEmptyList();
}"
37441,"@Override public void onRefresh(){
  if (!mFirstFetchFinished) {
    return;
  }
  mPresenter.getTopicList();
}","@Override public void onRefresh(){
  if (!mFirstFetchFinished) {
    return;
  }
  mNoContentTextView.setText(""String_Node_Str"");
  mPresenter.getTopicList();
}"
37442,"private void initSwipeLayout(SwipeRefreshLayout swipeRefreshLayout){
  swipeRefreshLayout.setOnRefreshListener(this);
  swipeRefreshLayout.setColorSchemeResources(R.color.metaColor,R.color.colorAccent,android.R.color.white);
}","private void initSwipeLayout(SwipeRefreshLayout swipeRefreshLayout){
  swipeRefreshLayout.setOnRefreshListener(this);
  swipeRefreshLayout.setColorSchemeResources(R.color.main);
}"
37443,"@Override public void onGetTopicListSucceed(TopicList topicList){
  finishRefresh();
  if (getContext() == null) {
    return;
  }
  mLoadable=topicList.isHasMore();
  mAdapter.setData(topicList.getTopics());
  handleEmptyList();
}","@Override public void onGetTopicListSucceed(TopicList topicList){
  finishRefresh();
  if (getContext() == null) {
    return;
  }
  if (topicList.getTopics().isEmpty()) {
    mNoContentTextView.setText(R.string.no_content);
  }
  mLoadable=topicList.isHasMore();
  mAdapter.setData(topicList.getTopics());
  handleEmptyList();
}"
37444,"@OnClick({R.id.user_favors,R.id.user_topics,R.id.user_replies,R.id.logout}) public void onClick(View v){
  if (mListener == null || mUserProfile == null) {
    return;
  }
switch (v.getId()) {
case R.id.user_favors:
    mListener.openPage(String.format(ConstantUtil.USER_FAVORS_BASE_URL,mUserProfile.getUsername()),mFavoriteTextView.getText().toString());
  break;
case R.id.user_topics:
mListener.openPage(String.format(ConstantUtil.USER_TOPICS_BASE_URL,mUserProfile.getUsername()),mTopicTextView.getText().toString());
break;
case R.id.user_replies:
mListener.openPage(String.format(ConstantUtil.USER_REPLIES_BASE_URL,mUserProfile.getUsername()),mReplyTextView.getText().toString());
break;
case R.id.logout:
mListener.onLoginStatusChanged(false);
getActivity().onBackPressed();
break;
default :
break;
}
}","@Override public void onClick(DialogInterface dialog,int which){
  mListener.onLoginStatusChanged(false);
  getActivity().onBackPressed();
}"
37445,"public GetTopicListTask(String url,OnResponseListener<List<Topic>> listener){
  super(listener);
  mUrl=url;
}","public GetTopicListTask(String url,OnResponseListener<TopicList> listener){
  super(listener);
  mUrl=url;
}"
37446,"@Override public void run(){
  List<Topic> topics=new ArrayList<>();
  boolean succeed=false;
  try {
    Document doc=getConnection(mUrl).get();
    Elements elements=doc.select(""String_Node_Str"");
    for (    Element element : elements) {
      Topic topic=createTopicFromElement(element);
      topics.add(topic);
    }
    succeed=true;
  }
 catch (  IOException e) {
    e.printStackTrace();
  }
  if (succeed) {
    if (topics.size() > 0) {
      successOnUI(topics);
    }
 else {
      failedOnUI(""String_Node_Str"");
    }
  }
 else {
    failedOnUI(""String_Node_Str"");
  }
}","@Override public void run(){
  List<Topic> topics=new ArrayList<>();
  boolean succeed=false;
  boolean hasMore=false;
  try {
    Document doc=getConnection(mUrl).get();
    Elements elements=doc.select(""String_Node_Str"");
    for (    Element element : elements) {
      Topic topic=createTopicFromElement(element);
      topics.add(topic);
    }
    succeed=true;
    Elements paginationElements=doc.select(""String_Node_Str"");
    if (!paginationElements.isEmpty()) {
      Elements disabledElements=paginationElements.select(""String_Node_Str"");
      if (disabledElements.isEmpty()) {
        hasMore=true;
      }
 else       if (disabledElements.last() != null) {
        Elements disableLinkElements=disabledElements.last().select(""String_Node_Str"");
        if (!""String_Node_Str"".equals(disableLinkElements.text())) {
          hasMore=true;
        }
      }
    }
  }
 catch (  IOException e) {
    e.printStackTrace();
  }
  if (succeed) {
    if (topics.size() > 0) {
      TopicList topicList=new TopicList();
      topicList.setTopics(topics);
      topicList.setHasMore(hasMore);
      successOnUI(topicList);
    }
 else {
      failedOnUI(""String_Node_Str"");
    }
  }
 else {
    failedOnUI(""String_Node_Str"");
  }
}"
37447,void onGetTopicListSucceed(List<Topic> topicList);,void onGetTopicListSucceed(TopicList topicList);
37448,void onGetMoreTopicSucceed(List<Topic> topicList);,void onGetMoreTopicSucceed(TopicList topicList);
37449,"@Override public void onGetTopicListSucceed(List<Topic> topicList){
  if (getContext() == null) {
    return;
  }
  mAdapter.setData(topicList);
}","@Override public void onGetTopicListSucceed(TopicList topicList){
  if (getContext() == null) {
    return;
  }
  mLoadable=topicList.isHasMore();
  mAdapter.setData(topicList.getTopics());
}"
37450,"@Override public View onCreateView(LayoutInflater inflater,ViewGroup container,Bundle savedInstanceState){
  View view=inflater.inflate(R.layout.fragment_topic_list,container,false);
  initParams();
  if (view instanceof RecyclerView) {
    Context context=view.getContext();
    RecyclerView recyclerView=(RecyclerView)view;
    final LinearLayoutManager layoutManager=new LinearLayoutManager(context);
    recyclerView.setLayoutManager(layoutManager);
    recyclerView.addItemDecoration(new RecyclerView.ItemDecoration(){
      @Override public void getItemOffsets(      Rect outRect,      View view,      RecyclerView parent,      RecyclerView.State state){
        outRect.set(0,0,0,1);
      }
    }
);
    if (mAdapter == null) {
      mAdapter=new TopicListAdapter(mListener);
    }
    recyclerView.setAdapter(mAdapter);
    recyclerView.addOnScrollListener(new RecyclerView.OnScrollListener(){
      @Override public void onScrolled(      RecyclerView recyclerView,      int dx,      int dy){
        if (dy > 0) {
          visibleItemCount=layoutManager.getChildCount();
          totalItemCount=layoutManager.getItemCount();
          pastVisibleItems=layoutManager.findFirstVisibleItemPosition();
          if (mLoadable) {
            if ((visibleItemCount + pastVisibleItems) >= totalItemCount) {
              mLoadable=false;
              if (totalItemCount > ConstantUtil.TOPICS_PER_PAGE && totalItemCount <= 1024) {
                mPresenter.getMoreTopic(totalItemCount / ConstantUtil.TOPICS_PER_PAGE + 1);
              }
 else {
                Toast.makeText(getActivity(),""String_Node_Str"",Toast.LENGTH_SHORT).show();
              }
            }
          }
        }
      }
    }
);
  }
  if (!mAdapter.isFilled()) {
    mPresenter.getTopicList();
  }
  return view;
}","@Override public View onCreateView(LayoutInflater inflater,ViewGroup container,Bundle savedInstanceState){
  View view=inflater.inflate(R.layout.fragment_topic_list,container,false);
  initParams();
  if (view instanceof RecyclerView) {
    Context context=view.getContext();
    RecyclerView recyclerView=(RecyclerView)view;
    final LinearLayoutManager layoutManager=new LinearLayoutManager(context);
    recyclerView.setLayoutManager(layoutManager);
    recyclerView.addItemDecoration(new RecyclerView.ItemDecoration(){
      @Override public void getItemOffsets(      Rect outRect,      View view,      RecyclerView parent,      RecyclerView.State state){
        outRect.set(0,0,0,1);
      }
    }
);
    if (mAdapter == null) {
      mAdapter=new TopicListAdapter(mListener);
    }
    recyclerView.setAdapter(mAdapter);
    recyclerView.addOnScrollListener(new RecyclerView.OnScrollListener(){
      @Override public void onScrolled(      RecyclerView recyclerView,      int dx,      int dy){
        if (dy > 0) {
          visibleItemCount=layoutManager.getChildCount();
          totalItemCount=layoutManager.getItemCount();
          pastVisibleItems=layoutManager.findFirstVisibleItemPosition();
          if (mLoadable) {
            if ((visibleItemCount + pastVisibleItems) >= totalItemCount) {
              mLoadable=false;
              if (totalItemCount >= ConstantUtil.TOPICS_PER_PAGE && totalItemCount <= 1024) {
                mPresenter.getMoreTopic(totalItemCount / ConstantUtil.TOPICS_PER_PAGE + 1);
              }
 else {
                Toast.makeText(getActivity(),""String_Node_Str"",Toast.LENGTH_SHORT).show();
              }
            }
          }
        }
      }
    }
);
  }
  if (!mAdapter.isFilled()) {
    mPresenter.getTopicList();
  }
  return view;
}"
37451,"@Override public void onScrolled(RecyclerView recyclerView,int dx,int dy){
  if (dy > 0) {
    visibleItemCount=layoutManager.getChildCount();
    totalItemCount=layoutManager.getItemCount();
    pastVisibleItems=layoutManager.findFirstVisibleItemPosition();
    if (mLoadable) {
      if ((visibleItemCount + pastVisibleItems) >= totalItemCount) {
        mLoadable=false;
        if (totalItemCount > ConstantUtil.TOPICS_PER_PAGE && totalItemCount <= 1024) {
          mPresenter.getMoreTopic(totalItemCount / ConstantUtil.TOPICS_PER_PAGE + 1);
        }
 else {
          Toast.makeText(getActivity(),""String_Node_Str"",Toast.LENGTH_SHORT).show();
        }
      }
    }
  }
}","@Override public void onScrolled(RecyclerView recyclerView,int dx,int dy){
  if (dy > 0) {
    visibleItemCount=layoutManager.getChildCount();
    totalItemCount=layoutManager.getItemCount();
    pastVisibleItems=layoutManager.findFirstVisibleItemPosition();
    if (mLoadable) {
      if ((visibleItemCount + pastVisibleItems) >= totalItemCount) {
        mLoadable=false;
        if (totalItemCount >= ConstantUtil.TOPICS_PER_PAGE && totalItemCount <= 1024) {
          mPresenter.getMoreTopic(totalItemCount / ConstantUtil.TOPICS_PER_PAGE + 1);
        }
 else {
          Toast.makeText(getActivity(),""String_Node_Str"",Toast.LENGTH_SHORT).show();
        }
      }
    }
  }
}"
37452,"@Override public void onGetMoreTopicSucceed(List<Topic> topicList){
  if (getContext() == null) {
    return;
  }
  mAdapter.addData(topicList);
  mLoadable=true;
}","@Override public void onGetMoreTopicSucceed(TopicList topicList){
  if (getContext() == null) {
    return;
  }
  mLoadable=topicList.isHasMore();
  mAdapter.addData(topicList.getTopics());
}"
37453,"@Override public void getMoreTopic(int page){
  NetworkTaskScheduler.getInstance().execute(new GetTopicListTask(UrlUtil.appendPage(mView.getUrl(),page),new OnResponseListener<List<Topic>>(){
    @Override public void onSucceed(    List<Topic> data){
      mView.onGetMoreTopicSucceed(data);
    }
    @Override public void onFailed(    String msg){
      mView.onGetMoreTopicFailed(msg);
    }
  }
));
}","@Override public void getMoreTopic(int page){
  NetworkTaskScheduler.getInstance().execute(new GetTopicListTask(UrlUtil.appendPage(mView.getUrl(),page),new OnResponseListener<TopicList>(){
    @Override public void onSucceed(    TopicList data){
      mView.onGetMoreTopicSucceed(data);
    }
    @Override public void onFailed(    String msg){
      mView.onGetMoreTopicFailed(msg);
    }
  }
));
}"
37454,"@Override public void getTopicList(){
  NetworkTaskScheduler.getInstance().execute(new GetTopicListTask(mView.getUrl(),new OnResponseListener<List<Topic>>(){
    @Override public void onSucceed(    List<Topic> data){
      mView.onGetTopicListSucceed(data);
    }
    @Override public void onFailed(    String msg){
      mView.onGetTopicListFailed(msg);
    }
  }
));
}","@Override public void getTopicList(){
  NetworkTaskScheduler.getInstance().execute(new GetTopicListTask(mView.getUrl(),new OnResponseListener<TopicList>(){
    @Override public void onSucceed(    TopicList data){
      mView.onGetTopicListSucceed(data);
    }
    @Override public void onFailed(    String msg){
      mView.onGetTopicListFailed(msg);
    }
  }
));
}"
37455,"@Override public void onSucceed(List<Topic> data){
  mView.onGetMoreTopicSucceed(data);
}","@Override public void onSucceed(TopicList data){
  mView.onGetMoreTopicSucceed(data);
}"
37456,"@Override public void updateState(String state,String logMessage,int localizedResId,ConnectionStatus level){
  Logger.logError(""String_Node_Str"",state + ""String_Node_Str"" + logMessage+ ""String_Node_Str""+ getString(localizedResId),null);
  runOnUiThread(() -> {
    if (state.equals(""String_Node_Str"") || (state.equals(""String_Node_Str""))) {
      if (AppPreferences.getInstance().getLong(AppConstants.PREFS_CONNECTION_START_TIME) == 0L && state.equals(""String_Node_Str""))       AppPreferences.getInstance().saveLong(AppConstants.PREFS_CONNECTION_START_TIME,System.currentTimeMillis());
      SentinelLiteApp.isVpnConnected=true;
    }
    if (!VpnStatus.isVPNActive()) {
      if (SentinelLiteApp.isVpnConnected && !mHasActivityResult) {
        SentinelLiteApp.isVpnInitiated=false;
        SentinelLiteApp.isVpnConnected=false;
        AppPreferences.getInstance().saveLong(AppConstants.PREFS_CONNECTION_START_TIME,0L);
        loadVpnFragment(state.equals(""String_Node_Str"") ? null : getString(localizedResId));
      }
    }
    if (state.equals(""String_Node_Str"")) {
      SentinelLiteApp.isVpnInitiated=false;
      SentinelLiteApp.isVpnConnected=false;
      AppPreferences.getInstance().saveLong(AppConstants.PREFS_CONNECTION_START_TIME,0L);
      loadVpnFragment(getString(localizedResId));
    }
    if (mHasActivityResult) {
      onVpnConnectionInitiated(AppPreferences.getInstance().getString(AppConstants.PREFS_CONFIG_PATH));
      mHasActivityResult=false;
    }
  }
);
}","@Override public void updateState(String state,String logMessage,int localizedResId,ConnectionStatus level){
  Logger.logError(""String_Node_Str"",state + ""String_Node_Str"" + logMessage+ ""String_Node_Str""+ getString(localizedResId),null);
  runOnUiThread(() -> {
    if (state.equals(""String_Node_Str"") || (state.equals(""String_Node_Str""))) {
      if (AppPreferences.getInstance().getLong(AppConstants.PREFS_CONNECTION_START_TIME) == 0L && state.equals(""String_Node_Str""))       AppPreferences.getInstance().saveLong(AppConstants.PREFS_CONNECTION_START_TIME,System.currentTimeMillis());
      SentinelLiteApp.isVpnConnected=true;
    }
    if (!VpnStatus.isVPNActive()) {
      if (SentinelLiteApp.isVpnConnected && !mHasActivityResult) {
        SentinelLiteApp.isVpnInitiated=false;
        SentinelLiteApp.isVpnConnected=false;
        AppPreferences.getInstance().saveLong(AppConstants.PREFS_CONNECTION_START_TIME,0L);
        loadVpnFragment(null);
      }
    }
    if (state.equals(""String_Node_Str"")) {
      SentinelLiteApp.isVpnInitiated=false;
      SentinelLiteApp.isVpnConnected=false;
      AppPreferences.getInstance().saveLong(AppConstants.PREFS_CONNECTION_START_TIME,0L);
      loadVpnFragment(getString(localizedResId));
    }
    if (mHasActivityResult) {
      onVpnConnectionInitiated(AppPreferences.getInstance().getString(AppConstants.PREFS_CONFIG_PATH));
      mHasActivityResult=false;
    }
  }
);
}"
37457,"private void initView(){
  mPrgDialog=ProgressDialogFragment.newInstance(true);
  mTetReferral=findViewById(R.id.tet_referral);
  findViewById(R.id.btn_next).setOnClickListener(this);
  mTetReferral.addTextChangedListener(this);
}","private void initView(){
  mPrgDialog=ProgressDialogFragment.newInstance(true);
  mTetReferral=findViewById(R.id.tet_referral);
  mTetReferral.setFilters(new InputFilter[]{new InputFilter.AllCaps()});
  findViewById(R.id.btn_next).setOnClickListener(this);
  mTetReferral.addTextChangedListener(this);
}"
37458,"private void initView(){
  mVpInfoPager=findViewById(R.id.vp_info_pager);
  mVpiInfoDots=findViewById(R.id.vpi_info_dots);
  mTvNext=findViewById(R.id.btn_next);
  mAdapter=new InfoPagerAdapter(getSupportFragmentManager(),this);
  mVpInfoPager.setAdapter(mAdapter);
  mVpInfoPager.setPageTransformer(true,new ZoomOutPageTransformer());
  mVpInfoPager.addOnPageChangeListener(new ViewPager.OnPageChangeListener(){
    @Override public void onPageScrolled(    int position,    float positionOffset,    int positionOffsetPixels){
    }
    @Override public void onPageSelected(    int position){
      mTvNext.setVisibility(position == 1 ? View.VISIBLE : View.GONE);
    }
    @Override public void onPageScrollStateChanged(    int state){
    }
  }
);
  mVpiInfoDots.setDotsClickable(true);
  mVpiInfoDots.setViewPager(mVpInfoPager);
  mTvNext.setOnClickListener(v -> openLauncherActivity());
}","private void initView(){
  mVpInfoPager=findViewById(R.id.vp_info_pager);
  mVpiInfoDots=findViewById(R.id.vpi_info_dots);
  mTvNext=findViewById(R.id.btn_next);
  mAdapter=new InfoPagerAdapter(getSupportFragmentManager(),this);
  mVpInfoPager.setAdapter(mAdapter);
  mVpInfoPager.setPageTransformer(true,new ZoomOutPageTransformer());
  mVpiInfoDots.setDotsClickable(true);
  mVpiInfoDots.setViewPager(mVpInfoPager);
  mTvNext.setOnClickListener(new View.OnClickListener(){
    @Override public void onClick(    View v){
      int aCurrentItem=mVpInfoPager.getCurrentItem();
      if (aCurrentItem == 0) {
        mVpInfoPager.setCurrentItem(mVpInfoPager.getCurrentItem() + 1);
      }
 else {
        openLauncherActivity();
      }
    }
  }
);
}"
37459,"private void setBalanceValue(Chains iData){
  boolean aIsChecked=AppPreferences.getInstance().getBoolean(AppConstants.PREFS_IS_TEST_NET_ACTIVE);
  mTvTotalEther.setText(mViewModel.getFormattedEthBalance(aIsChecked ? iData.getRinkeby().eths : iData.getMain().eths));
  mTvTotalSent.setText(mViewModel.getFormattedSentBalance(aIsChecked ? iData.getRinkeby().sents : iData.getMain().sents));
  setTextDesc(aIsChecked);
}","private void setBalanceValue(Chains iData){
  if (iData != null) {
    boolean aIsChecked=AppPreferences.getInstance().getBoolean(AppConstants.PREFS_IS_TEST_NET_ACTIVE);
    mTvTotalEther.setText(mViewModel.getFormattedEthBalance(aIsChecked ? iData.getRinkeby().eths : iData.getMain().eths));
    mTvTotalSent.setText(mViewModel.getFormattedSentBalance(aIsChecked ? iData.getRinkeby().sents : iData.getMain().sents));
    setTextDesc(aIsChecked);
  }
}"
37460,"public void updateBalance(boolean isChecked){
  setBalanceValue(mViewModel.updateBalance(isChecked));
}","public void updateBalance(){
  setBalanceValue(mViewModel.updateBalance());
}"
37461,"public Chains updateBalance(boolean isChecked){
  return mBalanceLiveData.getValue();
}","public Chains updateBalance(){
  return mBalanceLiveData.getValue();
}"
37462,"@Override public void onCreate(){
  super.onCreate();
  PRNGFixes.apply();
  Bugsnag.init(this);
  if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.O) {
    createNotificationChannels();
  }
  StatusListener mStatus=new StatusListener();
  mStatus.init(getApplicationContext());
  sInstance=this;
  MultiDex.install(this);
  if (AppPreferences.getInstance().getString(AppConstants.PREFS_FILE_PATH).isEmpty()) {
    String aFilePath=new File(getFilesDir(),AppConstants.FILE_NAME).getAbsolutePath();
    AppPreferences.getInstance().saveString(AppConstants.PREFS_FILE_PATH,aFilePath);
  }
  if (AppPreferences.getInstance().getString(AppConstants.PREFS_CONFIG_PATH).isEmpty()) {
    String aConfigPath=new File(getFilesDir(),AppConstants.CONFIG_NAME).getAbsolutePath();
    AppPreferences.getInstance().saveString(AppConstants.PREFS_CONFIG_PATH,aConfigPath);
  }
}","@Override public void onCreate(){
  super.onCreate();
  PRNGFixes.apply();
  Bugsnag.init(this);
  if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.O) {
    createNotificationChannels();
  }
  if (Build.VERSION.SDK_INT < Build.VERSION_CODES.LOLLIPOP) {
    upgradeSecurityProvider();
  }
  StatusListener mStatus=new StatusListener();
  mStatus.init(getApplicationContext());
  sInstance=this;
  MultiDex.install(this);
  if (AppPreferences.getInstance().getString(AppConstants.PREFS_FILE_PATH).isEmpty()) {
    String aFilePath=new File(getFilesDir(),AppConstants.FILE_NAME).getAbsolutePath();
    AppPreferences.getInstance().saveString(AppConstants.PREFS_FILE_PATH,aFilePath);
  }
  if (AppPreferences.getInstance().getString(AppConstants.PREFS_CONFIG_PATH).isEmpty()) {
    String aConfigPath=new File(getFilesDir(),AppConstants.CONFIG_NAME).getAbsolutePath();
    AppPreferences.getInstance().saveString(AppConstants.PREFS_CONFIG_PATH,aConfigPath);
  }
}"
37463,"private static void setupRestClient(){
  HttpLoggingInterceptor aLoggingInterceptor=new HttpLoggingInterceptor();
  aLoggingInterceptor.setLevel(BuildConfig.DEBUG ? HttpLoggingInterceptor.Level.BODY : HttpLoggingInterceptor.Level.NONE);
  ContentTypeInterceptor aContentTypeInterceptor=new ContentTypeInterceptor();
  OkHttpClient aClient=new OkHttpClient.Builder().connectTimeout(30,TimeUnit.SECONDS).readTimeout(30,TimeUnit.SECONDS).writeTimeout(30,TimeUnit.SECONDS).retryOnConnectionFailure(false).addInterceptor(aLoggingInterceptor).addInterceptor(aContentTypeInterceptor).build();
  Retrofit aRetrofit=new Retrofit.Builder().baseUrl(BASE_URL).client(aClient).addConverterFactory(GsonConverterFactory.create()).build();
  sWebService=aRetrofit.create(WebService.class);
}","private static void setupRestClient(){
  HttpLoggingInterceptor aLoggingInterceptor=new HttpLoggingInterceptor();
  aLoggingInterceptor.setLevel(BuildConfig.DEBUG ? HttpLoggingInterceptor.Level.BODY : HttpLoggingInterceptor.Level.NONE);
  ContentTypeInterceptor aContentTypeInterceptor=new ContentTypeInterceptor();
  OkHttpClient.Builder aClientBuilder=new OkHttpClient.Builder().connectTimeout(30,TimeUnit.SECONDS).readTimeout(30,TimeUnit.SECONDS).writeTimeout(30,TimeUnit.SECONDS).retryOnConnectionFailure(false).addInterceptor(aLoggingInterceptor).addInterceptor(aContentTypeInterceptor);
  OkHttpClient aClient=enableTls12OnPreLollipop(aClientBuilder).build();
  Retrofit aRetrofit=new Retrofit.Builder().baseUrl(BASE_URL).client(aClient).addConverterFactory(GsonConverterFactory.create()).build();
  sWebService=aRetrofit.create(WebService.class);
}"
37464,"private void getUnoccupiedVpnList(){
  mVpnListMutableLiveData.postValue(Resource.loading(null));
  mWebService.getUnoccupiedVpnList().enqueue(new Callback<Vpn>(){
    @Override public void onResponse(    Call<Vpn> call,    Response<Vpn> response){
      reportSuccessResponse(response);
    }
    @Override public void onFailure(    Call<Vpn> call,    Throwable t){
      reportErrorResponse(t.getLocalizedMessage());
    }
    private void reportSuccessResponse(    Response<Vpn> response){
      if (response != null && response.body() != null) {
        if (response.body().success)         mVpnListMutableLiveData.postValue(Resource.success(response.body()));
 else         reportErrorResponse(Resources.getSystem().getString(R.string.empty_vpn_list));
      }
    }
    private void reportErrorResponse(    String iThrowableLocalMessage){
      if (iThrowableLocalMessage != null)       mVpnListMutableLiveData.postValue(Resource.error(iThrowableLocalMessage,null));
 else       mVpnListMutableLiveData.postValue(Resource.error(AppConstants.GENERIC_ERROR,null));
    }
  }
);
}","private void getUnoccupiedVpnList(){
  mWebService.getUnoccupiedVpnList().enqueue(new Callback<Vpn>(){
    @Override public void onResponse(    Call<Vpn> call,    Response<Vpn> response){
      reportSuccessResponse(response);
    }
    @Override public void onFailure(    Call<Vpn> call,    Throwable t){
      reportErrorResponse(t.getLocalizedMessage());
    }
    private void reportSuccessResponse(    Response<Vpn> response){
      if (response != null && response.body() != null) {
        if (response.body().success)         mVpnListMutableLiveData.postValue(Resource.success(response.body()));
 else         reportErrorResponse(Resources.getSystem().getString(R.string.empty_vpn_list));
      }
    }
    private void reportErrorResponse(    String iThrowableLocalMessage){
      if (iThrowableLocalMessage != null)       mVpnListMutableLiveData.postValue(Resource.error(iThrowableLocalMessage,null));
 else       mVpnListMutableLiveData.postValue(Resource.error(AppConstants.GENERIC_ERROR,null));
    }
  }
);
}"
37465,"public void getVpnUsageForUser(GenericRequestBody iRequestBody){
  mVpnGetServerCredentialsLiveEvent.postValue(Resource.loading(null));
  mWebService.getVpnUsageForUser(iRequestBody).enqueue(new Callback<VpnUsage>(){
    @Override public void onResponse(    Call<VpnUsage> call,    Response<VpnUsage> response){
      reportSuccessResponse(response);
    }
    @Override public void onFailure(    Call<VpnUsage> call,    Throwable t){
      reportErrorResponse(t.getLocalizedMessage());
    }
    private void reportSuccessResponse(    Response<VpnUsage> response){
      if (response != null && response.body() != null) {
        if (response.body().success)         mVpnUsageLiveEvent.postValue(Resource.success(response.body()));
      }
 else {
        reportErrorResponse(null);
      }
    }
    private void reportErrorResponse(    String iThrowableLocalMessage){
      if (iThrowableLocalMessage != null)       mVpnGetServerCredentialsLiveEvent.postValue(Resource.error(iThrowableLocalMessage,null));
 else       mVpnGetServerCredentialsLiveEvent.postValue(Resource.error(AppConstants.GENERIC_ERROR,null));
    }
  }
);
}","public void getVpnUsageForUser(GenericRequestBody iRequestBody){
  mWebService.getVpnUsageForUser(iRequestBody).enqueue(new Callback<VpnUsage>(){
    @Override public void onResponse(    Call<VpnUsage> call,    Response<VpnUsage> response){
      reportSuccessResponse(response);
    }
    @Override public void onFailure(    Call<VpnUsage> call,    Throwable t){
      reportErrorResponse(t.getLocalizedMessage());
    }
    private void reportSuccessResponse(    Response<VpnUsage> response){
      if (response != null && response.body() != null) {
        if (response.body().success)         mVpnUsageLiveEvent.postValue(Resource.success(response.body()));
      }
 else {
        reportErrorResponse(null);
      }
    }
    private void reportErrorResponse(    String iThrowableLocalMessage){
      if (iThrowableLocalMessage != null)       mVpnUsageLiveEvent.postValue(Resource.error(iThrowableLocalMessage,null));
 else       mVpnUsageLiveEvent.postValue(Resource.error(AppConstants.GENERIC_ERROR,null));
    }
  }
);
}"
37466,"private void reportErrorResponse(String iThrowableLocalMessage){
  if (iThrowableLocalMessage != null)   mVpnGetServerCredentialsLiveEvent.postValue(Resource.error(iThrowableLocalMessage,null));
 else   mVpnGetServerCredentialsLiveEvent.postValue(Resource.error(AppConstants.GENERIC_ERROR,null));
}","private void reportErrorResponse(String iThrowableLocalMessage){
  if (iThrowableLocalMessage != null)   mVpnUsageLiveEvent.postValue(Resource.error(iThrowableLocalMessage,null));
 else   mVpnUsageLiveEvent.postValue(Resource.error(AppConstants.GENERIC_ERROR,null));
}"
37467,"private void initViewModel(){
  VpnListViewModelFactory aFactory=InjectorModule.provideVpnListViewModelFactory();
  mViewModel=ViewModelProviders.of(this,aFactory).get(VpnListViewModel.class);
  mViewModel.getVpnListLiveData().observe(this,vpnResource -> {
    if (vpnResource != null) {
      if (vpnResource.status.equals(Status.LOADING)) {
      }
 else       if (vpnResource.data != null && vpnResource.status.equals(Status.SUCCESS)) {
        hideProgressDialog();
        if (vpnResource.data.list != null && vpnResource.data.list.size() > 0)         mAdapter.loadData(vpnResource.data.list);
      }
 else       if (vpnResource.message != null && vpnResource.status.equals(Status.ERROR)) {
        hideProgressDialog();
        showErrorDialog(vpnResource.message);
      }
    }
  }
);
  mViewModel.getVpnGetServerCredentials().observe(this,vpnCredentialsResource -> {
    if (vpnCredentialsResource != null) {
      if (vpnCredentialsResource.status.equals(Status.LOADING)) {
        showProgressDialog(true,getString(R.string.fetching_server_details));
      }
 else       if (vpnCredentialsResource.data != null && vpnCredentialsResource.status.equals(Status.SUCCESS)) {
        hideProgressDialog();
      }
 else       if (vpnCredentialsResource.message != null && vpnCredentialsResource.status.equals(Status.ERROR)) {
        hideProgressDialog();
        if (vpnCredentialsResource.message.equals(AppConstants.INIT_PAY_ERROR))         loadNextActivity(constructSendActivityIntent(vpnCredentialsResource.message,true,getString(R.string.init_vpn_pay),null));
 else         showErrorDialog(vpnCredentialsResource.message);
      }
    }
  }
);
}","private void initViewModel(){
  VpnListViewModelFactory aFactory=InjectorModule.provideVpnListViewModelFactory();
  mViewModel=ViewModelProviders.of(this,aFactory).get(VpnListViewModel.class);
  mViewModel.getVpnListLiveData().observe(this,vpnResource -> {
    if (vpnResource != null) {
      if (vpnResource.data != null && vpnResource.status.equals(Status.SUCCESS)) {
        hideProgressDialog();
        if (vpnResource.data.list != null && vpnResource.data.list.size() > 0)         mAdapter.loadData(vpnResource.data.list);
      }
 else       if (vpnResource.message != null && vpnResource.status.equals(Status.ERROR)) {
        hideProgressDialog();
        showErrorDialog(vpnResource.message);
      }
    }
  }
);
  mViewModel.getVpnGetServerCredentials().observe(this,vpnCredentialsResource -> {
    if (vpnCredentialsResource != null) {
      if (vpnCredentialsResource.status.equals(Status.LOADING)) {
        showProgressDialog(true,getString(R.string.fetching_server_details));
      }
 else       if (vpnCredentialsResource.data != null && vpnCredentialsResource.status.equals(Status.SUCCESS)) {
        hideProgressDialog();
      }
 else       if (vpnCredentialsResource.message != null && vpnCredentialsResource.status.equals(Status.ERROR)) {
        hideProgressDialog();
        if (vpnCredentialsResource.message.equals(AppConstants.INIT_PAY_ERROR))         loadNextActivity(constructSendActivityIntent(vpnCredentialsResource.message,true,getString(R.string.init_vpn_pay),null));
 else         showErrorDialog(vpnCredentialsResource.message);
      }
    }
  }
);
}"
37468,"public SmsStatusPullCallbackResult jsonToSmsStatusPullCallbackrResult(JSONObject json){
  SmsStatusPullCallbackResult result=new SmsStatusPullCallbackResult();
  result.result=json.getInt(""String_Node_Str"");
  result.errmsg=json.getString(""String_Node_Str"");
  if (true == json.isNull(""String_Node_Str"")) {
    return result;
  }
  result.callbacks=new ArrayList<Callback>();
  JSONArray datas=json.getJSONArray(""String_Node_Str"");
  for (int index=0; index < datas.length(); index++) {
    JSONObject cb=datas.getJSONObject(index);
    SmsStatusPullCallbackResult.Callback callback=result.new Callback();
    callback.user_receive_time=cb.getString(""String_Node_Str"");
    callback.nationcode=cb.getString(""String_Node_Str"");
    callback.mobile=cb.getString(""String_Node_Str"");
    callback.report_status=cb.getString(""String_Node_Str"");
    callback.errmsg=cb.getString(""String_Node_Str"");
    callback.description=cb.getString(""String_Node_Str"");
    callback.sid=cb.getString(""String_Node_Str"");
    result.callbacks.add(callback);
  }
  return result;
}","public SmsStatusPullCallbackResult jsonToSmsStatusPullCallbackrResult(JSONObject json){
  SmsStatusPullCallbackResult result=new SmsStatusPullCallbackResult();
  result.result=json.getInt(""String_Node_Str"");
  result.errmsg=json.getString(""String_Node_Str"");
  result.count=json.getInt(""String_Node_Str"");
  if (true == json.isNull(""String_Node_Str"")) {
    return result;
  }
  result.callbacks=new ArrayList<Callback>();
  JSONArray datas=json.getJSONArray(""String_Node_Str"");
  for (int index=0; index < datas.length(); index++) {
    JSONObject cb=datas.getJSONObject(index);
    SmsStatusPullCallbackResult.Callback callback=result.new Callback();
    callback.user_receive_time=cb.getString(""String_Node_Str"");
    callback.nationcode=cb.getString(""String_Node_Str"");
    callback.mobile=cb.getString(""String_Node_Str"");
    callback.report_status=cb.getString(""String_Node_Str"");
    callback.errmsg=cb.getString(""String_Node_Str"");
    callback.description=cb.getString(""String_Node_Str"");
    callback.sid=cb.getString(""String_Node_Str"");
    result.callbacks.add(callback);
  }
  return result;
}"
37469,"/** 
 *  ---------------------------------------- USE [POOL_ID] RELOAD USER RELOAD ALL RELOAD FRONT RELOAD PATH RELOAD KAFKA RELOAD BIGKEY RELOAD NETFLOW JVM  JAVA_HOME  ---------------------------------------- JVM JSTACK JVM JSTAT JVM JMAP_HISTO JVM JMAP_HEAP JVM PS SHOW USER SHOW USER_NET_IO  SHOW CPU SHOW MEM SHOW QPS SHOW CONN SHOW USER_CONN SHOW BUFFER SHOW BIGKEY SHOW BIGKEY_COUNT SHOW BIGLENGTH SHOW SLOWKEY SHOW CMD SHOW USER_CMD SHOW USER_CMD_DETAIL USER SHOW VER SHOW NET_IO  SHOW NETBYTES SHOW VM SHOW POOL SHOW COST SHOW WAIT_COST SHOW USER_DAY_NET_IO SHOW POOL_NET_IO POOLNAME SHOW TOPIC SHOW LOG_ERROR SHOW LOG_WARN SHOW LOG_INFO SHOW LOG_DEBUG
 */
public static byte[] execute(final RedisRequest request,RedisFrontConnection frontCon){
  int numArgs=request.getNumArgs();
  if (numArgs < 2) {
    return ""String_Node_Str"".getBytes();
  }
  byte[] arg1=request.getArgs()[0];
  String arg2=new String(request.getArgs()[1]);
  if (arg1 == null || arg2 == null) {
    return ""String_Node_Str"".getBytes();
  }
  if (arg1.length == 3) {
    if ((arg1[0] == 'J' || arg1[0] == 'j') && (arg1[1] == 'V' || arg1[1] == 'v') && (arg1[2] == 'M' || arg1[2] == 'm')) {
      StringBuffer cmdBuffer=new StringBuffer();
      if (JavaUtils.isLinux())       cmdBuffer.append(JAVA_BIN_PATH);
      if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid());
        return encode(getOS_JVM_INFO(cmdBuffer.toString()));
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid());
        return encode(getOS_JVM_INFO(cmdBuffer.toString()));
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid());
        return encode(getOS_JVM_INFO(cmdBuffer.toString()));
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid());
        return encode(getOS_JVM_INFO(cmdBuffer.toString()));
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        String cmd=""String_Node_Str"" + JavaUtils.process_pid() + ""String_Node_Str"";
        List<String> line=new ArrayList<String>();
        try {
          line.add(ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",cmd));
        }
 catch (        IOException e) {
          line.add(e.getMessage());
        }
        return encode(line);
      }
    }
 else     if ((arg1[0] == 'U' || arg1[0] == 'u') && (arg1[1] == 'S' || arg1[1] == 's') && (arg1[2] == 'E' || arg1[2] == 'e')) {
      try {
        int poolId=Integer.parseInt(arg2);
        AbstractPool pool=RedisEngineCtx.INSTANCE().getPoolMap().get(poolId);
        if (pool == null) {
          return ""String_Node_Str"".getBytes();
        }
 else {
          int poolType=pool.getType();
          frontCon.getUserCfg().setUsePool(poolId,poolType);
          return ""String_Node_Str"".getBytes();
        }
      }
 catch (      NumberFormatException e) {
        return ""String_Node_Str"".getBytes();
      }
    }
  }
 else   if (arg1.length == 4) {
    if ((arg1[0] == 'S' || arg1[0] == 's') && (arg1[1] == 'H' || arg1[1] == 'h') && (arg1[2] == 'O' || arg1[2] == 'o')&& (arg1[3] == 'W' || arg1[3] == 'w')) {
      if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        AccessStatInfoResult result=StatUtil.getTotalAccessStatInfo().get(StatUtil.STAT_KEY);
        if (result != null) {
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(""String_Node_Str"").append(result.totalCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.slowCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.maxCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.minCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.avgCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.waitSlowCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.procTime).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.waitTime).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.created);
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<Object> lines=new ArrayList<Object>();
        long sum=0;
        Set<Entry<String,Command>> entrys=StatUtil.getCommandCountMap().entrySet();
        for (        Entry<String,Command> entry : entrys) {
          Command parent=entry.getValue();
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(parent.cmd).append(""String_Node_Str"").append(parent.count.get());
          if (parent.childs != null) {
            List<String> list=new ArrayList<String>();
            list.add(sBuffer.toString());
            for (            Entry<String,Command> childEntry : parent.childs.entrySet()) {
              Command child=childEntry.getValue();
              StringBuffer sb=new StringBuffer();
              sb.append(""String_Node_Str"").append(child.cmd).append(""String_Node_Str"").append(child.count.get());
              list.add(sb.toString());
            }
            lines.add(list);
          }
 else {
            lines.add(sBuffer.toString());
          }
          sum+=parent.count.get();
        }
        StringBuffer sBuffer=new StringBuffer();
        sBuffer.append(""String_Node_Str"").append(""String_Node_Str"").append(sum);
        lines.add(sBuffer.toString());
        return encodeObject(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer title=new StringBuffer();
        title.append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"");
        lines.add(title.toString());
        Set<Entry<String,UserCommand>> entrys=StatUtil.getUserCommandCountMap().entrySet();
        for (        Entry<String,UserCommand> entry : entrys) {
          UserCommand userCommand=entry.getValue();
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(userCommand.user).append(""String_Node_Str"").append(userCommand.readComandCount.get()).append(""String_Node_Str"").append(userCommand.writeCommandCount.get()).append(""String_Node_Str"").append(userCommand.readComandCount.get() + userCommand.writeCommandCount.get());
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") && numArgs == 3) {
        String user=new String(request.getArgs()[2]);
        List<String> lines=new ArrayList<String>();
        StringBuffer title=new StringBuffer();
        title.append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"");
        lines.add(title.toString());
        int sum=0;
        ConcurrentHashMap<String,UserCommand> userCommandMap=StatUtil.getUserCommandCountMap();
        UserCommand userCommand=userCommandMap.get(user);
        if (userCommand != null) {
          for (          Entry<String,AtomicLong> entry : userCommand.commandCount.entrySet()) {
            StringBuffer sBuffer=new StringBuffer();
            sBuffer.append(user).append(""String_Node_Str"").append(entry.getKey()).append(""String_Node_Str"").append(entry.getValue().get());
            lines.add(sBuffer.toString());
          }
        }
        StringBuffer end=new StringBuffer();
        end.append(""String_Node_Str"").append(""String_Node_Str"").append(sum);
        lines.add(end.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        lines.add(Versions.SERVER_VERSION);
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        if (JavaUtils.isLinux()) {
          StringBuffer cmdBuffer=new StringBuffer();
          cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid()).append(""String_Node_Str"");
          String response;
          try {
            response=ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",cmdBuffer.toString());
            lines.add(response);
          }
 catch (          IOException e) {
            LOGGER.error(""String_Node_Str"",e);
            lines.add(""String_Node_Str"");
          }
        }
 else {
          lines.add(""String_Node_Str"");
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        lines.add(""String_Node_Str"" + JavaUtils.bytesToString2(Math.round(JavaUtils.getMemUsage())));
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        int frontSize=0;
        int backendSize=0;
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisFrontConnection) {
            frontSize++;
          }
 else {
            backendSize++;
          }
        }
        StringBuffer sBuffer=new StringBuffer();
        sBuffer.append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"").append(frontSize).append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"").append(backendSize).append(""String_Node_Str"");
        return sBuffer.toString().getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        Map<String,Integer> userMap=new HashMap<String,Integer>();
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisFrontConnection) {
            userMap.put(((RedisFrontConnection)c).getPassword(),1 + (userMap.get(((RedisFrontConnection)c).getPassword()) == null ? 0 : userMap.get(((RedisFrontConnection)c).getPassword())));
          }
        }
        StringBuffer sBuffer=new StringBuffer();
        sBuffer.append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"");
        Iterator<Entry<String,Integer>> users=userMap.entrySet().iterator();
        while (users.hasNext()) {
          sBuffer.append(""String_Node_Str"");
          Entry<String,Integer> en=users.next();
          sBuffer.append(en.getKey());
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(en.getValue());
        }
        sBuffer.append(""String_Node_Str"");
        return sBuffer.toString().getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        ConcurrentHashMap<String,AccessStatInfoResult> results=StatUtil.getTotalAccessStatInfo();
        for (        Map.Entry<String,AccessStatInfoResult> entry : results.entrySet()) {
          AccessStatInfoResult result=entry.getValue();
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(""String_Node_Str"").append(result.key).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.totalCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.slowCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.maxCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.minCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.avgCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.procTime).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netInBytes[1]).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netInBytes[2]).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netInBytes[3]).append(""String_Node_Str"").append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netOutBytes[1]).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netOutBytes[2]).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netOutBytes[3]).append(""String_Node_Str"").append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.created);
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisFrontConnection) {
            lines.add(c.toString());
          }
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        BufferPool bufferPool=NetSystem.getInstance().getBufferPool();
        long usedBufferSize=bufferPool.getUsedBufferSize().get();
        long maxBufferSize=bufferPool.getMaxBufferSize();
        long minBufferSize=bufferPool.getMinBufferSize();
        long sharedOptsCount=bufferPool.getSharedOptsCount();
        int capacity=0;
        if (bufferPool instanceof BucketBufferPool) {
          BucketBufferPool p=(BucketBufferPool)bufferPool;
          AbstractBucket[] buckets=p.buckets();
          for (          AbstractBucket b : buckets) {
            capacity+=b.getCount();
          }
          int bucketLen=buckets.length;
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(capacity).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(minBufferSize).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(maxBufferSize).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(usedBufferSize).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(bucketLen).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(sharedOptsCount).append(""String_Node_Str"");
          return sBuffer.toString().getBytes();
        }
 else         if (bufferPool instanceof PageBufferPool) {
          List<String> lines=new ArrayList<String>();
          ConcurrentHashMap<Long,Long> bufferpoolUsageMap=bufferPool.getNetDirectMemoryUsage();
          long usedforNetwork=0;
          for (          Map.Entry<Long,Long> entry : bufferpoolUsageMap.entrySet()) {
            long value=entry.getValue();
            lines.add(""String_Node_Str"" + entry.getKey() + ""String_Node_Str""+ (value > 0 ? JavaUtils.bytesToString2(value) : ""String_Node_Str""));
            usedforNetwork=usedforNetwork + value;
          }
          lines.add(""String_Node_Str"" + JavaUtils.bytesToString2(minBufferSize));
          lines.add(""String_Node_Str"" + JavaUtils.bytesToString2(maxBufferSize));
          lines.add(""String_Node_Str"" + JavaUtils.bytesToString2(usedforNetwork));
          return encode(lines);
        }
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        BufferPool bufferPool=NetSystem.getInstance().getBufferPool();
        if (bufferPool instanceof BucketBufferPool) {
          BucketBufferPool p=(BucketBufferPool)bufferPool;
          AbstractBucket[] buckets=p.buckets();
          for (          AbstractBucket b : buckets) {
            StringBuffer sBuffer=new StringBuffer();
            sBuffer.append(""String_Node_Str"").append(b.getChunkSize()).append(""String_Node_Str"");
            sBuffer.append(""String_Node_Str"").append(b.getQueueSize()).append(""String_Node_Str"");
            sBuffer.append(""String_Node_Str"").append(b.getCount()).append(""String_Node_Str"");
            sBuffer.append(""String_Node_Str"").append(b.getUsedCount()).append(""String_Node_Str"");
            sBuffer.append(""String_Node_Str"").append(b.getShared());
            lines.add(sBuffer.toString());
          }
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        for (        BigKey bigkey : StatUtil.getBigKeys()) {
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(bigkey.lastCmd).append(""String_Node_Str"");
          sBuffer.append(bigkey.key).append(""String_Node_Str"");
          sBuffer.append(bigkey.size).append(""String_Node_Str"");
          sBuffer.append(bigkey.count.get());
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        BigKeyCollector bkc=StatUtil.getBigKeyCollector();
        StringBuffer sBuffer=new StringBuffer();
        sBuffer.append(""String_Node_Str"").append(bkc.getBigKeyCount()).append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"").append(bkc.getBypassBigKeyCount());
        lines.add(sBuffer.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        Map<String,AtomicInteger> poolConnections=new HashMap<String,AtomicInteger>();
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisBackendConnection) {
            String poolName=((RedisBackendConnection)c).getPhysicalNode().getPoolName();
            AtomicInteger poolConnCount=poolConnections.get(poolName);
            if (poolConnCount == null) {
              poolConnections.put(poolName,new AtomicInteger(1));
            }
 else {
              poolConnCount.incrementAndGet();
            }
            lines.add(c.toString());
          }
 else           if (c instanceof KafkaBackendConnection) {
            String poolName=((KafkaBackendConnection)c).getPhysicalNode().getPoolName();
            AtomicInteger poolConnCount=poolConnections.get(poolName);
            if (poolConnCount == null) {
              poolConnections.put(poolName,new AtomicInteger(1));
            }
 else {
              poolConnCount.incrementAndGet();
            }
            lines.add(c.toString());
          }
        }
        StringBuffer sb=new StringBuffer();
        for (        Map.Entry<String,AtomicInteger> entry : poolConnections.entrySet()) {
          sb.append(entry.getKey()).append(""String_Node_Str"").append(entry.getValue().get()).append(""String_Node_Str"");
        }
        lines.add(sb.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") && numArgs == 3) {
        List<String> lines=new ArrayList<String>();
        long minStartupTime=-1;
        long totalNetInBytes=0;
        long totalNetOutBytes=0;
        String poolName=new String(request.getArgs()[2]);
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisBackendConnection) {
            if (((RedisBackendConnection)c).getPhysicalNode().getPoolName().equals(poolName)) {
              StringBuffer sb=new StringBuffer();
              sb.append(""String_Node_Str"").append(c.getId()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(c.getStartupTime()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(c.getNetInBytes()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(c.getNetOutBytes()).append(""String_Node_Str"");
              lines.add(sb.toString());
              minStartupTime=minStartupTime < 0 ? c.getStartupTime() : Math.min(minStartupTime,c.getStartupTime());
              totalNetInBytes+=c.getNetInBytes();
              totalNetOutBytes+=c.getNetOutBytes();
            }
          }
        }
        StringBuffer end=new StringBuffer();
        end.append(""String_Node_Str"").append(minStartupTime).append(""String_Node_Str"");
        end.append(""String_Node_Str"").append(totalNetInBytes).append(""String_Node_Str"");
        end.append(""String_Node_Str"").append(totalNetOutBytes).append(""String_Node_Str"");
        lines.add(end.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") || arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        AccessStatInfoResult result=StatUtil.getTotalAccessStatInfo().get(StatUtil.STAT_KEY);
        if (result != null) {
          StringBuffer line0=new StringBuffer();
          line0.append(""String_Node_Str"").append(""String_Node_Str"");
          line0.append(""String_Node_Str"").append(""String_Node_Str"");
          line0.append(""String_Node_Str"").append(""String_Node_Str"");
          line0.append(""String_Node_Str"").append(""String_Node_Str"");
          line0.append(""String_Node_Str"");
          StringBuffer line1=new StringBuffer();
          line1.append(""String_Node_Str"").append(""String_Node_Str"");
          line1.append(result.netInBytes[0]).append(""String_Node_Str"");
          line1.append(result.netInBytes[1]).append(""String_Node_Str"");
          line1.append(result.netInBytes[2]).append(""String_Node_Str"");
          line1.append(result.netInBytes[3]);
          StringBuffer line2=new StringBuffer();
          line2.append(""String_Node_Str"").append(""String_Node_Str"");
          line2.append(result.netOutBytes[0]).append(""String_Node_Str"");
          line2.append(result.netOutBytes[1]).append(""String_Node_Str"");
          line2.append(result.netOutBytes[2]).append(""String_Node_Str"");
          line2.append(result.netOutBytes[3]);
          StringBuffer line3=new StringBuffer();
          line3.append(result.created);
          lines.add(line0.toString());
          lines.add(line1.toString());
          lines.add(line2.toString());
          lines.add(line3.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        for (        Map.Entry<String,AccessStatInfoResult> entry : StatUtil.getTotalAccessStatInfo().entrySet()) {
          if (!StatUtil.STAT_KEY.equals(entry.getKey())) {
            AccessStatInfoResult result=entry.getValue();
            StringBuffer line1=new StringBuffer();
            line1.append(result.key).append(""String_Node_Str"");
            line1.append(""String_Node_Str"").append(""String_Node_Str"");
            line1.append(result.netInBytes[0]).append(""String_Node_Str"");
            line1.append(result.netInBytes[1]).append(""String_Node_Str"");
            line1.append(result.netInBytes[2]).append(""String_Node_Str"");
            line1.append(result.netInBytes[3]);
            StringBuffer line2=new StringBuffer();
            line2.append(result.key).append(""String_Node_Str"");
            line2.append(""String_Node_Str"").append(""String_Node_Str"");
            line2.append(result.netOutBytes[0]).append(""String_Node_Str"");
            line2.append(result.netOutBytes[1]).append(""String_Node_Str"");
            line2.append(result.netOutBytes[2]).append(""String_Node_Str"");
            line2.append(result.netOutBytes[3]);
            StringBuffer line3=new StringBuffer();
            line3.append(result.created);
            lines.add(line1.toString());
            lines.add(line2.toString());
            lines.add(line3.toString());
          }
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        long totalNetIn=0;
        long totalNetOut=0;
        for (        Map.Entry<String,UserFlow> entry : StatUtil.getUserFlowMap().entrySet()) {
          if (!StatUtil.STAT_KEY.equals(entry.getKey())) {
            StringBuffer sb=new StringBuffer();
            UserFlow userNetIo=entry.getValue();
            sb.append(userNetIo.password).append(""String_Node_Str"");
            sb.append(JavaUtils.bytesToString2(userNetIo.netIn.get())).append(""String_Node_Str"");
            sb.append(JavaUtils.bytesToString2(userNetIo.netOut.get()));
            totalNetIn=totalNetIn + userNetIo.netIn.get();
            totalNetOut=totalNetOut + userNetIo.netOut.get();
            lines.add(sb.toString());
          }
        }
        StringBuffer total=new StringBuffer();
        total.append(""String_Node_Str"").append(""String_Node_Str"");
        total.append(JavaUtils.bytesToString2(totalNetIn)).append(""String_Node_Str"");
        total.append(JavaUtils.bytesToString2(totalNetOut));
        lines.add(total.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=showLog(request,""String_Node_Str"");
        return encode2(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=showLog(request,""String_Node_Str"");
        return encode2(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=showLog(request,""String_Node_Str"");
        return encode2(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=showLog(request,""String_Node_Str"");
        return encode2(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> ret=new ArrayList<String>();
        try {
          String resp=ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"");
          StringBuilder sb=new StringBuilder();
          sb.append(resp);
          sb.append(""String_Node_Str"");
          String[] lines=sb.toString().split(""String_Node_Str"");
          ret.add(""String_Node_Str"");
          for (int i=1; i < lines.length; i++) {
            if (lines[i].equals(""String_Node_Str""))             continue;
            ret.add(lines[i]);
          }
        }
 catch (        IOException e) {
          LOGGER.error(""String_Node_Str"",e);
          ret.add(""String_Node_Str"");
        }
        return encode2(ret);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> ret=new ArrayList<String>();
        try {
          String cmd1=ShellUtils.osType == ShellUtils.OSType.OS_TYPE_MAC ? ""String_Node_Str"" : ""String_Node_Str"";
          String cmd2=ShellUtils.osType == ShellUtils.OSType.OS_TYPE_MAC ? ""String_Node_Str"" : ""String_Node_Str"";
          String iostatOut=ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",cmd1);
          String vmstatOut=ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",cmd2);
          StringBuilder sb=new StringBuilder();
          sb.append(iostatOut);
          sb.append(""String_Node_Str"");
          sb.append(""String_Node_Str"");
          sb.append(vmstatOut);
          String[] lines=sb.toString().split(""String_Node_Str"");
          ret.add(""String_Node_Str"");
          for (int i=1; i < lines.length; i++) {
            if (lines[i].equals(""String_Node_Str""))             continue;
            ret.add(lines[i]);
          }
        }
 catch (        IOException e) {
          LOGGER.error(""String_Node_Str"",e);
          ret.add(""String_Node_Str"");
        }
        return encode2(ret);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<Object> list=new ArrayList<Object>();
        Map<Integer,AbstractPool> pools=RedisEngineCtx.INSTANCE().getPoolMap();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        list.add(titleLine.toString());
        for (        AbstractPool pool : pools.values()) {
          if (pool instanceof RedisStandalonePool) {
            StringBuffer sb=new StringBuffer();
            RedisStandalonePool redisStandalonePool=(RedisStandalonePool)pool;
            PhysicalNode physicalNode=redisStandalonePool.getPhysicalNode();
            if (physicalNode == null)             continue;
            sb.append(""String_Node_Str"");
            sb.append(redisStandalonePool.getId()).append(""String_Node_Str"");
            sb.append(physicalNode.getPoolName()).append(""String_Node_Str"");
            sb.append(""String_Node_Str"").append(""String_Node_Str"");
            sb.append(physicalNode.getName()).append(""String_Node_Str"");
            sb.append(physicalNode.getMinCon()).append(""String_Node_Str"");
            sb.append(physicalNode.getMaxCon()).append(""String_Node_Str"");
            sb.append(physicalNode.getIdleCount()).append(""String_Node_Str"");
            sb.append(physicalNode.getActiveCount());
            list.add(sb.toString());
          }
 else           if (pool instanceof RedisClusterPool) {
            RedisClusterPool redisClusterPool=(RedisClusterPool)pool;
            Map<String,ClusterNode> masters=redisClusterPool.getMasters();
            List<String> clusterInfo=new ArrayList<String>();
            for (            ClusterNode clusterNode : masters.values()) {
              PhysicalNode physicalNode=clusterNode.getPhysicalNode();
              StringBuffer sb=new StringBuffer();
              sb.append(redisClusterPool.getId()).append(""String_Node_Str"");
              sb.append(physicalNode.getPoolName()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(""String_Node_Str"");
              sb.append(physicalNode.getName()).append(""String_Node_Str"");
              sb.append(physicalNode.getMinCon()).append(""String_Node_Str"");
              sb.append(physicalNode.getMaxCon()).append(""String_Node_Str"");
              sb.append(physicalNode.getIdleCount()).append(""String_Node_Str"");
              sb.append(physicalNode.getActiveCount()).append(""String_Node_Str"");
              ;
              sb.append(!clusterNode.isFail());
              clusterInfo.add(sb.toString());
              sb.append(clusterNode.getConnectInfo());
            }
            list.add(clusterInfo);
          }
 else           if (pool instanceof KafkaPool) {
            KafkaPool kafkaPool=(KafkaPool)pool;
            Map<Integer,PhysicalNode> physicalNodes=kafkaPool.getPhysicalNodes();
            for (            PhysicalNode physicalNode : physicalNodes.values()) {
              StringBuffer sb=new StringBuffer();
              sb.append(""String_Node_Str"");
              sb.append(kafkaPool.getId()).append(""String_Node_Str"");
              sb.append(physicalNode.getPoolName()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(""String_Node_Str"");
              sb.append(physicalNode.getName()).append(""String_Node_Str"");
              sb.append(physicalNode.getMinCon()).append(""String_Node_Str"");
              sb.append(physicalNode.getMaxCon()).append(""String_Node_Str"");
              sb.append(physicalNode.getIdleCount()).append(""String_Node_Str"");
              sb.append(physicalNode.getActiveCount());
              list.add(sb.toString());
            }
          }
        }
        return encodeObject(list);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        Collection<Entry<String,AtomicLong>> entrys=StatUtil.getCommandProcTimeMap().entrySet();
        List<String> lines=new ArrayList<String>();
        for (        Entry<String,AtomicLong> entry : entrys) {
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(entry.getKey()).append(""String_Node_Str"").append(entry.getValue().get());
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        Collection<Entry<String,AtomicLong>> entrys=StatUtil.getCommandWaitTimeMap().entrySet();
        List<String> lines=new ArrayList<String>();
        for (        Entry<String,AtomicLong> entry : entrys) {
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(entry.getKey()).append(""String_Node_Str"").append(entry.getValue().get());
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        for (        BigLength bigLength : StatUtil.getBigLengthMap().values()) {
          StringBuffer line1=new StringBuffer();
          line1.append(bigLength.cmd).append(""String_Node_Str"");
          line1.append(bigLength.key).append(""String_Node_Str"");
          line1.append(bigLength.length.get()).append(""String_Node_Str"");
          line1.append(bigLength.count_1k.get()).append(""String_Node_Str"");
          line1.append(bigLength.count_10k.get());
          lines.add(line1.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        for (        SlowKey slowKey : StatUtil.getSlowKey()) {
          StringBuffer line1=new StringBuffer();
          line1.append(slowKey.cmd).append(""String_Node_Str"");
          line1.append(slowKey.key).append(""String_Node_Str"");
          line1.append(slowKey.count);
          lines.add(line1.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") && (numArgs == 3 || numArgs == 2)) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        if (numArgs == 2) {
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"");
        }
 else {
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"");
        }
        lines.add(titleLine.toString());
        final Map<Integer,PoolCfg> poolCfgMap=RedisEngineCtx.INSTANCE().getPoolCfgMap();
        for (        Entry<Integer,PoolCfg> poolEntry : poolCfgMap.entrySet()) {
          PoolCfg poolCfg=poolEntry.getValue();
          if (poolCfg instanceof KafkaPoolCfg) {
            Map<String,TopicCfg> kafkaMap=((KafkaPoolCfg)poolCfg).getTopicCfgMap();
            if (numArgs == 2) {
              for (              Entry<String,TopicCfg> kafkaEntry : kafkaMap.entrySet()) {
                TopicCfg kafkaCfg=kafkaEntry.getValue();
                StringBuffer line=new StringBuffer();
                line.append(kafkaCfg.getName()).append(""String_Node_Str"");
                line.append(kafkaCfg.getPoolId()).append(""String_Node_Str"");
                line.append(kafkaCfg.getPartitions()).append(""String_Node_Str"");
                line.append(kafkaCfg.getReplicationFactor()).append(""String_Node_Str"");
                line.append(kafkaCfg.getProducers()).append(""String_Node_Str"");
                line.append(kafkaCfg.getConsumers());
                lines.add(line.toString());
              }
            }
 else {
              String topic=new String(request.getArgs()[2]);
              TopicCfg kafkaCfg=kafkaMap.get(topic);
              if (kafkaCfg != null) {
                for (                BrokerPartition partition : kafkaCfg.getRunningInfo().getPartitions().values()) {
                  int pt=partition.getPartition();
                  StringBuffer line=new StringBuffer();
                  line.append(kafkaCfg.getName()).append(""String_Node_Str"");
                  line.append(partition.getLeader().getHost()).append(partition.getLeader().getPort()).append(""String_Node_Str"");
                  line.append(pt).append(""String_Node_Str"");
                  line.append(partition.getLogStartOffset()).append(""String_Node_Str"");
                  line.append(partition.getProducerOffset()).append(""String_Node_Str"");
                  for (                  ConsumerOffset consumerOffset : partition.getConsumerOffsets().values()) {
                    line.append(consumerOffset.getConsumer());
                    line.append(""String_Node_Str"");
                    line.append(consumerOffset.getCurrentOffset());
                    line.append(""String_Node_Str"");
                  }
                  lines.add(line.toString());
                }
              }
            }
          }
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") && numArgs == 2) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        NetFlowGuard nfg=RedisEngineCtx.INSTANCE().getNetflowGuard();
        Map<String,Guard> map=nfg.getGuardMap();
        for (        Entry<String,Guard> entry : map.entrySet()) {
          Guard guard=entry.getValue();
          StringBuffer line=new StringBuffer();
          line.append(entry.getKey()).append(""String_Node_Str"");
          line.append(guard.getPerSecondMaxSize()).append(""String_Node_Str"");
          line.append(guard.getRequestMaxSize()).append(""String_Node_Str"");
          line.append(guard.getHistogram());
          lines.add(line.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") && numArgs == 2) {
        List<String> lines=new ArrayList<>();
        lines.add(""String_Node_Str"");
        lines.add(""String_Node_Str"");
        Map<Integer,AbstractPool> pools=RedisEngineCtx.INSTANCE().getPoolMap();
        for (        AbstractPool pool : pools.values()) {
          if (pool instanceof RedisStandalonePool) {
            RedisStandalonePool standalonePool=(RedisStandalonePool)pool;
            PhysicalNode physicalNode=standalonePool.getPhysicalNode();
            List<LatencySample> samples=physicalNode.getLatencySamples();
            for (            LatencySample s : samples) {
              StringBuffer strBuffer=new StringBuffer();
              strBuffer.append(""String_Node_Str"").append(String.valueOf(standalonePool.getId()));
              strBuffer.append(""String_Node_Str"").append(physicalNode.getHost());
              strBuffer.append(""String_Node_Str"").append((s.latency));
              lines.add(strBuffer.toString());
            }
          }
 else           if (pool instanceof RedisClusterPool) {
            RedisClusterPool redisClusterPool=(RedisClusterPool)pool;
            Map<String,ClusterNode> masters=redisClusterPool.getMasters();
            lines.add(String.valueOf(redisClusterPool.getId()));
            for (            ClusterNode clusterNode : masters.values()) {
              PhysicalNode physicalNode=clusterNode.getPhysicalNode();
              List<LatencySample> samples=physicalNode.getLatencySamples();
              for (              LatencySample s : samples) {
                StringBuffer strBuffer=new StringBuffer();
                strBuffer.append(""String_Node_Str"").append(String.valueOf(redisClusterPool.getId()));
                strBuffer.append(""String_Node_Str"").append(physicalNode.getHost());
                strBuffer.append(""String_Node_Str"").append((s.latency));
                lines.add(strBuffer.toString());
              }
            }
          }
 else           if (pool instanceof KafkaPool) {
            KafkaPool kafkaPool=(KafkaPool)pool;
            Map<Integer,PhysicalNode> physicalNodes=kafkaPool.getPhysicalNodes();
            for (            PhysicalNode physicalNode : physicalNodes.values()) {
              List<LatencySample> samples=physicalNode.getLatencySamples();
              for (              LatencySample s : samples) {
                StringBuffer strBuffer=new StringBuffer();
                strBuffer.append(""String_Node_Str"").append(String.valueOf(kafkaPool.getId()));
                strBuffer.append(""String_Node_Str"").append(physicalNode.getHost());
                strBuffer.append(""String_Node_Str"").append((s.latency));
                lines.add(strBuffer.toString());
              }
            }
          }
        }
        return encode(lines);
      }
    }
  }
 else   if (arg1.length == 6) {
    if ((arg1[0] == 'R' || arg1[0] == 'r') && (arg1[1] == 'E' || arg1[1] == 'e') && (arg1[2] == 'L' || arg1[2] == 'l')&& (arg1[3] == 'O' || arg1[3] == 'o')&& (arg1[4] == 'A' || arg1[4] == 'a')&& (arg1[5] == 'D' || arg1[5] == 'd')) {
      if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        byte[] buff=RedisEngineCtx.INSTANCE().reloadAll();
        return buff;
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        byte[] buff=RedisEngineCtx.INSTANCE().reloadUser();
        return buff;
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        byte[] buff=RedisEngineCtx.INSTANCE().reloadNetflow();
        return buff;
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisFrontConnection) {
            LOGGER.info(""String_Node_Str"",c);
            c.close(""String_Node_Str"");
          }
        }
        return ""String_Node_Str"".getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        JAVA_BIN_PATH=new String(request.getArgs()[2]);
        return ""String_Node_Str"".getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        try {
          Map<Integer,PoolCfg> poolCfgMap=RedisEngineCtx.INSTANCE().getPoolCfgMap();
          for (          PoolCfg poolCfg : poolCfgMap.values()) {
            if (poolCfg instanceof KafkaPoolCfg)             poolCfg.reloadExtraCfg();
          }
        }
 catch (        Exception e) {
          LOGGER.error(""String_Node_Str"",e);
          StringBuffer sb=new StringBuffer();
          sb.append(""String_Node_Str"").append(e.getMessage()).append(""String_Node_Str"");
          return sb.toString().getBytes();
        }
        return ""String_Node_Str"".getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        byte[] buff=BypassService.INSTANCE().reload();
        return buff;
      }
    }
    if ((arg1[0] == 'R' || arg1[0] == 'r') && (arg1[1] == 'E' || arg1[1] == 'e') && (arg1[2] == 'P' || arg1[2] == 'p')&& (arg1[3] == 'A' || arg1[3] == 'a')&& (arg1[4] == 'I' || arg1[4] == 'i')&& (arg1[5] == 'R' || arg1[5] == 'r')) {
      if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        String password=new String(request.getArgs()[2]);
        String topicName=new String(request.getArgs()[3]);
        long offset=Long.parseLong(new String(request.getArgs()[4]));
        UserCfg userCfg=RedisEngineCtx.INSTANCE().getUserMap().get(password);
        if (userCfg != null) {
          int poolId=userCfg.getPoolId();
          PoolCfg poolCfg=(PoolCfg)RedisEngineCtx.INSTANCE().getPoolCfgMap().get(poolId);
          if (poolCfg != null && poolCfg instanceof KafkaPoolCfg) {
            TopicCfg topicCfg=((KafkaPoolCfg)poolCfg).getTopicCfgMap().get(topicName);
            if (topicCfg != null) {
              for (int partition=0; partition < topicCfg.getPartitions(); partition++) {
                boolean isRepair=BrokerOffsetService.INSTANCE().repairOffset(password,topicCfg,partition,offset);
                if (!isRepair) {
                  return (""String_Node_Str"" + partition + ""String_Node_Str"").getBytes();
                }
              }
            }
 else {
              return (""String_Node_Str"" + topicName + ""String_Node_Str"").getBytes();
            }
            return ""String_Node_Str"".getBytes();
          }
 else {
            return (""String_Node_Str"" + poolId + ""String_Node_Str"").getBytes();
          }
        }
 else {
          return (""String_Node_Str"" + password + ""String_Node_Str"").getBytes();
        }
      }
    }
  }
 else   if (arg1.length == 7) {
    if ((arg1[0] == 'C' || arg1[0] == 'c') && (arg1[1] == 'L' || arg1[1] == 'l') && (arg1[2] == 'U' || arg1[2] == 'u')&& (arg1[3] == 'S' || arg1[3] == 's')&& (arg1[4] == 'T' || arg1[4] == 't')&& (arg1[5] == 'E' || arg1[5] == 'e')&& (arg1[6] == 'R' || arg1[6] == 'r')) {
      AbstractPool pool=RedisEngineCtx.INSTANCE().getPoolMap().get(frontCon.getUserCfg().getPoolId());
      if (pool.getType() != 1) {
        return ""String_Node_Str"".getBytes();
      }
      PhysicalNode pysicalNode=((RedisClusterPool)pool).getPhysicalNodeBySlot(0);
      if (pysicalNode == null) {
        return ""String_Node_Str"".getBytes();
      }
      try {
        RedisBackendConnection backendCon=(RedisBackendConnection)pysicalNode.getConnection(new DirectTransTofrontCallBack(),frontCon);
        if (backendCon == null) {
          frontCon.writeErrMessage(""String_Node_Str"");
        }
 else {
          backendCon.write(request.encode());
        }
        return null;
      }
 catch (      IOException e) {
        LOGGER.error(""String_Node_Str"",e);
      }
    }
  }
  return ""String_Node_Str"".getBytes();
}","/** 
 *  ---------------------------------------- USE [POOL_ID] RELOAD USER RELOAD ALL RELOAD FRONT RELOAD PATH RELOAD KAFKA RELOAD BIGKEY RELOAD NETFLOW JVM  JAVA_HOME  ---------------------------------------- JVM JSTACK JVM JSTAT JVM JMAP_HISTO JVM JMAP_HEAP JVM PS SHOW USER SHOW USER_NET_IO  SHOW CPU SHOW MEM SHOW QPS SHOW CONN SHOW USER_CONN SHOW BUFFER SHOW BIGKEY SHOW BIGKEY_COUNT SHOW BIGLENGTH SHOW SLOWKEY SHOW CMD SHOW USER_CMD SHOW USER_CMD_DETAIL USER SHOW VER SHOW NET_IO  SHOW NETBYTES SHOW VM SHOW POOL SHOW COST SHOW WAIT_COST SHOW USER_DAY_NET_IO SHOW POOL_NET_IO POOLNAME SHOW TOPIC SHOW LOG_ERROR SHOW LOG_WARN SHOW LOG_INFO SHOW LOG_DEBUG
 */
public static byte[] execute(final RedisRequest request,RedisFrontConnection frontCon){
  int numArgs=request.getNumArgs();
  if (numArgs < 2) {
    return ""String_Node_Str"".getBytes();
  }
  byte[] arg1=request.getArgs()[0];
  String arg2=new String(request.getArgs()[1]);
  if (arg1 == null || arg2 == null) {
    return ""String_Node_Str"".getBytes();
  }
  if (arg1.length == 3) {
    if ((arg1[0] == 'J' || arg1[0] == 'j') && (arg1[1] == 'V' || arg1[1] == 'v') && (arg1[2] == 'M' || arg1[2] == 'm')) {
      StringBuffer cmdBuffer=new StringBuffer();
      if (JavaUtils.isLinux())       cmdBuffer.append(JAVA_BIN_PATH);
      if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid());
        return encode(getOS_JVM_INFO(cmdBuffer.toString()));
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid());
        return encode(getOS_JVM_INFO(cmdBuffer.toString()));
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid());
        return encode(getOS_JVM_INFO(cmdBuffer.toString()));
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid());
        return encode(getOS_JVM_INFO(cmdBuffer.toString()));
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        String cmd=""String_Node_Str"" + JavaUtils.process_pid() + ""String_Node_Str"";
        List<String> line=new ArrayList<String>();
        try {
          line.add(ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",cmd));
        }
 catch (        IOException e) {
          line.add(e.getMessage());
        }
        return encode(line);
      }
    }
 else     if ((arg1[0] == 'U' || arg1[0] == 'u') && (arg1[1] == 'S' || arg1[1] == 's') && (arg1[2] == 'E' || arg1[2] == 'e')) {
      try {
        int poolId=Integer.parseInt(arg2);
        AbstractPool pool=RedisEngineCtx.INSTANCE().getPoolMap().get(poolId);
        if (pool == null) {
          return ""String_Node_Str"".getBytes();
        }
 else {
          int poolType=pool.getType();
          frontCon.getUserCfg().setUsePool(poolId,poolType);
          return ""String_Node_Str"".getBytes();
        }
      }
 catch (      NumberFormatException e) {
        return ""String_Node_Str"".getBytes();
      }
    }
  }
 else   if (arg1.length == 4) {
    if ((arg1[0] == 'S' || arg1[0] == 's') && (arg1[1] == 'H' || arg1[1] == 'h') && (arg1[2] == 'O' || arg1[2] == 'o')&& (arg1[3] == 'W' || arg1[3] == 'w')) {
      if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        AccessStatInfoResult result=StatUtil.getTotalAccessStatInfo().get(StatUtil.STAT_KEY);
        if (result != null) {
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(""String_Node_Str"").append(result.totalCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.slowCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.maxCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.minCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.avgCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.waitSlowCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.procTime).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.waitTime).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.created);
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<Object> lines=new ArrayList<Object>();
        long sum=0;
        Set<Entry<String,Command>> entrys=StatUtil.getCommandCountMap().entrySet();
        for (        Entry<String,Command> entry : entrys) {
          Command parent=entry.getValue();
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(parent.cmd).append(""String_Node_Str"").append(parent.count.get());
          if (parent.childs != null) {
            List<String> list=new ArrayList<String>();
            list.add(sBuffer.toString());
            for (            Entry<String,Command> childEntry : parent.childs.entrySet()) {
              Command child=childEntry.getValue();
              StringBuffer sb=new StringBuffer();
              sb.append(""String_Node_Str"").append(child.cmd).append(""String_Node_Str"").append(child.count.get());
              list.add(sb.toString());
            }
            lines.add(list);
          }
 else {
            lines.add(sBuffer.toString());
          }
          sum+=parent.count.get();
        }
        StringBuffer sBuffer=new StringBuffer();
        sBuffer.append(""String_Node_Str"").append(""String_Node_Str"").append(sum);
        lines.add(sBuffer.toString());
        return encodeObject(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer title=new StringBuffer();
        title.append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"");
        lines.add(title.toString());
        Set<Entry<String,UserCommand>> entrys=StatUtil.getUserCommandCountMap().entrySet();
        for (        Entry<String,UserCommand> entry : entrys) {
          UserCommand userCommand=entry.getValue();
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(userCommand.user).append(""String_Node_Str"").append(userCommand.readComandCount.get()).append(""String_Node_Str"").append(userCommand.writeCommandCount.get()).append(""String_Node_Str"").append(userCommand.readComandCount.get() + userCommand.writeCommandCount.get());
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") && numArgs == 3) {
        String user=new String(request.getArgs()[2]);
        List<String> lines=new ArrayList<String>();
        StringBuffer title=new StringBuffer();
        title.append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"");
        lines.add(title.toString());
        int sum=0;
        ConcurrentHashMap<String,UserCommand> userCommandMap=StatUtil.getUserCommandCountMap();
        UserCommand userCommand=userCommandMap.get(user);
        if (userCommand != null) {
          for (          Entry<String,AtomicLong> entry : userCommand.commandCount.entrySet()) {
            StringBuffer sBuffer=new StringBuffer();
            sBuffer.append(user).append(""String_Node_Str"").append(entry.getKey()).append(""String_Node_Str"").append(entry.getValue().get());
            lines.add(sBuffer.toString());
          }
        }
        StringBuffer end=new StringBuffer();
        end.append(""String_Node_Str"").append(""String_Node_Str"").append(sum);
        lines.add(end.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        lines.add(Versions.SERVER_VERSION);
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        if (JavaUtils.isLinux()) {
          StringBuffer cmdBuffer=new StringBuffer();
          cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid()).append(""String_Node_Str"");
          String response;
          try {
            response=ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",cmdBuffer.toString());
            lines.add(response);
          }
 catch (          IOException e) {
            LOGGER.error(""String_Node_Str"",e);
            lines.add(""String_Node_Str"");
          }
        }
 else {
          lines.add(""String_Node_Str"");
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        lines.add(""String_Node_Str"" + JavaUtils.bytesToString2(Math.round(JavaUtils.getMemUsage())));
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        int frontSize=0;
        int backendSize=0;
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisFrontConnection) {
            frontSize++;
          }
 else {
            backendSize++;
          }
        }
        StringBuffer sBuffer=new StringBuffer();
        sBuffer.append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"").append(frontSize).append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"").append(backendSize).append(""String_Node_Str"");
        return sBuffer.toString().getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        Map<String,Integer> userMap=new HashMap<String,Integer>();
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisFrontConnection) {
            userMap.put(((RedisFrontConnection)c).getPassword(),1 + (userMap.get(((RedisFrontConnection)c).getPassword()) == null ? 0 : userMap.get(((RedisFrontConnection)c).getPassword())));
          }
        }
        StringBuffer sBuffer=new StringBuffer();
        sBuffer.append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"");
        Iterator<Entry<String,Integer>> users=userMap.entrySet().iterator();
        while (users.hasNext()) {
          sBuffer.append(""String_Node_Str"");
          Entry<String,Integer> en=users.next();
          sBuffer.append(en.getKey());
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(en.getValue());
        }
        sBuffer.append(""String_Node_Str"");
        return sBuffer.toString().getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        ConcurrentHashMap<String,AccessStatInfoResult> results=StatUtil.getTotalAccessStatInfo();
        for (        Map.Entry<String,AccessStatInfoResult> entry : results.entrySet()) {
          AccessStatInfoResult result=entry.getValue();
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(""String_Node_Str"").append(result.key).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.totalCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.slowCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.maxCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.minCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.avgCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.procTime).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netInBytes[1]).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netInBytes[2]).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netInBytes[3]).append(""String_Node_Str"").append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netOutBytes[1]).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netOutBytes[2]).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netOutBytes[3]).append(""String_Node_Str"").append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.created);
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisFrontConnection) {
            lines.add(c.toString());
          }
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        BufferPool bufferPool=NetSystem.getInstance().getBufferPool();
        long usedBufferSize=bufferPool.getUsedBufferSize().get();
        long maxBufferSize=bufferPool.getMaxBufferSize();
        long minBufferSize=bufferPool.getMinBufferSize();
        long sharedOptsCount=bufferPool.getSharedOptsCount();
        int capacity=0;
        if (bufferPool instanceof BucketBufferPool) {
          BucketBufferPool p=(BucketBufferPool)bufferPool;
          AbstractBucket[] buckets=p.buckets();
          for (          AbstractBucket b : buckets) {
            capacity+=b.getCount();
          }
          int bucketLen=buckets.length;
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(capacity).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(minBufferSize).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(maxBufferSize).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(usedBufferSize).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(bucketLen).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(sharedOptsCount).append(""String_Node_Str"");
          return sBuffer.toString().getBytes();
        }
 else         if (bufferPool instanceof PageBufferPool) {
          List<String> lines=new ArrayList<String>();
          ConcurrentHashMap<Long,Long> bufferpoolUsageMap=bufferPool.getNetDirectMemoryUsage();
          long usedforNetwork=0;
          for (          Map.Entry<Long,Long> entry : bufferpoolUsageMap.entrySet()) {
            long value=entry.getValue();
            lines.add(""String_Node_Str"" + entry.getKey() + ""String_Node_Str""+ (value > 0 ? JavaUtils.bytesToString2(value) : ""String_Node_Str""));
            usedforNetwork=usedforNetwork + value;
          }
          lines.add(""String_Node_Str"" + JavaUtils.bytesToString2(minBufferSize));
          lines.add(""String_Node_Str"" + JavaUtils.bytesToString2(maxBufferSize));
          lines.add(""String_Node_Str"" + JavaUtils.bytesToString2(usedforNetwork));
          return encode(lines);
        }
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        BufferPool bufferPool=NetSystem.getInstance().getBufferPool();
        if (bufferPool instanceof BucketBufferPool) {
          BucketBufferPool p=(BucketBufferPool)bufferPool;
          AbstractBucket[] buckets=p.buckets();
          for (          AbstractBucket b : buckets) {
            StringBuffer sBuffer=new StringBuffer();
            sBuffer.append(""String_Node_Str"").append(b.getChunkSize()).append(""String_Node_Str"");
            sBuffer.append(""String_Node_Str"").append(b.getQueueSize()).append(""String_Node_Str"");
            sBuffer.append(""String_Node_Str"").append(b.getCount()).append(""String_Node_Str"");
            sBuffer.append(""String_Node_Str"").append(b.getUsedCount()).append(""String_Node_Str"");
            sBuffer.append(""String_Node_Str"").append(b.getShared());
            lines.add(sBuffer.toString());
          }
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        for (        BigKey bigkey : StatUtil.getBigKeys()) {
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(bigkey.lastCmd).append(""String_Node_Str"");
          sBuffer.append(bigkey.key).append(""String_Node_Str"");
          sBuffer.append(bigkey.size).append(""String_Node_Str"");
          sBuffer.append(bigkey.count.get());
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        BigKeyCollector bkc=StatUtil.getBigKeyCollector();
        StringBuffer sBuffer=new StringBuffer();
        sBuffer.append(""String_Node_Str"").append(bkc.getBigKeyCount()).append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"").append(bkc.getBypassBigKeyCount());
        lines.add(sBuffer.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        Map<String,AtomicInteger> poolConnections=new HashMap<String,AtomicInteger>();
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisBackendConnection) {
            String poolName=((RedisBackendConnection)c).getPhysicalNode().getPoolName();
            AtomicInteger poolConnCount=poolConnections.get(poolName);
            if (poolConnCount == null) {
              poolConnections.put(poolName,new AtomicInteger(1));
            }
 else {
              poolConnCount.incrementAndGet();
            }
            lines.add(c.toString());
          }
 else           if (c instanceof KafkaBackendConnection) {
            String poolName=((KafkaBackendConnection)c).getPhysicalNode().getPoolName();
            AtomicInteger poolConnCount=poolConnections.get(poolName);
            if (poolConnCount == null) {
              poolConnections.put(poolName,new AtomicInteger(1));
            }
 else {
              poolConnCount.incrementAndGet();
            }
            lines.add(c.toString());
          }
        }
        StringBuffer sb=new StringBuffer();
        for (        Map.Entry<String,AtomicInteger> entry : poolConnections.entrySet()) {
          sb.append(entry.getKey()).append(""String_Node_Str"").append(entry.getValue().get()).append(""String_Node_Str"");
        }
        lines.add(sb.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") && numArgs == 3) {
        List<String> lines=new ArrayList<String>();
        long minStartupTime=-1;
        long totalNetInBytes=0;
        long totalNetOutBytes=0;
        String poolName=new String(request.getArgs()[2]);
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisBackendConnection) {
            if (((RedisBackendConnection)c).getPhysicalNode().getPoolName().equals(poolName)) {
              StringBuffer sb=new StringBuffer();
              sb.append(""String_Node_Str"").append(c.getId()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(c.getStartupTime()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(c.getNetInBytes()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(c.getNetOutBytes()).append(""String_Node_Str"");
              lines.add(sb.toString());
              minStartupTime=minStartupTime < 0 ? c.getStartupTime() : Math.min(minStartupTime,c.getStartupTime());
              totalNetInBytes+=c.getNetInBytes();
              totalNetOutBytes+=c.getNetOutBytes();
            }
          }
        }
        StringBuffer end=new StringBuffer();
        end.append(""String_Node_Str"").append(minStartupTime).append(""String_Node_Str"");
        end.append(""String_Node_Str"").append(totalNetInBytes).append(""String_Node_Str"");
        end.append(""String_Node_Str"").append(totalNetOutBytes).append(""String_Node_Str"");
        lines.add(end.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") || arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        AccessStatInfoResult result=StatUtil.getTotalAccessStatInfo().get(StatUtil.STAT_KEY);
        if (result != null) {
          StringBuffer line0=new StringBuffer();
          line0.append(""String_Node_Str"").append(""String_Node_Str"");
          line0.append(""String_Node_Str"").append(""String_Node_Str"");
          line0.append(""String_Node_Str"").append(""String_Node_Str"");
          line0.append(""String_Node_Str"").append(""String_Node_Str"");
          line0.append(""String_Node_Str"");
          StringBuffer line1=new StringBuffer();
          line1.append(""String_Node_Str"").append(""String_Node_Str"");
          line1.append(result.netInBytes[0]).append(""String_Node_Str"");
          line1.append(result.netInBytes[1]).append(""String_Node_Str"");
          line1.append(result.netInBytes[2]).append(""String_Node_Str"");
          line1.append(result.netInBytes[3]);
          StringBuffer line2=new StringBuffer();
          line2.append(""String_Node_Str"").append(""String_Node_Str"");
          line2.append(result.netOutBytes[0]).append(""String_Node_Str"");
          line2.append(result.netOutBytes[1]).append(""String_Node_Str"");
          line2.append(result.netOutBytes[2]).append(""String_Node_Str"");
          line2.append(result.netOutBytes[3]);
          StringBuffer line3=new StringBuffer();
          line3.append(result.created);
          lines.add(line0.toString());
          lines.add(line1.toString());
          lines.add(line2.toString());
          lines.add(line3.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        for (        Map.Entry<String,AccessStatInfoResult> entry : StatUtil.getTotalAccessStatInfo().entrySet()) {
          if (!StatUtil.STAT_KEY.equals(entry.getKey())) {
            AccessStatInfoResult result=entry.getValue();
            StringBuffer line1=new StringBuffer();
            line1.append(result.key).append(""String_Node_Str"");
            line1.append(""String_Node_Str"").append(""String_Node_Str"");
            line1.append(result.netInBytes[0]).append(""String_Node_Str"");
            line1.append(result.netInBytes[1]).append(""String_Node_Str"");
            line1.append(result.netInBytes[2]).append(""String_Node_Str"");
            line1.append(result.netInBytes[3]);
            StringBuffer line2=new StringBuffer();
            line2.append(result.key).append(""String_Node_Str"");
            line2.append(""String_Node_Str"").append(""String_Node_Str"");
            line2.append(result.netOutBytes[0]).append(""String_Node_Str"");
            line2.append(result.netOutBytes[1]).append(""String_Node_Str"");
            line2.append(result.netOutBytes[2]).append(""String_Node_Str"");
            line2.append(result.netOutBytes[3]);
            StringBuffer line3=new StringBuffer();
            line3.append(result.created);
            lines.add(line1.toString());
            lines.add(line2.toString());
            lines.add(line3.toString());
          }
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        long totalNetIn=0;
        long totalNetOut=0;
        for (        Map.Entry<String,UserFlow> entry : StatUtil.getUserFlowMap().entrySet()) {
          if (!StatUtil.STAT_KEY.equals(entry.getKey())) {
            StringBuffer sb=new StringBuffer();
            UserFlow userNetIo=entry.getValue();
            sb.append(userNetIo.password).append(""String_Node_Str"");
            sb.append(JavaUtils.bytesToString2(userNetIo.netIn.get())).append(""String_Node_Str"");
            sb.append(JavaUtils.bytesToString2(userNetIo.netOut.get()));
            totalNetIn=totalNetIn + userNetIo.netIn.get();
            totalNetOut=totalNetOut + userNetIo.netOut.get();
            lines.add(sb.toString());
          }
        }
        StringBuffer total=new StringBuffer();
        total.append(""String_Node_Str"").append(""String_Node_Str"");
        total.append(JavaUtils.bytesToString2(totalNetIn)).append(""String_Node_Str"");
        total.append(JavaUtils.bytesToString2(totalNetOut));
        lines.add(total.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=showLog(request,""String_Node_Str"");
        return encode2(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=showLog(request,""String_Node_Str"");
        return encode2(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=showLog(request,""String_Node_Str"");
        return encode2(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=showLog(request,""String_Node_Str"");
        return encode2(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> ret=new ArrayList<String>();
        try {
          String resp=ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"");
          StringBuilder sb=new StringBuilder();
          sb.append(resp);
          sb.append(""String_Node_Str"");
          String[] lines=sb.toString().split(""String_Node_Str"");
          ret.add(""String_Node_Str"");
          for (int i=1; i < lines.length; i++) {
            if (lines[i].equals(""String_Node_Str""))             continue;
            ret.add(lines[i]);
          }
        }
 catch (        IOException e) {
          LOGGER.error(""String_Node_Str"",e);
          ret.add(""String_Node_Str"");
        }
        return encode2(ret);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> ret=new ArrayList<String>();
        try {
          String cmd1=ShellUtils.osType == ShellUtils.OSType.OS_TYPE_MAC ? ""String_Node_Str"" : ""String_Node_Str"";
          String cmd2=ShellUtils.osType == ShellUtils.OSType.OS_TYPE_MAC ? ""String_Node_Str"" : ""String_Node_Str"";
          String iostatOut=ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",cmd1);
          String vmstatOut=ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",cmd2);
          StringBuilder sb=new StringBuilder();
          sb.append(iostatOut);
          sb.append(""String_Node_Str"");
          sb.append(""String_Node_Str"");
          sb.append(vmstatOut);
          String[] lines=sb.toString().split(""String_Node_Str"");
          ret.add(""String_Node_Str"");
          for (int i=1; i < lines.length; i++) {
            if (lines[i].equals(""String_Node_Str""))             continue;
            ret.add(lines[i]);
          }
        }
 catch (        IOException e) {
          LOGGER.error(""String_Node_Str"",e);
          ret.add(""String_Node_Str"");
        }
        return encode2(ret);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<Object> list=new ArrayList<Object>();
        Map<Integer,AbstractPool> pools=RedisEngineCtx.INSTANCE().getPoolMap();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        list.add(titleLine.toString());
        for (        AbstractPool pool : pools.values()) {
          if (pool instanceof RedisStandalonePool) {
            StringBuffer sb=new StringBuffer();
            RedisStandalonePool redisStandalonePool=(RedisStandalonePool)pool;
            PhysicalNode physicalNode=redisStandalonePool.getPhysicalNode();
            if (physicalNode == null)             continue;
            sb.append(""String_Node_Str"");
            sb.append(redisStandalonePool.getId()).append(""String_Node_Str"");
            sb.append(physicalNode.getPoolName()).append(""String_Node_Str"");
            sb.append(""String_Node_Str"").append(""String_Node_Str"");
            sb.append(physicalNode.getName()).append(""String_Node_Str"");
            sb.append(physicalNode.getMinCon()).append(""String_Node_Str"");
            sb.append(physicalNode.getMaxCon()).append(""String_Node_Str"");
            sb.append(physicalNode.getIdleCount()).append(""String_Node_Str"");
            sb.append(physicalNode.getActiveCount());
            list.add(sb.toString());
          }
 else           if (pool instanceof RedisClusterPool) {
            RedisClusterPool redisClusterPool=(RedisClusterPool)pool;
            Map<String,ClusterNode> masters=redisClusterPool.getMasters();
            List<String> clusterInfo=new ArrayList<String>();
            for (            ClusterNode clusterNode : masters.values()) {
              PhysicalNode physicalNode=clusterNode.getPhysicalNode();
              StringBuffer sb=new StringBuffer();
              sb.append(redisClusterPool.getId()).append(""String_Node_Str"");
              sb.append(physicalNode.getPoolName()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(""String_Node_Str"");
              sb.append(physicalNode.getName()).append(""String_Node_Str"");
              sb.append(physicalNode.getMinCon()).append(""String_Node_Str"");
              sb.append(physicalNode.getMaxCon()).append(""String_Node_Str"");
              sb.append(physicalNode.getIdleCount()).append(""String_Node_Str"");
              sb.append(physicalNode.getActiveCount()).append(""String_Node_Str"");
              ;
              sb.append(!clusterNode.isFail());
              clusterInfo.add(sb.toString());
              sb.append(clusterNode.getConnectInfo());
            }
            list.add(clusterInfo);
          }
 else           if (pool instanceof KafkaPool) {
            KafkaPool kafkaPool=(KafkaPool)pool;
            Map<Integer,PhysicalNode> physicalNodes=kafkaPool.getPhysicalNodes();
            for (            PhysicalNode physicalNode : physicalNodes.values()) {
              StringBuffer sb=new StringBuffer();
              sb.append(""String_Node_Str"");
              sb.append(kafkaPool.getId()).append(""String_Node_Str"");
              sb.append(physicalNode.getPoolName()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(""String_Node_Str"");
              sb.append(physicalNode.getName()).append(""String_Node_Str"");
              sb.append(physicalNode.getMinCon()).append(""String_Node_Str"");
              sb.append(physicalNode.getMaxCon()).append(""String_Node_Str"");
              sb.append(physicalNode.getIdleCount()).append(""String_Node_Str"");
              sb.append(physicalNode.getActiveCount());
              list.add(sb.toString());
            }
          }
        }
        return encodeObject(list);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        Collection<Entry<String,AtomicLong>> entrys=StatUtil.getCommandProcTimeMap().entrySet();
        List<String> lines=new ArrayList<String>();
        for (        Entry<String,AtomicLong> entry : entrys) {
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(entry.getKey()).append(""String_Node_Str"").append(entry.getValue().get());
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        Collection<Entry<String,AtomicLong>> entrys=StatUtil.getCommandWaitTimeMap().entrySet();
        List<String> lines=new ArrayList<String>();
        for (        Entry<String,AtomicLong> entry : entrys) {
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(entry.getKey()).append(""String_Node_Str"").append(entry.getValue().get());
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        for (        BigLength bigLength : StatUtil.getBigLengthMap().values()) {
          StringBuffer line1=new StringBuffer();
          line1.append(bigLength.cmd).append(""String_Node_Str"");
          line1.append(bigLength.key).append(""String_Node_Str"");
          line1.append(bigLength.length.get()).append(""String_Node_Str"");
          line1.append(bigLength.count_1k.get()).append(""String_Node_Str"");
          line1.append(bigLength.count_10k.get());
          lines.add(line1.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        for (        SlowKey slowKey : StatUtil.getSlowKey()) {
          StringBuffer line1=new StringBuffer();
          line1.append(slowKey.cmd).append(""String_Node_Str"");
          line1.append(slowKey.key).append(""String_Node_Str"");
          line1.append(slowKey.count);
          lines.add(line1.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") && (numArgs == 3 || numArgs == 2)) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        if (numArgs == 2) {
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"");
        }
 else {
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"");
        }
        lines.add(titleLine.toString());
        final Map<Integer,PoolCfg> poolCfgMap=RedisEngineCtx.INSTANCE().getPoolCfgMap();
        for (        Entry<Integer,PoolCfg> poolEntry : poolCfgMap.entrySet()) {
          PoolCfg poolCfg=poolEntry.getValue();
          if (poolCfg instanceof KafkaPoolCfg) {
            Map<String,TopicCfg> kafkaMap=((KafkaPoolCfg)poolCfg).getTopicCfgMap();
            if (numArgs == 2) {
              for (              Entry<String,TopicCfg> kafkaEntry : kafkaMap.entrySet()) {
                TopicCfg kafkaCfg=kafkaEntry.getValue();
                StringBuffer line=new StringBuffer();
                line.append(kafkaCfg.getName()).append(""String_Node_Str"");
                line.append(kafkaCfg.getPoolId()).append(""String_Node_Str"");
                line.append(kafkaCfg.getPartitions()).append(""String_Node_Str"");
                line.append(kafkaCfg.getReplicationFactor()).append(""String_Node_Str"");
                line.append(kafkaCfg.getProducers()).append(""String_Node_Str"");
                line.append(kafkaCfg.getConsumers());
                lines.add(line.toString());
              }
            }
 else {
              String topic=new String(request.getArgs()[2]);
              TopicCfg kafkaCfg=kafkaMap.get(topic);
              if (kafkaCfg != null) {
                for (                BrokerPartition partition : kafkaCfg.getRunningInfo().getPartitions().values()) {
                  int pt=partition.getPartition();
                  StringBuffer line=new StringBuffer();
                  line.append(kafkaCfg.getName()).append(""String_Node_Str"");
                  line.append(partition.getLeader().getHost()).append(partition.getLeader().getPort()).append(""String_Node_Str"");
                  line.append(pt).append(""String_Node_Str"");
                  line.append(partition.getLogStartOffset()).append(""String_Node_Str"");
                  line.append(partition.getProducerOffset()).append(""String_Node_Str"");
                  for (                  ConsumerOffset consumerOffset : partition.getConsumerOffsets().values()) {
                    line.append(consumerOffset.getConsumer());
                    line.append(""String_Node_Str"");
                    line.append(consumerOffset.getCurrentOffset());
                    line.append(""String_Node_Str"");
                  }
                  lines.add(line.toString());
                }
              }
            }
          }
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") && numArgs == 2) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        NetFlowGuard nfg=RedisEngineCtx.INSTANCE().getNetflowGuard();
        Map<String,Guard> map=nfg.getGuardMap();
        for (        Entry<String,Guard> entry : map.entrySet()) {
          Guard guard=entry.getValue();
          StringBuffer line=new StringBuffer();
          line.append(entry.getKey()).append(""String_Node_Str"");
          line.append(guard.getPerSecondMaxSize()).append(""String_Node_Str"");
          line.append(guard.getRequestMaxSize()).append(""String_Node_Str"");
          line.append(guard.getHistogram());
          lines.add(line.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") && numArgs == 2) {
        List<String> lines=new ArrayList<>();
        lines.add(""String_Node_Str"");
        lines.add(""String_Node_Str"");
        Map<Integer,AbstractPool> pools=RedisEngineCtx.INSTANCE().getPoolMap();
        for (        AbstractPool pool : pools.values()) {
          if (pool instanceof RedisStandalonePool) {
            RedisStandalonePool standalonePool=(RedisStandalonePool)pool;
            PhysicalNode physicalNode=standalonePool.getPhysicalNode();
            List<LatencySample> samples=physicalNode.getLatencySamples();
            for (            LatencySample s : samples) {
              StringBuffer strBuffer=new StringBuffer();
              strBuffer.append(""String_Node_Str"").append(String.valueOf(standalonePool.getId()));
              strBuffer.append(""String_Node_Str"").append(physicalNode.getHost());
              strBuffer.append(""String_Node_Str"").append(physicalNode.getPort());
              strBuffer.append(""String_Node_Str"").append((s.time));
              strBuffer.append(""String_Node_Str"").append((s.latency));
              strBuffer.append(""String_Node_Str"").append((physicalNode.isOverload()));
              lines.add(strBuffer.toString());
            }
          }
 else           if (pool instanceof RedisClusterPool) {
            RedisClusterPool redisClusterPool=(RedisClusterPool)pool;
            Map<String,ClusterNode> masters=redisClusterPool.getMasters();
            lines.add(String.valueOf(redisClusterPool.getId()));
            for (            ClusterNode clusterNode : masters.values()) {
              PhysicalNode physicalNode=clusterNode.getPhysicalNode();
              List<LatencySample> samples=physicalNode.getLatencySamples();
              for (              LatencySample s : samples) {
                StringBuffer strBuffer=new StringBuffer();
                strBuffer.append(""String_Node_Str"").append(String.valueOf(redisClusterPool.getId()));
                strBuffer.append(""String_Node_Str"").append(physicalNode.getHost());
                strBuffer.append(""String_Node_Str"").append((s.latency));
                lines.add(strBuffer.toString());
              }
            }
          }
 else           if (pool instanceof KafkaPool) {
            KafkaPool kafkaPool=(KafkaPool)pool;
            Map<Integer,PhysicalNode> physicalNodes=kafkaPool.getPhysicalNodes();
            for (            PhysicalNode physicalNode : physicalNodes.values()) {
              List<LatencySample> samples=physicalNode.getLatencySamples();
              for (              LatencySample s : samples) {
                StringBuffer strBuffer=new StringBuffer();
                strBuffer.append(""String_Node_Str"").append(String.valueOf(kafkaPool.getId()));
                strBuffer.append(""String_Node_Str"").append(physicalNode.getHost());
                strBuffer.append(""String_Node_Str"").append((s.latency));
                lines.add(strBuffer.toString());
              }
            }
          }
        }
        return encode(lines);
      }
    }
  }
 else   if (arg1.length == 6) {
    if ((arg1[0] == 'R' || arg1[0] == 'r') && (arg1[1] == 'E' || arg1[1] == 'e') && (arg1[2] == 'L' || arg1[2] == 'l')&& (arg1[3] == 'O' || arg1[3] == 'o')&& (arg1[4] == 'A' || arg1[4] == 'a')&& (arg1[5] == 'D' || arg1[5] == 'd')) {
      if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        byte[] buff=RedisEngineCtx.INSTANCE().reloadAll();
        return buff;
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        byte[] buff=RedisEngineCtx.INSTANCE().reloadUser();
        return buff;
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        byte[] buff=RedisEngineCtx.INSTANCE().reloadNetflow();
        return buff;
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisFrontConnection) {
            LOGGER.info(""String_Node_Str"",c);
            c.close(""String_Node_Str"");
          }
        }
        return ""String_Node_Str"".getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        JAVA_BIN_PATH=new String(request.getArgs()[2]);
        return ""String_Node_Str"".getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        try {
          Map<Integer,PoolCfg> poolCfgMap=RedisEngineCtx.INSTANCE().getPoolCfgMap();
          for (          PoolCfg poolCfg : poolCfgMap.values()) {
            if (poolCfg instanceof KafkaPoolCfg)             poolCfg.reloadExtraCfg();
          }
        }
 catch (        Exception e) {
          LOGGER.error(""String_Node_Str"",e);
          StringBuffer sb=new StringBuffer();
          sb.append(""String_Node_Str"").append(e.getMessage()).append(""String_Node_Str"");
          return sb.toString().getBytes();
        }
        return ""String_Node_Str"".getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        byte[] buff=BypassService.INSTANCE().reload();
        return buff;
      }
    }
    if ((arg1[0] == 'R' || arg1[0] == 'r') && (arg1[1] == 'E' || arg1[1] == 'e') && (arg1[2] == 'P' || arg1[2] == 'p')&& (arg1[3] == 'A' || arg1[3] == 'a')&& (arg1[4] == 'I' || arg1[4] == 'i')&& (arg1[5] == 'R' || arg1[5] == 'r')) {
      if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        String password=new String(request.getArgs()[2]);
        String topicName=new String(request.getArgs()[3]);
        long offset=Long.parseLong(new String(request.getArgs()[4]));
        UserCfg userCfg=RedisEngineCtx.INSTANCE().getUserMap().get(password);
        if (userCfg != null) {
          int poolId=userCfg.getPoolId();
          PoolCfg poolCfg=(PoolCfg)RedisEngineCtx.INSTANCE().getPoolCfgMap().get(poolId);
          if (poolCfg != null && poolCfg instanceof KafkaPoolCfg) {
            TopicCfg topicCfg=((KafkaPoolCfg)poolCfg).getTopicCfgMap().get(topicName);
            if (topicCfg != null) {
              for (int partition=0; partition < topicCfg.getPartitions(); partition++) {
                boolean isRepair=BrokerOffsetService.INSTANCE().repairOffset(password,topicCfg,partition,offset);
                if (!isRepair) {
                  return (""String_Node_Str"" + partition + ""String_Node_Str"").getBytes();
                }
              }
            }
 else {
              return (""String_Node_Str"" + topicName + ""String_Node_Str"").getBytes();
            }
            return ""String_Node_Str"".getBytes();
          }
 else {
            return (""String_Node_Str"" + poolId + ""String_Node_Str"").getBytes();
          }
        }
 else {
          return (""String_Node_Str"" + password + ""String_Node_Str"").getBytes();
        }
      }
    }
  }
 else   if (arg1.length == 7) {
    if ((arg1[0] == 'C' || arg1[0] == 'c') && (arg1[1] == 'L' || arg1[1] == 'l') && (arg1[2] == 'U' || arg1[2] == 'u')&& (arg1[3] == 'S' || arg1[3] == 's')&& (arg1[4] == 'T' || arg1[4] == 't')&& (arg1[5] == 'E' || arg1[5] == 'e')&& (arg1[6] == 'R' || arg1[6] == 'r')) {
      AbstractPool pool=RedisEngineCtx.INSTANCE().getPoolMap().get(frontCon.getUserCfg().getPoolId());
      if (pool.getType() != 1) {
        return ""String_Node_Str"".getBytes();
      }
      PhysicalNode pysicalNode=((RedisClusterPool)pool).getPhysicalNodeBySlot(0);
      if (pysicalNode == null) {
        return ""String_Node_Str"".getBytes();
      }
      try {
        RedisBackendConnection backendCon=(RedisBackendConnection)pysicalNode.getConnection(new DirectTransTofrontCallBack(),frontCon);
        if (backendCon == null) {
          frontCon.writeErrMessage(""String_Node_Str"");
        }
 else {
          backendCon.write(request.encode());
        }
        return null;
      }
 catch (      IOException e) {
        LOGGER.error(""String_Node_Str"",e);
      }
    }
  }
  return ""String_Node_Str"".getBytes();
}"
37470,"public void setPassword(String newPassword){
  AtomicInteger num1=CONN_NUM.get(newPassword);
  if (num1 != null) {
    int maxConn=this.userCfg.getMaxCon();
    if (num1.get() > maxConn) {
      StringBuffer reasonSb=new StringBuffer(90);
      reasonSb.append(""String_Node_Str"");
      reasonSb.append(""String_Node_Str"").append(maxConn).append(""String_Node_Str"");
      reasonSb.append(""String_Node_Str"");
      reasonSb.append(""String_Node_Str"");
      this.write(reasonSb.toString().getBytes());
      this.close(""String_Node_Str"");
      return;
    }
    num1.incrementAndGet();
  }
 else {
    CONN_NUM.put(newPassword,new AtomicInteger(1));
  }
  if (isAuthenticated) {
    AtomicInteger num2=CONN_NUM.get(password);
    if (num2 != null && !this.password.equals(newPassword)) {
      num2.decrementAndGet();
    }
  }
  this.password=newPassword;
  this.isAuthenticated=true;
}","public void setPassword(String newPassword){
  AtomicInteger num1=conNums.get(newPassword);
  if (num1 != null) {
    int maxConn=this.userCfg.getMaxCon();
    if (num1.get() > maxConn) {
      StringBuffer reasonSb=new StringBuffer(90);
      reasonSb.append(""String_Node_Str"");
      reasonSb.append(""String_Node_Str"").append(maxConn).append(""String_Node_Str"");
      reasonSb.append(""String_Node_Str"");
      reasonSb.append(""String_Node_Str"");
      this.write(reasonSb.toString().getBytes());
      this.close(""String_Node_Str"");
      return;
    }
    num1.incrementAndGet();
  }
 else {
    conNums.put(newPassword,new AtomicInteger(1));
  }
  if (isAuthenticated) {
    AtomicInteger num2=conNums.get(password);
    if (num2 != null && !this.password.equals(newPassword)) {
      num2.decrementAndGet();
    }
  }
  this.password=newPassword;
  this.isAuthenticated=true;
}"
37471,"@Override public void close(String reason){
  super.close(reason);
  this.releaseLock();
  if (isAuthenticated) {
    AtomicInteger num=CONN_NUM.get(password);
    if (num != null) {
      int v=num.decrementAndGet();
      if (v < 0) {
        LOGGER.warn(""String_Node_Str"",password,v);
      }
    }
  }
}","@Override public void close(String reason){
  super.close(reason);
  this.releaseLock();
synchronized (this) {
    if (isAuthenticated) {
      isAuthenticated=false;
      AtomicInteger num=conNums.get(password);
      if (num != null) {
        int v=num.decrementAndGet();
        if (v < 0) {
          LOGGER.warn(""String_Node_Str"",password,v);
        }
      }
    }
  }
}"
37472,"/** 
 * topic
 * @return
 */
public Map<String,TopicDescription> getTopicAndDescriptions(){
  ListTopicsOptions lto=new ListTopicsOptions();
  lto.timeoutMs(10 * 1000);
  ListTopicsResult ltr=adminClient.listTopics(lto);
  try {
    DescribeTopicsOptions dto=new DescribeTopicsOptions();
    dto.timeoutMs(15 * 1000);
    DescribeTopicsResult dtr=adminClient.describeTopics(ltr.names().get(),dto);
    return dtr.all().get();
  }
 catch (  Exception e) {
    LOGGER.error(""String_Node_Str"",e);
  }
  return null;
}","public Map<String,TopicDescription> getTopicAndDescriptions() throws Exception {
  try {
    ListTopicsOptions lto=new ListTopicsOptions();
    lto.timeoutMs(10 * 1000);
    ListTopicsResult ltr=adminClient.listTopics(lto);
    DescribeTopicsOptions dto=new DescribeTopicsOptions();
    dto.timeoutMs(15 * 1000);
    DescribeTopicsResult dtr=adminClient.describeTopics(ltr.names().get(),dto);
    return dtr.all().get();
  }
 catch (  Exception e) {
    throw e;
  }
}"
37473,"/** 
 * topic
 * @param topic
 * @param partitions
 * @return
 */
public CreatePartitionsResult addPartitionsForTopic(String topic,int partitions){
  Map<String,NewPartitions> map=new HashMap<>();
  NewPartitions np=NewPartitions.increaseTo(partitions);
  map.put(topic,np);
  CreatePartitionsOptions cpo=new CreatePartitionsOptions();
  cpo.timeoutMs(5 * 1000);
  return adminClient.createPartitions(map,cpo);
}","/** 
 * topic
 */
public CreatePartitionsResult addPartitionsForTopic(String topic,int partitions){
  Map<String,NewPartitions> map=new HashMap<>();
  NewPartitions np=NewPartitions.increaseTo(partitions);
  map.put(topic,np);
  CreatePartitionsOptions cpo=new CreatePartitionsOptions();
  cpo.timeoutMs(5 * 1000);
  return adminClient.createPartitions(map,cpo);
}"
37474,"/** 
 * zhuamdeMacBook-Pro:logs zhuam$ [2018-05-28 15:26:41,394] INFO [Admin Manager on Broker 0]:  Error processing create topic request for topic test01 with arguments (numPartitions=3, replicationFactor=2, replicasAssignments={}, configs={}) (kafka.server.AdminManager) org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 2 larger than available brokers: 1.
 */
private void initializeOfKafka(Map<String,TopicCfg> topicCfgMap) throws Exception {
  if (topicCfgMap == null || topicCfgMap.isEmpty()) {
    return;
  }
  StringBuffer servers=new StringBuffer();
  List<String> nodes=this.getNodes();
  for (int i=0; i < nodes.size(); i++) {
    String str=nodes.get(i);
    String[] node=str.split(""String_Node_Str"");
    servers.append(node[0]).append(""String_Node_Str"").append(node[1]);
    if (i < nodes.size() - 1) {
      servers.append(""String_Node_Str"");
    }
  }
  KafkaAdmin kafkaAdmin=null;
  try {
    kafkaAdmin=KafkaAdmin.create(servers.toString());
    Map<String,TopicDescription> remoteTopics=kafkaAdmin.getTopicAndDescriptions();
    Collection<Node> clusterNodes=kafkaAdmin.getClusterNodes();
    for (    TopicCfg topicCfg : topicCfgMap.values()) {
      String topicName=topicCfg.getName();
      short replicationFactor=topicCfg.getReplicationFactor();
      int partitionNum=topicCfg.getPartitions();
      TopicDescription topicDescription=remoteTopics.get(topicName);
      if (topicDescription != null) {
        int oldPartitionNum=topicDescription.partitions().size();
        if (partitionNum > oldPartitionNum) {
          kafkaAdmin.addPartitionsForTopic(topicName,partitionNum);
          topicDescription=kafkaAdmin.getDescriptionByTopicName(topicName);
        }
      }
 else {
        if (clusterNodes == null || replicationFactor > clusterNodes.size()) {
          throw new Exception(""String_Node_Str"" + topicName + ""String_Node_Str"");
        }
        kafkaAdmin.createTopic(topicName,partitionNum,replicationFactor);
        topicDescription=kafkaAdmin.getDescriptionByTopicName(topicName);
      }
      if (topicDescription == null) {
        throw new Exception(""String_Node_Str"" + topicName + ""String_Node_Str"");
      }
      String name=topicDescription.name();
      boolean internal=topicDescription.isInternal();
      int partitionSize=topicDescription.partitions().size();
      BrokerPartition[] newPartitions=new BrokerPartition[partitionSize];
      for (int i=0; i < partitionSize; i++) {
        TopicPartitionInfo partitionInfo=topicDescription.partitions().get(i);
        int partition=partitionInfo.partition();
        Node leader=partitionInfo.leader();
        BrokerNode newLeader=new BrokerNode(leader.id(),leader.host(),leader.port());
        List<Node> replicas=partitionInfo.replicas();
        BrokerNode[] newReplicas=new BrokerNode[replicas.size()];
        for (int j=0; j < replicas.size(); j++) {
          newReplicas[j]=new BrokerNode(replicas.get(j).id(),replicas.get(j).host(),replicas.get(j).port());
        }
        BrokerPartition newPartition=new BrokerPartition(partition,newLeader,newReplicas);
        newPartitions[i]=newPartition;
      }
      topicCfg.setRunningInfo(new BrokerRunningInfo(name,internal,newPartitions));
    }
  }
 catch (  Throwable e) {
    throw e;
  }
 finally {
    if (kafkaAdmin != null)     kafkaAdmin.close();
  }
}","/** 
 * zhuamdeMacBook-Pro:logs zhuam$ [2018-05-28 15:26:41,394] INFO [Admin Manager on Broker 0]:  Error processing create topic request for topic test01 with arguments (numPartitions=3, replicationFactor=2, replicasAssignments={}, configs={}) (kafka.server.AdminManager) org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 2 larger than available brokers: 1.
 */
private void initializeOfKafka(Map<String,TopicCfg> topicCfgMap) throws Exception, org.apache.kafka.common.errors.TimeoutException {
  if (topicCfgMap == null || topicCfgMap.isEmpty()) {
    return;
  }
  StringBuffer servers=new StringBuffer();
  List<String> nodes=this.getNodes();
  for (int i=0; i < nodes.size(); i++) {
    String str=nodes.get(i);
    String[] node=str.split(""String_Node_Str"");
    servers.append(node[0]).append(""String_Node_Str"").append(node[1]);
    if (i < nodes.size() - 1) {
      servers.append(""String_Node_Str"");
    }
  }
  KafkaAdmin kafkaAdmin=null;
  try {
    kafkaAdmin=KafkaAdmin.create(servers.toString());
    Map<String,TopicDescription> remoteTopics=kafkaAdmin.getTopicAndDescriptions();
    Collection<Node> clusterNodes=kafkaAdmin.getClusterNodes();
    for (    TopicCfg topicCfg : topicCfgMap.values()) {
      String topicName=topicCfg.getName();
      short replicationFactor=topicCfg.getReplicationFactor();
      int partitionNum=topicCfg.getPartitions();
      TopicDescription topicDescription=remoteTopics.get(topicName);
      if (topicDescription != null) {
        int oldPartitionNum=topicDescription.partitions().size();
        if (partitionNum > oldPartitionNum) {
          kafkaAdmin.addPartitionsForTopic(topicName,partitionNum);
          topicDescription=kafkaAdmin.getDescriptionByTopicName(topicName);
        }
      }
 else {
        if (clusterNodes == null || replicationFactor > clusterNodes.size()) {
          throw new Exception(""String_Node_Str"" + topicName + ""String_Node_Str"");
        }
        kafkaAdmin.createTopic(topicName,partitionNum,replicationFactor);
        topicDescription=kafkaAdmin.getDescriptionByTopicName(topicName);
      }
      if (topicDescription == null) {
        throw new Exception(""String_Node_Str"" + topicName + ""String_Node_Str"");
      }
      String name=topicDescription.name();
      boolean internal=topicDescription.isInternal();
      int partitionSize=topicDescription.partitions().size();
      BrokerPartition[] newPartitions=new BrokerPartition[partitionSize];
      for (int i=0; i < partitionSize; i++) {
        TopicPartitionInfo partitionInfo=topicDescription.partitions().get(i);
        int partition=partitionInfo.partition();
        Node leader=partitionInfo.leader();
        BrokerNode newLeader=new BrokerNode(leader.id(),leader.host(),leader.port());
        List<Node> replicas=partitionInfo.replicas();
        BrokerNode[] newReplicas=new BrokerNode[replicas.size()];
        for (int j=0; j < replicas.size(); j++) {
          newReplicas[j]=new BrokerNode(replicas.get(j).id(),replicas.get(j).host(),replicas.get(j).port());
        }
        BrokerPartition newPartition=new BrokerPartition(partition,newLeader,newReplicas);
        newPartitions[i]=newPartition;
      }
      topicCfg.setRunningInfo(new BrokerRunningInfo(name,internal,newPartitions));
    }
  }
 catch (  Throwable e) {
    throw new Exception(""String_Node_Str"" + servers.toString(),e);
  }
 finally {
    if (kafkaAdmin != null)     kafkaAdmin.close();
  }
}"
37475,"public static void main(String[] args) throws IOException {
  if (System.getProperty(""String_Node_Str"") == null) {
    System.setProperty(""String_Node_Str"",System.getProperty(""String_Node_Str""));
  }
  Log4jInitializer.configureAndWatch(System.getProperty(""String_Node_Str""),""String_Node_Str"",30000L);
  try {
    final Logger LOGGER=LoggerFactory.getLogger(""String_Node_Str"");
    RedisEngineCtx.INSTANCE().init();
    heartbeatScheduler.scheduleAtFixedRate(new Runnable(){
      @Override public void run(){
        TimeUtil.update();
      }
    }
,0,2L,TimeUnit.MILLISECONDS);
    scheduler.scheduleAtFixedRate(new Runnable(){
      @Override public void run(){
        NetSystem.getInstance().getTimerExecutor().execute(new Runnable(){
          @Override public void run(){
            NetSystem.getInstance().checkConnections();
          }
        }
);
      }
    }
,0L,1 * 1000L,TimeUnit.MILLISECONDS);
    heartbeatScheduler.scheduleAtFixedRate(new Runnable(){
      @Override public void run(){
        NetSystem.getInstance().getTimerExecutor().execute(new Runnable(){
          @Override public void run(){
            Map<Integer,AbstractPool> pools=RedisEngineCtx.INSTANCE().getPoolMap();
            for (            AbstractPool pool : pools.values()) {
              try {
                pool.availableCheck();
              }
 catch (              Throwable e) {
                LOGGER.error(""String_Node_Str"" + pool.getId(),e);
              }
            }
          }
        }
);
      }
    }
,10L,10L,TimeUnit.SECONDS);
    heartbeatScheduler.scheduleAtFixedRate(new Runnable(){
      static final long TIMEOUT=2 * 60 * 1000L;
      @Override public void run(){
        NetSystem.getInstance().getTimerExecutor().execute(new Runnable(){
          @Override public void run(){
            Map<Integer,AbstractPool> pools=RedisEngineCtx.INSTANCE().getPoolMap();
            for (            AbstractPool pool : pools.values()) {
              pool.heartbeatCheck(TIMEOUT);
            }
          }
        }
);
      }
    }
,30L,30L,TimeUnit.SECONDS);
    StringBuffer strBuffer=new StringBuffer();
    strBuffer.append(""String_Node_Str"").append(""String_Node_Str"");
    strBuffer.append(""String_Node_Str"").append(""String_Node_Str"");
    strBuffer.append(""String_Node_Str"").append(System.getProperty(""String_Node_Str"")).append(""String_Node_Str"");
    strBuffer.append(""String_Node_Str"").append(System.currentTimeMillis()).append(""String_Node_Str"");
    System.out.println(strBuffer.toString());
  }
 catch (  Throwable e) {
    System.exit(0);
  }
}","public static void main(String[] args) throws IOException {
  if (System.getProperty(""String_Node_Str"") == null) {
    System.setProperty(""String_Node_Str"",System.getProperty(""String_Node_Str""));
  }
  Log4jInitializer.configureAndWatch(System.getProperty(""String_Node_Str""),""String_Node_Str"",30000L);
  try {
    final Logger LOGGER=LoggerFactory.getLogger(""String_Node_Str"");
    RedisEngineCtx.INSTANCE().init();
    heartbeatScheduler.scheduleAtFixedRate(new Runnable(){
      @Override public void run(){
        TimeUtil.update();
      }
    }
,0,2L,TimeUnit.MILLISECONDS);
    scheduler.scheduleAtFixedRate(new Runnable(){
      @Override public void run(){
        NetSystem.getInstance().getTimerExecutor().execute(new Runnable(){
          @Override public void run(){
            NetSystem.getInstance().checkConnections();
          }
        }
);
      }
    }
,0L,1 * 1000L,TimeUnit.MILLISECONDS);
    heartbeatScheduler.scheduleAtFixedRate(new Runnable(){
      @Override public void run(){
        NetSystem.getInstance().getTimerExecutor().execute(new Runnable(){
          @Override public void run(){
            Map<Integer,AbstractPool> pools=RedisEngineCtx.INSTANCE().getPoolMap();
            for (            AbstractPool pool : pools.values()) {
              try {
                pool.availableCheck();
              }
 catch (              Throwable e) {
                LOGGER.error(""String_Node_Str"" + pool.getId(),e);
              }
            }
          }
        }
);
      }
    }
,10L,10L,TimeUnit.SECONDS);
    heartbeatScheduler.scheduleAtFixedRate(new Runnable(){
      static final long TIMEOUT=2 * 60 * 1000L;
      @Override public void run(){
        NetSystem.getInstance().getTimerExecutor().execute(new Runnable(){
          @Override public void run(){
            Map<Integer,AbstractPool> pools=RedisEngineCtx.INSTANCE().getPoolMap();
            for (            AbstractPool pool : pools.values()) {
              pool.heartbeatCheck(TIMEOUT);
            }
          }
        }
);
      }
    }
,30L,30L,TimeUnit.SECONDS);
    StringBuffer strBuffer=new StringBuffer();
    strBuffer.append(""String_Node_Str"").append(""String_Node_Str"");
    strBuffer.append(""String_Node_Str"").append(""String_Node_Str"");
    strBuffer.append(""String_Node_Str"").append(System.getProperty(""String_Node_Str"")).append(""String_Node_Str"");
    strBuffer.append(""String_Node_Str"").append(System.currentTimeMillis()).append(""String_Node_Str"");
    System.out.println(strBuffer.toString());
  }
 catch (  Throwable e) {
    e.printStackTrace();
    System.exit(0);
  }
}"
37476,"/** 
 *  ---------------------------------------- USE [POOL_ID] RELOAD USER RELOAD ALL RELOAD FRONT RELOAD PATH RELOAD KAFKA RELOAD BIGKEY RELOAD NETFLOW JVM  JAVA_HOME  ---------------------------------------- JVM JSTACK JVM JSTAT JVM JMAP_HISTO JVM JMAP_HEAP JVM PS SHOW USER SHOW USER_NET_IO  SHOW CPU SHOW MEM SHOW QPS SHOW CONN SHOW USER_CONN SHOW BUFFER SHOW BIGKEY SHOW BIGKEY_COUNT SHOW BIGLENGTH SHOW SLOWKEY SHOW CMD SHOW USER_CMD SHOW USER_CMD_DETAIL USER SHOW VER SHOW NET_IO  SHOW NETBYTES SHOW VM SHOW POOL SHOW COST SHOW WAIT_COST SHOW USER_DAY_NET_IO SHOW POOL_NET_IO POOLNAME SHOW TOPIC SHOW LOG_ERROR SHOW LOG_WARN SHOW LOG_INFO SHOW LOG_DEBUG
 */
public static byte[] execute(final RedisRequest request,RedisFrontConnection frontCon){
  int numArgs=request.getNumArgs();
  if (numArgs < 2) {
    return ""String_Node_Str"".getBytes();
  }
  byte[] arg1=request.getArgs()[0];
  String arg2=new String(request.getArgs()[1]);
  if (arg1 == null || arg2 == null) {
    return ""String_Node_Str"".getBytes();
  }
  if (arg1.length == 3) {
    if ((arg1[0] == 'J' || arg1[0] == 'j') && (arg1[1] == 'V' || arg1[1] == 'v') && (arg1[2] == 'M' || arg1[2] == 'm')) {
      StringBuffer cmdBuffer=new StringBuffer();
      if (JavaUtils.isLinux())       cmdBuffer.append(JAVA_BIN_PATH);
      if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid());
        return encode(getOS_JVM_INFO(cmdBuffer.toString()));
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid());
        return encode(getOS_JVM_INFO(cmdBuffer.toString()));
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid());
        return encode(getOS_JVM_INFO(cmdBuffer.toString()));
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid());
        return encode(getOS_JVM_INFO(cmdBuffer.toString()));
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        String cmd=""String_Node_Str"" + JavaUtils.process_pid() + ""String_Node_Str"";
        List<String> line=new ArrayList<String>();
        try {
          line.add(ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",cmd));
        }
 catch (        IOException e) {
          line.add(e.getMessage());
        }
        return encode(line);
      }
    }
 else     if ((arg1[0] == 'U' || arg1[0] == 'u') && (arg1[1] == 'S' || arg1[1] == 's') && (arg1[2] == 'E' || arg1[2] == 'e')) {
      try {
        int poolId=Integer.parseInt(arg2);
        AbstractPool pool=RedisEngineCtx.INSTANCE().getPoolMap().get(poolId);
        if (pool == null) {
          return ""String_Node_Str"".getBytes();
        }
 else {
          int poolType=pool.getType();
          frontCon.getUserCfg().setUsePool(poolId,poolType);
          return ""String_Node_Str"".getBytes();
        }
      }
 catch (      NumberFormatException e) {
        return ""String_Node_Str"".getBytes();
      }
    }
  }
 else   if (arg1.length == 4) {
    if ((arg1[0] == 'S' || arg1[0] == 's') && (arg1[1] == 'H' || arg1[1] == 'h') && (arg1[2] == 'O' || arg1[2] == 'o')&& (arg1[3] == 'W' || arg1[3] == 'w')) {
      if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        AccessStatInfoResult result=StatUtil.getTotalAccessStatInfo().get(StatUtil.STAT_KEY);
        if (result != null) {
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(""String_Node_Str"").append(result.totalCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.slowCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.maxCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.minCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.avgCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.waitSlowCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.procTime).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.waitTime).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.created);
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<Object> lines=new ArrayList<Object>();
        long sum=0;
        Set<Entry<String,Command>> entrys=StatUtil.getCommandCountMap().entrySet();
        for (        Entry<String,Command> entry : entrys) {
          Command parent=entry.getValue();
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(parent.cmd).append(""String_Node_Str"").append(parent.count.get());
          if (parent.childs != null) {
            List<String> list=new ArrayList<String>();
            list.add(sBuffer.toString());
            for (            Entry<String,Command> childEntry : parent.childs.entrySet()) {
              Command child=childEntry.getValue();
              StringBuffer sb=new StringBuffer();
              sb.append(""String_Node_Str"").append(child.cmd).append(""String_Node_Str"").append(child.count.get());
              list.add(sb.toString());
            }
            lines.add(list);
          }
 else {
            lines.add(sBuffer.toString());
          }
          sum+=parent.count.get();
        }
        StringBuffer sBuffer=new StringBuffer();
        sBuffer.append(""String_Node_Str"").append(""String_Node_Str"").append(sum);
        lines.add(sBuffer.toString());
        return encodeObject(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer title=new StringBuffer();
        title.append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"");
        lines.add(title.toString());
        Set<Entry<String,UserCommand>> entrys=StatUtil.getUserCommandCountMap().entrySet();
        for (        Entry<String,UserCommand> entry : entrys) {
          UserCommand userCommand=entry.getValue();
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(userCommand.user).append(""String_Node_Str"").append(userCommand.readComandCount.get()).append(""String_Node_Str"").append(userCommand.writeCommandCount.get()).append(""String_Node_Str"").append(userCommand.readComandCount.get() + userCommand.writeCommandCount.get());
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") && numArgs == 3) {
        String user=new String(request.getArgs()[2]);
        List<String> lines=new ArrayList<String>();
        StringBuffer title=new StringBuffer();
        title.append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"");
        lines.add(title.toString());
        int sum=0;
        ConcurrentHashMap<String,UserCommand> userCommandMap=StatUtil.getUserCommandCountMap();
        UserCommand userCommand=userCommandMap.get(user);
        if (userCommand != null) {
          for (          Entry<String,AtomicLong> entry : userCommand.commandCount.entrySet()) {
            StringBuffer sBuffer=new StringBuffer();
            sBuffer.append(user).append(""String_Node_Str"").append(entry.getKey()).append(""String_Node_Str"").append(entry.getValue().get());
            lines.add(sBuffer.toString());
          }
        }
        StringBuffer end=new StringBuffer();
        end.append(""String_Node_Str"").append(""String_Node_Str"").append(sum);
        lines.add(end.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        lines.add(Versions.SERVER_VERSION);
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        if (JavaUtils.isLinux()) {
          StringBuffer cmdBuffer=new StringBuffer();
          cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid()).append(""String_Node_Str"");
          String response;
          try {
            response=ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",cmdBuffer.toString());
            lines.add(response);
          }
 catch (          IOException e) {
            LOGGER.error(""String_Node_Str"",e);
            lines.add(""String_Node_Str"");
          }
        }
 else {
          lines.add(""String_Node_Str"");
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        lines.add(""String_Node_Str"" + JavaUtils.bytesToString2(Math.round(JavaUtils.getMemUsage())));
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        int frontSize=0;
        int backendSize=0;
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisFrontConnection) {
            frontSize++;
          }
 else {
            backendSize++;
          }
        }
        StringBuffer sBuffer=new StringBuffer();
        sBuffer.append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"").append(frontSize).append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"").append(backendSize).append(""String_Node_Str"");
        return sBuffer.toString().getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        Map<String,Integer> userMap=new HashMap<String,Integer>();
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisFrontConnection) {
            userMap.put(((RedisFrontConnection)c).getPassword(),1 + (userMap.get(((RedisFrontConnection)c).getPassword()) == null ? 0 : userMap.get(((RedisFrontConnection)c).getPassword())));
          }
        }
        StringBuffer sBuffer=new StringBuffer();
        sBuffer.append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"");
        Iterator<Entry<String,Integer>> users=userMap.entrySet().iterator();
        while (users.hasNext()) {
          sBuffer.append(""String_Node_Str"");
          Entry<String,Integer> en=users.next();
          sBuffer.append(en.getKey());
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(en.getValue());
        }
        sBuffer.append(""String_Node_Str"");
        return sBuffer.toString().getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        ConcurrentHashMap<String,AccessStatInfoResult> results=StatUtil.getTotalAccessStatInfo();
        for (        Map.Entry<String,AccessStatInfoResult> entry : results.entrySet()) {
          AccessStatInfoResult result=entry.getValue();
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(""String_Node_Str"").append(result.key).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.totalCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.slowCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.maxCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.minCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.avgCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.procTime).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netInBytes[1]).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netInBytes[2]).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netInBytes[3]).append(""String_Node_Str"").append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netOutBytes[1]).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netOutBytes[2]).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netOutBytes[3]).append(""String_Node_Str"").append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.created);
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisFrontConnection) {
            lines.add(c.toString());
          }
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        BufferPool bufferPool=NetSystem.getInstance().getBufferPool();
        long usedBufferSize=bufferPool.getUsedBufferSize().get();
        long maxBufferSize=bufferPool.getMaxBufferSize();
        long minBufferSize=bufferPool.getMinBufferSize();
        long sharedOptsCount=bufferPool.getSharedOptsCount();
        int capacity=0;
        if (bufferPool instanceof BucketBufferPool) {
          BucketBufferPool p=(BucketBufferPool)bufferPool;
          AbstractBucket[] buckets=p.buckets();
          for (          AbstractBucket b : buckets) {
            capacity+=b.getCount();
          }
          int bucketLen=buckets.length;
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(capacity).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(minBufferSize).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(maxBufferSize).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(usedBufferSize).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(bucketLen).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(sharedOptsCount).append(""String_Node_Str"");
          return sBuffer.toString().getBytes();
        }
 else         if (bufferPool instanceof PageBufferPool) {
          List<String> lines=new ArrayList<String>();
          ConcurrentHashMap<Long,Long> bufferpoolUsageMap=bufferPool.getNetDirectMemoryUsage();
          long usedforNetwork=0;
          for (          Map.Entry<Long,Long> entry : bufferpoolUsageMap.entrySet()) {
            long value=entry.getValue();
            lines.add(""String_Node_Str"" + entry.getKey() + ""String_Node_Str""+ (value > 0 ? JavaUtils.bytesToString2(value) : ""String_Node_Str""));
            usedforNetwork=usedforNetwork + value;
          }
          lines.add(""String_Node_Str"" + JavaUtils.bytesToString2(minBufferSize));
          lines.add(""String_Node_Str"" + JavaUtils.bytesToString2(maxBufferSize));
          lines.add(""String_Node_Str"" + JavaUtils.bytesToString2(usedforNetwork));
          return encode(lines);
        }
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        BufferPool bufferPool=NetSystem.getInstance().getBufferPool();
        if (bufferPool instanceof BucketBufferPool) {
          BucketBufferPool p=(BucketBufferPool)bufferPool;
          AbstractBucket[] buckets=p.buckets();
          for (          AbstractBucket b : buckets) {
            StringBuffer sBuffer=new StringBuffer();
            sBuffer.append(""String_Node_Str"").append(b.getChunkSize()).append(""String_Node_Str"");
            sBuffer.append(""String_Node_Str"").append(b.getQueueSize()).append(""String_Node_Str"");
            sBuffer.append(""String_Node_Str"").append(b.getCount()).append(""String_Node_Str"");
            sBuffer.append(""String_Node_Str"").append(b.getUsedCount()).append(""String_Node_Str"");
            sBuffer.append(""String_Node_Str"").append(b.getShared());
            lines.add(sBuffer.toString());
          }
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        for (        BigKey bigkey : StatUtil.getBigKeys()) {
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(bigkey.lastCmd).append(""String_Node_Str"");
          sBuffer.append(bigkey.key).append(""String_Node_Str"");
          sBuffer.append(bigkey.size).append(""String_Node_Str"");
          sBuffer.append(bigkey.count.get());
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        BigKeyCollector bkc=StatUtil.getBigKeyCollector();
        StringBuffer sBuffer=new StringBuffer();
        sBuffer.append(""String_Node_Str"").append(bkc.getBigKeyCount()).append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"").append(bkc.getBypassBigKeyCount());
        lines.add(sBuffer.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        Map<String,AtomicInteger> poolConnections=new HashMap<String,AtomicInteger>();
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisBackendConnection) {
            String poolName=((RedisBackendConnection)c).getPhysicalNode().getPoolName();
            AtomicInteger poolConnCount=poolConnections.get(poolName);
            if (poolConnCount == null) {
              poolConnections.put(poolName,new AtomicInteger(1));
            }
 else {
              poolConnCount.incrementAndGet();
            }
            lines.add(c.toString());
          }
 else           if (c instanceof KafkaBackendConnection) {
            String poolName=((KafkaBackendConnection)c).getPhysicalNode().getPoolName();
            AtomicInteger poolConnCount=poolConnections.get(poolName);
            if (poolConnCount == null) {
              poolConnections.put(poolName,new AtomicInteger(1));
            }
 else {
              poolConnCount.incrementAndGet();
            }
            lines.add(c.toString());
          }
        }
        StringBuffer sb=new StringBuffer();
        for (        Map.Entry<String,AtomicInteger> entry : poolConnections.entrySet()) {
          sb.append(entry.getKey()).append(""String_Node_Str"").append(entry.getValue().get()).append(""String_Node_Str"");
        }
        lines.add(sb.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") && numArgs == 3) {
        List<String> lines=new ArrayList<String>();
        long minStartupTime=-1;
        long totalNetInBytes=0;
        long totalNetOutBytes=0;
        String poolName=new String(request.getArgs()[2]);
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisBackendConnection) {
            if (((RedisBackendConnection)c).getPhysicalNode().getPoolName().equals(poolName)) {
              StringBuffer sb=new StringBuffer();
              sb.append(""String_Node_Str"").append(c.getId()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(c.getStartupTime()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(c.getNetInBytes()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(c.getNetOutBytes()).append(""String_Node_Str"");
              lines.add(sb.toString());
              minStartupTime=minStartupTime < 0 ? c.getStartupTime() : Math.min(minStartupTime,c.getStartupTime());
              totalNetInBytes+=c.getNetInBytes();
              totalNetOutBytes+=c.getNetOutBytes();
            }
          }
        }
        StringBuffer end=new StringBuffer();
        end.append(""String_Node_Str"").append(minStartupTime).append(""String_Node_Str"");
        end.append(""String_Node_Str"").append(totalNetInBytes).append(""String_Node_Str"");
        end.append(""String_Node_Str"").append(totalNetOutBytes).append(""String_Node_Str"");
        lines.add(end.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") || arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        AccessStatInfoResult result=StatUtil.getTotalAccessStatInfo().get(StatUtil.STAT_KEY);
        if (result != null) {
          StringBuffer line0=new StringBuffer();
          line0.append(""String_Node_Str"").append(""String_Node_Str"");
          line0.append(""String_Node_Str"").append(""String_Node_Str"");
          line0.append(""String_Node_Str"").append(""String_Node_Str"");
          line0.append(""String_Node_Str"").append(""String_Node_Str"");
          line0.append(""String_Node_Str"");
          StringBuffer line1=new StringBuffer();
          line1.append(""String_Node_Str"").append(""String_Node_Str"");
          line1.append(result.netInBytes[0]).append(""String_Node_Str"");
          line1.append(result.netInBytes[1]).append(""String_Node_Str"");
          line1.append(result.netInBytes[2]).append(""String_Node_Str"");
          line1.append(result.netInBytes[3]);
          StringBuffer line2=new StringBuffer();
          line2.append(""String_Node_Str"").append(""String_Node_Str"");
          line2.append(result.netOutBytes[0]).append(""String_Node_Str"");
          line2.append(result.netOutBytes[1]).append(""String_Node_Str"");
          line2.append(result.netOutBytes[2]).append(""String_Node_Str"");
          line2.append(result.netOutBytes[3]);
          StringBuffer line3=new StringBuffer();
          line3.append(result.created);
          lines.add(line0.toString());
          lines.add(line1.toString());
          lines.add(line2.toString());
          lines.add(line3.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        for (        Map.Entry<String,AccessStatInfoResult> entry : StatUtil.getTotalAccessStatInfo().entrySet()) {
          if (!StatUtil.STAT_KEY.equals(entry.getKey())) {
            AccessStatInfoResult result=entry.getValue();
            StringBuffer line1=new StringBuffer();
            line1.append(result.key).append(""String_Node_Str"");
            line1.append(""String_Node_Str"").append(""String_Node_Str"");
            line1.append(result.netInBytes[0]).append(""String_Node_Str"");
            line1.append(result.netInBytes[1]).append(""String_Node_Str"");
            line1.append(result.netInBytes[2]).append(""String_Node_Str"");
            line1.append(result.netInBytes[3]);
            StringBuffer line2=new StringBuffer();
            line2.append(result.key).append(""String_Node_Str"");
            line2.append(""String_Node_Str"").append(""String_Node_Str"");
            line2.append(result.netOutBytes[0]).append(""String_Node_Str"");
            line2.append(result.netOutBytes[1]).append(""String_Node_Str"");
            line2.append(result.netOutBytes[2]).append(""String_Node_Str"");
            line2.append(result.netOutBytes[3]);
            StringBuffer line3=new StringBuffer();
            line3.append(result.created);
            lines.add(line1.toString());
            lines.add(line2.toString());
            lines.add(line3.toString());
          }
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        long totalNetIn=0;
        long totalNetOut=0;
        for (        Map.Entry<String,UserFlow> entry : StatUtil.getUserFlowMap().entrySet()) {
          if (!StatUtil.STAT_KEY.equals(entry.getKey())) {
            StringBuffer sb=new StringBuffer();
            UserFlow userNetIo=entry.getValue();
            sb.append(userNetIo.password).append(""String_Node_Str"");
            sb.append(JavaUtils.bytesToString2(userNetIo.netIn.get())).append(""String_Node_Str"");
            sb.append(JavaUtils.bytesToString2(userNetIo.netOut.get()));
            totalNetIn=totalNetIn + userNetIo.netIn.get();
            totalNetOut=totalNetOut + userNetIo.netOut.get();
            lines.add(sb.toString());
          }
        }
        StringBuffer total=new StringBuffer();
        total.append(""String_Node_Str"").append(""String_Node_Str"");
        total.append(JavaUtils.bytesToString2(totalNetIn)).append(""String_Node_Str"");
        total.append(JavaUtils.bytesToString2(totalNetOut));
        lines.add(total.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=showLog(request,""String_Node_Str"");
        return encode2(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=showLog(request,""String_Node_Str"");
        return encode2(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=showLog(request,""String_Node_Str"");
        return encode2(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=showLog(request,""String_Node_Str"");
        return encode2(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> ret=new ArrayList<String>();
        try {
          String resp=ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"");
          StringBuilder sb=new StringBuilder();
          sb.append(resp);
          sb.append(""String_Node_Str"");
          String[] lines=sb.toString().split(""String_Node_Str"");
          ret.add(""String_Node_Str"");
          for (int i=1; i < lines.length; i++) {
            if (lines[i].equals(""String_Node_Str""))             continue;
            ret.add(lines[i]);
          }
        }
 catch (        IOException e) {
          LOGGER.error(""String_Node_Str"",e);
          ret.add(""String_Node_Str"");
        }
        return encode2(ret);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> ret=new ArrayList<String>();
        try {
          String cmd1=ShellUtils.osType == ShellUtils.OSType.OS_TYPE_MAC ? ""String_Node_Str"" : ""String_Node_Str"";
          String cmd2=ShellUtils.osType == ShellUtils.OSType.OS_TYPE_MAC ? ""String_Node_Str"" : ""String_Node_Str"";
          String iostatOut=ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",cmd1);
          String vmstatOut=ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",cmd2);
          StringBuilder sb=new StringBuilder();
          sb.append(iostatOut);
          sb.append(""String_Node_Str"");
          sb.append(""String_Node_Str"");
          sb.append(vmstatOut);
          String[] lines=sb.toString().split(""String_Node_Str"");
          ret.add(""String_Node_Str"");
          for (int i=1; i < lines.length; i++) {
            if (lines[i].equals(""String_Node_Str""))             continue;
            ret.add(lines[i]);
          }
        }
 catch (        IOException e) {
          LOGGER.error(""String_Node_Str"",e);
          ret.add(""String_Node_Str"");
        }
        return encode2(ret);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<Object> list=new ArrayList<Object>();
        Map<Integer,AbstractPool> pools=RedisEngineCtx.INSTANCE().getPoolMap();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        list.add(titleLine.toString());
        for (        AbstractPool pool : pools.values()) {
          if (pool instanceof RedisStandalonePool) {
            StringBuffer sb=new StringBuffer();
            RedisStandalonePool redisStandalonePool=(RedisStandalonePool)pool;
            PhysicalNode physicalNode=redisStandalonePool.getPhysicalNode();
            if (physicalNode == null)             continue;
            sb.append(""String_Node_Str"");
            sb.append(redisStandalonePool.getId()).append(""String_Node_Str"");
            sb.append(physicalNode.getPoolName()).append(""String_Node_Str"");
            sb.append(""String_Node_Str"").append(""String_Node_Str"");
            sb.append(physicalNode.getName()).append(""String_Node_Str"");
            sb.append(physicalNode.getMinCon()).append(""String_Node_Str"");
            sb.append(physicalNode.getMaxCon()).append(""String_Node_Str"");
            sb.append(physicalNode.getIdleCount()).append(""String_Node_Str"");
            sb.append(physicalNode.getActiveCount());
            list.add(sb.toString());
          }
 else           if (pool instanceof RedisClusterPool) {
            RedisClusterPool redisClusterPool=(RedisClusterPool)pool;
            Map<String,ClusterNode> masters=redisClusterPool.getMasters();
            List<String> clusterInfo=new ArrayList<String>();
            for (            ClusterNode clusterNode : masters.values()) {
              PhysicalNode physicalNode=clusterNode.getPhysicalNode();
              StringBuffer sb=new StringBuffer();
              sb.append(redisClusterPool.getId()).append(""String_Node_Str"");
              sb.append(physicalNode.getPoolName()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(""String_Node_Str"");
              sb.append(physicalNode.getName()).append(""String_Node_Str"");
              sb.append(physicalNode.getMinCon()).append(""String_Node_Str"");
              sb.append(physicalNode.getMaxCon()).append(""String_Node_Str"");
              sb.append(physicalNode.getIdleCount()).append(""String_Node_Str"");
              sb.append(physicalNode.getActiveCount()).append(""String_Node_Str"");
              ;
              sb.append(!clusterNode.isFail());
              clusterInfo.add(sb.toString());
              sb.append(clusterNode.getConnectInfo());
            }
            list.add(clusterInfo);
          }
 else           if (pool instanceof KafkaPool) {
            KafkaPool kafkaPool=(KafkaPool)pool;
            Map<Integer,PhysicalNode> physicalNodes=kafkaPool.getPhysicalNodes();
            for (            PhysicalNode physicalNode : physicalNodes.values()) {
              StringBuffer sb=new StringBuffer();
              sb.append(""String_Node_Str"");
              sb.append(kafkaPool.getId()).append(""String_Node_Str"");
              sb.append(physicalNode.getPoolName()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(""String_Node_Str"");
              sb.append(physicalNode.getName()).append(""String_Node_Str"");
              sb.append(physicalNode.getMinCon()).append(""String_Node_Str"");
              sb.append(physicalNode.getMaxCon()).append(""String_Node_Str"");
              sb.append(physicalNode.getIdleCount()).append(""String_Node_Str"");
              sb.append(physicalNode.getActiveCount());
              list.add(sb.toString());
            }
          }
        }
        return encodeObject(list);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        Collection<Entry<String,AtomicLong>> entrys=StatUtil.getCommandProcTimeMap().entrySet();
        List<String> lines=new ArrayList<String>();
        for (        Entry<String,AtomicLong> entry : entrys) {
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(entry.getKey()).append(""String_Node_Str"").append(entry.getValue().get());
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        Collection<Entry<String,AtomicLong>> entrys=StatUtil.getCommandWaitTimeMap().entrySet();
        List<String> lines=new ArrayList<String>();
        for (        Entry<String,AtomicLong> entry : entrys) {
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(entry.getKey()).append(""String_Node_Str"").append(entry.getValue().get());
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        for (        BigLength bigLength : StatUtil.getBigLengthMap().values()) {
          StringBuffer line1=new StringBuffer();
          line1.append(bigLength.cmd).append(""String_Node_Str"");
          line1.append(bigLength.key).append(""String_Node_Str"");
          line1.append(bigLength.length.get()).append(""String_Node_Str"");
          line1.append(bigLength.count_1k.get()).append(""String_Node_Str"");
          line1.append(bigLength.count_10k.get());
          lines.add(line1.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        for (        SlowKey slowKey : StatUtil.getSlowKey()) {
          StringBuffer line1=new StringBuffer();
          line1.append(slowKey.cmd).append(""String_Node_Str"");
          line1.append(slowKey.key).append(""String_Node_Str"");
          line1.append(slowKey.count);
          lines.add(line1.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") && (numArgs == 3 || numArgs == 2)) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        if (numArgs == 2) {
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"");
        }
 else {
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"");
        }
        lines.add(titleLine.toString());
        final Map<Integer,PoolCfg> poolCfgMap=RedisEngineCtx.INSTANCE().getPoolCfgMap();
        for (        Entry<Integer,PoolCfg> poolEntry : poolCfgMap.entrySet()) {
          PoolCfg poolCfg=poolEntry.getValue();
          if (poolCfg instanceof KafkaPoolCfg) {
            Map<String,TopicCfg> kafkaMap=((KafkaPoolCfg)poolCfg).getTopicCfgMap();
            if (numArgs == 2) {
              for (              Entry<String,TopicCfg> kafkaEntry : kafkaMap.entrySet()) {
                TopicCfg kafkaCfg=kafkaEntry.getValue();
                StringBuffer line=new StringBuffer();
                line.append(kafkaCfg.getName()).append(""String_Node_Str"");
                line.append(kafkaCfg.getPoolId()).append(""String_Node_Str"");
                line.append(kafkaCfg.getPartitions()).append(""String_Node_Str"");
                line.append(kafkaCfg.getReplicationFactor()).append(""String_Node_Str"");
                line.append(kafkaCfg.getProducers()).append(""String_Node_Str"");
                line.append(kafkaCfg.getConsumers());
                lines.add(line.toString());
              }
            }
 else {
              String topic=new String(request.getArgs()[2]);
              TopicCfg kafkaCfg=kafkaMap.get(topic);
              if (kafkaCfg != null) {
                for (                BrokerPartition partition : kafkaCfg.getRunningInfo().getPartitions().values()) {
                  int pt=partition.getPartition();
                  StringBuffer line=new StringBuffer();
                  line.append(kafkaCfg.getName()).append(""String_Node_Str"");
                  line.append(partition.getLeader().getHost()).append(partition.getLeader().getPort()).append(""String_Node_Str"");
                  line.append(pt).append(""String_Node_Str"");
                  line.append(partition.getLogStartOffset()).append(""String_Node_Str"");
                  line.append(partition.getProducerOffset()).append(""String_Node_Str"");
                  for (                  ConsumerOffset consumerOffset : partition.getConsumerOffsets().values()) {
                    line.append(consumerOffset.getConsumer());
                    line.append(""String_Node_Str"");
                    line.append(consumerOffset.getCurrentOffset());
                    line.append(""String_Node_Str"");
                  }
                  lines.add(line.toString());
                }
              }
            }
          }
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") && numArgs == 2) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        NetFlowGuard nfg=RedisEngineCtx.INSTANCE().getNetflowGuard();
        Map<String,Guard> map=nfg.getGuardMap();
        for (        Entry<String,Guard> entry : map.entrySet()) {
          Guard guard=entry.getValue();
          StringBuffer line=new StringBuffer();
          line.append(entry.getKey()).append(""String_Node_Str"");
          line.append(guard.getPerSecondMaxSize()).append(""String_Node_Str"");
          line.append(guard.getRequestMaxSize()).append(""String_Node_Str"");
          line.append(guard.getHistogram());
          lines.add(line.toString());
        }
        return encode(lines);
      }
    }
  }
 else   if (arg1.length == 6) {
    if ((arg1[0] == 'R' || arg1[0] == 'r') && (arg1[1] == 'E' || arg1[1] == 'e') && (arg1[2] == 'L' || arg1[2] == 'l')&& (arg1[3] == 'O' || arg1[3] == 'o')&& (arg1[4] == 'A' || arg1[4] == 'a')&& (arg1[5] == 'D' || arg1[5] == 'd')) {
      if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        byte[] buff=RedisEngineCtx.INSTANCE().reloadAll();
        return buff;
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        byte[] buff=RedisEngineCtx.INSTANCE().reloadUser();
        return buff;
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        byte[] buff=RedisEngineCtx.INSTANCE().reloadNetflow();
        return buff;
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisFrontConnection) {
            LOGGER.info(""String_Node_Str"",c);
            c.close(""String_Node_Str"");
          }
        }
        return ""String_Node_Str"".getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        JAVA_BIN_PATH=new String(request.getArgs()[2]);
        return ""String_Node_Str"".getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        try {
          Map<Integer,PoolCfg> poolCfgMap=RedisEngineCtx.INSTANCE().getPoolCfgMap();
          for (          PoolCfg poolCfg : poolCfgMap.values()) {
            if (poolCfg instanceof KafkaPoolCfg)             poolCfg.reloadExtraCfg();
          }
        }
 catch (        Exception e) {
          LOGGER.error(""String_Node_Str"",e);
          StringBuffer sb=new StringBuffer();
          sb.append(""String_Node_Str"").append(e.getMessage()).append(""String_Node_Str"");
          return sb.toString().getBytes();
        }
        return ""String_Node_Str"".getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        byte[] buff=BypassService.INSTANCE().reload();
        return buff;
      }
    }
    if ((arg1[0] == 'R' || arg1[0] == 'r') && (arg1[1] == 'E' || arg1[1] == 'e') && (arg1[2] == 'P' || arg1[2] == 'p')&& (arg1[3] == 'A' || arg1[3] == 'a')&& (arg1[4] == 'I' || arg1[4] == 'i')&& (arg1[5] == 'R' || arg1[5] == 'r')) {
      if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        String password=new String(request.getArgs()[2]);
        String topicName=new String(request.getArgs()[3]);
        long offset=Long.parseLong(new String(request.getArgs()[4]));
        UserCfg userCfg=RedisEngineCtx.INSTANCE().getUserMap().get(password);
        if (userCfg != null) {
          int poolId=userCfg.getPoolId();
          KafkaPoolCfg kafkaPoolCfg=(KafkaPoolCfg)RedisEngineCtx.INSTANCE().getPoolCfgMap().get(poolId);
          if (kafkaPoolCfg != null) {
            TopicCfg topicCfg=kafkaPoolCfg.getTopicCfgMap().get(topicName);
            if (topicCfg != null) {
              for (int partition=0; partition < topicCfg.getPartitions(); partition++) {
                boolean isRepair=BrokerOffsetService.INSTANCE().repairOffset(password,topicCfg,partition,offset);
                if (!isRepair) {
                  return (""String_Node_Str"" + partition + ""String_Node_Str"").getBytes();
                }
              }
            }
 else {
              return (""String_Node_Str"" + topicName + ""String_Node_Str"").getBytes();
            }
            return ""String_Node_Str"".getBytes();
          }
 else {
            return (""String_Node_Str"" + poolId + ""String_Node_Str"").getBytes();
          }
        }
 else {
          return (""String_Node_Str"" + password + ""String_Node_Str"").getBytes();
        }
      }
    }
  }
 else   if (arg1.length == 7) {
    if ((arg1[0] == 'C' || arg1[0] == 'c') && (arg1[1] == 'L' || arg1[1] == 'l') && (arg1[2] == 'U' || arg1[2] == 'u')&& (arg1[3] == 'S' || arg1[3] == 's')&& (arg1[4] == 'T' || arg1[4] == 't')&& (arg1[5] == 'E' || arg1[5] == 'e')&& (arg1[6] == 'R' || arg1[6] == 'r')) {
      AbstractPool pool=RedisEngineCtx.INSTANCE().getPoolMap().get(frontCon.getUserCfg().getPoolId());
      if (pool.getType() != 1) {
        return ""String_Node_Str"".getBytes();
      }
      PhysicalNode pysicalNode=((RedisClusterPool)pool).getPhysicalNodeBySlot(0);
      if (pysicalNode == null) {
        return ""String_Node_Str"".getBytes();
      }
      try {
        RedisBackendConnection backendCon=(RedisBackendConnection)pysicalNode.getConnection(new DirectTransTofrontCallBack(),frontCon);
        if (backendCon == null) {
          frontCon.writeErrMessage(""String_Node_Str"");
        }
 else {
          backendCon.write(request.encode());
        }
        return null;
      }
 catch (      IOException e) {
        LOGGER.error(""String_Node_Str"",e);
      }
    }
  }
  return ""String_Node_Str"".getBytes();
}","/** 
 *  ---------------------------------------- USE [POOL_ID] RELOAD USER RELOAD ALL RELOAD FRONT RELOAD PATH RELOAD KAFKA RELOAD BIGKEY RELOAD NETFLOW JVM  JAVA_HOME  ---------------------------------------- JVM JSTACK JVM JSTAT JVM JMAP_HISTO JVM JMAP_HEAP JVM PS SHOW USER SHOW USER_NET_IO  SHOW CPU SHOW MEM SHOW QPS SHOW CONN SHOW USER_CONN SHOW BUFFER SHOW BIGKEY SHOW BIGKEY_COUNT SHOW BIGLENGTH SHOW SLOWKEY SHOW CMD SHOW USER_CMD SHOW USER_CMD_DETAIL USER SHOW VER SHOW NET_IO  SHOW NETBYTES SHOW VM SHOW POOL SHOW COST SHOW WAIT_COST SHOW USER_DAY_NET_IO SHOW POOL_NET_IO POOLNAME SHOW TOPIC SHOW LOG_ERROR SHOW LOG_WARN SHOW LOG_INFO SHOW LOG_DEBUG
 */
public static byte[] execute(final RedisRequest request,RedisFrontConnection frontCon){
  int numArgs=request.getNumArgs();
  if (numArgs < 2) {
    return ""String_Node_Str"".getBytes();
  }
  byte[] arg1=request.getArgs()[0];
  String arg2=new String(request.getArgs()[1]);
  if (arg1 == null || arg2 == null) {
    return ""String_Node_Str"".getBytes();
  }
  if (arg1.length == 3) {
    if ((arg1[0] == 'J' || arg1[0] == 'j') && (arg1[1] == 'V' || arg1[1] == 'v') && (arg1[2] == 'M' || arg1[2] == 'm')) {
      StringBuffer cmdBuffer=new StringBuffer();
      if (JavaUtils.isLinux())       cmdBuffer.append(JAVA_BIN_PATH);
      if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid());
        return encode(getOS_JVM_INFO(cmdBuffer.toString()));
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid());
        return encode(getOS_JVM_INFO(cmdBuffer.toString()));
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid());
        return encode(getOS_JVM_INFO(cmdBuffer.toString()));
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid());
        return encode(getOS_JVM_INFO(cmdBuffer.toString()));
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        String cmd=""String_Node_Str"" + JavaUtils.process_pid() + ""String_Node_Str"";
        List<String> line=new ArrayList<String>();
        try {
          line.add(ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",cmd));
        }
 catch (        IOException e) {
          line.add(e.getMessage());
        }
        return encode(line);
      }
    }
 else     if ((arg1[0] == 'U' || arg1[0] == 'u') && (arg1[1] == 'S' || arg1[1] == 's') && (arg1[2] == 'E' || arg1[2] == 'e')) {
      try {
        int poolId=Integer.parseInt(arg2);
        AbstractPool pool=RedisEngineCtx.INSTANCE().getPoolMap().get(poolId);
        if (pool == null) {
          return ""String_Node_Str"".getBytes();
        }
 else {
          int poolType=pool.getType();
          frontCon.getUserCfg().setUsePool(poolId,poolType);
          return ""String_Node_Str"".getBytes();
        }
      }
 catch (      NumberFormatException e) {
        return ""String_Node_Str"".getBytes();
      }
    }
  }
 else   if (arg1.length == 4) {
    if ((arg1[0] == 'S' || arg1[0] == 's') && (arg1[1] == 'H' || arg1[1] == 'h') && (arg1[2] == 'O' || arg1[2] == 'o')&& (arg1[3] == 'W' || arg1[3] == 'w')) {
      if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        AccessStatInfoResult result=StatUtil.getTotalAccessStatInfo().get(StatUtil.STAT_KEY);
        if (result != null) {
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(""String_Node_Str"").append(result.totalCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.slowCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.maxCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.minCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.avgCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.waitSlowCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.procTime).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.waitTime).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.created);
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<Object> lines=new ArrayList<Object>();
        long sum=0;
        Set<Entry<String,Command>> entrys=StatUtil.getCommandCountMap().entrySet();
        for (        Entry<String,Command> entry : entrys) {
          Command parent=entry.getValue();
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(parent.cmd).append(""String_Node_Str"").append(parent.count.get());
          if (parent.childs != null) {
            List<String> list=new ArrayList<String>();
            list.add(sBuffer.toString());
            for (            Entry<String,Command> childEntry : parent.childs.entrySet()) {
              Command child=childEntry.getValue();
              StringBuffer sb=new StringBuffer();
              sb.append(""String_Node_Str"").append(child.cmd).append(""String_Node_Str"").append(child.count.get());
              list.add(sb.toString());
            }
            lines.add(list);
          }
 else {
            lines.add(sBuffer.toString());
          }
          sum+=parent.count.get();
        }
        StringBuffer sBuffer=new StringBuffer();
        sBuffer.append(""String_Node_Str"").append(""String_Node_Str"").append(sum);
        lines.add(sBuffer.toString());
        return encodeObject(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer title=new StringBuffer();
        title.append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"");
        lines.add(title.toString());
        Set<Entry<String,UserCommand>> entrys=StatUtil.getUserCommandCountMap().entrySet();
        for (        Entry<String,UserCommand> entry : entrys) {
          UserCommand userCommand=entry.getValue();
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(userCommand.user).append(""String_Node_Str"").append(userCommand.readComandCount.get()).append(""String_Node_Str"").append(userCommand.writeCommandCount.get()).append(""String_Node_Str"").append(userCommand.readComandCount.get() + userCommand.writeCommandCount.get());
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") && numArgs == 3) {
        String user=new String(request.getArgs()[2]);
        List<String> lines=new ArrayList<String>();
        StringBuffer title=new StringBuffer();
        title.append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"");
        lines.add(title.toString());
        int sum=0;
        ConcurrentHashMap<String,UserCommand> userCommandMap=StatUtil.getUserCommandCountMap();
        UserCommand userCommand=userCommandMap.get(user);
        if (userCommand != null) {
          for (          Entry<String,AtomicLong> entry : userCommand.commandCount.entrySet()) {
            StringBuffer sBuffer=new StringBuffer();
            sBuffer.append(user).append(""String_Node_Str"").append(entry.getKey()).append(""String_Node_Str"").append(entry.getValue().get());
            lines.add(sBuffer.toString());
          }
        }
        StringBuffer end=new StringBuffer();
        end.append(""String_Node_Str"").append(""String_Node_Str"").append(sum);
        lines.add(end.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        lines.add(Versions.SERVER_VERSION);
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        if (JavaUtils.isLinux()) {
          StringBuffer cmdBuffer=new StringBuffer();
          cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid()).append(""String_Node_Str"");
          String response;
          try {
            response=ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",cmdBuffer.toString());
            lines.add(response);
          }
 catch (          IOException e) {
            LOGGER.error(""String_Node_Str"",e);
            lines.add(""String_Node_Str"");
          }
        }
 else {
          lines.add(""String_Node_Str"");
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        lines.add(""String_Node_Str"" + JavaUtils.bytesToString2(Math.round(JavaUtils.getMemUsage())));
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        int frontSize=0;
        int backendSize=0;
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisFrontConnection) {
            frontSize++;
          }
 else {
            backendSize++;
          }
        }
        StringBuffer sBuffer=new StringBuffer();
        sBuffer.append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"").append(frontSize).append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"").append(backendSize).append(""String_Node_Str"");
        return sBuffer.toString().getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        Map<String,Integer> userMap=new HashMap<String,Integer>();
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisFrontConnection) {
            userMap.put(((RedisFrontConnection)c).getPassword(),1 + (userMap.get(((RedisFrontConnection)c).getPassword()) == null ? 0 : userMap.get(((RedisFrontConnection)c).getPassword())));
          }
        }
        StringBuffer sBuffer=new StringBuffer();
        sBuffer.append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"");
        Iterator<Entry<String,Integer>> users=userMap.entrySet().iterator();
        while (users.hasNext()) {
          sBuffer.append(""String_Node_Str"");
          Entry<String,Integer> en=users.next();
          sBuffer.append(en.getKey());
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(en.getValue());
        }
        sBuffer.append(""String_Node_Str"");
        return sBuffer.toString().getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        ConcurrentHashMap<String,AccessStatInfoResult> results=StatUtil.getTotalAccessStatInfo();
        for (        Map.Entry<String,AccessStatInfoResult> entry : results.entrySet()) {
          AccessStatInfoResult result=entry.getValue();
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(""String_Node_Str"").append(result.key).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.totalCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.slowCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.maxCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.minCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.avgCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.procTime).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netInBytes[1]).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netInBytes[2]).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netInBytes[3]).append(""String_Node_Str"").append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netOutBytes[1]).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netOutBytes[2]).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netOutBytes[3]).append(""String_Node_Str"").append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.created);
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisFrontConnection) {
            lines.add(c.toString());
          }
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        BufferPool bufferPool=NetSystem.getInstance().getBufferPool();
        long usedBufferSize=bufferPool.getUsedBufferSize().get();
        long maxBufferSize=bufferPool.getMaxBufferSize();
        long minBufferSize=bufferPool.getMinBufferSize();
        long sharedOptsCount=bufferPool.getSharedOptsCount();
        int capacity=0;
        if (bufferPool instanceof BucketBufferPool) {
          BucketBufferPool p=(BucketBufferPool)bufferPool;
          AbstractBucket[] buckets=p.buckets();
          for (          AbstractBucket b : buckets) {
            capacity+=b.getCount();
          }
          int bucketLen=buckets.length;
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(capacity).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(minBufferSize).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(maxBufferSize).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(usedBufferSize).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(bucketLen).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(sharedOptsCount).append(""String_Node_Str"");
          return sBuffer.toString().getBytes();
        }
 else         if (bufferPool instanceof PageBufferPool) {
          List<String> lines=new ArrayList<String>();
          ConcurrentHashMap<Long,Long> bufferpoolUsageMap=bufferPool.getNetDirectMemoryUsage();
          long usedforNetwork=0;
          for (          Map.Entry<Long,Long> entry : bufferpoolUsageMap.entrySet()) {
            long value=entry.getValue();
            lines.add(""String_Node_Str"" + entry.getKey() + ""String_Node_Str""+ (value > 0 ? JavaUtils.bytesToString2(value) : ""String_Node_Str""));
            usedforNetwork=usedforNetwork + value;
          }
          lines.add(""String_Node_Str"" + JavaUtils.bytesToString2(minBufferSize));
          lines.add(""String_Node_Str"" + JavaUtils.bytesToString2(maxBufferSize));
          lines.add(""String_Node_Str"" + JavaUtils.bytesToString2(usedforNetwork));
          return encode(lines);
        }
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        BufferPool bufferPool=NetSystem.getInstance().getBufferPool();
        if (bufferPool instanceof BucketBufferPool) {
          BucketBufferPool p=(BucketBufferPool)bufferPool;
          AbstractBucket[] buckets=p.buckets();
          for (          AbstractBucket b : buckets) {
            StringBuffer sBuffer=new StringBuffer();
            sBuffer.append(""String_Node_Str"").append(b.getChunkSize()).append(""String_Node_Str"");
            sBuffer.append(""String_Node_Str"").append(b.getQueueSize()).append(""String_Node_Str"");
            sBuffer.append(""String_Node_Str"").append(b.getCount()).append(""String_Node_Str"");
            sBuffer.append(""String_Node_Str"").append(b.getUsedCount()).append(""String_Node_Str"");
            sBuffer.append(""String_Node_Str"").append(b.getShared());
            lines.add(sBuffer.toString());
          }
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        for (        BigKey bigkey : StatUtil.getBigKeys()) {
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(bigkey.lastCmd).append(""String_Node_Str"");
          sBuffer.append(bigkey.key).append(""String_Node_Str"");
          sBuffer.append(bigkey.size).append(""String_Node_Str"");
          sBuffer.append(bigkey.count.get());
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        BigKeyCollector bkc=StatUtil.getBigKeyCollector();
        StringBuffer sBuffer=new StringBuffer();
        sBuffer.append(""String_Node_Str"").append(bkc.getBigKeyCount()).append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"").append(bkc.getBypassBigKeyCount());
        lines.add(sBuffer.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        Map<String,AtomicInteger> poolConnections=new HashMap<String,AtomicInteger>();
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisBackendConnection) {
            String poolName=((RedisBackendConnection)c).getPhysicalNode().getPoolName();
            AtomicInteger poolConnCount=poolConnections.get(poolName);
            if (poolConnCount == null) {
              poolConnections.put(poolName,new AtomicInteger(1));
            }
 else {
              poolConnCount.incrementAndGet();
            }
            lines.add(c.toString());
          }
 else           if (c instanceof KafkaBackendConnection) {
            String poolName=((KafkaBackendConnection)c).getPhysicalNode().getPoolName();
            AtomicInteger poolConnCount=poolConnections.get(poolName);
            if (poolConnCount == null) {
              poolConnections.put(poolName,new AtomicInteger(1));
            }
 else {
              poolConnCount.incrementAndGet();
            }
            lines.add(c.toString());
          }
        }
        StringBuffer sb=new StringBuffer();
        for (        Map.Entry<String,AtomicInteger> entry : poolConnections.entrySet()) {
          sb.append(entry.getKey()).append(""String_Node_Str"").append(entry.getValue().get()).append(""String_Node_Str"");
        }
        lines.add(sb.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") && numArgs == 3) {
        List<String> lines=new ArrayList<String>();
        long minStartupTime=-1;
        long totalNetInBytes=0;
        long totalNetOutBytes=0;
        String poolName=new String(request.getArgs()[2]);
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisBackendConnection) {
            if (((RedisBackendConnection)c).getPhysicalNode().getPoolName().equals(poolName)) {
              StringBuffer sb=new StringBuffer();
              sb.append(""String_Node_Str"").append(c.getId()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(c.getStartupTime()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(c.getNetInBytes()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(c.getNetOutBytes()).append(""String_Node_Str"");
              lines.add(sb.toString());
              minStartupTime=minStartupTime < 0 ? c.getStartupTime() : Math.min(minStartupTime,c.getStartupTime());
              totalNetInBytes+=c.getNetInBytes();
              totalNetOutBytes+=c.getNetOutBytes();
            }
          }
        }
        StringBuffer end=new StringBuffer();
        end.append(""String_Node_Str"").append(minStartupTime).append(""String_Node_Str"");
        end.append(""String_Node_Str"").append(totalNetInBytes).append(""String_Node_Str"");
        end.append(""String_Node_Str"").append(totalNetOutBytes).append(""String_Node_Str"");
        lines.add(end.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") || arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        AccessStatInfoResult result=StatUtil.getTotalAccessStatInfo().get(StatUtil.STAT_KEY);
        if (result != null) {
          StringBuffer line0=new StringBuffer();
          line0.append(""String_Node_Str"").append(""String_Node_Str"");
          line0.append(""String_Node_Str"").append(""String_Node_Str"");
          line0.append(""String_Node_Str"").append(""String_Node_Str"");
          line0.append(""String_Node_Str"").append(""String_Node_Str"");
          line0.append(""String_Node_Str"");
          StringBuffer line1=new StringBuffer();
          line1.append(""String_Node_Str"").append(""String_Node_Str"");
          line1.append(result.netInBytes[0]).append(""String_Node_Str"");
          line1.append(result.netInBytes[1]).append(""String_Node_Str"");
          line1.append(result.netInBytes[2]).append(""String_Node_Str"");
          line1.append(result.netInBytes[3]);
          StringBuffer line2=new StringBuffer();
          line2.append(""String_Node_Str"").append(""String_Node_Str"");
          line2.append(result.netOutBytes[0]).append(""String_Node_Str"");
          line2.append(result.netOutBytes[1]).append(""String_Node_Str"");
          line2.append(result.netOutBytes[2]).append(""String_Node_Str"");
          line2.append(result.netOutBytes[3]);
          StringBuffer line3=new StringBuffer();
          line3.append(result.created);
          lines.add(line0.toString());
          lines.add(line1.toString());
          lines.add(line2.toString());
          lines.add(line3.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        for (        Map.Entry<String,AccessStatInfoResult> entry : StatUtil.getTotalAccessStatInfo().entrySet()) {
          if (!StatUtil.STAT_KEY.equals(entry.getKey())) {
            AccessStatInfoResult result=entry.getValue();
            StringBuffer line1=new StringBuffer();
            line1.append(result.key).append(""String_Node_Str"");
            line1.append(""String_Node_Str"").append(""String_Node_Str"");
            line1.append(result.netInBytes[0]).append(""String_Node_Str"");
            line1.append(result.netInBytes[1]).append(""String_Node_Str"");
            line1.append(result.netInBytes[2]).append(""String_Node_Str"");
            line1.append(result.netInBytes[3]);
            StringBuffer line2=new StringBuffer();
            line2.append(result.key).append(""String_Node_Str"");
            line2.append(""String_Node_Str"").append(""String_Node_Str"");
            line2.append(result.netOutBytes[0]).append(""String_Node_Str"");
            line2.append(result.netOutBytes[1]).append(""String_Node_Str"");
            line2.append(result.netOutBytes[2]).append(""String_Node_Str"");
            line2.append(result.netOutBytes[3]);
            StringBuffer line3=new StringBuffer();
            line3.append(result.created);
            lines.add(line1.toString());
            lines.add(line2.toString());
            lines.add(line3.toString());
          }
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        long totalNetIn=0;
        long totalNetOut=0;
        for (        Map.Entry<String,UserFlow> entry : StatUtil.getUserFlowMap().entrySet()) {
          if (!StatUtil.STAT_KEY.equals(entry.getKey())) {
            StringBuffer sb=new StringBuffer();
            UserFlow userNetIo=entry.getValue();
            sb.append(userNetIo.password).append(""String_Node_Str"");
            sb.append(JavaUtils.bytesToString2(userNetIo.netIn.get())).append(""String_Node_Str"");
            sb.append(JavaUtils.bytesToString2(userNetIo.netOut.get()));
            totalNetIn=totalNetIn + userNetIo.netIn.get();
            totalNetOut=totalNetOut + userNetIo.netOut.get();
            lines.add(sb.toString());
          }
        }
        StringBuffer total=new StringBuffer();
        total.append(""String_Node_Str"").append(""String_Node_Str"");
        total.append(JavaUtils.bytesToString2(totalNetIn)).append(""String_Node_Str"");
        total.append(JavaUtils.bytesToString2(totalNetOut));
        lines.add(total.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=showLog(request,""String_Node_Str"");
        return encode2(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=showLog(request,""String_Node_Str"");
        return encode2(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=showLog(request,""String_Node_Str"");
        return encode2(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=showLog(request,""String_Node_Str"");
        return encode2(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> ret=new ArrayList<String>();
        try {
          String resp=ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"");
          StringBuilder sb=new StringBuilder();
          sb.append(resp);
          sb.append(""String_Node_Str"");
          String[] lines=sb.toString().split(""String_Node_Str"");
          ret.add(""String_Node_Str"");
          for (int i=1; i < lines.length; i++) {
            if (lines[i].equals(""String_Node_Str""))             continue;
            ret.add(lines[i]);
          }
        }
 catch (        IOException e) {
          LOGGER.error(""String_Node_Str"",e);
          ret.add(""String_Node_Str"");
        }
        return encode2(ret);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> ret=new ArrayList<String>();
        try {
          String cmd1=ShellUtils.osType == ShellUtils.OSType.OS_TYPE_MAC ? ""String_Node_Str"" : ""String_Node_Str"";
          String cmd2=ShellUtils.osType == ShellUtils.OSType.OS_TYPE_MAC ? ""String_Node_Str"" : ""String_Node_Str"";
          String iostatOut=ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",cmd1);
          String vmstatOut=ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",cmd2);
          StringBuilder sb=new StringBuilder();
          sb.append(iostatOut);
          sb.append(""String_Node_Str"");
          sb.append(""String_Node_Str"");
          sb.append(vmstatOut);
          String[] lines=sb.toString().split(""String_Node_Str"");
          ret.add(""String_Node_Str"");
          for (int i=1; i < lines.length; i++) {
            if (lines[i].equals(""String_Node_Str""))             continue;
            ret.add(lines[i]);
          }
        }
 catch (        IOException e) {
          LOGGER.error(""String_Node_Str"",e);
          ret.add(""String_Node_Str"");
        }
        return encode2(ret);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<Object> list=new ArrayList<Object>();
        Map<Integer,AbstractPool> pools=RedisEngineCtx.INSTANCE().getPoolMap();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        list.add(titleLine.toString());
        for (        AbstractPool pool : pools.values()) {
          if (pool instanceof RedisStandalonePool) {
            StringBuffer sb=new StringBuffer();
            RedisStandalonePool redisStandalonePool=(RedisStandalonePool)pool;
            PhysicalNode physicalNode=redisStandalonePool.getPhysicalNode();
            if (physicalNode == null)             continue;
            sb.append(""String_Node_Str"");
            sb.append(redisStandalonePool.getId()).append(""String_Node_Str"");
            sb.append(physicalNode.getPoolName()).append(""String_Node_Str"");
            sb.append(""String_Node_Str"").append(""String_Node_Str"");
            sb.append(physicalNode.getName()).append(""String_Node_Str"");
            sb.append(physicalNode.getMinCon()).append(""String_Node_Str"");
            sb.append(physicalNode.getMaxCon()).append(""String_Node_Str"");
            sb.append(physicalNode.getIdleCount()).append(""String_Node_Str"");
            sb.append(physicalNode.getActiveCount());
            list.add(sb.toString());
          }
 else           if (pool instanceof RedisClusterPool) {
            RedisClusterPool redisClusterPool=(RedisClusterPool)pool;
            Map<String,ClusterNode> masters=redisClusterPool.getMasters();
            List<String> clusterInfo=new ArrayList<String>();
            for (            ClusterNode clusterNode : masters.values()) {
              PhysicalNode physicalNode=clusterNode.getPhysicalNode();
              StringBuffer sb=new StringBuffer();
              sb.append(redisClusterPool.getId()).append(""String_Node_Str"");
              sb.append(physicalNode.getPoolName()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(""String_Node_Str"");
              sb.append(physicalNode.getName()).append(""String_Node_Str"");
              sb.append(physicalNode.getMinCon()).append(""String_Node_Str"");
              sb.append(physicalNode.getMaxCon()).append(""String_Node_Str"");
              sb.append(physicalNode.getIdleCount()).append(""String_Node_Str"");
              sb.append(physicalNode.getActiveCount()).append(""String_Node_Str"");
              ;
              sb.append(!clusterNode.isFail());
              clusterInfo.add(sb.toString());
              sb.append(clusterNode.getConnectInfo());
            }
            list.add(clusterInfo);
          }
 else           if (pool instanceof KafkaPool) {
            KafkaPool kafkaPool=(KafkaPool)pool;
            Map<Integer,PhysicalNode> physicalNodes=kafkaPool.getPhysicalNodes();
            for (            PhysicalNode physicalNode : physicalNodes.values()) {
              StringBuffer sb=new StringBuffer();
              sb.append(""String_Node_Str"");
              sb.append(kafkaPool.getId()).append(""String_Node_Str"");
              sb.append(physicalNode.getPoolName()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(""String_Node_Str"");
              sb.append(physicalNode.getName()).append(""String_Node_Str"");
              sb.append(physicalNode.getMinCon()).append(""String_Node_Str"");
              sb.append(physicalNode.getMaxCon()).append(""String_Node_Str"");
              sb.append(physicalNode.getIdleCount()).append(""String_Node_Str"");
              sb.append(physicalNode.getActiveCount());
              list.add(sb.toString());
            }
          }
        }
        return encodeObject(list);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        Collection<Entry<String,AtomicLong>> entrys=StatUtil.getCommandProcTimeMap().entrySet();
        List<String> lines=new ArrayList<String>();
        for (        Entry<String,AtomicLong> entry : entrys) {
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(entry.getKey()).append(""String_Node_Str"").append(entry.getValue().get());
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        Collection<Entry<String,AtomicLong>> entrys=StatUtil.getCommandWaitTimeMap().entrySet();
        List<String> lines=new ArrayList<String>();
        for (        Entry<String,AtomicLong> entry : entrys) {
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(entry.getKey()).append(""String_Node_Str"").append(entry.getValue().get());
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        for (        BigLength bigLength : StatUtil.getBigLengthMap().values()) {
          StringBuffer line1=new StringBuffer();
          line1.append(bigLength.cmd).append(""String_Node_Str"");
          line1.append(bigLength.key).append(""String_Node_Str"");
          line1.append(bigLength.length.get()).append(""String_Node_Str"");
          line1.append(bigLength.count_1k.get()).append(""String_Node_Str"");
          line1.append(bigLength.count_10k.get());
          lines.add(line1.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        for (        SlowKey slowKey : StatUtil.getSlowKey()) {
          StringBuffer line1=new StringBuffer();
          line1.append(slowKey.cmd).append(""String_Node_Str"");
          line1.append(slowKey.key).append(""String_Node_Str"");
          line1.append(slowKey.count);
          lines.add(line1.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") && (numArgs == 3 || numArgs == 2)) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        if (numArgs == 2) {
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"");
        }
 else {
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"");
        }
        lines.add(titleLine.toString());
        final Map<Integer,PoolCfg> poolCfgMap=RedisEngineCtx.INSTANCE().getPoolCfgMap();
        for (        Entry<Integer,PoolCfg> poolEntry : poolCfgMap.entrySet()) {
          PoolCfg poolCfg=poolEntry.getValue();
          if (poolCfg instanceof KafkaPoolCfg) {
            Map<String,TopicCfg> kafkaMap=((KafkaPoolCfg)poolCfg).getTopicCfgMap();
            if (numArgs == 2) {
              for (              Entry<String,TopicCfg> kafkaEntry : kafkaMap.entrySet()) {
                TopicCfg kafkaCfg=kafkaEntry.getValue();
                StringBuffer line=new StringBuffer();
                line.append(kafkaCfg.getName()).append(""String_Node_Str"");
                line.append(kafkaCfg.getPoolId()).append(""String_Node_Str"");
                line.append(kafkaCfg.getPartitions()).append(""String_Node_Str"");
                line.append(kafkaCfg.getReplicationFactor()).append(""String_Node_Str"");
                line.append(kafkaCfg.getProducers()).append(""String_Node_Str"");
                line.append(kafkaCfg.getConsumers());
                lines.add(line.toString());
              }
            }
 else {
              String topic=new String(request.getArgs()[2]);
              TopicCfg kafkaCfg=kafkaMap.get(topic);
              if (kafkaCfg != null) {
                for (                BrokerPartition partition : kafkaCfg.getRunningInfo().getPartitions().values()) {
                  int pt=partition.getPartition();
                  StringBuffer line=new StringBuffer();
                  line.append(kafkaCfg.getName()).append(""String_Node_Str"");
                  line.append(partition.getLeader().getHost()).append(partition.getLeader().getPort()).append(""String_Node_Str"");
                  line.append(pt).append(""String_Node_Str"");
                  line.append(partition.getLogStartOffset()).append(""String_Node_Str"");
                  line.append(partition.getProducerOffset()).append(""String_Node_Str"");
                  for (                  ConsumerOffset consumerOffset : partition.getConsumerOffsets().values()) {
                    line.append(consumerOffset.getConsumer());
                    line.append(""String_Node_Str"");
                    line.append(consumerOffset.getCurrentOffset());
                    line.append(""String_Node_Str"");
                  }
                  lines.add(line.toString());
                }
              }
            }
          }
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") && numArgs == 2) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        NetFlowGuard nfg=RedisEngineCtx.INSTANCE().getNetflowGuard();
        Map<String,Guard> map=nfg.getGuardMap();
        for (        Entry<String,Guard> entry : map.entrySet()) {
          Guard guard=entry.getValue();
          StringBuffer line=new StringBuffer();
          line.append(entry.getKey()).append(""String_Node_Str"");
          line.append(guard.getPerSecondMaxSize()).append(""String_Node_Str"");
          line.append(guard.getRequestMaxSize()).append(""String_Node_Str"");
          line.append(guard.getHistogram());
          lines.add(line.toString());
        }
        return encode(lines);
      }
    }
  }
 else   if (arg1.length == 6) {
    if ((arg1[0] == 'R' || arg1[0] == 'r') && (arg1[1] == 'E' || arg1[1] == 'e') && (arg1[2] == 'L' || arg1[2] == 'l')&& (arg1[3] == 'O' || arg1[3] == 'o')&& (arg1[4] == 'A' || arg1[4] == 'a')&& (arg1[5] == 'D' || arg1[5] == 'd')) {
      if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        byte[] buff=RedisEngineCtx.INSTANCE().reloadAll();
        return buff;
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        byte[] buff=RedisEngineCtx.INSTANCE().reloadUser();
        return buff;
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        byte[] buff=RedisEngineCtx.INSTANCE().reloadNetflow();
        return buff;
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisFrontConnection) {
            LOGGER.info(""String_Node_Str"",c);
            c.close(""String_Node_Str"");
          }
        }
        return ""String_Node_Str"".getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        JAVA_BIN_PATH=new String(request.getArgs()[2]);
        return ""String_Node_Str"".getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        try {
          Map<Integer,PoolCfg> poolCfgMap=RedisEngineCtx.INSTANCE().getPoolCfgMap();
          for (          PoolCfg poolCfg : poolCfgMap.values()) {
            if (poolCfg instanceof KafkaPoolCfg)             poolCfg.reloadExtraCfg();
          }
        }
 catch (        Exception e) {
          LOGGER.error(""String_Node_Str"",e);
          StringBuffer sb=new StringBuffer();
          sb.append(""String_Node_Str"").append(e.getMessage()).append(""String_Node_Str"");
          return sb.toString().getBytes();
        }
        return ""String_Node_Str"".getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        byte[] buff=BypassService.INSTANCE().reload();
        return buff;
      }
    }
    if ((arg1[0] == 'R' || arg1[0] == 'r') && (arg1[1] == 'E' || arg1[1] == 'e') && (arg1[2] == 'P' || arg1[2] == 'p')&& (arg1[3] == 'A' || arg1[3] == 'a')&& (arg1[4] == 'I' || arg1[4] == 'i')&& (arg1[5] == 'R' || arg1[5] == 'r')) {
      if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        String password=new String(request.getArgs()[2]);
        String topicName=new String(request.getArgs()[3]);
        long offset=Long.parseLong(new String(request.getArgs()[4]));
        UserCfg userCfg=RedisEngineCtx.INSTANCE().getUserMap().get(password);
        if (userCfg != null) {
          int poolId=userCfg.getPoolId();
          PoolCfg poolCfg=(PoolCfg)RedisEngineCtx.INSTANCE().getPoolCfgMap().get(poolId);
          if (poolCfg != null && poolCfg instanceof KafkaPoolCfg) {
            TopicCfg topicCfg=((KafkaPoolCfg)poolCfg).getTopicCfgMap().get(topicName);
            if (topicCfg != null) {
              for (int partition=0; partition < topicCfg.getPartitions(); partition++) {
                boolean isRepair=BrokerOffsetService.INSTANCE().repairOffset(password,topicCfg,partition,offset);
                if (!isRepair) {
                  return (""String_Node_Str"" + partition + ""String_Node_Str"").getBytes();
                }
              }
            }
 else {
              return (""String_Node_Str"" + topicName + ""String_Node_Str"").getBytes();
            }
            return ""String_Node_Str"".getBytes();
          }
 else {
            return (""String_Node_Str"" + poolId + ""String_Node_Str"").getBytes();
          }
        }
 else {
          return (""String_Node_Str"" + password + ""String_Node_Str"").getBytes();
        }
      }
    }
  }
 else   if (arg1.length == 7) {
    if ((arg1[0] == 'C' || arg1[0] == 'c') && (arg1[1] == 'L' || arg1[1] == 'l') && (arg1[2] == 'U' || arg1[2] == 'u')&& (arg1[3] == 'S' || arg1[3] == 's')&& (arg1[4] == 'T' || arg1[4] == 't')&& (arg1[5] == 'E' || arg1[5] == 'e')&& (arg1[6] == 'R' || arg1[6] == 'r')) {
      AbstractPool pool=RedisEngineCtx.INSTANCE().getPoolMap().get(frontCon.getUserCfg().getPoolId());
      if (pool.getType() != 1) {
        return ""String_Node_Str"".getBytes();
      }
      PhysicalNode pysicalNode=((RedisClusterPool)pool).getPhysicalNodeBySlot(0);
      if (pysicalNode == null) {
        return ""String_Node_Str"".getBytes();
      }
      try {
        RedisBackendConnection backendCon=(RedisBackendConnection)pysicalNode.getConnection(new DirectTransTofrontCallBack(),frontCon);
        if (backendCon == null) {
          frontCon.writeErrMessage(""String_Node_Str"");
        }
 else {
          backendCon.write(request.encode());
        }
        return null;
      }
 catch (      IOException e) {
        LOGGER.error(""String_Node_Str"",e);
      }
    }
  }
  return ""String_Node_Str"".getBytes();
}"
37477,"public byte[] encode(HttpResponse response){
  if (response == null)   return null;
  StringBuffer buf=new StringBuffer();
  buf.append(response.getHttpVersion()).append(SP);
  buf.append(String.valueOf(response.getStatusCode())).append(SP);
  buf.append(response.getReasonPhrase()).append(CRLF);
  for (  Map.Entry<String,String> h : response.headers().entrySet()) {
    buf.append(h.getKey()).append(COLON).append(SP);
    buf.append(h.getValue()).append(CRLF);
  }
  buf.append(CRLF);
  byte[] src1=buf.toString().getBytes();
  byte[] src2=response.getContent();
  byte[] dest=new byte[src1.length + src2.length];
  System.arraycopy(src1,0,dest,0,src1.length);
  System.arraycopy(src2,0,dest,dest.length,src2.length);
  return dest;
}","public byte[] encode(HttpResponse response){
  if (response == null)   return null;
  StringBuffer buf=new StringBuffer();
  buf.append(response.getHttpVersion()).append(SP);
  buf.append(String.valueOf(response.getStatusCode())).append(SP);
  buf.append(response.getReasonPhrase()).append(CRLF);
  for (  Map.Entry<String,String> h : response.headers().entrySet()) {
    buf.append(h.getKey()).append(COLON).append(SP);
    buf.append(h.getValue()).append(CRLF);
  }
  buf.append(CRLF);
  byte[] head=buf.toString().getBytes();
  byte[] body=response.getContent();
  if (body != null) {
    byte[] dest=new byte[head.length + body.length];
    System.arraycopy(head,0,dest,0,head.length);
    System.arraycopy(body,0,dest,dest.length,body.length);
    return dest;
  }
 else {
    return head;
  }
}"
37478,"@Override public void onCollect(String password,String cmd,String key,int requestSize,int responseSize,int procTimeMills,int waitTimeMills,boolean isCommandOnly,boolean isBypass){
  if (isCommandOnly)   return;
  if (requestSize < REQUIRED_SIZE && responseSize < REQUIRED_SIZE) {
    return;
  }
  totalCount.incrementAndGet();
  if (isBypass) {
    bypassCount.incrementAndGet();
  }
  if (!locking.compareAndSet(false,true)) {
    return;
  }
  try {
    if (bkList.size() >= LENGTH) {
      while (bkList.size() >= (LENGTH * 0.5)) {
        int index=bkList.size() - 1;
        BigKey bk=bkList.remove(index);
        if (bk != null) {
          bkHashMap.remove(bk.key);
        }
      }
    }
    BigKey newBK=new BigKey();
    newBK.key=key;
    int index=bkList.indexOf(newBK);
    if (index >= 0) {
      BigKey oldBK=bkHashMap.get(key);
      if (oldBK == null) {
        oldBK=newBK;
        bkHashMap.put(key,oldBK);
      }
      oldBK.lastCmd=cmd;
      oldBK.size=requestSize > responseSize ? requestSize : responseSize;
      oldBK.lastUseTime=TimeUtil.currentTimeMillis();
      oldBK.count.incrementAndGet();
      oldBK.fromReq=requestSize >= REQUIRED_SIZE;
      oldBK.fromResp=responseSize >= REQUIRED_SIZE;
    }
 else {
      newBK.lastCmd=cmd;
      newBK.size=requestSize > responseSize ? requestSize : responseSize;
      newBK.lastUseTime=TimeUtil.currentTimeMillis();
      newBK.fromReq=requestSize >= REQUIRED_SIZE;
      newBK.fromResp=responseSize >= REQUIRED_SIZE;
      bkList.add(newBK);
      bkHashMap.put(key,newBK);
    }
  }
  finally {
    locking.set(false);
  }
}","@Override public void onCollect(String password,String cmd,String key,int requestSize,int responseSize,int procTimeMills,int waitTimeMills,boolean isCommandOnly,boolean isBypass){
  if (isCommandOnly)   return;
  if (requestSize < REQUIRED_SIZE && responseSize < REQUIRED_SIZE) {
    return;
  }
  totalCount.incrementAndGet();
  if (isBypass) {
    bypassCount.incrementAndGet();
  }
  if (!locking.compareAndSet(false,true)) {
    return;
  }
  try {
    if (bkList.size() >= LENGTH) {
      Collections.sort(bkList,new BigKey());
      while (bkList.size() >= (LENGTH * 0.5)) {
        int index=bkList.size() - 1;
        BigKey bk=bkList.remove(index);
        if (bk != null) {
          bkHashMap.remove(bk.key);
        }
      }
    }
    BigKey newBK=new BigKey();
    newBK.key=key;
    int index=bkList.indexOf(newBK);
    if (index >= 0) {
      BigKey oldBK=bkHashMap.get(key);
      if (oldBK == null) {
        oldBK=bkList.get(index);
        if (!key.equals(oldBK.key)) {
          return;
        }
        bkHashMap.put(key,oldBK);
      }
      oldBK.lastCmd=cmd;
      oldBK.size=requestSize > responseSize ? requestSize : responseSize;
      oldBK.lastUseTime=TimeUtil.currentTimeMillis();
      oldBK.count.incrementAndGet();
      oldBK.fromReq=requestSize >= REQUIRED_SIZE;
      oldBK.fromResp=responseSize >= REQUIRED_SIZE;
    }
 else {
      newBK.lastCmd=cmd;
      newBK.size=requestSize > responseSize ? requestSize : responseSize;
      newBK.lastUseTime=TimeUtil.currentTimeMillis();
      newBK.fromReq=requestSize >= REQUIRED_SIZE;
      newBK.fromResp=responseSize >= REQUIRED_SIZE;
      bkList.add(newBK);
      bkHashMap.put(key,newBK);
    }
  }
  finally {
    locking.set(false);
  }
}"
37479,"public List<BigKey> getTop100(){
  try {
    while (!locking.compareAndSet(false,true)) {
    }
    int len=bkList.size() > 100 ? 100 : bkList.size();
    List<BigKey> newList=new ArrayList<BigKey>(len);
    for (int i=0; i < len; i++) {
      newList.add(bkList.get(i));
    }
    return newList;
  }
  finally {
    locking.set(false);
  }
}","public List<BigKey> getTop100(){
  try {
    while (!locking.compareAndSet(false,true)) {
    }
    int len=bkList.size() > 100 ? 100 : bkList.size();
    Collections.sort(bkList,new BigKey());
    List<BigKey> newList=new ArrayList<BigKey>(len);
    for (int i=0; i < len; i++) {
      newList.add(bkList.get(i));
    }
    return newList;
  }
  finally {
    locking.set(false);
  }
}"
37480,"/** 
 *  
 */
@Override public RedisPipelineResponse decode(byte[] buffer){
  int result=0;
  append(buffer);
  try {
    for (; ; ) {
      if (compositeArray.remaining(readOffset) < 4) {
        return new RedisPipelineResponse(RedisPipelineResponse.ERR,0,null);
      }
      startByteArray=readByteArray=compositeArray.findByteArray(readOffset);
      byte type=readByteArray.get(readOffset++);
switch (type) {
case '*':
case '+':
case '-':
case ':':
case '$':
        parseResponse(type);
      result++;
    index.add(readOffset);
}
if (compositeArray.getByteCount() < readOffset) {
  throw new IndexOutOfBoundsException(""String_Node_Str"");
}
 else if (compositeArray.getByteCount() == readOffset) {
  readOffset=0;
  return new RedisPipelineResponse(RedisPipelineResponse.OK,result,getResponses());
}
}
}
 catch (IndexOutOfBoundsException e1) {
readOffset=0;
index.clear();
return new RedisPipelineResponse(RedisPipelineResponse.ERR,0,null);
}
}","/** 
 *  
 */
@Override public RedisPipelineResponse decode(byte[] buffer){
  int result=0;
  append(buffer);
  try {
    startByteArray=readByteArray=compositeArray.findByteArray(readOffset);
    for (; ; ) {
      if (compositeArray.remaining(readOffset) < 4) {
        return new RedisPipelineResponse(RedisPipelineResponse.ERR,0,null);
      }
      byte type=readByteArray.get(readOffset++);
      updateReadOffsetAndReadByteChunk(readOffset);
switch (type) {
case '*':
case '+':
case '-':
case ':':
case '$':
        parseResponse(type);
      result++;
    index.add(readOffset);
}
if (compositeArray.getByteCount() < readOffset) {
  throw new IndexOutOfBoundsException(""String_Node_Str"");
}
 else if (compositeArray.getByteCount() == readOffset) {
  readOffset=0;
  return new RedisPipelineResponse(RedisPipelineResponse.OK,result,getResponses());
}
}
}
 catch (IndexOutOfBoundsException e1) {
readOffset=0;
index.clear();
return new RedisPipelineResponse(RedisPipelineResponse.ERR,0,null);
}
}"
37481,"/** 
 * 
 */
private void accept(){
  SocketChannel channel=null;
  try {
    channel=serverChannel.accept();
    channel.socket().setTcpNoDelay(true);
    channel.configureBlocking(false);
    if (NETWORK_QOS_FLAG != null) {
      try {
        if (""String_Node_Str"".equals(NETWORK_QOS_FLAG)) {
          channel.socket().setTrafficClass(144);
        }
 else         if (""String_Node_Str"".equals(NETWORK_QOS_FLAG)) {
          channel.socket().setTrafficClass(24);
        }
      }
 catch (      Exception ex) {
        ex.printStackTrace();
      }
    }
    ClosableConnection c=factory.make(channel);
    c.setDirection(ClosableConnection.Direction.in);
    InetSocketAddress remoteAddr=(InetSocketAddress)channel.getRemoteAddress();
    c.setHost(remoteAddr.getHostString());
    c.setPort(remoteAddr.getPort());
    NIOReactor reactor=reactorPool.getNextReactor();
    reactor.postRegister(c);
  }
 catch (  Exception e) {
    LOGGER.warn(getName(),e);
    closeChannel(channel);
  }
}","/** 
 * 
 */
private void accept(){
  SocketChannel channel=null;
  try {
    channel=serverChannel.accept();
    channel.socket().setTcpNoDelay(true);
    channel.configureBlocking(false);
    channel.socket().setTrafficClass(0x04 | 0x08);
    ClosableConnection c=factory.make(channel);
    c.setDirection(ClosableConnection.Direction.in);
    InetSocketAddress remoteAddr=(InetSocketAddress)channel.getRemoteAddress();
    c.setHost(remoteAddr.getHostString());
    c.setPort(remoteAddr.getPort());
    NIOReactor reactor=reactorPool.getNextReactor();
    reactor.postRegister(c);
  }
 catch (  Exception e) {
    LOGGER.warn(getName(),e);
    closeChannel(channel);
  }
}"
37482,"public void init() throws Exception {
  this.lock=new ReentrantLock();
  try {
    this.serverMap=ConfigLoader.loadServerMap(ConfigLoader.buidCfgAbsPathFor(""String_Node_Str""));
    this.poolCfgMap=ConfigLoader.loadPoolMap(ConfigLoader.buidCfgAbsPathFor(""String_Node_Str""));
    this.userMap=ConfigLoader.loadUserMap(poolCfgMap,ConfigLoader.buidCfgAbsPathFor(""String_Node_Str""));
    this.mailProperty=ConfigLoader.loadMailProperties(ConfigLoader.buidCfgAbsPathFor(""String_Node_Str""));
  }
 catch (  Exception e) {
    throw e;
  }
  String portString=this.serverMap.get(""String_Node_Str"");
  String reactorSizeString=this.serverMap.get(""String_Node_Str"");
  String minBufferSizeString=this.serverMap.get(""String_Node_Str"");
  String maxBufferSizeString=this.serverMap.get(""String_Node_Str"");
  String decomposeBufferSizeString=this.serverMap.get(""String_Node_Str"");
  String minChunkSizeString=this.serverMap.get(""String_Node_Str"");
  String incrementString=this.serverMap.get(""String_Node_Str"");
  String maxChunkSizeString=this.serverMap.get(""String_Node_Str"");
  String bufferLocalPercentString=this.serverMap.get(""String_Node_Str"");
  String bossSizeString=this.serverMap.get(""String_Node_Str"");
  String timerSizeString=this.serverMap.get(""String_Node_Str"");
  String networkFlowLimitSizeString=this.serverMap.get(""String_Node_Str"");
  int processors=Runtime.getRuntime().availableProcessors();
  int port=portString == null ? 8066 : Integer.parseInt(portString);
  int reactorSize=reactorSizeString == null ? processors : Integer.parseInt(reactorSizeString);
  long minBufferSize=minBufferSizeString == null ? 16384 * 1000 : Long.parseLong(minBufferSizeString);
  long maxBufferSize=maxBufferSizeString == null ? 16384 * 10000 : Long.parseLong(maxBufferSizeString);
  int decomposeBufferSize=decomposeBufferSizeString == null ? 64 * 1024 : Integer.parseInt(decomposeBufferSizeString);
  int minChunkSize=minChunkSizeString == null ? 0 : Integer.parseInt(minChunkSizeString);
  long networkFlowLimitSize=networkFlowLimitSizeString == null ? -1 : Long.parseLong(networkFlowLimitSizeString);
  this.flowMonitor=new NetFlowMonitor(networkFlowLimitSize);
  int[] increments=null;
  if (incrementString == null) {
    increments=new int[]{1024};
  }
 else {
    String[] incrementStrings=incrementString.split(""String_Node_Str"");
    if (incrementStrings == null || incrementStrings.length == 0) {
      increments=new int[]{1024};
    }
 else {
      increments=new int[incrementStrings.length];
      for (int i=0; i < incrementStrings.length; i++) {
        increments[i]=Integer.parseInt(incrementStrings[i]);
      }
    }
  }
  int maxChunkSize=maxChunkSizeString == null ? 64 * 1024 : Integer.parseInt(maxChunkSizeString);
  int bufferLocalPercent=bufferLocalPercentString == null ? 100 : Integer.parseInt(bufferLocalPercentString);
  int threadLocalPercent=bufferLocalPercent / reactorSize;
  int bossSize=bossSizeString == null ? 10 : Integer.parseInt(bossSizeString);
  int timerSize=timerSizeString == null ? 6 : Integer.parseInt(timerSizeString);
  this.bufferPool=new BucketBufferPool(minBufferSize,maxBufferSize,decomposeBufferSize,minChunkSize,increments,maxChunkSize,threadLocalPercent);
  this.virtualMemoryService=new VirtualMemoryService();
  this.virtualMemoryService.start();
  new NetSystem(bufferPool,ExecutorUtil.create(""String_Node_Str"",bossSize),ExecutorUtil.create(""String_Node_Str"",timerSize));
  String frontIdleTimeoutString=this.serverMap.get(""String_Node_Str"");
  String backendIdleTimeoutString=this.serverMap.get(""String_Node_Str"");
  int frontIdleTimeout=frontIdleTimeoutString == null ? 5 * 60 * 1000 : Integer.parseInt(frontIdleTimeoutString);
  int backendIdleTimeout=backendIdleTimeoutString == null ? 30 * 60 * 1000 : Integer.parseInt(backendIdleTimeoutString);
  SystemConfig systemConfig=new SystemConfig();
  systemConfig.setFrontIdleTimeout(frontIdleTimeout);
  systemConfig.setBackendIdleTimeout(backendIdleTimeout);
  NetSystem.getInstance().setNetConfig(systemConfig);
  System.out.println(String.format(""String_Node_Str"",processors,reactorSize,bossSize,timerSize,frontIdleTimeout,backendIdleTimeout));
  NIOReactorPool reactorPool=new NIOReactorPool(BufferPool.LOCAL_BUF_THREAD_PREX + ""String_Node_Str"",reactorSize);
  NIOReactor[] reactors=reactorPool.getAllReactors();
  for (  NIOReactor r : reactors) {
    this.reactorMap.put(r.getName(),r);
  }
  NIOConnector connector=new NIOConnector(""String_Node_Str"",reactorPool);
  connector.start();
  NetSystem.getInstance().setConnector(connector);
  boolean isKafkaPoolExist=false;
  this.poolMap=new HashMap<Integer,AbstractPool>(poolCfgMap.size());
  for (  final PoolCfg poolCfg : poolCfgMap.values()) {
    AbstractPool pool=PoolFactory.createPoolByCfg(poolCfg);
    pool.startup();
    this.poolMap.put(pool.getId(),pool);
    if (poolCfg instanceof KafkaPoolCfg) {
      isKafkaPoolExist=true;
    }
  }
  if (isKafkaPoolExist == true && !BrokerOffsetService.INSTANCE().isRunning()) {
    BrokerOffsetService.INSTANCE().start();
    Runtime.getRuntime().addShutdownHook(new Thread(){
      public void run(){
        BrokerOffsetService.INSTANCE().stop();
      }
    }
);
  }
  NIOAcceptor acceptor=new NIOAcceptor(""String_Node_Str"",""String_Node_Str"",port,new RedisFrontendConnectionFactory(),reactorPool);
  acceptor.start();
  LOGGER.info(acceptor.getName() + ""String_Node_Str"",acceptor.getPort());
  Iterator<String> it=userMap.keySet().iterator();
  String authString=it.hasNext() ? it.next() : ""String_Node_Str"";
  KeepAlived.check(port,authString);
}","public void init() throws Exception {
  this.lock=new ReentrantLock();
  try {
    this.serverMap=ConfigLoader.loadServerMap(ConfigLoader.buidCfgAbsPathFor(""String_Node_Str""));
    this.poolCfgMap=ConfigLoader.loadPoolMap(ConfigLoader.buidCfgAbsPathFor(""String_Node_Str""));
    this.userMap=ConfigLoader.loadUserMap(poolCfgMap,ConfigLoader.buidCfgAbsPathFor(""String_Node_Str""));
    this.mailProperty=ConfigLoader.loadMailProperties(ConfigLoader.buidCfgAbsPathFor(""String_Node_Str""));
  }
 catch (  Exception e) {
    throw e;
  }
  String portString=this.serverMap.get(""String_Node_Str"");
  String reactorSizeString=this.serverMap.get(""String_Node_Str"");
  String minBufferSizeString=this.serverMap.get(""String_Node_Str"");
  String maxBufferSizeString=this.serverMap.get(""String_Node_Str"");
  String decomposeBufferSizeString=this.serverMap.get(""String_Node_Str"");
  String minChunkSizeString=this.serverMap.get(""String_Node_Str"");
  String incrementString=this.serverMap.get(""String_Node_Str"");
  String maxChunkSizeString=this.serverMap.get(""String_Node_Str"");
  String bufferLocalPercentString=this.serverMap.get(""String_Node_Str"");
  String bossSizeString=this.serverMap.get(""String_Node_Str"");
  String timerSizeString=this.serverMap.get(""String_Node_Str"");
  String networkFlowLimitSizeString=this.serverMap.get(""String_Node_Str"");
  int port=portString == null ? 8066 : Integer.parseInt(portString);
  int processors=Runtime.getRuntime().availableProcessors();
  int reactorSize=reactorSizeString == null ? processors + 1 : Integer.parseInt(reactorSizeString);
  if (reactorSize > 9) {
    reactorSize=4 + (processors * 5 / 8);
  }
  long minBufferSize=minBufferSizeString == null ? 16384 * 1000 : Long.parseLong(minBufferSizeString);
  long maxBufferSize=maxBufferSizeString == null ? 16384 * 10000 : Long.parseLong(maxBufferSizeString);
  int decomposeBufferSize=decomposeBufferSizeString == null ? 64 * 1024 : Integer.parseInt(decomposeBufferSizeString);
  int minChunkSize=minChunkSizeString == null ? 0 : Integer.parseInt(minChunkSizeString);
  long networkFlowLimitSize=networkFlowLimitSizeString == null ? -1 : Long.parseLong(networkFlowLimitSizeString);
  this.flowMonitor=new NetFlowMonitor(networkFlowLimitSize);
  int[] increments=null;
  if (incrementString == null) {
    increments=new int[]{1024};
  }
 else {
    String[] incrementStrings=incrementString.split(""String_Node_Str"");
    if (incrementStrings == null || incrementStrings.length == 0) {
      increments=new int[]{1024};
    }
 else {
      increments=new int[incrementStrings.length];
      for (int i=0; i < incrementStrings.length; i++) {
        increments[i]=Integer.parseInt(incrementStrings[i]);
      }
    }
  }
  int maxChunkSize=maxChunkSizeString == null ? 64 * 1024 : Integer.parseInt(maxChunkSizeString);
  int bufferLocalPercent=bufferLocalPercentString == null ? 100 : Integer.parseInt(bufferLocalPercentString);
  int threadLocalPercent=bufferLocalPercent / reactorSize;
  int bossSize=bossSizeString == null ? 10 : Integer.parseInt(bossSizeString);
  int timerSize=timerSizeString == null ? 6 : Integer.parseInt(timerSizeString);
  this.bufferPool=new BucketBufferPool(minBufferSize,maxBufferSize,decomposeBufferSize,minChunkSize,increments,maxChunkSize,threadLocalPercent);
  this.virtualMemoryService=new VirtualMemoryService();
  this.virtualMemoryService.start();
  new NetSystem(bufferPool,ExecutorUtil.create(""String_Node_Str"",bossSize),ExecutorUtil.create(""String_Node_Str"",timerSize));
  String frontIdleTimeoutString=this.serverMap.get(""String_Node_Str"");
  String backendIdleTimeoutString=this.serverMap.get(""String_Node_Str"");
  int frontIdleTimeout=frontIdleTimeoutString == null ? 5 * 60 * 1000 : Integer.parseInt(frontIdleTimeoutString);
  int backendIdleTimeout=backendIdleTimeoutString == null ? 30 * 60 * 1000 : Integer.parseInt(backendIdleTimeoutString);
  SystemConfig systemConfig=new SystemConfig();
  systemConfig.setFrontIdleTimeout(frontIdleTimeout);
  systemConfig.setBackendIdleTimeout(backendIdleTimeout);
  NetSystem.getInstance().setNetConfig(systemConfig);
  System.out.println(String.format(""String_Node_Str"",processors,reactorSize,bossSize,timerSize,frontIdleTimeout,backendIdleTimeout));
  NIOReactorPool reactorPool=new NIOReactorPool(BufferPool.LOCAL_BUF_THREAD_PREX + ""String_Node_Str"",reactorSize);
  NIOReactor[] reactors=reactorPool.getAllReactors();
  for (  NIOReactor r : reactors) {
    this.reactorMap.put(r.getName(),r);
  }
  NIOConnector connector=new NIOConnector(""String_Node_Str"",reactorPool);
  connector.start();
  NetSystem.getInstance().setConnector(connector);
  boolean isKafkaPoolExist=false;
  this.poolMap=new HashMap<Integer,AbstractPool>(poolCfgMap.size());
  for (  final PoolCfg poolCfg : poolCfgMap.values()) {
    AbstractPool pool=PoolFactory.createPoolByCfg(poolCfg);
    pool.startup();
    this.poolMap.put(pool.getId(),pool);
    if (poolCfg instanceof KafkaPoolCfg) {
      isKafkaPoolExist=true;
    }
  }
  if (isKafkaPoolExist == true && !BrokerOffsetService.INSTANCE().isRunning()) {
    BrokerOffsetService.INSTANCE().start();
    Runtime.getRuntime().addShutdownHook(new Thread(){
      public void run(){
        BrokerOffsetService.INSTANCE().stop();
      }
    }
);
  }
  NIOAcceptor acceptor=new NIOAcceptor(""String_Node_Str"",""String_Node_Str"",port,new RedisFrontendConnectionFactory(),reactorPool);
  acceptor.start();
  LOGGER.info(acceptor.getName() + ""String_Node_Str"",acceptor.getPort());
  Iterator<String> it=userMap.keySet().iterator();
  String authString=it.hasNext() ? it.next() : ""String_Node_Str"";
  KeepAlived.check(port,authString);
}"
37483,"public byte[] subArray(int beginIndex,int length){
  checkIndex(beginIndex,length);
  byte[] resultArr=new byte[length];
  Component c=findComponent(beginIndex);
  int srcBeginIndex=beginIndex - c.beginIndex;
  int availableByteCount=c.length - srcBeginIndex;
  if (availableByteCount >= length) {
    System.arraycopy(c.bytes,srcBeginIndex,resultArr,0,length);
  }
 else {
    System.arraycopy(c.bytes,srcBeginIndex,resultArr,0,availableByteCount);
    int destPos=availableByteCount;
    int remaining=length - availableByteCount;
    int index=components.indexOf(c);
    while (remaining > 0) {
      c=components.get(index++);
      if (remaining <= c.length) {
        System.arraycopy(c.bytes,0,resultArr,destPos,remaining);
        break;
      }
 else {
        System.arraycopy(c.bytes,0,resultArr,destPos,c.length);
      }
      destPos+=c.length;
      remaining-=c.length;
    }
  }
  return resultArr;
}","public byte[] subArray(int beginIndex,int length){
  checkIndex(beginIndex,length);
  byte[] resultArr=new byte[length];
  Component c=findComponent(beginIndex);
  int srcBeginIndex=beginIndex - c.beginIndex;
  int availableByteCount=c.length - srcBeginIndex;
  if (availableByteCount >= length) {
    System.arraycopy(c.bytes,srcBeginIndex,resultArr,0,length);
  }
 else {
    System.arraycopy(c.bytes,srcBeginIndex,resultArr,0,availableByteCount);
    int destPos=availableByteCount;
    int remaining=length - availableByteCount;
    int index=components.indexOf(c);
    while (remaining > 0) {
      c=components.get(++index);
      if (remaining <= c.length) {
        System.arraycopy(c.bytes,0,resultArr,destPos,remaining);
        break;
      }
 else {
        System.arraycopy(c.bytes,0,resultArr,destPos,c.length);
      }
      destPos+=c.length;
      remaining-=c.length;
    }
  }
  return resultArr;
}"
37484,"private JedisPool initialize(String host,int port){
  GenericObjectPoolConfig jedisPoolConfig=new GenericObjectPoolConfig();
  jedisPoolConfig.setMaxIdle(maxIdle);
  jedisPoolConfig.setMinIdle(minIdle);
  jedisPoolConfig.setTestOnBorrow(testOnBorrow);
  jedisPoolConfig.setTestOnReturn(testOnReturn);
  jedisPoolConfig.setTestWhileIdle(testWhileIdle);
  jedisPoolConfig.setNumTestsPerEvictionRun(numTestsPerEvictionRun);
  jedisPoolConfig.setMinEvictableIdleTimeMillis(minEvictableIdleTimeMillis);
  jedisPoolConfig.setTimeBetweenEvictionRunsMillis(timeBetweenEvictionRunsMillis);
  return new JedisPool(jedisPoolConfig,host,port,timeBetweenEvictionRunsMillis,null);
}","private JedisPool initialize(String host,int port){
  GenericObjectPoolConfig jedisPoolConfig=new GenericObjectPoolConfig();
  jedisPoolConfig.setMaxIdle(maxIdle);
  jedisPoolConfig.setMinIdle(minIdle);
  jedisPoolConfig.setTestOnBorrow(testOnBorrow);
  jedisPoolConfig.setTestOnReturn(testOnReturn);
  jedisPoolConfig.setTestWhileIdle(testWhileIdle);
  jedisPoolConfig.setNumTestsPerEvictionRun(numTestsPerEvictionRun);
  jedisPoolConfig.setMinEvictableIdleTimeMillis(-1);
  jedisPoolConfig.setSoftMinEvictableIdleTimeMillis(softMinEvictableIdleTimeMillis);
  jedisPoolConfig.setTimeBetweenEvictionRunsMillis(timeBetweenEvictionRunsMillis);
  return new JedisPool(jedisPoolConfig,host,port,timeBetweenEvictionRunsMillis,null);
}"
37485,"@Override public void write(ByteBuffer buf){
  try {
    for (; ; ) {
      if (!rwLock.compareAndSet(false,true)) {
        break;
      }
    }
    buf.flip();
    int bufSize=buf.limit();
    if (bufSize <= MAPPED_SIZE) {
      mappedByteBuffer.clear();
      int position=0;
      int count=fileChannel.write(buf,position);
      if (buf.hasRemaining()) {
        throw new IOException(""String_Node_Str"" + count + ""String_Node_Str""+ buf.remaining());
      }
 else {
        NetSystem.getInstance().getBufferPool().recycle(buf);
      }
      int tranfered=write0(position,count);
      netOutCounter++;
      netOutBytes+=tranfered;
      lastWriteTime=TimeUtil.currentTimeMillis();
    }
 else {
      int cnt=(bufSize / MAPPED_SIZE) + (bufSize % MAPPED_SIZE > 0 ? 1 : 0);
      int postion=0;
      for (int i=1; i <= cnt; i++) {
        int limit=MAPPED_SIZE * i;
        if (limit > bufSize) {
          limit=bufSize;
        }
        buf.position(postion);
        buf.limit(limit);
        ByteBuffer tmpBuf=buf.slice();
        mappedByteBuffer.clear();
        int count=fileChannel.write(tmpBuf,0);
        if (tmpBuf.hasRemaining()) {
          throw new IOException(""String_Node_Str"" + count + ""String_Node_Str""+ tmpBuf.remaining());
        }
        int tranfered=write0(0,count);
        postion+=tranfered;
        netOutCounter++;
        netOutBytes+=tranfered;
        lastWriteTime=TimeUtil.currentTimeMillis();
      }
      NetSystem.getInstance().getBufferPool().recycle(buf);
    }
  }
 catch (  IOException e) {
    LOGGER.error(""String_Node_Str"",e);
    this.close(""String_Node_Str"" + e);
  }
 finally {
    rwLock.set(false);
  }
}","@Override public void write(ByteBuffer buf){
  try {
    for (; ; ) {
      if (!rwLock.compareAndSet(false,true)) {
        break;
      }
    }
    buf.flip();
    int bufSize=buf.limit();
    if (bufSize <= MAPPED_SIZE) {
      mappedByteBuffer.clear();
      int position=0;
      int count=fileChannel.write(buf,position);
      if (buf.hasRemaining()) {
        throw new IOException(""String_Node_Str"" + count + ""String_Node_Str""+ buf.remaining());
      }
      int tranfered=write0(position,count);
      netOutCounter++;
      netOutBytes+=tranfered;
      lastWriteTime=TimeUtil.currentTimeMillis();
      NetSystem.getInstance().getBufferPool().recycle(buf);
    }
 else {
      int cnt=(bufSize / MAPPED_SIZE) + (bufSize % MAPPED_SIZE > 0 ? 1 : 0);
      int postion=0;
      for (int i=1; i <= cnt; i++) {
        int limit=MAPPED_SIZE * i;
        if (limit > bufSize) {
          limit=bufSize;
        }
        buf.position(postion);
        buf.limit(limit);
        ByteBuffer tmpBuf=buf.slice();
        mappedByteBuffer.clear();
        int count=fileChannel.write(tmpBuf,0);
        if (tmpBuf.hasRemaining()) {
          throw new IOException(""String_Node_Str"" + count + ""String_Node_Str""+ tmpBuf.remaining());
        }
        int tranfered=write0(0,count);
        postion+=tranfered;
        netOutCounter++;
        netOutBytes+=tranfered;
        lastWriteTime=TimeUtil.currentTimeMillis();
      }
      NetSystem.getInstance().getBufferPool().recycle(buf);
    }
  }
 catch (  IOException e) {
    LOGGER.error(""String_Node_Str"",e);
    this.close(""String_Node_Str"" + e);
  }
 finally {
    rwLock.set(false);
  }
}"
37486,"public ZeroCopyConnection(SocketChannel channel){
  super(channel);
  try {
    String path=System.getProperty(""String_Node_Str"");
    if (path == null) {
      if (JavaUtils.isLinux())       path=""String_Node_Str"";
 else       path=""String_Node_Str"";
    }
    this.fileName=path + id + ""String_Node_Str"";
    this.file=new File(this.fileName);
    ensureDirOK(this.file.getParent());
    this.randomAccessFile=new RandomAccessFile(file,""String_Node_Str"");
    this.randomAccessFile.setLength(MAPPED_SIZE);
    this.randomAccessFile.seek(0);
    this.fileChannel=randomAccessFile.getChannel();
    this.mappedByteBuffer=fileChannel.map(FileChannel.MapMode.READ_WRITE,0,MAPPED_SIZE);
  }
 catch (  IOException e) {
    LOGGER.error(""String_Node_Str"",e);
  }
}","public ZeroCopyConnection(SocketChannel channel){
  super(channel);
  try {
    this.fileName=MAPPED_PATH + id + MAPPED_SUFFIX;
    this.file=new File(this.fileName);
    this.randomAccessFile=new RandomAccessFile(file,""String_Node_Str"");
    this.randomAccessFile.setLength(MAPPED_SIZE);
    this.randomAccessFile.seek(0);
    this.fileChannel=randomAccessFile.getChannel();
    this.mappedByteBuffer=fileChannel.map(FileChannel.MapMode.READ_WRITE,0,MAPPED_SIZE);
  }
 catch (  IOException e) {
    LOGGER.error(""String_Node_Str"",e);
  }
}"
37487,"private void ensureDirOK(final String dirName){
  if (dirName != null) {
    File f=new File(dirName);
    if (!f.exists()) {
      boolean result=f.mkdirs();
      LOGGER.info(dirName + ""String_Node_Str"" + (result ? ""String_Node_Str"" : ""String_Node_Str""));
    }
  }
}","private static void ensureDirOK(String dirName){
  if (dirName != null) {
    File f=new File(dirName);
    if (!f.exists()) {
      boolean result=f.mkdirs();
      LOGGER.info(dirName + ""String_Node_Str"" + (result ? ""String_Node_Str"" : ""String_Node_Str""));
    }
 else {
      String[] mfList=f.list(new FilenameFilter(){
        @Override public boolean accept(        File dir,        String name){
          return name.endsWith(MAPPED_SUFFIX);
        }
      }
);
      if (mfList != null && mfList.length > 0) {
        for (        String mf : mfList) {
          File mff=new File(mf);
          if (mff != null && mff.exists()) {
            mff.delete();
            LOGGER.info(""String_Node_Str"",mff.getName());
          }
        }
      }
    }
  }
}"
37488,"/** 
 *  ---------------------------------------- USE [POOL_ID] RELOAD USER RELOAD ALL RELOAD FRONT RELOAD PATH RELOAD KAFKA RELOAD BIGKEY JVM  JAVA_HOME  ---------------------------------------- JVM JSTACK JVM JSTAT JVM JMAP_HISTO JVM JMAP_HEAP JVM PS SHOW USER SHOW USER_NET_IO  SHOW CPU SHOW MEM SHOW QPS SHOW CONN SHOW USER_CONN SHOW BUFFER SHOW BIGKEY SHOW BIGLENGTH SHOW SLOWKEY SHOW CMD SHOW USER_CMD SHOW USER_CMD_DETAIL USER SHOW VER SHOW NET_IO  SHOW NETBYTES SHOW VM SHOW POOL SHOW COST SHOW WAIT_COST SHOW USER_DAY_NET_IO SHOW POOL_NET_IO POOLNAME SHOW TOPIC SHOW LOG_ERROR SHOW LOG_WARN SHOW LOG_INFO SHOW LOG_DEBUG
 */
public static byte[] execute(final RedisRequest request,RedisFrontConnection frontCon){
  int numArgs=request.getNumArgs();
  if (numArgs != 2 && numArgs != 3 && numArgs != 4) {
    return ""String_Node_Str"".getBytes();
  }
  byte[] arg1=request.getArgs()[0];
  String arg2=new String(request.getArgs()[1]);
  if (arg1 == null || arg2 == null) {
    return ""String_Node_Str"".getBytes();
  }
  if (arg1.length == 3) {
    if ((arg1[0] == 'J' || arg1[0] == 'j') && (arg1[1] == 'V' || arg1[1] == 'v') && (arg1[2] == 'M' || arg1[2] == 'm')) {
      StringBuffer cmdBuffer=new StringBuffer();
      if (JavaUtils.isLinux())       cmdBuffer.append(JAVA_BIN_PATH);
      if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid());
        return encode(getOS_JVM_INFO(cmdBuffer.toString()));
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid());
        return encode(getOS_JVM_INFO(cmdBuffer.toString()));
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid());
        return encode(getOS_JVM_INFO(cmdBuffer.toString()));
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid());
        return encode(getOS_JVM_INFO(cmdBuffer.toString()));
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        String cmd=""String_Node_Str"" + JavaUtils.process_pid() + ""String_Node_Str"";
        List<String> line=new ArrayList<String>();
        try {
          line.add(ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",cmd));
        }
 catch (        IOException e) {
          line.add(e.getMessage());
        }
        return encode(line);
      }
    }
 else     if ((arg1[0] == 'U' || arg1[0] == 'u') && (arg1[1] == 'S' || arg1[1] == 's') && (arg1[2] == 'E' || arg1[2] == 'e')) {
      try {
        int poolId=Integer.parseInt(arg2);
        AbstractPool pool=RedisEngineCtx.INSTANCE().getPoolMap().get(poolId);
        if (pool == null) {
          return ""String_Node_Str"".getBytes();
        }
 else {
          int poolType=pool.getType();
          frontCon.getUserCfg().setUsePool(poolId,poolType);
          return ""String_Node_Str"".getBytes();
        }
      }
 catch (      NumberFormatException e) {
        return ""String_Node_Str"".getBytes();
      }
    }
  }
 else   if (arg1.length == 4) {
    if ((arg1[0] == 'S' || arg1[0] == 's') && (arg1[1] == 'H' || arg1[1] == 'h') && (arg1[2] == 'O' || arg1[2] == 'o')&& (arg1[3] == 'W' || arg1[3] == 'w')) {
      if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        AccessStatInfoResult result=StatUtil.getTotalAccessStatInfo().get(StatUtil.STAT_KEY);
        if (result != null) {
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(""String_Node_Str"").append(result.totalCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.slowCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.waitSlowCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.maxCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.minCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.avgCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.procTime).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.waitTime).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.created);
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<Object> lines=new ArrayList<Object>();
        long sum=0;
        Set<Entry<String,Command>> entrys=StatUtil.getCommandCountMap().entrySet();
        for (        Entry<String,Command> entry : entrys) {
          Command parent=entry.getValue();
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(parent.cmd).append(""String_Node_Str"").append(parent.count.get());
          if (parent.childs != null) {
            List<String> list=new ArrayList<String>();
            list.add(sBuffer.toString());
            for (            Entry<String,Command> childEntry : parent.childs.entrySet()) {
              Command child=childEntry.getValue();
              StringBuffer sb=new StringBuffer();
              sb.append(""String_Node_Str"").append(child.cmd).append(""String_Node_Str"").append(child.count.get());
              list.add(sb.toString());
            }
            lines.add(list);
          }
 else {
            lines.add(sBuffer.toString());
          }
          sum+=parent.count.get();
        }
        StringBuffer sBuffer=new StringBuffer();
        sBuffer.append(""String_Node_Str"").append(""String_Node_Str"").append(sum);
        lines.add(sBuffer.toString());
        return encodeObject(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer title=new StringBuffer();
        title.append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"");
        lines.add(title.toString());
        Set<Entry<String,UserCommand>> entrys=StatUtil.getUserCommandCountMap().entrySet();
        for (        Entry<String,UserCommand> entry : entrys) {
          UserCommand userCommand=entry.getValue();
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(userCommand.user).append(""String_Node_Str"").append(userCommand.readComandCount.get()).append(""String_Node_Str"").append(userCommand.writeCommandCount.get()).append(""String_Node_Str"").append(userCommand.readComandCount.get() + userCommand.writeCommandCount.get());
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") && numArgs == 3) {
        String user=new String(request.getArgs()[2]);
        List<String> lines=new ArrayList<String>();
        StringBuffer title=new StringBuffer();
        title.append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"");
        lines.add(title.toString());
        int sum=0;
        ConcurrentHashMap<String,UserCommand> userCommandMap=StatUtil.getUserCommandCountMap();
        UserCommand userCommand=userCommandMap.get(user);
        if (userCommand != null) {
          for (          Entry<String,AtomicLong> entry : userCommand.commandCount.entrySet()) {
            StringBuffer sBuffer=new StringBuffer();
            sBuffer.append(user).append(""String_Node_Str"").append(entry.getKey()).append(""String_Node_Str"").append(entry.getValue().get());
            lines.add(sBuffer.toString());
          }
        }
        StringBuffer end=new StringBuffer();
        end.append(""String_Node_Str"").append(""String_Node_Str"").append(sum);
        lines.add(end.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        lines.add(Versions.SERVER_VERSION);
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        if (JavaUtils.isLinux()) {
          StringBuffer cmdBuffer=new StringBuffer();
          cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid()).append(""String_Node_Str"");
          String response;
          try {
            response=ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",cmdBuffer.toString());
            lines.add(response);
          }
 catch (          IOException e) {
            LOGGER.error(""String_Node_Str"",e);
            lines.add(""String_Node_Str"");
          }
        }
 else {
          lines.add(""String_Node_Str"");
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        lines.add(""String_Node_Str"" + JavaUtils.bytesToString2(Math.round(JavaUtils.getMemUsage())));
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        int frontSize=0;
        int backendSize=0;
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisFrontConnection) {
            frontSize++;
          }
 else {
            backendSize++;
          }
        }
        StringBuffer sBuffer=new StringBuffer();
        sBuffer.append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"").append(frontSize).append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"").append(backendSize).append(""String_Node_Str"");
        return sBuffer.toString().getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        Map<String,Integer> userMap=new HashMap<String,Integer>();
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof ClosableConnection) {
            userMap.put(((RedisFrontConnection)c).getPassword(),1 + (userMap.get(((RedisFrontConnection)c).getPassword()) == null ? 0 : userMap.get(((RedisFrontConnection)c).getPassword())));
          }
        }
        StringBuffer sBuffer=new StringBuffer();
        sBuffer.append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"");
        Iterator<Entry<String,Integer>> users=userMap.entrySet().iterator();
        while (users.hasNext()) {
          sBuffer.append(""String_Node_Str"");
          Entry<String,Integer> en=users.next();
          sBuffer.append(en.getKey());
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(en.getValue());
        }
        sBuffer.append(""String_Node_Str"");
        return sBuffer.toString().getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        ConcurrentHashMap<String,AccessStatInfoResult> results=StatUtil.getTotalAccessStatInfo();
        for (        Map.Entry<String,AccessStatInfoResult> entry : results.entrySet()) {
          AccessStatInfoResult result=entry.getValue();
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(""String_Node_Str"").append(result.key).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.totalCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.slowCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.maxCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.minCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.avgCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.procTime).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netInBytes[1]).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netInBytes[2]).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netInBytes[3]).append(""String_Node_Str"").append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netOutBytes[1]).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netOutBytes[2]).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netOutBytes[3]).append(""String_Node_Str"").append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.created);
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisFrontConnection) {
            lines.add(c.toString());
          }
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        BufferPool bufferPool=NetSystem.getInstance().getBufferPool();
        long usedBufferSize=bufferPool.getUsedBufferSize().get();
        long maxBufferSize=bufferPool.getMaxBufferSize();
        long minBufferSize=bufferPool.getMinBufferSize();
        long sharedOptsCount=bufferPool.getSharedOptsCount();
        int capacity=0;
        if (bufferPool instanceof BucketBufferPool) {
          BucketBufferPool p=(BucketBufferPool)bufferPool;
          AbstractBucket[] buckets=p.buckets();
          for (          AbstractBucket b : buckets) {
            capacity+=b.getCount();
          }
          int bucketLen=buckets.length;
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(capacity).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(minBufferSize).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(maxBufferSize).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(usedBufferSize).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(bucketLen).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(sharedOptsCount).append(""String_Node_Str"");
          return sBuffer.toString().getBytes();
        }
 else         if (bufferPool instanceof PageBufferPool) {
          List<String> lines=new ArrayList<String>();
          ConcurrentHashMap<Long,Long> bufferpoolUsageMap=bufferPool.getNetDirectMemoryUsage();
          long usedforNetwork=0;
          for (          Map.Entry<Long,Long> entry : bufferpoolUsageMap.entrySet()) {
            long value=entry.getValue();
            lines.add(""String_Node_Str"" + entry.getKey() + ""String_Node_Str""+ (value > 0 ? JavaUtils.bytesToString2(value) : ""String_Node_Str""));
            usedforNetwork=usedforNetwork + value;
          }
          lines.add(""String_Node_Str"" + JavaUtils.bytesToString2(minBufferSize));
          lines.add(""String_Node_Str"" + JavaUtils.bytesToString2(maxBufferSize));
          lines.add(""String_Node_Str"" + JavaUtils.bytesToString2(usedforNetwork));
          return encode(lines);
        }
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        BufferPool bufferPool=NetSystem.getInstance().getBufferPool();
        if (bufferPool instanceof BucketBufferPool) {
          BucketBufferPool p=(BucketBufferPool)bufferPool;
          AbstractBucket[] buckets=p.buckets();
          for (          AbstractBucket b : buckets) {
            StringBuffer sBuffer=new StringBuffer();
            sBuffer.append(""String_Node_Str"").append(b.getChunkSize()).append(""String_Node_Str"");
            sBuffer.append(""String_Node_Str"").append(b.getQueueSize()).append(""String_Node_Str"");
            sBuffer.append(""String_Node_Str"").append(b.getCount()).append(""String_Node_Str"");
            sBuffer.append(""String_Node_Str"").append(b.getUsedCount()).append(""String_Node_Str"");
            sBuffer.append(""String_Node_Str"").append(b.getShared());
            lines.add(sBuffer.toString());
          }
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        for (        BigKey bigkey : StatUtil.getBigKeys()) {
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(bigkey.lastCmd).append(""String_Node_Str"");
          sBuffer.append(bigkey.key).append(""String_Node_Str"");
          sBuffer.append(bigkey.size).append(""String_Node_Str"");
          sBuffer.append(bigkey.count.get());
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        Map<String,AtomicInteger> poolConnections=new HashMap<String,AtomicInteger>();
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisBackendConnection) {
            String poolName=((RedisBackendConnection)c).getPhysicalNode().getPoolName();
            AtomicInteger poolConnCount=poolConnections.get(poolName);
            if (poolConnCount == null) {
              poolConnections.put(poolName,new AtomicInteger(1));
            }
 else {
              poolConnCount.incrementAndGet();
            }
            lines.add(c.toString());
          }
 else           if (c instanceof KafkaBackendConnection) {
            String poolName=((KafkaBackendConnection)c).getPhysicalNode().getPoolName();
            AtomicInteger poolConnCount=poolConnections.get(poolName);
            if (poolConnCount == null) {
              poolConnections.put(poolName,new AtomicInteger(1));
            }
 else {
              poolConnCount.incrementAndGet();
            }
            lines.add(c.toString());
          }
        }
        StringBuffer sb=new StringBuffer();
        for (        Map.Entry<String,AtomicInteger> entry : poolConnections.entrySet()) {
          sb.append(entry.getKey()).append(""String_Node_Str"").append(entry.getValue().get()).append(""String_Node_Str"");
        }
        lines.add(sb.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") && numArgs == 3) {
        List<String> lines=new ArrayList<String>();
        long minStartupTime=-1;
        long totalNetInCounter=0;
        long totalNetInBytes=0;
        long totalNetOutCounter=0;
        long totalNetOutBytes=0;
        String poolName=new String(request.getArgs()[2]);
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisBackendConnection) {
            if (((RedisBackendConnection)c).getPhysicalNode().getPoolName().equals(poolName)) {
              StringBuffer sb=new StringBuffer();
              sb.append(""String_Node_Str"").append(c.getId()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(c.getStartupTime()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(c.getNetInCounter()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(c.getNetInBytes()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(c.getNetOutBytes()).append(""String_Node_Str"");
              lines.add(sb.toString());
              minStartupTime=minStartupTime < 0 ? c.getStartupTime() : Math.min(minStartupTime,c.getStartupTime());
              totalNetInCounter+=c.getNetInCounter();
              totalNetInBytes+=c.getNetInBytes();
              totalNetOutCounter+=c.getNetOutCounter();
              totalNetOutBytes+=c.getNetOutBytes();
            }
          }
        }
        StringBuffer end=new StringBuffer();
        end.append(""String_Node_Str"").append(minStartupTime).append(""String_Node_Str"");
        end.append(""String_Node_Str"").append(totalNetInCounter).append(""String_Node_Str"");
        end.append(""String_Node_Str"").append(totalNetInBytes).append(""String_Node_Str"");
        end.append(""String_Node_Str"").append(totalNetOutCounter).append(""String_Node_Str"");
        end.append(""String_Node_Str"").append(totalNetOutBytes).append(""String_Node_Str"");
        lines.add(end.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") || arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        AccessStatInfoResult result=StatUtil.getTotalAccessStatInfo().get(StatUtil.STAT_KEY);
        if (result != null) {
          StringBuffer line0=new StringBuffer();
          line0.append(""String_Node_Str"").append(""String_Node_Str"");
          line0.append(""String_Node_Str"").append(""String_Node_Str"");
          line0.append(""String_Node_Str"").append(""String_Node_Str"");
          line0.append(""String_Node_Str"").append(""String_Node_Str"");
          line0.append(""String_Node_Str"");
          StringBuffer line1=new StringBuffer();
          line1.append(""String_Node_Str"").append(""String_Node_Str"");
          line1.append(result.netInBytes[0]).append(""String_Node_Str"");
          line1.append(result.netInBytes[1]).append(""String_Node_Str"");
          line1.append(result.netInBytes[2]).append(""String_Node_Str"");
          line1.append(result.netInBytes[3]);
          StringBuffer line2=new StringBuffer();
          line2.append(""String_Node_Str"").append(""String_Node_Str"");
          line2.append(result.netOutBytes[0]).append(""String_Node_Str"");
          line2.append(result.netOutBytes[1]).append(""String_Node_Str"");
          line2.append(result.netOutBytes[2]).append(""String_Node_Str"");
          line2.append(result.netOutBytes[3]);
          StringBuffer line3=new StringBuffer();
          line3.append(result.created);
          lines.add(line0.toString());
          lines.add(line1.toString());
          lines.add(line2.toString());
          lines.add(line3.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        for (        Map.Entry<String,AccessStatInfoResult> entry : StatUtil.getTotalAccessStatInfo().entrySet()) {
          if (!StatUtil.STAT_KEY.equals(entry.getKey())) {
            AccessStatInfoResult result=entry.getValue();
            StringBuffer line1=new StringBuffer();
            line1.append(result.key).append(""String_Node_Str"");
            line1.append(""String_Node_Str"").append(""String_Node_Str"");
            line1.append(result.netInBytes[0]).append(""String_Node_Str"");
            line1.append(result.netInBytes[1]).append(""String_Node_Str"");
            line1.append(result.netInBytes[2]).append(""String_Node_Str"");
            line1.append(result.netInBytes[3]);
            StringBuffer line2=new StringBuffer();
            line2.append(result.key).append(""String_Node_Str"");
            line2.append(""String_Node_Str"").append(""String_Node_Str"");
            line2.append(result.netOutBytes[0]).append(""String_Node_Str"");
            line2.append(result.netOutBytes[1]).append(""String_Node_Str"");
            line2.append(result.netOutBytes[2]).append(""String_Node_Str"");
            line2.append(result.netOutBytes[3]);
            StringBuffer line3=new StringBuffer();
            line3.append(result.created);
            lines.add(line1.toString());
            lines.add(line2.toString());
            lines.add(line3.toString());
          }
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        long totalNetIn=0;
        long totalNetOut=0;
        for (        Map.Entry<String,UserNetFlow> entry : StatUtil.getUserFlowMap().entrySet()) {
          if (!StatUtil.STAT_KEY.equals(entry.getKey())) {
            StringBuffer sb=new StringBuffer();
            UserNetFlow userNetIo=entry.getValue();
            sb.append(userNetIo.password).append(""String_Node_Str"");
            sb.append(JavaUtils.bytesToString2(userNetIo.netIn.get())).append(""String_Node_Str"");
            sb.append(JavaUtils.bytesToString2(userNetIo.netOut.get()));
            totalNetIn=totalNetIn + userNetIo.netIn.get();
            totalNetOut=totalNetOut + userNetIo.netOut.get();
            lines.add(sb.toString());
          }
        }
        StringBuffer total=new StringBuffer();
        total.append(""String_Node_Str"").append(""String_Node_Str"");
        total.append(JavaUtils.bytesToString2(totalNetIn)).append(""String_Node_Str"");
        total.append(JavaUtils.bytesToString2(totalNetOut));
        lines.add(total.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=showLog(request,""String_Node_Str"");
        return encode2(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=showLog(request,""String_Node_Str"");
        return encode2(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=showLog(request,""String_Node_Str"");
        return encode2(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=showLog(request,""String_Node_Str"");
        return encode2(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> ret=new ArrayList<String>();
        try {
          String resp=ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"");
          StringBuilder sb=new StringBuilder();
          sb.append(resp);
          sb.append(""String_Node_Str"");
          String[] lines=sb.toString().split(""String_Node_Str"");
          ret.add(""String_Node_Str"");
          for (int i=1; i < lines.length; i++) {
            if (lines[i].equals(""String_Node_Str""))             continue;
            ret.add(lines[i]);
          }
        }
 catch (        IOException e) {
          LOGGER.error(""String_Node_Str"",e);
          ret.add(""String_Node_Str"");
        }
        return encode2(ret);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> ret=new ArrayList<String>();
        try {
          String cmd1=ShellUtils.osType == ShellUtils.OSType.OS_TYPE_MAC ? ""String_Node_Str"" : ""String_Node_Str"";
          String cmd2=ShellUtils.osType == ShellUtils.OSType.OS_TYPE_MAC ? ""String_Node_Str"" : ""String_Node_Str"";
          String iostatOut=ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",cmd1);
          String vmstatOut=ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",cmd2);
          StringBuilder sb=new StringBuilder();
          sb.append(iostatOut);
          sb.append(""String_Node_Str"");
          sb.append(""String_Node_Str"");
          sb.append(vmstatOut);
          String[] lines=sb.toString().split(""String_Node_Str"");
          ret.add(""String_Node_Str"");
          for (int i=1; i < lines.length; i++) {
            if (lines[i].equals(""String_Node_Str""))             continue;
            ret.add(lines[i]);
          }
        }
 catch (        IOException e) {
          LOGGER.error(""String_Node_Str"",e);
          ret.add(""String_Node_Str"");
        }
        return encode2(ret);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<Object> list=new ArrayList<Object>();
        Map<Integer,AbstractPool> pools=RedisEngineCtx.INSTANCE().getPoolMap();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        list.add(titleLine.toString());
        for (        AbstractPool pool : pools.values()) {
          if (pool instanceof RedisStandalonePool) {
            StringBuffer sb=new StringBuffer();
            RedisStandalonePool redisStandalonePool=(RedisStandalonePool)pool;
            PhysicalNode physicalNode=redisStandalonePool.getPhysicalNode();
            if (physicalNode == null)             continue;
            sb.append(""String_Node_Str"");
            sb.append(redisStandalonePool.getId()).append(""String_Node_Str"");
            sb.append(physicalNode.getPoolName()).append(""String_Node_Str"");
            sb.append(""String_Node_Str"").append(""String_Node_Str"");
            sb.append(physicalNode.getName()).append(""String_Node_Str"");
            sb.append(physicalNode.getMinCon()).append(""String_Node_Str"");
            sb.append(physicalNode.getMaxCon()).append(""String_Node_Str"");
            sb.append(physicalNode.getIdleCount()).append(""String_Node_Str"");
            sb.append(physicalNode.getActiveCount());
            list.add(sb.toString());
          }
 else           if (pool instanceof RedisClusterPool) {
            RedisClusterPool redisClusterPool=(RedisClusterPool)pool;
            Map<String,ClusterNode> masters=redisClusterPool.getMasters();
            List<String> clusterInfo=new ArrayList<String>();
            for (            ClusterNode clusterNode : masters.values()) {
              PhysicalNode physicalNode=clusterNode.getPhysicalNode();
              StringBuffer sb=new StringBuffer();
              sb.append(redisClusterPool.getId()).append(""String_Node_Str"");
              sb.append(physicalNode.getPoolName()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(""String_Node_Str"");
              sb.append(physicalNode.getName()).append(""String_Node_Str"");
              sb.append(physicalNode.getMinCon()).append(""String_Node_Str"");
              sb.append(physicalNode.getMaxCon()).append(""String_Node_Str"");
              sb.append(physicalNode.getIdleCount()).append(""String_Node_Str"");
              sb.append(physicalNode.getActiveCount()).append(""String_Node_Str"");
              ;
              sb.append(!clusterNode.isFail());
              clusterInfo.add(sb.toString());
              sb.append(clusterNode.getConnectInfo());
            }
            list.add(clusterInfo);
          }
 else           if (pool instanceof KafkaPool) {
            KafkaPool kafkaPool=(KafkaPool)pool;
            Map<Integer,PhysicalNode> physicalNodes=kafkaPool.getPhysicalNodes();
            for (            PhysicalNode physicalNode : physicalNodes.values()) {
              StringBuffer sb=new StringBuffer();
              sb.append(""String_Node_Str"");
              sb.append(kafkaPool.getId()).append(""String_Node_Str"");
              sb.append(physicalNode.getPoolName()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(""String_Node_Str"");
              sb.append(physicalNode.getName()).append(""String_Node_Str"");
              sb.append(physicalNode.getMinCon()).append(""String_Node_Str"");
              sb.append(physicalNode.getMaxCon()).append(""String_Node_Str"");
              sb.append(physicalNode.getIdleCount()).append(""String_Node_Str"");
              sb.append(physicalNode.getActiveCount());
              list.add(sb.toString());
            }
          }
        }
        return encodeObject(list);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        Collection<Entry<String,AtomicLong>> entrys=StatUtil.getCommandProcTimeMap().entrySet();
        List<String> lines=new ArrayList<String>();
        for (        Entry<String,AtomicLong> entry : entrys) {
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(entry.getKey()).append(""String_Node_Str"").append(entry.getValue().get());
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        Collection<Entry<String,AtomicLong>> entrys=StatUtil.getCommandWaitTimeMap().entrySet();
        List<String> lines=new ArrayList<String>();
        for (        Entry<String,AtomicLong> entry : entrys) {
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(entry.getKey()).append(""String_Node_Str"").append(entry.getValue().get());
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        for (        BigLength bigLength : StatUtil.getBigLengthMap().values()) {
          StringBuffer line1=new StringBuffer();
          line1.append(bigLength.cmd).append(""String_Node_Str"");
          line1.append(bigLength.key).append(""String_Node_Str"");
          line1.append(bigLength.length.get()).append(""String_Node_Str"");
          line1.append(bigLength.count_1k.get()).append(""String_Node_Str"");
          line1.append(bigLength.count_10k.get());
          lines.add(line1.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        for (        SlowKey slowKey : StatUtil.getSlowKey()) {
          StringBuffer line1=new StringBuffer();
          line1.append(slowKey.cmd).append(""String_Node_Str"");
          line1.append(slowKey.key).append(""String_Node_Str"");
          line1.append(slowKey.count);
          lines.add(line1.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") && (numArgs == 3 || numArgs == 2)) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        if (numArgs == 2) {
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"");
        }
 else {
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"");
        }
        lines.add(titleLine.toString());
        final Map<Integer,PoolCfg> poolCfgMap=RedisEngineCtx.INSTANCE().getPoolCfgMap();
        for (        Entry<Integer,PoolCfg> poolEntry : poolCfgMap.entrySet()) {
          PoolCfg poolCfg=poolEntry.getValue();
          if (poolCfg instanceof KafkaPoolCfg) {
            Map<String,TopicCfg> kafkaMap=((KafkaPoolCfg)poolCfg).getTopicCfgMap();
            if (numArgs == 2) {
              for (              Entry<String,TopicCfg> kafkaEntry : kafkaMap.entrySet()) {
                TopicCfg kafkaCfg=kafkaEntry.getValue();
                StringBuffer line=new StringBuffer();
                line.append(kafkaCfg.getName()).append(""String_Node_Str"");
                line.append(kafkaCfg.getPoolId()).append(""String_Node_Str"");
                line.append(kafkaCfg.getPartitions()).append(""String_Node_Str"");
                line.append(kafkaCfg.getReplicationFactor()).append(""String_Node_Str"");
                line.append(kafkaCfg.getProducers()).append(""String_Node_Str"");
                line.append(kafkaCfg.getConsumers());
                lines.add(line.toString());
              }
            }
 else {
              String topic=new String(request.getArgs()[2]);
              TopicCfg kafkaCfg=kafkaMap.get(topic);
              if (kafkaCfg != null) {
                for (                BrokerPartition partition : kafkaCfg.getRunningInfo().getPartitions().values()) {
                  int pt=partition.getPartition();
                  StringBuffer line=new StringBuffer();
                  line.append(kafkaCfg.getName()).append(""String_Node_Str"");
                  line.append(partition.getLeader().getHost()).append(partition.getLeader().getPort()).append(""String_Node_Str"");
                  line.append(pt).append(""String_Node_Str"");
                  line.append(partition.getLogStartOffset()).append(""String_Node_Str"");
                  line.append(partition.getProducerOffset()).append(""String_Node_Str"");
                  for (                  ConsumerOffset consumerOffset : partition.getConsumerOffsets().values()) {
                    line.append(consumerOffset.getConsumer());
                    line.append(""String_Node_Str"");
                    line.append(consumerOffset.getCurrentOffset());
                    line.append(""String_Node_Str"");
                  }
                  lines.add(line.toString());
                }
              }
            }
          }
        }
        return encode(lines);
      }
    }
 else     if ((arg1[0] == 'N' || arg1[0] == 'n') && (arg1[1] == 'O' || arg1[1] == 'o') && (arg1[2] == 'D' || arg1[2] == 'd')&& (arg1[3] == 'E' || arg1[3] == 'e')) {
      return ""String_Node_Str"".getBytes();
    }
  }
 else   if (arg1.length == 6) {
    if ((arg1[0] == 'R' || arg1[0] == 'r') && (arg1[1] == 'E' || arg1[1] == 'e') && (arg1[2] == 'L' || arg1[2] == 'l')&& (arg1[3] == 'O' || arg1[3] == 'o')&& (arg1[4] == 'A' || arg1[4] == 'a')&& (arg1[5] == 'D' || arg1[5] == 'd')) {
      if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        byte[] buff=RedisEngineCtx.INSTANCE().reloadAll();
        return buff;
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        byte[] buff=RedisEngineCtx.INSTANCE().reloadUser();
        return buff;
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisFrontConnection) {
            LOGGER.info(""String_Node_Str"",c);
            c.close(""String_Node_Str"");
          }
        }
        return ""String_Node_Str"".getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        JAVA_BIN_PATH=new String(request.getArgs()[2]);
        return ""String_Node_Str"".getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        try {
          Map<Integer,PoolCfg> poolCfgMap=RedisEngineCtx.INSTANCE().getPoolCfgMap();
          for (          PoolCfg poolCfg : poolCfgMap.values()) {
            if (poolCfg instanceof KafkaPoolCfg)             poolCfg.reloadExtraCfg();
          }
        }
 catch (        Exception e) {
          LOGGER.error(""String_Node_Str"",e);
          StringBuffer sb=new StringBuffer();
          sb.append(""String_Node_Str"").append(e.getMessage()).append(""String_Node_Str"");
          return sb.toString().getBytes();
        }
        return ""String_Node_Str"".getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        byte[] buff=BypassService.INSTANCE().reload();
        return buff;
      }
    }
  }
 else   if (arg1.length == 7) {
    if ((arg1[0] == 'C' || arg1[0] == 'c') && (arg1[1] == 'L' || arg1[1] == 'l') && (arg1[2] == 'U' || arg1[2] == 'u')&& (arg1[3] == 'S' || arg1[3] == 's')&& (arg1[4] == 'T' || arg1[4] == 't')&& (arg1[5] == 'E' || arg1[5] == 'e')&& (arg1[6] == 'R' || arg1[6] == 'r')) {
      AbstractPool pool=RedisEngineCtx.INSTANCE().getPoolMap().get(frontCon.getUserCfg().getPoolId());
      if (pool.getType() != 1) {
        return ""String_Node_Str"".getBytes();
      }
      PhysicalNode pysicalNode=((RedisClusterPool)pool).getPhysicalNodeBySlot(0);
      if (pysicalNode == null) {
        return ""String_Node_Str"".getBytes();
      }
      try {
        RedisBackendConnection backendCon=(RedisBackendConnection)pysicalNode.getConnection(new DirectTransTofrontCallBack(),frontCon);
        if (backendCon == null) {
          frontCon.writeErrMessage(""String_Node_Str"");
        }
 else {
          backendCon.write(request.encode());
        }
        return null;
      }
 catch (      IOException e) {
        LOGGER.error(""String_Node_Str"",e);
      }
    }
  }
  return ""String_Node_Str"".getBytes();
}","/** 
 *  ---------------------------------------- USE [POOL_ID] RELOAD USER RELOAD ALL RELOAD FRONT RELOAD PATH RELOAD KAFKA RELOAD BIGKEY JVM  JAVA_HOME  ---------------------------------------- JVM JSTACK JVM JSTAT JVM JMAP_HISTO JVM JMAP_HEAP JVM PS SHOW USER SHOW USER_NET_IO  SHOW CPU SHOW MEM SHOW QPS SHOW CONN SHOW USER_CONN SHOW BUFFER SHOW BIGKEY SHOW BIGLENGTH SHOW SLOWKEY SHOW CMD SHOW USER_CMD SHOW USER_CMD_DETAIL USER SHOW VER SHOW NET_IO  SHOW NETBYTES SHOW VM SHOW POOL SHOW COST SHOW WAIT_COST SHOW USER_DAY_NET_IO SHOW POOL_NET_IO POOLNAME SHOW TOPIC SHOW LOG_ERROR SHOW LOG_WARN SHOW LOG_INFO SHOW LOG_DEBUG
 */
public static byte[] execute(final RedisRequest request,RedisFrontConnection frontCon){
  int numArgs=request.getNumArgs();
  if (numArgs != 2 && numArgs != 3 && numArgs != 4) {
    return ""String_Node_Str"".getBytes();
  }
  byte[] arg1=request.getArgs()[0];
  String arg2=new String(request.getArgs()[1]);
  if (arg1 == null || arg2 == null) {
    return ""String_Node_Str"".getBytes();
  }
  if (arg1.length == 3) {
    if ((arg1[0] == 'J' || arg1[0] == 'j') && (arg1[1] == 'V' || arg1[1] == 'v') && (arg1[2] == 'M' || arg1[2] == 'm')) {
      StringBuffer cmdBuffer=new StringBuffer();
      if (JavaUtils.isLinux())       cmdBuffer.append(JAVA_BIN_PATH);
      if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid());
        return encode(getOS_JVM_INFO(cmdBuffer.toString()));
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid());
        return encode(getOS_JVM_INFO(cmdBuffer.toString()));
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid());
        return encode(getOS_JVM_INFO(cmdBuffer.toString()));
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid());
        return encode(getOS_JVM_INFO(cmdBuffer.toString()));
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        String cmd=""String_Node_Str"" + JavaUtils.process_pid() + ""String_Node_Str"";
        List<String> line=new ArrayList<String>();
        try {
          line.add(ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",cmd));
        }
 catch (        IOException e) {
          line.add(e.getMessage());
        }
        return encode(line);
      }
    }
 else     if ((arg1[0] == 'U' || arg1[0] == 'u') && (arg1[1] == 'S' || arg1[1] == 's') && (arg1[2] == 'E' || arg1[2] == 'e')) {
      try {
        int poolId=Integer.parseInt(arg2);
        AbstractPool pool=RedisEngineCtx.INSTANCE().getPoolMap().get(poolId);
        if (pool == null) {
          return ""String_Node_Str"".getBytes();
        }
 else {
          int poolType=pool.getType();
          frontCon.getUserCfg().setUsePool(poolId,poolType);
          return ""String_Node_Str"".getBytes();
        }
      }
 catch (      NumberFormatException e) {
        return ""String_Node_Str"".getBytes();
      }
    }
  }
 else   if (arg1.length == 4) {
    if ((arg1[0] == 'S' || arg1[0] == 's') && (arg1[1] == 'H' || arg1[1] == 'h') && (arg1[2] == 'O' || arg1[2] == 'o')&& (arg1[3] == 'W' || arg1[3] == 'w')) {
      if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        AccessStatInfoResult result=StatUtil.getTotalAccessStatInfo().get(StatUtil.STAT_KEY);
        if (result != null) {
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(""String_Node_Str"").append(result.totalCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.slowCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.waitSlowCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.maxCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.minCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.avgCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.procTime).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.waitTime).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.created);
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<Object> lines=new ArrayList<Object>();
        long sum=0;
        Set<Entry<String,Command>> entrys=StatUtil.getCommandCountMap().entrySet();
        for (        Entry<String,Command> entry : entrys) {
          Command parent=entry.getValue();
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(parent.cmd).append(""String_Node_Str"").append(parent.count.get());
          if (parent.childs != null) {
            List<String> list=new ArrayList<String>();
            list.add(sBuffer.toString());
            for (            Entry<String,Command> childEntry : parent.childs.entrySet()) {
              Command child=childEntry.getValue();
              StringBuffer sb=new StringBuffer();
              sb.append(""String_Node_Str"").append(child.cmd).append(""String_Node_Str"").append(child.count.get());
              list.add(sb.toString());
            }
            lines.add(list);
          }
 else {
            lines.add(sBuffer.toString());
          }
          sum+=parent.count.get();
        }
        StringBuffer sBuffer=new StringBuffer();
        sBuffer.append(""String_Node_Str"").append(""String_Node_Str"").append(sum);
        lines.add(sBuffer.toString());
        return encodeObject(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer title=new StringBuffer();
        title.append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"");
        lines.add(title.toString());
        Set<Entry<String,UserCommand>> entrys=StatUtil.getUserCommandCountMap().entrySet();
        for (        Entry<String,UserCommand> entry : entrys) {
          UserCommand userCommand=entry.getValue();
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(userCommand.user).append(""String_Node_Str"").append(userCommand.readComandCount.get()).append(""String_Node_Str"").append(userCommand.writeCommandCount.get()).append(""String_Node_Str"").append(userCommand.readComandCount.get() + userCommand.writeCommandCount.get());
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") && numArgs == 3) {
        String user=new String(request.getArgs()[2]);
        List<String> lines=new ArrayList<String>();
        StringBuffer title=new StringBuffer();
        title.append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"");
        lines.add(title.toString());
        int sum=0;
        ConcurrentHashMap<String,UserCommand> userCommandMap=StatUtil.getUserCommandCountMap();
        UserCommand userCommand=userCommandMap.get(user);
        if (userCommand != null) {
          for (          Entry<String,AtomicLong> entry : userCommand.commandCount.entrySet()) {
            StringBuffer sBuffer=new StringBuffer();
            sBuffer.append(user).append(""String_Node_Str"").append(entry.getKey()).append(""String_Node_Str"").append(entry.getValue().get());
            lines.add(sBuffer.toString());
          }
        }
        StringBuffer end=new StringBuffer();
        end.append(""String_Node_Str"").append(""String_Node_Str"").append(sum);
        lines.add(end.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        lines.add(Versions.SERVER_VERSION);
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        if (JavaUtils.isLinux()) {
          StringBuffer cmdBuffer=new StringBuffer();
          cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid()).append(""String_Node_Str"");
          String response;
          try {
            response=ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",cmdBuffer.toString());
            lines.add(response);
          }
 catch (          IOException e) {
            LOGGER.error(""String_Node_Str"",e);
            lines.add(""String_Node_Str"");
          }
        }
 else {
          lines.add(""String_Node_Str"");
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        lines.add(""String_Node_Str"" + JavaUtils.bytesToString2(Math.round(JavaUtils.getMemUsage())));
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        int frontSize=0;
        int backendSize=0;
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisFrontConnection) {
            frontSize++;
          }
 else {
            backendSize++;
          }
        }
        StringBuffer sBuffer=new StringBuffer();
        sBuffer.append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"").append(frontSize).append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"").append(backendSize).append(""String_Node_Str"");
        return sBuffer.toString().getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        Map<String,Integer> userMap=new HashMap<String,Integer>();
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisFrontConnection) {
            userMap.put(((RedisFrontConnection)c).getPassword(),1 + (userMap.get(((RedisFrontConnection)c).getPassword()) == null ? 0 : userMap.get(((RedisFrontConnection)c).getPassword())));
          }
        }
        StringBuffer sBuffer=new StringBuffer();
        sBuffer.append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"");
        Iterator<Entry<String,Integer>> users=userMap.entrySet().iterator();
        while (users.hasNext()) {
          sBuffer.append(""String_Node_Str"");
          Entry<String,Integer> en=users.next();
          sBuffer.append(en.getKey());
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(en.getValue());
        }
        sBuffer.append(""String_Node_Str"");
        return sBuffer.toString().getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        ConcurrentHashMap<String,AccessStatInfoResult> results=StatUtil.getTotalAccessStatInfo();
        for (        Map.Entry<String,AccessStatInfoResult> entry : results.entrySet()) {
          AccessStatInfoResult result=entry.getValue();
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(""String_Node_Str"").append(result.key).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.totalCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.slowCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.maxCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.minCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.avgCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.procTime).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netInBytes[1]).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netInBytes[2]).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netInBytes[3]).append(""String_Node_Str"").append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netOutBytes[1]).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netOutBytes[2]).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netOutBytes[3]).append(""String_Node_Str"").append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.created);
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisFrontConnection) {
            lines.add(c.toString());
          }
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        BufferPool bufferPool=NetSystem.getInstance().getBufferPool();
        long usedBufferSize=bufferPool.getUsedBufferSize().get();
        long maxBufferSize=bufferPool.getMaxBufferSize();
        long minBufferSize=bufferPool.getMinBufferSize();
        long sharedOptsCount=bufferPool.getSharedOptsCount();
        int capacity=0;
        if (bufferPool instanceof BucketBufferPool) {
          BucketBufferPool p=(BucketBufferPool)bufferPool;
          AbstractBucket[] buckets=p.buckets();
          for (          AbstractBucket b : buckets) {
            capacity+=b.getCount();
          }
          int bucketLen=buckets.length;
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(capacity).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(minBufferSize).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(maxBufferSize).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(usedBufferSize).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(bucketLen).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(sharedOptsCount).append(""String_Node_Str"");
          return sBuffer.toString().getBytes();
        }
 else         if (bufferPool instanceof PageBufferPool) {
          List<String> lines=new ArrayList<String>();
          ConcurrentHashMap<Long,Long> bufferpoolUsageMap=bufferPool.getNetDirectMemoryUsage();
          long usedforNetwork=0;
          for (          Map.Entry<Long,Long> entry : bufferpoolUsageMap.entrySet()) {
            long value=entry.getValue();
            lines.add(""String_Node_Str"" + entry.getKey() + ""String_Node_Str""+ (value > 0 ? JavaUtils.bytesToString2(value) : ""String_Node_Str""));
            usedforNetwork=usedforNetwork + value;
          }
          lines.add(""String_Node_Str"" + JavaUtils.bytesToString2(minBufferSize));
          lines.add(""String_Node_Str"" + JavaUtils.bytesToString2(maxBufferSize));
          lines.add(""String_Node_Str"" + JavaUtils.bytesToString2(usedforNetwork));
          return encode(lines);
        }
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        BufferPool bufferPool=NetSystem.getInstance().getBufferPool();
        if (bufferPool instanceof BucketBufferPool) {
          BucketBufferPool p=(BucketBufferPool)bufferPool;
          AbstractBucket[] buckets=p.buckets();
          for (          AbstractBucket b : buckets) {
            StringBuffer sBuffer=new StringBuffer();
            sBuffer.append(""String_Node_Str"").append(b.getChunkSize()).append(""String_Node_Str"");
            sBuffer.append(""String_Node_Str"").append(b.getQueueSize()).append(""String_Node_Str"");
            sBuffer.append(""String_Node_Str"").append(b.getCount()).append(""String_Node_Str"");
            sBuffer.append(""String_Node_Str"").append(b.getUsedCount()).append(""String_Node_Str"");
            sBuffer.append(""String_Node_Str"").append(b.getShared());
            lines.add(sBuffer.toString());
          }
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        for (        BigKey bigkey : StatUtil.getBigKeys()) {
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(bigkey.lastCmd).append(""String_Node_Str"");
          sBuffer.append(bigkey.key).append(""String_Node_Str"");
          sBuffer.append(bigkey.size).append(""String_Node_Str"");
          sBuffer.append(bigkey.count.get());
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        Map<String,AtomicInteger> poolConnections=new HashMap<String,AtomicInteger>();
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisBackendConnection) {
            String poolName=((RedisBackendConnection)c).getPhysicalNode().getPoolName();
            AtomicInteger poolConnCount=poolConnections.get(poolName);
            if (poolConnCount == null) {
              poolConnections.put(poolName,new AtomicInteger(1));
            }
 else {
              poolConnCount.incrementAndGet();
            }
            lines.add(c.toString());
          }
 else           if (c instanceof KafkaBackendConnection) {
            String poolName=((KafkaBackendConnection)c).getPhysicalNode().getPoolName();
            AtomicInteger poolConnCount=poolConnections.get(poolName);
            if (poolConnCount == null) {
              poolConnections.put(poolName,new AtomicInteger(1));
            }
 else {
              poolConnCount.incrementAndGet();
            }
            lines.add(c.toString());
          }
        }
        StringBuffer sb=new StringBuffer();
        for (        Map.Entry<String,AtomicInteger> entry : poolConnections.entrySet()) {
          sb.append(entry.getKey()).append(""String_Node_Str"").append(entry.getValue().get()).append(""String_Node_Str"");
        }
        lines.add(sb.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") && numArgs == 3) {
        List<String> lines=new ArrayList<String>();
        long minStartupTime=-1;
        long totalNetInCounter=0;
        long totalNetInBytes=0;
        long totalNetOutCounter=0;
        long totalNetOutBytes=0;
        String poolName=new String(request.getArgs()[2]);
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisBackendConnection) {
            if (((RedisBackendConnection)c).getPhysicalNode().getPoolName().equals(poolName)) {
              StringBuffer sb=new StringBuffer();
              sb.append(""String_Node_Str"").append(c.getId()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(c.getStartupTime()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(c.getNetInCounter()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(c.getNetInBytes()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(c.getNetOutBytes()).append(""String_Node_Str"");
              lines.add(sb.toString());
              minStartupTime=minStartupTime < 0 ? c.getStartupTime() : Math.min(minStartupTime,c.getStartupTime());
              totalNetInCounter+=c.getNetInCounter();
              totalNetInBytes+=c.getNetInBytes();
              totalNetOutCounter+=c.getNetOutCounter();
              totalNetOutBytes+=c.getNetOutBytes();
            }
          }
        }
        StringBuffer end=new StringBuffer();
        end.append(""String_Node_Str"").append(minStartupTime).append(""String_Node_Str"");
        end.append(""String_Node_Str"").append(totalNetInCounter).append(""String_Node_Str"");
        end.append(""String_Node_Str"").append(totalNetInBytes).append(""String_Node_Str"");
        end.append(""String_Node_Str"").append(totalNetOutCounter).append(""String_Node_Str"");
        end.append(""String_Node_Str"").append(totalNetOutBytes).append(""String_Node_Str"");
        lines.add(end.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") || arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        AccessStatInfoResult result=StatUtil.getTotalAccessStatInfo().get(StatUtil.STAT_KEY);
        if (result != null) {
          StringBuffer line0=new StringBuffer();
          line0.append(""String_Node_Str"").append(""String_Node_Str"");
          line0.append(""String_Node_Str"").append(""String_Node_Str"");
          line0.append(""String_Node_Str"").append(""String_Node_Str"");
          line0.append(""String_Node_Str"").append(""String_Node_Str"");
          line0.append(""String_Node_Str"");
          StringBuffer line1=new StringBuffer();
          line1.append(""String_Node_Str"").append(""String_Node_Str"");
          line1.append(result.netInBytes[0]).append(""String_Node_Str"");
          line1.append(result.netInBytes[1]).append(""String_Node_Str"");
          line1.append(result.netInBytes[2]).append(""String_Node_Str"");
          line1.append(result.netInBytes[3]);
          StringBuffer line2=new StringBuffer();
          line2.append(""String_Node_Str"").append(""String_Node_Str"");
          line2.append(result.netOutBytes[0]).append(""String_Node_Str"");
          line2.append(result.netOutBytes[1]).append(""String_Node_Str"");
          line2.append(result.netOutBytes[2]).append(""String_Node_Str"");
          line2.append(result.netOutBytes[3]);
          StringBuffer line3=new StringBuffer();
          line3.append(result.created);
          lines.add(line0.toString());
          lines.add(line1.toString());
          lines.add(line2.toString());
          lines.add(line3.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        for (        Map.Entry<String,AccessStatInfoResult> entry : StatUtil.getTotalAccessStatInfo().entrySet()) {
          if (!StatUtil.STAT_KEY.equals(entry.getKey())) {
            AccessStatInfoResult result=entry.getValue();
            StringBuffer line1=new StringBuffer();
            line1.append(result.key).append(""String_Node_Str"");
            line1.append(""String_Node_Str"").append(""String_Node_Str"");
            line1.append(result.netInBytes[0]).append(""String_Node_Str"");
            line1.append(result.netInBytes[1]).append(""String_Node_Str"");
            line1.append(result.netInBytes[2]).append(""String_Node_Str"");
            line1.append(result.netInBytes[3]);
            StringBuffer line2=new StringBuffer();
            line2.append(result.key).append(""String_Node_Str"");
            line2.append(""String_Node_Str"").append(""String_Node_Str"");
            line2.append(result.netOutBytes[0]).append(""String_Node_Str"");
            line2.append(result.netOutBytes[1]).append(""String_Node_Str"");
            line2.append(result.netOutBytes[2]).append(""String_Node_Str"");
            line2.append(result.netOutBytes[3]);
            StringBuffer line3=new StringBuffer();
            line3.append(result.created);
            lines.add(line1.toString());
            lines.add(line2.toString());
            lines.add(line3.toString());
          }
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        long totalNetIn=0;
        long totalNetOut=0;
        for (        Map.Entry<String,UserNetFlow> entry : StatUtil.getUserFlowMap().entrySet()) {
          if (!StatUtil.STAT_KEY.equals(entry.getKey())) {
            StringBuffer sb=new StringBuffer();
            UserNetFlow userNetIo=entry.getValue();
            sb.append(userNetIo.password).append(""String_Node_Str"");
            sb.append(JavaUtils.bytesToString2(userNetIo.netIn.get())).append(""String_Node_Str"");
            sb.append(JavaUtils.bytesToString2(userNetIo.netOut.get()));
            totalNetIn=totalNetIn + userNetIo.netIn.get();
            totalNetOut=totalNetOut + userNetIo.netOut.get();
            lines.add(sb.toString());
          }
        }
        StringBuffer total=new StringBuffer();
        total.append(""String_Node_Str"").append(""String_Node_Str"");
        total.append(JavaUtils.bytesToString2(totalNetIn)).append(""String_Node_Str"");
        total.append(JavaUtils.bytesToString2(totalNetOut));
        lines.add(total.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=showLog(request,""String_Node_Str"");
        return encode2(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=showLog(request,""String_Node_Str"");
        return encode2(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=showLog(request,""String_Node_Str"");
        return encode2(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=showLog(request,""String_Node_Str"");
        return encode2(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> ret=new ArrayList<String>();
        try {
          String resp=ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"");
          StringBuilder sb=new StringBuilder();
          sb.append(resp);
          sb.append(""String_Node_Str"");
          String[] lines=sb.toString().split(""String_Node_Str"");
          ret.add(""String_Node_Str"");
          for (int i=1; i < lines.length; i++) {
            if (lines[i].equals(""String_Node_Str""))             continue;
            ret.add(lines[i]);
          }
        }
 catch (        IOException e) {
          LOGGER.error(""String_Node_Str"",e);
          ret.add(""String_Node_Str"");
        }
        return encode2(ret);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> ret=new ArrayList<String>();
        try {
          String cmd1=ShellUtils.osType == ShellUtils.OSType.OS_TYPE_MAC ? ""String_Node_Str"" : ""String_Node_Str"";
          String cmd2=ShellUtils.osType == ShellUtils.OSType.OS_TYPE_MAC ? ""String_Node_Str"" : ""String_Node_Str"";
          String iostatOut=ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",cmd1);
          String vmstatOut=ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",cmd2);
          StringBuilder sb=new StringBuilder();
          sb.append(iostatOut);
          sb.append(""String_Node_Str"");
          sb.append(""String_Node_Str"");
          sb.append(vmstatOut);
          String[] lines=sb.toString().split(""String_Node_Str"");
          ret.add(""String_Node_Str"");
          for (int i=1; i < lines.length; i++) {
            if (lines[i].equals(""String_Node_Str""))             continue;
            ret.add(lines[i]);
          }
        }
 catch (        IOException e) {
          LOGGER.error(""String_Node_Str"",e);
          ret.add(""String_Node_Str"");
        }
        return encode2(ret);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<Object> list=new ArrayList<Object>();
        Map<Integer,AbstractPool> pools=RedisEngineCtx.INSTANCE().getPoolMap();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        list.add(titleLine.toString());
        for (        AbstractPool pool : pools.values()) {
          if (pool instanceof RedisStandalonePool) {
            StringBuffer sb=new StringBuffer();
            RedisStandalonePool redisStandalonePool=(RedisStandalonePool)pool;
            PhysicalNode physicalNode=redisStandalonePool.getPhysicalNode();
            if (physicalNode == null)             continue;
            sb.append(""String_Node_Str"");
            sb.append(redisStandalonePool.getId()).append(""String_Node_Str"");
            sb.append(physicalNode.getPoolName()).append(""String_Node_Str"");
            sb.append(""String_Node_Str"").append(""String_Node_Str"");
            sb.append(physicalNode.getName()).append(""String_Node_Str"");
            sb.append(physicalNode.getMinCon()).append(""String_Node_Str"");
            sb.append(physicalNode.getMaxCon()).append(""String_Node_Str"");
            sb.append(physicalNode.getIdleCount()).append(""String_Node_Str"");
            sb.append(physicalNode.getActiveCount());
            list.add(sb.toString());
          }
 else           if (pool instanceof RedisClusterPool) {
            RedisClusterPool redisClusterPool=(RedisClusterPool)pool;
            Map<String,ClusterNode> masters=redisClusterPool.getMasters();
            List<String> clusterInfo=new ArrayList<String>();
            for (            ClusterNode clusterNode : masters.values()) {
              PhysicalNode physicalNode=clusterNode.getPhysicalNode();
              StringBuffer sb=new StringBuffer();
              sb.append(redisClusterPool.getId()).append(""String_Node_Str"");
              sb.append(physicalNode.getPoolName()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(""String_Node_Str"");
              sb.append(physicalNode.getName()).append(""String_Node_Str"");
              sb.append(physicalNode.getMinCon()).append(""String_Node_Str"");
              sb.append(physicalNode.getMaxCon()).append(""String_Node_Str"");
              sb.append(physicalNode.getIdleCount()).append(""String_Node_Str"");
              sb.append(physicalNode.getActiveCount()).append(""String_Node_Str"");
              ;
              sb.append(!clusterNode.isFail());
              clusterInfo.add(sb.toString());
              sb.append(clusterNode.getConnectInfo());
            }
            list.add(clusterInfo);
          }
 else           if (pool instanceof KafkaPool) {
            KafkaPool kafkaPool=(KafkaPool)pool;
            Map<Integer,PhysicalNode> physicalNodes=kafkaPool.getPhysicalNodes();
            for (            PhysicalNode physicalNode : physicalNodes.values()) {
              StringBuffer sb=new StringBuffer();
              sb.append(""String_Node_Str"");
              sb.append(kafkaPool.getId()).append(""String_Node_Str"");
              sb.append(physicalNode.getPoolName()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(""String_Node_Str"");
              sb.append(physicalNode.getName()).append(""String_Node_Str"");
              sb.append(physicalNode.getMinCon()).append(""String_Node_Str"");
              sb.append(physicalNode.getMaxCon()).append(""String_Node_Str"");
              sb.append(physicalNode.getIdleCount()).append(""String_Node_Str"");
              sb.append(physicalNode.getActiveCount());
              list.add(sb.toString());
            }
          }
        }
        return encodeObject(list);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        Collection<Entry<String,AtomicLong>> entrys=StatUtil.getCommandProcTimeMap().entrySet();
        List<String> lines=new ArrayList<String>();
        for (        Entry<String,AtomicLong> entry : entrys) {
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(entry.getKey()).append(""String_Node_Str"").append(entry.getValue().get());
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        Collection<Entry<String,AtomicLong>> entrys=StatUtil.getCommandWaitTimeMap().entrySet();
        List<String> lines=new ArrayList<String>();
        for (        Entry<String,AtomicLong> entry : entrys) {
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(entry.getKey()).append(""String_Node_Str"").append(entry.getValue().get());
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        for (        BigLength bigLength : StatUtil.getBigLengthMap().values()) {
          StringBuffer line1=new StringBuffer();
          line1.append(bigLength.cmd).append(""String_Node_Str"");
          line1.append(bigLength.key).append(""String_Node_Str"");
          line1.append(bigLength.length.get()).append(""String_Node_Str"");
          line1.append(bigLength.count_1k.get()).append(""String_Node_Str"");
          line1.append(bigLength.count_10k.get());
          lines.add(line1.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        for (        SlowKey slowKey : StatUtil.getSlowKey()) {
          StringBuffer line1=new StringBuffer();
          line1.append(slowKey.cmd).append(""String_Node_Str"");
          line1.append(slowKey.key).append(""String_Node_Str"");
          line1.append(slowKey.count);
          lines.add(line1.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") && (numArgs == 3 || numArgs == 2)) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        if (numArgs == 2) {
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"");
        }
 else {
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"");
        }
        lines.add(titleLine.toString());
        final Map<Integer,PoolCfg> poolCfgMap=RedisEngineCtx.INSTANCE().getPoolCfgMap();
        for (        Entry<Integer,PoolCfg> poolEntry : poolCfgMap.entrySet()) {
          PoolCfg poolCfg=poolEntry.getValue();
          if (poolCfg instanceof KafkaPoolCfg) {
            Map<String,TopicCfg> kafkaMap=((KafkaPoolCfg)poolCfg).getTopicCfgMap();
            if (numArgs == 2) {
              for (              Entry<String,TopicCfg> kafkaEntry : kafkaMap.entrySet()) {
                TopicCfg kafkaCfg=kafkaEntry.getValue();
                StringBuffer line=new StringBuffer();
                line.append(kafkaCfg.getName()).append(""String_Node_Str"");
                line.append(kafkaCfg.getPoolId()).append(""String_Node_Str"");
                line.append(kafkaCfg.getPartitions()).append(""String_Node_Str"");
                line.append(kafkaCfg.getReplicationFactor()).append(""String_Node_Str"");
                line.append(kafkaCfg.getProducers()).append(""String_Node_Str"");
                line.append(kafkaCfg.getConsumers());
                lines.add(line.toString());
              }
            }
 else {
              String topic=new String(request.getArgs()[2]);
              TopicCfg kafkaCfg=kafkaMap.get(topic);
              if (kafkaCfg != null) {
                for (                BrokerPartition partition : kafkaCfg.getRunningInfo().getPartitions().values()) {
                  int pt=partition.getPartition();
                  StringBuffer line=new StringBuffer();
                  line.append(kafkaCfg.getName()).append(""String_Node_Str"");
                  line.append(partition.getLeader().getHost()).append(partition.getLeader().getPort()).append(""String_Node_Str"");
                  line.append(pt).append(""String_Node_Str"");
                  line.append(partition.getLogStartOffset()).append(""String_Node_Str"");
                  line.append(partition.getProducerOffset()).append(""String_Node_Str"");
                  for (                  ConsumerOffset consumerOffset : partition.getConsumerOffsets().values()) {
                    line.append(consumerOffset.getConsumer());
                    line.append(""String_Node_Str"");
                    line.append(consumerOffset.getCurrentOffset());
                    line.append(""String_Node_Str"");
                  }
                  lines.add(line.toString());
                }
              }
            }
          }
        }
        return encode(lines);
      }
    }
 else     if ((arg1[0] == 'N' || arg1[0] == 'n') && (arg1[1] == 'O' || arg1[1] == 'o') && (arg1[2] == 'D' || arg1[2] == 'd')&& (arg1[3] == 'E' || arg1[3] == 'e')) {
      return ""String_Node_Str"".getBytes();
    }
  }
 else   if (arg1.length == 6) {
    if ((arg1[0] == 'R' || arg1[0] == 'r') && (arg1[1] == 'E' || arg1[1] == 'e') && (arg1[2] == 'L' || arg1[2] == 'l')&& (arg1[3] == 'O' || arg1[3] == 'o')&& (arg1[4] == 'A' || arg1[4] == 'a')&& (arg1[5] == 'D' || arg1[5] == 'd')) {
      if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        byte[] buff=RedisEngineCtx.INSTANCE().reloadAll();
        return buff;
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        byte[] buff=RedisEngineCtx.INSTANCE().reloadUser();
        return buff;
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        ConcurrentMap<Long,ClosableConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,ClosableConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          ClosableConnection c=it.next().getValue();
          if (c instanceof RedisFrontConnection) {
            LOGGER.info(""String_Node_Str"",c);
            c.close(""String_Node_Str"");
          }
        }
        return ""String_Node_Str"".getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        JAVA_BIN_PATH=new String(request.getArgs()[2]);
        return ""String_Node_Str"".getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        try {
          Map<Integer,PoolCfg> poolCfgMap=RedisEngineCtx.INSTANCE().getPoolCfgMap();
          for (          PoolCfg poolCfg : poolCfgMap.values()) {
            if (poolCfg instanceof KafkaPoolCfg)             poolCfg.reloadExtraCfg();
          }
        }
 catch (        Exception e) {
          LOGGER.error(""String_Node_Str"",e);
          StringBuffer sb=new StringBuffer();
          sb.append(""String_Node_Str"").append(e.getMessage()).append(""String_Node_Str"");
          return sb.toString().getBytes();
        }
        return ""String_Node_Str"".getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        byte[] buff=BypassService.INSTANCE().reload();
        return buff;
      }
    }
  }
 else   if (arg1.length == 7) {
    if ((arg1[0] == 'C' || arg1[0] == 'c') && (arg1[1] == 'L' || arg1[1] == 'l') && (arg1[2] == 'U' || arg1[2] == 'u')&& (arg1[3] == 'S' || arg1[3] == 's')&& (arg1[4] == 'T' || arg1[4] == 't')&& (arg1[5] == 'E' || arg1[5] == 'e')&& (arg1[6] == 'R' || arg1[6] == 'r')) {
      AbstractPool pool=RedisEngineCtx.INSTANCE().getPoolMap().get(frontCon.getUserCfg().getPoolId());
      if (pool.getType() != 1) {
        return ""String_Node_Str"".getBytes();
      }
      PhysicalNode pysicalNode=((RedisClusterPool)pool).getPhysicalNodeBySlot(0);
      if (pysicalNode == null) {
        return ""String_Node_Str"".getBytes();
      }
      try {
        RedisBackendConnection backendCon=(RedisBackendConnection)pysicalNode.getConnection(new DirectTransTofrontCallBack(),frontCon);
        if (backendCon == null) {
          frontCon.writeErrMessage(""String_Node_Str"");
        }
 else {
          backendCon.write(request.encode());
        }
        return null;
      }
 catch (      IOException e) {
        LOGGER.error(""String_Node_Str"",e);
      }
    }
  }
  return ""String_Node_Str"".getBytes();
}"
37489,"@Override public String toString(){
  StringBuffer sbuffer=new StringBuffer(100);
  sbuffer.append(delegateConn.toString());
  sbuffer.append(""String_Node_Str"");
  sbuffer.append(""String_Node_Str"").append(borrowed);
  sbuffer.append(""String_Node_Str"").append(isZeroCopy);
  if (heartbeatTime > 0) {
    sbuffer.append(""String_Node_Str"").append(heartbeatTime);
  }
  sbuffer.append(""String_Node_Str"");
  return sbuffer.toString();
}","@Override public String toString(){
  StringBuffer sbuffer=new StringBuffer(100);
  sbuffer.append(delegateConn.toString());
  sbuffer.append(""String_Node_Str"").append(borrowed);
  sbuffer.append(""String_Node_Str"").append(isZeroCopy);
  if (heartbeatTime > 0) {
    sbuffer.append(""String_Node_Str"").append(heartbeatTime);
  }
  sbuffer.append(""String_Node_Str"");
  return sbuffer.toString();
}"
37490,"@Override public String toString(){
  StringBuffer sbuffer=new StringBuffer(200);
  sbuffer.append(""String_Node_Str"").append(reactor);
  sbuffer.append(""String_Node_Str"").append(host).append(""String_Node_Str"").append(port);
  sbuffer.append(""String_Node_Str"").append(userCfg != null ? userCfg.getPassword() : ""String_Node_Str"");
  sbuffer.append(""String_Node_Str"").append(id);
  if (session != null) {
    sbuffer.append(""String_Node_Str"").append(session.getRequestCmd());
    sbuffer.append(""String_Node_Str"").append(session.getRequestKey() != null ? new String(session.getRequestKey()) : ""String_Node_Str"");
  }
  sbuffer.append(""String_Node_Str"").append(_readLock.get());
  sbuffer.append(""String_Node_Str"").append(TimeUtil.formatTimestamp(startupTime));
  sbuffer.append(""String_Node_Str"").append(TimeUtil.formatTimestamp(lastReadTime));
  sbuffer.append(""String_Node_Str"").append(TimeUtil.formatTimestamp(lastWriteTime));
  sbuffer.append(""String_Node_Str"").append(writeAttempts);
  if (isClosed.get()) {
    sbuffer.append(""String_Node_Str"").append(TimeUtil.formatTimestamp(closeTime));
    sbuffer.append(""String_Node_Str"").append(closeReason);
  }
  sbuffer.append(""String_Node_Str"").append(isClosed.get());
  sbuffer.append(""String_Node_Str"");
  return sbuffer.toString();
}","@Override public String toString(){
  StringBuffer sbuffer=new StringBuffer(200);
  sbuffer.append(""String_Node_Str"").append(reactor);
  sbuffer.append(""String_Node_Str"").append(host).append(""String_Node_Str"").append(port);
  sbuffer.append(""String_Node_Str"").append(userCfg != null ? userCfg.getPassword() : ""String_Node_Str"");
  sbuffer.append(""String_Node_Str"").append(id);
  if (session != null) {
    sbuffer.append(""String_Node_Str"").append(session.getRequestCmd());
    sbuffer.append(""String_Node_Str"").append(session.getRequestKey() != null ? new String(session.getRequestKey()) : ""String_Node_Str"");
  }
  sbuffer.append(""String_Node_Str"").append(_readLock.get());
  sbuffer.append(""String_Node_Str"").append(TimeUtil.formatTimestamp(startupTime));
  sbuffer.append(""String_Node_Str"").append(TimeUtil.formatTimestamp(lastReadTime));
  sbuffer.append(""String_Node_Str"").append(TimeUtil.formatTimestamp(lastWriteTime));
  sbuffer.append(""String_Node_Str"").append(writeAttempts);
  if (isClosed.get()) {
    sbuffer.append(""String_Node_Str"").append(isClosed.get());
    sbuffer.append(""String_Node_Str"").append(TimeUtil.formatTimestamp(closeTime));
    sbuffer.append(""String_Node_Str"").append(closeReason);
  }
  sbuffer.append(""String_Node_Str"");
  return sbuffer.toString();
}"
37491,"/** 
 * , reactor 
 */
@SuppressWarnings(""String_Node_Str"") @Override public void asynRead() throws IOException {
  if (isClosed.get()) {
    return;
  }
  if (!reading.compareAndSet(false,true)) {
    LOGGER.info(""String_Node_Str"");
    return;
  }
  try {
    if (readBuffer == null) {
      if (direction == Direction.in)       readBuffer=allocate(1024 * 16);
 else       readBuffer=allocate(1024 * 64);
    }
    lastReadTime=TimeUtil.currentTimeMillis();
    int offset=0;
    for (; ; ) {
      if (isClosed()) {
        return;
      }
      int length=socketChannel.read(readBuffer);
      if (length == -1) {
        this.close(""String_Node_Str"");
        return;
      }
 else       if (length == 0 && !this.socketChannel.isOpen()) {
        this.close(""String_Node_Str"");
        return;
      }
      netInBytes+=length;
      netInCounter++;
      if (isFlowLimit() && netFlowMonitor.pool(length)) {
        flowClean();
        return;
      }
      if (!readBuffer.hasRemaining()) {
        if (readBuffer.capacity() >= maxCapacity) {
          LOGGER.warn(""String_Node_Str"",this);
          throw new IllegalArgumentException(""String_Node_Str"");
        }
        int newCapacity=readBuffer.capacity() << 1;
        newCapacity=(newCapacity > maxCapacity) ? maxCapacity : newCapacity;
        ByteBuffer newBuffer=allocate(newCapacity);
        readBuffer.position(offset);
        newBuffer.put(readBuffer);
        recycle(readBuffer);
        readBuffer=newBuffer;
        lastLargeMessageTime=TimeUtil.currentTimeMillis();
        largeCounter++;
        continue;
      }
      int dataLength=readBuffer.position();
      readBuffer.position(offset);
      byte[] data=new byte[dataLength];
      readBuffer.get(data,0,dataLength);
      if (isNested)       handler.handleReadEvent(parent,data);
 else       handler.handleReadEvent(this,data);
      if (readBuffer != null && lastLargeMessageTime != 0 && lastLargeMessageTime < (lastReadTime - 30 * 1000L)) {
        if (LOGGER.isDebugEnabled()) {
          LOGGER.debug(""String_Node_Str"" + readBuffer.capacity());
        }
        ByteBuffer oldBuffer=readBuffer;
        ByteBuffer newBuffer=allocate(1024 * 16);
        readBuffer=newBuffer;
        if (oldBuffer.isDirect())         recycle(oldBuffer);
        lastLargeMessageTime=0;
      }
 else {
        if (readBuffer != null) {
          readBuffer.clear();
        }
      }
      break;
    }
  }
  finally {
    reading.set(false);
  }
}","/** 
 * , reactor 
 */
@SuppressWarnings(""String_Node_Str"") @Override public void asynRead() throws IOException {
  if (isClosed.get()) {
    return;
  }
  if (!reading.compareAndSet(false,true)) {
    LOGGER.info(""String_Node_Str"");
    return;
  }
  try {
    if (readBuffer == null) {
      if (direction == Direction.in)       readBuffer=allocate(1024 * 16);
 else       readBuffer=allocate(1024 * 64);
    }
    lastReadTime=TimeUtil.currentTimeMillis();
    int offset=0;
    for (; ; ) {
      if (isClosed()) {
        return;
      }
      int length=socketChannel.read(readBuffer);
      if (length == -1) {
        this.close(""String_Node_Str"");
        return;
      }
 else       if (length == 0 && !this.socketChannel.isOpen()) {
        this.close(""String_Node_Str"");
        return;
      }
      netInBytes+=length;
      netInCounter++;
      if (isFlowLimit() && netFlowMonitor != null && netFlowMonitor.pool(length)) {
        flowClean();
        return;
      }
      if (!readBuffer.hasRemaining()) {
        if (readBuffer.capacity() >= maxCapacity) {
          LOGGER.warn(""String_Node_Str"",this);
          throw new IllegalArgumentException(""String_Node_Str"");
        }
        int newCapacity=readBuffer.capacity() << 1;
        newCapacity=(newCapacity > maxCapacity) ? maxCapacity : newCapacity;
        ByteBuffer newBuffer=allocate(newCapacity);
        readBuffer.position(offset);
        newBuffer.put(readBuffer);
        recycle(readBuffer);
        readBuffer=newBuffer;
        lastLargeMessageTime=TimeUtil.currentTimeMillis();
        largeCounter++;
        continue;
      }
      int dataLength=readBuffer.position();
      readBuffer.position(offset);
      byte[] data=new byte[dataLength];
      readBuffer.get(data,0,dataLength);
      if (isNested)       handler.handleReadEvent(parent,data);
 else       handler.handleReadEvent(this,data);
      if (readBuffer != null && lastLargeMessageTime != 0 && lastLargeMessageTime < (lastReadTime - 30 * 1000L)) {
        if (LOGGER.isDebugEnabled()) {
          LOGGER.debug(""String_Node_Str"" + readBuffer.capacity());
        }
        ByteBuffer oldBuffer=readBuffer;
        ByteBuffer newBuffer=allocate(1024 * 16);
        readBuffer=newBuffer;
        if (oldBuffer.isDirect())         recycle(oldBuffer);
        lastLargeMessageTime=0;
      }
 else {
        if (readBuffer != null) {
          readBuffer.clear();
        }
      }
      break;
    }
  }
  finally {
    reading.set(false);
  }
}"
37492,"@Override public String toString(){
  StringBuffer sbuffer=new StringBuffer(100);
  sbuffer.append(""String_Node_Str"");
  sbuffer.append(""String_Node_Str"").append(reactor);
  sbuffer.append(""String_Node_Str"").append(host);
  sbuffer.append(""String_Node_Str"").append(port);
  sbuffer.append(""String_Node_Str"").append(id);
  sbuffer.append(""String_Node_Str"").append(startupTime);
  sbuffer.append(""String_Node_Str"").append(lastReadTime);
  sbuffer.append(""String_Node_Str"").append(lastWriteTime);
  sbuffer.append(""String_Node_Str"").append(writeAttempts);
  sbuffer.append(""String_Node_Str"").append(netInCounter).append(""String_Node_Str"").append(netOutCounter);
  if (isClosed.get()) {
    sbuffer.append(""String_Node_Str"").append(isClosed);
    sbuffer.append(""String_Node_Str"").append(closeTime);
    sbuffer.append(""String_Node_Str"").append(closeReason);
  }
  sbuffer.append(""String_Node_Str"");
  return sbuffer.toString();
}","@Override public String toString(){
  StringBuffer sbuffer=new StringBuffer(100);
  sbuffer.append(""String_Node_Str"");
  sbuffer.append(""String_Node_Str"").append(reactor);
  sbuffer.append(""String_Node_Str"").append(host).append(""String_Node_Str"").append(port);
  sbuffer.append(""String_Node_Str"").append(id);
  sbuffer.append(""String_Node_Str"").append(startupTime);
  sbuffer.append(""String_Node_Str"").append(lastReadTime);
  sbuffer.append(""String_Node_Str"").append(lastWriteTime);
  sbuffer.append(""String_Node_Str"").append(writeAttempts);
  sbuffer.append(""String_Node_Str"").append(netInCounter).append(""String_Node_Str"").append(netOutCounter);
  if (isClosed.get()) {
    sbuffer.append(""String_Node_Str"").append(isClosed);
    sbuffer.append(""String_Node_Str"").append(closeTime);
    sbuffer.append(""String_Node_Str"").append(closeReason);
  }
  sbuffer.append(""String_Node_Str"");
  return sbuffer.toString();
}"
37493,"@SuppressWarnings(""String_Node_Str"") @Override public void asynRead() throws IOException {
  if (isClosed.get()) {
    return;
  }
  if (!rwLock.compareAndSet(false,true)) {
    return;
  }
  lastReadTime=TimeUtil.currentTimeMillis();
  try {
    for (; ; ) {
      int position=mappedByteBuffer.position();
      int count=MAPPED_SIZE - position;
      int tranfered=(int)fileChannel.transferFrom(socketChannel,position,count);
      mappedByteBuffer.position(position + tranfered);
      if (tranfered == 0 && count > 0) {
        tranfered=socketChannel.read(mappedByteBuffer);
      }
      if (tranfered > 0) {
        byte[] data=new byte[tranfered];
        mappedByteBuffer.flip();
        mappedByteBuffer.get(data,0,tranfered);
        if (isNested)         handler.handleReadEvent(parent,data);
 else         handler.handleReadEvent(this,data);
        break;
      }
 else       if (tranfered == 0) {
        LOGGER.warn(""String_Node_Str"",tranfered);
        if (!this.socketChannel.isOpen()) {
          this.close(""String_Node_Str"");
          return;
        }
        this.mappedByteBuffer.clear();
      }
 else {
        this.close(""String_Node_Str"");
        return;
      }
    }
  }
  finally {
    rwLock.set(false);
  }
}","@SuppressWarnings(""String_Node_Str"") @Override public void asynRead() throws IOException {
  if (isClosed.get()) {
    return;
  }
  if (!rwLock.compareAndSet(false,true)) {
    return;
  }
  lastReadTime=TimeUtil.currentTimeMillis();
  try {
    for (; ; ) {
      int position=mappedByteBuffer.position();
      int count=MAPPED_SIZE - position;
      int tranfered=(int)fileChannel.transferFrom(socketChannel,position,count);
      mappedByteBuffer.position(position + tranfered);
      if (tranfered == 0 && count > 0) {
        tranfered=socketChannel.read(mappedByteBuffer);
      }
      if (tranfered > 0) {
        netInBytes+=tranfered;
        netInCounter++;
        byte[] data=new byte[tranfered];
        mappedByteBuffer.flip();
        mappedByteBuffer.get(data,0,tranfered);
        if (isNested)         handler.handleReadEvent(parent,data);
 else         handler.handleReadEvent(this,data);
        break;
      }
 else       if (tranfered == 0) {
        LOGGER.warn(""String_Node_Str"",tranfered);
        if (!this.socketChannel.isOpen()) {
          this.close(""String_Node_Str"");
          return;
        }
        this.mappedByteBuffer.clear();
      }
 else {
        this.close(""String_Node_Str"");
        return;
      }
    }
  }
  finally {
    rwLock.set(false);
  }
}"
37494,"@Override public String toString(){
  StringBuffer sbuffer=new StringBuffer(100);
  sbuffer.append(""String_Node_Str"");
  sbuffer.append(""String_Node_Str"").append(reactor);
  sbuffer.append(""String_Node_Str"").append(host);
  sbuffer.append(""String_Node_Str"").append(port);
  sbuffer.append(""String_Node_Str"").append(id);
  sbuffer.append(""String_Node_Str"").append(startupTime);
  sbuffer.append(""String_Node_Str"").append(lastReadTime);
  sbuffer.append(""String_Node_Str"").append(lastWriteTime);
  sbuffer.append(""String_Node_Str"").append(writeAttempts);
  sbuffer.append(""String_Node_Str"").append(netInCounter).append(""String_Node_Str"").append(netOutCounter);
  if (isClosed.get()) {
    sbuffer.append(""String_Node_Str"").append(isClosed);
    sbuffer.append(""String_Node_Str"").append(closeTime);
    sbuffer.append(""String_Node_Str"").append(closeReason);
  }
  sbuffer.append(""String_Node_Str"");
  return sbuffer.toString();
}","@Override public String toString(){
  StringBuffer sbuffer=new StringBuffer(100);
  sbuffer.append(""String_Node_Str"");
  sbuffer.append(""String_Node_Str"").append(reactor);
  sbuffer.append(""String_Node_Str"").append(host).append(""String_Node_Str"").append(port);
  sbuffer.append(""String_Node_Str"").append(id);
  sbuffer.append(""String_Node_Str"").append(startupTime);
  sbuffer.append(""String_Node_Str"").append(lastReadTime);
  sbuffer.append(""String_Node_Str"").append(lastWriteTime);
  sbuffer.append(""String_Node_Str"").append(writeAttempts);
  sbuffer.append(""String_Node_Str"").append(netInCounter).append(""String_Node_Str"").append(netOutCounter);
  if (isClosed.get()) {
    sbuffer.append(""String_Node_Str"").append(isClosed);
    sbuffer.append(""String_Node_Str"").append(closeTime);
    sbuffer.append(""String_Node_Str"").append(closeReason);
  }
  sbuffer.append(""String_Node_Str"");
  return sbuffer.toString();
}"
37495,"@Override public void write(ByteBuffer buf){
  try {
    for (; ; ) {
      if (!rwLock.compareAndSet(false,true)) {
        break;
      }
    }
    buf.flip();
    int bufSize=buf.limit();
    if (bufSize <= MAPPED_SIZE) {
      mappedByteBuffer.clear();
      int position=0;
      int count=fileChannel.write(buf,position);
      if (buf.hasRemaining()) {
        throw new IOException(""String_Node_Str"" + count + ""String_Node_Str""+ buf.remaining());
      }
 else {
        NetSystem.getInstance().getBufferPool().recycle(buf);
      }
      write0(position,count);
    }
 else {
      int cnt=(bufSize / MAPPED_SIZE) + (bufSize % MAPPED_SIZE > 0 ? 1 : 0);
      int postion=0;
      for (int i=1; i <= cnt; i++) {
        int limit=MAPPED_SIZE * i;
        if (limit > bufSize) {
          limit=bufSize;
        }
        buf.position(postion);
        buf.limit(limit);
        ByteBuffer tmpBuf=buf.slice();
        mappedByteBuffer.clear();
        int count=fileChannel.write(tmpBuf,0);
        if (tmpBuf.hasRemaining()) {
          throw new IOException(""String_Node_Str"" + count + ""String_Node_Str""+ tmpBuf.remaining());
        }
        int tranfered=write0(0,count);
        postion+=tranfered;
      }
      NetSystem.getInstance().getBufferPool().recycle(buf);
    }
  }
 catch (  IOException e) {
    LOGGER.error(""String_Node_Str"",e);
    this.close(""String_Node_Str"" + e);
  }
 finally {
    rwLock.set(false);
  }
}","@Override public void write(ByteBuffer buf){
  try {
    for (; ; ) {
      if (!rwLock.compareAndSet(false,true)) {
        break;
      }
    }
    buf.flip();
    int bufSize=buf.limit();
    if (bufSize <= MAPPED_SIZE) {
      mappedByteBuffer.clear();
      int position=0;
      int count=fileChannel.write(buf,position);
      if (buf.hasRemaining()) {
        throw new IOException(""String_Node_Str"" + count + ""String_Node_Str""+ buf.remaining());
      }
 else {
        NetSystem.getInstance().getBufferPool().recycle(buf);
      }
      int tranfered=write0(position,count);
      netOutCounter++;
      netOutBytes+=tranfered;
      lastWriteTime=TimeUtil.currentTimeMillis();
    }
 else {
      int cnt=(bufSize / MAPPED_SIZE) + (bufSize % MAPPED_SIZE > 0 ? 1 : 0);
      int postion=0;
      for (int i=1; i <= cnt; i++) {
        int limit=MAPPED_SIZE * i;
        if (limit > bufSize) {
          limit=bufSize;
        }
        buf.position(postion);
        buf.limit(limit);
        ByteBuffer tmpBuf=buf.slice();
        mappedByteBuffer.clear();
        int count=fileChannel.write(tmpBuf,0);
        if (tmpBuf.hasRemaining()) {
          throw new IOException(""String_Node_Str"" + count + ""String_Node_Str""+ tmpBuf.remaining());
        }
        int tranfered=write0(0,count);
        postion+=tranfered;
        netOutCounter++;
        netOutBytes+=tranfered;
        lastWriteTime=TimeUtil.currentTimeMillis();
      }
      NetSystem.getInstance().getBufferPool().recycle(buf);
    }
  }
 catch (  IOException e) {
    LOGGER.error(""String_Node_Str"",e);
    this.close(""String_Node_Str"" + e);
  }
 finally {
    rwLock.set(false);
  }
}"
37496,"private void sendCommand(final RedisOutputStream os,final byte[]... args){
  try {
    os.write(ASTERISK_BYTE);
    os.writeIntCrLf(args.length);
    os.writeCrLf();
    for (    final byte[] arg : args) {
      os.write(DOLLAR_BYTE);
      os.writeIntCrLf(arg.length);
      os.write(arg);
      os.writeCrLf();
    }
  }
 catch (  IOException e) {
    throw new JedisConnectionException(e);
  }
}","private void sendCommand(final RedisOutputStream os,final byte[]... args){
  try {
    os.write(ASTERISK_BYTE);
    os.writeIntCrLf(args.length);
    for (    final byte[] arg : args) {
      os.write(DOLLAR_BYTE);
      os.writeIntCrLf(arg.length);
      os.write(arg);
      os.writeCrLf();
    }
  }
 catch (  IOException e) {
    throw new JedisConnectionException(e);
  }
}"
37497,"@Override public void write(ByteBuffer buf){
  writeQueue.offer(buf);
  try {
    for (; ; ) {
      if (!rwLock.compareAndSet(false,true)) {
        break;
      }
    }
    ByteBuffer tmpBuf;
    while ((tmpBuf=writeQueue.poll()) != null) {
      mappedByteBuffer.clear();
      int position=0;
      int count=fileChannel.write(tmpBuf,position);
      if (tmpBuf.hasRemaining()) {
        throw new IOException(""String_Node_Str"" + count + ""String_Node_Str""+ tmpBuf.remaining());
      }
      write0(position,count);
    }
  }
 catch (  IOException e) {
    LOGGER.error(""String_Node_Str"",e);
    this.close(""String_Node_Str"" + e);
  }
 finally {
    rwLock.set(false);
  }
}","@Override public void write(ByteBuffer buf){
  buf.flip();
  writeQueue.offer(buf);
  try {
    for (; ; ) {
      if (!rwLock.compareAndSet(false,true)) {
        break;
      }
    }
    ByteBuffer tmpBuf;
    while ((tmpBuf=writeQueue.poll()) != null) {
      mappedByteBuffer.clear();
      int position=0;
      int count=fileChannel.write(tmpBuf,position);
      if (tmpBuf.hasRemaining()) {
        throw new IOException(""String_Node_Str"" + count + ""String_Node_Str""+ tmpBuf.remaining());
      }
      write0(position,count);
    }
  }
 catch (  IOException e) {
    LOGGER.error(""String_Node_Str"",e);
    this.close(""String_Node_Str"" + e);
  }
 finally {
    rwLock.set(false);
  }
}"
37498,"public List<RedisResponse> writeToBackend(RedisRequest request){
  JedisPool jedisPool=JedisHolder.INSTANCE().getJedisPool(host,port);
  JedisConnection jedisConn=jedisPool.getResource();
  try {
    jedisConn.sendCommand(request.getArgs());
    byte[] response=jedisConn.getBinaryReply();
    RedisResponseDecoder decoder=new RedisResponseDecoder();
    return decoder.decode(response);
  }
 catch (  Exception e) {
    LOGGER.error(""String_Node_Str"" + host + ""String_Node_Str""+ port,e);
  }
 finally {
    if (jedisConn != null) {
      jedisConn.close();
    }
  }
  return null;
}","public List<RedisResponse> writeToBackend(RedisRequest request){
  JedisPool jedisPool=JedisHolder.INSTANCE().getJedisPool(host,port);
  JedisConnection jedisConn=jedisPool.getResource();
  try {
    jedisConn.sendCommand(request.getArgs());
    byte[] response=jedisConn.getBinaryReply();
    RedisResponseDecoder decoder=new RedisResponseDecoder();
    List<RedisResponse> result=decoder.decode(response);
    while (result == null) {
      response=jedisConn.getBinaryReply();
      result=decoder.decode(response);
    }
    return result;
  }
 catch (  Exception e) {
    LOGGER.error(""String_Node_Str"" + host + ""String_Node_Str""+ port,e);
  }
 finally {
    if (jedisConn != null) {
      jedisConn.close();
    }
  }
  return null;
}"
37499,"@Override public void onCollect(String password,String cmd,String key,int requestSize,int responseSize,int procTimeMills,int waitTimeMills,boolean isCommandOnly){
  if (isCommandOnly)   return;
  if (requestSize < REQUIRED_SIZE && responseSize < REQUIRED_SIZE) {
    return;
  }
  if (!locking.compareAndSet(false,true)) {
    return;
  }
  try {
    if (bkList.size() >= LENGTH) {
      while (bkList.size() >= (LENGTH * 0.5)) {
        int index=bkList.size() - 1;
        BigKey bk=bkList.remove(index);
        if (bk != null) {
          bkHashMap.remove(bk.key);
        }
      }
    }
    BigKey newBK=new BigKey();
    newBK.key=key;
    int index=bkList.indexOf(newBK);
    if (index >= 0) {
      BigKey oldBK=bkHashMap.get(key);
      oldBK.lastCmd=cmd;
      oldBK.size=requestSize > responseSize ? requestSize : responseSize;
      oldBK.lastUseTime=TimeUtil.currentTimeMillis();
      oldBK.count.incrementAndGet();
      oldBK.fromReq=requestSize >= REQUIRED_SIZE;
      oldBK.fromResp=responseSize >= REQUIRED_SIZE;
    }
 else {
      newBK.lastCmd=cmd;
      newBK.size=requestSize > responseSize ? requestSize : responseSize;
      newBK.lastUseTime=TimeUtil.currentTimeMillis();
      newBK.fromReq=requestSize >= REQUIRED_SIZE;
      newBK.fromResp=responseSize >= REQUIRED_SIZE;
      bkList.add(newBK);
      bkHashMap.put(key,newBK);
    }
  }
  finally {
    locking.set(false);
  }
}","@Override public void onCollect(String password,String cmd,String key,int requestSize,int responseSize,int procTimeMills,int waitTimeMills,boolean isCommandOnly){
  if (isCommandOnly)   return;
  if (requestSize < REQUIRED_SIZE && responseSize < REQUIRED_SIZE) {
    return;
  }
  if (!locking.compareAndSet(false,true)) {
    return;
  }
  try {
    if (bkList.size() >= LENGTH) {
      while (bkList.size() >= (LENGTH * 0.5)) {
        int index=bkList.size() - 1;
        BigKey bk=bkList.remove(index);
        if (bk != null) {
          bkHashMap.remove(bk.key);
        }
      }
    }
    BigKey newBK=new BigKey();
    newBK.key=key;
    int index=bkList.indexOf(newBK);
    if (index >= 0) {
      BigKey oldBK=bkHashMap.get(key);
      if (oldBK == null) {
        oldBK=newBK;
        bkHashMap.put(key,oldBK);
      }
      oldBK.lastCmd=cmd;
      oldBK.size=requestSize > responseSize ? requestSize : responseSize;
      oldBK.lastUseTime=TimeUtil.currentTimeMillis();
      oldBK.count.incrementAndGet();
      oldBK.fromReq=requestSize >= REQUIRED_SIZE;
      oldBK.fromResp=responseSize >= REQUIRED_SIZE;
    }
 else {
      newBK.lastCmd=cmd;
      newBK.size=requestSize > responseSize ? requestSize : responseSize;
      newBK.lastUseTime=TimeUtil.currentTimeMillis();
      newBK.fromReq=requestSize >= REQUIRED_SIZE;
      newBK.fromResp=responseSize >= REQUIRED_SIZE;
      bkList.add(newBK);
      bkHashMap.put(key,newBK);
    }
  }
  finally {
    locking.set(false);
  }
}"
37500,"@Override public String toString(){
  StringBuffer sbuffer=new StringBuffer(100);
  sbuffer.append(""String_Node_Str"");
  sbuffer.append(""String_Node_Str"").append(delegateConn.toString());
  sbuffer.append(""String_Node_Str"").append(borrowed);
  if (heartbeatTime > 0) {
    sbuffer.append(""String_Node_Str"").append(heartbeatTime);
  }
  sbuffer.append(""String_Node_Str"").append(isZeroCopy);
  return sbuffer.toString();
}","@Override public String toString(){
  StringBuffer sbuffer=new StringBuffer(100);
  sbuffer.append(delegateConn.toString());
  sbuffer.append(""String_Node_Str"");
  sbuffer.append(""String_Node_Str"").append(borrowed);
  sbuffer.append(""String_Node_Str"").append(isZeroCopy);
  if (heartbeatTime > 0) {
    sbuffer.append(""String_Node_Str"").append(heartbeatTime);
  }
  sbuffer.append(""String_Node_Str"");
  return sbuffer.toString();
}"
37501,"@Override public void write(ByteBuffer buf){
  try {
    for (; ; ) {
      if (!rwLock.compareAndSet(false,true)) {
        break;
      }
    }
    buf.flip();
    if (buf.limit() <= BUF_SIZE) {
      mappedByteBuffer.clear();
      int position=0;
      int count=fileChannel.write(buf,position);
      if (buf.hasRemaining()) {
        throw new IOException(""String_Node_Str"" + count + ""String_Node_Str""+ buf.remaining());
      }
      write0(position,count);
    }
 else {
      int bufSize=buf.limit();
      int cnt=(bufSize / BUF_SIZE) + (bufSize % BUF_SIZE > 0 ? 1 : 0);
      int postion=0;
      for (int i=0; i < cnt; i++) {
        int limit=BUF_SIZE * i;
        if (limit > bufSize) {
          limit=bufSize - postion;
        }
        buf.position(postion);
        buf.limit(limit);
        ByteBuffer tmpBuf=buf.slice();
        mappedByteBuffer.clear();
        int count=fileChannel.write(tmpBuf,0);
        if (tmpBuf.hasRemaining()) {
          throw new IOException(""String_Node_Str"" + count + ""String_Node_Str""+ tmpBuf.remaining());
        }
        int tranfered=write0(0,count);
        postion+=tranfered;
      }
    }
  }
 catch (  IOException e) {
    LOGGER.error(""String_Node_Str"",e);
    this.close(""String_Node_Str"" + e);
  }
 finally {
    rwLock.set(false);
  }
}","@Override public void write(ByteBuffer buf){
  try {
    for (; ; ) {
      if (!rwLock.compareAndSet(false,true)) {
        break;
      }
    }
    buf.flip();
    int bufSize=buf.limit();
    if (bufSize <= BUF_SIZE) {
      mappedByteBuffer.clear();
      int position=0;
      int count=fileChannel.write(buf,position);
      if (buf.hasRemaining()) {
        throw new IOException(""String_Node_Str"" + count + ""String_Node_Str""+ buf.remaining());
      }
      write0(position,count);
    }
 else {
      int cnt=(bufSize / BUF_SIZE) + (bufSize % BUF_SIZE > 0 ? 1 : 0);
      int postion=0;
      for (int i=1; i <= cnt; i++) {
        int limit=BUF_SIZE * i;
        if (limit > bufSize) {
          limit=bufSize;
        }
        buf.position(postion);
        buf.limit(limit);
        ByteBuffer tmpBuf=buf.slice();
        mappedByteBuffer.clear();
        int count=fileChannel.write(tmpBuf,0);
        if (tmpBuf.hasRemaining()) {
          throw new IOException(""String_Node_Str"" + count + ""String_Node_Str""+ tmpBuf.remaining());
        }
        int tranfered=write0(0,count);
        postion+=tranfered;
      }
    }
  }
 catch (  IOException e) {
    LOGGER.error(""String_Node_Str"",e);
    this.close(""String_Node_Str"" + e);
  }
 finally {
    rwLock.set(false);
  }
}"
37502,"@Override public void setHandler(NIOHandler<? extends ClosableConnection> handler){
  delegateConn.setHandler(handler);
}","@Override public void setHandler(NIOHandler<? extends ClosableConnection> handler){
  this.delegateConn.setHandler(handler);
}"
37503,"@Override public void close(String reason){
  delegateConn.close(reason);
}","@Override public void close(String reason){
  delegateConn.close(reason);
  delegateConn.setNested(false);
  delegateConn.setParent(null);
}"
37504,"public BackendConnection(boolean isZeroCopy,SocketChannel socketChannel){
  if (isZeroCopy) {
    delegateConn=new ZeroCopyConnection(socketChannel);
  }
 else {
    delegateConn=new Connection(socketChannel);
  }
  this.isZeroCopy=true;
}","public BackendConnection(boolean isZeroCopy,SocketChannel socketChannel){
  if (isZeroCopy) {
    delegateConn=new ZeroCopyConnection(socketChannel);
  }
 else {
    delegateConn=new Connection(socketChannel);
  }
  delegateConn.setParent(this);
  delegateConn.setNested(true);
  this.isZeroCopy=true;
}"
37505,"@Override public String toString(){
  StringBuffer sbuffer=new StringBuffer(100);
  sbuffer.append(""String_Node_Str"").append(reactor);
  sbuffer.append(""String_Node_Str"").append(delegateConn.toString());
  sbuffer.append(""String_Node_Str"").append(borrowed);
  if (heartbeatTime > 0) {
    sbuffer.append(""String_Node_Str"").append(heartbeatTime);
  }
  sbuffer.append(""String_Node_Str"").append(isZeroCopy);
  return sbuffer.toString();
}","@Override public String toString(){
  StringBuffer sbuffer=new StringBuffer(100);
  sbuffer.append(""String_Node_Str"");
  sbuffer.append(""String_Node_Str"").append(delegateConn.toString());
  sbuffer.append(""String_Node_Str"").append(borrowed);
  if (heartbeatTime > 0) {
    sbuffer.append(""String_Node_Str"").append(heartbeatTime);
  }
  sbuffer.append(""String_Node_Str"").append(isZeroCopy);
  return sbuffer.toString();
}"
37506,"@SuppressWarnings(""String_Node_Str"") public void close(String reason){
  if (!isClosed.get()) {
    closeSocket();
    isClosed.set(true);
    this.closeTime=TimeUtil.currentTimeMillis();
    if (reason != null)     this.closeReason=reason;
    this.cleanup();
    NetSystem.getInstance().removeConnection(this);
    if (LOGGER.isDebugEnabled()) {
      LOGGER.debug(""String_Node_Str"" + reason + ""String_Node_Str""+ this.toString());
    }
    if (handler != null) {
      handler.onClosed(this,reason);
    }
    this.attachement=null;
  }
 else {
    this.cleanup();
  }
}","@SuppressWarnings(""String_Node_Str"") public void close(String reason){
  if (!isClosed.get()) {
    closeSocket();
    isClosed.set(true);
    this.closeTime=TimeUtil.currentTimeMillis();
    if (reason != null)     this.closeReason=reason;
    this.cleanup();
    if (isNested) {
      NetSystem.getInstance().removeConnection(parent);
      if (handler != null)       handler.onClosed(parent,reason);
    }
 else {
      NetSystem.getInstance().removeConnection(this);
      if (handler != null)       handler.onClosed(this,reason);
    }
    if (LOGGER.isDebugEnabled()) {
      LOGGER.debug(""String_Node_Str"" + reason + ""String_Node_Str""+ this.toString());
    }
    this.attachement=null;
  }
 else {
    this.cleanup();
  }
}"
37507,"@SuppressWarnings(""String_Node_Str"") public void register(Selector selector) throws IOException {
  try {
    processKey=socketChannel.register(selector,SelectionKey.OP_READ,this);
    if (LOGGER.isDebugEnabled()) {
      LOGGER.debug(""String_Node_Str"" + this);
    }
    this.setState(Connection.STATE_CONNECTED);
    NetSystem.getInstance().addConnection(this);
    this.handler.onConnected(this);
  }
  finally {
    if (isClosed()) {
      clearSelectionKey();
    }
  }
}","@SuppressWarnings(""String_Node_Str"") public void register(Selector selector) throws IOException {
  try {
    processKey=socketChannel.register(selector,SelectionKey.OP_READ,this);
    if (LOGGER.isDebugEnabled()) {
      LOGGER.debug(""String_Node_Str"" + this);
    }
    this.setState(Connection.STATE_CONNECTED);
    if (isNested) {
      NetSystem.getInstance().addConnection(parent);
      this.handler.onConnected(parent);
    }
 else {
      NetSystem.getInstance().addConnection(this);
      this.handler.onConnected(this);
    }
  }
  finally {
    if (isClosed()) {
      clearSelectionKey();
    }
  }
}"
37508,"/** 
 * , reactor 
 */
@SuppressWarnings(""String_Node_Str"") @Override public void asynRead() throws IOException {
  if (isClosed.get()) {
    return;
  }
  if (!reading.compareAndSet(false,true)) {
    LOGGER.info(""String_Node_Str"");
    return;
  }
  try {
    if (readBuffer == null) {
      if (direction == Direction.in)       readBuffer=allocate(1024 * 16);
 else       readBuffer=allocate(1024 * 64);
    }
    lastReadTime=TimeUtil.currentTimeMillis();
    int offset=0;
    for (; ; ) {
      if (isClosed()) {
        return;
      }
      int length=socketChannel.read(readBuffer);
      if (length == -1) {
        this.close(""String_Node_Str"");
        return;
      }
 else       if (length == 0 && !this.socketChannel.isOpen()) {
        this.close(""String_Node_Str"");
        return;
      }
      netInBytes+=length;
      netInCounter++;
      if (isFlowLimit() && netFlowMonitor.pool(length)) {
        flowClean();
        return;
      }
      if (!readBuffer.hasRemaining()) {
        if (readBuffer.capacity() >= maxCapacity) {
          LOGGER.warn(""String_Node_Str"",this);
          throw new IllegalArgumentException(""String_Node_Str"");
        }
        int newCapacity=readBuffer.capacity() << 1;
        newCapacity=(newCapacity > maxCapacity) ? maxCapacity : newCapacity;
        ByteBuffer newBuffer=allocate(newCapacity);
        readBuffer.position(offset);
        newBuffer.put(readBuffer);
        recycle(readBuffer);
        readBuffer=newBuffer;
        lastLargeMessageTime=TimeUtil.currentTimeMillis();
        largeCounter++;
        continue;
      }
      int dataLength=readBuffer.position();
      readBuffer.position(offset);
      byte[] data=new byte[dataLength];
      readBuffer.get(data,0,dataLength);
      handler.handleReadEvent(this,data);
      if (readBuffer != null && lastLargeMessageTime != 0 && lastLargeMessageTime < (lastReadTime - 30 * 1000L)) {
        if (LOGGER.isDebugEnabled()) {
          LOGGER.debug(""String_Node_Str"" + readBuffer.capacity());
        }
        ByteBuffer oldBuffer=readBuffer;
        ByteBuffer newBuffer=allocate(1024 * 16);
        readBuffer=newBuffer;
        if (oldBuffer.isDirect())         recycle(oldBuffer);
        lastLargeMessageTime=0;
      }
 else {
        if (readBuffer != null) {
          readBuffer.clear();
        }
      }
      break;
    }
  }
  finally {
    reading.set(false);
  }
}","/** 
 * , reactor 
 */
@SuppressWarnings(""String_Node_Str"") @Override public void asynRead() throws IOException {
  if (isClosed.get()) {
    return;
  }
  if (!reading.compareAndSet(false,true)) {
    LOGGER.info(""String_Node_Str"");
    return;
  }
  try {
    if (readBuffer == null) {
      if (direction == Direction.in)       readBuffer=allocate(1024 * 16);
 else       readBuffer=allocate(1024 * 64);
    }
    lastReadTime=TimeUtil.currentTimeMillis();
    int offset=0;
    for (; ; ) {
      if (isClosed()) {
        return;
      }
      int length=socketChannel.read(readBuffer);
      if (length == -1) {
        this.close(""String_Node_Str"");
        return;
      }
 else       if (length == 0 && !this.socketChannel.isOpen()) {
        this.close(""String_Node_Str"");
        return;
      }
      netInBytes+=length;
      netInCounter++;
      if (isFlowLimit() && netFlowMonitor.pool(length)) {
        flowClean();
        return;
      }
      if (!readBuffer.hasRemaining()) {
        if (readBuffer.capacity() >= maxCapacity) {
          LOGGER.warn(""String_Node_Str"",this);
          throw new IllegalArgumentException(""String_Node_Str"");
        }
        int newCapacity=readBuffer.capacity() << 1;
        newCapacity=(newCapacity > maxCapacity) ? maxCapacity : newCapacity;
        ByteBuffer newBuffer=allocate(newCapacity);
        readBuffer.position(offset);
        newBuffer.put(readBuffer);
        recycle(readBuffer);
        readBuffer=newBuffer;
        lastLargeMessageTime=TimeUtil.currentTimeMillis();
        largeCounter++;
        continue;
      }
      int dataLength=readBuffer.position();
      readBuffer.position(offset);
      byte[] data=new byte[dataLength];
      readBuffer.get(data,0,dataLength);
      if (isNested)       handler.handleReadEvent(parent,data);
 else       handler.handleReadEvent(this,data);
      if (readBuffer != null && lastLargeMessageTime != 0 && lastLargeMessageTime < (lastReadTime - 30 * 1000L)) {
        if (LOGGER.isDebugEnabled()) {
          LOGGER.debug(""String_Node_Str"" + readBuffer.capacity());
        }
        ByteBuffer oldBuffer=readBuffer;
        ByteBuffer newBuffer=allocate(1024 * 16);
        readBuffer=newBuffer;
        if (oldBuffer.isDirect())         recycle(oldBuffer);
        lastLargeMessageTime=0;
      }
 else {
        if (readBuffer != null) {
          readBuffer.clear();
        }
      }
      break;
    }
  }
  finally {
    reading.set(false);
  }
}"
37509,"@Override public void doNextWriteCheck(){
  if (!writing.compareAndSet(false,true)) {
    return;
  }
  if (writeQueue.isEmpty()) {
    return;
  }
  try {
    boolean noMoreData=write0();
    if (noMoreData && writeQueue.isEmpty()) {
      if ((processKey.isValid() && (processKey.interestOps() & SelectionKey.OP_WRITE) != 0)) {
        disableWrite();
      }
    }
 else {
      if ((processKey.isValid() && (processKey.interestOps() & SelectionKey.OP_WRITE) == 0)) {
        enableWrite(false);
      }
    }
  }
 catch (  IOException e) {
    if (LOGGER.isDebugEnabled()) {
      LOGGER.debug(""String_Node_Str"",e);
    }
    close(""String_Node_Str"" + e);
  }
 finally {
    writing.set(false);
  }
}","@Override public void doNextWriteCheck(){
  if (writeQueue.isEmpty()) {
    return;
  }
  if (!writing.compareAndSet(false,true)) {
    return;
  }
  try {
    boolean noMoreData=write0();
    if (noMoreData && writeQueue.isEmpty()) {
      if ((processKey.isValid() && (processKey.interestOps() & SelectionKey.OP_WRITE) != 0)) {
        disableWrite();
      }
    }
 else {
      if ((processKey.isValid() && (processKey.interestOps() & SelectionKey.OP_WRITE) == 0)) {
        enableWrite(false);
      }
    }
  }
 catch (  IOException e) {
    if (LOGGER.isDebugEnabled()) {
      LOGGER.debug(""String_Node_Str"",e);
    }
    close(""String_Node_Str"" + e);
  }
 finally {
    writing.set(false);
  }
}"
37510,"private void processPendingQueue(Selector selector){
  ClosableConnection c=null;
  while ((c=pendingQueue.poll()) != null) {
    try {
      c.register(selector);
    }
 catch (    Exception e) {
      LOGGER.warn(""String_Node_Str"",e);
      c.close(""String_Node_Str"");
    }
  }
}","private void processPendingQueue(Selector selector){
  ClosableConnection c=null;
  while ((c=pendingQueue.poll()) != null) {
    try {
      c.register(selector);
    }
 catch (    Exception e) {
      c.close(""String_Node_Str"");
    }
  }
}"
37511,"@SuppressWarnings(""String_Node_Str"") @Override public void asynRead() throws IOException {
  if (isClosed.get()) {
    return;
  }
  if (!rwLock.compareAndSet(false,true)) {
    return;
  }
  lastReadTime=TimeUtil.currentTimeMillis();
  try {
    for (; ; ) {
      int position=mappedByteBuffer.position();
      int count=BUF_SIZE - position;
      int tranfered=(int)fileChannel.transferFrom(socketChannel,position,count);
      mappedByteBuffer.position(position + tranfered);
      if (tranfered == 0 && count > 0) {
        tranfered=socketChannel.read(mappedByteBuffer);
      }
      if (tranfered > 0) {
        byte[] data=new byte[tranfered];
        mappedByteBuffer.flip();
        mappedByteBuffer.get(data,0,tranfered);
        System.out.println(""String_Node_Str"" + tranfered + ""String_Node_Str""+ new String(data));
        handler.handleReadEvent(this,data);
        break;
      }
 else       if (tranfered == 0) {
        LOGGER.warn(""String_Node_Str"",tranfered);
        if (!this.socketChannel.isOpen()) {
          this.close(""String_Node_Str"");
          return;
        }
        this.mappedByteBuffer.clear();
      }
 else {
        this.close(""String_Node_Str"");
        return;
      }
    }
  }
  finally {
    rwLock.set(false);
  }
}","@SuppressWarnings(""String_Node_Str"") @Override public void asynRead() throws IOException {
  if (isClosed.get()) {
    return;
  }
  if (!rwLock.compareAndSet(false,true)) {
    return;
  }
  lastReadTime=TimeUtil.currentTimeMillis();
  try {
    for (; ; ) {
      int position=mappedByteBuffer.position();
      int count=BUF_SIZE - position;
      int tranfered=(int)fileChannel.transferFrom(socketChannel,position,count);
      mappedByteBuffer.position(position + tranfered);
      if (tranfered == 0 && count > 0) {
        tranfered=socketChannel.read(mappedByteBuffer);
      }
      if (tranfered > 0) {
        byte[] data=new byte[tranfered];
        mappedByteBuffer.flip();
        mappedByteBuffer.get(data,0,tranfered);
        System.out.println(""String_Node_Str"" + tranfered + ""String_Node_Str""+ new String(data));
        if (isNested)         handler.handleReadEvent(parent,data);
 else         handler.handleReadEvent(this,data);
        break;
      }
 else       if (tranfered == 0) {
        LOGGER.warn(""String_Node_Str"",tranfered);
        if (!this.socketChannel.isOpen()) {
          this.close(""String_Node_Str"");
          return;
        }
        this.mappedByteBuffer.clear();
      }
 else {
        this.close(""String_Node_Str"");
        return;
      }
    }
  }
  finally {
    rwLock.set(false);
  }
}"
37512,"private void connect(Selector selector){
  ClosableConnection c=null;
  while ((c=connectQueue.poll()) != null) {
    try {
      SocketChannel channel=(SocketChannel)c.getSocketChannel();
      channel.register(selector,SelectionKey.OP_CONNECT,c);
      channel.connect(new InetSocketAddress(c.host,c.port));
    }
 catch (    Exception e) {
      LOGGER.error(""String_Node_Str"",e);
      c.close(""String_Node_Str"" + e.toString());
    }
  }
}","private void connect(Selector selector){
  ClosableConnection c=null;
  while ((c=connectQueue.poll()) != null) {
    try {
      SocketChannel channel=(SocketChannel)c.getSocketChannel();
      channel.register(selector,SelectionKey.OP_CONNECT,c);
      channel.connect(new InetSocketAddress(c.getHost(),c.getPort()));
    }
 catch (    Exception e) {
      LOGGER.error(""String_Node_Str"",e);
      c.close(""String_Node_Str"" + e.toString());
    }
  }
}"
37513,"/** 
 * , reactor 
 */
@SuppressWarnings(""String_Node_Str"") @Override protected void asynRead() throws IOException {
  if (isClosed.get()) {
    return;
  }
  if (!rwLock.compareAndSet(false,true)) {
    return;
  }
  lastReadTime=TimeUtil.currentTimeMillis();
  rewind();
  try {
    for (; ; ) {
      final int position=mappedByteBuffer.position();
      final int count=totalSize - position;
      int tranfered=(int)fileChannel.transferFrom(channel,position,count);
      mappedByteBuffer.position(position + tranfered);
      if (tranfered == 0 && count > 0) {
        tranfered=channel.read(mappedByteBuffer);
      }
      if (tranfered > 0) {
        int oldPos=mappedByteBuffer.position();
        mappedByteBuffer.position(0);
        ByteBuffer copyBuf=mappedByteBuffer.slice();
        copyBuf.limit(tranfered);
        byte[] data=new byte[tranfered];
        copyBuf.get(data);
        mappedByteBuffer.position(oldPos);
        System.out.println(""String_Node_Str"" + tranfered + ""String_Node_Str""+ new String(data));
        handler.handleReadEvent(this,data);
        break;
      }
 else       if (tranfered == 0) {
        if (!this.channel.isOpen()) {
          this.close(""String_Node_Str"");
          return;
        }
      }
 else {
        this.close(""String_Node_Str"");
        return;
      }
    }
  }
  finally {
    rwLock.set(false);
  }
}","/** 
 * , reactor 
 */
@SuppressWarnings(""String_Node_Str"") @Override protected void asynRead() throws IOException {
  if (isClosed.get()) {
    return;
  }
  if (!rwLock.compareAndSet(false,true)) {
    return;
  }
  lastReadTime=TimeUtil.currentTimeMillis();
  rewind();
  try {
    for (; ; ) {
      final int position=mappedByteBuffer.position();
      final int count=totalSize - position;
      int tranfered=(int)fileChannel.transferFrom(channel,position,count);
      mappedByteBuffer.position(position + tranfered);
      if (tranfered == 0 && count > 0) {
        tranfered=channel.read(mappedByteBuffer);
      }
      if (tranfered > 0) {
        int oldPos=mappedByteBuffer.position();
        mappedByteBuffer.position(position);
        ByteBuffer copyBuf=mappedByteBuffer.slice();
        copyBuf.limit(tranfered);
        byte[] data=new byte[tranfered];
        copyBuf.get(data);
        mappedByteBuffer.position(oldPos);
        System.out.println(""String_Node_Str"" + tranfered + ""String_Node_Str""+ new String(data));
        handler.handleReadEvent(this,data);
        break;
      }
 else       if (tranfered == 0) {
        if (!this.channel.isOpen()) {
          this.close(""String_Node_Str"");
          return;
        }
      }
 else {
        this.close(""String_Node_Str"");
        return;
      }
    }
  }
  finally {
    rwLock.set(false);
  }
}"
37514,"private void write0(int position,int count) throws IOException {
  int writed=(int)fileChannel.transferTo(position,count,channel);
  boolean noMoreData=writed == count;
  if (noMoreData) {
    if ((processKey.isValid() && (processKey.interestOps() & SelectionKey.OP_WRITE) != 0)) {
      disableWrite();
    }
  }
 else {
    if ((processKey.isValid() && (processKey.interestOps() & SelectionKey.OP_WRITE) == 0)) {
      enableWrite(false);
    }
  }
}","private void write0(int position,int count) throws IOException {
  int tranfered=(int)fileChannel.transferTo(position,count,channel);
  boolean noMoreData=tranfered == count;
  if (noMoreData) {
    if ((processKey.isValid() && (processKey.interestOps() & SelectionKey.OP_WRITE) != 0)) {
      disableWrite();
    }
  }
 else {
    if ((processKey.isValid() && (processKey.interestOps() & SelectionKey.OP_WRITE) == 0)) {
      enableWrite(false);
    }
  }
}"
37515,"public static void main(String[] args) throws IOException {
  Log4jInitializer.configureAndWatch(System.getProperty(""String_Node_Str""),""String_Node_Str"",30000L);
  String name=""String_Node_Str"";
  String bindIp=""String_Node_Str"";
  int port=8066;
  ConnectionFactory factory=new ZeroCopyConnectionFactory();
  NIOReactorPool reactorPool=new NIOReactorPool(""String_Node_Str"",8);
  final NIOAcceptor acceptor=new NIOAcceptor(name,bindIp,port,factory,reactorPool);
  acceptor.start();
}","public static void main(String[] args) throws IOException {
  Log4jInitializer.configureAndWatch(System.getProperty(""String_Node_Str""),""String_Node_Str"",30000L);
  BufferPool bufferPool=new BucketBufferPool(1024 * 1024 * 40,1024 * 1024 * 80,1024 * 16,1024,new int[]{1024},1024 * 32,3);
  new NetSystem(bufferPool,ExecutorUtil.create(""String_Node_Str"",2),ExecutorUtil.create(""String_Node_Str"",2));
  String name=""String_Node_Str"";
  String bindIp=""String_Node_Str"";
  int port=8066;
  ConnectionFactory factory=new ZeroCopyConnectionFactory();
  NIOReactorPool reactorPool=new NIOReactorPool(""String_Node_Str"",8);
  final NIOAcceptor acceptor=new NIOAcceptor(name,bindIp,port,factory,reactorPool);
  acceptor.start();
}"
37516,"public void handle(byte[] byteBuff){
  boolean isImmediateReleaseConReadLock=true;
  List<RedisRequest> requests=null;
  RedisRequest firstRequest=null;
  try {
    requests=requestDecoder.decode(byteBuff);
    if (requests == null || requests.size() == 0) {
      return;
    }
    firstRequest=requests.get(0);
    if (requests.size() == 1) {
      byte[] cmd=firstRequest.getArgs()[0];
      int len=cmd.length;
      if (len == 4) {
        if ((cmd[0] == 'A' || cmd[0] == 'a') && (cmd[1] == 'U' || cmd[1] == 'u') && (cmd[2] == 'T' || cmd[2] == 't')&& (cmd[3] == 'H' || cmd[3] == 'h')) {
          if (firstRequest.getArgs().length < 2) {
            frontCon.write(ERR_NO_AUTH_NO_PASSWORD);
            return;
          }
          auth(firstRequest);
          return;
        }
 else         if ((cmd[0] == 'E' || cmd[0] == 'e') && (cmd[1] == 'C' || cmd[1] == 'c') && (cmd[2] == 'H' || cmd[2] == 'h')&& (cmd[3] == 'O' || cmd[3] == 'o')) {
          echo(firstRequest);
          return;
        }
 else         if ((cmd[0] == 'P' || cmd[0] == 'p') && (cmd[1] == 'I' || cmd[1] == 'i') && (cmd[2] == 'N' || cmd[2] == 'n')&& (cmd[3] == 'G' || cmd[3] == 'g')) {
          frontCon.write(PONG);
          return;
        }
 else         if ((cmd[0] == 'Q' || cmd[0] == 'q') && (cmd[1] == 'U' || cmd[1] == 'u') && (cmd[2] == 'I' || cmd[2] == 'i')&& (cmd[3] == 'T' || cmd[3] == 't')) {
          frontCon.write(OK);
          frontCon.close(""String_Node_Str"");
          return;
        }
      }
 else       if (len == 6) {
        if ((cmd[0] == 'S' || cmd[0] == 's') && (cmd[1] == 'E' || cmd[1] == 'e') && (cmd[2] == 'L' || cmd[2] == 'l')&& (cmd[3] == 'E' || cmd[3] == 'e')&& (cmd[4] == 'C' || cmd[4] == 'c')&& (cmd[5] == 'T' || cmd[5] == 't')) {
          frontCon.write(OK);
          return;
        }
      }
    }
    if (!frontCon.isAuthenticated()) {
      byte[] cmd=firstRequest.getArgs()[0];
      if (cmd.length == 4 && (cmd[0] == 'A' || cmd[0] == 'a') && (cmd[1] == 'U' || cmd[1] == 'u') && (cmd[2] == 'T' || cmd[2] == 't') && (cmd[3] == 'H' || cmd[3] == 'h')) {
        auth(firstRequest);
        requests.remove(0);
        if (requests.isEmpty()) {
          return;
        }
      }
 else {
        frontCon.write(ERR_NO_AUTH);
        return;
      }
    }
    try {
      if (frontCon.getUserCfg().isAdmin() && requests.size() == 1) {
        String cmd=new String(firstRequest.getArgs()[0]).toUpperCase();
        RedisRequestPolicy policy=CommandParse.getPolicy(cmd);
        if (policy.getCategory() == CommandParse.MANAGE_CMD) {
          byte[] buff=Manage.execute(firstRequest,frontCon);
          if (buff != null)           frontCon.write(buff);
          return;
        }
      }
      RouteResult routeResult=RouteService.route(requests,frontCon);
      if (routeResult == null) {
        frontCon.write(""String_Node_Str"".getBytes());
        return;
      }
      if (intercept(routeResult)) {
        return;
      }
      currentCommandHandler=this.getCommandHandler(routeResult.getRequestType());
      currentCommandHandler.handle(routeResult);
      if (routeResult.getRequestType() != RedisRequestType.DEFAULT) {
        isImmediateReleaseConReadLock=false;
      }
    }
 catch (    InvalidRequestExistsException e) {
      if (e.isIsfaultTolerant()) {
        if (requests.size() > 1) {
          frontCon.write(ERR_INVALID_COMMAND);
        }
 else {
          frontCon.write(OK);
        }
      }
 else {
        StringBuffer errCmdBuffer=new StringBuffer(50);
        errCmdBuffer.append(""String_Node_Str"");
        errCmdBuffer.append(e.getMessage());
        errCmdBuffer.append(""String_Node_Str"");
        byte[] ERR_INVALID_COMMAND=errCmdBuffer.toString().getBytes();
        frontCon.write(ERR_INVALID_COMMAND);
      }
      LOGGER.warn(""String_Node_Str"",this.frontCon,requests);
    }
catch (    FullRequestNoThroughtException e) {
      for (int i=0; i < e.getRequests().size(); i++) {
        RedisRequest request=e.getRequests().get(i);
        if (request == null) {
          continue;
        }
        String cmd=new String(request.getArgs()[0]).toUpperCase();
        if (""String_Node_Str"".equals(cmd)) {
          auth(request);
        }
 else         if (""String_Node_Str"".equals(cmd)) {
          echo(request);
        }
 else         if (""String_Node_Str"".equals(cmd)) {
          select(request);
        }
 else         if (""String_Node_Str"".equals(cmd)) {
          frontCon.write(PONG);
        }
 else         if (""String_Node_Str"".equals(cmd)) {
          frontCon.write(OK);
          frontCon.close(""String_Node_Str"");
        }
      }
    }
catch (    PhysicalNodeUnavailableException e) {
      frontCon.write(""String_Node_Str"".getBytes());
    }
  }
 catch (  RedisRequestUnknowException e0) {
    frontCon.close(""String_Node_Str"");
  }
catch (  IOException e1) {
    String error=""String_Node_Str"" + e1.getMessage() + ""String_Node_Str"";
    frontCon.write(error.getBytes());
  }
 finally {
    if (isImmediateReleaseConReadLock)     frontCon.releaseLock();
  }
}","public void handle(byte[] byteBuff){
  boolean isImmediateReleaseConReadLock=true;
  List<RedisRequest> requests=null;
  RedisRequest firstRequest=null;
  try {
    requests=requestDecoder.decode(byteBuff);
    if (requests == null || requests.size() == 0) {
      return;
    }
    firstRequest=requests.get(0);
    if (requests.size() == 1) {
      byte[] cmd=firstRequest.getArgs()[0];
      int len=cmd.length;
      if (len == 4) {
        if ((cmd[0] == 'A' || cmd[0] == 'a') && (cmd[1] == 'U' || cmd[1] == 'u') && (cmd[2] == 'T' || cmd[2] == 't')&& (cmd[3] == 'H' || cmd[3] == 'h')) {
          if (firstRequest.getArgs().length < 2) {
            frontCon.write(ERR_NO_AUTH_NO_PASSWORD);
            return;
          }
          auth(firstRequest);
          return;
        }
 else         if ((cmd[0] == 'E' || cmd[0] == 'e') && (cmd[1] == 'C' || cmd[1] == 'c') && (cmd[2] == 'H' || cmd[2] == 'h')&& (cmd[3] == 'O' || cmd[3] == 'o')) {
          echo(firstRequest);
          return;
        }
 else         if ((cmd[0] == 'P' || cmd[0] == 'p') && (cmd[1] == 'I' || cmd[1] == 'i') && (cmd[2] == 'N' || cmd[2] == 'n')&& (cmd[3] == 'G' || cmd[3] == 'g')) {
          frontCon.write(PONG);
          return;
        }
 else         if ((cmd[0] == 'Q' || cmd[0] == 'q') && (cmd[1] == 'U' || cmd[1] == 'u') && (cmd[2] == 'I' || cmd[2] == 'i')&& (cmd[3] == 'T' || cmd[3] == 't')) {
          frontCon.write(OK);
          frontCon.close(""String_Node_Str"");
          return;
        }
      }
 else       if (len == 6) {
        if ((cmd[0] == 'S' || cmd[0] == 's') && (cmd[1] == 'E' || cmd[1] == 'e') && (cmd[2] == 'L' || cmd[2] == 'l')&& (cmd[3] == 'E' || cmd[3] == 'e')&& (cmd[4] == 'C' || cmd[4] == 'c')&& (cmd[5] == 'T' || cmd[5] == 't')) {
          frontCon.write(OK);
          return;
        }
      }
    }
    if (!frontCon.isAuthenticated()) {
      byte[] cmd=firstRequest.getArgs()[0];
      if (cmd.length == 4 && (cmd[0] == 'A' || cmd[0] == 'a') && (cmd[1] == 'U' || cmd[1] == 'u') && (cmd[2] == 'T' || cmd[2] == 't') && (cmd[3] == 'H' || cmd[3] == 'h')) {
        boolean isPass=auth(firstRequest);
        if (isPass) {
          requests.remove(0);
          if (requests.isEmpty()) {
            return;
          }
        }
 else {
          return;
        }
      }
 else {
        frontCon.write(ERR_NO_AUTH);
        return;
      }
    }
    try {
      if (frontCon.getUserCfg().isAdmin() && requests.size() == 1) {
        String cmd=new String(firstRequest.getArgs()[0]).toUpperCase();
        RedisRequestPolicy policy=CommandParse.getPolicy(cmd);
        if (policy.getCategory() == CommandParse.MANAGE_CMD) {
          byte[] buff=Manage.execute(firstRequest,frontCon);
          if (buff != null)           frontCon.write(buff);
          return;
        }
      }
      RouteResult routeResult=RouteService.route(requests,frontCon);
      if (routeResult == null) {
        frontCon.write(""String_Node_Str"".getBytes());
        return;
      }
      if (intercept(routeResult)) {
        return;
      }
      currentCommandHandler=this.getCommandHandler(routeResult.getRequestType());
      currentCommandHandler.handle(routeResult);
      if (routeResult.getRequestType() != RedisRequestType.DEFAULT) {
        isImmediateReleaseConReadLock=false;
      }
    }
 catch (    InvalidRequestExistsException e) {
      if (e.isIsfaultTolerant()) {
        if (requests.size() > 1) {
          frontCon.write(ERR_INVALID_COMMAND);
        }
 else {
          frontCon.write(OK);
        }
      }
 else {
        StringBuffer errCmdBuffer=new StringBuffer(50);
        errCmdBuffer.append(""String_Node_Str"");
        errCmdBuffer.append(e.getMessage());
        errCmdBuffer.append(""String_Node_Str"");
        byte[] ERR_INVALID_COMMAND=errCmdBuffer.toString().getBytes();
        frontCon.write(ERR_INVALID_COMMAND);
      }
      LOGGER.warn(""String_Node_Str"",this.frontCon,requests);
    }
catch (    FullRequestNoThroughtException e) {
      for (int i=0; i < e.getRequests().size(); i++) {
        RedisRequest request=e.getRequests().get(i);
        if (request == null) {
          continue;
        }
        String cmd=new String(request.getArgs()[0]).toUpperCase();
        if (""String_Node_Str"".equals(cmd)) {
          auth(request);
        }
 else         if (""String_Node_Str"".equals(cmd)) {
          echo(request);
        }
 else         if (""String_Node_Str"".equals(cmd)) {
          select(request);
        }
 else         if (""String_Node_Str"".equals(cmd)) {
          frontCon.write(PONG);
        }
 else         if (""String_Node_Str"".equals(cmd)) {
          frontCon.write(OK);
          frontCon.close(""String_Node_Str"");
        }
      }
    }
catch (    PhysicalNodeUnavailableException e) {
      frontCon.write(""String_Node_Str"".getBytes());
    }
  }
 catch (  RedisRequestUnknowException e0) {
    frontCon.close(""String_Node_Str"");
  }
catch (  IOException e1) {
    String error=""String_Node_Str"" + e1.getMessage() + ""String_Node_Str"";
    frontCon.write(error.getBytes());
  }
 finally {
    if (isImmediateReleaseConReadLock)     frontCon.releaseLock();
  }
}"
37517,"/** 
 * 
 */
public void checkConnections(){
  Iterator<Entry<Long,AbstractConnection>> it=allConnections.entrySet().iterator();
  while (it.hasNext()) {
    AbstractConnection c=it.next().getValue();
    if (c == null) {
      it.remove();
      continue;
    }
    if (c instanceof RedisBackendConnection) {
      RedisBackendConnection backendCon=(RedisBackendConnection)c;
      if (backendCon.isBorrowed() && backendCon.getLastTime() < TimeUtil.currentTimeMillis() - TIMEOUT) {
        StringBuffer errBuffer=new StringBuffer();
        errBuffer.append(""String_Node_Str"").append(c);
        if (c.getAttachement() != null) {
          errBuffer.append(""String_Node_Str"").append(c.getAttachement());
        }
        errBuffer.append(""String_Node_Str"").append(backendCon.getChannel().isConnected());
        errBuffer.append(""String_Node_Str"").append(backendCon.getChannel().isBlocking());
        errBuffer.append(""String_Node_Str"").append(backendCon.getChannel().isOpen());
        errBuffer.append(""String_Node_Str"").append(backendCon.getChannel().socket().isConnected());
        errBuffer.append(""String_Node_Str"").append(backendCon.getChannel().socket().isClosed());
        LOGGER.warn(errBuffer.toString());
        c.close(""String_Node_Str"");
      }
    }
    if (c.isClosed()) {
      it.remove();
    }
 else {
      if (c.isConnected() && !c.writeQueue.isEmpty()) {
        c.doNextWriteCheck();
      }
      c.idleCheck();
    }
  }
}","/** 
 * 
 */
public void checkConnections(){
  Iterator<Entry<Long,AbstractConnection>> it=allConnections.entrySet().iterator();
  while (it.hasNext()) {
    AbstractConnection c=it.next().getValue();
    if (c == null) {
      it.remove();
      continue;
    }
    if (c instanceof BackendConnection) {
      BackendConnection backendCon=(BackendConnection)c;
      if (backendCon.isBorrowed() && backendCon.getLastTime() < TimeUtil.currentTimeMillis() - TIMEOUT) {
        StringBuffer errBuffer=new StringBuffer();
        errBuffer.append(""String_Node_Str"").append(c);
        if (c.getAttachement() != null) {
          errBuffer.append(""String_Node_Str"").append(c.getAttachement());
        }
        errBuffer.append(""String_Node_Str"").append(backendCon.getChannel().isConnected());
        errBuffer.append(""String_Node_Str"").append(backendCon.getChannel().isBlocking());
        errBuffer.append(""String_Node_Str"").append(backendCon.getChannel().isOpen());
        errBuffer.append(""String_Node_Str"").append(backendCon.getChannel().socket().isConnected());
        errBuffer.append(""String_Node_Str"").append(backendCon.getChannel().socket().isClosed());
        LOGGER.warn(errBuffer.toString());
        c.close(""String_Node_Str"");
      }
    }
    if (c.isClosed()) {
      it.remove();
    }
 else {
      if (c.isConnected() && !c.writeQueue.isEmpty()) {
        c.doNextWriteCheck();
      }
      c.idleCheck();
    }
  }
}"
37518,"private void initRunning(){
  if (!isStart()) {
    return;
  }
  byte[] bytes=JsonUtils.marshalToByte(serverData);
  try {
    mutex.set(false);
    zkClient.create(path,bytes,CreateMode.EPHEMERAL);
    activeData=serverData;
    processActiveEnter();
    mutex.set(true);
  }
 catch (  ZkNodeExistsException e) {
    bytes=zkClient.readData(path,true);
    if (bytes == null) {
      initRunning();
    }
 else {
      activeData=JsonUtils.unmarshalFromByte(bytes,ServerRunningData.class);
    }
  }
catch (  ZkNoNodeException e) {
    zkClient.createPersistent(path,true);
    initRunning();
  }
}","private void initRunning(){
  if (!isStart()) {
    return;
  }
  byte[] bytes=JsonUtils.marshalToByte(serverData);
  try {
    mutex.set(false);
    zkClient.create(path,bytes,CreateMode.EPHEMERAL);
    activeData=serverData;
    processActiveEnter();
    mutex.set(true);
  }
 catch (  ZkNodeExistsException e) {
    bytes=zkClient.readData(path,true);
    if (bytes == null) {
      initRunning();
    }
 else {
      activeData=JsonUtils.unmarshalFromByte(bytes,ServerRunningData.class);
    }
  }
catch (  ZkNoNodeException e) {
    if (path.lastIndexOf(File.separator) > 0) {
      String fatherPath=path.substring(0,path.lastIndexOf(File.separator));
      zkClient.createPersistent(fatherPath,true);
      initRunning();
    }
 else {
      LOGGER.error(""String_Node_Str"" + path + ""String_Node_Str"",e);
    }
  }
}"
37519,"@Override public void reloadExtraCfg() throws Exception {
  Map<String,TopicCfg> newTopicCfgMap=KafkaConfigLoader.loadTopicCfgMap(this.id,ConfigLoader.buidCfgAbsPathFor(""String_Node_Str""));
  KafkaCtx.getInstance().load(newTopicCfgMap,this);
  Map<String,TopicCfg> oldTopicCfgMap=topicCfgMap;
  for (  TopicCfg newTopicCfg : newTopicCfgMap.values()) {
    TopicCfg oldTopicCfg=oldTopicCfgMap.get(newTopicCfg.getName());
    if (oldTopicCfg != null) {
      for (      BrokerPartition newPartition : newTopicCfg.getRunningOffset().getPartitions().values()) {
        BrokerPartition oldPartition=oldTopicCfg.getRunningOffset().getPartition(newPartition.getPartition());
        if (oldPartition != null) {
          newPartition.setProducerConsumerOffset(oldPartition.getProducerConsumerOffset());
        }
 else {
        }
      }
    }
  }
}","@Override public void reloadExtraCfg() throws Exception {
  Map<String,TopicCfg> newTopicCfgMap=KafkaConfigLoader.loadTopicCfgMap(this.id,ConfigLoader.buidCfgAbsPathFor(""String_Node_Str""));
  KafkaCtx.getInstance().load(newTopicCfgMap,this);
  Map<String,TopicCfg> oldTopicCfgMap=topicCfgMap;
  for (  TopicCfg newTopicCfg : newTopicCfgMap.values()) {
    TopicCfg oldTopicCfg=oldTopicCfgMap.get(newTopicCfg.getName());
    if (oldTopicCfg != null) {
      for (      BrokerPartition newPartition : newTopicCfg.getRunningOffset().getPartitions().values()) {
        BrokerPartition oldPartition=oldTopicCfg.getRunningOffset().getPartition(newPartition.getPartition());
        if (oldPartition != null) {
          newPartition.setProducerConsumerOffset(oldPartition.getProducerConsumerOffset());
        }
 else {
        }
      }
    }
  }
  this.topicCfgMap=newTopicCfgMap;
}"
37520,"public byte[] reloadAll(){
  try {
    Map<Integer,PoolCfg> poolCfgMap=RedisEngineCtx.INSTANCE().getPoolCfgMap();
    for (    Entry<Integer,PoolCfg> entry : poolCfgMap.entrySet()) {
      PoolCfg poolCfg=entry.getValue();
      if (poolCfg instanceof KafkaPoolCfg)       poolCfg.reloadExtraCfg();
    }
  }
 catch (  Exception e) {
    LOGGER.error(""String_Node_Str"",e);
    StringBuffer sb=new StringBuffer();
    sb.append(""String_Node_Str"").append(e.getMessage()).append(""String_Node_Str"");
    return sb.toString().getBytes();
  }
 finally {
    lock.unlock();
  }
  return ""String_Node_Str"".getBytes();
}","public byte[] reloadAll(){
  try {
    Map<Integer,PoolCfg> poolCfgMap=RedisEngineCtx.INSTANCE().getPoolCfgMap();
    for (    PoolCfg poolCfg : poolCfgMap.values()) {
      if (poolCfg instanceof KafkaPoolCfg)       poolCfg.reloadExtraCfg();
    }
  }
 catch (  Exception e) {
    LOGGER.error(""String_Node_Str"",e);
    StringBuffer sb=new StringBuffer();
    sb.append(""String_Node_Str"").append(e.getMessage()).append(""String_Node_Str"");
    return sb.toString().getBytes();
  }
 finally {
    lock.unlock();
  }
  return ""String_Node_Str"".getBytes();
}"
37521,"/** 
 *  ---------------------------------------- USE [POOL_ID] RELOAD USER RELOAD ALL RELOAD FRONT RELOAD PATH RELOAD KAFKA JVM  JAVA_HOME  ---------------------------------------- JVM JSTACK JVM JSTAT JVM JMAP_HISTO JVM JMAP_HEAP JVM PS SHOW USER SHOW USER_NET_IO  SHOW CPU SHOW MEM SHOW QPS SHOW CONN SHOW USER_CONN SHOW BUFFER SHOW BIGKEY SHOW BIGLENGTH SHOW SLOWKEY SHOW CMD SHOW USER_CMD SHOW USER_CMD_DETAIL USER SHOW VER SHOW NET_IO  SHOW NETBYTES SHOW VM SHOW POOL SHOW COST SHOW USER_DAY_NET_IO SHOW POOL_NET_IO POOLNAME SHOW TOPIC SHOW LOG_ERROR SHOW LOG_WARN SHOW LOG_INFO SHOW LOG_DEBUG
 */
public static byte[] execute(final RedisRequest request,RedisFrontConnection frontCon){
  int numArgs=request.getNumArgs();
  if (numArgs != 2 && numArgs != 3 && numArgs != 4) {
    return ""String_Node_Str"".getBytes();
  }
  byte[] arg1=request.getArgs()[0];
  String arg2=new String(request.getArgs()[1]);
  if (arg1 == null || arg2 == null) {
    return ""String_Node_Str"".getBytes();
  }
  if (arg1.length == 3) {
    if ((arg1[0] == 'J' || arg1[0] == 'j') && (arg1[1] == 'V' || arg1[1] == 'v') && (arg1[2] == 'M' || arg1[2] == 'm')) {
      StringBuffer cmdBuffer=new StringBuffer();
      if (JavaUtils.isLinux())       cmdBuffer.append(JAVA_BIN_PATH);
      if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid());
        return encode(getOS_JVM_INFO(cmdBuffer.toString()));
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid());
        return encode(getOS_JVM_INFO(cmdBuffer.toString()));
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid());
        return encode(getOS_JVM_INFO(cmdBuffer.toString()));
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid());
        return encode(getOS_JVM_INFO(cmdBuffer.toString()));
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        String cmd=""String_Node_Str"" + JavaUtils.process_pid() + ""String_Node_Str"";
        List<String> line=new ArrayList<String>();
        try {
          line.add(ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",cmd));
        }
 catch (        IOException e) {
          line.add(e.getMessage());
        }
        return encode(line);
      }
    }
 else     if ((arg1[0] == 'U' || arg1[0] == 'u') && (arg1[1] == 'S' || arg1[1] == 's') && (arg1[2] == 'E' || arg1[2] == 'e')) {
      try {
        int poolId=Integer.parseInt(arg2);
        AbstractPool pool=RedisEngineCtx.INSTANCE().getPoolMap().get(poolId);
        if (pool == null) {
          return ""String_Node_Str"".getBytes();
        }
 else {
          int poolType=pool.getType();
          frontCon.getUserCfg().setUsePool(poolId,poolType);
          return ""String_Node_Str"".getBytes();
        }
      }
 catch (      NumberFormatException e) {
        return ""String_Node_Str"".getBytes();
      }
    }
  }
 else   if (arg1.length == 4) {
    if ((arg1[0] == 'S' || arg1[0] == 's') && (arg1[1] == 'H' || arg1[1] == 'h') && (arg1[2] == 'O' || arg1[2] == 'o')&& (arg1[3] == 'W' || arg1[3] == 'w')) {
      if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        AccessStatInfoResult result=StatUtil.getTotalAccessStatInfo().get(StatUtil.STAT_KEY);
        if (result != null) {
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(""String_Node_Str"").append(result.totalCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.slowCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.maxCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.minCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.avgCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.procTime).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.created);
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<Object> lines=new ArrayList<Object>();
        long sum=0;
        Set<Entry<String,Command>> entrys=StatUtil.getCommandCountMap().entrySet();
        for (        Entry<String,Command> entry : entrys) {
          Command parent=entry.getValue();
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(parent.cmd).append(""String_Node_Str"").append(parent.count.get());
          if (parent.childs != null) {
            List<String> list=new ArrayList<String>();
            list.add(sBuffer.toString());
            for (            Entry<String,Command> childEntry : parent.childs.entrySet()) {
              Command child=childEntry.getValue();
              StringBuffer sb=new StringBuffer();
              sb.append(""String_Node_Str"").append(child.cmd).append(""String_Node_Str"").append(child.count.get());
              list.add(sb.toString());
            }
            lines.add(list);
          }
 else {
            lines.add(sBuffer.toString());
          }
          sum+=parent.count.get();
        }
        StringBuffer sBuffer=new StringBuffer();
        sBuffer.append(""String_Node_Str"").append(""String_Node_Str"").append(sum);
        lines.add(sBuffer.toString());
        return encodeObject(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer title=new StringBuffer();
        title.append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"");
        lines.add(title.toString());
        Set<Entry<String,UserCommand>> entrys=StatUtil.getUserCommandCountMap().entrySet();
        for (        Entry<String,UserCommand> entry : entrys) {
          UserCommand userCommand=entry.getValue();
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(userCommand.user).append(""String_Node_Str"").append(userCommand.readComandCount.get()).append(""String_Node_Str"").append(userCommand.writeCommandCount.get()).append(""String_Node_Str"").append(userCommand.readComandCount.get() + userCommand.writeCommandCount.get());
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") && numArgs == 3) {
        String user=new String(request.getArgs()[2]);
        List<String> lines=new ArrayList<String>();
        StringBuffer title=new StringBuffer();
        title.append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"");
        lines.add(title.toString());
        int sum=0;
        ConcurrentHashMap<String,UserCommand> userCommandMap=StatUtil.getUserCommandCountMap();
        UserCommand userCommand=userCommandMap.get(user);
        if (userCommand != null) {
          for (          Entry<String,AtomicLong> entry : userCommand.commandCount.entrySet()) {
            StringBuffer sBuffer=new StringBuffer();
            sBuffer.append(user).append(""String_Node_Str"").append(entry.getKey()).append(""String_Node_Str"").append(entry.getValue().get());
            lines.add(sBuffer.toString());
          }
        }
        StringBuffer end=new StringBuffer();
        end.append(""String_Node_Str"").append(""String_Node_Str"").append(sum);
        lines.add(end.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        lines.add(Versions.SERVER_VERSION);
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        if (JavaUtils.isLinux()) {
          StringBuffer cmdBuffer=new StringBuffer();
          cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid()).append(""String_Node_Str"");
          String response;
          try {
            response=ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",cmdBuffer.toString());
            lines.add(response);
          }
 catch (          IOException e) {
            LOGGER.error(""String_Node_Str"",e);
            lines.add(""String_Node_Str"");
          }
        }
 else {
          lines.add(""String_Node_Str"");
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        lines.add(""String_Node_Str"" + JavaUtils.bytesToString2(Math.round(JavaUtils.getMemUsage())));
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        int frontSize=0;
        int backendSize=0;
        ConcurrentMap<Long,AbstractConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,AbstractConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          AbstractConnection c=it.next().getValue();
          if (c instanceof RedisFrontConnection) {
            frontSize++;
          }
 else {
            backendSize++;
          }
        }
        StringBuffer sBuffer=new StringBuffer();
        sBuffer.append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"").append(frontSize).append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"").append(backendSize).append(""String_Node_Str"");
        return sBuffer.toString().getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        Map<String,Integer> userMap=new HashMap<String,Integer>();
        ConcurrentMap<Long,AbstractConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,AbstractConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          AbstractConnection c=it.next().getValue();
          if (c instanceof RedisFrontConnection) {
            userMap.put(((RedisFrontConnection)c).getPassword(),1 + (userMap.get(((RedisFrontConnection)c).getPassword()) == null ? 0 : userMap.get(((RedisFrontConnection)c).getPassword())));
          }
        }
        StringBuffer sBuffer=new StringBuffer();
        sBuffer.append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"");
        Iterator<Entry<String,Integer>> users=userMap.entrySet().iterator();
        while (users.hasNext()) {
          sBuffer.append(""String_Node_Str"");
          Entry<String,Integer> en=users.next();
          sBuffer.append(en.getKey());
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(en.getValue());
        }
        sBuffer.append(""String_Node_Str"");
        return sBuffer.toString().getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        ConcurrentHashMap<String,AccessStatInfoResult> results=StatUtil.getTotalAccessStatInfo();
        for (        Map.Entry<String,AccessStatInfoResult> entry : results.entrySet()) {
          AccessStatInfoResult result=entry.getValue();
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(""String_Node_Str"").append(result.key).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.totalCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.slowCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.maxCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.minCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.avgCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.procTime).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netInBytes[1]).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netInBytes[2]).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netInBytes[3]).append(""String_Node_Str"").append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netOutBytes[1]).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netOutBytes[2]).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netOutBytes[3]).append(""String_Node_Str"").append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.created);
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        ConcurrentMap<Long,AbstractConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,AbstractConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          AbstractConnection c=it.next().getValue();
          if (c instanceof RedisFrontConnection) {
            lines.add(c.toString());
          }
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        BufferPool bufferPool=NetSystem.getInstance().getBufferPool();
        long usedBufferSize=bufferPool.getUsedBufferSize().get();
        long maxBufferSize=bufferPool.getMaxBufferSize();
        long minBufferSize=bufferPool.getMinBufferSize();
        long sharedOptsCount=bufferPool.getSharedOptsCount();
        int capacity=0;
        if (bufferPool instanceof BucketBufferPool) {
          BucketBufferPool p=(BucketBufferPool)bufferPool;
          AbstractBucket[] buckets=p.buckets();
          for (          AbstractBucket b : buckets) {
            capacity+=b.getCount();
          }
          int bucketLen=buckets.length;
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(capacity).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(minBufferSize).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(maxBufferSize).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(usedBufferSize).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(bucketLen).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(sharedOptsCount).append(""String_Node_Str"");
          return sBuffer.toString().getBytes();
        }
 else         if (bufferPool instanceof PageBufferPool) {
          List<String> lines=new ArrayList<String>();
          ConcurrentHashMap<Long,Long> bufferpoolUsageMap=bufferPool.getNetDirectMemoryUsage();
          long usedforNetwork=0;
          for (          Map.Entry<Long,Long> entry : bufferpoolUsageMap.entrySet()) {
            long value=entry.getValue();
            lines.add(""String_Node_Str"" + entry.getKey() + ""String_Node_Str""+ (value > 0 ? JavaUtils.bytesToString2(value) : ""String_Node_Str""));
            usedforNetwork=usedforNetwork + value;
          }
          lines.add(""String_Node_Str"" + JavaUtils.bytesToString2(minBufferSize));
          lines.add(""String_Node_Str"" + JavaUtils.bytesToString2(maxBufferSize));
          lines.add(""String_Node_Str"" + JavaUtils.bytesToString2(usedforNetwork));
          return encode(lines);
        }
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        BufferPool bufferPool=NetSystem.getInstance().getBufferPool();
        if (bufferPool instanceof BucketBufferPool) {
          BucketBufferPool p=(BucketBufferPool)bufferPool;
          AbstractBucket[] buckets=p.buckets();
          for (          AbstractBucket b : buckets) {
            StringBuffer sBuffer=new StringBuffer();
            sBuffer.append(""String_Node_Str"").append(b.getChunkSize()).append(""String_Node_Str"");
            sBuffer.append(""String_Node_Str"").append(b.getQueueSize()).append(""String_Node_Str"");
            sBuffer.append(""String_Node_Str"").append(b.getCount()).append(""String_Node_Str"");
            sBuffer.append(""String_Node_Str"").append(b.getUsedCount()).append(""String_Node_Str"");
            sBuffer.append(""String_Node_Str"").append(b.getShared());
            lines.add(sBuffer.toString());
          }
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        for (        BigKey bigkey : StatUtil.getBigKeys()) {
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(bigkey.cmd).append(""String_Node_Str"");
          sBuffer.append(bigkey.key).append(""String_Node_Str"");
          sBuffer.append(bigkey.size).append(""String_Node_Str"");
          sBuffer.append(bigkey.count.get());
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        Map<String,AtomicInteger> poolConnections=new HashMap<String,AtomicInteger>();
        ConcurrentMap<Long,AbstractConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,AbstractConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          AbstractConnection c=it.next().getValue();
          if (c instanceof RedisBackendConnection) {
            String poolName=((RedisBackendConnection)c).getPhysicalNode().getPoolName();
            AtomicInteger poolConnCount=poolConnections.get(poolName);
            if (poolConnCount == null) {
              poolConnections.put(poolName,new AtomicInteger(1));
            }
 else {
              poolConnCount.incrementAndGet();
            }
            lines.add(c.toString());
          }
 else           if (c instanceof KafkaBackendConnection) {
            String poolName=((KafkaBackendConnection)c).getPhysicalNode().getPoolName();
            AtomicInteger poolConnCount=poolConnections.get(poolName);
            if (poolConnCount == null) {
              poolConnections.put(poolName,new AtomicInteger(1));
            }
 else {
              poolConnCount.incrementAndGet();
            }
            lines.add(c.toString());
          }
        }
        StringBuffer sb=new StringBuffer();
        for (        Map.Entry<String,AtomicInteger> entry : poolConnections.entrySet()) {
          sb.append(entry.getKey()).append(""String_Node_Str"").append(entry.getValue().get()).append(""String_Node_Str"");
        }
        lines.add(sb.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") && numArgs == 3) {
        String poolName=new String(request.getArgs()[2]);
        List<String> lines=new ArrayList<String>();
        ConcurrentMap<Long,AbstractConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,AbstractConnection>> it=allConnections.entrySet().iterator();
        long minStartupTime=-1;
        long maxLastLargeMessageTime=-1;
        long totalLargeCount=0;
        long totalNetInCount=0;
        long totalNetInBytes=0;
        long totalNetOutBytes=0;
        while (it.hasNext()) {
          AbstractConnection c=it.next().getValue();
          if (c instanceof RedisBackendConnection) {
            if (((RedisBackendConnection)c).getPhysicalNode().getPoolName().equals(poolName)) {
              StringBuffer sb=new StringBuffer();
              sb.append(""String_Node_Str"").append(c.getId()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(c.getStartupTime()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(c.getLastLargeMessageTime()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(c.getLargeCount()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(c.getNetInCount()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(c.getNetInBytes()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(c.getNetOutBytes()).append(""String_Node_Str"");
              lines.add(sb.toString());
              minStartupTime=minStartupTime < 0 ? c.getStartupTime() : Math.min(minStartupTime,c.getStartupTime());
              maxLastLargeMessageTime=Math.max(maxLastLargeMessageTime,c.getLastLargeMessageTime());
              totalLargeCount=totalLargeCount + c.getLargeCount();
              totalNetInCount=totalNetInCount + c.getNetInCount();
              totalNetInBytes=totalNetInBytes + c.getNetInBytes();
              totalNetOutBytes=totalNetOutBytes + c.getNetOutBytes();
            }
          }
        }
        StringBuffer end=new StringBuffer();
        end.append(""String_Node_Str"").append(minStartupTime).append(""String_Node_Str"");
        end.append(""String_Node_Str"").append(maxLastLargeMessageTime).append(""String_Node_Str"");
        end.append(""String_Node_Str"").append(totalLargeCount).append(""String_Node_Str"");
        end.append(""String_Node_Str"").append(totalNetInCount).append(""String_Node_Str"");
        end.append(""String_Node_Str"").append(totalNetInBytes).append(""String_Node_Str"");
        end.append(""String_Node_Str"").append(totalNetOutBytes).append(""String_Node_Str"");
        lines.add(end.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") || arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        AccessStatInfoResult result=StatUtil.getTotalAccessStatInfo().get(StatUtil.STAT_KEY);
        if (result != null) {
          StringBuffer line0=new StringBuffer();
          line0.append(""String_Node_Str"").append(""String_Node_Str"");
          line0.append(""String_Node_Str"").append(""String_Node_Str"");
          line0.append(""String_Node_Str"").append(""String_Node_Str"");
          line0.append(""String_Node_Str"").append(""String_Node_Str"");
          line0.append(""String_Node_Str"");
          StringBuffer line1=new StringBuffer();
          line1.append(""String_Node_Str"").append(""String_Node_Str"");
          line1.append(result.netInBytes[0]).append(""String_Node_Str"");
          line1.append(result.netInBytes[1]).append(""String_Node_Str"");
          line1.append(result.netInBytes[2]).append(""String_Node_Str"");
          line1.append(result.netInBytes[3]);
          StringBuffer line2=new StringBuffer();
          line2.append(""String_Node_Str"").append(""String_Node_Str"");
          line2.append(result.netOutBytes[0]).append(""String_Node_Str"");
          line2.append(result.netOutBytes[1]).append(""String_Node_Str"");
          line2.append(result.netOutBytes[2]).append(""String_Node_Str"");
          line2.append(result.netOutBytes[3]);
          StringBuffer line3=new StringBuffer();
          line3.append(result.created);
          lines.add(line0.toString());
          lines.add(line1.toString());
          lines.add(line2.toString());
          lines.add(line3.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        for (        Map.Entry<String,AccessStatInfoResult> entry : StatUtil.getTotalAccessStatInfo().entrySet()) {
          if (!StatUtil.STAT_KEY.equals(entry.getKey())) {
            AccessStatInfoResult result=entry.getValue();
            StringBuffer line1=new StringBuffer();
            line1.append(result.key).append(""String_Node_Str"");
            line1.append(""String_Node_Str"").append(""String_Node_Str"");
            line1.append(result.netInBytes[0]).append(""String_Node_Str"");
            line1.append(result.netInBytes[1]).append(""String_Node_Str"");
            line1.append(result.netInBytes[2]).append(""String_Node_Str"");
            line1.append(result.netInBytes[3]);
            StringBuffer line2=new StringBuffer();
            line2.append(result.key).append(""String_Node_Str"");
            line2.append(""String_Node_Str"").append(""String_Node_Str"");
            line2.append(result.netOutBytes[0]).append(""String_Node_Str"");
            line2.append(result.netOutBytes[1]).append(""String_Node_Str"");
            line2.append(result.netOutBytes[2]).append(""String_Node_Str"");
            line2.append(result.netOutBytes[3]);
            StringBuffer line3=new StringBuffer();
            line3.append(result.created);
            lines.add(line1.toString());
            lines.add(line2.toString());
            lines.add(line3.toString());
          }
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        long totalNetIn=0;
        long totalNetOut=0;
        for (        Map.Entry<String,UserNetFlow> entry : StatUtil.getUserFlowMap().entrySet()) {
          if (!StatUtil.STAT_KEY.equals(entry.getKey())) {
            StringBuffer sb=new StringBuffer();
            UserNetFlow userNetIo=entry.getValue();
            sb.append(userNetIo.password).append(""String_Node_Str"");
            sb.append(JavaUtils.bytesToString2(userNetIo.netIn.get())).append(""String_Node_Str"");
            sb.append(JavaUtils.bytesToString2(userNetIo.netOut.get()));
            totalNetIn=totalNetIn + userNetIo.netIn.get();
            totalNetOut=totalNetOut + userNetIo.netOut.get();
            lines.add(sb.toString());
          }
        }
        StringBuffer total=new StringBuffer();
        total.append(""String_Node_Str"").append(""String_Node_Str"");
        total.append(JavaUtils.bytesToString2(totalNetIn)).append(""String_Node_Str"");
        total.append(JavaUtils.bytesToString2(totalNetOut));
        lines.add(total.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=showLog(request,""String_Node_Str"");
        return encode2(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=showLog(request,""String_Node_Str"");
        return encode2(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=showLog(request,""String_Node_Str"");
        return encode2(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=showLog(request,""String_Node_Str"");
        return encode2(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> ret=new ArrayList<String>();
        try {
          String cmd1=ShellUtils.osType == ShellUtils.OSType.OS_TYPE_MAC ? ""String_Node_Str"" : ""String_Node_Str"";
          String cmd2=ShellUtils.osType == ShellUtils.OSType.OS_TYPE_MAC ? ""String_Node_Str"" : ""String_Node_Str"";
          String iostatOut=ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",cmd1);
          String vmstatOut=ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",cmd2);
          StringBuilder sb=new StringBuilder();
          sb.append(iostatOut);
          sb.append(""String_Node_Str"");
          sb.append(""String_Node_Str"");
          sb.append(vmstatOut);
          String[] lines=sb.toString().split(""String_Node_Str"");
          ret.add(""String_Node_Str"");
          for (int i=1; i < lines.length; i++) {
            if (lines[i].equals(""String_Node_Str""))             continue;
            ret.add(lines[i]);
          }
        }
 catch (        IOException e) {
          LOGGER.error(""String_Node_Str"",e);
          ret.add(""String_Node_Str"");
        }
        return encode2(ret);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<Object> list=new ArrayList<Object>();
        Map<Integer,AbstractPool> pools=RedisEngineCtx.INSTANCE().getPoolMap();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        list.add(titleLine.toString());
        for (        AbstractPool pool : pools.values()) {
          if (pool instanceof RedisStandalonePool) {
            StringBuffer sb=new StringBuffer();
            RedisStandalonePool redisStandalonePool=(RedisStandalonePool)pool;
            PhysicalNode physicalNode=redisStandalonePool.getPhysicalNode();
            if (physicalNode == null)             continue;
            sb.append(""String_Node_Str"");
            sb.append(redisStandalonePool.getId()).append(""String_Node_Str"");
            sb.append(physicalNode.getPoolName()).append(""String_Node_Str"");
            sb.append(""String_Node_Str"").append(""String_Node_Str"");
            sb.append(physicalNode.getName()).append(""String_Node_Str"");
            sb.append(physicalNode.getMinCon()).append(""String_Node_Str"");
            sb.append(physicalNode.getMaxCon()).append(""String_Node_Str"");
            sb.append(physicalNode.getIdleCount()).append(""String_Node_Str"");
            sb.append(physicalNode.getActiveCount());
            list.add(sb.toString());
          }
 else           if (pool instanceof RedisClusterPool) {
            RedisClusterPool redisClusterPool=(RedisClusterPool)pool;
            Map<String,ClusterNode> masters=redisClusterPool.getMasters();
            List<String> clusterInfo=new ArrayList<String>();
            for (            ClusterNode clusterNode : masters.values()) {
              PhysicalNode physicalNode=clusterNode.getPhysicalNode();
              StringBuffer sb=new StringBuffer();
              sb.append(redisClusterPool.getId()).append(""String_Node_Str"");
              sb.append(physicalNode.getPoolName()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(""String_Node_Str"");
              sb.append(physicalNode.getName()).append(""String_Node_Str"");
              sb.append(physicalNode.getMinCon()).append(""String_Node_Str"");
              sb.append(physicalNode.getMaxCon()).append(""String_Node_Str"");
              sb.append(physicalNode.getIdleCount()).append(""String_Node_Str"");
              sb.append(physicalNode.getActiveCount()).append(""String_Node_Str"");
              ;
              sb.append(!clusterNode.isFail());
              clusterInfo.add(sb.toString());
              sb.append(clusterNode.getConnectInfo());
            }
            list.add(clusterInfo);
          }
 else           if (pool instanceof KafkaPool) {
            KafkaPool kafkaPool=(KafkaPool)pool;
            Map<Integer,PhysicalNode> physicalNodes=kafkaPool.getPhysicalNodes();
            for (            PhysicalNode physicalNode : physicalNodes.values()) {
              StringBuffer sb=new StringBuffer();
              sb.append(""String_Node_Str"");
              sb.append(kafkaPool.getId()).append(""String_Node_Str"");
              sb.append(physicalNode.getPoolName()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(""String_Node_Str"");
              sb.append(physicalNode.getName()).append(""String_Node_Str"");
              sb.append(physicalNode.getMinCon()).append(""String_Node_Str"");
              sb.append(physicalNode.getMaxCon()).append(""String_Node_Str"");
              sb.append(physicalNode.getIdleCount()).append(""String_Node_Str"");
              sb.append(physicalNode.getActiveCount());
              list.add(sb.toString());
            }
          }
        }
        return encodeObject(list);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        Collection<Entry<String,AtomicLong>> entrys=StatUtil.getCommandProcTimeMap().entrySet();
        List<String> lines=new ArrayList<String>();
        for (        Entry<String,AtomicLong> entry : entrys) {
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(entry.getKey()).append(""String_Node_Str"").append(entry.getValue().get());
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        for (        BigLength bigLength : StatUtil.getBigLengthMap().values()) {
          StringBuffer line1=new StringBuffer();
          line1.append(bigLength.cmd).append(""String_Node_Str"");
          line1.append(bigLength.key).append(""String_Node_Str"");
          line1.append(bigLength.length.get()).append(""String_Node_Str"");
          line1.append(bigLength.count_1k.get()).append(""String_Node_Str"");
          line1.append(bigLength.count_10k.get());
          lines.add(line1.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        for (        SlowKey slowKey : StatUtil.getSlowKey()) {
          StringBuffer line1=new StringBuffer();
          line1.append(slowKey.cmd).append(""String_Node_Str"");
          line1.append(slowKey.key).append(""String_Node_Str"");
          line1.append(slowKey.count);
          lines.add(line1.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") && (numArgs == 3 || numArgs == 2)) {
        Map<String,KafkaCfg> kafkaMap=RedisEngineCtx.INSTANCE().getKafkaMap();
        List<String> lines=new ArrayList<String>();
        if (numArgs == 2) {
          StringBuffer titleLine=new StringBuffer();
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"");
          lines.add(titleLine.toString());
          for (          Entry<String,KafkaCfg> entry : kafkaMap.entrySet()) {
            KafkaCfg kafkaCfg=entry.getValue();
            StringBuffer line=new StringBuffer();
            line.append(kafkaCfg.getTopic()).append(""String_Node_Str"");
            line.append(kafkaCfg.getPoolId()).append(""String_Node_Str"");
            line.append(kafkaCfg.getPartitions()).append(""String_Node_Str"");
            line.append(kafkaCfg.getReplicationFactor()).append(""String_Node_Str"");
            line.append(kafkaCfg.getProducers()).append(""String_Node_Str"");
            line.append(kafkaCfg.getConsumers());
            lines.add(line.toString());
          }
        }
 else {
          StringBuffer titleLine=new StringBuffer();
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"");
          lines.add(titleLine.toString());
          String topic=new String(request.getArgs()[2]);
          KafkaCfg kafkaCfg=kafkaMap.get(topic);
          Map<Integer,MetaDataOffset> offsets=kafkaCfg.getMetaData().getOffsets();
          MetaDataPartition[] partitions=kafkaCfg.getMetaData().getPartitions();
          for (          MetaDataPartition partition : partitions) {
            int pt=partition.getPartition();
            MetaDataOffset offset=offsets.get(pt);
            StringBuffer line=new StringBuffer();
            line.append(kafkaCfg.getTopic()).append(""String_Node_Str"");
            line.append(partition.getLeader().getHost()).append(partition.getLeader().getPort()).append(""String_Node_Str"");
            line.append(pt).append(""String_Node_Str"");
            line.append(offset.getProducerOffset()).append(""String_Node_Str"");
            line.append(offset.getAllConsumerOffset());
            lines.add(line.toString());
          }
        }
        return encode(lines);
      }
    }
 else     if ((arg1[0] == 'N' || arg1[0] == 'n') && (arg1[1] == 'O' || arg1[1] == 'o') && (arg1[2] == 'D' || arg1[2] == 'd')&& (arg1[3] == 'E' || arg1[3] == 'e')) {
      return ""String_Node_Str"".getBytes();
    }
  }
 else   if (arg1.length == 6) {
    if ((arg1[0] == 'R' || arg1[0] == 'r') && (arg1[1] == 'E' || arg1[1] == 'e') && (arg1[2] == 'L' || arg1[2] == 'l')&& (arg1[3] == 'O' || arg1[3] == 'o')&& (arg1[4] == 'A' || arg1[4] == 'a')&& (arg1[5] == 'D' || arg1[5] == 'd')) {
      if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        byte[] buff=RedisEngineCtx.INSTANCE().reloadAll();
        return buff;
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        byte[] buff=RedisEngineCtx.INSTANCE().reloadUser();
        return buff;
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        ConcurrentMap<Long,AbstractConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,AbstractConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          AbstractConnection c=it.next().getValue();
          if (c instanceof RedisFrontConnection) {
            LOGGER.info(""String_Node_Str"",c);
            c.close(""String_Node_Str"");
          }
        }
        return ""String_Node_Str"".getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        JAVA_BIN_PATH=new String(request.getArgs()[2]);
        return ""String_Node_Str"".getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        byte[] buff=KafkaLoad.instance().reLoad();
        return buff;
      }
    }
  }
 else   if (arg1.length == 2) {
    if ((arg1[0] == 'Z' || arg1[0] == 'z') && (arg1[1] == 'K' || arg1[1] == 'k')) {
      return ZkClientManage.execute(request);
    }
  }
 else   if (arg1.length == 7) {
    if ((arg1[0] == 'C' || arg1[0] == 'c') && (arg1[1] == 'L' || arg1[1] == 'l') && (arg1[2] == 'U' || arg1[2] == 'u')&& (arg1[3] == 'S' || arg1[3] == 's')&& (arg1[4] == 'T' || arg1[4] == 't')&& (arg1[5] == 'E' || arg1[5] == 'e')&& (arg1[6] == 'R' || arg1[6] == 'r')) {
      AbstractPool pool=RedisEngineCtx.INSTANCE().getPoolMap().get(frontCon.getUserCfg().getPoolId());
      if (pool.getType() != 1) {
        return ""String_Node_Str"".getBytes();
      }
      PhysicalNode pysicalNode=((RedisClusterPool)pool).getPhysicalNodeBySlot(0);
      if (pysicalNode == null) {
        return ""String_Node_Str"".getBytes();
      }
      try {
        RedisBackendConnection backendCon=(RedisBackendConnection)pysicalNode.getConnection(new DirectTransTofrontCallBack(),frontCon);
        if (backendCon == null) {
          frontCon.writeErrMessage(""String_Node_Str"");
        }
 else {
          backendCon.write(request.encode());
        }
        return null;
      }
 catch (      IOException e) {
        LOGGER.error(""String_Node_Str"",e);
      }
    }
  }
  return ""String_Node_Str"".getBytes();
}","/** 
 *  ---------------------------------------- USE [POOL_ID] RELOAD USER RELOAD ALL RELOAD FRONT RELOAD PATH RELOAD KAFKA JVM  JAVA_HOME  ---------------------------------------- JVM JSTACK JVM JSTAT JVM JMAP_HISTO JVM JMAP_HEAP JVM PS SHOW USER SHOW USER_NET_IO  SHOW CPU SHOW MEM SHOW QPS SHOW CONN SHOW USER_CONN SHOW BUFFER SHOW BIGKEY SHOW BIGLENGTH SHOW SLOWKEY SHOW CMD SHOW USER_CMD SHOW USER_CMD_DETAIL USER SHOW VER SHOW NET_IO  SHOW NETBYTES SHOW VM SHOW POOL SHOW COST SHOW USER_DAY_NET_IO SHOW POOL_NET_IO POOLNAME SHOW TOPIC SHOW LOG_ERROR SHOW LOG_WARN SHOW LOG_INFO SHOW LOG_DEBUG
 */
public static byte[] execute(final RedisRequest request,RedisFrontConnection frontCon){
  int numArgs=request.getNumArgs();
  if (numArgs != 2 && numArgs != 3 && numArgs != 4) {
    return ""String_Node_Str"".getBytes();
  }
  byte[] arg1=request.getArgs()[0];
  String arg2=new String(request.getArgs()[1]);
  if (arg1 == null || arg2 == null) {
    return ""String_Node_Str"".getBytes();
  }
  if (arg1.length == 3) {
    if ((arg1[0] == 'J' || arg1[0] == 'j') && (arg1[1] == 'V' || arg1[1] == 'v') && (arg1[2] == 'M' || arg1[2] == 'm')) {
      StringBuffer cmdBuffer=new StringBuffer();
      if (JavaUtils.isLinux())       cmdBuffer.append(JAVA_BIN_PATH);
      if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid());
        return encode(getOS_JVM_INFO(cmdBuffer.toString()));
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid());
        return encode(getOS_JVM_INFO(cmdBuffer.toString()));
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid());
        return encode(getOS_JVM_INFO(cmdBuffer.toString()));
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid());
        return encode(getOS_JVM_INFO(cmdBuffer.toString()));
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        String cmd=""String_Node_Str"" + JavaUtils.process_pid() + ""String_Node_Str"";
        List<String> line=new ArrayList<String>();
        try {
          line.add(ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",cmd));
        }
 catch (        IOException e) {
          line.add(e.getMessage());
        }
        return encode(line);
      }
    }
 else     if ((arg1[0] == 'U' || arg1[0] == 'u') && (arg1[1] == 'S' || arg1[1] == 's') && (arg1[2] == 'E' || arg1[2] == 'e')) {
      try {
        int poolId=Integer.parseInt(arg2);
        AbstractPool pool=RedisEngineCtx.INSTANCE().getPoolMap().get(poolId);
        if (pool == null) {
          return ""String_Node_Str"".getBytes();
        }
 else {
          int poolType=pool.getType();
          frontCon.getUserCfg().setUsePool(poolId,poolType);
          return ""String_Node_Str"".getBytes();
        }
      }
 catch (      NumberFormatException e) {
        return ""String_Node_Str"".getBytes();
      }
    }
  }
 else   if (arg1.length == 4) {
    if ((arg1[0] == 'S' || arg1[0] == 's') && (arg1[1] == 'H' || arg1[1] == 'h') && (arg1[2] == 'O' || arg1[2] == 'o')&& (arg1[3] == 'W' || arg1[3] == 'w')) {
      if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        AccessStatInfoResult result=StatUtil.getTotalAccessStatInfo().get(StatUtil.STAT_KEY);
        if (result != null) {
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(""String_Node_Str"").append(result.totalCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.slowCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.maxCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.minCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.avgCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.procTime).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.created);
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<Object> lines=new ArrayList<Object>();
        long sum=0;
        Set<Entry<String,Command>> entrys=StatUtil.getCommandCountMap().entrySet();
        for (        Entry<String,Command> entry : entrys) {
          Command parent=entry.getValue();
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(parent.cmd).append(""String_Node_Str"").append(parent.count.get());
          if (parent.childs != null) {
            List<String> list=new ArrayList<String>();
            list.add(sBuffer.toString());
            for (            Entry<String,Command> childEntry : parent.childs.entrySet()) {
              Command child=childEntry.getValue();
              StringBuffer sb=new StringBuffer();
              sb.append(""String_Node_Str"").append(child.cmd).append(""String_Node_Str"").append(child.count.get());
              list.add(sb.toString());
            }
            lines.add(list);
          }
 else {
            lines.add(sBuffer.toString());
          }
          sum+=parent.count.get();
        }
        StringBuffer sBuffer=new StringBuffer();
        sBuffer.append(""String_Node_Str"").append(""String_Node_Str"").append(sum);
        lines.add(sBuffer.toString());
        return encodeObject(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer title=new StringBuffer();
        title.append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"");
        lines.add(title.toString());
        Set<Entry<String,UserCommand>> entrys=StatUtil.getUserCommandCountMap().entrySet();
        for (        Entry<String,UserCommand> entry : entrys) {
          UserCommand userCommand=entry.getValue();
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(userCommand.user).append(""String_Node_Str"").append(userCommand.readComandCount.get()).append(""String_Node_Str"").append(userCommand.writeCommandCount.get()).append(""String_Node_Str"").append(userCommand.readComandCount.get() + userCommand.writeCommandCount.get());
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") && numArgs == 3) {
        String user=new String(request.getArgs()[2]);
        List<String> lines=new ArrayList<String>();
        StringBuffer title=new StringBuffer();
        title.append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"").append(""String_Node_Str"");
        lines.add(title.toString());
        int sum=0;
        ConcurrentHashMap<String,UserCommand> userCommandMap=StatUtil.getUserCommandCountMap();
        UserCommand userCommand=userCommandMap.get(user);
        if (userCommand != null) {
          for (          Entry<String,AtomicLong> entry : userCommand.commandCount.entrySet()) {
            StringBuffer sBuffer=new StringBuffer();
            sBuffer.append(user).append(""String_Node_Str"").append(entry.getKey()).append(""String_Node_Str"").append(entry.getValue().get());
            lines.add(sBuffer.toString());
          }
        }
        StringBuffer end=new StringBuffer();
        end.append(""String_Node_Str"").append(""String_Node_Str"").append(sum);
        lines.add(end.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        lines.add(Versions.SERVER_VERSION);
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        if (JavaUtils.isLinux()) {
          StringBuffer cmdBuffer=new StringBuffer();
          cmdBuffer.append(""String_Node_Str"").append(JavaUtils.process_pid()).append(""String_Node_Str"");
          String response;
          try {
            response=ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",cmdBuffer.toString());
            lines.add(response);
          }
 catch (          IOException e) {
            LOGGER.error(""String_Node_Str"",e);
            lines.add(""String_Node_Str"");
          }
        }
 else {
          lines.add(""String_Node_Str"");
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        lines.add(""String_Node_Str"" + JavaUtils.bytesToString2(Math.round(JavaUtils.getMemUsage())));
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        int frontSize=0;
        int backendSize=0;
        ConcurrentMap<Long,AbstractConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,AbstractConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          AbstractConnection c=it.next().getValue();
          if (c instanceof RedisFrontConnection) {
            frontSize++;
          }
 else {
            backendSize++;
          }
        }
        StringBuffer sBuffer=new StringBuffer();
        sBuffer.append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"").append(frontSize).append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"").append(backendSize).append(""String_Node_Str"");
        return sBuffer.toString().getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        Map<String,Integer> userMap=new HashMap<String,Integer>();
        ConcurrentMap<Long,AbstractConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,AbstractConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          AbstractConnection c=it.next().getValue();
          if (c instanceof RedisFrontConnection) {
            userMap.put(((RedisFrontConnection)c).getPassword(),1 + (userMap.get(((RedisFrontConnection)c).getPassword()) == null ? 0 : userMap.get(((RedisFrontConnection)c).getPassword())));
          }
        }
        StringBuffer sBuffer=new StringBuffer();
        sBuffer.append(""String_Node_Str"");
        sBuffer.append(""String_Node_Str"");
        Iterator<Entry<String,Integer>> users=userMap.entrySet().iterator();
        while (users.hasNext()) {
          sBuffer.append(""String_Node_Str"");
          Entry<String,Integer> en=users.next();
          sBuffer.append(en.getKey());
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(en.getValue());
        }
        sBuffer.append(""String_Node_Str"");
        return sBuffer.toString().getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        ConcurrentHashMap<String,AccessStatInfoResult> results=StatUtil.getTotalAccessStatInfo();
        for (        Map.Entry<String,AccessStatInfoResult> entry : results.entrySet()) {
          AccessStatInfoResult result=entry.getValue();
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(""String_Node_Str"").append(result.key).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.totalCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.slowCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.maxCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.minCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.avgCount).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.procTime).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netInBytes[1]).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netInBytes[2]).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netInBytes[3]).append(""String_Node_Str"").append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netOutBytes[1]).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netOutBytes[2]).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.netOutBytes[3]).append(""String_Node_Str"").append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(result.created);
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        ConcurrentMap<Long,AbstractConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,AbstractConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          AbstractConnection c=it.next().getValue();
          if (c instanceof RedisFrontConnection) {
            lines.add(c.toString());
          }
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        BufferPool bufferPool=NetSystem.getInstance().getBufferPool();
        long usedBufferSize=bufferPool.getUsedBufferSize().get();
        long maxBufferSize=bufferPool.getMaxBufferSize();
        long minBufferSize=bufferPool.getMinBufferSize();
        long sharedOptsCount=bufferPool.getSharedOptsCount();
        int capacity=0;
        if (bufferPool instanceof BucketBufferPool) {
          BucketBufferPool p=(BucketBufferPool)bufferPool;
          AbstractBucket[] buckets=p.buckets();
          for (          AbstractBucket b : buckets) {
            capacity+=b.getCount();
          }
          int bucketLen=buckets.length;
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(capacity).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(minBufferSize).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(maxBufferSize).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(usedBufferSize).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(bucketLen).append(""String_Node_Str"");
          sBuffer.append(""String_Node_Str"").append(sharedOptsCount).append(""String_Node_Str"");
          return sBuffer.toString().getBytes();
        }
 else         if (bufferPool instanceof PageBufferPool) {
          List<String> lines=new ArrayList<String>();
          ConcurrentHashMap<Long,Long> bufferpoolUsageMap=bufferPool.getNetDirectMemoryUsage();
          long usedforNetwork=0;
          for (          Map.Entry<Long,Long> entry : bufferpoolUsageMap.entrySet()) {
            long value=entry.getValue();
            lines.add(""String_Node_Str"" + entry.getKey() + ""String_Node_Str""+ (value > 0 ? JavaUtils.bytesToString2(value) : ""String_Node_Str""));
            usedforNetwork=usedforNetwork + value;
          }
          lines.add(""String_Node_Str"" + JavaUtils.bytesToString2(minBufferSize));
          lines.add(""String_Node_Str"" + JavaUtils.bytesToString2(maxBufferSize));
          lines.add(""String_Node_Str"" + JavaUtils.bytesToString2(usedforNetwork));
          return encode(lines);
        }
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        BufferPool bufferPool=NetSystem.getInstance().getBufferPool();
        if (bufferPool instanceof BucketBufferPool) {
          BucketBufferPool p=(BucketBufferPool)bufferPool;
          AbstractBucket[] buckets=p.buckets();
          for (          AbstractBucket b : buckets) {
            StringBuffer sBuffer=new StringBuffer();
            sBuffer.append(""String_Node_Str"").append(b.getChunkSize()).append(""String_Node_Str"");
            sBuffer.append(""String_Node_Str"").append(b.getQueueSize()).append(""String_Node_Str"");
            sBuffer.append(""String_Node_Str"").append(b.getCount()).append(""String_Node_Str"");
            sBuffer.append(""String_Node_Str"").append(b.getUsedCount()).append(""String_Node_Str"");
            sBuffer.append(""String_Node_Str"").append(b.getShared());
            lines.add(sBuffer.toString());
          }
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        for (        BigKey bigkey : StatUtil.getBigKeys()) {
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(bigkey.cmd).append(""String_Node_Str"");
          sBuffer.append(bigkey.key).append(""String_Node_Str"");
          sBuffer.append(bigkey.size).append(""String_Node_Str"");
          sBuffer.append(bigkey.count.get());
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        Map<String,AtomicInteger> poolConnections=new HashMap<String,AtomicInteger>();
        ConcurrentMap<Long,AbstractConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,AbstractConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          AbstractConnection c=it.next().getValue();
          if (c instanceof RedisBackendConnection) {
            String poolName=((RedisBackendConnection)c).getPhysicalNode().getPoolName();
            AtomicInteger poolConnCount=poolConnections.get(poolName);
            if (poolConnCount == null) {
              poolConnections.put(poolName,new AtomicInteger(1));
            }
 else {
              poolConnCount.incrementAndGet();
            }
            lines.add(c.toString());
          }
 else           if (c instanceof KafkaBackendConnection) {
            String poolName=((KafkaBackendConnection)c).getPhysicalNode().getPoolName();
            AtomicInteger poolConnCount=poolConnections.get(poolName);
            if (poolConnCount == null) {
              poolConnections.put(poolName,new AtomicInteger(1));
            }
 else {
              poolConnCount.incrementAndGet();
            }
            lines.add(c.toString());
          }
        }
        StringBuffer sb=new StringBuffer();
        for (        Map.Entry<String,AtomicInteger> entry : poolConnections.entrySet()) {
          sb.append(entry.getKey()).append(""String_Node_Str"").append(entry.getValue().get()).append(""String_Node_Str"");
        }
        lines.add(sb.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") && numArgs == 3) {
        String poolName=new String(request.getArgs()[2]);
        List<String> lines=new ArrayList<String>();
        ConcurrentMap<Long,AbstractConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,AbstractConnection>> it=allConnections.entrySet().iterator();
        long minStartupTime=-1;
        long maxLastLargeMessageTime=-1;
        long totalLargeCount=0;
        long totalNetInCount=0;
        long totalNetInBytes=0;
        long totalNetOutBytes=0;
        while (it.hasNext()) {
          AbstractConnection c=it.next().getValue();
          if (c instanceof RedisBackendConnection) {
            if (((RedisBackendConnection)c).getPhysicalNode().getPoolName().equals(poolName)) {
              StringBuffer sb=new StringBuffer();
              sb.append(""String_Node_Str"").append(c.getId()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(c.getStartupTime()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(c.getLastLargeMessageTime()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(c.getLargeCount()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(c.getNetInCount()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(c.getNetInBytes()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(c.getNetOutBytes()).append(""String_Node_Str"");
              lines.add(sb.toString());
              minStartupTime=minStartupTime < 0 ? c.getStartupTime() : Math.min(minStartupTime,c.getStartupTime());
              maxLastLargeMessageTime=Math.max(maxLastLargeMessageTime,c.getLastLargeMessageTime());
              totalLargeCount=totalLargeCount + c.getLargeCount();
              totalNetInCount=totalNetInCount + c.getNetInCount();
              totalNetInBytes=totalNetInBytes + c.getNetInBytes();
              totalNetOutBytes=totalNetOutBytes + c.getNetOutBytes();
            }
          }
        }
        StringBuffer end=new StringBuffer();
        end.append(""String_Node_Str"").append(minStartupTime).append(""String_Node_Str"");
        end.append(""String_Node_Str"").append(maxLastLargeMessageTime).append(""String_Node_Str"");
        end.append(""String_Node_Str"").append(totalLargeCount).append(""String_Node_Str"");
        end.append(""String_Node_Str"").append(totalNetInCount).append(""String_Node_Str"");
        end.append(""String_Node_Str"").append(totalNetInBytes).append(""String_Node_Str"");
        end.append(""String_Node_Str"").append(totalNetOutBytes).append(""String_Node_Str"");
        lines.add(end.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") || arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        AccessStatInfoResult result=StatUtil.getTotalAccessStatInfo().get(StatUtil.STAT_KEY);
        if (result != null) {
          StringBuffer line0=new StringBuffer();
          line0.append(""String_Node_Str"").append(""String_Node_Str"");
          line0.append(""String_Node_Str"").append(""String_Node_Str"");
          line0.append(""String_Node_Str"").append(""String_Node_Str"");
          line0.append(""String_Node_Str"").append(""String_Node_Str"");
          line0.append(""String_Node_Str"");
          StringBuffer line1=new StringBuffer();
          line1.append(""String_Node_Str"").append(""String_Node_Str"");
          line1.append(result.netInBytes[0]).append(""String_Node_Str"");
          line1.append(result.netInBytes[1]).append(""String_Node_Str"");
          line1.append(result.netInBytes[2]).append(""String_Node_Str"");
          line1.append(result.netInBytes[3]);
          StringBuffer line2=new StringBuffer();
          line2.append(""String_Node_Str"").append(""String_Node_Str"");
          line2.append(result.netOutBytes[0]).append(""String_Node_Str"");
          line2.append(result.netOutBytes[1]).append(""String_Node_Str"");
          line2.append(result.netOutBytes[2]).append(""String_Node_Str"");
          line2.append(result.netOutBytes[3]);
          StringBuffer line3=new StringBuffer();
          line3.append(result.created);
          lines.add(line0.toString());
          lines.add(line1.toString());
          lines.add(line2.toString());
          lines.add(line3.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        for (        Map.Entry<String,AccessStatInfoResult> entry : StatUtil.getTotalAccessStatInfo().entrySet()) {
          if (!StatUtil.STAT_KEY.equals(entry.getKey())) {
            AccessStatInfoResult result=entry.getValue();
            StringBuffer line1=new StringBuffer();
            line1.append(result.key).append(""String_Node_Str"");
            line1.append(""String_Node_Str"").append(""String_Node_Str"");
            line1.append(result.netInBytes[0]).append(""String_Node_Str"");
            line1.append(result.netInBytes[1]).append(""String_Node_Str"");
            line1.append(result.netInBytes[2]).append(""String_Node_Str"");
            line1.append(result.netInBytes[3]);
            StringBuffer line2=new StringBuffer();
            line2.append(result.key).append(""String_Node_Str"");
            line2.append(""String_Node_Str"").append(""String_Node_Str"");
            line2.append(result.netOutBytes[0]).append(""String_Node_Str"");
            line2.append(result.netOutBytes[1]).append(""String_Node_Str"");
            line2.append(result.netOutBytes[2]).append(""String_Node_Str"");
            line2.append(result.netOutBytes[3]);
            StringBuffer line3=new StringBuffer();
            line3.append(result.created);
            lines.add(line1.toString());
            lines.add(line2.toString());
            lines.add(line3.toString());
          }
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        long totalNetIn=0;
        long totalNetOut=0;
        for (        Map.Entry<String,UserNetFlow> entry : StatUtil.getUserFlowMap().entrySet()) {
          if (!StatUtil.STAT_KEY.equals(entry.getKey())) {
            StringBuffer sb=new StringBuffer();
            UserNetFlow userNetIo=entry.getValue();
            sb.append(userNetIo.password).append(""String_Node_Str"");
            sb.append(JavaUtils.bytesToString2(userNetIo.netIn.get())).append(""String_Node_Str"");
            sb.append(JavaUtils.bytesToString2(userNetIo.netOut.get()));
            totalNetIn=totalNetIn + userNetIo.netIn.get();
            totalNetOut=totalNetOut + userNetIo.netOut.get();
            lines.add(sb.toString());
          }
        }
        StringBuffer total=new StringBuffer();
        total.append(""String_Node_Str"").append(""String_Node_Str"");
        total.append(JavaUtils.bytesToString2(totalNetIn)).append(""String_Node_Str"");
        total.append(JavaUtils.bytesToString2(totalNetOut));
        lines.add(total.toString());
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=showLog(request,""String_Node_Str"");
        return encode2(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=showLog(request,""String_Node_Str"");
        return encode2(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=showLog(request,""String_Node_Str"");
        return encode2(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=showLog(request,""String_Node_Str"");
        return encode2(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> ret=new ArrayList<String>();
        try {
          String cmd1=ShellUtils.osType == ShellUtils.OSType.OS_TYPE_MAC ? ""String_Node_Str"" : ""String_Node_Str"";
          String cmd2=ShellUtils.osType == ShellUtils.OSType.OS_TYPE_MAC ? ""String_Node_Str"" : ""String_Node_Str"";
          String iostatOut=ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",cmd1);
          String vmstatOut=ShellUtils.execCommand(""String_Node_Str"",""String_Node_Str"",cmd2);
          StringBuilder sb=new StringBuilder();
          sb.append(iostatOut);
          sb.append(""String_Node_Str"");
          sb.append(""String_Node_Str"");
          sb.append(vmstatOut);
          String[] lines=sb.toString().split(""String_Node_Str"");
          ret.add(""String_Node_Str"");
          for (int i=1; i < lines.length; i++) {
            if (lines[i].equals(""String_Node_Str""))             continue;
            ret.add(lines[i]);
          }
        }
 catch (        IOException e) {
          LOGGER.error(""String_Node_Str"",e);
          ret.add(""String_Node_Str"");
        }
        return encode2(ret);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<Object> list=new ArrayList<Object>();
        Map<Integer,AbstractPool> pools=RedisEngineCtx.INSTANCE().getPoolMap();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        list.add(titleLine.toString());
        for (        AbstractPool pool : pools.values()) {
          if (pool instanceof RedisStandalonePool) {
            StringBuffer sb=new StringBuffer();
            RedisStandalonePool redisStandalonePool=(RedisStandalonePool)pool;
            PhysicalNode physicalNode=redisStandalonePool.getPhysicalNode();
            if (physicalNode == null)             continue;
            sb.append(""String_Node_Str"");
            sb.append(redisStandalonePool.getId()).append(""String_Node_Str"");
            sb.append(physicalNode.getPoolName()).append(""String_Node_Str"");
            sb.append(""String_Node_Str"").append(""String_Node_Str"");
            sb.append(physicalNode.getName()).append(""String_Node_Str"");
            sb.append(physicalNode.getMinCon()).append(""String_Node_Str"");
            sb.append(physicalNode.getMaxCon()).append(""String_Node_Str"");
            sb.append(physicalNode.getIdleCount()).append(""String_Node_Str"");
            sb.append(physicalNode.getActiveCount());
            list.add(sb.toString());
          }
 else           if (pool instanceof RedisClusterPool) {
            RedisClusterPool redisClusterPool=(RedisClusterPool)pool;
            Map<String,ClusterNode> masters=redisClusterPool.getMasters();
            List<String> clusterInfo=new ArrayList<String>();
            for (            ClusterNode clusterNode : masters.values()) {
              PhysicalNode physicalNode=clusterNode.getPhysicalNode();
              StringBuffer sb=new StringBuffer();
              sb.append(redisClusterPool.getId()).append(""String_Node_Str"");
              sb.append(physicalNode.getPoolName()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(""String_Node_Str"");
              sb.append(physicalNode.getName()).append(""String_Node_Str"");
              sb.append(physicalNode.getMinCon()).append(""String_Node_Str"");
              sb.append(physicalNode.getMaxCon()).append(""String_Node_Str"");
              sb.append(physicalNode.getIdleCount()).append(""String_Node_Str"");
              sb.append(physicalNode.getActiveCount()).append(""String_Node_Str"");
              ;
              sb.append(!clusterNode.isFail());
              clusterInfo.add(sb.toString());
              sb.append(clusterNode.getConnectInfo());
            }
            list.add(clusterInfo);
          }
 else           if (pool instanceof KafkaPool) {
            KafkaPool kafkaPool=(KafkaPool)pool;
            Map<Integer,PhysicalNode> physicalNodes=kafkaPool.getPhysicalNodes();
            for (            PhysicalNode physicalNode : physicalNodes.values()) {
              StringBuffer sb=new StringBuffer();
              sb.append(""String_Node_Str"");
              sb.append(kafkaPool.getId()).append(""String_Node_Str"");
              sb.append(physicalNode.getPoolName()).append(""String_Node_Str"");
              sb.append(""String_Node_Str"").append(""String_Node_Str"");
              sb.append(physicalNode.getName()).append(""String_Node_Str"");
              sb.append(physicalNode.getMinCon()).append(""String_Node_Str"");
              sb.append(physicalNode.getMaxCon()).append(""String_Node_Str"");
              sb.append(physicalNode.getIdleCount()).append(""String_Node_Str"");
              sb.append(physicalNode.getActiveCount());
              list.add(sb.toString());
            }
          }
        }
        return encodeObject(list);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        Collection<Entry<String,AtomicLong>> entrys=StatUtil.getCommandProcTimeMap().entrySet();
        List<String> lines=new ArrayList<String>();
        for (        Entry<String,AtomicLong> entry : entrys) {
          StringBuffer sBuffer=new StringBuffer();
          sBuffer.append(entry.getKey()).append(""String_Node_Str"").append(entry.getValue().get());
          lines.add(sBuffer.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        for (        BigLength bigLength : StatUtil.getBigLengthMap().values()) {
          StringBuffer line1=new StringBuffer();
          line1.append(bigLength.cmd).append(""String_Node_Str"");
          line1.append(bigLength.key).append(""String_Node_Str"");
          line1.append(bigLength.length.get()).append(""String_Node_Str"");
          line1.append(bigLength.count_1k.get()).append(""String_Node_Str"");
          line1.append(bigLength.count_10k.get());
          lines.add(line1.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        List<String> lines=new ArrayList<String>();
        StringBuffer titleLine=new StringBuffer();
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
        titleLine.append(""String_Node_Str"");
        lines.add(titleLine.toString());
        for (        SlowKey slowKey : StatUtil.getSlowKey()) {
          StringBuffer line1=new StringBuffer();
          line1.append(slowKey.cmd).append(""String_Node_Str"");
          line1.append(slowKey.key).append(""String_Node_Str"");
          line1.append(slowKey.count);
          lines.add(line1.toString());
        }
        return encode(lines);
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"") && (numArgs == 3 || numArgs == 2)) {
        Map<String,KafkaCfg> kafkaMap=RedisEngineCtx.INSTANCE().getKafkaMap();
        List<String> lines=new ArrayList<String>();
        if (numArgs == 2) {
          StringBuffer titleLine=new StringBuffer();
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"");
          lines.add(titleLine.toString());
          for (          Entry<String,KafkaCfg> entry : kafkaMap.entrySet()) {
            KafkaCfg kafkaCfg=entry.getValue();
            StringBuffer line=new StringBuffer();
            line.append(kafkaCfg.getTopic()).append(""String_Node_Str"");
            line.append(kafkaCfg.getPoolId()).append(""String_Node_Str"");
            line.append(kafkaCfg.getPartitions()).append(""String_Node_Str"");
            line.append(kafkaCfg.getReplicationFactor()).append(""String_Node_Str"");
            line.append(kafkaCfg.getProducers()).append(""String_Node_Str"");
            line.append(kafkaCfg.getConsumers());
            lines.add(line.toString());
          }
        }
 else {
          StringBuffer titleLine=new StringBuffer();
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"").append(""String_Node_Str"");
          titleLine.append(""String_Node_Str"");
          lines.add(titleLine.toString());
          String topic=new String(request.getArgs()[2]);
          KafkaCfg kafkaCfg=kafkaMap.get(topic);
          if (kafkaCfg != null) {
            Map<Integer,MetaDataOffset> offsets=kafkaCfg.getMetaData().getOffsets();
            MetaDataPartition[] partitions=kafkaCfg.getMetaData().getPartitions();
            for (            MetaDataPartition partition : partitions) {
              int pt=partition.getPartition();
              MetaDataOffset offset=offsets.get(pt);
              StringBuffer line=new StringBuffer();
              line.append(kafkaCfg.getTopic()).append(""String_Node_Str"");
              line.append(partition.getLeader().getHost()).append(partition.getLeader().getPort()).append(""String_Node_Str"");
              line.append(pt).append(""String_Node_Str"");
              line.append(offset.getProducerOffset()).append(""String_Node_Str"");
              line.append(offset.getAllConsumerOffset());
              lines.add(line.toString());
            }
          }
        }
        return encode(lines);
      }
    }
 else     if ((arg1[0] == 'N' || arg1[0] == 'n') && (arg1[1] == 'O' || arg1[1] == 'o') && (arg1[2] == 'D' || arg1[2] == 'd')&& (arg1[3] == 'E' || arg1[3] == 'e')) {
      return ""String_Node_Str"".getBytes();
    }
  }
 else   if (arg1.length == 6) {
    if ((arg1[0] == 'R' || arg1[0] == 'r') && (arg1[1] == 'E' || arg1[1] == 'e') && (arg1[2] == 'L' || arg1[2] == 'l')&& (arg1[3] == 'O' || arg1[3] == 'o')&& (arg1[4] == 'A' || arg1[4] == 'a')&& (arg1[5] == 'D' || arg1[5] == 'd')) {
      if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        byte[] buff=RedisEngineCtx.INSTANCE().reloadAll();
        return buff;
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        byte[] buff=RedisEngineCtx.INSTANCE().reloadUser();
        return buff;
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        ConcurrentMap<Long,AbstractConnection> allConnections=NetSystem.getInstance().getAllConnectios();
        Iterator<Entry<Long,AbstractConnection>> it=allConnections.entrySet().iterator();
        while (it.hasNext()) {
          AbstractConnection c=it.next().getValue();
          if (c instanceof RedisFrontConnection) {
            LOGGER.info(""String_Node_Str"",c);
            c.close(""String_Node_Str"");
          }
        }
        return ""String_Node_Str"".getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        JAVA_BIN_PATH=new String(request.getArgs()[2]);
        return ""String_Node_Str"".getBytes();
      }
 else       if (arg2.equalsIgnoreCase(""String_Node_Str"")) {
        byte[] buff=KafkaLoad.instance().reLoad();
        return buff;
      }
    }
  }
 else   if (arg1.length == 2) {
    if ((arg1[0] == 'Z' || arg1[0] == 'z') && (arg1[1] == 'K' || arg1[1] == 'k')) {
      return ZkClientManage.execute(request);
    }
  }
 else   if (arg1.length == 7) {
    if ((arg1[0] == 'C' || arg1[0] == 'c') && (arg1[1] == 'L' || arg1[1] == 'l') && (arg1[2] == 'U' || arg1[2] == 'u')&& (arg1[3] == 'S' || arg1[3] == 's')&& (arg1[4] == 'T' || arg1[4] == 't')&& (arg1[5] == 'E' || arg1[5] == 'e')&& (arg1[6] == 'R' || arg1[6] == 'r')) {
      AbstractPool pool=RedisEngineCtx.INSTANCE().getPoolMap().get(frontCon.getUserCfg().getPoolId());
      if (pool.getType() != 1) {
        return ""String_Node_Str"".getBytes();
      }
      PhysicalNode pysicalNode=((RedisClusterPool)pool).getPhysicalNodeBySlot(0);
      if (pysicalNode == null) {
        return ""String_Node_Str"".getBytes();
      }
      try {
        RedisBackendConnection backendCon=(RedisBackendConnection)pysicalNode.getConnection(new DirectTransTofrontCallBack(),frontCon);
        if (backendCon == null) {
          frontCon.writeErrMessage(""String_Node_Str"");
        }
 else {
          backendCon.write(request.encode());
        }
        return null;
      }
 catch (      IOException e) {
        LOGGER.error(""String_Node_Str"",e);
      }
    }
  }
  return ""String_Node_Str"".getBytes();
}"
37522,"public void load(Map<String,KafkaCfg> kafkaMap){
  Map<Integer,List<KafkaCfg>> topics=groupBy(kafkaMap);
  for (  Entry<Integer,List<KafkaCfg>> entry : topics.entrySet()) {
    int poolId=entry.getKey();
    PoolCfg poolCfg=RedisEngineCtx.INSTANCE().getPoolCfgMap().get(poolId);
    StringBuffer servers=new StringBuffer();
    List<String> nodes=poolCfg.getNodes();
    for (int i=0; i < nodes.size(); i++) {
      String str=nodes.get(i);
      String[] node=str.split(""String_Node_Str"");
      servers.append(node[0]).append(""String_Node_Str"").append(node[1]);
      if (i < nodes.size() - 1) {
        servers.append(""String_Node_Str"");
      }
    }
    KafkaAdmin kafkaAdmin=new KafkaAdmin(servers.toString());
    Map<String,TopicDescription> existsTopics=kafkaAdmin.getTopicAndDescriptions();
    List<KafkaCfg> kafkaCfgs=entry.getValue();
    for (    KafkaCfg kafkaCfg : kafkaCfgs) {
      if (existsTopics.containsKey(kafkaCfg.getTopic())) {
        TopicDescription topicDescription=existsTopics.get(kafkaCfg.getTopic());
        List<TopicPartitionInfo> partitions=topicDescription.partitions();
        if (partitions.size() < kafkaCfg.getPartitions()) {
          kafkaAdmin.addPartitionsForTopic(kafkaCfg.getTopic(),kafkaCfg.getPartitions());
          topicDescription=kafkaAdmin.getDescriptionByTopic(kafkaCfg.getTopic());
        }
        initKafkaCfgMetaData(kafkaCfg,topicDescription);
      }
 else {
        kafkaAdmin.createTopic(kafkaCfg.getTopic(),kafkaCfg.getPartitions(),kafkaCfg.getReplicationFactor());
        TopicDescription topicDescription=kafkaAdmin.getDescriptionByTopic(kafkaCfg.getTopic());
        initKafkaCfgMetaData(kafkaCfg,topicDescription);
      }
    }
    kafkaAdmin.close();
  }
}","public void load(Map<String,KafkaCfg> kafkaMap){
  if (kafkaMap == null || kafkaMap.isEmpty()) {
    return;
  }
  Map<Integer,List<KafkaCfg>> topics=groupBy(kafkaMap);
  for (  Entry<Integer,List<KafkaCfg>> entry : topics.entrySet()) {
    int poolId=entry.getKey();
    PoolCfg poolCfg=RedisEngineCtx.INSTANCE().getPoolCfgMap().get(poolId);
    StringBuffer servers=new StringBuffer();
    List<String> nodes=poolCfg.getNodes();
    for (int i=0; i < nodes.size(); i++) {
      String str=nodes.get(i);
      String[] node=str.split(""String_Node_Str"");
      servers.append(node[0]).append(""String_Node_Str"").append(node[1]);
      if (i < nodes.size() - 1) {
        servers.append(""String_Node_Str"");
      }
    }
    KafkaAdmin kafkaAdmin=new KafkaAdmin(servers.toString());
    Map<String,TopicDescription> existsTopics=kafkaAdmin.getTopicAndDescriptions();
    List<KafkaCfg> kafkaCfgs=entry.getValue();
    for (    KafkaCfg kafkaCfg : kafkaCfgs) {
      if (existsTopics.containsKey(kafkaCfg.getTopic())) {
        TopicDescription topicDescription=existsTopics.get(kafkaCfg.getTopic());
        List<TopicPartitionInfo> partitions=topicDescription.partitions();
        if (partitions.size() < kafkaCfg.getPartitions()) {
          kafkaAdmin.addPartitionsForTopic(kafkaCfg.getTopic(),kafkaCfg.getPartitions());
          topicDescription=kafkaAdmin.getDescriptionByTopic(kafkaCfg.getTopic());
        }
        initKafkaCfgMetaData(kafkaCfg,topicDescription);
      }
 else {
        kafkaAdmin.createTopic(kafkaCfg.getTopic(),kafkaCfg.getPartitions(),kafkaCfg.getReplicationFactor());
        TopicDescription topicDescription=kafkaAdmin.getDescriptionByTopic(kafkaCfg.getTopic());
        initKafkaCfgMetaData(kafkaCfg,topicDescription);
      }
    }
    kafkaAdmin.close();
  }
}"
37523,"public void init() throws IOException {
  this.lock=new ReentrantLock();
  try {
    this.serverMap=ConfigLoader.loadServerMap(ConfigLoader.buidCfgAbsPathFor(""String_Node_Str""));
    this.poolCfgMap=ConfigLoader.loadPoolMap(ConfigLoader.buidCfgAbsPathFor(""String_Node_Str""));
    this.userMap=ConfigLoader.loadUserMap(poolCfgMap,ConfigLoader.buidCfgAbsPathFor(""String_Node_Str""));
    this.mailProperty=ConfigLoader.loadMailProperties(ConfigLoader.buidCfgAbsPathFor(""String_Node_Str""));
    this.kafkaMap=KafkaConfigLoader.loadKafkaMap(poolCfgMap,ConfigLoader.buidCfgAbsPathFor(""String_Node_Str""));
  }
 catch (  Exception e) {
  }
  String portString=this.serverMap.get(""String_Node_Str"");
  String reactorSizeString=this.serverMap.get(""String_Node_Str"");
  String minBufferSizeString=this.serverMap.get(""String_Node_Str"");
  String maxBufferSizeString=this.serverMap.get(""String_Node_Str"");
  String decomposeBufferSizeString=this.serverMap.get(""String_Node_Str"");
  String minChunkSizeString=this.serverMap.get(""String_Node_Str"");
  String incrementString=this.serverMap.get(""String_Node_Str"");
  String maxChunkSizeString=this.serverMap.get(""String_Node_Str"");
  String bufferLocalPercentString=this.serverMap.get(""String_Node_Str"");
  String bossSizeString=this.serverMap.get(""String_Node_Str"");
  String timerSizeString=this.serverMap.get(""String_Node_Str"");
  String networkFlowLimitSizeString=this.serverMap.get(""String_Node_Str"");
  int processors=Runtime.getRuntime().availableProcessors();
  int port=portString == null ? 8066 : Integer.parseInt(portString);
  int reactorSize=reactorSizeString == null ? processors : Integer.parseInt(reactorSizeString);
  long minBufferSize=minBufferSizeString == null ? 16384 * 1000 : Long.parseLong(minBufferSizeString);
  long maxBufferSize=maxBufferSizeString == null ? 16384 * 10000 : Long.parseLong(maxBufferSizeString);
  int decomposeBufferSize=decomposeBufferSizeString == null ? 64 * 1024 : Integer.parseInt(decomposeBufferSizeString);
  int minChunkSize=minChunkSizeString == null ? 0 : Integer.parseInt(minChunkSizeString);
  long networkFlowLimitSize=networkFlowLimitSizeString == null ? -1 : Long.parseLong(networkFlowLimitSizeString);
  this.flowMonitor=new NetFlowMonitor(networkFlowLimitSize);
  int[] increments=null;
  if (incrementString == null) {
    increments=new int[]{1024};
  }
 else {
    String[] incrementStrings=incrementString.split(""String_Node_Str"");
    if (incrementStrings == null || incrementStrings.length == 0) {
      increments=new int[]{1024};
    }
 else {
      increments=new int[incrementStrings.length];
      for (int i=0; i < incrementStrings.length; i++) {
        increments[i]=Integer.parseInt(incrementStrings[i]);
      }
    }
  }
  int maxChunkSize=maxChunkSizeString == null ? 64 * 1024 : Integer.parseInt(maxChunkSizeString);
  int bufferLocalPercent=bufferLocalPercentString == null ? 100 : Integer.parseInt(bufferLocalPercentString);
  int threadLocalPercent=bufferLocalPercent / reactorSize;
  int bossSize=bossSizeString == null ? 10 : Integer.parseInt(bossSizeString);
  int timerSize=timerSizeString == null ? 6 : Integer.parseInt(timerSizeString);
  this.bufferPool=new BucketBufferPool(minBufferSize,maxBufferSize,decomposeBufferSize,minChunkSize,increments,maxChunkSize,threadLocalPercent);
  this.virtualMemoryService=new VirtualMemoryService();
  this.virtualMemoryService.start();
  new NetSystem(bufferPool,ExecutorUtil.create(""String_Node_Str"",bossSize),ExecutorUtil.create(""String_Node_Str"",timerSize));
  String frontIdleTimeoutString=this.serverMap.get(""String_Node_Str"");
  String backendIdleTimeoutString=this.serverMap.get(""String_Node_Str"");
  int frontIdleTimeout=frontIdleTimeoutString == null ? 5 * 60 * 1000 : Integer.parseInt(frontIdleTimeoutString);
  int backendIdleTimeout=backendIdleTimeoutString == null ? 30 * 60 * 1000 : Integer.parseInt(backendIdleTimeoutString);
  SystemConfig systemConfig=new SystemConfig();
  systemConfig.setFrontIdleTimeout(frontIdleTimeout);
  systemConfig.setBackendIdleTimeout(backendIdleTimeout);
  NetSystem.getInstance().setNetConfig(systemConfig);
  System.out.println(String.format(""String_Node_Str"",processors,reactorSize,bossSize,timerSize,frontIdleTimeout,backendIdleTimeout));
  NIOReactorPool reactorPool=new NIOReactorPool(BufferPool.LOCAL_BUF_THREAD_PREX + ""String_Node_Str"",reactorSize);
  NIOReactor[] reactors=reactorPool.getAllReactors();
  for (  NIOReactor r : reactors) {
    this.reactorMap.put(r.getName(),r);
  }
  NIOConnector connector=new NIOConnector(""String_Node_Str"",reactorPool);
  connector.start();
  NetSystem.getInstance().setConnector(connector);
  this.poolMap=new HashMap<Integer,AbstractPool>(poolCfgMap.size());
  for (  final PoolCfg poolCfg : poolCfgMap.values()) {
    AbstractPool pool=PoolFactory.createPoolByCfg(poolCfg);
    pool.startup();
    this.poolMap.put(pool.getId(),pool);
  }
  NIOAcceptor acceptor=new NIOAcceptor(""String_Node_Str"",""String_Node_Str"",port,new RedisFrontendConnectionFactory(),reactorPool);
  acceptor.start();
  LOGGER.info(acceptor.getName() + ""String_Node_Str"",acceptor.getPort());
  Iterator<String> it=userMap.keySet().iterator();
  String authString=it.hasNext() ? it.next() : ""String_Node_Str"";
  KeepAlived.check(port,authString);
  KafkaLoad.instance().load(kafkaMap);
  OffsetAdmin.getInstance().startUp();
  Runtime.getRuntime().addShutdownHook(new Thread(){
    public void run(){
      OffsetAdmin.getInstance().close();
    }
  }
);
}","public void init() throws IOException {
  this.lock=new ReentrantLock();
  try {
    this.serverMap=ConfigLoader.loadServerMap(ConfigLoader.buidCfgAbsPathFor(""String_Node_Str""));
    this.poolCfgMap=ConfigLoader.loadPoolMap(ConfigLoader.buidCfgAbsPathFor(""String_Node_Str""));
    this.userMap=ConfigLoader.loadUserMap(poolCfgMap,ConfigLoader.buidCfgAbsPathFor(""String_Node_Str""));
    this.mailProperty=ConfigLoader.loadMailProperties(ConfigLoader.buidCfgAbsPathFor(""String_Node_Str""));
    this.kafkaMap=KafkaConfigLoader.loadKafkaMap(poolCfgMap,ConfigLoader.buidCfgAbsPathFor(""String_Node_Str""));
  }
 catch (  Exception e) {
  }
  String portString=this.serverMap.get(""String_Node_Str"");
  String reactorSizeString=this.serverMap.get(""String_Node_Str"");
  String minBufferSizeString=this.serverMap.get(""String_Node_Str"");
  String maxBufferSizeString=this.serverMap.get(""String_Node_Str"");
  String decomposeBufferSizeString=this.serverMap.get(""String_Node_Str"");
  String minChunkSizeString=this.serverMap.get(""String_Node_Str"");
  String incrementString=this.serverMap.get(""String_Node_Str"");
  String maxChunkSizeString=this.serverMap.get(""String_Node_Str"");
  String bufferLocalPercentString=this.serverMap.get(""String_Node_Str"");
  String bossSizeString=this.serverMap.get(""String_Node_Str"");
  String timerSizeString=this.serverMap.get(""String_Node_Str"");
  String networkFlowLimitSizeString=this.serverMap.get(""String_Node_Str"");
  int processors=Runtime.getRuntime().availableProcessors();
  int port=portString == null ? 8066 : Integer.parseInt(portString);
  int reactorSize=reactorSizeString == null ? processors : Integer.parseInt(reactorSizeString);
  long minBufferSize=minBufferSizeString == null ? 16384 * 1000 : Long.parseLong(minBufferSizeString);
  long maxBufferSize=maxBufferSizeString == null ? 16384 * 10000 : Long.parseLong(maxBufferSizeString);
  int decomposeBufferSize=decomposeBufferSizeString == null ? 64 * 1024 : Integer.parseInt(decomposeBufferSizeString);
  int minChunkSize=minChunkSizeString == null ? 0 : Integer.parseInt(minChunkSizeString);
  long networkFlowLimitSize=networkFlowLimitSizeString == null ? -1 : Long.parseLong(networkFlowLimitSizeString);
  this.flowMonitor=new NetFlowMonitor(networkFlowLimitSize);
  int[] increments=null;
  if (incrementString == null) {
    increments=new int[]{1024};
  }
 else {
    String[] incrementStrings=incrementString.split(""String_Node_Str"");
    if (incrementStrings == null || incrementStrings.length == 0) {
      increments=new int[]{1024};
    }
 else {
      increments=new int[incrementStrings.length];
      for (int i=0; i < incrementStrings.length; i++) {
        increments[i]=Integer.parseInt(incrementStrings[i]);
      }
    }
  }
  int maxChunkSize=maxChunkSizeString == null ? 64 * 1024 : Integer.parseInt(maxChunkSizeString);
  int bufferLocalPercent=bufferLocalPercentString == null ? 100 : Integer.parseInt(bufferLocalPercentString);
  int threadLocalPercent=bufferLocalPercent / reactorSize;
  int bossSize=bossSizeString == null ? 10 : Integer.parseInt(bossSizeString);
  int timerSize=timerSizeString == null ? 6 : Integer.parseInt(timerSizeString);
  this.bufferPool=new BucketBufferPool(minBufferSize,maxBufferSize,decomposeBufferSize,minChunkSize,increments,maxChunkSize,threadLocalPercent);
  this.virtualMemoryService=new VirtualMemoryService();
  this.virtualMemoryService.start();
  new NetSystem(bufferPool,ExecutorUtil.create(""String_Node_Str"",bossSize),ExecutorUtil.create(""String_Node_Str"",timerSize));
  String frontIdleTimeoutString=this.serverMap.get(""String_Node_Str"");
  String backendIdleTimeoutString=this.serverMap.get(""String_Node_Str"");
  int frontIdleTimeout=frontIdleTimeoutString == null ? 5 * 60 * 1000 : Integer.parseInt(frontIdleTimeoutString);
  int backendIdleTimeout=backendIdleTimeoutString == null ? 30 * 60 * 1000 : Integer.parseInt(backendIdleTimeoutString);
  SystemConfig systemConfig=new SystemConfig();
  systemConfig.setFrontIdleTimeout(frontIdleTimeout);
  systemConfig.setBackendIdleTimeout(backendIdleTimeout);
  NetSystem.getInstance().setNetConfig(systemConfig);
  System.out.println(String.format(""String_Node_Str"",processors,reactorSize,bossSize,timerSize,frontIdleTimeout,backendIdleTimeout));
  NIOReactorPool reactorPool=new NIOReactorPool(BufferPool.LOCAL_BUF_THREAD_PREX + ""String_Node_Str"",reactorSize);
  NIOReactor[] reactors=reactorPool.getAllReactors();
  for (  NIOReactor r : reactors) {
    this.reactorMap.put(r.getName(),r);
  }
  NIOConnector connector=new NIOConnector(""String_Node_Str"",reactorPool);
  connector.start();
  NetSystem.getInstance().setConnector(connector);
  this.poolMap=new HashMap<Integer,AbstractPool>(poolCfgMap.size());
  for (  final PoolCfg poolCfg : poolCfgMap.values()) {
    AbstractPool pool=PoolFactory.createPoolByCfg(poolCfg);
    pool.startup();
    this.poolMap.put(pool.getId(),pool);
  }
  NIOAcceptor acceptor=new NIOAcceptor(""String_Node_Str"",""String_Node_Str"",port,new RedisFrontendConnectionFactory(),reactorPool);
  acceptor.start();
  LOGGER.info(acceptor.getName() + ""String_Node_Str"",acceptor.getPort());
  Iterator<String> it=userMap.keySet().iterator();
  String authString=it.hasNext() ? it.next() : ""String_Node_Str"";
  KeepAlived.check(port,authString);
  if (kafkaMap != null && kafkaMap.isEmpty()) {
    KafkaLoad.instance().load(kafkaMap);
    OffsetAdmin.getInstance().startUp();
  }
  Runtime.getRuntime().addShutdownHook(new Thread(){
    public void run(){
      OffsetAdmin.getInstance().close();
    }
  }
);
}"
37524,"@Override public RouteResult route(UserCfg userCfg,List<RedisRequest> requests) throws InvalidRequestExistsException, PhysicalNodeUnavailableException {
  RedisRequest request=requests.get(0);
  KafkaCfg kafkaCfg;
  MetaDataPartition partition;
  if (request.getPolicy().getHandleType() == CommandParse.PRODUCE_CMD) {
    if (request.getNumArgs() != 3) {
      throw new InvalidRequestExistsException(""String_Node_Str"");
    }
    kafkaCfg=getKafkaCfg(userCfg.getPassword(),request);
    partition=kafkaCfg.getMetaData().getProducerMetaDataPartition();
  }
 else {
    if (request.getNumArgs() != 2 && request.getNumArgs() != 4) {
      throw new InvalidRequestExistsException(""String_Node_Str"");
    }
    kafkaCfg=getKafkaCfg(userCfg.getPassword(),request);
    if (request.getNumArgs() == 4) {
      int pt=Integer.parseInt(new String(request.getArgs()[2]));
      partition=kafkaCfg.getMetaData().getConsumerMetaDataPartition(pt);
      if (partition == null) {
        throw new InvalidRequestExistsException(""String_Node_Str"");
      }
    }
 else {
      partition=kafkaCfg.getMetaData().getConsumerMetaDataPartition();
    }
  }
  List<RouteResultNode> nodes=new ArrayList<RouteResultNode>();
  KafkaPool pool=(KafkaPool)RedisEngineCtx.INSTANCE().getPoolMap().get(kafkaCfg.getPoolId());
  RouteResultNode node=new RouteResultNode();
  PhysicalNode physicalNode=pool.getPhysicalNode(partition.getLeader().getId());
  if (physicalNode == null)   throw new PhysicalNodeUnavailableException(""String_Node_Str"");
  node.setPhysicalNode(physicalNode);
  node.addRequestIndex(0);
  node.setKafkaMetaDataOffset(kafkaCfg.getMetaData().getMetaDataOffsetByPartition(partition.getPartition()));
  nodes.add(node);
  RouteResult routeResult=new RouteResult(RedisRequestType.KAFKA,requests,nodes);
  return routeResult;
}","@Override public RouteResult route(UserCfg userCfg,List<RedisRequest> requests) throws InvalidRequestExistsException, PhysicalNodeUnavailableException {
  RedisRequest request=requests.get(0);
  KafkaCfg kafkaCfg;
  MetaDataPartition partition;
  if (request.getPolicy().getHandleType() == CommandParse.PRODUCE_CMD) {
    if (request.getNumArgs() != 3) {
      throw new InvalidRequestExistsException(""String_Node_Str"");
    }
    kafkaCfg=getKafkaCfg(userCfg.getPassword(),request,false);
    partition=kafkaCfg.getMetaData().getProducerMetaDataPartition();
  }
 else {
    if (request.getNumArgs() != 2 && request.getNumArgs() != 4) {
      throw new InvalidRequestExistsException(""String_Node_Str"");
    }
    kafkaCfg=getKafkaCfg(userCfg.getPassword(),request,true);
    if (request.getNumArgs() == 4) {
      int pt=Integer.parseInt(new String(request.getArgs()[2]));
      partition=kafkaCfg.getMetaData().getConsumerMetaDataPartition(pt);
      if (partition == null) {
        throw new InvalidRequestExistsException(""String_Node_Str"");
      }
    }
 else {
      partition=kafkaCfg.getMetaData().getConsumerMetaDataPartition();
    }
  }
  List<RouteResultNode> nodes=new ArrayList<RouteResultNode>();
  KafkaPool pool=(KafkaPool)RedisEngineCtx.INSTANCE().getPoolMap().get(kafkaCfg.getPoolId());
  RouteResultNode node=new RouteResultNode();
  PhysicalNode physicalNode=pool.getPhysicalNode(partition.getLeader().getId());
  if (physicalNode == null)   throw new PhysicalNodeUnavailableException(""String_Node_Str"");
  node.setPhysicalNode(physicalNode);
  node.addRequestIndex(0);
  node.setKafkaMetaDataOffset(kafkaCfg.getMetaData().getMetaDataOffsetByPartition(partition.getPartition()));
  nodes.add(node);
  RouteResult routeResult=new RouteResult(RedisRequestType.KAFKA,requests,nodes);
  return routeResult;
}"
37525,"private KafkaCfg getKafkaCfg(String password,RedisRequest request) throws InvalidRequestExistsException {
  String topic=new String(request.getArgs()[1]);
  KafkaCfg kafkaCfg=RedisEngineCtx.INSTANCE().getKafkaMap().get(topic);
  if (kafkaCfg == null) {
    throw new InvalidRequestExistsException(""String_Node_Str"");
  }
  if (!kafkaCfg.isProducer(password)) {
    throw new InvalidRequestExistsException(""String_Node_Str"");
  }
  if (kafkaCfg.getMetaData() == null) {
    throw new InvalidRequestExistsException(""String_Node_Str"");
  }
  return kafkaCfg;
}","private KafkaCfg getKafkaCfg(String password,RedisRequest request,boolean isConsumer) throws InvalidRequestExistsException {
  String topic=new String(request.getArgs()[1]);
  KafkaCfg kafkaCfg=RedisEngineCtx.INSTANCE().getKafkaMap().get(topic);
  if (kafkaCfg == null) {
    throw new InvalidRequestExistsException(""String_Node_Str"");
  }
  if (!isConsumer && !kafkaCfg.isProducer(password)) {
    throw new InvalidRequestExistsException(""String_Node_Str"");
  }
  if (isConsumer && !kafkaCfg.isConsumer(password)) {
    throw new InvalidRequestExistsException(""String_Node_Str"");
  }
  if (kafkaCfg.getMetaData() == null) {
    throw new InvalidRequestExistsException(""String_Node_Str"");
  }
  return kafkaCfg;
}"
37526,"public void init() throws IOException {
  this.lock=new ReentrantLock();
  try {
    this.serverMap=ConfigLoader.loadServerMap(ConfigLoader.buidCfgAbsPathFor(""String_Node_Str""));
    this.poolCfgMap=ConfigLoader.loadPoolMap(ConfigLoader.buidCfgAbsPathFor(""String_Node_Str""));
    this.userMap=ConfigLoader.loadUserMap(poolCfgMap,ConfigLoader.buidCfgAbsPathFor(""String_Node_Str""));
    this.mailProperty=ConfigLoader.loadMailProperties(ConfigLoader.buidCfgAbsPathFor(""String_Node_Str""));
    this.kafkaMap=KafkaConfigLoader.loadKafkaMap(poolCfgMap,ConfigLoader.buidCfgAbsPathFor(""String_Node_Str""));
  }
 catch (  Exception e) {
  }
  String portString=this.serverMap.get(""String_Node_Str"");
  String reactorSizeString=this.serverMap.get(""String_Node_Str"");
  String minBufferSizeString=this.serverMap.get(""String_Node_Str"");
  String maxBufferSizeString=this.serverMap.get(""String_Node_Str"");
  String decomposeBufferSizeString=this.serverMap.get(""String_Node_Str"");
  String minChunkSizeString=this.serverMap.get(""String_Node_Str"");
  String incrementString=this.serverMap.get(""String_Node_Str"");
  String maxChunkSizeString=this.serverMap.get(""String_Node_Str"");
  String bufferLocalPercentString=this.serverMap.get(""String_Node_Str"");
  String bossSizeString=this.serverMap.get(""String_Node_Str"");
  String timerSizeString=this.serverMap.get(""String_Node_Str"");
  String networkFlowLimitSizeString=this.serverMap.get(""String_Node_Str"");
  int processors=Runtime.getRuntime().availableProcessors();
  int port=portString == null ? 8066 : Integer.parseInt(portString);
  int reactorSize=reactorSizeString == null ? processors : Integer.parseInt(reactorSizeString);
  long minBufferSize=minBufferSizeString == null ? 16384 * 1000 : Long.parseLong(minBufferSizeString);
  long maxBufferSize=maxBufferSizeString == null ? 16384 * 10000 : Long.parseLong(maxBufferSizeString);
  int decomposeBufferSize=decomposeBufferSizeString == null ? 64 * 1024 : Integer.parseInt(decomposeBufferSizeString);
  int minChunkSize=minChunkSizeString == null ? 0 : Integer.parseInt(minChunkSizeString);
  long networkFlowLimitSize=networkFlowLimitSizeString == null ? -1 : Long.parseLong(networkFlowLimitSizeString);
  this.flowMonitor=new NetFlowMonitor(networkFlowLimitSize);
  int[] increments=null;
  if (incrementString == null) {
    increments=new int[]{1024};
  }
 else {
    String[] incrementStrings=incrementString.split(""String_Node_Str"");
    if (incrementStrings == null || incrementStrings.length == 0) {
      increments=new int[]{1024};
    }
 else {
      increments=new int[incrementStrings.length];
      for (int i=0; i < incrementStrings.length; i++) {
        increments[i]=Integer.parseInt(incrementStrings[i]);
      }
    }
  }
  int maxChunkSize=maxChunkSizeString == null ? 64 * 1024 : Integer.parseInt(maxChunkSizeString);
  int bufferLocalPercent=bufferLocalPercentString == null ? 100 : Integer.parseInt(bufferLocalPercentString);
  int threadLocalPercent=bufferLocalPercent / reactorSize;
  int bossSize=bossSizeString == null ? 10 : Integer.parseInt(bossSizeString);
  int timerSize=timerSizeString == null ? 6 : Integer.parseInt(timerSizeString);
  this.bufferPool=new BucketBufferPool(minBufferSize,maxBufferSize,decomposeBufferSize,minChunkSize,increments,maxChunkSize,threadLocalPercent);
  this.virtualMemoryService=new VirtualMemoryService();
  this.virtualMemoryService.start();
  new NetSystem(bufferPool,ExecutorUtil.create(""String_Node_Str"",bossSize),ExecutorUtil.create(""String_Node_Str"",timerSize));
  String frontIdleTimeoutString=this.serverMap.get(""String_Node_Str"");
  String backendIdleTimeoutString=this.serverMap.get(""String_Node_Str"");
  int frontIdleTimeout=frontIdleTimeoutString == null ? 5 * 60 * 1000 : Integer.parseInt(frontIdleTimeoutString);
  int backendIdleTimeout=backendIdleTimeoutString == null ? 30 * 60 * 1000 : Integer.parseInt(backendIdleTimeoutString);
  SystemConfig systemConfig=new SystemConfig();
  systemConfig.setFrontIdleTimeout(frontIdleTimeout);
  systemConfig.setBackendIdleTimeout(backendIdleTimeout);
  NetSystem.getInstance().setNetConfig(systemConfig);
  System.out.println(String.format(""String_Node_Str"",processors,reactorSize,bossSize,timerSize,frontIdleTimeout,backendIdleTimeout));
  NIOReactorPool reactorPool=new NIOReactorPool(BufferPool.LOCAL_BUF_THREAD_PREX + ""String_Node_Str"",reactorSize);
  NIOReactor[] reactors=reactorPool.getAllReactors();
  for (  NIOReactor r : reactors) {
    this.reactorMap.put(r.getName(),r);
  }
  NIOConnector connector=new NIOConnector(""String_Node_Str"",reactorPool);
  connector.start();
  NetSystem.getInstance().setConnector(connector);
  this.poolMap=new HashMap<Integer,AbstractPool>(poolCfgMap.size());
  for (  final PoolCfg poolCfg : poolCfgMap.values()) {
    AbstractPool pool=PoolFactory.createPoolByCfg(poolCfg);
    pool.startup();
    this.poolMap.put(pool.getId(),pool);
  }
  NIOAcceptor acceptor=new NIOAcceptor(""String_Node_Str"",""String_Node_Str"",port,new RedisFrontendConnectionFactory(),reactorPool);
  acceptor.start();
  LOGGER.info(acceptor.getName() + ""String_Node_Str"",acceptor.getPort());
  Iterator<String> it=userMap.keySet().iterator();
  String authString=it.hasNext() ? it.next() : ""String_Node_Str"";
  KeepAlived.check(port,authString);
  if (kafkaMap != null && kafkaMap.isEmpty()) {
    KafkaLoad.instance().load(kafkaMap);
    OffsetAdmin.getInstance().startUp();
  }
  Runtime.getRuntime().addShutdownHook(new Thread(){
    public void run(){
      OffsetAdmin.getInstance().close();
    }
  }
);
}","public void init() throws IOException {
  this.lock=new ReentrantLock();
  try {
    this.serverMap=ConfigLoader.loadServerMap(ConfigLoader.buidCfgAbsPathFor(""String_Node_Str""));
    this.poolCfgMap=ConfigLoader.loadPoolMap(ConfigLoader.buidCfgAbsPathFor(""String_Node_Str""));
    this.userMap=ConfigLoader.loadUserMap(poolCfgMap,ConfigLoader.buidCfgAbsPathFor(""String_Node_Str""));
    this.mailProperty=ConfigLoader.loadMailProperties(ConfigLoader.buidCfgAbsPathFor(""String_Node_Str""));
    this.kafkaMap=KafkaConfigLoader.loadKafkaMap(poolCfgMap,ConfigLoader.buidCfgAbsPathFor(""String_Node_Str""));
  }
 catch (  Exception e) {
  }
  String portString=this.serverMap.get(""String_Node_Str"");
  String reactorSizeString=this.serverMap.get(""String_Node_Str"");
  String minBufferSizeString=this.serverMap.get(""String_Node_Str"");
  String maxBufferSizeString=this.serverMap.get(""String_Node_Str"");
  String decomposeBufferSizeString=this.serverMap.get(""String_Node_Str"");
  String minChunkSizeString=this.serverMap.get(""String_Node_Str"");
  String incrementString=this.serverMap.get(""String_Node_Str"");
  String maxChunkSizeString=this.serverMap.get(""String_Node_Str"");
  String bufferLocalPercentString=this.serverMap.get(""String_Node_Str"");
  String bossSizeString=this.serverMap.get(""String_Node_Str"");
  String timerSizeString=this.serverMap.get(""String_Node_Str"");
  String networkFlowLimitSizeString=this.serverMap.get(""String_Node_Str"");
  int processors=Runtime.getRuntime().availableProcessors();
  int port=portString == null ? 8066 : Integer.parseInt(portString);
  int reactorSize=reactorSizeString == null ? processors : Integer.parseInt(reactorSizeString);
  long minBufferSize=minBufferSizeString == null ? 16384 * 1000 : Long.parseLong(minBufferSizeString);
  long maxBufferSize=maxBufferSizeString == null ? 16384 * 10000 : Long.parseLong(maxBufferSizeString);
  int decomposeBufferSize=decomposeBufferSizeString == null ? 64 * 1024 : Integer.parseInt(decomposeBufferSizeString);
  int minChunkSize=minChunkSizeString == null ? 0 : Integer.parseInt(minChunkSizeString);
  long networkFlowLimitSize=networkFlowLimitSizeString == null ? -1 : Long.parseLong(networkFlowLimitSizeString);
  this.flowMonitor=new NetFlowMonitor(networkFlowLimitSize);
  int[] increments=null;
  if (incrementString == null) {
    increments=new int[]{1024};
  }
 else {
    String[] incrementStrings=incrementString.split(""String_Node_Str"");
    if (incrementStrings == null || incrementStrings.length == 0) {
      increments=new int[]{1024};
    }
 else {
      increments=new int[incrementStrings.length];
      for (int i=0; i < incrementStrings.length; i++) {
        increments[i]=Integer.parseInt(incrementStrings[i]);
      }
    }
  }
  int maxChunkSize=maxChunkSizeString == null ? 64 * 1024 : Integer.parseInt(maxChunkSizeString);
  int bufferLocalPercent=bufferLocalPercentString == null ? 100 : Integer.parseInt(bufferLocalPercentString);
  int threadLocalPercent=bufferLocalPercent / reactorSize;
  int bossSize=bossSizeString == null ? 10 : Integer.parseInt(bossSizeString);
  int timerSize=timerSizeString == null ? 6 : Integer.parseInt(timerSizeString);
  this.bufferPool=new BucketBufferPool(minBufferSize,maxBufferSize,decomposeBufferSize,minChunkSize,increments,maxChunkSize,threadLocalPercent);
  this.virtualMemoryService=new VirtualMemoryService();
  this.virtualMemoryService.start();
  new NetSystem(bufferPool,ExecutorUtil.create(""String_Node_Str"",bossSize),ExecutorUtil.create(""String_Node_Str"",timerSize));
  String frontIdleTimeoutString=this.serverMap.get(""String_Node_Str"");
  String backendIdleTimeoutString=this.serverMap.get(""String_Node_Str"");
  int frontIdleTimeout=frontIdleTimeoutString == null ? 5 * 60 * 1000 : Integer.parseInt(frontIdleTimeoutString);
  int backendIdleTimeout=backendIdleTimeoutString == null ? 30 * 60 * 1000 : Integer.parseInt(backendIdleTimeoutString);
  SystemConfig systemConfig=new SystemConfig();
  systemConfig.setFrontIdleTimeout(frontIdleTimeout);
  systemConfig.setBackendIdleTimeout(backendIdleTimeout);
  NetSystem.getInstance().setNetConfig(systemConfig);
  System.out.println(String.format(""String_Node_Str"",processors,reactorSize,bossSize,timerSize,frontIdleTimeout,backendIdleTimeout));
  NIOReactorPool reactorPool=new NIOReactorPool(BufferPool.LOCAL_BUF_THREAD_PREX + ""String_Node_Str"",reactorSize);
  NIOReactor[] reactors=reactorPool.getAllReactors();
  for (  NIOReactor r : reactors) {
    this.reactorMap.put(r.getName(),r);
  }
  NIOConnector connector=new NIOConnector(""String_Node_Str"",reactorPool);
  connector.start();
  NetSystem.getInstance().setConnector(connector);
  this.poolMap=new HashMap<Integer,AbstractPool>(poolCfgMap.size());
  for (  final PoolCfg poolCfg : poolCfgMap.values()) {
    AbstractPool pool=PoolFactory.createPoolByCfg(poolCfg);
    pool.startup();
    this.poolMap.put(pool.getId(),pool);
  }
  NIOAcceptor acceptor=new NIOAcceptor(""String_Node_Str"",""String_Node_Str"",port,new RedisFrontendConnectionFactory(),reactorPool);
  acceptor.start();
  LOGGER.info(acceptor.getName() + ""String_Node_Str"",acceptor.getPort());
  Iterator<String> it=userMap.keySet().iterator();
  String authString=it.hasNext() ? it.next() : ""String_Node_Str"";
  KeepAlived.check(port,authString);
  if (kafkaMap != null && !kafkaMap.isEmpty()) {
    KafkaLoad.instance().load(kafkaMap);
    OffsetAdmin.getInstance().startUp();
  }
  Runtime.getRuntime().addShutdownHook(new Thread(){
    public void run(){
      OffsetAdmin.getInstance().close();
    }
  }
);
}"
37527,"/** 
 *  redis key
 */
private void checkListKeyLength(){
  if (!isChecking.compareAndSet(false,true)) {
    return;
  }
  try {
    lastCheckTime=TimeUtil.currentTimeMillis();
    for (    java.util.Map.Entry<String,String[]> listKey : keyMap.entrySet()) {
      String key=listKey.getKey();
      String[] value=listKey.getValue();
      String password=value[0];
      String cmd=value[1];
      UserCfg userCfg=RedisEngineCtx.INSTANCE().getUserMap().get(password);
      if (userCfg != null) {
        AbstractPool pool=RedisEngineCtx.INSTANCE().getPoolMap().get(userCfg.getPoolId());
        PhysicalNode physicalNode;
        if (pool.getType() == 1) {
          physicalNode=pool.getPhysicalNode(cmd,key);
        }
 else {
          physicalNode=pool.getPhysicalNode();
        }
        JedisConnection conn=null;
        try {
          conn=new JedisConnection(physicalNode.getHost(),physicalNode.getPort(),1000,0);
          if (cmd.equals(""String_Node_Str"") || cmd.equals(""String_Node_Str"") || cmd.equals(""String_Node_Str"")|| cmd.equals(""String_Node_Str"")|| cmd.equals(""String_Node_Str"")) {
            conn.sendCommand(RedisCommand.HLEN,key);
          }
 else           if (cmd.equals(""String_Node_Str"") || cmd.equals(""String_Node_Str"") || cmd.equals(""String_Node_Str"")|| cmd.equals(""String_Node_Str"")) {
            conn.sendCommand(RedisCommand.LLEN,key);
          }
 else           if (cmd.equals(""String_Node_Str"")) {
            conn.sendCommand(RedisCommand.SCARD,key);
          }
 else           if (cmd.equals(""String_Node_Str"") || cmd.equals(""String_Node_Str"") || cmd.equals(""String_Node_Str"")) {
            conn.sendCommand(RedisCommand.ZCARD,key);
          }
          long length=conn.getIntegerReply();
          if (length > THRESHOLD) {
            BigLength bigLen=bigLengthMap.get(key);
            if (bigLen == null) {
              bigLen=new BigLength();
              bigLen.cmd=cmd;
              bigLen.key=key;
            }
            bigLen.length.set((int)length);
          }
 else {
            keyMap.remove(key);
          }
          BigLength min=null;
          for (          BigLength bigLen : bigLengthMap.values()) {
            if (min == null) {
              min=bigLen;
            }
 else {
              if (bigLen.length.get() < min.length.get()) {
                min=bigLen;
              }
            }
          }
          if (min != null)           bigLengthMap.remove(min.key);
        }
 catch (        JedisDataException e1) {
        }
catch (        JedisConnectionException e2) {
          LOGGER.error(""String_Node_Str"",e2);
        }
 finally {
          if (conn != null) {
            conn.disconnect();
          }
        }
      }
    }
  }
  finally {
    isChecking.set(false);
  }
}","/** 
 *  redis key
 */
private void checkListKeyLength(){
  if (!isChecking.compareAndSet(false,true)) {
    return;
  }
  try {
    lastCheckTime=TimeUtil.currentTimeMillis();
    for (    java.util.Map.Entry<String,String[]> listKey : keyMap.entrySet()) {
      String key=listKey.getKey();
      String[] value=listKey.getValue();
      String password=value[0];
      String cmd=value[1];
      UserCfg userCfg=RedisEngineCtx.INSTANCE().getUserMap().get(password);
      if (userCfg != null) {
        AbstractPool pool=RedisEngineCtx.INSTANCE().getPoolMap().get(userCfg.getPoolId());
        PhysicalNode physicalNode;
        if (pool.getType() == 1) {
          physicalNode=pool.getPhysicalNode(cmd,key);
        }
 else {
          physicalNode=pool.getPhysicalNode();
        }
        JedisConnection conn=null;
        try {
          conn=new JedisConnection(physicalNode.getHost(),physicalNode.getPort(),1000,0);
          if (cmd.equals(""String_Node_Str"") || cmd.equals(""String_Node_Str"") || cmd.equals(""String_Node_Str"")|| cmd.equals(""String_Node_Str"")|| cmd.equals(""String_Node_Str"")) {
            conn.sendCommand(RedisCommand.HLEN,key);
          }
 else           if (cmd.equals(""String_Node_Str"") || cmd.equals(""String_Node_Str"") || cmd.equals(""String_Node_Str"")|| cmd.equals(""String_Node_Str"")) {
            conn.sendCommand(RedisCommand.LLEN,key);
          }
 else           if (cmd.equals(""String_Node_Str"")) {
            conn.sendCommand(RedisCommand.SCARD,key);
          }
 else           if (cmd.equals(""String_Node_Str"") || cmd.equals(""String_Node_Str"") || cmd.equals(""String_Node_Str"")) {
            conn.sendCommand(RedisCommand.ZCARD,key);
          }
          long length=conn.getIntegerReply();
          if (length > THRESHOLD) {
            BigLength bigLen=bigLengthMap.get(key);
            if (bigLen == null) {
              bigLen=new BigLength();
              bigLen.cmd=cmd;
              bigLen.key=key;
              bigLengthMap.put(key,bigLen);
            }
            bigLen.length.set((int)length);
          }
 else {
            keyMap.remove(key);
          }
          if (bigLengthMap.size() > 100) {
            BigLength min=null;
            for (            BigLength bigLen : bigLengthMap.values()) {
              if (min == null) {
                min=bigLen;
              }
 else {
                if (bigLen.length.get() < min.length.get()) {
                  min=bigLen;
                }
              }
            }
            bigLengthMap.remove(min.key);
          }
        }
 catch (        JedisDataException e1) {
        }
catch (        JedisConnectionException e2) {
          LOGGER.error(""String_Node_Str"",e2);
        }
 finally {
          if (conn != null) {
            conn.disconnect();
          }
        }
      }
    }
  }
  finally {
    isChecking.set(false);
  }
}"
37528,"public List<SlowKey> getSlowKeys(){
  try {
    while (!blocking.compareAndSet(false,true)) {
    }
    sort();
    return keys.subList(0,100);
  }
  finally {
    blocking.set(false);
  }
}","public List<SlowKey> getSlowKeys(){
  try {
    while (!blocking.compareAndSet(false,true)) {
    }
    sort();
    return keys.subList(0,keys.size() > 100 ? 100 : keys.size());
  }
  finally {
    blocking.set(false);
  }
}"
37529,"/** 
 *  redis key
 */
private void checkListKeyLength(){
  if (!isChecking.compareAndSet(false,true)) {
    return;
  }
  try {
    lastCheckTime=TimeUtil.currentTimeMillis();
    for (    java.util.Map.Entry<String,String[]> listKey : keyMap.entrySet()) {
      String key=listKey.getKey();
      String[] value=listKey.getValue();
      String password=value[0];
      String cmd=value[1];
      UserCfg userCfg=RedisEngineCtx.INSTANCE().getUserMap().get(password);
      if (userCfg != null) {
        AbstractPool pool=RedisEngineCtx.INSTANCE().getPoolMap().get(userCfg.getPoolId());
        PhysicalNode physicalNode=pool.getPhysicalNode();
        JedisConnection conn=null;
        try {
          conn=new JedisConnection(physicalNode.getHost(),physicalNode.getPort(),1000,0);
          conn.sendCommand(RedisCommand.READONLY);
          conn.getBulkReply();
          if (cmd.equals(""String_Node_Str"") || cmd.equals(""String_Node_Str"") || cmd.equals(""String_Node_Str"")|| cmd.equals(""String_Node_Str"")|| cmd.equals(""String_Node_Str"")) {
            conn.sendCommand(RedisCommand.HLEN,key);
          }
 else           if (cmd.equals(""String_Node_Str"") || cmd.equals(""String_Node_Str"") || cmd.equals(""String_Node_Str"")|| cmd.equals(""String_Node_Str"")) {
            conn.sendCommand(RedisCommand.LLEN,key);
          }
 else           if (cmd.equals(""String_Node_Str"")) {
            conn.sendCommand(RedisCommand.SCARD,key);
          }
 else           if (cmd.equals(""String_Node_Str"") || cmd.equals(""String_Node_Str"") || cmd.equals(""String_Node_Str"")) {
            conn.sendCommand(RedisCommand.ZCARD,key);
          }
          long length=conn.getIntegerReply();
          if (length > THRESHOLD) {
            BigLength bigLen=bigLengthMap.get(key);
            if (bigLen == null) {
              bigLen=new BigLength();
              bigLen.cmd=cmd;
              bigLen.key=key;
            }
            bigLen.length.set((int)length);
          }
 else {
            keyMap.remove(key);
          }
          BigLength min=null;
          for (          BigLength bigLen : bigLengthMap.values()) {
            if (min == null) {
              min=bigLen;
            }
 else {
              if (bigLen.length.get() < min.length.get()) {
                min=bigLen;
              }
            }
          }
          if (min != null)           bigLengthMap.remove(min.key);
        }
 catch (        JedisDataException e1) {
        }
catch (        JedisConnectionException e2) {
          LOGGER.error(""String_Node_Str"",e2);
        }
 finally {
          if (conn != null) {
            conn.disconnect();
          }
        }
      }
    }
  }
  finally {
    isChecking.set(false);
  }
}","/** 
 *  redis key
 */
private void checkListKeyLength(){
  if (!isChecking.compareAndSet(false,true)) {
    return;
  }
  try {
    lastCheckTime=TimeUtil.currentTimeMillis();
    for (    java.util.Map.Entry<String,String[]> listKey : keyMap.entrySet()) {
      String key=listKey.getKey();
      String[] value=listKey.getValue();
      String password=value[0];
      String cmd=value[1];
      UserCfg userCfg=RedisEngineCtx.INSTANCE().getUserMap().get(password);
      if (userCfg != null) {
        AbstractPool pool=RedisEngineCtx.INSTANCE().getPoolMap().get(userCfg.getPoolId());
        PhysicalNode physicalNode;
        if (pool.getType() == 1) {
          physicalNode=pool.getPhysicalNode(cmd,key);
        }
 else {
          physicalNode=pool.getPhysicalNode();
        }
        JedisConnection conn=null;
        try {
          conn=new JedisConnection(physicalNode.getHost(),physicalNode.getPort(),1000,0);
          if (cmd.equals(""String_Node_Str"") || cmd.equals(""String_Node_Str"") || cmd.equals(""String_Node_Str"")|| cmd.equals(""String_Node_Str"")|| cmd.equals(""String_Node_Str"")) {
            conn.sendCommand(RedisCommand.HLEN,key);
          }
 else           if (cmd.equals(""String_Node_Str"") || cmd.equals(""String_Node_Str"") || cmd.equals(""String_Node_Str"")|| cmd.equals(""String_Node_Str"")) {
            conn.sendCommand(RedisCommand.LLEN,key);
          }
 else           if (cmd.equals(""String_Node_Str"")) {
            conn.sendCommand(RedisCommand.SCARD,key);
          }
 else           if (cmd.equals(""String_Node_Str"") || cmd.equals(""String_Node_Str"") || cmd.equals(""String_Node_Str"")) {
            conn.sendCommand(RedisCommand.ZCARD,key);
          }
          long length=conn.getIntegerReply();
          if (length > THRESHOLD) {
            BigLength bigLen=bigLengthMap.get(key);
            if (bigLen == null) {
              bigLen=new BigLength();
              bigLen.cmd=cmd;
              bigLen.key=key;
            }
            bigLen.length.set((int)length);
          }
 else {
            keyMap.remove(key);
          }
          BigLength min=null;
          for (          BigLength bigLen : bigLengthMap.values()) {
            if (min == null) {
              min=bigLen;
            }
 else {
              if (bigLen.length.get() < min.length.get()) {
                min=bigLen;
              }
            }
          }
          if (min != null)           bigLengthMap.remove(min.key);
        }
 catch (        JedisDataException e1) {
        }
catch (        JedisConnectionException e2) {
          LOGGER.error(""String_Node_Str"",e2);
        }
 finally {
          if (conn != null) {
            conn.disconnect();
          }
        }
      }
    }
  }
  finally {
    isChecking.set(false);
  }
}"
37530,"public int getSlot(String cmd,String key){
  if (key == null)   return 0;
  int slot=0;
  Byte isCached=cmds.get(cmd);
  if (isCached != null && isCached == B1) {
    try {
      slot=cache.get(key);
    }
 catch (    Exception e) {
      slot=ClusterCRC16Util.getSlot(key,false);
    }
  }
 else {
    slot=ClusterCRC16Util.getSlot(key,false);
  }
  return slot;
}","public int getSlot(String cmd,String key){
  if (key == null)   return 0;
  int slot=0;
  Byte isCached=cmds.get(cmd);
  if (isCached != null && isCached == B1) {
    try {
      slot=cache.get(key);
    }
 catch (    Exception e) {
      slot=ClusterCRC16Util.getSlot(key);
    }
  }
 else {
    slot=ClusterCRC16Util.getSlot(key);
  }
  return slot;
}"
37531,"@Override public Integer load(String key) throws Exception {
  int slot=ClusterCRC16Util.getSlot(key,false);
  cache.put(key,slot);
  return slot;
}","@Override public Integer load(String key) throws Exception {
  int slot=ClusterCRC16Util.getSlot(key);
  cache.put(key,slot);
  return slot;
}"
37532,"public static int getSlot(byte[] key,boolean isHashTag){
  if (isHashTag) {
    int s=-1;
    int e=-1;
    boolean sFound=false;
    for (int i=0; i < key.length; i++) {
      if (key[i] == '{' && !sFound) {
        s=i;
        sFound=true;
      }
      if (key[i] == '}' && sFound) {
        e=i;
        break;
      }
    }
    if (s > -1 && e > -1 && e != s + 1) {
      return getCRC16(key,s + 1,e) & 16383;
    }
  }
  return getCRC16(key) & 16383;
}","public static int getSlot(byte[] key){
  int s=-1;
  int e=-1;
  boolean sFound=false;
  for (int i=0; i < key.length; i++) {
    if (key[i] == '{' && !sFound) {
      s=i;
      sFound=true;
    }
    if (key[i] == '}' && sFound) {
      e=i;
      break;
    }
  }
  if (s > -1 && e > -1 && e != s + 1) {
    return getCRC16(key,s + 1,e) & 16383;
  }
  return getCRC16(key) & 16383;
}"
37533,"public static void main(String[] args){
  long begin=System.currentTimeMillis();
  for (int n=0; n <= TOTAL_OPERATIONS; n++) {
    ClusterCRC16Util.getSlot((TEST_SET[n % TEST_SET.length]),false);
  }
  long elapsed=System.currentTimeMillis() - begin;
  System.out.println(((1000 * TOTAL_OPERATIONS) / elapsed) + ""String_Node_Str"");
}","public static void main(String[] args){
  long begin=System.currentTimeMillis();
  for (int n=0; n <= TOTAL_OPERATIONS; n++) {
    ClusterCRC16Util.getSlot((TEST_SET[n % TEST_SET.length]));
  }
  long elapsed=System.currentTimeMillis() - begin;
  System.out.println(((1000 * TOTAL_OPERATIONS) / elapsed) + ""String_Node_Str"");
}"
37534,"@Override public PhysicalNode getPhysicalNode(String cmd,byte[] key){
  int slot=0;
  if (key != null) {
    slot=ClusterCRC16Util.getSlot(key,false);
  }
  PhysicalNode node=getPhysicalNodeBySlot(slot);
  return node;
}","@Override public PhysicalNode getPhysicalNode(String cmd,byte[] key){
  int slot=0;
  if (key != null) {
    slot=ClusterCRC16Util.getSlot(key);
  }
  PhysicalNode node=getPhysicalNodeBySlot(slot);
  return node;
}"
37535,"protected List<RouteResultNode> doSharding(int poolId,List<RedisRequest> requests,List<RedisRequestPolicy> requestPolicys) throws PhysicalNodeUnavailableException {
  List<RouteResultNode> nodes=new ArrayList<RouteResultNode>();
  AbstractPool pool=RedisEngineCtx.INSTANCE().getPoolMap().get(poolId);
  if (pool.getType() == 0) {
    RouteResultNode node=new RouteResultNode();
    PhysicalNode physicalNode=pool.getPhysicalNode();
    if (physicalNode == null)     throw new PhysicalNodeUnavailableException(""String_Node_Str"");
    node.setPhysicalNode(physicalNode);
    for (int i=0; i < requests.size(); i++) {
      node.addRequestIndex(i);
    }
    node.setPhysicalNode(pool.getPhysicalNode());
    nodes.add(node);
  }
 else   if (pool.getType() == 1) {
    RedisClusterPool clusterPool=(RedisClusterPool)pool;
    for (int i=0; i < requests.size(); i++) {
      if (requestPolicys.get(i).getLevel() == CommandParse.AUTO_RESP_CMD) {
        continue;
      }
      int slot=0;
      RedisRequest request=requests.get(i);
      byte[] requestKey=request.getNumArgs() > 1 ? request.getArgs()[1] : null;
      if (requestKey != null) {
        slot=ClusterCRC16Util.getSlot(requestKey,false);
      }
      PhysicalNode physicalNode=clusterPool.getPhysicalNodeBySlot(slot);
      if (physicalNode == null)       throw new PhysicalNodeUnavailableException(""String_Node_Str"");
      arrangePhyNode(nodes,i,physicalNode);
    }
  }
 else   if (pool.getType() == 2) {
    RedisCustomClusterPool ccPool=(RedisCustomClusterPool)pool;
    for (int i=0; i < requests.size(); i++) {
      if (requestPolicys.get(i).getLevel() == CommandParse.AUTO_RESP_CMD) {
        continue;
      }
      RedisRequest request=requests.get(i);
      PhysicalNode physicalNode=ccPool.getPhysicalNode(request);
      arrangePhyNode(nodes,i,physicalNode);
    }
  }
  return nodes;
}","protected List<RouteResultNode> doSharding(int poolId,List<RedisRequest> requests,List<RedisRequestPolicy> requestPolicys) throws PhysicalNodeUnavailableException {
  List<RouteResultNode> nodes=new ArrayList<RouteResultNode>();
  AbstractPool pool=RedisEngineCtx.INSTANCE().getPoolMap().get(poolId);
  if (pool.getType() == 0) {
    RouteResultNode node=new RouteResultNode();
    PhysicalNode physicalNode=pool.getPhysicalNode();
    if (physicalNode == null)     throw new PhysicalNodeUnavailableException(""String_Node_Str"");
    node.setPhysicalNode(physicalNode);
    for (int i=0; i < requests.size(); i++) {
      node.addRequestIndex(i);
    }
    node.setPhysicalNode(pool.getPhysicalNode());
    nodes.add(node);
  }
 else   if (pool.getType() == 1) {
    RedisClusterPool clusterPool=(RedisClusterPool)pool;
    for (int i=0; i < requests.size(); i++) {
      if (requestPolicys.get(i).getLevel() == CommandParse.AUTO_RESP_CMD) {
        continue;
      }
      int slot=0;
      RedisRequest request=requests.get(i);
      byte[] requestKey=request.getNumArgs() > 1 ? request.getArgs()[1] : null;
      if (requestKey != null) {
        slot=ClusterCRC16Util.getSlot(requestKey);
      }
      PhysicalNode physicalNode=clusterPool.getPhysicalNodeBySlot(slot);
      if (physicalNode == null)       throw new PhysicalNodeUnavailableException(""String_Node_Str"");
      arrangePhyNode(nodes,i,physicalNode);
    }
  }
 else   if (pool.getType() == 2) {
    RedisCustomClusterPool ccPool=(RedisCustomClusterPool)pool;
    for (int i=0; i < requests.size(); i++) {
      if (requestPolicys.get(i).getLevel() == CommandParse.AUTO_RESP_CMD) {
        continue;
      }
      RedisRequest request=requests.get(i);
      PhysicalNode physicalNode=ccPool.getPhysicalNode(request);
      arrangePhyNode(nodes,i,physicalNode);
    }
  }
  return nodes;
}"
37536,"@Override public void setOnErrorListener(IMediaPlayer.OnErrorListener var1){
  setOnErrorListener((MediaPlayer.OnErrorListener)var1::onError);
}","@Override public void setOnErrorListener(IMediaPlayer.OnErrorListener var1){
  setOnErrorListener((MediaPlayer.OnErrorListener)(mp,what,extra) -> var1.onError(DefaultMediaPlayer.this,what,extra));
}"
37537,"/** 
 * Called to indicate an error.
 * @param mp    the MediaPlayer the error pertains to
 * @param what  the type of error that has occurred:
 * @param extra an extra code, specific to the error. Typically implementation dependent.
 * @return True if the method handled the error, false if it didn't.Returning false, or not having an OnErrorListener at all, will cause the OnCompletionListener to be called.
 */
boolean onError(MediaPlayer mp,int what,int extra);","/** 
 * Called to indicate an error.
 * @param mp    the MediaPlayer the error pertains to
 * @param what  the type of error that has occurred:
 * @param extra an extra code, specific to the error. Typically implementation dependent.
 * @return True if the method handled the error, false if it didn't.Returning false, or not having an OnErrorListener at all, will cause the OnCompletionListener to be called.
 */
boolean onError(IMediaPlayer mp,int what,int extra);"
37538,"/** 
 * 
 * @param context
 * @param path
 * @param width   
 * @param height  
 * @return
 */
public static Bitmap loadBitmap(Context context,String path,int width,int height){
  InputStream in=null;
  try {
    BitmapFactory.Options options=new BitmapFactory.Options();
    options.inJustDecodeBounds=true;
    if (Path.ASSETS.belongsTo(path)) {
      in=context.getAssets().open(Path.ASSETS.crop(path));
      if (in != null) {
        BitmapFactory.decodeStream(in,null,options);
      }
    }
 else     if (Path.FILE.belongsTo(path)) {
      BitmapFactory.decodeFile(Path.FILE.crop(path),options);
    }
 else     if (Path.DRAWABLE.belongsTo(path)) {
      BitmapFactory.decodeResource(context.getResources(),Integer.parseInt(Path.DRAWABLE.crop(path)),options);
    }
 else {
      BitmapFactory.decodeFile(path,options);
    }
    int outWidth=options.outWidth;
    int outHeight=options.outHeight;
    int sampleSize=1;
    while (outWidth / sampleSize > width || outHeight / sampleSize > height) {
      sampleSize++;
    }
    options.inJustDecodeBounds=false;
    options.inSampleSize=sampleSize;
    if (Path.ASSETS.belongsTo(path)) {
      in=context.getAssets().open(Path.ASSETS.crop(path));
      if (in != null) {
        return BitmapFactory.decodeStream(in,null,options);
      }
    }
 else     if (Path.FILE.belongsTo(path)) {
      return BitmapFactory.decodeFile(Path.FILE.crop(path),options);
    }
 else     if (Path.DRAWABLE.belongsTo(path)) {
      return BitmapFactory.decodeResource(context.getResources(),Integer.parseInt(Path.DRAWABLE.crop(path)),options);
    }
 else {
      return BitmapFactory.decodeFile(path,options);
    }
  }
 catch (  IOException|OutOfMemoryError e) {
    e.printStackTrace();
  }
 finally {
    if (in != null) {
      try {
        in.close();
      }
 catch (      Exception e) {
        e.printStackTrace();
      }
    }
  }
  return null;
}","/** 
 * 
 * @param context
 * @param path
 * @param width   
 * @param height  
 * @return
 */
public static Bitmap loadBitmap(Context context,String path,int width,int height){
  InputStream in=null;
  try {
    BitmapFactory.Options options=new BitmapFactory.Options();
    options.inJustDecodeBounds=true;
    if (Path.ASSETS.belongsTo(path)) {
      in=context.getAssets().open(Path.ASSETS.crop(path));
      if (in != null) {
        BitmapFactory.decodeStream(in,null,options);
      }
    }
 else     if (Path.FILE.belongsTo(path)) {
      BitmapFactory.decodeFile(Path.FILE.crop(path),options);
    }
 else     if (Path.DRAWABLE.belongsTo(path)) {
      BitmapFactory.decodeResource(context.getResources(),Integer.parseInt(Path.DRAWABLE.crop(path)),options);
    }
 else {
      BitmapFactory.decodeFile(path,options);
    }
    int outWidth=options.outWidth;
    int outHeight=options.outHeight;
    int sampleSize=1;
    while (outWidth / (sampleSize * 2) > width || outHeight / (sampleSize * 2) > height) {
      sampleSize*=2;
    }
    options.inJustDecodeBounds=false;
    options.inSampleSize=sampleSize;
    if (Path.ASSETS.belongsTo(path)) {
      in=context.getAssets().open(Path.ASSETS.crop(path));
      if (in != null) {
        return BitmapFactory.decodeStream(in,null,options);
      }
    }
 else     if (Path.FILE.belongsTo(path)) {
      return BitmapFactory.decodeFile(Path.FILE.crop(path),options);
    }
 else     if (Path.DRAWABLE.belongsTo(path)) {
      return BitmapFactory.decodeResource(context.getResources(),Integer.parseInt(Path.DRAWABLE.crop(path)),options);
    }
 else {
      return BitmapFactory.decodeFile(path,options);
    }
  }
 catch (  IOException|OutOfMemoryError e) {
    e.printStackTrace();
  }
 finally {
    if (in != null) {
      try {
        in.close();
      }
 catch (      Exception e) {
        e.printStackTrace();
      }
    }
  }
  return null;
}"
37539,"@Override public void onTextureAcceptable(int texture,GLRender source){
  super.onTextureAcceptable(texture,source);
synchronized (this) {
    if (mVideoEncoder != null) {
      int oldTexture=mVideoEncoder.getInputTextureId();
      if (texture != oldTexture) {
        mVideoEncoder.setInputTextureId(texture);
      }
    }
  }
}","@Override public void onTextureAcceptable(int texture,GLRender source){
  super.onTextureAcceptable(texture,source);
  try {
    if (mVideoEncoder != null) {
      int oldTexture=mVideoEncoder.getInputTextureId();
      if (texture != oldTexture) {
        mVideoEncoder.setInputTextureId(texture);
      }
    }
  }
 catch (  Exception e) {
    e.printStackTrace();
  }
}"
37540,"/** 
 * 
 * @param encoder
 */
public void setVideoEncoder(final MediaVideoEncoder encoder){
synchronized (this) {
    mVideoEncoder=encoder;
  }
}","/** 
 * 
 * @param encoder
 */
public void setVideoEncoder(final MediaVideoEncoder encoder){
  mVideoEncoder=encoder;
}"
37541,"@Override protected void drawFrame(){
  super.drawFrame();
synchronized (this) {
    if (mVideoEncoder != null) {
      mVideoEncoder.frameAvailableSoon();
    }
  }
}","@Override protected void drawFrame(){
  super.drawFrame();
  try {
    if (mVideoEncoder != null) {
      mVideoEncoder.frameAvailableSoon();
    }
  }
 catch (  Exception e) {
    e.printStackTrace();
  }
}"
37542,"static String convert(InputStream stream) throws IOException {
  BufferedReader r=new BufferedReader(new InputStreamReader(stream));
  StringBuilder total=new StringBuilder();
  String line;
  while ((line=r.readLine()) != null) {
    total.append(line);
    total.append('\n');
  }
  return total.toString();
}","static String convert(InputStream stream) throws IOException {
  BufferedReader r=new BufferedReader(new InputStreamReader(stream));
  StringBuilder total=new StringBuilder();
  String line;
  while ((line=r.readLine()) != null) {
    total.append(line);
    total.append(RETURN_SYMBOL);
  }
  return total.toString();
}"
37543,"private void connectClient(){
  Uri.Builder uriBuilder=parsedUri.buildUpon();
  uriBuilder.appendQueryParameter(""String_Node_Str"",connectionId);
  uriBuilder.scheme(parsedUri.getScheme().replace(""String_Node_Str"",""String_Node_Str""));
  Uri uri=uriBuilder.build();
  Map<String,String> headers=new HashMap<>();
  if (authHeader != null && !authHeader.isEmpty()) {
    headers.put(""String_Node_Str"",authHeader);
  }
  try {
    client=new WebSocketClient(new URI(uri.toString()),new Draft_6455(),headers,15000){
      @Override public void onOpen(      ServerHandshake handshakeData){
        Log.i(TAG,""String_Node_Str"");
        for (        HubConnectionListener listener : listeners) {
          listener.onConnected();
        }
        send(""String_Node_Str"" + SPECIAL_SYMBOL);
      }
      @Override public void onMessage(      String message){
        Log.i(TAG,message);
        String[] messages=message.split(SPECIAL_SYMBOL);
        for (        String m : messages) {
          SignalRMessage element=gson.fromJson(m,SignalRMessage.class);
          if (element.getType() == 1) {
            HubMessage hubMessage=new HubMessage(element.getInvocationId(),element.getTarget(),element.getArguments());
            for (            HubConnectionListener listener : listeners) {
              listener.onMessage(hubMessage);
            }
            List<HubEventListener> hubEventListeners=eventListeners.get(hubMessage.getTarget());
            if (hubEventListeners != null) {
              for (              HubEventListener listener : hubEventListeners) {
                listener.onEventMessage(hubMessage);
              }
            }
          }
        }
      }
      @Override public void onClose(      int code,      String reason,      boolean remote){
        Log.i(TAG,String.format(""String_Node_Str"",code,reason,remote));
        for (        HubConnectionListener listener : listeners) {
          listener.onDisconnected();
        }
        connectionId=null;
      }
      @Override public void onError(      Exception ex){
        Log.i(TAG,""String_Node_Str"" + ex.getMessage());
        error(ex);
      }
    }
;
    if (parsedUri.getScheme().equals(""String_Node_Str"")) {
      client.setSocket(SSLSocketFactory.getDefault().createSocket());
    }
  }
 catch (  Exception e) {
    error(e);
  }
  Log.i(TAG,""String_Node_Str"");
  client.connect();
}","private void connectClient(){
  Uri.Builder uriBuilder=parsedUri.buildUpon();
  uriBuilder.appendQueryParameter(""String_Node_Str"",connectionId);
  uriBuilder.scheme(parsedUri.getScheme().replace(""String_Node_Str"",""String_Node_Str""));
  Uri uri=uriBuilder.build();
  Map<String,String> headers=new HashMap<>();
  if (authHeader != null && !authHeader.isEmpty()) {
    headers.put(""String_Node_Str"",authHeader);
  }
  try {
    client=new WebSocketClient(new URI(uri.toString()),new Draft_6455(),headers,15000){
      @Override public void onOpen(      ServerHandshake handshakeData){
        Log.i(TAG,""String_Node_Str"");
        for (        HubConnectionListener listener : listeners) {
          listener.onConnected();
        }
        send(""String_Node_Str"" + SPECIAL_SYMBOL);
      }
      @Override public void onMessage(      String message){
        Log.i(TAG,message);
        String[] messages=message.split(SPECIAL_SYMBOL);
        for (        String m : messages) {
          SignalRMessage element=gson.fromJson(m,SignalRMessage.class);
          Integer type=element.getType();
          if (type != null && type == 1) {
            HubMessage hubMessage=new HubMessage(element.getInvocationId(),element.getTarget(),element.getArguments());
            for (            HubConnectionListener listener : listeners) {
              listener.onMessage(hubMessage);
            }
            List<HubEventListener> hubEventListeners=eventListeners.get(hubMessage.getTarget());
            if (hubEventListeners != null) {
              for (              HubEventListener listener : hubEventListeners) {
                listener.onEventMessage(hubMessage);
              }
            }
          }
        }
      }
      @Override public void onClose(      int code,      String reason,      boolean remote){
        Log.i(TAG,String.format(""String_Node_Str"",code,reason,remote));
        for (        HubConnectionListener listener : listeners) {
          listener.onDisconnected();
        }
        connectionId=null;
      }
      @Override public void onError(      Exception ex){
        Log.i(TAG,""String_Node_Str"" + ex.getMessage());
        error(ex);
      }
    }
;
    if (parsedUri.getScheme().equals(""String_Node_Str"")) {
      client.setSocket(SSLSocketFactory.getDefault().createSocket());
    }
  }
 catch (  Exception e) {
    error(e);
  }
  Log.i(TAG,""String_Node_Str"");
  client.connect();
}"
37544,"@Override public void onMessage(String message){
  Log.i(TAG,message);
  String[] messages=message.split(SPECIAL_SYMBOL);
  for (  String m : messages) {
    SignalRMessage element=gson.fromJson(m,SignalRMessage.class);
    if (element.getType() == 1) {
      HubMessage hubMessage=new HubMessage(element.getInvocationId(),element.getTarget(),element.getArguments());
      for (      HubConnectionListener listener : listeners) {
        listener.onMessage(hubMessage);
      }
      List<HubEventListener> hubEventListeners=eventListeners.get(hubMessage.getTarget());
      if (hubEventListeners != null) {
        for (        HubEventListener listener : hubEventListeners) {
          listener.onEventMessage(hubMessage);
        }
      }
    }
  }
}","@Override public void onMessage(String message){
  Log.i(TAG,message);
  String[] messages=message.split(SPECIAL_SYMBOL);
  for (  String m : messages) {
    SignalRMessage element=gson.fromJson(m,SignalRMessage.class);
    Integer type=element.getType();
    if (type != null && type == 1) {
      HubMessage hubMessage=new HubMessage(element.getInvocationId(),element.getTarget(),element.getArguments());
      for (      HubConnectionListener listener : listeners) {
        listener.onMessage(hubMessage);
      }
      List<HubEventListener> hubEventListeners=eventListeners.get(hubMessage.getTarget());
      if (hubEventListeners != null) {
        for (        HubEventListener listener : hubEventListeners) {
          listener.onEventMessage(hubMessage);
        }
      }
    }
  }
}"
37545,"/** 
 * Replace the variables in the given   {@code InputStream} and produce a new stream.If the  {@code variableResolver} is null, the original {@code InputStream} will be returned.<p> Note that although we're processing streams, all the contents will be loaded and returned for this substitution.
 * @param original         the original {@code InputStream}
 * @param variableResolver the variable resolver
 * @return a new {@code InputStream} with the variables replaced by their values,or the original if the  {@code variableResolver} is {@code null}.
 * @throws IOException error on reading the original InputStream.
 */
public static InputStream replaceMacro(InputStream original,VariableResolver<String> variableResolver) throws IOException {
  try {
    if (variableResolver == null) {
      return original;
    }
    String content=IOUtils.toString(original,Constants.DEFAULT_CHARSET);
    content=Util.replaceMacro(content,variableResolver);
    if (content != null) {
      return new ByteArrayInputStream(content.getBytes(Constants.DEFAULT_CHARSET));
    }
 else {
      throw new IllegalArgumentException(Messages.JobContext_nullContent());
    }
  }
  finally {
    original.close();
  }
}","/** 
 * Replace the variables in the given   {@code InputStream} and produce a new stream.If the  {@code variableResolver} is null, the original {@code InputStream} will be returned.<p> Note that although we're processing streams, all the contents will be loaded and returned for this substitution.
 * @param original         the original {@code InputStream}
 * @param variableResolver the variable resolver
 * @return a new {@code InputStream} with the variables replaced by their values,or the original if the  {@code variableResolver} is {@code null}.
 * @throws IOException error on reading the original InputStream.
 */
public static InputStream replaceMacro(InputStream original,VariableResolver<String> variableResolver) throws IOException {
  if (variableResolver == null) {
    return original;
  }
  try {
    String content=IOUtils.toString(original,Constants.DEFAULT_CHARSET);
    content=Util.replaceMacro(content,variableResolver);
    if (content != null) {
      return new ByteArrayInputStream(content.getBytes(Constants.DEFAULT_CHARSET));
    }
 else {
      throw new IllegalArgumentException(Messages.JobContext_nullContent());
    }
  }
  finally {
    original.close();
  }
}"
37546,"private void testReplaceMacro(String expected,String original,Map<String,String> variables) throws Exception {
  ByteArrayInputStream in=new ByteArrayInputStream(original.getBytes(Constants.DEFAULT_CHARSET));
  InputStream result=CommonUtils.replaceMacro(in,new VariableResolver.ByMap<>(variables));
  assertEquals(expected,IOUtils.toString(result,Constants.DEFAULT_CHARSET));
}","private void testReplaceMacro(String expected,String original,Map<String,String> variables) throws Exception {
  ByteArrayInputStream in=new ByteArrayInputStream(original.getBytes(Constants.DEFAULT_CHARSET));
  InputStream result=CommonUtils.replaceMacro(in,variables == null ? null : new VariableResolver.ByMap<>(variables));
  assertEquals(expected,IOUtils.toString(result,Constants.DEFAULT_CHARSET));
}"
37547,"public void refresh(){
  refreshLegend();
  getAdapter().notifyDataSetChanged();
}","@SuppressWarnings(""String_Node_Str"") public void refresh(){
  refreshLegend();
  getAdapter().notifyDataSetChanged();
}"
37548,"void bind(CalendarMonth month){
  if (title != null) {
    title.setText(month.getReadableMonthName());
  }
  for (int i=1; i <= weeks.length; i++) {
    weeks[i - 1].display(i,month,filterWeekDays(i,month));
  }
}","void bind(CalendarMonth month){
  if (title != null) {
    title.setText(month.getReadableMonthName());
  }
  for (int i=0; i <= weeks.length - 1; i++) {
    weeks[i].display(i,month,filterWeekDays(i,month));
  }
}"
37549,"private boolean isRightAligned(int week){
  return week == 1;
}","private boolean isRightAligned(int week){
  return week <= 1;
}"
37550,"@Override protected void onCreate(Bundle savedInstanceState){
  super.onCreate(savedInstanceState);
  EventBus.getDefault().register(this);
  try {
    ConnectionUtil.initialize(this);
  }
 catch (  Exception e) {
    Toast.makeText(MainActivity.this,R.string.sslFailed,Toast.LENGTH_LONG).show();
  }
  getWindow().addFlags(WindowManager.LayoutParams.FLAG_FULLSCREEN);
  setContentView(R.layout.activity_main);
  PreferenceManager.setDefaultValues(this,R.xml.preferences,false);
  NavigationView navigationView=(NavigationView)findViewById(R.id.nav_view);
  LinearLayout navHeader=(LinearLayout)LayoutInflater.from(this).inflate(R.layout.nav_header_main,null);
  navigationView.addHeaderView(navHeader);
  navigationView.setNavigationItemSelectedListener(this);
  final SharedPreferences prefs=PreferenceManager.getDefaultSharedPreferences(MainActivity.this);
  mServerConnection=new ServerConnection(this);
  mServerConnection.addConnectionListener(this);
  if (getPackageManager().hasSystemFeature(PackageManager.FEATURE_CAMERA)) {
    if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.M) {
      try {
        mFlashService=new FlashHandler(this,(CameraManager)getSystemService(Context.CAMERA_SERVICE));
      }
 catch (      CameraAccessException|IllegalAccessException e) {
        Log.d(""String_Node_Str"",""String_Node_Str"");
      }
    }
    final SurfaceView motionView=((SurfaceView)findViewById(R.id.motionView));
    int scaledSize=getResources().getDimensionPixelSize(R.dimen.motionFontSize);
    MotionVisualizer mv=new MotionVisualizer(motionView,navigationView,prefs,scaledSize);
    boolean newApi=prefs.getBoolean(""String_Node_Str"",Build.VERSION.SDK_INT >= Build.VERSION_CODES.LOLLIPOP);
    if (newApi && Build.VERSION.SDK_INT >= Build.VERSION_CODES.LOLLIPOP) {
      mMotionDetector=new MotionDetectorCamera2(this,(CameraManager)getSystemService(Context.CAMERA_SERVICE),mv,this,mServerConnection);
    }
 else {
      mMotionDetector=new MotionDetector(this,mv,mServerConnection);
    }
  }
  mDiscovery=new ServerDiscovery((NsdManager)getSystemService(Context.NSD_SERVICE));
  if (prefs.getBoolean(""String_Node_Str"",true)) {
    SharedPreferences.Editor editor1=prefs.edit();
    editor1.putBoolean(""String_Node_Str"",false);
    editor1.putString(""String_Node_Str"",BuildConfig.VERSION_NAME);
    editor1.apply();
    final String startText=ResourcesUtil.fetchFirstStart(this);
    UiUtil.showScrollDialog(this,""String_Node_Str"",getString(R.string.welcome),startText);
    if (prefs.getString(""String_Node_Str"",""String_Node_Str"").isEmpty()) {
      mDiscovery.discover(new ServerDiscovery.DiscoveryListener(){
        @Override public void found(        String serverUrl){
          SharedPreferences.Editor editor1=prefs.edit();
          editor1.putString(""String_Node_Str"",serverUrl);
          editor1.apply();
        }
        @Override public void notFound(){
        }
      }
,true,true);
    }
  }
 else {
    String lastVersion=prefs.getString(""String_Node_Str"",""String_Node_Str"");
    if (!BuildConfig.VERSION_NAME.equals(lastVersion)) {
      SharedPreferences.Editor editor1=prefs.edit();
      editor1.putString(""String_Node_Str"",BuildConfig.VERSION_NAME);
      editor1.apply();
      final String relText=ResourcesUtil.fetchReleaseNotes(this,lastVersion);
      UiUtil.showScrollDialog(this,getString(R.string.updated),getString(R.string.updatedText),relText);
    }
  }
  mBatteryMonitor=new BatteryMonitor(this,mServerConnection);
  mVolumeMonitor=new VolumeMonitor(this,(AudioManager)getSystemService(Context.AUDIO_SERVICE),mServerConnection);
  mConnectedReporter=new ConnectedIndicator(this,mServerConnection);
  SensorManager m=(SensorManager)getSystemService(Context.SENSOR_SERVICE);
  try {
    mProximityMonitor=new ProximityMonitor(this,m,mServerConnection);
  }
 catch (  SensorMissingException e) {
    Log.d(""String_Node_Str"",""String_Node_Str"");
  }
  try {
    mBrightnessMonitor=new BrightnessMonitor(this,m,mServerConnection);
  }
 catch (  SensorMissingException e) {
    Log.d(""String_Node_Str"",""String_Node_Str"");
  }
  try {
    mPressureMonitor=new PressureMonitor(this,m,mServerConnection);
  }
 catch (  SensorMissingException e) {
    Log.d(""String_Node_Str"",""String_Node_Str"");
  }
  try {
    mTemperatureMonitor=new TemperatureMonitor(this,m,mServerConnection);
  }
 catch (  SensorMissingException e) {
    Log.d(""String_Node_Str"",""String_Node_Str"");
  }
  mScreenHandler=new ScreenHandler((PowerManager)getSystemService(POWER_SERVICE),this);
  mCommandQueue=new CommandQueue(mServerConnection);
  mCommandQueue.addHandler(new InternalCommandHandler(this,mServerConnection));
  mCommandQueue.addHandler(new AdminHandler(this));
  mCommandQueue.addHandler(new BluetoothHandler(this,(BluetoothManager)getSystemService(BLUETOOTH_SERVICE)));
  mCommandQueue.addHandler(mScreenHandler);
  mCommandQueue.addHandler(new VolumeHandler(this,(AudioManager)getSystemService(Context.AUDIO_SERVICE)));
  if (mFlashService != null) {
    mCommandQueue.addHandler(mFlashService);
  }
  mRestartCount=getIntent().getIntExtra(""String_Node_Str"",0);
  showInitialToastMessage(mRestartCount);
  mTextView=navHeader.findViewById(R.id.textView);
  mWebView=((ClientWebView)findViewById(R.id.activity_main_webview));
  mWebView.initialize();
}","@Override protected void onCreate(Bundle savedInstanceState){
  super.onCreate(savedInstanceState);
  EventBus.getDefault().register(this);
  try {
    ConnectionUtil.initialize(this);
  }
 catch (  Exception e) {
    Toast.makeText(MainActivity.this,R.string.sslFailed,Toast.LENGTH_LONG).show();
  }
  getWindow().addFlags(WindowManager.LayoutParams.FLAG_FULLSCREEN);
  setContentView(R.layout.activity_main);
  PreferenceManager.setDefaultValues(this,R.xml.preferences,false);
  NavigationView navigationView=(NavigationView)findViewById(R.id.nav_view);
  LinearLayout navHeader=(LinearLayout)LayoutInflater.from(this).inflate(R.layout.nav_header_main,null);
  navigationView.addHeaderView(navHeader);
  navigationView.setNavigationItemSelectedListener(this);
  final SharedPreferences prefs=PreferenceManager.getDefaultSharedPreferences(MainActivity.this);
  mServerConnection=new ServerConnection(this);
  mServerConnection.addConnectionListener(this);
  if (getPackageManager().hasSystemFeature(PackageManager.FEATURE_CAMERA)) {
    if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.M) {
      try {
        mFlashService=new FlashHandler(this,(CameraManager)getSystemService(Context.CAMERA_SERVICE));
      }
 catch (      CameraAccessException|IllegalAccessException e) {
        Log.d(""String_Node_Str"",""String_Node_Str"");
      }
    }
    final SurfaceView motionView=((SurfaceView)findViewById(R.id.motionView));
    int scaledSize=getResources().getDimensionPixelSize(R.dimen.motionFontSize);
    MotionVisualizer mv=new MotionVisualizer(motionView,navigationView,prefs,scaledSize);
    boolean newApi=prefs.getBoolean(""String_Node_Str"",Build.VERSION.SDK_INT >= Build.VERSION_CODES.LOLLIPOP);
    if (newApi && Build.VERSION.SDK_INT >= Build.VERSION_CODES.LOLLIPOP) {
      mMotionDetector=new MotionDetectorCamera2(this,(CameraManager)getSystemService(Context.CAMERA_SERVICE),mv,this,mServerConnection);
    }
 else {
      mMotionDetector=new MotionDetector(this,mv,mServerConnection);
    }
  }
  mDiscovery=new ServerDiscovery((NsdManager)getSystemService(Context.NSD_SERVICE));
  if (prefs.getBoolean(""String_Node_Str"",true)) {
    SharedPreferences.Editor editor1=prefs.edit();
    editor1.putBoolean(""String_Node_Str"",false);
    editor1.putString(""String_Node_Str"",BuildConfig.VERSION_NAME);
    editor1.apply();
    final String startText=ResourcesUtil.fetchFirstStart(this);
    UiUtil.showScrollDialog(this,""String_Node_Str"",getString(R.string.welcome),startText);
    if (prefs.getString(""String_Node_Str"",""String_Node_Str"").isEmpty()) {
      mDiscovery.discover(new ServerDiscovery.DiscoveryListener(){
        @Override public void found(        String serverUrl){
          SharedPreferences.Editor editor1=prefs.edit();
          editor1.putString(""String_Node_Str"",serverUrl);
          editor1.apply();
        }
        @Override public void notFound(){
        }
      }
,true,true);
    }
  }
 else {
    String lastVersion=prefs.getString(""String_Node_Str"",""String_Node_Str"");
    if (!BuildConfig.VERSION_NAME.equals(lastVersion)) {
      SharedPreferences.Editor editor1=prefs.edit();
      editor1.putString(""String_Node_Str"",BuildConfig.VERSION_NAME);
      editor1.apply();
      final String relText=ResourcesUtil.fetchReleaseNotes(this,lastVersion);
      UiUtil.showScrollDialog(this,getString(R.string.updated),getString(R.string.updatedText),relText);
    }
  }
  mBatteryMonitor=new BatteryMonitor(this,mServerConnection);
  mVolumeMonitor=new VolumeMonitor(this,(AudioManager)getSystemService(Context.AUDIO_SERVICE),mServerConnection);
  mConnectedReporter=new ConnectedIndicator(this,mServerConnection);
  SensorManager m=(SensorManager)getSystemService(Context.SENSOR_SERVICE);
  try {
    mProximityMonitor=new ProximityMonitor(this,m,mServerConnection);
  }
 catch (  SensorMissingException e) {
    Log.d(""String_Node_Str"",""String_Node_Str"");
  }
  try {
    mBrightnessMonitor=new BrightnessMonitor(this,m,mServerConnection);
  }
 catch (  SensorMissingException e) {
    Log.d(""String_Node_Str"",""String_Node_Str"");
  }
  try {
    mPressureMonitor=new PressureMonitor(this,m,mServerConnection);
  }
 catch (  SensorMissingException e) {
    Log.d(""String_Node_Str"",""String_Node_Str"");
  }
  try {
    mTemperatureMonitor=new TemperatureMonitor(this,m,mServerConnection);
  }
 catch (  SensorMissingException e) {
    Log.d(""String_Node_Str"",""String_Node_Str"");
  }
  ScreenHandler mScreenHandler=new ScreenHandler((PowerManager)getSystemService(POWER_SERVICE),this);
  mCommandQueue=new CommandQueue(this,mServerConnection);
  mCommandQueue.addHandler(new InternalCommandHandler(this,mServerConnection));
  mCommandQueue.addHandler(new AdminHandler(this));
  mCommandQueue.addHandler(new BluetoothHandler(this,(BluetoothManager)getSystemService(BLUETOOTH_SERVICE)));
  mCommandQueue.addHandler(mScreenHandler);
  mCommandQueue.addHandler(new VolumeHandler(this,(AudioManager)getSystemService(Context.AUDIO_SERVICE)));
  if (mFlashService != null) {
    mCommandQueue.addHandler(mFlashService);
  }
  mRestartCount=getIntent().getIntExtra(""String_Node_Str"",0);
  showInitialToastMessage(mRestartCount);
  mTextView=navHeader.findViewById(R.id.textView);
  mWebView=((ClientWebView)findViewById(R.id.activity_main_webview));
  mWebView.initialize();
}"
37551,"public CommandQueue(ServerConnection serverConnection){
  EventBus.getDefault().register(this);
  mServerConnection=serverConnection;
}","public CommandQueue(Activity ctx,ServerConnection serverConnection){
  EventBus.getDefault().register(this);
  mCtx=ctx;
  mServerConnection=serverConnection;
}"
37552,"@Override public void itemUpdated(String name,String value){
  if (value != null && !value.isEmpty()) {
    try {
synchronized (mHandlers) {
        for (        CommandHandler mHandler : mHandlers) {
          try {
            if (mHandler.handleCommand(value)) {
              mCmdLog.add(new CommandInfo(value,true));
              return;
            }
          }
 catch (          Throwable t) {
            Log.e(""String_Node_Str"",""String_Node_Str"",t);
            mCmdLog.add(new CommandInfo(value,true,t));
            return;
          }
        }
      }
      Log.w(""String_Node_Str"",""String_Node_Str"" + value);
      mCmdLog.add(new CommandInfo(value,false));
    }
  finally {
      mServerConnection.updateState(name,""String_Node_Str"");
    }
  }
}","@Override public void itemUpdated(String name,String value){
  if (value != null && !value.isEmpty()) {
    try {
synchronized (mHandlers) {
        for (        CommandHandler mHandler : mHandlers) {
          try {
            if (mHandler.handleCommand(value)) {
              addToCmdLog(new CommandInfo(value,true));
              return;
            }
          }
 catch (          Throwable t) {
            Log.e(""String_Node_Str"",""String_Node_Str"",t);
            addToCmdLog(new CommandInfo(value,true,t));
            return;
          }
        }
      }
      Log.w(""String_Node_Str"",""String_Node_Str"" + value);
      addToCmdLog(new CommandInfo(value,false));
    }
  finally {
      mServerConnection.updateState(name,""String_Node_Str"");
    }
  }
}"
37553,"public void updateFromPreferences(SharedPreferences prefs){
  mCmdItemName=prefs.getString(""String_Node_Str"",""String_Node_Str"");
  mCmdLog.setSize(prefs.getInt(""String_Node_Str"",100));
  if (mServerConnection.subscribeItems(this,false,mCmdItemName)) {
    mServerConnection.updateState(mCmdItemName,""String_Node_Str"");
  }
}","public void updateFromPreferences(final SharedPreferences prefs){
  mCmdItemName=prefs.getString(""String_Node_Str"",""String_Node_Str"");
  mCtx.runOnUiThread(new Runnable(){
    @Override public void run(){
      mCmdLog.setSize(prefs.getInt(""String_Node_Str"",100));
    }
  }
);
  if (mServerConnection.subscribeItems(this,false,mCmdItemName)) {
    mServerConnection.updateState(mCmdItemName,""String_Node_Str"");
  }
}"
37554,"public void add(CommandInfo commandInfo){
synchronized (mCommands) {
    mCommands.add(commandInfo);
  }
}","public void add(CommandInfo commandInfo){
synchronized (mCommands) {
    if (mCommands.isEmpty()) {
      mCommands.add(commandInfo);
    }
 else {
      mCommands.add(0,commandInfo);
    }
  }
  if (mCommands.size() > mSize) {
    mCommands.remove(mSize);
  }
  notifyListeners();
}"
37555,"public void trim(){
synchronized (mCommands) {
    while (mCommands.size() > mSize) {
      mCommands.remove(0);
    }
  }
}","private void trim(){
synchronized (mCommands) {
    while (mCommands.size() > mSize) {
      mCommands.remove(mSize);
    }
  }
  notifyListeners();
}"
37556,"@Override public void run(){
  if (adapter != null) {
    adapter.notifyDataSetChanged();
  }
}","@Override public void run(){
  notifyDataSetChanged();
}"
37557,"private void installAdapter(CommandLog cmdLog){
  final ListView listView=findViewById(R.id.command_log_listview);
  adapter=new CommandInfoAdapter(this,cmdLog.getCommands());
  listView.setAdapter(adapter);
}","private void installAdapter(CommandLog cmdLog){
  final ListView listView=findViewById(R.id.command_log_listview);
  adapter=new CommandInfoAdapter(this,cmdLog.getCommands());
  cmdLog.addListener(adapter);
  listView.setAdapter(adapter);
}"
37558,"/** 
 * This method checks the replace functions. The following scenarios are checked: <ol> <li>The functions do not throw an exception when invoked using sample values <li> <li>The function is null-safe if null strategy is not skip-when-null</li> </ol>
 */
@SuppressWarnings(""String_Node_Str"") private void checkReplaceFunctions(){
  Set<Transformation> mappings=mapper.getMapping().getMappings();
  mappings.stream().filter(t -> {
    return (t instanceof ReplaceTransformation);
  }
).map(t -> {
    return (ReplaceTransformation)t;
  }
).forEach(r -> {
    Transform<?,?> transformation=r.getTransformation();
    if (!r.isSkipWhenNull()) {
      try {
        transformation.transform(null);
      }
 catch (      NullPointerException t) {
        throw new AssertionError(NOT_NULL_SAFE + r.toString(),t);
      }
catch (      Throwable t) {
        throw new AssertionError(UNEXPECTED_EXCEPTION + r.toString(),t);
      }
    }
  }
);
}","/** 
 * This method checks the replace functions. The following scenarios are checked: <ol> <li>The functions do not throw an exception when invoked using sample values <li> <li>The function is null-safe if null strategy is not skip-when-null</li> </ol>
 */
@SuppressWarnings(""String_Node_Str"") private void checkReplaceFunctions(){
  Set<Transformation> mappings=mapper.getMapping().getMappings();
  mappings.stream().filter(t -> {
    return (t instanceof SkipWhenNullTransformation);
  }
).map(t -> {
    return (SkipWhenNullTransformation)t;
  }
).forEach(r -> {
    Transform<?,?> transformation=r.getTransformation();
    if (!r.isSkipWhenNull()) {
      try {
        transformation.transform(null);
      }
 catch (      NullPointerException t) {
        throw new AssertionError(NOT_NULL_SAFE + r.toString(),t);
      }
catch (      Throwable t) {
        throw new AssertionError(UNEXPECTED_EXCEPTION + r.toString(),t);
      }
    }
  }
);
}"
37559,"/** 
 * This method checks that the expected replace transformations and the actual replace transformations have equal null strategies.
 */
@SuppressWarnings(""String_Node_Str"") private void checkReplaceTransformations(){
  Set<Transformation> mappings=mapper.getMapping().getMappings();
  mappings.stream().filter(t -> {
    return (t instanceof ReplaceTransformation);
  }
).map(t -> {
    return (ReplaceTransformation)t;
  }
).forEach(replace -> {
    Optional<ReplaceTransformation> sameTransformation=assertedTransformations().stream().filter(t -> {
      return (t instanceof ReplaceTransformation);
    }
).map(t -> {
      return (ReplaceTransformation)t;
    }
).filter(r -> {
      return r.getSourceProperty().equals(replace.getSourceProperty());
    }
).filter(r -> {
      return r.getDestinationProperty().equals(replace.getDestinationProperty());
    }
).findFirst();
    if (sameTransformation.isPresent()) {
      ReplaceTransformation assertedReplaceTransformation=sameTransformation.get();
      if (replace.isSkipWhenNull() != assertedReplaceTransformation.isSkipWhenNull()) {
        throw new AssertionError(DIFFERENT_NULL_STRATEGY + replace.toString() + ""String_Node_Str""+ assertedTransformations.toString());
      }
    }
  }
);
}","/** 
 * This method checks that the expected replace transformations and the actual replace transformations have equal null strategies.
 */
@SuppressWarnings(""String_Node_Str"") private void checkReplaceTransformations(){
  Set<Transformation> mappings=mapper.getMapping().getMappings();
  mappings.stream().filter(t -> {
    return (t instanceof SkipWhenNullTransformation);
  }
).map(t -> {
    return (SkipWhenNullTransformation)t;
  }
).forEach(replace -> {
    Optional<SkipWhenNullTransformation> sameTransformation=assertedTransformations().stream().filter(t -> {
      return (t instanceof SkipWhenNullTransformation);
    }
).map(t -> {
      return (SkipWhenNullTransformation)t;
    }
).filter(r -> {
      return r.getSourceProperty().equals(replace.getSourceProperty());
    }
).filter(r -> {
      return r.getDestinationProperty().equals(replace.getDestinationProperty());
    }
).findFirst();
    if (sameTransformation.isPresent()) {
      SkipWhenNullTransformation assertedReplaceTransformation=sameTransformation.get();
      if (replace.isSkipWhenNull() != assertedReplaceTransformation.isSkipWhenNull()) {
        throw new AssertionError(DIFFERENT_NULL_STRATEGY + replace.toString() + ""String_Node_Str""+ assertedTransformations.toString());
      }
    }
  }
);
}"
37560,"/** 
 * Specifies the transformation function that will be checked against null input.
 * @param transformation The transformation to test.
 * @return Returns the {@link AssertMapping} for further configuration.
 */
public AssertMapping<S,D> andTest(Transform<RS,RD> transformation){
  denyNull(""String_Node_Str"",transformation);
  ReplaceTransformation<RS,RD> replace=new ReplaceTransformation<>(asserts.getMapping(),sourceProperty.property,destProperty.property,transformation,false);
  asserts.addAssertion(replace);
  return asserts;
}","/** 
 * Specifies the transformation function that will be checked against null input.
 * @param transformation The transformation to test.
 * @return Returns the {@link AssertMapping} for further configuration.
 */
public AssertMapping<S,D> andTest(Transform<RS,RD> transformation){
  denyNull(""String_Node_Str"",transformation);
  ReplaceCollectionTransformation<RS,RD> replace=new ReplaceCollectionTransformation<>(asserts.getMapping(),sourceProperty.property,destProperty.property,transformation,false);
  asserts.addAssertion(replace);
  return asserts;
}"
37561,"/** 
 * Transforms the items in the collection held by the selected field by applying the specified transform function on each item. <b>Note: The transform function must check the value for <code>null</code> itself. Use   {@link #withSkipWhenNull(Transform)} to skip on <code>null</code> items.</b>
 * @param transformation The transform function.
 * @return Returns the {@link Mapping} for further mapping configuration.
 */
public Mapping<S,D> with(Transform<RS,RD> transformation){
  denyNull(""String_Node_Str"",transformation);
  ReplaceTransformation<RS,RD> replace=new ReplaceTransformation<>(mapping,sourceProperty.property,destProperty.property,transformation,false);
  mapping.addMapping(sourceProperty.property,destProperty.property,replace);
  return mapping;
}","/** 
 * Transforms the items in the collection held by the selected field by applying the specified transform function on each item. <b>Note: The transform function must check the value for <code>null</code> itself. Use   {@link #withSkipWhenNull(Transform)} to skip on <code>null</code> items.</b>
 * @param transformation The transform function.
 * @return Returns the {@link Mapping} for further mapping configuration.
 */
public Mapping<S,D> with(Transform<RS,RD> transformation){
  denyNull(""String_Node_Str"",transformation);
  ReplaceCollectionTransformation<RS,RD> replace=new ReplaceCollectionTransformation<>(mapping,sourceProperty.property,destProperty.property,transformation,false);
  mapping.addMapping(sourceProperty.property,destProperty.property,replace);
  return mapping;
}"
37562,"/** 
 * Transforms the items in the collection held by the selected field by applying the specified transform function on each item if the item is not <code>null</code>. <b>This method skips the execution of the transform function if the source value is <code>null</code>.</b>
 * @param transformation The transform function.
 * @return Returns the {@link Mapping} for further mapping configuration.
 */
public Mapping<S,D> withSkipWhenNull(Transform<RS,RD> transformation){
  denyNull(""String_Node_Str"",transformation);
  ReplaceTransformation<RS,RD> replace=new ReplaceTransformation<>(mapping,sourceProperty.property,destProperty.property,transformation,true);
  mapping.addMapping(sourceProperty.property,destProperty.property,replace);
  return mapping;
}","/** 
 * Transforms the items in the collection held by the selected field by applying the specified transform function on each item if the item is not <code>null</code>. <b>This method skips the execution of the transform function if the source value is <code>null</code>.</b>
 * @param transformation The transform function.
 * @return Returns the {@link Mapping} for further mapping configuration.
 */
public Mapping<S,D> withSkipWhenNull(Transform<RS,RD> transformation){
  denyNull(""String_Node_Str"",transformation);
  ReplaceCollectionTransformation<RS,RD> replace=new ReplaceCollectionTransformation<>(mapping,sourceProperty.property,destProperty.property,transformation,true);
  mapping.addMapping(sourceProperty.property,destProperty.property,replace);
  return mapping;
}"
37563,"@Override @SuppressWarnings({""String_Node_Str"",""String_Node_Str""}) protected void performTransformation(PropertyDescriptor sourceProperty,Object source,PropertyDescriptor destinationProperty,Object destination) throws MappingException {
  Object sourceValue=readOrFail(sourceProperty,source);
  if (isCollection(sourceProperty.getPropertyType())) {
    if (sourceValue == null) {
      return;
    }
 else {
      Collection collection=(Collection)sourceValue;
      Collection<RD> destinationValue=null;
      if (skipWhenNull) {
        destinationValue=(Collection<RD>)collection.stream().filter(i -> (i != null)).map(sourceItem -> transformation.transform((RS)sourceItem)).collect(getCollector(collection));
      }
 else {
        destinationValue=(Collection<RD>)collection.stream().map(sourceItem -> transformation.transform((RS)sourceItem)).collect(getCollector(collection));
      }
      writeOrFail(destinationProperty,destination,destinationValue);
    }
  }
 else {
    if (sourceValue == null && skipWhenNull) {
      return;
    }
    RD destinationValue=transformation.transform((RS)sourceValue);
    writeOrFail(destinationProperty,destination,destinationValue);
  }
}","@Override @SuppressWarnings({""String_Node_Str""}) protected void performTransformation(PropertyDescriptor sourceProperty,Object source,PropertyDescriptor destinationProperty,Object destination) throws MappingException {
  Object sourceValue=readOrFail(sourceProperty,source);
  if (sourceValue == null && skipWhenNull) {
    return;
  }
  RD destinationValue=transformation.transform((RS)sourceValue);
  writeOrFail(destinationProperty,destination,destinationValue);
}"
37564,"Transform<RS,RD> getTransformation(){
  return transformation;
}","@Override Transform<RS,RD> getTransformation(){
  return transformation;
}"
37565,"boolean isSkipWhenNull(){
  return skipWhenNull;
}","@Override boolean isSkipWhenNull(){
  return skipWhenNull;
}"
37566,"@Test public void shouldSkipNullItems(){
  Mapper<Source,Destination> mapper=Mapping.from(Source.class).to(Destination.class).replaceCollection(Source::getIds,Destination::getIds).withSkipWhenNull(idBuilder()).mapper();
  Source source=Source.builder().ids(Arrays.asList(1L,null,2L,null,3L)).build();
  Destination map=mapper.map(source);
  List<Id> expected=Arrays.asList(idBuilder().transform(1L),idBuilder().transform(2L),idBuilder().transform(3L));
  List<Id> actual=map.getIds();
  assertEquals(expected,actual);
  AssertMapping.of(mapper).expectReplaceCollection(Source::getIds,Destination::getIds).andTestButSkipWhenNull(idBuilder()).ensure();
}","@Test public void shouldSkipNullItems(){
  Mapper<Source,Destination> mapper=Mapping.from(Source.class).to(Destination.class).replaceCollection(Source::getIds,Destination::getIds).withSkipWhenNull(idBuilder()).mapper();
  Source source=Source.builder().ids(Arrays.asList(1L,null,2L,null,3L)).build();
  Destination map=mapper.map(source);
  List<Id> expected=Arrays.asList(idBuilder().transform(1L),idBuilder().transform(2L),idBuilder().transform(3L));
  List<Id> actual=map.getIds();
  assertEquals(expected,actual);
  AssertMapping.of(mapper).expectReplaceCollection(Source::getIds,Destination::getIds).andSkipWhenNull().ensure();
}"
37567,"@Test public void shouldDetectDifferentNullStrategy(){
  Mapper<Source,Destination> mapper=Mapping.from(Source.class).to(Destination.class).replaceCollection(Source::getIds,Destination::getIds).with(idBuilder()).mapper();
  assertThatThrownBy(() -> {
    AssertMapping.of(mapper).expectReplaceCollection(Source::getIds,Destination::getIds).andTestButSkipWhenNull(idBuilder()).ensure();
  }
).isInstanceOf(AssertionError.class).hasMessageContaining(DIFFERENT_NULL_STRATEGY).hasNoCause();
}","@Test public void shouldDetectDifferentNullStrategy(){
  Mapper<Source,Destination> mapper=Mapping.from(Source.class).to(Destination.class).replaceCollection(Source::getIds,Destination::getIds).with(idBuilder()).mapper();
  assertThatThrownBy(() -> {
    AssertMapping.of(mapper).expectReplaceCollection(Source::getIds,Destination::getIds).andSkipWhenNull().ensure();
  }
).isInstanceOf(AssertionError.class).hasMessageContaining(DIFFERENT_NULL_STRATEGY).hasNoCause();
}"
37568,"static boolean isBool(Class<?> type){
  return type == Boolean.TYPE || type == Boolean.class;
}","static boolean isBool(Class<?> type){
  return type == Boolean.TYPE;
}"
37569,"/** 
 * Sends the HTTP request
 * @param request           the request description
 * @param resultClass       the class of the response from the service
 * @param serializable      the object to send to the service in the body of the request
 * @param progress          the progress callback for the request
 * @param handler           the handler for stateful response
 * @param < Result >          the type of the response object
 * @param < Body >            the type of the object to send to the service in the body of the request
 * @param < DeserializeType > the response handler for stateful response
 * @return                  the result from the request
 * @throws ClientException an exception occurs if the request was unable to complete for any reason
 */
@SuppressWarnings(""String_Node_Str"") private <Result,Body,DeserializeType>Result sendRequestInternal(final IHttpRequest request,final Class<Result> resultClass,final Body serializable,final IProgressCallback<Result> progress,final IStatefulResponseHandler<Result,DeserializeType> handler) throws ClientException {
  final int defaultBufferSize=4096;
  final String binaryContentType=""String_Node_Str"";
  try {
    if (authenticationProvider != null) {
      authenticationProvider.authenticateRequest(request);
    }
    OutputStream out=null;
    InputStream in=null;
    boolean isBinaryStreamInput=false;
    final URL requestUrl=request.getRequestUrl();
    logger.logDebug(""String_Node_Str"" + requestUrl.toString());
    final IConnection connection=connectionFactory.createFromRequest(request);
    try {
      logger.logDebug(""String_Node_Str"" + request.getHttpMethod().toString());
      List<HeaderOption> requestHeaders=request.getHeaders();
      final byte[] bytesToWrite;
      connection.addRequestHeader(""String_Node_Str"",""String_Node_Str"");
      if (serializable == null) {
        if (request.getHttpMethod() == HttpMethod.POST) {
          bytesToWrite=new byte[0];
        }
 else {
          bytesToWrite=null;
        }
      }
 else       if (serializable instanceof byte[]) {
        logger.logDebug(""String_Node_Str"");
        bytesToWrite=(byte[])serializable;
        if (!hasHeader(requestHeaders,CONTENT_TYPE_HEADER_NAME)) {
          connection.addRequestHeader(CONTENT_TYPE_HEADER_NAME,binaryContentType);
        }
        connection.setContentLength(bytesToWrite.length);
      }
 else {
        logger.logDebug(""String_Node_Str"" + serializable.getClass().getName() + ""String_Node_Str"");
        final String serializeObject=serializer.serializeObject(serializable);
        bytesToWrite=serializeObject.getBytes();
        if (!hasHeader(requestHeaders,CONTENT_TYPE_HEADER_NAME)) {
          connection.addRequestHeader(CONTENT_TYPE_HEADER_NAME,JSON_CONTENT_TYPE);
        }
        connection.setContentLength(bytesToWrite.length);
      }
      if (bytesToWrite != null) {
        out=connection.getOutputStream();
        int writtenSoFar=0;
        BufferedOutputStream bos=new BufferedOutputStream(out);
        int toWrite;
        do {
          toWrite=Math.min(defaultBufferSize,bytesToWrite.length - writtenSoFar);
          bos.write(bytesToWrite,writtenSoFar,toWrite);
          writtenSoFar=writtenSoFar + toWrite;
          if (progress != null) {
            executors.performOnForeground(writtenSoFar,bytesToWrite.length,progress);
          }
        }
 while (toWrite > 0);
        bos.close();
      }
      if (handler != null) {
        handler.configConnection(connection);
      }
      logger.logDebug(String.format(""String_Node_Str"",connection.getResponseCode(),connection.getResponseMessage()));
      if (handler != null) {
        logger.logDebug(""String_Node_Str"");
        return handler.generateResult(request,connection,this.getSerializer(),this.logger);
      }
      if (connection.getResponseCode() >= HttpResponseCode.HTTP_CLIENT_ERROR) {
        logger.logDebug(""String_Node_Str"");
        in=connection.getInputStream();
        handleErrorResponse(request,serializable,connection);
      }
      if (connection.getResponseCode() == HttpResponseCode.HTTP_NOBODY || connection.getResponseCode() == HttpResponseCode.HTTP_NOT_MODIFIED) {
        logger.logDebug(""String_Node_Str"");
        return handleEmptyResponse(connection.getResponseHeaders(),resultClass);
      }
      if (connection.getResponseCode() == HttpResponseCode.HTTP_ACCEPTED) {
        logger.logDebug(""String_Node_Str"");
        return handleEmptyResponse(connection.getResponseHeaders(),resultClass);
      }
      in=new BufferedInputStream(connection.getInputStream());
      final Map<String,String> headers=connection.getHeaders();
      final String contentType=headers.get(CONTENT_TYPE_HEADER_NAME);
      if (contentType.contains(JSON_CONTENT_TYPE)) {
        logger.logDebug(""String_Node_Str"");
        return handleJsonResponse(in,connection.getResponseHeaders(),resultClass);
      }
 else {
        logger.logDebug(""String_Node_Str"");
        isBinaryStreamInput=true;
        return (Result)handleBinaryStream(in);
      }
    }
  finally {
      if (out != null) {
        out.close();
      }
      if (!isBinaryStreamInput && in != null) {
        in.close();
        connection.close();
      }
    }
  }
 catch (  final GraphServiceException ex) {
    final boolean shouldLogVerbosely=logger.getLoggingLevel() == LoggerLevel.DEBUG;
    logger.logError(""String_Node_Str"" + ex.getMessage(shouldLogVerbosely),ex);
    throw ex;
  }
catch (  final Exception ex) {
    final ClientException clientException=new ClientException(""String_Node_Str"",ex);
    logger.logError(""String_Node_Str"",clientException);
    throw clientException;
  }
}","/** 
 * Sends the HTTP request
 * @param request           the request description
 * @param resultClass       the class of the response from the service
 * @param serializable      the object to send to the service in the body of the request
 * @param progress          the progress callback for the request
 * @param handler           the handler for stateful response
 * @param < Result >          the type of the response object
 * @param < Body >            the type of the object to send to the service in the body of the request
 * @param < DeserializeType > the response handler for stateful response
 * @return                  the result from the request
 * @throws ClientException an exception occurs if the request was unable to complete for any reason
 */
@SuppressWarnings(""String_Node_Str"") private <Result,Body,DeserializeType>Result sendRequestInternal(final IHttpRequest request,final Class<Result> resultClass,final Body serializable,final IProgressCallback<Result> progress,final IStatefulResponseHandler<Result,DeserializeType> handler) throws ClientException {
  final int defaultBufferSize=4096;
  final String binaryContentType=""String_Node_Str"";
  try {
    if (authenticationProvider != null) {
      authenticationProvider.authenticateRequest(request);
    }
    OutputStream out=null;
    InputStream in=null;
    boolean isBinaryStreamInput=false;
    final URL requestUrl=request.getRequestUrl();
    logger.logDebug(""String_Node_Str"" + requestUrl.toString());
    final IConnection connection=connectionFactory.createFromRequest(request);
    try {
      logger.logDebug(""String_Node_Str"" + request.getHttpMethod().toString());
      List<HeaderOption> requestHeaders=request.getHeaders();
      final byte[] bytesToWrite;
      connection.addRequestHeader(""String_Node_Str"",""String_Node_Str"");
      if (serializable == null) {
        if (request.getHttpMethod() == HttpMethod.POST) {
          bytesToWrite=new byte[0];
        }
 else {
          bytesToWrite=null;
        }
      }
 else       if (serializable instanceof byte[]) {
        logger.logDebug(""String_Node_Str"");
        bytesToWrite=(byte[])serializable;
        if (!hasHeader(requestHeaders,CONTENT_TYPE_HEADER_NAME)) {
          connection.addRequestHeader(CONTENT_TYPE_HEADER_NAME,binaryContentType);
        }
        connection.setContentLength(bytesToWrite.length);
      }
 else {
        logger.logDebug(""String_Node_Str"" + serializable.getClass().getName() + ""String_Node_Str"");
        final String serializeObject=serializer.serializeObject(serializable);
        bytesToWrite=serializeObject.getBytes(JSON_ENCODING);
        if (!hasHeader(requestHeaders,CONTENT_TYPE_HEADER_NAME)) {
          connection.addRequestHeader(CONTENT_TYPE_HEADER_NAME,JSON_CONTENT_TYPE);
        }
        connection.setContentLength(bytesToWrite.length);
      }
      if (bytesToWrite != null) {
        out=connection.getOutputStream();
        int writtenSoFar=0;
        BufferedOutputStream bos=new BufferedOutputStream(out);
        int toWrite;
        do {
          toWrite=Math.min(defaultBufferSize,bytesToWrite.length - writtenSoFar);
          bos.write(bytesToWrite,writtenSoFar,toWrite);
          writtenSoFar=writtenSoFar + toWrite;
          if (progress != null) {
            executors.performOnForeground(writtenSoFar,bytesToWrite.length,progress);
          }
        }
 while (toWrite > 0);
        bos.close();
      }
      if (handler != null) {
        handler.configConnection(connection);
      }
      logger.logDebug(String.format(""String_Node_Str"",connection.getResponseCode(),connection.getResponseMessage()));
      if (handler != null) {
        logger.logDebug(""String_Node_Str"");
        return handler.generateResult(request,connection,this.getSerializer(),this.logger);
      }
      if (connection.getResponseCode() >= HttpResponseCode.HTTP_CLIENT_ERROR) {
        logger.logDebug(""String_Node_Str"");
        in=connection.getInputStream();
        handleErrorResponse(request,serializable,connection);
      }
      if (connection.getResponseCode() == HttpResponseCode.HTTP_NOBODY || connection.getResponseCode() == HttpResponseCode.HTTP_NOT_MODIFIED) {
        logger.logDebug(""String_Node_Str"");
        return handleEmptyResponse(connection.getResponseHeaders(),resultClass);
      }
      if (connection.getResponseCode() == HttpResponseCode.HTTP_ACCEPTED) {
        logger.logDebug(""String_Node_Str"");
        return handleEmptyResponse(connection.getResponseHeaders(),resultClass);
      }
      in=new BufferedInputStream(connection.getInputStream());
      final Map<String,String> headers=connection.getHeaders();
      final String contentType=headers.get(CONTENT_TYPE_HEADER_NAME);
      if (contentType.contains(JSON_CONTENT_TYPE)) {
        logger.logDebug(""String_Node_Str"");
        return handleJsonResponse(in,connection.getResponseHeaders(),resultClass);
      }
 else {
        logger.logDebug(""String_Node_Str"");
        isBinaryStreamInput=true;
        return (Result)handleBinaryStream(in);
      }
    }
  finally {
      if (out != null) {
        out.close();
      }
      if (!isBinaryStreamInput && in != null) {
        in.close();
        connection.close();
      }
    }
  }
 catch (  final GraphServiceException ex) {
    final boolean shouldLogVerbosely=logger.getLoggingLevel() == LoggerLevel.DEBUG;
    logger.logError(""String_Node_Str"" + ex.getMessage(shouldLogVerbosely),ex);
    throw ex;
  }
catch (  final UnsupportedEncodingException ex) {
    final ClientException clientException=new ClientException(""String_Node_Str"",ex);
    logger.logError(""String_Node_Str"" + ex.getMessage(),ex);
    throw clientException;
  }
catch (  final Exception ex) {
    final ClientException clientException=new ClientException(""String_Node_Str"",ex);
    logger.logError(""String_Node_Str"",clientException);
    throw clientException;
  }
}"
37570,"/** 
 * Handles the case where the response body is empty
 * @param responseHeaders the response headers
 * @param clazz           the type of the response object
 * @return                the JSON object
 */
private <Result>Result handleEmptyResponse(Map<String,List<String>> responseHeaders,final Class<Result> clazz){
  InputStream in=new ByteArrayInputStream(""String_Node_Str"".getBytes());
  return handleJsonResponse(in,responseHeaders,clazz);
}","/** 
 * Handles the case where the response body is empty
 * @param responseHeaders the response headers
 * @param clazz           the type of the response object
 * @return                the JSON object
 */
private <Result>Result handleEmptyResponse(Map<String,List<String>> responseHeaders,final Class<Result> clazz) throws UnsupportedEncodingException {
  InputStream in=new ByteArrayInputStream(""String_Node_Str"".getBytes(JSON_ENCODING));
  return handleJsonResponse(in,responseHeaders,clazz);
}"
37571,"/** 
 * Sends the HTTP request
 * @param request           the request description
 * @param resultClass       the class of the response from the service
 * @param serializable      the object to send to the service in the body of the request
 * @param progress          the progress callback for the request
 * @param handler           the handler for stateful response
 * @param < Result >          the type of the response object
 * @param < Body >            the type of the object to send to the service in the body of the request
 * @param < DeserializeType > the response handler for stateful response
 * @return                  the result from the request
 * @throws ClientException an exception occurs if the request was unable to complete for any reason
 */
@SuppressWarnings(""String_Node_Str"") private <Result,Body,DeserializeType>Result sendRequestInternal(final IHttpRequest request,final Class<Result> resultClass,final Body serializable,final IProgressCallback<Result> progress,final IStatefulResponseHandler<Result,DeserializeType> handler) throws ClientException {
  final int defaultBufferSize=4096;
  final String binaryContentType=""String_Node_Str"";
  try {
    if (authenticationProvider != null) {
      authenticationProvider.authenticateRequest(request);
    }
    OutputStream out=null;
    InputStream in=null;
    boolean isBinaryStreamInput=false;
    final URL requestUrl=request.getRequestUrl();
    logger.logDebug(""String_Node_Str"" + requestUrl.toString());
    final IConnection connection=connectionFactory.createFromRequest(request);
    try {
      logger.logDebug(""String_Node_Str"" + request.getHttpMethod().toString());
      List<HeaderOption> requestHeaders=request.getHeaders();
      final byte[] bytesToWrite;
      connection.addRequestHeader(""String_Node_Str"",""String_Node_Str"");
      if (serializable == null) {
        if (request.getHttpMethod() == HttpMethod.POST) {
          bytesToWrite=new byte[0];
        }
 else {
          bytesToWrite=null;
        }
      }
 else       if (serializable instanceof byte[]) {
        logger.logDebug(""String_Node_Str"");
        bytesToWrite=(byte[])serializable;
        if (!hasHeader(requestHeaders,CONTENT_TYPE_HEADER_NAME)) {
          connection.addRequestHeader(CONTENT_TYPE_HEADER_NAME,binaryContentType);
        }
        connection.setContentLength(bytesToWrite.length);
      }
 else {
        logger.logDebug(""String_Node_Str"" + serializable.getClass().getName() + ""String_Node_Str"");
        final String serializeObject=serializer.serializeObject(serializable);
        bytesToWrite=serializeObject.getBytes(""String_Node_Str"");
        if (!hasHeader(requestHeaders,CONTENT_TYPE_HEADER_NAME)) {
          connection.addRequestHeader(CONTENT_TYPE_HEADER_NAME,JSON_CONTENT_TYPE);
        }
        connection.setContentLength(bytesToWrite.length);
      }
      if (bytesToWrite != null) {
        out=connection.getOutputStream();
        int writtenSoFar=0;
        BufferedOutputStream bos=new BufferedOutputStream(out);
        int toWrite;
        do {
          toWrite=Math.min(defaultBufferSize,bytesToWrite.length - writtenSoFar);
          bos.write(bytesToWrite,writtenSoFar,toWrite);
          writtenSoFar=writtenSoFar + toWrite;
          if (progress != null) {
            executors.performOnForeground(writtenSoFar,bytesToWrite.length,progress);
          }
        }
 while (toWrite > 0);
        bos.close();
      }
      if (handler != null) {
        handler.configConnection(connection);
      }
      logger.logDebug(String.format(""String_Node_Str"",connection.getResponseCode(),connection.getResponseMessage()));
      if (handler != null) {
        logger.logDebug(""String_Node_Str"");
        return handler.generateResult(request,connection,this.getSerializer(),this.logger);
      }
      if (connection.getResponseCode() >= HttpResponseCode.HTTP_CLIENT_ERROR) {
        logger.logDebug(""String_Node_Str"");
        in=connection.getInputStream();
        handleErrorResponse(request,serializable,connection);
      }
      if (connection.getResponseCode() == HttpResponseCode.HTTP_NOBODY || connection.getResponseCode() == HttpResponseCode.HTTP_NOT_MODIFIED) {
        logger.logDebug(""String_Node_Str"");
        return handleEmptyResponse(connection.getResponseHeaders(),resultClass);
      }
      if (connection.getResponseCode() == HttpResponseCode.HTTP_ACCEPTED) {
        logger.logDebug(""String_Node_Str"");
        return handleEmptyResponse(connection.getResponseHeaders(),resultClass);
      }
      in=new BufferedInputStream(connection.getInputStream());
      final Map<String,String> headers=connection.getHeaders();
      final String contentType=headers.get(CONTENT_TYPE_HEADER_NAME);
      if (contentType.contains(JSON_CONTENT_TYPE)) {
        logger.logDebug(""String_Node_Str"");
        return handleJsonResponse(in,connection.getResponseHeaders(),resultClass);
      }
 else {
        logger.logDebug(""String_Node_Str"");
        isBinaryStreamInput=true;
        return (Result)handleBinaryStream(in);
      }
    }
  finally {
      if (out != null) {
        out.close();
      }
      if (!isBinaryStreamInput && in != null) {
        in.close();
        connection.close();
      }
    }
  }
 catch (  final GraphServiceException ex) {
    final boolean shouldLogVerbosely=logger.getLoggingLevel() == LoggerLevel.DEBUG;
    logger.logError(""String_Node_Str"" + ex.getMessage(shouldLogVerbosely),ex);
    throw ex;
  }
catch (  final Exception ex) {
    final ClientException clientException=new ClientException(""String_Node_Str"",ex);
    logger.logError(""String_Node_Str"",clientException);
    throw clientException;
  }
}","/** 
 * Sends the HTTP request
 * @param request           the request description
 * @param resultClass       the class of the response from the service
 * @param serializable      the object to send to the service in the body of the request
 * @param progress          the progress callback for the request
 * @param handler           the handler for stateful response
 * @param < Result >          the type of the response object
 * @param < Body >            the type of the object to send to the service in the body of the request
 * @param < DeserializeType > the response handler for stateful response
 * @return                  the result from the request
 * @throws ClientException an exception occurs if the request was unable to complete for any reason
 */
@SuppressWarnings(""String_Node_Str"") private <Result,Body,DeserializeType>Result sendRequestInternal(final IHttpRequest request,final Class<Result> resultClass,final Body serializable,final IProgressCallback<Result> progress,final IStatefulResponseHandler<Result,DeserializeType> handler) throws ClientException {
  final int defaultBufferSize=4096;
  final String binaryContentType=""String_Node_Str"";
  try {
    if (authenticationProvider != null) {
      authenticationProvider.authenticateRequest(request);
    }
    OutputStream out=null;
    InputStream in=null;
    boolean isBinaryStreamInput=false;
    final URL requestUrl=request.getRequestUrl();
    logger.logDebug(""String_Node_Str"" + requestUrl.toString());
    final IConnection connection=connectionFactory.createFromRequest(request);
    try {
      logger.logDebug(""String_Node_Str"" + request.getHttpMethod().toString());
      List<HeaderOption> requestHeaders=request.getHeaders();
      final byte[] bytesToWrite;
      connection.addRequestHeader(""String_Node_Str"",""String_Node_Str"");
      if (serializable == null) {
        if (request.getHttpMethod() == HttpMethod.POST) {
          bytesToWrite=new byte[0];
        }
 else {
          bytesToWrite=null;
        }
      }
 else       if (serializable instanceof byte[]) {
        logger.logDebug(""String_Node_Str"");
        bytesToWrite=(byte[])serializable;
        if (!hasHeader(requestHeaders,CONTENT_TYPE_HEADER_NAME)) {
          connection.addRequestHeader(CONTENT_TYPE_HEADER_NAME,binaryContentType);
        }
        connection.setContentLength(bytesToWrite.length);
      }
 else {
        logger.logDebug(""String_Node_Str"" + serializable.getClass().getName() + ""String_Node_Str"");
        final String serializeObject=serializer.serializeObject(serializable);
        bytesToWrite=serializeObject.getBytes(ENCODING_TYPE);
        if (!hasHeader(requestHeaders,CONTENT_TYPE_HEADER_NAME)) {
          connection.addRequestHeader(CONTENT_TYPE_HEADER_NAME,JSON_CONTENT_TYPE);
        }
        connection.setContentLength(bytesToWrite.length);
      }
      if (bytesToWrite != null) {
        out=connection.getOutputStream();
        int writtenSoFar=0;
        BufferedOutputStream bos=new BufferedOutputStream(out);
        int toWrite;
        do {
          toWrite=Math.min(defaultBufferSize,bytesToWrite.length - writtenSoFar);
          bos.write(bytesToWrite,writtenSoFar,toWrite);
          writtenSoFar=writtenSoFar + toWrite;
          if (progress != null) {
            executors.performOnForeground(writtenSoFar,bytesToWrite.length,progress);
          }
        }
 while (toWrite > 0);
        bos.close();
      }
      if (handler != null) {
        handler.configConnection(connection);
      }
      logger.logDebug(String.format(""String_Node_Str"",connection.getResponseCode(),connection.getResponseMessage()));
      if (handler != null) {
        logger.logDebug(""String_Node_Str"");
        return handler.generateResult(request,connection,this.getSerializer(),this.logger);
      }
      if (connection.getResponseCode() >= HttpResponseCode.HTTP_CLIENT_ERROR) {
        logger.logDebug(""String_Node_Str"");
        in=connection.getInputStream();
        handleErrorResponse(request,serializable,connection);
      }
      if (connection.getResponseCode() == HttpResponseCode.HTTP_NOBODY || connection.getResponseCode() == HttpResponseCode.HTTP_NOT_MODIFIED) {
        logger.logDebug(""String_Node_Str"");
        return handleEmptyResponse(connection.getResponseHeaders(),resultClass);
      }
      if (connection.getResponseCode() == HttpResponseCode.HTTP_ACCEPTED) {
        logger.logDebug(""String_Node_Str"");
        return handleEmptyResponse(connection.getResponseHeaders(),resultClass);
      }
      in=new BufferedInputStream(connection.getInputStream());
      final Map<String,String> headers=connection.getHeaders();
      final String contentType=headers.get(CONTENT_TYPE_HEADER_NAME);
      if (contentType.contains(JSON_CONTENT_TYPE)) {
        logger.logDebug(""String_Node_Str"");
        return handleJsonResponse(in,connection.getResponseHeaders(),resultClass);
      }
 else {
        logger.logDebug(""String_Node_Str"");
        isBinaryStreamInput=true;
        return (Result)handleBinaryStream(in);
      }
    }
  finally {
      if (out != null) {
        out.close();
      }
      if (!isBinaryStreamInput && in != null) {
        in.close();
        connection.close();
      }
    }
  }
 catch (  final GraphServiceException ex) {
    final boolean shouldLogVerbosely=logger.getLoggingLevel() == LoggerLevel.DEBUG;
    logger.logError(""String_Node_Str"" + ex.getMessage(shouldLogVerbosely),ex);
    throw ex;
  }
catch (  final Exception ex) {
    final ClientException clientException=new ClientException(""String_Node_Str"",ex);
    logger.logError(""String_Node_Str"",clientException);
    throw clientException;
  }
}"
37572,"/** 
 * Handles the case where the response body is empty
 * @param responseHeaders the response headers
 * @param clazz           the type of the response object
 * @return                the JSON object
 */
private <Result>Result handleEmptyResponse(Map<String,List<String>> responseHeaders,final Class<Result> clazz){
  InputStream in=new ByteArrayInputStream(""String_Node_Str"".getBytes());
  return handleJsonResponse(in,responseHeaders,clazz);
}","/** 
 * Handles the case where the response body is empty
 * @param responseHeaders the response headers
 * @param clazz           the type of the response object
 * @return                the JSON object
 */
private <Result>Result handleEmptyResponse(Map<String,List<String>> responseHeaders,final Class<Result> clazz){
  InputStream in=null;
  try {
    in=new ByteArrayInputStream(""String_Node_Str"".getBytes(ENCODING_TYPE));
  }
 catch (  UnsupportedEncodingException ex) {
    ex.printStackTrace();
  }
  return handleJsonResponse(in,responseHeaders,clazz);
}"
37573,"/** 
 * Sends the HTTP request
 * @param request           the request description
 * @param resultClass       the class of the response from the service
 * @param serializable      the object to send to the service in the body of the request
 * @param progress          the progress callback for the request
 * @param handler           the handler for stateful response
 * @param < Result >          the type of the response object
 * @param < Body >            the type of the object to send to the service in the body of the request
 * @param < DeserializeType > the response handler for stateful response
 * @return                  the result from the request
 * @throws ClientException an exception occurs if the request was unable to complete for any reason
 */
@SuppressWarnings(""String_Node_Str"") private <Result,Body,DeserializeType>Result sendRequestInternal(final IHttpRequest request,final Class<Result> resultClass,final Body serializable,final IProgressCallback<Result> progress,final IStatefulResponseHandler<Result,DeserializeType> handler) throws ClientException {
  final int defaultBufferSize=4096;
  final String binaryContentType=""String_Node_Str"";
  try {
    if (authenticationProvider != null) {
      authenticationProvider.authenticateRequest(request);
    }
    OutputStream out=null;
    InputStream in=null;
    boolean isBinaryStreamInput=false;
    final URL requestUrl=request.getRequestUrl();
    logger.logDebug(""String_Node_Str"" + requestUrl.toString());
    final IConnection connection=connectionFactory.createFromRequest(request);
    try {
      logger.logDebug(""String_Node_Str"" + request.getHttpMethod().toString());
      List<HeaderOption> requestHeaders=request.getHeaders();
      final byte[] bytesToWrite;
      connection.addRequestHeader(""String_Node_Str"",""String_Node_Str"");
      if (serializable == null) {
        if (request.getHttpMethod() == HttpMethod.POST) {
          bytesToWrite=new byte[0];
        }
 else {
          bytesToWrite=null;
        }
      }
 else       if (serializable instanceof byte[]) {
        logger.logDebug(""String_Node_Str"");
        bytesToWrite=(byte[])serializable;
        if (!hasHeader(requestHeaders,CONTENT_TYPE_HEADER_NAME)) {
          connection.addRequestHeader(CONTENT_TYPE_HEADER_NAME,binaryContentType);
        }
        connection.setContentLength(bytesToWrite.length);
      }
 else {
        logger.logDebug(""String_Node_Str"" + serializable.getClass().getName() + ""String_Node_Str"");
        final String serializeObject=serializer.serializeObject(serializable);
        bytesToWrite=serializeObject.getBytes();
        if (!hasHeader(requestHeaders,CONTENT_TYPE_HEADER_NAME)) {
          connection.addRequestHeader(CONTENT_TYPE_HEADER_NAME,JSON_CONTENT_TYPE);
        }
        connection.setContentLength(bytesToWrite.length);
      }
      if (bytesToWrite != null) {
        out=connection.getOutputStream();
        int writtenSoFar=0;
        BufferedOutputStream bos=new BufferedOutputStream(out);
        int toWrite;
        do {
          toWrite=Math.min(defaultBufferSize,bytesToWrite.length - writtenSoFar);
          bos.write(bytesToWrite,writtenSoFar,toWrite);
          writtenSoFar=writtenSoFar + toWrite;
          if (progress != null) {
            executors.performOnForeground(writtenSoFar,bytesToWrite.length,progress);
          }
        }
 while (toWrite > 0);
        bos.close();
      }
      if (handler != null) {
        handler.configConnection(connection);
      }
      logger.logDebug(String.format(""String_Node_Str"",connection.getResponseCode(),connection.getResponseMessage()));
      if (handler != null) {
        logger.logDebug(""String_Node_Str"");
        return handler.generateResult(request,connection,this.getSerializer(),this.logger);
      }
      if (connection.getResponseCode() >= HttpResponseCode.HTTP_CLIENT_ERROR) {
        logger.logDebug(""String_Node_Str"");
        in=connection.getInputStream();
        handleErrorResponse(request,serializable,connection);
      }
      if (connection.getResponseCode() == HttpResponseCode.HTTP_NOBODY || connection.getResponseCode() == HttpResponseCode.HTTP_NOT_MODIFIED) {
        logger.logDebug(""String_Node_Str"");
        return handleEmptyResponse(connection.getResponseHeaders(),resultClass);
      }
      if (connection.getResponseCode() == HttpResponseCode.HTTP_ACCEPTED) {
        logger.logDebug(""String_Node_Str"");
        return handleEmptyResponse(connection.getResponseHeaders(),resultClass);
      }
      in=new BufferedInputStream(connection.getInputStream());
      final Map<String,String> headers=connection.getHeaders();
      final String contentType=headers.get(CONTENT_TYPE_HEADER_NAME);
      if (contentType.contains(JSON_CONTENT_TYPE)) {
        logger.logDebug(""String_Node_Str"");
        return handleJsonResponse(in,connection.getResponseHeaders(),resultClass);
      }
 else {
        logger.logDebug(""String_Node_Str"");
        isBinaryStreamInput=true;
        return (Result)handleBinaryStream(in);
      }
    }
  finally {
      if (out != null) {
        out.close();
      }
      if (!isBinaryStreamInput && in != null) {
        in.close();
        connection.close();
      }
    }
  }
 catch (  final GraphServiceException ex) {
    final boolean shouldLogVerbosely=logger.getLoggingLevel() == LoggerLevel.DEBUG;
    logger.logError(""String_Node_Str"" + ex.getMessage(shouldLogVerbosely),ex);
    throw ex;
  }
catch (  final Exception ex) {
    final ClientException clientException=new ClientException(""String_Node_Str"",ex);
    logger.logError(""String_Node_Str"",clientException);
    throw clientException;
  }
}","/** 
 * Sends the HTTP request
 * @param request           the request description
 * @param resultClass       the class of the response from the service
 * @param serializable      the object to send to the service in the body of the request
 * @param progress          the progress callback for the request
 * @param handler           the handler for stateful response
 * @param < Result >          the type of the response object
 * @param < Body >            the type of the object to send to the service in the body of the request
 * @param < DeserializeType > the response handler for stateful response
 * @return                  the result from the request
 * @throws ClientException an exception occurs if the request was unable to complete for any reason
 */
@SuppressWarnings(""String_Node_Str"") private <Result,Body,DeserializeType>Result sendRequestInternal(final IHttpRequest request,final Class<Result> resultClass,final Body serializable,final IProgressCallback<Result> progress,final IStatefulResponseHandler<Result,DeserializeType> handler) throws ClientException {
  final int defaultBufferSize=4096;
  final String binaryContentType=""String_Node_Str"";
  try {
    if (authenticationProvider != null) {
      authenticationProvider.authenticateRequest(request);
    }
    OutputStream out=null;
    InputStream in=null;
    boolean isBinaryStreamInput=false;
    final URL requestUrl=request.getRequestUrl();
    logger.logDebug(""String_Node_Str"" + requestUrl.toString());
    final IConnection connection=connectionFactory.createFromRequest(request);
    try {
      logger.logDebug(""String_Node_Str"" + request.getHttpMethod().toString());
      List<HeaderOption> requestHeaders=request.getHeaders();
      final byte[] bytesToWrite;
      connection.addRequestHeader(""String_Node_Str"",""String_Node_Str"");
      if (serializable == null) {
        if (request.getHttpMethod() == HttpMethod.POST) {
          bytesToWrite=new byte[0];
        }
 else {
          bytesToWrite=null;
        }
      }
 else       if (serializable instanceof byte[]) {
        logger.logDebug(""String_Node_Str"");
        bytesToWrite=(byte[])serializable;
        if (!hasHeader(requestHeaders,CONTENT_TYPE_HEADER_NAME)) {
          connection.addRequestHeader(CONTENT_TYPE_HEADER_NAME,binaryContentType);
        }
        connection.setContentLength(bytesToWrite.length);
      }
 else {
        logger.logDebug(""String_Node_Str"" + serializable.getClass().getName() + ""String_Node_Str"");
        final String serializeObject=serializer.serializeObject(serializable);
        bytesToWrite=serializeObject.getBytes(""String_Node_Str"");
        if (!hasHeader(requestHeaders,CONTENT_TYPE_HEADER_NAME)) {
          connection.addRequestHeader(CONTENT_TYPE_HEADER_NAME,JSON_CONTENT_TYPE);
        }
        connection.setContentLength(bytesToWrite.length);
      }
      if (bytesToWrite != null) {
        out=connection.getOutputStream();
        int writtenSoFar=0;
        BufferedOutputStream bos=new BufferedOutputStream(out);
        int toWrite;
        do {
          toWrite=Math.min(defaultBufferSize,bytesToWrite.length - writtenSoFar);
          bos.write(bytesToWrite,writtenSoFar,toWrite);
          writtenSoFar=writtenSoFar + toWrite;
          if (progress != null) {
            executors.performOnForeground(writtenSoFar,bytesToWrite.length,progress);
          }
        }
 while (toWrite > 0);
        bos.close();
      }
      if (handler != null) {
        handler.configConnection(connection);
      }
      logger.logDebug(String.format(""String_Node_Str"",connection.getResponseCode(),connection.getResponseMessage()));
      if (handler != null) {
        logger.logDebug(""String_Node_Str"");
        return handler.generateResult(request,connection,this.getSerializer(),this.logger);
      }
      if (connection.getResponseCode() >= HttpResponseCode.HTTP_CLIENT_ERROR) {
        logger.logDebug(""String_Node_Str"");
        in=connection.getInputStream();
        handleErrorResponse(request,serializable,connection);
      }
      if (connection.getResponseCode() == HttpResponseCode.HTTP_NOBODY || connection.getResponseCode() == HttpResponseCode.HTTP_NOT_MODIFIED) {
        logger.logDebug(""String_Node_Str"");
        return handleEmptyResponse(connection.getResponseHeaders(),resultClass);
      }
      if (connection.getResponseCode() == HttpResponseCode.HTTP_ACCEPTED) {
        logger.logDebug(""String_Node_Str"");
        return handleEmptyResponse(connection.getResponseHeaders(),resultClass);
      }
      in=new BufferedInputStream(connection.getInputStream());
      final Map<String,String> headers=connection.getHeaders();
      final String contentType=headers.get(CONTENT_TYPE_HEADER_NAME);
      if (contentType.contains(JSON_CONTENT_TYPE)) {
        logger.logDebug(""String_Node_Str"");
        return handleJsonResponse(in,connection.getResponseHeaders(),resultClass);
      }
 else {
        logger.logDebug(""String_Node_Str"");
        isBinaryStreamInput=true;
        return (Result)handleBinaryStream(in);
      }
    }
  finally {
      if (out != null) {
        out.close();
      }
      if (!isBinaryStreamInput && in != null) {
        in.close();
        connection.close();
      }
    }
  }
 catch (  final GraphServiceException ex) {
    final boolean shouldLogVerbosely=logger.getLoggingLevel() == LoggerLevel.DEBUG;
    logger.logError(""String_Node_Str"" + ex.getMessage(shouldLogVerbosely),ex);
    throw ex;
  }
catch (  final Exception ex) {
    final ClientException clientException=new ClientException(""String_Node_Str"",ex);
    logger.logError(""String_Node_Str"",clientException);
    throw clientException;
  }
}"
37574,"/** 
 * Gets the response type.
 * @return The response type.
 */
@SuppressWarnings(""String_Node_Str"") public <T>Class<T> getResponseType(){
  return (Class<T>)responseClass;
}","/** 
 * Gets the response type.
 * @return The response type.
 */
@SuppressWarnings(""String_Node_Str"") public Class getResponseType(){
  return responseClass;
}"
37575,"/** 
 * Sends the HTTP request.
 * @param request           The request description.
 * @param resultClass       The class of the response from the service.
 * @param serializable      The object to send to the service in the body of the request.
 * @param progress          The progress callback for the request.
 * @param handler           The handler for stateful response.
 * @param < Result >          The type of the response object.
 * @param < Body >            The type of the object to send to the service in the body of the request.
 * @param < DeserializeType > The response handler for stateful response.
 * @return The result from the request.
 * @throws ClientException An exception occurs if the request was unable to complete for any reason.
 */
private <Result,Body,DeserializeType>Result sendRequestInternal(final IHttpRequest request,final Class<Result> resultClass,final Body serializable,final IProgressCallback<Result> progress,final IStatefulResponseHandler<Result,DeserializeType> handler) throws ClientException {
  final int defaultBufferSize=4096;
  final String contentLengthHeaderName=""String_Node_Str"";
  final String binaryContentType=""String_Node_Str"";
  try {
    if (authenticationProvider != null) {
      authenticationProvider.authenticateRequest(request);
    }
    OutputStream out=null;
    InputStream in=null;
    boolean isBinaryStreamInput=false;
    final URL requestUrl=request.getRequestUrl();
    logger.logDebug(""String_Node_Str"" + requestUrl.toString());
    final IConnection connection=connectionFactory.createFromRequest(request);
    try {
      logger.logDebug(""String_Node_Str"" + request.getHttpMethod().toString());
      List<HeaderOption> requestHeaders=request.getHeaders();
      final byte[] bytesToWrite;
      connection.addRequestHeader(""String_Node_Str"",""String_Node_Str"");
      if (serializable == null) {
        bytesToWrite=null;
      }
 else       if (serializable instanceof byte[]) {
        logger.logDebug(""String_Node_Str"");
        bytesToWrite=(byte[])serializable;
        if (!hasHeader(requestHeaders,CONTENT_TYPE_HEADER_NAME)) {
          connection.addRequestHeader(CONTENT_TYPE_HEADER_NAME,binaryContentType);
        }
        connection.setContentLength(bytesToWrite.length);
      }
 else {
        logger.logDebug(""String_Node_Str"" + serializable.getClass().getName() + ""String_Node_Str"");
        final String serializeObject=serializer.serializeObject(serializable);
        bytesToWrite=serializeObject.getBytes();
        if (!hasHeader(requestHeaders,CONTENT_TYPE_HEADER_NAME)) {
          connection.addRequestHeader(CONTENT_TYPE_HEADER_NAME,JSON_CONTENT_TYPE);
        }
        connection.setContentLength(bytesToWrite.length);
      }
      if (bytesToWrite != null) {
        out=connection.getOutputStream();
        int writtenSoFar=0;
        BufferedOutputStream bos=new BufferedOutputStream(out);
        int toWrite;
        do {
          toWrite=Math.min(defaultBufferSize,bytesToWrite.length - writtenSoFar);
          bos.write(bytesToWrite,writtenSoFar,toWrite);
          writtenSoFar=writtenSoFar + toWrite;
          if (progress != null) {
            executors.performOnForeground(writtenSoFar,bytesToWrite.length,progress);
          }
        }
 while (toWrite > 0);
        bos.close();
      }
      if (handler != null) {
        handler.configConnection(connection);
      }
      logger.logDebug(String.format(""String_Node_Str"",connection.getResponseCode(),connection.getResponseMessage()));
      if (handler != null) {
        logger.logDebug(""String_Node_Str"");
        return handler.generateResult(request,connection,this.getSerializer(),this.logger);
      }
      if (connection.getResponseCode() >= HttpResponseCode.HTTP_CLIENT_ERROR) {
        logger.logDebug(""String_Node_Str"");
        in=connection.getInputStream();
        handleErrorResponse(request,serializable,connection);
      }
      if (connection.getResponseCode() == HttpResponseCode.HTTP_NOBODY || connection.getResponseCode() == HttpResponseCode.HTTP_NOT_MODIFIED) {
        logger.logDebug(""String_Node_Str"");
        return handleEmptyResponse(connection.getResponseHeaders(),resultClass);
      }
      if (connection.getResponseCode() == HttpResponseCode.HTTP_ACCEPTED) {
        logger.logDebug(""String_Node_Str"");
        return handleEmptyResponse(connection.getResponseHeaders(),resultClass);
      }
      in=new BufferedInputStream(connection.getInputStream());
      final Map<String,String> headers=connection.getHeaders();
      final String contentType=headers.get(CONTENT_TYPE_HEADER_NAME);
      if (contentType.contains(JSON_CONTENT_TYPE)) {
        logger.logDebug(""String_Node_Str"");
        return handleJsonResponse(in,connection.getResponseHeaders(),resultClass);
      }
 else {
        logger.logDebug(""String_Node_Str"");
        isBinaryStreamInput=true;
        return (Result)handleBinaryStream(in);
      }
    }
  finally {
      if (out != null) {
        out.close();
      }
      if (!isBinaryStreamInput && in != null) {
        in.close();
        connection.close();
      }
    }
  }
 catch (  final GraphServiceException ex) {
    final boolean shouldLogVerbosely=logger.getLoggingLevel() == LoggerLevel.DEBUG;
    logger.logError(""String_Node_Str"" + ex.getMessage(shouldLogVerbosely),ex);
    throw ex;
  }
catch (  final Exception ex) {
    final ClientException clientException=new ClientException(""String_Node_Str"",ex);
    logger.logError(""String_Node_Str"",clientException);
    throw clientException;
  }
}","/** 
 * Sends the HTTP request.
 * @param request           The request description.
 * @param resultClass       The class of the response from the service.
 * @param serializable      The object to send to the service in the body of the request.
 * @param progress          The progress callback for the request.
 * @param handler           The handler for stateful response.
 * @param < Result >          The type of the response object.
 * @param < Body >            The type of the object to send to the service in the body of the request.
 * @param < DeserializeType > The response handler for stateful response.
 * @return The result from the request.
 * @throws ClientException An exception occurs if the request was unable to complete for any reason.
 */
private <Result,Body,DeserializeType>Result sendRequestInternal(final IHttpRequest request,final Class<Result> resultClass,final Body serializable,final IProgressCallback<Result> progress,final IStatefulResponseHandler<Result,DeserializeType> handler) throws ClientException {
  final int defaultBufferSize=4096;
  final String binaryContentType=""String_Node_Str"";
  try {
    if (authenticationProvider != null) {
      authenticationProvider.authenticateRequest(request);
    }
    OutputStream out=null;
    InputStream in=null;
    boolean isBinaryStreamInput=false;
    final URL requestUrl=request.getRequestUrl();
    logger.logDebug(""String_Node_Str"" + requestUrl.toString());
    final IConnection connection=connectionFactory.createFromRequest(request);
    try {
      logger.logDebug(""String_Node_Str"" + request.getHttpMethod().toString());
      List<HeaderOption> requestHeaders=request.getHeaders();
      final byte[] bytesToWrite;
      connection.addRequestHeader(""String_Node_Str"",""String_Node_Str"");
      if (serializable == null) {
        if (request.getHttpMethod() == HttpMethod.POST) {
          bytesToWrite=new byte[0];
        }
 else {
          bytesToWrite=null;
        }
      }
 else       if (serializable instanceof byte[]) {
        logger.logDebug(""String_Node_Str"");
        bytesToWrite=(byte[])serializable;
        if (!hasHeader(requestHeaders,CONTENT_TYPE_HEADER_NAME)) {
          connection.addRequestHeader(CONTENT_TYPE_HEADER_NAME,binaryContentType);
        }
        connection.setContentLength(bytesToWrite.length);
      }
 else {
        logger.logDebug(""String_Node_Str"" + serializable.getClass().getName() + ""String_Node_Str"");
        final String serializeObject=serializer.serializeObject(serializable);
        bytesToWrite=serializeObject.getBytes();
        if (!hasHeader(requestHeaders,CONTENT_TYPE_HEADER_NAME)) {
          connection.addRequestHeader(CONTENT_TYPE_HEADER_NAME,JSON_CONTENT_TYPE);
        }
        connection.setContentLength(bytesToWrite.length);
      }
      if (bytesToWrite != null) {
        out=connection.getOutputStream();
        int writtenSoFar=0;
        BufferedOutputStream bos=new BufferedOutputStream(out);
        int toWrite;
        do {
          toWrite=Math.min(defaultBufferSize,bytesToWrite.length - writtenSoFar);
          bos.write(bytesToWrite,writtenSoFar,toWrite);
          writtenSoFar=writtenSoFar + toWrite;
          if (progress != null) {
            executors.performOnForeground(writtenSoFar,bytesToWrite.length,progress);
          }
        }
 while (toWrite > 0);
        bos.close();
      }
      if (handler != null) {
        handler.configConnection(connection);
      }
      logger.logDebug(String.format(""String_Node_Str"",connection.getResponseCode(),connection.getResponseMessage()));
      if (handler != null) {
        logger.logDebug(""String_Node_Str"");
        return handler.generateResult(request,connection,this.getSerializer(),this.logger);
      }
      if (connection.getResponseCode() >= HttpResponseCode.HTTP_CLIENT_ERROR) {
        logger.logDebug(""String_Node_Str"");
        in=connection.getInputStream();
        handleErrorResponse(request,serializable,connection);
      }
      if (connection.getResponseCode() == HttpResponseCode.HTTP_NOBODY || connection.getResponseCode() == HttpResponseCode.HTTP_NOT_MODIFIED) {
        logger.logDebug(""String_Node_Str"");
        return handleEmptyResponse(connection.getResponseHeaders(),resultClass);
      }
      if (connection.getResponseCode() == HttpResponseCode.HTTP_ACCEPTED) {
        logger.logDebug(""String_Node_Str"");
        return handleEmptyResponse(connection.getResponseHeaders(),resultClass);
      }
      in=new BufferedInputStream(connection.getInputStream());
      final Map<String,String> headers=connection.getHeaders();
      final String contentType=headers.get(CONTENT_TYPE_HEADER_NAME);
      if (contentType.contains(JSON_CONTENT_TYPE)) {
        logger.logDebug(""String_Node_Str"");
        return handleJsonResponse(in,connection.getResponseHeaders(),resultClass);
      }
 else {
        logger.logDebug(""String_Node_Str"");
        isBinaryStreamInput=true;
        return (Result)handleBinaryStream(in);
      }
    }
  finally {
      if (out != null) {
        out.close();
      }
      if (!isBinaryStreamInput && in != null) {
        in.close();
        connection.close();
      }
    }
  }
 catch (  final GraphServiceException ex) {
    final boolean shouldLogVerbosely=logger.getLoggingLevel() == LoggerLevel.DEBUG;
    logger.logError(""String_Node_Str"" + ex.getMessage(shouldLogVerbosely),ex);
    throw ex;
  }
catch (  final Exception ex) {
    final ClientException clientException=new ClientException(""String_Node_Str"",ex);
    logger.logError(""String_Node_Str"",clientException);
    throw clientException;
  }
}"
37576,"@Override public void processLineForFile(BufferedReader output,IFile file) throws IOException {
  String line;
  String issue=""String_Node_Str"";
  line=output.readLine();
  final List<String> issues=Lists.newArrayList();
  while (line != null && !Thread.currentThread().isInterrupted()) {
    if (!line.isEmpty()) {
      issue=processLine(line,issue,issues,file);
    }
    line=output.readLine();
  }
  creator.createMarkers(issues,file);
}","@Override public void processLineForFile(BufferedReader output,IFile file) throws IOException {
  String line;
  String issue=""String_Node_Str"";
  line=output.readLine();
  final List<String> issues=Lists.newArrayList();
  while (line != null && !Thread.currentThread().isInterrupted()) {
    if (!line.isEmpty()) {
      issue=processLine(line,issue,issues,file);
    }
    line=output.readLine();
  }
  if (!issue.isEmpty()) {
    issues.add(issue);
  }
  creator.createMarkers(issues,file);
}"
37577,"@Override public void processLine(String line){
  if (line.startsWith(fileLocation())) {
    if (!issue.isEmpty()) {
      String[] parts=line.split(""String_Node_Str"");
      if (parts.length < 6) {
        return;
      }
      createMarker(parts);
      issue=""String_Node_Str"";
    }
    issue+=line;
  }
 else {
    issue+=(LINE_BREAK + line);
  }
}","@Override public void processLine(String line){
  if (line.startsWith(fileLocation())) {
    if (!issue.isEmpty()) {
      String[] parts=issue.split(""String_Node_Str"");
      if (parts.length < 6) {
        return;
      }
      createMarker(parts);
      issue=""String_Node_Str"";
    }
    issue+=line;
  }
 else {
    issue+=(LINE_BREAK + line);
  }
}"
37578,"@Override public View getView(int position,View convertView,ViewGroup parent){
  View v;
  AppData a;
  if (convertView == null) {
    LayoutInflater inflater=(LayoutInflater)mContext.getSystemService(Context.LAYOUT_INFLATER_SERVICE);
    if (curMode == GRID)     v=inflater.inflate(R.layout.iconbutton,parent,false);
 else     v=inflater.inflate(R.layout.oneline,parent,false);
  }
 else {
    v=convertView;
  }
  a=toDisplay.get(position);
  img=(ImageView)v.findViewById(R.id.icon);
  v.setTag(a);
  tv=(TextView)v.findViewById(R.id.text);
  if (appShortcut != Options.ICON) {
    if (appShortcut == Options.TEXT) {
      img.setVisibility(View.GONE);
    }
    tv.setText(a.name);
    tv.setTextSize(textSize);
    if (theme == Options.LIGHT || theme == Options.WALLPAPER_DARK || theme == Options.DEFAULT_THEME) {
      tv.setTextColor(Color.BLACK);
    }
 else {
      tv.setTextColor(Color.WHITE);
    }
    tv.setTypeface(Typeface.DEFAULT,Integer.parseInt(options.getString(Options.PREF_FONT_STYLE,""String_Node_Str"")));
  }
 else {
    tv.setVisibility(View.GONE);
  }
  if (appShortcut >= Options.ICON) {
    IconPackManager.setIcon(Apps.this,img,a);
    img.setVisibility(View.VISIBLE);
    ViewGroup.LayoutParams p=img.getLayoutParams();
    p.width=iconSize;
    p.height=iconSize;
    img.setLayoutParams(p);
  }
  v.setOnClickListener(onClickListener);
  v.setOnLongClickListener(onLongClickListener);
  return v;
}","@Override public View getView(int position,View convertView,ViewGroup parent){
  View v;
  AppData a;
  if (convertView == null) {
    LayoutInflater inflater=(LayoutInflater)mContext.getSystemService(Context.LAYOUT_INFLATER_SERVICE);
    if (options.getBoolean(Options.PREF_TILE,true))     v=inflater.inflate(R.layout.iconbutton,parent,false);
 else     v=inflater.inflate(R.layout.oneline,parent,false);
  }
 else {
    v=convertView;
  }
  a=toDisplay.get(position);
  img=(ImageView)v.findViewById(R.id.icon);
  v.setTag(a);
  tv=(TextView)v.findViewById(R.id.text);
  if (appShortcut != Options.ICON) {
    if (appShortcut == Options.TEXT) {
      img.setVisibility(View.GONE);
    }
    tv.setText(a.name);
    tv.setTextSize(textSize);
    if (theme == Options.LIGHT || theme == Options.WALLPAPER_DARK || theme == Options.DEFAULT_THEME) {
      tv.setTextColor(Color.BLACK);
    }
 else {
      tv.setTextColor(Color.WHITE);
    }
    tv.setTypeface(Typeface.DEFAULT,Integer.parseInt(options.getString(Options.PREF_FONT_STYLE,""String_Node_Str"")));
  }
 else {
    tv.setVisibility(View.GONE);
  }
  if (appShortcut >= Options.ICON) {
    IconPackManager.setIcon(Apps.this,img,a);
    img.setVisibility(View.VISIBLE);
    ViewGroup.LayoutParams p=img.getLayoutParams();
    p.width=iconSize;
    p.height=iconSize;
    img.setLayoutParams(p);
  }
  v.setOnClickListener(onClickListener);
  v.setOnLongClickListener(onLongClickListener);
  return v;
}"
37579,"public void loadFilteredApps(){
  curCatData=categories.filterApps(map);
  if (options.getBoolean(Options.PREF_TILE,true)) {
    makeAppGrid();
  }
 else {
    makeAppList();
  }
}","public void loadFilteredApps(){
  curCatData=categories.filterApps(map);
  adapter.update(curCatData);
}"
37580,"@Override public boolean onKeyDown(int keyCode,KeyEvent event){
  if (keyCode == KeyEvent.KEYCODE_MENU) {
    menu();
    return true;
  }
 else   if (keyCode == KeyEvent.KEYCODE_BACK) {
    if (searchIsOpened) {
      closeSearch();
      searchIsOpened=false;
    }
    if (categories.getCurCategory().equals(CategoryManager.HIDDEN)) {
      findViewById(R.id.quit_hidden_apps).setVisibility(View.GONE);
      findViewById(R.id.tabs).setVisibility(View.VISIBLE);
    }
    categories.prevCategory();
    loadFilteredApps();
    setSpinner();
    return true;
  }
  return false;
}","@Override public boolean onKeyDown(int keyCode,KeyEvent event){
  if (keyCode == KeyEvent.KEYCODE_MENU) {
    menu();
    return true;
  }
 else   if (keyCode == KeyEvent.KEYCODE_BACK) {
    if (searchIsOpened) {
      closeSearch();
      searchIsOpened=false;
    }
    if (categories.getCurCategory().equals(CategoryManager.HIDDEN)) {
      findViewById(R.id.quit_hidden_apps).setVisibility(View.GONE);
      findViewById(R.id.tabs).setVisibility(View.VISIBLE);
      categories.setCurCategory(CategoryManager.ALL);
    }
 else {
      categories.prevCategory();
    }
    loadFilteredApps();
    setSpinner();
    return true;
  }
  return false;
}"
37581,"public CustomAdapter(Context context,ArrayList<AppData> curCatData,int curMode){
  super();
  this.mContext=context;
  this.catData=curCatData;
  toDisplay=catData;
  this.curMode=curMode;
  onClickListener=new View.OnClickListener(){
    @Override public void onClick(    View arg0){
      if (arg0.getTag() instanceof AppData)       ((Apps)mContext).launch((AppData)arg0.getTag());
    }
  }
;
  if (lock) {
    onLongClickListener=new View.OnLongClickListener(){
      @Override public boolean onLongClick(      View arg0){
        final View v=arg0;
        AlertDialog.Builder builder=new AlertDialog.Builder(mContext);
        builder.setMessage(mContext.getResources().getString(R.string.type_password));
        final EditText inputBox=new EditText(mContext);
        inputBox.setInputType(InputType.TYPE_CLASS_TEXT | InputType.TYPE_TEXT_VARIATION_PASSWORD);
        builder.setView(inputBox);
        builder.setPositiveButton(android.R.string.yes,new DialogInterface.OnClickListener(){
          @Override public void onClick(          DialogInterface dialog,          int which){
            if (inputBox.getText().toString().equals(options.getString(Options.PREF_PASSWORD,""String_Node_Str""))) {
              ((Apps)mContext).itemContextMenu((AppData)v.getTag());
            }
 else {
              Toast.makeText(mContext,mContext.getResources().getString(R.string.wrong_password),Toast.LENGTH_LONG).show();
            }
          }
        }
);
        builder.setCancelable(true);
        builder.show();
        return false;
      }
    }
;
  }
 else {
    onLongClickListener=new View.OnLongClickListener(){
      @Override public boolean onLongClick(      View arg0){
        ((Apps)mContext).itemContextMenu((AppData)arg0.getTag());
        return false;
      }
    }
;
  }
  comparator=new Comparator<AppData>(){
    @Override public int compare(    AppData first,    AppData second){
      boolean firstStarts=first.name.toLowerCase().startsWith(searchInput);
      boolean secondStarts=second.name.toLowerCase().startsWith(searchInput);
      if (firstStarts && !secondStarts) {
        return -1;
      }
 else       if (!firstStarts && secondStarts) {
        return 1;
      }
 else {
        return AppData.NameComparator.compare(first,second);
      }
    }
  }
;
}","public CustomAdapter(Context context){
  super();
  this.mContext=context;
  curCatData=new ArrayList<AppData>();
  toDisplay=new ArrayList<AppData>();
  onClickListener=new View.OnClickListener(){
    @Override public void onClick(    View arg0){
      if (arg0.getTag() instanceof AppData)       ((Apps)mContext).launch((AppData)arg0.getTag());
    }
  }
;
  if (lock) {
    onLongClickListener=new View.OnLongClickListener(){
      @Override public boolean onLongClick(      View arg0){
        final View v=arg0;
        AlertDialog.Builder builder=new AlertDialog.Builder(mContext);
        builder.setMessage(mContext.getResources().getString(R.string.type_password));
        final EditText inputBox=new EditText(mContext);
        inputBox.setInputType(InputType.TYPE_CLASS_TEXT | InputType.TYPE_TEXT_VARIATION_PASSWORD);
        builder.setView(inputBox);
        builder.setPositiveButton(android.R.string.yes,new DialogInterface.OnClickListener(){
          @Override public void onClick(          DialogInterface dialog,          int which){
            if (inputBox.getText().toString().equals(options.getString(Options.PREF_PASSWORD,""String_Node_Str""))) {
              ((Apps)mContext).itemContextMenu((AppData)v.getTag());
            }
 else {
              Toast.makeText(mContext,mContext.getResources().getString(R.string.wrong_password),Toast.LENGTH_LONG).show();
            }
          }
        }
);
        builder.setCancelable(true);
        builder.show();
        return false;
      }
    }
;
  }
 else {
    onLongClickListener=new View.OnLongClickListener(){
      @Override public boolean onLongClick(      View arg0){
        ((Apps)mContext).itemContextMenu((AppData)arg0.getTag());
        return false;
      }
    }
;
  }
  comparator=new Comparator<AppData>(){
    @Override public int compare(    AppData first,    AppData second){
      boolean firstStarts=first.name.toLowerCase().startsWith(searchInput);
      boolean secondStarts=second.name.toLowerCase().startsWith(searchInput);
      if (firstStarts && !secondStarts) {
        return -1;
      }
 else       if (!firstStarts && secondStarts) {
        return 1;
      }
 else {
        return AppData.NameComparator.compare(first,second);
      }
    }
  }
;
}"
37582,"public void onMyClick(View v){
switch (v.getId()) {
case R.id.searchButton:
    openSearch();
  break;
case R.id.menuButton:
menu();
break;
case R.id.quit_hidden_apps:
categories.setCurCategory(CategoryManager.ALL);
v.setVisibility(View.GONE);
findViewById(R.id.tabs).setVisibility(View.VISIBLE);
loadFilteredApps();
break;
}
}","public void onMyClick(View v){
switch (v.getId()) {
case R.id.searchButton:
    openSearch();
  break;
case R.id.menuButton:
menu();
break;
case R.id.quit_hidden_apps:
categories.setCurCategory(CategoryManager.ALL);
v.setVisibility(View.GONE);
findViewById(R.id.tabs).setVisibility(View.VISIBLE);
loadFilteredApps();
setSpinner();
break;
}
}"
37583,"@Override public void onCreate(Bundle savedInstanceState){
  super.onCreate(savedInstanceState);
  options=PreferenceManager.getDefaultSharedPreferences(this);
  if (Build.VERSION.SDK_INT >= 11 && options.getBoolean(""String_Node_Str"",false)) {
    Notification noti=new Notification.Builder(this).setContentTitle(""String_Node_Str"").setContentText(""String_Node_Str"").setSmallIcon(R.drawable.icon).build();
    NotificationManager notiManager=(NotificationManager)getSystemService(Context.NOTIFICATION_SERVICE);
    notiManager.notify(0,noti);
  }
  setRequestedOrientation(Integer.parseInt(options.getString(Options.PREF_ORIENTATION,""String_Node_Str"")));
  setContentView(R.layout.apps);
  findViewById(R.id.appsWindow).setBackgroundColor(options.getInt(Options.PREF_APPS_WINDOW_BACKGROUND,0));
  findViewById(R.id.topbar).setBackgroundColor(options.getInt(Options.PREF_BAR_BACKGROUND,0x22000000));
  findViewById(R.id.dummy_top_view).setBackgroundColor(options.getInt(Options.PREF_BAR_BACKGROUND,0x22000000));
  findViewById(R.id.dummy_bottom_view).setBackgroundColor(options.getInt(Options.PREF_BAR_BACKGROUND,0x22000000));
  findViewById(R.id.dock_bar).setBackgroundColor(options.getInt(Options.PREF_DOCK_BACKGROUND,0x22000000));
  grid=(GridView)findViewById(R.id.appsGrid);
  ManagerContainer.setIconPackManager(this);
  prefListener=new OnSharedPreferenceChangeListener(){
    @Override public void onSharedPreferenceChanged(    SharedPreferences sharedPreferences,    String key){
      if (key.equals(Options.PREF_ORIENTATION) || key.equals(""String_Node_Str"") || key.equals(""String_Node_Str"")) {
        Toast.makeText(Apps.this,getResources().getString(R.string.restartToImplement),Toast.LENGTH_LONG).show();
      }
 else       if (key.equals(Options.PREF_BAR_BACKGROUND)) {
        findViewById(R.id.topbar).setBackgroundColor(options.getInt(Options.PREF_BAR_BACKGROUND,0));
      }
 else       if (key.equals(Options.PREF_APPS_WINDOW_BACKGROUND)) {
        findViewById(R.id.appsWindow).setBackgroundColor(options.getInt(Options.PREF_APPS_WINDOW_BACKGROUND,0));
      }
 else       if (key.equals(Options.PREF_ICON_PACK) || key.equals(Options.PREF_TRANSFORM_DRAWABLE)) {
        MyCache.deleteIcons(Apps.this);
        ManagerContainer.getIconPackManager().setIconPack(sharedPreferences.getString(Options.PREF_ICON_PACK,""String_Node_Str""));
        if (scanner != null && scanner.getStatus() == AsyncTask.Status.RUNNING)         return;
        scanner=new GetApps(Apps.this);
        scanner.execute(true);
        loadFilteredApps();
        setSpinner();
        return;
      }
 else       if (key.equals(Options.PREF_DIRTY) && sharedPreferences.getBoolean(Options.PREF_DIRTY,false)) {
        if (scanner == null || scanner.getStatus() != AsyncTask.Status.RUNNING) {
          scanner=new GetApps(Apps.this);
          scanner.execute(false);
        }
      }
    }
  }
;
  options.registerOnSharedPreferenceChangeListener(prefListener);
  setScrollbar();
  fixPadding();
  categories=null;
  spin=(Spinner)findViewById(R.id.category);
  swipeListener=new View.OnTouchListener(){
    float x, density;
    public boolean onTouch(    View v,    MotionEvent e){
      density=getResources().getDisplayMetrics().density;
      int action=e.getAction() & 255;
switch (action) {
case MotionEvent.ACTION_DOWN:
        x=e.getX();
      return true;
case MotionEvent.ACTION_UP:
    if (e.getX() - x > 30.0 * density) {
      categories.setCurCategory(categories.getPrevCategory());
      loadFilteredApps();
      setSpinner();
      return true;
    }
 else     if (x - e.getX() > 30.0 * density) {
      categories.setCurCategory(categories.getNextCategory());
      loadFilteredApps();
      setSpinner();
      return true;
    }
 else     v.performClick();
default :
  return false;
}
}
}
;
spin.setOnTouchListener(swipeListener);
dock=new Dock(this);
changePrefsOnRotate();
}","@Override public void onCreate(Bundle savedInstanceState){
  super.onCreate(savedInstanceState);
  options=PreferenceManager.getDefaultSharedPreferences(this);
  if (Build.VERSION.SDK_INT >= 11 && options.getBoolean(""String_Node_Str"",false)) {
    Notification noti=new Notification.Builder(this).setContentTitle(""String_Node_Str"").setContentText(""String_Node_Str"").setSmallIcon(R.drawable.icon).build();
    NotificationManager notiManager=(NotificationManager)getSystemService(Context.NOTIFICATION_SERVICE);
    notiManager.notify(0,noti);
  }
  setRequestedOrientation(Integer.parseInt(options.getString(Options.PREF_ORIENTATION,""String_Node_Str"")));
  setContentView(R.layout.apps);
  findViewById(R.id.appsWindow).setBackgroundColor(options.getInt(Options.PREF_APPS_WINDOW_BACKGROUND,0));
  findViewById(R.id.topbar).setBackgroundColor(options.getInt(Options.PREF_BAR_BACKGROUND,0x22000000));
  findViewById(R.id.dummy_top_view).setBackgroundColor(options.getInt(Options.PREF_BAR_BACKGROUND,0x22000000));
  findViewById(R.id.dummy_bottom_view).setBackgroundColor(options.getInt(Options.PREF_BAR_BACKGROUND,0x22000000));
  findViewById(R.id.dock_bar).setBackgroundColor(options.getInt(Options.PREF_DOCK_BACKGROUND,0x22000000));
  grid=(GridView)findViewById(R.id.appsGrid);
  ManagerContainer.setIconPackManager(this);
  prefListener=new OnSharedPreferenceChangeListener(){
    @Override public void onSharedPreferenceChanged(    SharedPreferences sharedPreferences,    String key){
      if (key.equals(Options.PREF_ORIENTATION) || key.equals(""String_Node_Str"") || key.equals(""String_Node_Str"")) {
        Toast.makeText(Apps.this,getResources().getString(R.string.restartToImplement),Toast.LENGTH_LONG).show();
      }
 else       if (key.equals(Options.PREF_BAR_BACKGROUND)) {
        findViewById(R.id.topbar).setBackgroundColor(options.getInt(Options.PREF_BAR_BACKGROUND,0));
      }
 else       if (key.equals(Options.PREF_APPS_WINDOW_BACKGROUND)) {
        findViewById(R.id.appsWindow).setBackgroundColor(options.getInt(Options.PREF_APPS_WINDOW_BACKGROUND,0));
      }
 else       if (key.equals(Options.PREF_ICON_PACK) || key.equals(Options.PREF_TRANSFORM_DRAWABLE)) {
        MyCache.deleteIcons(Apps.this);
        ManagerContainer.getIconPackManager().setIconPack(sharedPreferences.getString(Options.PREF_ICON_PACK,""String_Node_Str""));
        if (scanner != null && scanner.getStatus() == AsyncTask.Status.RUNNING)         return;
        scanner=new GetApps(Apps.this);
        scanner.execute(true);
        loadFilteredApps();
        setSpinner();
        return;
      }
 else       if (key.equals(Options.PREF_DIRTY) && sharedPreferences.getBoolean(Options.PREF_DIRTY,false)) {
        if (scanner == null || scanner.getStatus() != AsyncTask.Status.RUNNING) {
          scanner=new GetApps(Apps.this);
          scanner.execute(false);
        }
      }
    }
  }
;
  options.registerOnSharedPreferenceChangeListener(prefListener);
  initGrid();
  setScrollbar();
  fixPadding();
  categories=null;
  spin=(Spinner)findViewById(R.id.category);
  swipeListener=new View.OnTouchListener(){
    float x, density;
    public boolean onTouch(    View v,    MotionEvent e){
      density=getResources().getDisplayMetrics().density;
      int action=e.getAction() & 255;
switch (action) {
case MotionEvent.ACTION_DOWN:
        x=e.getX();
      return true;
case MotionEvent.ACTION_UP:
    if (e.getX() - x > 30.0 * density) {
      categories.setCurCategory(categories.getPrevCategory());
      loadFilteredApps();
      setSpinner();
      return true;
    }
 else     if (x - e.getX() > 30.0 * density) {
      categories.setCurCategory(categories.getNextCategory());
      loadFilteredApps();
      setSpinner();
      return true;
    }
 else     v.performClick();
default :
  return false;
}
}
}
;
spin.setOnTouchListener(swipeListener);
dock=new Dock(this);
changePrefsOnRotate();
}"
37584,"public Bitmap transformDrawable(Drawable d){
  Bitmap b=((BitmapDrawable)d).getBitmap();
  if ((iconBacks == null && iconMask == null && iconUpon == null && factor == 1.f) || !transformDrawable) {
    return b;
  }
  int w, h;
  Paint paint;
  if (iconBacks != null) {
    w=iconBacks.get(0).getWidth();
    h=iconBacks.get(0).getHeight();
  }
 else {
    w=b.getWidth();
    h=b.getHeight();
  }
  Bitmap result=Bitmap.createBitmap(w,h,Bitmap.Config.ARGB_8888);
  Canvas canvas=new Canvas(result);
  if (iconBacks != null) {
    canvas.drawBitmap(iconBacks.get((int)(Math.random() * iconBacks.size())),0,0,null);
  }
  paint=new Paint(Paint.ANTI_ALIAS_FLAG);
  Bitmap scaledBitmap=Bitmap.createScaledBitmap(b,(int)(w * factor),(int)(h * factor),false);
  canvas.drawBitmap(scaledBitmap,w * (1 - factor) / 2,h * (1 - factor) / 2,paint);
  if (iconMask != null) {
    paint.setXfermode(new PorterDuffXfermode(Mode.DST_OUT));
    canvas.drawBitmap(iconMask,0.f,0.f,paint);
    paint.setXfermode(null);
  }
  if (iconUpon != null) {
    canvas.drawBitmap(iconUpon,0,0,null);
  }
  return result;
}","public Bitmap transformDrawable(Drawable d){
  Bitmap b=((BitmapDrawable)d).getBitmap();
  if ((iconBacks == null && iconMask == null && iconUpon == null && factor == 1.f) || !transformDrawable) {
    return b;
  }
  int w, h;
  Paint paint;
  if (iconBacks != null) {
    if (iconBacks.size() > 0) {
      w=iconBacks.get(0).getWidth();
      h=iconBacks.get(0).getHeight();
    }
 else {
      w=b.getWidth();
      h=b.getHeight();
    }
  }
 else {
    w=b.getWidth();
    h=b.getHeight();
  }
  Bitmap result=Bitmap.createBitmap(w,h,Bitmap.Config.ARGB_8888);
  Canvas canvas=new Canvas(result);
  if (iconBacks != null) {
    if (iconBacks.size() > 0) {
      canvas.drawBitmap(iconBacks.get((int)(Math.random() * iconBacks.size())),0,0,null);
    }
  }
  paint=new Paint(Paint.ANTI_ALIAS_FLAG);
  Bitmap scaledBitmap=Bitmap.createScaledBitmap(b,(int)(w * factor),(int)(h * factor),false);
  canvas.drawBitmap(scaledBitmap,w * (1 - factor) / 2,h * (1 - factor) / 2,paint);
  if (iconMask != null) {
    paint.setXfermode(new PorterDuffXfermode(Mode.DST_OUT));
    canvas.drawBitmap(iconMask,0.f,0.f,paint);
    paint.setXfermode(null);
  }
  if (iconUpon != null) {
    canvas.drawBitmap(iconUpon,0,0,null);
  }
  return result;
}"
37585,"public void setIcons(){
  iconsData=new HashMap<String,String>();
  iconBacks=null;
  iconMask=null;
  iconUpon=null;
  factor=1.0f;
  iconPackRes=null;
  if (iconPackName.equals(""String_Node_Str"")) {
    return;
  }
  transformDrawable=PreferenceManager.getDefaultSharedPreferences(context).getBoolean(Options.PREF_TRANSFORM_DRAWABLE,true);
  String component=null;
  String drawable=null;
  PackageManager pm=context.getPackageManager();
  iconBacks=new ArrayList<Bitmap>();
  try {
    iconPackRes=pm.getResourcesForApplication(iconPackName);
  }
 catch (  PackageManager.NameNotFoundException nameNotFound) {
  }
  try {
    int id=iconPackRes.getIdentifier(""String_Node_Str"",""String_Node_Str"",iconPackName);
    XmlPullParser parser=iconPackRes.getXml(id);
    int parserEvent=parser.getEventType();
    while (parserEvent != XmlPullParser.END_DOCUMENT) {
      if (parserEvent == XmlPullParser.START_TAG) {
        if (parser.getName().equals(""String_Node_Str"")) {
          for (int i=0; i < parser.getAttributeCount(); i++) {
            if (parser.getAttributeName(i).equals(""String_Node_Str"")) {
              component=parser.getAttributeValue(i);
              int c=component.indexOf(""String_Node_Str"");
              component=component.substring(c + 1,component.length() - 1);
            }
 else             if (parser.getAttributeName(i).equals(""String_Node_Str"")) {
              drawable=parser.getAttributeValue(i);
            }
          }
          iconsData.put(component,drawable);
        }
 else         if (parser.getName().equals(""String_Node_Str"")) {
          for (int i=0; i < parser.getAttributeCount(); i++) {
            iconBacks.add(loadBitmap(parser.getAttributeValue(i)));
          }
        }
 else         if (parser.getName().equals(""String_Node_Str"")) {
          iconMask=loadBitmap(parser.getAttributeValue(0));
        }
 else         if (parser.getName().equals(""String_Node_Str"")) {
          iconUpon=loadBitmap(parser.getAttributeValue(0));
        }
 else         if (parser.getName().equals(""String_Node_Str"")) {
          if (parser.getAttributeCount() > 0 && parser.getAttributeName(0).equals(""String_Node_Str"")) {
            factor=Float.valueOf(parser.getAttributeValue(0));
          }
        }
      }
      parserEvent=parser.next();
    }
  }
 catch (  Exception e) {
  }
}","public void setIcons(){
  iconsData=new HashMap<String,String>();
  iconBacks=null;
  iconMask=null;
  iconUpon=null;
  factor=1.0f;
  iconPackRes=null;
  if (iconPackName.equals(""String_Node_Str"")) {
    return;
  }
  transformDrawable=PreferenceManager.getDefaultSharedPreferences(context).getBoolean(Options.PREF_TRANSFORM_DRAWABLE,true);
  String component=null;
  String drawable=null;
  PackageManager pm=context.getPackageManager();
  iconBacks=new ArrayList<Bitmap>();
  try {
    iconPackRes=pm.getResourcesForApplication(iconPackName);
  }
 catch (  PackageManager.NameNotFoundException nameNotFound) {
  }
  try {
    int id=iconPackRes.getIdentifier(""String_Node_Str"",""String_Node_Str"",iconPackName);
    XmlPullParser parser=iconPackRes.getXml(id);
    int parserEvent=parser.getEventType();
    while (parserEvent != XmlPullParser.END_DOCUMENT) {
      if (parserEvent == XmlPullParser.START_TAG) {
        if (parser.getName().equals(""String_Node_Str"")) {
          for (int i=0; i < parser.getAttributeCount(); i++) {
            if (parser.getAttributeName(i).equals(""String_Node_Str"")) {
              component=parser.getAttributeValue(i);
              int c=component.indexOf(""String_Node_Str"");
              component=component.substring(c + 1,component.length() - 1);
            }
 else             if (parser.getAttributeName(i).equals(""String_Node_Str"")) {
              drawable=parser.getAttributeValue(i);
            }
          }
          iconsData.put(component,drawable);
        }
 else         if (parser.getName().equals(""String_Node_Str"")) {
          for (int i=0; i < parser.getAttributeCount(); i++) {
            iconBacks.add(loadBitmap(parser.getAttributeValue(i)));
          }
        }
 else         if (parser.getName().equals(""String_Node_Str"")) {
          if (parser.getAttributeCount() > 0 && parser.getAttributeName(0).equals(""String_Node_Str"")) {
            iconMask=loadBitmap(parser.getAttributeValue(0));
          }
        }
 else         if (parser.getName().equals(""String_Node_Str"")) {
          if (parser.getAttributeCount() > 0 && parser.getAttributeName(0).equals(""String_Node_Str"")) {
            iconUpon=loadBitmap(parser.getAttributeValue(0));
          }
        }
 else         if (parser.getName().equals(""String_Node_Str"")) {
          if (parser.getAttributeCount() > 0 && parser.getAttributeName(0).equals(""String_Node_Str"")) {
            factor=Float.valueOf(parser.getAttributeValue(0));
          }
        }
      }
      parserEvent=parser.next();
    }
  }
 catch (  Exception e) {
  }
}"
37586,"@Override public Observable<TrafficManagerProfile> updateResourceAsync(){
  final TrafficManagerProfileImpl self=this;
  final ProfilesInner innerCollection=this.manager().inner().profiles();
  return self.endpoints.commitAndGetAllAsync().flatMap(new Func1<List<TrafficManagerEndpointImpl>,Observable<? extends TrafficManagerProfile>>(){
    public Observable<? extends TrafficManagerProfile> call(    List<TrafficManagerEndpointImpl> endpoints){
      return innerCollection.createOrUpdateAsync(resourceGroupName(),name(),inner()).map(new Func1<ProfileInner,TrafficManagerProfile>(){
        @Override public TrafficManagerProfile call(        ProfileInner profileInner){
          self.setInner(profileInner);
          return self;
        }
      }
);
    }
  }
);
}","@Override public Observable<TrafficManagerProfile> updateResourceAsync(){
  final TrafficManagerProfileImpl self=this;
  final ProfilesInner innerCollection=this.manager().inner().profiles();
  return self.endpoints.commitAndGetAllAsync().flatMap(new Func1<List<TrafficManagerEndpointImpl>,Observable<? extends TrafficManagerProfile>>(){
    public Observable<? extends TrafficManagerProfile> call(    List<TrafficManagerEndpointImpl> endpoints){
      List<EndpointInner> innerEndpoints=new ArrayList<>();
      for (      TrafficManagerEndpointImpl ei : endpoints) {
        innerEndpoints.add(ei.inner());
      }
      inner().withEndpoints(innerEndpoints);
      return innerCollection.createOrUpdateAsync(resourceGroupName(),name(),inner()).map(new Func1<ProfileInner,TrafficManagerProfile>(){
        @Override public TrafficManagerProfile call(        ProfileInner profileInner){
          self.setInner(profileInner);
          return self;
        }
      }
);
    }
  }
);
}"
37587,"@Override public TrafficManagerProfile createResource(TrafficManagerProfiles profiles) throws Exception {
  final Region region=Region.US_EAST;
  final String groupName=""String_Node_Str"" + this.testId;
  final String pipName=""String_Node_Str"" + this.testId;
  final String pipDnsLabel=SdkContext.randomResourceName(""String_Node_Str"",15);
  final String tmProfileName=""String_Node_Str"" + this.testId;
  final String nestedTmProfileName=""String_Node_Str"" + tmProfileName;
  final String tmProfileDnsLabel=SdkContext.randomResourceName(""String_Node_Str"",15);
  final String nestedTmProfileDnsLabel=""String_Node_Str"" + tmProfileDnsLabel;
  ResourceGroup.DefinitionStages.WithCreate rgCreatable=profiles.manager().resourceManager().resourceGroups().define(groupName).withRegion(region);
  TrafficManagerProfile nestedProfile=profiles.define(nestedTmProfileName).withNewResourceGroup(rgCreatable).withLeafDomainLabel(nestedTmProfileDnsLabel).withPriorityBasedRouting().defineExternalTargetEndpoint(""String_Node_Str"").toFqdn(""String_Node_Str"").fromRegion(Region.INDIA_CENTRAL).attach().withHttpsMonitoring().withTimeToLive(500).create();
  Assert.assertTrue(nestedProfile.isEnabled());
  Assert.assertNotNull(nestedProfile.monitorStatus());
  Assert.assertEquals(nestedProfile.monitoringPort(),443);
  Assert.assertEquals(nestedProfile.monitoringPath(),""String_Node_Str"");
  Assert.assertEquals(nestedProfile.azureEndpoints().size(),0);
  Assert.assertEquals(nestedProfile.nestedProfileEndpoints().size(),0);
  Assert.assertEquals(nestedProfile.externalEndpoints().size(),1);
  Assert.assertEquals(nestedProfile.fqdn(),nestedTmProfileDnsLabel + ""String_Node_Str"");
  Assert.assertEquals(nestedProfile.timeToLive(),500);
  PublicIPAddress publicIPAddress=this.publicIPAddresses.define(pipName).withRegion(region).withNewResourceGroup(rgCreatable).withLeafDomainLabel(pipDnsLabel).create();
  Assert.assertNotNull(publicIPAddress.fqdn());
  TrafficManagerProfile profile=profiles.define(tmProfileName).withNewResourceGroup(rgCreatable).withLeafDomainLabel(tmProfileDnsLabel).withWeightBasedRouting().defineExternalTargetEndpoint(externalEndpointName21).toFqdn(externalFqdn21).fromRegion(Region.US_EAST).withRoutingPriority(1).withRoutingWeight(1).attach().defineExternalTargetEndpoint(externalEndpointName22).toFqdn(externalFqdn22).fromRegion(Region.US_EAST2).withRoutingPriority(2).withRoutingWeight(1).withTrafficDisabled().attach().defineAzureTargetEndpoint(azureEndpointName).toResourceId(publicIPAddress.id()).withRoutingPriority(3).attach().defineNestedTargetEndpoint(nestedProfileEndpointName).toProfile(nestedProfile).fromRegion(Region.INDIA_CENTRAL).withMinimumEndpointsToEnableTraffic(1).withRoutingPriority(4).attach().withHttpMonitoring().create();
  Assert.assertTrue(profile.isEnabled());
  Assert.assertNotNull(profile.monitorStatus());
  Assert.assertEquals(profile.monitoringPort(),80);
  Assert.assertEquals(profile.monitoringPath(),""String_Node_Str"");
  Assert.assertEquals(profile.azureEndpoints().size(),1);
  Assert.assertEquals(profile.nestedProfileEndpoints().size(),1);
  Assert.assertEquals(profile.externalEndpoints().size(),2);
  Assert.assertEquals(profile.fqdn(),tmProfileDnsLabel + ""String_Node_Str"");
  Assert.assertEquals(profile.timeToLive(),300);
  profile=profile.refresh();
  Assert.assertEquals(profile.azureEndpoints().size(),1);
  Assert.assertEquals(profile.nestedProfileEndpoints().size(),1);
  Assert.assertEquals(profile.externalEndpoints().size(),2);
  int c=0;
  for (  TrafficManagerExternalEndpoint endpoint : profile.externalEndpoints().values()) {
    Assert.assertEquals(endpoint.endpointType(),EndpointType.EXTERNAL);
    if (endpoint.name().equalsIgnoreCase(externalEndpointName21)) {
      Assert.assertEquals(endpoint.routingPriority(),1);
      Assert.assertEquals(endpoint.fqdn(),externalFqdn21);
      Assert.assertNotNull(endpoint.monitorStatus());
      Assert.assertEquals(endpoint.sourceTrafficLocation(),Region.US_EAST);
      c++;
    }
 else     if (endpoint.name().equalsIgnoreCase(externalEndpointName22)) {
      Assert.assertEquals(endpoint.routingPriority(),2);
      Assert.assertEquals(endpoint.fqdn(),externalFqdn22);
      Assert.assertNotNull(endpoint.monitorStatus());
      Assert.assertEquals(endpoint.sourceTrafficLocation(),Region.US_EAST2);
      c++;
    }
  }
  Assert.assertEquals(c,2);
  c=0;
  for (  TrafficManagerAzureEndpoint endpoint : profile.azureEndpoints().values()) {
    Assert.assertEquals(endpoint.endpointType(),EndpointType.AZURE);
    if (endpoint.name().equalsIgnoreCase(azureEndpointName)) {
      Assert.assertEquals(endpoint.routingPriority(),3);
      Assert.assertNotNull(endpoint.monitorStatus());
      Assert.assertEquals(endpoint.targetAzureResourceId(),publicIPAddress.id());
      Assert.assertEquals(endpoint.targetResourceType(),TargetAzureResourceType.PUBLICIP);
      c++;
    }
  }
  Assert.assertEquals(c,1);
  c=0;
  for (  TrafficManagerNestedProfileEndpoint endpoint : profile.nestedProfileEndpoints().values()) {
    Assert.assertEquals(endpoint.endpointType(),EndpointType.NESTED_PROFILE);
    if (endpoint.name().equalsIgnoreCase(nestedProfileEndpointName)) {
      Assert.assertEquals(endpoint.routingPriority(),4);
      Assert.assertNotNull(endpoint.monitorStatus());
      Assert.assertEquals(endpoint.minimumChildEndpointCount(),1);
      Assert.assertEquals(endpoint.nestedProfileId(),nestedProfile.id());
      Assert.assertEquals(endpoint.sourceTrafficLocation(),Region.INDIA_CENTRAL);
      c++;
    }
  }
  Assert.assertEquals(c,1);
  return profile;
}","@Override public TrafficManagerProfile createResource(TrafficManagerProfiles profiles) throws Exception {
  final Region region=Region.US_EAST;
  final String groupName=""String_Node_Str"" + this.testId;
  final String pipName=""String_Node_Str"" + this.testId;
  final String pipDnsLabel=SdkContext.randomResourceName(""String_Node_Str"",15);
  final String tmProfileName=""String_Node_Str"" + this.testId;
  final String nestedTmProfileName=""String_Node_Str"" + tmProfileName;
  final String tmProfileDnsLabel=SdkContext.randomResourceName(""String_Node_Str"",15);
  final String nestedTmProfileDnsLabel=""String_Node_Str"" + tmProfileDnsLabel;
  ResourceGroup.DefinitionStages.WithCreate rgCreatable=profiles.manager().resourceManager().resourceGroups().define(groupName).withRegion(region);
  TrafficManagerProfile nestedProfile=profiles.define(nestedTmProfileName).withNewResourceGroup(rgCreatable).withLeafDomainLabel(nestedTmProfileDnsLabel).withPriorityBasedRouting().defineExternalTargetEndpoint(""String_Node_Str"").toFqdn(""String_Node_Str"").fromRegion(Region.INDIA_CENTRAL).attach().withHttpsMonitoring().withTimeToLive(500).create();
  Assert.assertTrue(nestedProfile.isEnabled());
  Assert.assertNotNull(nestedProfile.monitorStatus());
  Assert.assertEquals(nestedProfile.monitoringPort(),443);
  Assert.assertEquals(nestedProfile.monitoringPath(),""String_Node_Str"");
  Assert.assertEquals(nestedProfile.azureEndpoints().size(),0);
  Assert.assertEquals(nestedProfile.nestedProfileEndpoints().size(),0);
  Assert.assertEquals(nestedProfile.externalEndpoints().size(),1);
  Assert.assertEquals(nestedProfile.fqdn(),nestedTmProfileDnsLabel + ""String_Node_Str"");
  Assert.assertEquals(nestedProfile.timeToLive(),500);
  PublicIPAddress publicIPAddress=this.publicIPAddresses.define(pipName).withRegion(region).withNewResourceGroup(rgCreatable).withLeafDomainLabel(pipDnsLabel).create();
  Assert.assertNotNull(publicIPAddress.fqdn());
  TrafficManagerProfile updatedProfile=nestedProfile.update().defineAzureTargetEndpoint(azureEndpointName).toResourceId(publicIPAddress.id()).withTrafficDisabled().withRoutingPriority(11).attach().apply();
  Assert.assertEquals(1,updatedProfile.azureEndpoints().size());
  Assert.assertTrue(updatedProfile.azureEndpoints().containsKey(azureEndpointName));
  TrafficManagerProfile updatedProfileFromGet=profiles.getById(updatedProfile.id());
  Assert.assertEquals(1,updatedProfileFromGet.azureEndpoints().size());
  Assert.assertTrue(updatedProfileFromGet.azureEndpoints().containsKey(azureEndpointName));
  nestedProfile.update().withoutEndpoint(azureEndpointName).apply();
  TrafficManagerProfile profile=profiles.define(tmProfileName).withNewResourceGroup(rgCreatable).withLeafDomainLabel(tmProfileDnsLabel).withWeightBasedRouting().defineExternalTargetEndpoint(externalEndpointName21).toFqdn(externalFqdn21).fromRegion(Region.US_EAST).withRoutingPriority(1).withRoutingWeight(1).attach().defineExternalTargetEndpoint(externalEndpointName22).toFqdn(externalFqdn22).fromRegion(Region.US_EAST2).withRoutingPriority(2).withRoutingWeight(1).withTrafficDisabled().attach().defineAzureTargetEndpoint(azureEndpointName).toResourceId(publicIPAddress.id()).withRoutingPriority(3).attach().defineNestedTargetEndpoint(nestedProfileEndpointName).toProfile(nestedProfile).fromRegion(Region.INDIA_CENTRAL).withMinimumEndpointsToEnableTraffic(1).withRoutingPriority(4).attach().withHttpMonitoring().create();
  Assert.assertTrue(profile.isEnabled());
  Assert.assertNotNull(profile.monitorStatus());
  Assert.assertEquals(profile.monitoringPort(),80);
  Assert.assertEquals(profile.monitoringPath(),""String_Node_Str"");
  Assert.assertEquals(profile.azureEndpoints().size(),1);
  Assert.assertEquals(profile.nestedProfileEndpoints().size(),1);
  Assert.assertEquals(profile.externalEndpoints().size(),2);
  Assert.assertEquals(profile.fqdn(),tmProfileDnsLabel + ""String_Node_Str"");
  Assert.assertEquals(profile.timeToLive(),300);
  profile=profile.refresh();
  Assert.assertEquals(profile.azureEndpoints().size(),1);
  Assert.assertEquals(profile.nestedProfileEndpoints().size(),1);
  Assert.assertEquals(profile.externalEndpoints().size(),2);
  int c=0;
  for (  TrafficManagerExternalEndpoint endpoint : profile.externalEndpoints().values()) {
    Assert.assertEquals(endpoint.endpointType(),EndpointType.EXTERNAL);
    if (endpoint.name().equalsIgnoreCase(externalEndpointName21)) {
      Assert.assertEquals(endpoint.routingPriority(),1);
      Assert.assertEquals(endpoint.fqdn(),externalFqdn21);
      Assert.assertNotNull(endpoint.monitorStatus());
      Assert.assertEquals(endpoint.sourceTrafficLocation(),Region.US_EAST);
      c++;
    }
 else     if (endpoint.name().equalsIgnoreCase(externalEndpointName22)) {
      Assert.assertEquals(endpoint.routingPriority(),2);
      Assert.assertEquals(endpoint.fqdn(),externalFqdn22);
      Assert.assertNotNull(endpoint.monitorStatus());
      Assert.assertEquals(endpoint.sourceTrafficLocation(),Region.US_EAST2);
      c++;
    }
  }
  Assert.assertEquals(c,2);
  c=0;
  for (  TrafficManagerAzureEndpoint endpoint : profile.azureEndpoints().values()) {
    Assert.assertEquals(endpoint.endpointType(),EndpointType.AZURE);
    if (endpoint.name().equalsIgnoreCase(azureEndpointName)) {
      Assert.assertEquals(endpoint.routingPriority(),3);
      Assert.assertNotNull(endpoint.monitorStatus());
      Assert.assertEquals(endpoint.targetAzureResourceId(),publicIPAddress.id());
      Assert.assertEquals(endpoint.targetResourceType(),TargetAzureResourceType.PUBLICIP);
      c++;
    }
  }
  Assert.assertEquals(c,1);
  c=0;
  for (  TrafficManagerNestedProfileEndpoint endpoint : profile.nestedProfileEndpoints().values()) {
    Assert.assertEquals(endpoint.endpointType(),EndpointType.NESTED_PROFILE);
    if (endpoint.name().equalsIgnoreCase(nestedProfileEndpointName)) {
      Assert.assertEquals(endpoint.routingPriority(),4);
      Assert.assertNotNull(endpoint.monitorStatus());
      Assert.assertEquals(endpoint.minimumChildEndpointCount(),1);
      Assert.assertEquals(endpoint.nestedProfileId(),nestedProfile.id());
      Assert.assertEquals(endpoint.sourceTrafficLocation(),Region.INDIA_CENTRAL);
      c++;
    }
  }
  Assert.assertEquals(c,1);
  return profile;
}"
37588,"@Override public DeploymentImpl beginCreate(){
  if (creatableResourceGroup != null) {
    creatableResourceGroup.create();
  }
  DeploymentInner inner=new DeploymentInner().withProperties(new DeploymentProperties());
  inner.properties().withMode(mode());
  inner.properties().withTemplate(template());
  inner.properties().withTemplateLink(templateLink());
  inner.properties().withParameters(parameters());
  inner.properties().withParametersLink(parametersLink());
  this.manager().inner().deployments().beginCreateOrUpdate(resourceGroupName(),name(),inner);
  return this;
}","@Override public DeploymentImpl beginCreate(){
  if (creatableResourceGroup != null) {
    creatableResourceGroup.create();
  }
  DeploymentInner inner=new DeploymentInner().withProperties(new DeploymentProperties());
  inner.properties().withMode(mode());
  inner.properties().withTemplate(template());
  inner.properties().withTemplateLink(templateLink());
  inner.properties().withParameters(parameters());
  inner.properties().withParametersLink(parametersLink());
  setInner(this.manager().inner().deployments().beginCreateOrUpdate(resourceGroupName(),name(),inner));
  return this;
}"
37589,"@Test public void canUpdateVirtualNetworkDeployment() throws Exception {
  final String dp=""String_Node_Str"" + testId;
  resourceClient.deployments().define(dp).withExistingResourceGroup(rgName).withTemplateLink(templateUri,contentVersion).withParametersLink(parametersUri,contentVersion).withMode(DeploymentMode.COMPLETE).beginCreate();
  Deployment deployment=resourceClient.deployments().getByResourceGroup(rgName,dp);
  Assert.assertEquals(dp,deployment.name());
  deployment.cancel();
  deployment=resourceClient.deployments().getByResourceGroup(rgName,dp);
  Assert.assertEquals(""String_Node_Str"",deployment.provisioningState());
  deployment.update().withTemplate(updateTemplate).withParameters(updateParameters).withMode(DeploymentMode.INCREMENTAL).apply();
  deployment=resourceClient.deployments().getByResourceGroup(rgName,dp);
  Assert.assertEquals(DeploymentMode.INCREMENTAL,deployment.mode());
  Assert.assertEquals(""String_Node_Str"",deployment.provisioningState());
  GenericResource genericVnet=resourceClient.genericResources().get(rgName,""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"");
  Assert.assertNotNull(genericVnet);
  resourceClient.genericResources().delete(rgName,""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"");
}","@Test public void canUpdateVirtualNetworkDeployment() throws Exception {
  final String dp=""String_Node_Str"" + testId;
  Deployment createdDeployment=resourceClient.deployments().define(dp).withExistingResourceGroup(rgName).withTemplateLink(templateUri,contentVersion).withParametersLink(parametersUri,contentVersion).withMode(DeploymentMode.COMPLETE).beginCreate();
  Deployment deployment=resourceClient.deployments().getByResourceGroup(rgName,dp);
  Assert.assertEquals(createdDeployment.correlationId(),deployment.correlationId());
  Assert.assertEquals(dp,deployment.name());
  deployment.cancel();
  deployment=resourceClient.deployments().getByResourceGroup(rgName,dp);
  Assert.assertEquals(""String_Node_Str"",deployment.provisioningState());
  deployment.update().withTemplate(updateTemplate).withParameters(updateParameters).withMode(DeploymentMode.INCREMENTAL).apply();
  deployment=resourceClient.deployments().getByResourceGroup(rgName,dp);
  Assert.assertEquals(DeploymentMode.INCREMENTAL,deployment.mode());
  Assert.assertEquals(""String_Node_Str"",deployment.provisioningState());
  GenericResource genericVnet=resourceClient.genericResources().get(rgName,""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"");
  Assert.assertNotNull(genericVnet);
  resourceClient.genericResources().delete(rgName,""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"");
}"
37590,"private void addLocationsForCreateUpdateParameters(DatabaseAccountCreateUpdateParametersInner createUpdateParametersInner,List<FailoverPolicyInner> failoverPolicies){
  List<Location> locations=new ArrayList<Location>();
  for (int i=0; i < failoverPolicies.size(); i++) {
    FailoverPolicyInner policyInner=failoverPolicies.get(i);
    Location location=new Location();
    location.withFailoverPriority(i);
    location.withLocationName(policyInner.locationName());
    locations.add(location);
  }
  if (locations.size() > 0) {
    createUpdateParametersInner.withLocations(locations);
  }
}","private void addLocationsForCreateUpdateParameters(DatabaseAccountCreateUpdateParametersInner createUpdateParametersInner,List<FailoverPolicyInner> failoverPolicies){
  List<Location> locations=new ArrayList<Location>();
  if (failoverPolicies.size() > 0) {
    for (int i=0; i < failoverPolicies.size(); i++) {
      FailoverPolicyInner policyInner=failoverPolicies.get(i);
      Location location=new Location();
      location.withFailoverPriority(i);
      location.withLocationName(policyInner.locationName());
      locations.add(location);
    }
  }
 else {
    Location location=new Location();
    location.withFailoverPriority(0);
    location.withLocationName(createUpdateParametersInner.location());
    locations.add(location);
  }
  createUpdateParametersInner.withLocations(locations);
}"
37591,"@Override public ActionGroupImpl withAzureFunction(String functionAppResourceId,String functionName,String httpTriggerUrl){
  String compositeKey=this.actionReceiverPrefix + functionSuffix;
  if (this.functionReceivers.containsKey(compositeKey)) {
    this.functionReceivers.remove(compositeKey);
  }
  AzureFunctionReceiver afr=new AzureFunctionReceiver();
  afr.withName(compositeKey);
  afr.withFunctionAppResourceId(functionAppResourceId);
  afr.withFunctionName(functionName);
  afr.withHttpTriggerUrl(httpTriggerUrl);
  this.functionReceivers.put(compositeKey,afr);
  return this;
}","@Override public ActionGroupImpl withAzureFunction(String functionAppResourceId,String functionName,String httpTriggerUrl){
  this.withoutAzureFunction();
  String compositeKey=this.actionReceiverPrefix + functionSuffix;
  AzureFunctionReceiver afr=new AzureFunctionReceiver();
  afr.withName(compositeKey);
  afr.withFunctionAppResourceId(functionAppResourceId);
  afr.withFunctionName(functionName);
  afr.withHttpTriggerUrl(httpTriggerUrl);
  this.functionReceivers.put(compositeKey,afr);
  return this;
}"
37592,"/** 
 * Sets the short name of the action group. This will be used in SMS messages. Maximum length cannot exceed 15 symbols.
 * @param shortName short name of the action group. Cannot exceed 15 symbols
 * @return the next stage of the update
 */
Update withShortName(String shortName);","/** 
 * Sets the short name of the action group. This will be used in SMS messages. Maximum length cannot exceed 12 symbols.
 * @param shortName short name of the action group. Cannot exceed 12 symbols
 * @return the next stage of the update
 */
Update withShortName(String shortName);"
37593,"@Override public SqlDatabase call(DatabaseInner inner){
  return new SqlDatabaseImpl(resourceGroupName,sqlServerName,inner.location(),inner.name(),inner,manager);
}","@Override public SqlDatabase call(DatabaseInner inner){
  return new SqlDatabaseImpl(inner.name(),(SqlServerImpl)sqlServer,inner,sqlServer.manager());
}"
37594,"@Override public Observable<SqlDatabase> listBySqlServerAsync(SqlServer sqlServer){
  return null;
}","@Override public Observable<SqlDatabase> listBySqlServerAsync(final SqlServer sqlServer){
  return sqlServer.manager().inner().databases().listByServerAsync(sqlServer.resourceGroupName(),sqlServer.name()).flatMap(new Func1<List<DatabaseInner>,Observable<DatabaseInner>>(){
    @Override public Observable<DatabaseInner> call(    List<DatabaseInner> databaseInners){
      return Observable.from(databaseInners);
    }
  }
).map(new Func1<DatabaseInner,SqlDatabase>(){
    @Override public SqlDatabase call(    DatabaseInner inner){
      return new SqlDatabaseImpl(inner.name(),(SqlServerImpl)sqlServer,inner,sqlServer.manager());
    }
  }
);
}"
37595,"@Override protected Observable<ServerAutomaticTuningInner> getInnerAsync(){
  return null;
}","@Override protected Observable<ServerAutomaticTuningInner> getInnerAsync(){
  return this.sqlServerManager.inner().serverAutomaticTunings().getAsync(this.resourceGroupName,this.sqlServerName);
}"
37596,"Observable<Indexable> submitAppSettings(){
  return Observable.just(configurationSource).flatMap(new Func1<WebAppBase,Observable<Indexable>>(){
    @Override public Observable<Indexable> call(    WebAppBase webAppBase){
      if (webAppBase == null || !isInCreateMode()) {
        return Observable.just((Indexable)DeploymentSlotBaseImpl.this);
      }
      return webAppBase.getAppSettingsAsync().flatMap(new Func1<Map<String,AppSetting>,Observable<Indexable>>(){
        @Override public Observable<Indexable> call(        Map<String,AppSetting> stringAppSettingMap){
          for (          AppSetting appSetting : stringAppSettingMap.values()) {
            if (appSetting.sticky()) {
              withStickyAppSetting(appSetting.key(),appSetting.value());
            }
 else {
              withAppSetting(appSetting.key(),appSetting.value());
            }
          }
          return DeploymentSlotBaseImpl.super.submitAppSettings();
        }
      }
);
    }
  }
);
}","Observable<Indexable> submitAppSettings(){
  return Observable.just(configurationSource).flatMap(new Func1<WebAppBase,Observable<Indexable>>(){
    @Override public Observable<Indexable> call(    WebAppBase webAppBase){
      if (webAppBase == null || !isInCreateMode()) {
        return DeploymentSlotBaseImpl.super.submitAppSettings();
      }
      return webAppBase.getAppSettingsAsync().flatMap(new Func1<Map<String,AppSetting>,Observable<Indexable>>(){
        @Override public Observable<Indexable> call(        Map<String,AppSetting> stringAppSettingMap){
          for (          AppSetting appSetting : stringAppSettingMap.values()) {
            if (appSetting.sticky()) {
              withStickyAppSetting(appSetting.key(),appSetting.value());
            }
 else {
              withAppSetting(appSetting.key(),appSetting.value());
            }
          }
          return DeploymentSlotBaseImpl.super.submitAppSettings();
        }
      }
);
    }
  }
);
}"
37597,"Observable<Indexable> submitConnectionStrings(){
  return Observable.just(configurationSource).flatMap(new Func1<WebAppBase,Observable<Indexable>>(){
    @Override public Observable<Indexable> call(    WebAppBase webAppBase){
      if (webAppBase == null || !isInCreateMode()) {
        return Observable.just((Indexable)DeploymentSlotBaseImpl.this);
      }
      return webAppBase.getConnectionStringsAsync().flatMap(new Func1<Map<String,ConnectionString>,Observable<Indexable>>(){
        @Override public Observable<Indexable> call(        Map<String,ConnectionString> stringConnectionStringMap){
          for (          ConnectionString connectionString : stringConnectionStringMap.values()) {
            if (connectionString.sticky()) {
              withStickyConnectionString(connectionString.name(),connectionString.value(),connectionString.type());
            }
 else {
              withConnectionString(connectionString.name(),connectionString.value(),connectionString.type());
            }
          }
          return DeploymentSlotBaseImpl.super.submitConnectionStrings();
        }
      }
);
    }
  }
);
}","Observable<Indexable> submitConnectionStrings(){
  return Observable.just(configurationSource).flatMap(new Func1<WebAppBase,Observable<Indexable>>(){
    @Override public Observable<Indexable> call(    WebAppBase webAppBase){
      if (webAppBase == null || !isInCreateMode()) {
        return DeploymentSlotBaseImpl.super.submitConnectionStrings();
      }
      return webAppBase.getConnectionStringsAsync().flatMap(new Func1<Map<String,ConnectionString>,Observable<Indexable>>(){
        @Override public Observable<Indexable> call(        Map<String,ConnectionString> stringConnectionStringMap){
          for (          ConnectionString connectionString : stringConnectionStringMap.values()) {
            if (connectionString.sticky()) {
              withStickyConnectionString(connectionString.name(),connectionString.value(),connectionString.type());
            }
 else {
              withConnectionString(connectionString.name(),connectionString.value(),connectionString.type());
            }
          }
          return DeploymentSlotBaseImpl.super.submitConnectionStrings();
        }
      }
);
    }
  }
);
}"
37598,"@Test public void canCRUDSwapSlots() throws Exception {
  WebApp webApp=appServiceManager.webApps().define(WEBAPP_NAME).withRegion(Region.US_WEST).withNewResourceGroup(RG_NAME).withNewWindowsPlan(PricingTier.STANDARD_S2).withAppSetting(""String_Node_Str"",""String_Node_Str"").withStickyAppSetting(""String_Node_Str"",""String_Node_Str"").withConnectionString(""String_Node_Str"",""String_Node_Str"",ConnectionStringType.CUSTOM).withStickyConnectionString(""String_Node_Str"",""String_Node_Str"",ConnectionStringType.CUSTOM).withJavaVersion(JavaVersion.JAVA_1_7_0_51).withWebContainer(WebContainer.TOMCAT_7_0_50).create();
  Assert.assertNotNull(webApp);
  Assert.assertEquals(Region.US_WEST,webApp.region());
  DeploymentSlot slot1=webApp.deploymentSlots().define(SLOT_NAME_1).withBrandNewConfiguration().withPythonVersion(PythonVersion.PYTHON_27).create();
  Assert.assertNotNull(slot1);
  Assert.assertNotEquals(JavaVersion.JAVA_1_7_0_51,slot1.javaVersion());
  Assert.assertEquals(PythonVersion.PYTHON_27,slot1.pythonVersion());
  Map<String,AppSetting> appSettingMap=slot1.getAppSettings();
  Assert.assertFalse(appSettingMap.containsKey(""String_Node_Str""));
  Assert.assertFalse(appSettingMap.containsKey(""String_Node_Str""));
  Map<String,ConnectionString> connectionStringMap=slot1.getConnectionStrings();
  Assert.assertFalse(connectionStringMap.containsKey(""String_Node_Str""));
  Assert.assertFalse(connectionStringMap.containsKey(""String_Node_Str""));
  DeploymentSlot slot2=webApp.deploymentSlots().define(SLOT_NAME_2).withConfigurationFromParent().create();
  Assert.assertNotNull(slot2);
  Assert.assertEquals(JavaVersion.JAVA_1_7_0_51,slot2.javaVersion());
  appSettingMap=slot2.getAppSettings();
  Assert.assertEquals(""String_Node_Str"",appSettingMap.get(""String_Node_Str"").value());
  Assert.assertEquals(false,appSettingMap.get(""String_Node_Str"").sticky());
  Assert.assertEquals(""String_Node_Str"",appSettingMap.get(""String_Node_Str"").value());
  Assert.assertEquals(true,appSettingMap.get(""String_Node_Str"").sticky());
  connectionStringMap=slot2.getConnectionStrings();
  Assert.assertEquals(""String_Node_Str"",connectionStringMap.get(""String_Node_Str"").value());
  Assert.assertEquals(false,connectionStringMap.get(""String_Node_Str"").sticky());
  Assert.assertEquals(""String_Node_Str"",connectionStringMap.get(""String_Node_Str"").value());
  Assert.assertEquals(true,connectionStringMap.get(""String_Node_Str"").sticky());
  slot2.update().withoutJava().withPythonVersion(PythonVersion.PYTHON_34).withAppSetting(""String_Node_Str"",""String_Node_Str"").withStickyAppSetting(""String_Node_Str"",""String_Node_Str"").apply();
  Assert.assertNotNull(slot2);
  Assert.assertEquals(JavaVersion.OFF,slot2.javaVersion());
  Assert.assertEquals(PythonVersion.PYTHON_34,slot2.pythonVersion());
  appSettingMap=slot2.getAppSettings();
  Assert.assertEquals(""String_Node_Str"",appSettingMap.get(""String_Node_Str"").value());
  DeploymentSlot slot3=webApp.deploymentSlots().define(SLOT_NAME_3).withConfigurationFromDeploymentSlot(slot2).create();
  Assert.assertNotNull(slot3);
  Assert.assertEquals(JavaVersion.OFF,slot3.javaVersion());
  Assert.assertEquals(PythonVersion.PYTHON_34,slot3.pythonVersion());
  appSettingMap=slot3.getAppSettings();
  Assert.assertEquals(""String_Node_Str"",appSettingMap.get(""String_Node_Str"").value());
  DeploymentSlot deploymentSlot=webApp.deploymentSlots().getByName(SLOT_NAME_3);
  Assert.assertEquals(slot3.id(),deploymentSlot.id());
  List<DeploymentSlot> deploymentSlots=webApp.deploymentSlots().list();
  Assert.assertEquals(3,deploymentSlots.size());
  slot3.swap(slot1.name());
  slot1=webApp.deploymentSlots().getByName(SLOT_NAME_1);
  Assert.assertEquals(JavaVersion.OFF,slot1.javaVersion());
  Assert.assertEquals(PythonVersion.PYTHON_34,slot1.pythonVersion());
  Assert.assertEquals(PythonVersion.PYTHON_27,slot3.pythonVersion());
  Map<String,AppSetting> slot1AppSettings=slot1.getAppSettings();
  Map<String,AppSetting> slot3AppSettings=slot3.getAppSettings();
  Assert.assertEquals(""String_Node_Str"",slot1AppSettings.get(""String_Node_Str"").value());
  Assert.assertEquals(""String_Node_Str"",slot1AppSettings.get(""String_Node_Str"").value());
  Assert.assertEquals(""String_Node_Str"",slot3AppSettings.get(""String_Node_Str"").value());
  Assert.assertEquals(""String_Node_Str"",slot3AppSettings.get(""String_Node_Str"").value());
}","@Test public void canCRUDSwapSlots() throws Exception {
  WebApp webApp=appServiceManager.webApps().define(WEBAPP_NAME).withRegion(Region.US_WEST).withNewResourceGroup(RG_NAME).withNewWindowsPlan(PricingTier.STANDARD_S2).withAppSetting(""String_Node_Str"",""String_Node_Str"").withStickyAppSetting(""String_Node_Str"",""String_Node_Str"").withConnectionString(""String_Node_Str"",""String_Node_Str"",ConnectionStringType.CUSTOM).withStickyConnectionString(""String_Node_Str"",""String_Node_Str"",ConnectionStringType.CUSTOM).withJavaVersion(JavaVersion.JAVA_1_7_0_51).withWebContainer(WebContainer.TOMCAT_7_0_50).create();
  Assert.assertNotNull(webApp);
  Assert.assertEquals(Region.US_WEST,webApp.region());
  DeploymentSlot slot1=webApp.deploymentSlots().define(SLOT_NAME_1).withBrandNewConfiguration().withAppSetting(""String_Node_Str"",""String_Node_Str"").withStickyAppSetting(""String_Node_Str"",""String_Node_Str"").withConnectionString(""String_Node_Str"",""String_Node_Str"",ConnectionStringType.CUSTOM).withStickyConnectionString(""String_Node_Str"",""String_Node_Str"",ConnectionStringType.CUSTOM).withPythonVersion(PythonVersion.PYTHON_27).create();
  Assert.assertNotNull(slot1);
  Assert.assertNotEquals(JavaVersion.JAVA_1_7_0_51,slot1.javaVersion());
  Assert.assertEquals(PythonVersion.PYTHON_27,slot1.pythonVersion());
  Map<String,AppSetting> appSettingMap=slot1.getAppSettings();
  Assert.assertFalse(appSettingMap.containsKey(""String_Node_Str""));
  Assert.assertFalse(appSettingMap.containsKey(""String_Node_Str""));
  Assert.assertEquals(""String_Node_Str"",appSettingMap.get(""String_Node_Str"").value());
  Assert.assertFalse(appSettingMap.get(""String_Node_Str"").sticky());
  Assert.assertEquals(""String_Node_Str"",appSettingMap.get(""String_Node_Str"").value());
  Assert.assertTrue(appSettingMap.get(""String_Node_Str"").sticky());
  Map<String,ConnectionString> connectionStringMap=slot1.getConnectionStrings();
  Assert.assertFalse(connectionStringMap.containsKey(""String_Node_Str""));
  Assert.assertFalse(connectionStringMap.containsKey(""String_Node_Str""));
  Assert.assertEquals(""String_Node_Str"",connectionStringMap.get(""String_Node_Str"").value());
  Assert.assertFalse(connectionStringMap.get(""String_Node_Str"").sticky());
  Assert.assertEquals(""String_Node_Str"",connectionStringMap.get(""String_Node_Str"").value());
  Assert.assertTrue(connectionStringMap.get(""String_Node_Str"").sticky());
  DeploymentSlot slot2=webApp.deploymentSlots().define(SLOT_NAME_2).withConfigurationFromParent().create();
  Assert.assertNotNull(slot2);
  Assert.assertEquals(JavaVersion.JAVA_1_7_0_51,slot2.javaVersion());
  appSettingMap=slot2.getAppSettings();
  Assert.assertEquals(""String_Node_Str"",appSettingMap.get(""String_Node_Str"").value());
  Assert.assertEquals(false,appSettingMap.get(""String_Node_Str"").sticky());
  Assert.assertEquals(""String_Node_Str"",appSettingMap.get(""String_Node_Str"").value());
  Assert.assertEquals(true,appSettingMap.get(""String_Node_Str"").sticky());
  connectionStringMap=slot2.getConnectionStrings();
  Assert.assertEquals(""String_Node_Str"",connectionStringMap.get(""String_Node_Str"").value());
  Assert.assertEquals(false,connectionStringMap.get(""String_Node_Str"").sticky());
  Assert.assertEquals(""String_Node_Str"",connectionStringMap.get(""String_Node_Str"").value());
  Assert.assertEquals(true,connectionStringMap.get(""String_Node_Str"").sticky());
  slot2.update().withoutJava().withPythonVersion(PythonVersion.PYTHON_34).withAppSetting(""String_Node_Str"",""String_Node_Str"").withStickyAppSetting(""String_Node_Str"",""String_Node_Str"").apply();
  Assert.assertNotNull(slot2);
  Assert.assertEquals(JavaVersion.OFF,slot2.javaVersion());
  Assert.assertEquals(PythonVersion.PYTHON_34,slot2.pythonVersion());
  appSettingMap=slot2.getAppSettings();
  Assert.assertEquals(""String_Node_Str"",appSettingMap.get(""String_Node_Str"").value());
  DeploymentSlot slot3=webApp.deploymentSlots().define(SLOT_NAME_3).withConfigurationFromDeploymentSlot(slot2).create();
  Assert.assertNotNull(slot3);
  Assert.assertEquals(JavaVersion.OFF,slot3.javaVersion());
  Assert.assertEquals(PythonVersion.PYTHON_34,slot3.pythonVersion());
  appSettingMap=slot3.getAppSettings();
  Assert.assertEquals(""String_Node_Str"",appSettingMap.get(""String_Node_Str"").value());
  DeploymentSlot deploymentSlot=webApp.deploymentSlots().getByName(SLOT_NAME_3);
  Assert.assertEquals(slot3.id(),deploymentSlot.id());
  List<DeploymentSlot> deploymentSlots=webApp.deploymentSlots().list();
  Assert.assertEquals(3,deploymentSlots.size());
  slot3.swap(slot1.name());
  slot1=webApp.deploymentSlots().getByName(SLOT_NAME_1);
  Assert.assertEquals(JavaVersion.OFF,slot1.javaVersion());
  Assert.assertEquals(PythonVersion.PYTHON_34,slot1.pythonVersion());
  Assert.assertEquals(PythonVersion.PYTHON_27,slot3.pythonVersion());
  Map<String,AppSetting> slot1AppSettings=slot1.getAppSettings();
  Map<String,AppSetting> slot3AppSettings=slot3.getAppSettings();
  Assert.assertEquals(""String_Node_Str"",slot1AppSettings.get(""String_Node_Str"").value());
  Assert.assertEquals(""String_Node_Str"",slot1AppSettings.get(""String_Node_Str"").value());
  Assert.assertEquals(""String_Node_Str"",slot3AppSettings.get(""String_Node_Str"").value());
  Assert.assertEquals(""String_Node_Str"",slot3AppSettings.get(""String_Node_Str"").value());
}"
37599,"@Override public Observable<CdnEndpoint> refreshAsync(){
  final CdnEndpointImpl self=this;
  return refreshAsync().flatMap(new Func1<CdnEndpoint,Observable<CdnEndpoint>>(){
    @Override public Observable<CdnEndpoint> call(    CdnEndpoint cdnEndpoint){
      self.customDomainList.clear();
      self.deletedCustomDomainList.clear();
      return self.parent().manager().inner().customDomains().listByEndpointAsync(self.parent().resourceGroupName(),self.parent().name(),self.name()).flatMap(new Func1<Page<CustomDomainInner>,Observable<CdnEndpoint>>(){
        @Override public Observable<CdnEndpoint> call(        Page<CustomDomainInner> customDomainInnerPage){
          self.customDomainList.addAll(customDomainInnerPage.items());
          return Observable.just((CdnEndpoint)self);
        }
      }
);
    }
  }
);
}","@Override public Observable<CdnEndpoint> refreshAsync(){
  final CdnEndpointImpl self=this;
  return super.refreshAsync().flatMap(new Func1<CdnEndpoint,Observable<CdnEndpoint>>(){
    @Override public Observable<CdnEndpoint> call(    CdnEndpoint cdnEndpoint){
      self.customDomainList.clear();
      self.deletedCustomDomainList.clear();
      return self.parent().manager().inner().customDomains().listByEndpointAsync(self.parent().resourceGroupName(),self.parent().name(),self.name()).flatMap(new Func1<Page<CustomDomainInner>,Observable<CdnEndpoint>>(){
        @Override public Observable<CdnEndpoint> call(        Page<CustomDomainInner> customDomainInnerPage){
          self.customDomainList.addAll(customDomainInnerPage.items());
          return Observable.just((CdnEndpoint)self);
        }
      }
);
    }
  }
);
}"
37600,"private void handleUnManagedOSDiskContainers(){
  final VirtualMachineScaleSetStorageProfile storageProfile=inner().virtualMachineProfile().storageProfile();
  if (isManagedDiskEnabled()) {
    storageProfile.osDisk().withVhdContainers(null);
    return;
  }
  if (isOSDiskFromStoredImage(storageProfile)) {
    storageProfile.osDisk().vhdContainers().clear();
    return;
  }
  String containerName=this.vhdContainerName;
  if (containerName == null) {
    for (    String containerUrl : storageProfile.osDisk().vhdContainers()) {
      containerName=containerUrl.substring(containerUrl.lastIndexOf(""String_Node_Str"") + 1);
      break;
    }
  }
  if (containerName == null) {
    containerName=""String_Node_Str"";
  }
  if (isInCreateMode() && this.creatableStorageAccountKeys.isEmpty() && this.existingStorageAccountsToAssociate.isEmpty()) {
    throw new IllegalStateException(""String_Node_Str"");
  }
  for (  String storageAccountKey : this.creatableStorageAccountKeys) {
    StorageAccount storageAccount=this.<StorageAccount>taskResult(storageAccountKey);
    storageProfile.osDisk().vhdContainers().add(mergePath(storageAccount.endPoints().primary().blob(),containerName));
  }
  for (  StorageAccount storageAccount : this.existingStorageAccountsToAssociate) {
    storageProfile.osDisk().vhdContainers().add(mergePath(storageAccount.endPoints().primary().blob(),containerName));
  }
  this.vhdContainerName=null;
  this.creatableStorageAccountKeys.clear();
  this.existingStorageAccountsToAssociate.clear();
}","private void handleUnManagedOSDiskContainers(){
  final VirtualMachineScaleSetStorageProfile storageProfile=inner().virtualMachineProfile().storageProfile();
  if (isManagedDiskEnabled()) {
    storageProfile.osDisk().withVhdContainers(null);
    return;
  }
  if (isOSDiskFromStoredImage(storageProfile)) {
    storageProfile.osDisk().vhdContainers().clear();
    return;
  }
  String containerName=null;
  for (  String containerUrl : storageProfile.osDisk().vhdContainers()) {
    containerName=containerUrl.substring(containerUrl.lastIndexOf(""String_Node_Str"") + 1);
    break;
  }
  if (containerName == null) {
    containerName=""String_Node_Str"";
  }
  if (isInCreateMode() && this.creatableStorageAccountKeys.isEmpty() && this.existingStorageAccountsToAssociate.isEmpty()) {
    throw new IllegalStateException(""String_Node_Str"");
  }
  for (  String storageAccountKey : this.creatableStorageAccountKeys) {
    StorageAccount storageAccount=this.<StorageAccount>taskResult(storageAccountKey);
    storageProfile.osDisk().vhdContainers().add(mergePath(storageAccount.endPoints().primary().blob(),containerName));
  }
  for (  StorageAccount storageAccount : this.existingStorageAccountsToAssociate) {
    storageProfile.osDisk().vhdContainers().add(mergePath(storageAccount.endPoints().primary().blob(),containerName));
  }
  this.creatableStorageAccountKeys.clear();
  this.existingStorageAccountsToAssociate.clear();
}"
37601,"@Override protected RecordSetInner prepareForUpdate(RecordSetInner resource){
  if (this.inner().mxRecords() != null && this.inner().mxRecords().size() > 0) {
    if (resource.mxRecords() == null) {
      resource.withMxRecords(new ArrayList<MxRecord>());
    }
    resource.mxRecords().addAll(this.inner().mxRecords());
    this.inner().mxRecords().clear();
  }
  if (this.recordSetRemoveInfo.mxRecords().size() > 0) {
    if (resource.mxRecords() != null) {
      for (      MxRecord recordToRemove : this.recordSetRemoveInfo.mxRecords()) {
        for (        MxRecord record : resource.mxRecords()) {
          if (record.exchange().equalsIgnoreCase(recordToRemove.exchange()) && (record.preference() == recordToRemove.preference())) {
            resource.mxRecords().remove(record);
            break;
          }
        }
      }
    }
    this.recordSetRemoveInfo.mxRecords().clear();
  }
  return resource;
}","@Override protected RecordSetInner prepareForUpdate(RecordSetInner resource){
  if (this.inner().mxRecords() != null && this.inner().mxRecords().size() > 0) {
    if (resource.mxRecords() == null) {
      resource.withMxRecords(new ArrayList<MxRecord>());
    }
    resource.mxRecords().addAll(this.inner().mxRecords());
    this.inner().mxRecords().clear();
  }
  if (this.recordSetRemoveInfo.mxRecords().size() > 0) {
    if (resource.mxRecords() != null) {
      for (      MxRecord recordToRemove : this.recordSetRemoveInfo.mxRecords()) {
        for (        MxRecord record : resource.mxRecords()) {
          if (record.exchange().equalsIgnoreCase(recordToRemove.exchange()) && (record.preference().equals(recordToRemove.preference()))) {
            resource.mxRecords().remove(record);
            break;
          }
        }
      }
    }
    this.recordSetRemoveInfo.mxRecords().clear();
  }
  return resource;
}"
37602,"@Override public PublicIPAddressImpl withReverseFqdn(String reverseFqdn){
  this.inner().dnsSettings().withReverseFqdn(reverseFqdn.toLowerCase());
  return this;
}","@Override public PublicIPAddressImpl withReverseFqdn(String reverseFqdn){
  this.inner().dnsSettings().withReverseFqdn(reverseFqdn != null ? reverseFqdn.toLowerCase() : null);
  return this;
}"
37603,"boolean isTerminalMatched(Character charToMatch){
  return terminalChar == charToMatch;
}","boolean isTerminalMatched(Character charToMatch){
  if (terminalChar == null && charToMatch == null) {
    return true;
  }
  return terminalChar != null && charToMatch != null && terminalChar.equals(charToMatch);
}"
37604,"@Override public void beforeGroupCreateOrUpdate(){
  if (parentSqlElasticPool != null) {
    this.addParentDependency(parentSqlElasticPool);
  }
  if (this.importRequestInner != null && this.elasticPoolName() != null) {
    final SqlDatabaseImpl self=this;
    final String epName=this.elasticPoolName();
    this.addPostRunDependent(new FunctionalTaskItem(){
      @Override public Observable<Indexable> call(      final Context context){
        self.importRequestInner=null;
        self.withExistingElasticPool(epName);
        return self.createResourceAsync().flatMap(new Func1<SqlDatabase,Observable<Indexable>>(){
          @Override public Observable<Indexable> call(          SqlDatabase sqlDatabase){
            return context.voidObservable();
          }
        }
);
      }
    }
);
  }
}","@Override public void beforeGroupCreateOrUpdate(){
  if (this.importRequestInner != null && this.elasticPoolName() != null) {
    final SqlDatabaseImpl self=this;
    final String epName=this.elasticPoolName();
    this.addPostRunDependent(new FunctionalTaskItem(){
      @Override public Observable<Indexable> call(      final Context context){
        self.importRequestInner=null;
        self.withExistingElasticPool(epName);
        return self.createResourceAsync().flatMap(new Func1<SqlDatabase,Observable<Indexable>>(){
          @Override public Observable<Indexable> call(          SqlDatabase sqlDatabase){
            return context.voidObservable();
          }
        }
);
      }
    }
);
  }
}"
37605,"/** 
 * Creates an instance of external child resource in-memory.
 * @param parentSqlElasticPool the parent SqlElasticPool this database belongs to
 * @param name        the name of this external child resource
 * @param innerObject reference to the inner object representing this external child resource
 * @param sqlServerManager reference to the SQL server manager that accesses firewall rule operations
 */
SqlDatabaseImpl(TaskGroup.HasTaskGroup parentSqlElasticPool,String name,DatabaseInner innerObject,SqlServerManager sqlServerManager){
  super(name,null,innerObject);
  Objects.requireNonNull(parentSqlElasticPool);
  Objects.requireNonNull(sqlServerManager);
  this.sqlServerManager=sqlServerManager;
  this.sqlElasticPools=new SqlElasticPoolsAsExternalChildResourcesImpl(this.sqlServerManager,""String_Node_Str"");
  this.parentSqlElasticPool=null;
  this.isPatchUpdate=false;
  this.importRequestInner=null;
}","/** 
 * Creates an instance of external child resource in-memory.
 * @param parentSqlElasticPool the parent SqlElasticPool this database belongs to
 * @param name        the name of this external child resource
 * @param innerObject reference to the inner object representing this external child resource
 * @param sqlServerManager reference to the SQL server manager that accesses firewall rule operations
 */
SqlDatabaseImpl(TaskGroup.HasTaskGroup parentSqlElasticPool,String name,DatabaseInner innerObject,SqlServerManager sqlServerManager){
  super(name,null,innerObject);
  Objects.requireNonNull(parentSqlElasticPool);
  Objects.requireNonNull(sqlServerManager);
  this.sqlServerManager=sqlServerManager;
  this.sqlElasticPools=new SqlElasticPoolsAsExternalChildResourcesImpl(this.sqlServerManager,""String_Node_Str"");
  this.isPatchUpdate=false;
  this.importRequestInner=null;
}"
37606,"/** 
 * This method creates a certificate for given password.
 * @param certPath location of certificate file
 * @param pfxPath location of pfx file
 * @param alias User alias
 * @param password alias password
 * @param cnName domain name
 * @throws Exception exceptions from the creation
 */
public static void createCertificate(String certPath,String pfxPath,String alias,String password,String cnName) throws Exception {
  if (new File(pfxPath).exists()) {
    return;
  }
  String validityInDays=""String_Node_Str"";
  String keyAlg=""String_Node_Str"";
  String sigAlg=""String_Node_Str"";
  String keySize=""String_Node_Str"";
  String storeType=""String_Node_Str"";
  String command=""String_Node_Str"";
  String jdkPath=System.getProperty(""String_Node_Str"");
  if (jdkPath != null && !jdkPath.isEmpty()) {
    jdkPath=jdkPath.concat(""String_Node_Str"");
  }
  if (new File(jdkPath).isDirectory()) {
    command=String.format(""String_Node_Str"",jdkPath,File.separator,command);
  }
  String[] commandArgs={command,""String_Node_Str"",""String_Node_Str"",alias,""String_Node_Str"",pfxPath,""String_Node_Str"",password,""String_Node_Str"",validityInDays,""String_Node_Str"",keyAlg,""String_Node_Str"",sigAlg,""String_Node_Str"",keySize,""String_Node_Str"",storeType,""String_Node_Str"",""String_Node_Str"" + cnName,""String_Node_Str"",""String_Node_Str""};
  Utils.cmdInvocation(commandArgs,false);
  File pfxFile=new File(pfxPath);
  if (pfxFile.exists()) {
    String[] certCommandArgs={command,""String_Node_Str"",""String_Node_Str"",alias,""String_Node_Str"",storeType,""String_Node_Str"",pfxPath,""String_Node_Str"",password,""String_Node_Str"",""String_Node_Str"",certPath};
    Utils.cmdInvocation(certCommandArgs,true);
    File cerFile=new File(pfxPath);
    if (!cerFile.exists()) {
      throw new IOException(""String_Node_Str"" + StringUtils.join(""String_Node_Str"",certCommandArgs));
    }
  }
 else {
    throw new IOException(""String_Node_Str"" + StringUtils.join(""String_Node_Str"",commandArgs));
  }
}","/** 
 * This method creates a certificate for given password.
 * @param certPath location of certificate file
 * @param pfxPath location of pfx file
 * @param alias User alias
 * @param password alias password
 * @param cnName domain name
 * @throws Exception exceptions from the creation
 */
public static void createCertificate(String certPath,String pfxPath,String alias,String password,String cnName) throws Exception {
  if (new File(pfxPath).exists()) {
    return;
  }
  String validityInDays=""String_Node_Str"";
  String keyAlg=""String_Node_Str"";
  String sigAlg=""String_Node_Str"";
  String keySize=""String_Node_Str"";
  String storeType=""String_Node_Str"";
  String command=""String_Node_Str"";
  String jdkPath=System.getProperty(""String_Node_Str"");
  if (jdkPath != null && !jdkPath.isEmpty()) {
    jdkPath=jdkPath.concat(""String_Node_Str"");
    if (new File(jdkPath).isDirectory()) {
      command=String.format(""String_Node_Str"",jdkPath,File.separator,command);
    }
  }
 else {
    return;
  }
  String[] commandArgs={command,""String_Node_Str"",""String_Node_Str"",alias,""String_Node_Str"",pfxPath,""String_Node_Str"",password,""String_Node_Str"",validityInDays,""String_Node_Str"",keyAlg,""String_Node_Str"",sigAlg,""String_Node_Str"",keySize,""String_Node_Str"",storeType,""String_Node_Str"",""String_Node_Str"" + cnName,""String_Node_Str"",""String_Node_Str""};
  Utils.cmdInvocation(commandArgs,false);
  File pfxFile=new File(pfxPath);
  if (pfxFile.exists()) {
    String[] certCommandArgs={command,""String_Node_Str"",""String_Node_Str"",alias,""String_Node_Str"",storeType,""String_Node_Str"",pfxPath,""String_Node_Str"",password,""String_Node_Str"",""String_Node_Str"",certPath};
    Utils.cmdInvocation(certCommandArgs,true);
    File cerFile=new File(pfxPath);
    if (!cerFile.exists()) {
      throw new IOException(""String_Node_Str"" + StringUtils.join(""String_Node_Str"",certCommandArgs));
    }
  }
 else {
    throw new IOException(""String_Node_Str"" + StringUtils.join(""String_Node_Str"",commandArgs));
  }
}"
37607,"@Override public final VirtualMachineExtensionImpl withoutTag(String key){
  this.inner().getTags().remove(key);
  return this;
}","@Override public final VirtualMachineExtensionImpl withoutTag(String key){
  if (this.inner().getTags() != null) {
    this.inner().getTags().remove(key);
  }
  return this;
}"
37608,"@Override public final VirtualMachineExtensionImpl withTag(String key,String value){
  this.inner().getTags().put(key,value);
  return this;
}","@Override public final VirtualMachineExtensionImpl withTag(String key,String value){
  if (this.inner().getTags() == null) {
    this.inner().withTags(new HashMap<String,String>());
  }
  this.inner().getTags().put(key,value);
  return this;
}"
37609,"/** 
 * Adds a tag to the resource.
 * @param key the key for the tag
 * @param value the value for the tag
 * @return the next stage of the definition/update
 */
@SuppressWarnings(""String_Node_Str"") public final FluentModelImplT withTag(String key,String value){
  this.inner().getTags().put(key,value);
  return (FluentModelImplT)this;
}","/** 
 * Adds a tag to the resource.
 * @param key the key for the tag
 * @param value the value for the tag
 * @return the next stage of the definition/update
 */
@SuppressWarnings(""String_Node_Str"") public final FluentModelImplT withTag(String key,String value){
  if (this.inner().getTags() == null) {
    this.inner().withTags(new HashMap<String,String>());
  }
  this.inner().getTags().put(key,value);
  return (FluentModelImplT)this;
}"
37610,"/** 
 * Removes a tag from the resource.
 * @param key the key of the tag to remove
 * @return the next stage of the definition/update
 */
@SuppressWarnings(""String_Node_Str"") public final FluentModelImplT withoutTag(String key){
  this.inner().getTags().remove(key);
  return (FluentModelImplT)this;
}","/** 
 * Removes a tag from the resource.
 * @param key the key of the tag to remove
 * @return the next stage of the definition/update
 */
@SuppressWarnings(""String_Node_Str"") public final FluentModelImplT withoutTag(String key){
  if (this.inner().getTags() != null) {
    this.inner().getTags().remove(key);
  }
  return (FluentModelImplT)this;
}"
37611,"/** 
 * Removes a tag from the resource.
 * @param key the key of the tag to remove
 * @return the next stage of the definition/update
 */
@SuppressWarnings(""String_Node_Str"") public final FluentModelImplT withoutTag(String key){
  this.inner().getTags().remove(key);
  return (FluentModelImplT)this;
}","/** 
 * Removes a tag from the resource.
 * @param key the key of the tag to remove
 * @return the next stage of the definition/update
 */
@SuppressWarnings(""String_Node_Str"") public final FluentModelImplT withoutTag(String key){
  if (this.inner().getTags() != null) {
    this.inner().getTags().remove(key);
  }
  return (FluentModelImplT)this;
}"
37612,"/** 
 * Adds a tag to the resource.
 * @param key the key for the tag
 * @param value the value for the tag
 * @return the next stage of the definition/update
 */
@SuppressWarnings(""String_Node_Str"") public final FluentModelImplT withTag(String key,String value){
  this.inner().getTags().put(key,value);
  return (FluentModelImplT)this;
}","/** 
 * Adds a tag to the resource.
 * @param key the key for the tag
 * @param value the value for the tag
 * @return the next stage of the definition/update
 */
@SuppressWarnings(""String_Node_Str"") public final FluentModelImplT withTag(String key,String value){
  if (this.inner().getTags() == null) {
    this.inner().withTags(new HashMap<String,String>());
  }
  this.inner().getTags().put(key,value);
  return (FluentModelImplT)this;
}"
37613,"@Override public SqlDatabaseImpl withTags(Map<String,String> tags){
  this.inner().withTags(tags);
  return this;
}","@Override public SqlDatabaseImpl withTags(Map<String,String> tags){
  this.inner().withTags(new HashMap<>(tags));
  return this;
}"
37614,"@Override public SqlDatabaseImpl withTag(String key,String value){
  this.inner().getTags().put(key,value);
  return this;
}","@Override public SqlDatabaseImpl withTag(String key,String value){
  if (this.inner().getTags() == null) {
    this.inner().withTags(new HashMap<String,String>());
  }
  this.inner().getTags().put(key,value);
  return this;
}"
37615,"@Override public SqlDatabaseImpl withoutTag(String key){
  this.inner().getTags().remove(key);
  return this;
}","@Override public SqlDatabaseImpl withoutTag(String key){
  if (this.inner().getTags() != null) {
    this.inner().getTags().remove(key);
  }
  return this;
}"
37616,"@Override public SqlElasticPoolImpl withTags(Map<String,String> tags){
  this.inner().withTags(tags);
  return this;
}","@Override public SqlElasticPoolImpl withTags(Map<String,String> tags){
  this.inner().withTags(new HashMap<>(tags));
  return this;
}"
37617,"@Override public SqlElasticPoolImpl withTag(String key,String value){
  this.inner().getTags().put(key,value);
  return this;
}","@Override public SqlElasticPoolImpl withTag(String key,String value){
  if (this.inner().getTags() == null) {
    this.inner().withTags(new HashMap<String,String>());
  }
  this.inner().getTags().put(key,value);
  return this;
}"
37618,"@Override public SqlElasticPoolImpl withoutTag(String key){
  this.inner().getTags().remove(key);
  return this;
}","@Override public SqlElasticPoolImpl withoutTag(String key){
  if (this.inner().getTags() != null) {
    this.inner().getTags().remove(key);
  }
  return this;
}"
37619,"@Test public void canUseCoolShortcutsForResourceCreation() throws Exception {
  String database2Name=""String_Node_Str"";
  String database1InEPName=""String_Node_Str"";
  String database2InEPName=""String_Node_Str"";
  String elasticPool2Name=""String_Node_Str"";
  String elasticPool3Name=""String_Node_Str"";
  String elasticPool1Name=SQL_ELASTIC_POOL_NAME;
  SqlServer sqlServer=sqlServerManager.sqlServers().define(SQL_SERVER_NAME).withRegion(Region.US_CENTRAL).withNewResourceGroup(RG_NAME).withAdministratorLogin(""String_Node_Str"").withAdministratorPassword(""String_Node_Str"").withoutAccessFromAzureServices().withNewDatabase(SQL_DATABASE_NAME).withNewDatabase(database2Name).withNewElasticPool(elasticPool1Name,ElasticPoolEditions.STANDARD).withNewElasticPool(elasticPool2Name,ElasticPoolEditions.PREMIUM,database1InEPName,database2InEPName).withNewElasticPool(elasticPool3Name,ElasticPoolEditions.STANDARD).withNewFirewallRule(START_IPADDRESS,END_IPADDRESS,SQL_FIREWALLRULE_NAME).withNewFirewallRule(START_IPADDRESS,END_IPADDRESS).withNewFirewallRule(START_IPADDRESS).create();
  validateMultiCreation(database2Name,database1InEPName,database2InEPName,elasticPool1Name,elasticPool2Name,elasticPool3Name,sqlServer,false);
  elasticPool1Name=SQL_ELASTIC_POOL_NAME + ""String_Node_Str"";
  database2Name=""String_Node_Str"";
  database1InEPName=""String_Node_Str"";
  database2InEPName=""String_Node_Str"";
  elasticPool2Name=""String_Node_Str"";
  elasticPool3Name=""String_Node_Str"";
  sqlServer=sqlServer.update().withNewDatabase(SQL_DATABASE_NAME).withNewDatabase(database2Name).withNewElasticPool(elasticPool1Name,ElasticPoolEditions.STANDARD).withNewElasticPool(elasticPool2Name,ElasticPoolEditions.PREMIUM,database1InEPName,database2InEPName).withNewElasticPool(elasticPool3Name,ElasticPoolEditions.STANDARD).withNewFirewallRule(START_IPADDRESS,END_IPADDRESS,SQL_FIREWALLRULE_NAME).withNewFirewallRule(START_IPADDRESS,END_IPADDRESS).withNewFirewallRule(START_IPADDRESS).apply();
  validateMultiCreation(database2Name,database1InEPName,database2InEPName,elasticPool1Name,elasticPool2Name,elasticPool3Name,sqlServer,true);
  sqlServer.refresh();
  Assert.assertEquals(sqlServer.elasticPools().list().size(),0);
  List<SqlServer> sqlServers=sqlServerManager.sqlServers().listByResourceGroup(RG_NAME);
  boolean found=false;
  for (  SqlServer server : sqlServers) {
    if (server.name().equals(SQL_SERVER_NAME)) {
      found=true;
    }
  }
  Assert.assertTrue(found);
  sqlServer=sqlServerManager.sqlServers().getByResourceGroup(RG_NAME,SQL_SERVER_NAME);
  Assert.assertNotNull(sqlServer);
  sqlServerManager.sqlServers().deleteByResourceGroup(sqlServer.resourceGroupName(),sqlServer.name());
  validateSqlServerNotFound(sqlServer);
}","@Test public void canUseCoolShortcutsForResourceCreation() throws Exception {
  String database2Name=""String_Node_Str"";
  String database1InEPName=""String_Node_Str"";
  String database2InEPName=""String_Node_Str"";
  String elasticPool2Name=""String_Node_Str"";
  String elasticPool3Name=""String_Node_Str"";
  String elasticPool1Name=SQL_ELASTIC_POOL_NAME;
  SqlServer sqlServer=sqlServerManager.sqlServers().define(SQL_SERVER_NAME).withRegion(Region.US_CENTRAL).withNewResourceGroup(RG_NAME).withAdministratorLogin(""String_Node_Str"").withAdministratorPassword(""String_Node_Str"").withoutAccessFromAzureServices().withNewDatabase(SQL_DATABASE_NAME).withNewDatabase(database2Name).withNewElasticPool(elasticPool1Name,ElasticPoolEditions.STANDARD).withNewElasticPool(elasticPool2Name,ElasticPoolEditions.PREMIUM,database1InEPName,database2InEPName).withNewElasticPool(elasticPool3Name,ElasticPoolEditions.STANDARD).withNewFirewallRule(START_IPADDRESS,END_IPADDRESS,SQL_FIREWALLRULE_NAME).withNewFirewallRule(START_IPADDRESS,END_IPADDRESS).withNewFirewallRule(START_IPADDRESS).create();
  validateMultiCreation(database2Name,database1InEPName,database2InEPName,elasticPool1Name,elasticPool2Name,elasticPool3Name,sqlServer,false);
  elasticPool1Name=SQL_ELASTIC_POOL_NAME + ""String_Node_Str"";
  database2Name=""String_Node_Str"";
  database1InEPName=""String_Node_Str"";
  database2InEPName=""String_Node_Str"";
  elasticPool2Name=""String_Node_Str"";
  elasticPool3Name=""String_Node_Str"";
  sqlServer=sqlServer.update().withNewDatabase(SQL_DATABASE_NAME).withNewDatabase(database2Name).withNewElasticPool(elasticPool1Name,ElasticPoolEditions.STANDARD).withNewElasticPool(elasticPool2Name,ElasticPoolEditions.PREMIUM,database1InEPName,database2InEPName).withNewElasticPool(elasticPool3Name,ElasticPoolEditions.STANDARD).withNewFirewallRule(START_IPADDRESS,END_IPADDRESS,SQL_FIREWALLRULE_NAME).withNewFirewallRule(START_IPADDRESS,END_IPADDRESS).withNewFirewallRule(START_IPADDRESS).withTag(""String_Node_Str"",""String_Node_Str"").apply();
  validateMultiCreation(database2Name,database1InEPName,database2InEPName,elasticPool1Name,elasticPool2Name,elasticPool3Name,sqlServer,true);
  sqlServer.refresh();
  Assert.assertEquals(sqlServer.elasticPools().list().size(),0);
  List<SqlServer> sqlServers=sqlServerManager.sqlServers().listByResourceGroup(RG_NAME);
  boolean found=false;
  for (  SqlServer server : sqlServers) {
    if (server.name().equals(SQL_SERVER_NAME)) {
      found=true;
    }
  }
  Assert.assertTrue(found);
  sqlServer=sqlServerManager.sqlServers().getByResourceGroup(RG_NAME,SQL_SERVER_NAME);
  Assert.assertNotNull(sqlServer);
  sqlServerManager.sqlServers().deleteByResourceGroup(sqlServer.resourceGroupName(),sqlServer.name());
  validateSqlServerNotFound(sqlServer);
}"
37620,"@Test public void canCRUDSqlServerWithImportDatabase() throws Exception {
  if (isPlaybackMode()) {
    return;
  }
  String rgName=RG_NAME;
  String sqlServerName=SQL_SERVER_NAME;
  String sqlServerAdminName=""String_Node_Str"";
  String sqlServerAdminPassword=""String_Node_Str"";
  String id=SdkContext.randomUuid();
  String storageName=SdkContext.randomResourceName(SQL_SERVER_NAME,22);
  SqlServer sqlServer=sqlServerManager.sqlServers().define(sqlServerName).withRegion(Region.US_EAST).withNewResourceGroup(rgName).withAdministratorLogin(sqlServerAdminName).withAdministratorPassword(sqlServerAdminPassword).withActiveDirectoryAdministrator(""String_Node_Str"",id).create();
  SqlDatabase dbFromSample=sqlServer.databases().define(""String_Node_Str"").fromSample(SampleName.ADVENTURE_WORKS_LT).withBasicEdition().create();
  Assert.assertNotNull(dbFromSample);
  Assert.assertEquals(DatabaseEditions.BASIC,dbFromSample.edition());
  SqlDatabaseImportExportResponse exportedDB;
  StorageAccount storageAccount=storageManager.storageAccounts().getByResourceGroup(sqlServer.resourceGroupName(),storageName);
  if (storageAccount == null) {
    Creatable<StorageAccount> storageAccountCreatable=storageManager.storageAccounts().define(storageName).withRegion(sqlServer.regionName()).withExistingResourceGroup(sqlServer.resourceGroupName());
    exportedDB=dbFromSample.exportTo(storageAccountCreatable,""String_Node_Str"",""String_Node_Str"").withSqlAdministratorLoginAndPassword(sqlServerAdminName,sqlServerAdminPassword).execute();
    storageAccount=storageManager.storageAccounts().getByResourceGroup(sqlServer.resourceGroupName(),storageName);
  }
 else {
    exportedDB=dbFromSample.exportTo(storageAccount,""String_Node_Str"",""String_Node_Str"").withSqlAdministratorLoginAndPassword(sqlServerAdminName,sqlServerAdminPassword).execute();
  }
  SqlDatabase dbFromImport=sqlServer.databases().define(""String_Node_Str"").defineElasticPool(""String_Node_Str"").withBasicPool().attach().importFrom(storageAccount,""String_Node_Str"",""String_Node_Str"").withSqlAdministratorLoginAndPassword(sqlServerAdminName,sqlServerAdminPassword).create();
  Assert.assertNotNull(dbFromImport);
  Assert.assertEquals(""String_Node_Str"",dbFromImport.elasticPoolName());
  dbFromImport.delete();
  dbFromSample.delete();
  sqlServer.elasticPools().delete(""String_Node_Str"");
  sqlServerManager.sqlServers().deleteByResourceGroup(rgName,sqlServerName);
}","@Test public void canCRUDSqlServerWithImportDatabase() throws Exception {
  if (isPlaybackMode()) {
    return;
  }
  String rgName=RG_NAME;
  String sqlServerName=SQL_SERVER_NAME;
  String sqlServerAdminName=""String_Node_Str"";
  String sqlServerAdminPassword=""String_Node_Str"";
  String id=SdkContext.randomUuid();
  String storageName=SdkContext.randomResourceName(SQL_SERVER_NAME,22);
  SqlServer sqlServer=sqlServerManager.sqlServers().define(sqlServerName).withRegion(Region.US_EAST).withNewResourceGroup(rgName).withAdministratorLogin(sqlServerAdminName).withAdministratorPassword(sqlServerAdminPassword).withActiveDirectoryAdministrator(""String_Node_Str"",id).create();
  SqlDatabase dbFromSample=sqlServer.databases().define(""String_Node_Str"").fromSample(SampleName.ADVENTURE_WORKS_LT).withBasicEdition().withTag(""String_Node_Str"",""String_Node_Str"").create();
  Assert.assertNotNull(dbFromSample);
  Assert.assertEquals(DatabaseEditions.BASIC,dbFromSample.edition());
  SqlDatabaseImportExportResponse exportedDB;
  StorageAccount storageAccount=storageManager.storageAccounts().getByResourceGroup(sqlServer.resourceGroupName(),storageName);
  if (storageAccount == null) {
    Creatable<StorageAccount> storageAccountCreatable=storageManager.storageAccounts().define(storageName).withRegion(sqlServer.regionName()).withExistingResourceGroup(sqlServer.resourceGroupName());
    exportedDB=dbFromSample.exportTo(storageAccountCreatable,""String_Node_Str"",""String_Node_Str"").withSqlAdministratorLoginAndPassword(sqlServerAdminName,sqlServerAdminPassword).execute();
    storageAccount=storageManager.storageAccounts().getByResourceGroup(sqlServer.resourceGroupName(),storageName);
  }
 else {
    exportedDB=dbFromSample.exportTo(storageAccount,""String_Node_Str"",""String_Node_Str"").withSqlAdministratorLoginAndPassword(sqlServerAdminName,sqlServerAdminPassword).execute();
  }
  SqlDatabase dbFromImport=sqlServer.databases().define(""String_Node_Str"").defineElasticPool(""String_Node_Str"").withBasicPool().attach().importFrom(storageAccount,""String_Node_Str"",""String_Node_Str"").withSqlAdministratorLoginAndPassword(sqlServerAdminName,sqlServerAdminPassword).withTag(""String_Node_Str"",""String_Node_Str"").create();
  Assert.assertNotNull(dbFromImport);
  Assert.assertEquals(""String_Node_Str"",dbFromImport.elasticPoolName());
  dbFromImport.delete();
  dbFromSample.delete();
  sqlServer.elasticPools().delete(""String_Node_Str"");
  sqlServerManager.sqlServers().deleteByResourceGroup(rgName,sqlServerName);
}"
37621,"@Test public void canCRUDSqlServerWithFirewallRule() throws Exception {
  String rgName=RG_NAME;
  String sqlServerName=SQL_SERVER_NAME;
  String sqlServerAdminName=""String_Node_Str"";
  String id=SdkContext.randomUuid();
  SqlServer sqlServer=sqlServerManager.sqlServers().define(SQL_SERVER_NAME).withRegion(Region.US_CENTRAL).withNewResourceGroup(RG_NAME).withAdministratorLogin(sqlServerAdminName).withAdministratorPassword(""String_Node_Str"").withActiveDirectoryAdministrator(""String_Node_Str"",id).withoutAccessFromAzureServices().defineFirewallRule(""String_Node_Str"").withIPAddress(""String_Node_Str"").attach().create();
  Assert.assertEquals(sqlServerAdminName,sqlServer.administratorLogin());
  Assert.assertEquals(""String_Node_Str"",sqlServer.kind());
  Assert.assertEquals(""String_Node_Str"",sqlServer.version());
  sqlServer=sqlServerManager.sqlServers().getByResourceGroup(RG_NAME,SQL_SERVER_NAME);
  Assert.assertEquals(sqlServerAdminName,sqlServer.administratorLogin());
  Assert.assertEquals(""String_Node_Str"",sqlServer.kind());
  Assert.assertEquals(""String_Node_Str"",sqlServer.version());
  SqlActiveDirectoryAdministrator sqlADAdmin=sqlServer.getActiveDirectoryAdministrator();
  Assert.assertNotNull(sqlADAdmin);
  Assert.assertEquals(""String_Node_Str"",sqlADAdmin.signInName());
  Assert.assertNotNull(sqlADAdmin.id());
  Assert.assertEquals(""String_Node_Str"",sqlADAdmin.administratorType());
  sqlADAdmin=sqlServer.setActiveDirectoryAdministrator(""String_Node_Str"",id);
  Assert.assertNotNull(sqlADAdmin);
  Assert.assertEquals(""String_Node_Str"",sqlADAdmin.signInName());
  Assert.assertNotNull(sqlADAdmin.id());
  Assert.assertEquals(""String_Node_Str"",sqlADAdmin.administratorType());
  sqlServer.removeActiveDirectoryAdministrator();
  sqlADAdmin=sqlServer.getActiveDirectoryAdministrator();
  Assert.assertNull(sqlADAdmin);
  SqlFirewallRule firewallRule=sqlServerManager.sqlServers().firewallRules().getBySqlServer(RG_NAME,SQL_SERVER_NAME,""String_Node_Str"");
  Assert.assertEquals(""String_Node_Str"",firewallRule.startIPAddress());
  Assert.assertEquals(""String_Node_Str"",firewallRule.endIPAddress());
  firewallRule=sqlServerManager.sqlServers().firewallRules().getBySqlServer(RG_NAME,SQL_SERVER_NAME,""String_Node_Str"");
  Assert.assertNull(firewallRule);
  sqlServer.enableAccessFromAzureServices();
  firewallRule=sqlServerManager.sqlServers().firewallRules().getBySqlServer(RG_NAME,SQL_SERVER_NAME,""String_Node_Str"");
  Assert.assertEquals(""String_Node_Str"",firewallRule.startIPAddress());
  Assert.assertEquals(""String_Node_Str"",firewallRule.endIPAddress());
  sqlServer.update().withNewFirewallRule(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"").apply();
  sqlServer.firewallRules().delete(""String_Node_Str"");
  Assert.assertNull(sqlServer.firewallRules().get(""String_Node_Str""));
  firewallRule=sqlServerManager.sqlServers().firewallRules().define(""String_Node_Str"").withExistingSqlServer(RG_NAME,SQL_SERVER_NAME).withIPAddress(""String_Node_Str"").create();
  Assert.assertEquals(""String_Node_Str"",firewallRule.startIPAddress());
  Assert.assertEquals(""String_Node_Str"",firewallRule.endIPAddress());
  firewallRule=firewallRule.update().withStartIPAddress(""String_Node_Str"").apply();
  Assert.assertEquals(""String_Node_Str"",firewallRule.startIPAddress());
  Assert.assertEquals(""String_Node_Str"",firewallRule.endIPAddress());
  sqlServer.firewallRules().delete(""String_Node_Str"");
  firewallRule=sqlServerManager.sqlServers().firewallRules().getBySqlServer(RG_NAME,SQL_SERVER_NAME,""String_Node_Str"");
  Assert.assertNull(firewallRule);
  firewallRule=sqlServer.firewallRules().define(""String_Node_Str"").withIPAddress(""String_Node_Str"").create();
  Assert.assertEquals(""String_Node_Str"",firewallRule.startIPAddress());
  Assert.assertEquals(""String_Node_Str"",firewallRule.endIPAddress());
  firewallRule.delete();
}","@Test public void canCRUDSqlServerWithFirewallRule() throws Exception {
  String rgName=RG_NAME;
  String sqlServerName=SQL_SERVER_NAME;
  String sqlServerAdminName=""String_Node_Str"";
  String id=SdkContext.randomUuid();
  SqlServer sqlServer=sqlServerManager.sqlServers().define(SQL_SERVER_NAME).withRegion(Region.US_CENTRAL).withNewResourceGroup(RG_NAME).withAdministratorLogin(sqlServerAdminName).withAdministratorPassword(""String_Node_Str"").withActiveDirectoryAdministrator(""String_Node_Str"",id).withoutAccessFromAzureServices().defineFirewallRule(""String_Node_Str"").withIPAddress(""String_Node_Str"").attach().withTag(""String_Node_Str"",""String_Node_Str"").create();
  Assert.assertEquals(sqlServerAdminName,sqlServer.administratorLogin());
  Assert.assertEquals(""String_Node_Str"",sqlServer.kind());
  Assert.assertEquals(""String_Node_Str"",sqlServer.version());
  sqlServer=sqlServerManager.sqlServers().getByResourceGroup(RG_NAME,SQL_SERVER_NAME);
  Assert.assertEquals(sqlServerAdminName,sqlServer.administratorLogin());
  Assert.assertEquals(""String_Node_Str"",sqlServer.kind());
  Assert.assertEquals(""String_Node_Str"",sqlServer.version());
  SqlActiveDirectoryAdministrator sqlADAdmin=sqlServer.getActiveDirectoryAdministrator();
  Assert.assertNotNull(sqlADAdmin);
  Assert.assertEquals(""String_Node_Str"",sqlADAdmin.signInName());
  Assert.assertNotNull(sqlADAdmin.id());
  Assert.assertEquals(""String_Node_Str"",sqlADAdmin.administratorType());
  sqlADAdmin=sqlServer.setActiveDirectoryAdministrator(""String_Node_Str"",id);
  Assert.assertNotNull(sqlADAdmin);
  Assert.assertEquals(""String_Node_Str"",sqlADAdmin.signInName());
  Assert.assertNotNull(sqlADAdmin.id());
  Assert.assertEquals(""String_Node_Str"",sqlADAdmin.administratorType());
  sqlServer.removeActiveDirectoryAdministrator();
  sqlADAdmin=sqlServer.getActiveDirectoryAdministrator();
  Assert.assertNull(sqlADAdmin);
  SqlFirewallRule firewallRule=sqlServerManager.sqlServers().firewallRules().getBySqlServer(RG_NAME,SQL_SERVER_NAME,""String_Node_Str"");
  Assert.assertEquals(""String_Node_Str"",firewallRule.startIPAddress());
  Assert.assertEquals(""String_Node_Str"",firewallRule.endIPAddress());
  firewallRule=sqlServerManager.sqlServers().firewallRules().getBySqlServer(RG_NAME,SQL_SERVER_NAME,""String_Node_Str"");
  Assert.assertNull(firewallRule);
  sqlServer.enableAccessFromAzureServices();
  firewallRule=sqlServerManager.sqlServers().firewallRules().getBySqlServer(RG_NAME,SQL_SERVER_NAME,""String_Node_Str"");
  Assert.assertEquals(""String_Node_Str"",firewallRule.startIPAddress());
  Assert.assertEquals(""String_Node_Str"",firewallRule.endIPAddress());
  sqlServer.update().withNewFirewallRule(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"").apply();
  sqlServer.firewallRules().delete(""String_Node_Str"");
  Assert.assertNull(sqlServer.firewallRules().get(""String_Node_Str""));
  firewallRule=sqlServerManager.sqlServers().firewallRules().define(""String_Node_Str"").withExistingSqlServer(RG_NAME,SQL_SERVER_NAME).withIPAddress(""String_Node_Str"").create();
  Assert.assertEquals(""String_Node_Str"",firewallRule.startIPAddress());
  Assert.assertEquals(""String_Node_Str"",firewallRule.endIPAddress());
  firewallRule=firewallRule.update().withStartIPAddress(""String_Node_Str"").apply();
  Assert.assertEquals(""String_Node_Str"",firewallRule.startIPAddress());
  Assert.assertEquals(""String_Node_Str"",firewallRule.endIPAddress());
  sqlServer.firewallRules().delete(""String_Node_Str"");
  firewallRule=sqlServerManager.sqlServers().firewallRules().getBySqlServer(RG_NAME,SQL_SERVER_NAME,""String_Node_Str"");
  Assert.assertNull(firewallRule);
  firewallRule=sqlServer.firewallRules().define(""String_Node_Str"").withIPAddress(""String_Node_Str"").create();
  Assert.assertEquals(""String_Node_Str"",firewallRule.startIPAddress());
  Assert.assertEquals(""String_Node_Str"",firewallRule.endIPAddress());
  firewallRule.delete();
}"
37622,"@Test public void canCRUDSqlDatabaseWithElasticPool() throws Exception {
  SqlServer sqlServer=createSqlServer();
  Creatable<SqlElasticPool> sqlElasticPoolCreatable=sqlServer.elasticPools().define(SQL_ELASTIC_POOL_NAME).withEdition(ElasticPoolEditions.STANDARD);
  Observable<Indexable> resourceStream=sqlServer.databases().define(SQL_DATABASE_NAME).withNewElasticPool(sqlElasticPoolCreatable).withCollation(COLLATION).createAsync();
  SqlDatabase sqlDatabase=Utils.<SqlDatabase>rootResource(resourceStream).toBlocking().first();
  validateSqlDatabase(sqlDatabase,SQL_DATABASE_NAME);
  sqlServer=sqlServerManager.sqlServers().getByResourceGroup(RG_NAME,SQL_SERVER_NAME);
  validateSqlServer(sqlServer);
  SqlElasticPool elasticPool=sqlServer.elasticPools().get(SQL_ELASTIC_POOL_NAME);
  validateSqlElasticPool(elasticPool);
  validateSqlDatabaseWithElasticPool(sqlServer.databases().get(SQL_DATABASE_NAME),SQL_DATABASE_NAME);
  validateListSqlDatabase(sqlServer.databases().list());
  sqlDatabase.update().withoutElasticPool().withEdition(DatabaseEditions.STANDARD).withServiceObjective(ServiceObjectiveName.S3).apply();
  sqlDatabase=sqlServer.databases().get(SQL_DATABASE_NAME);
  Assert.assertNull(sqlDatabase.elasticPoolName());
  sqlDatabase.update().withEdition(DatabaseEditions.PREMIUM).withServiceObjective(ServiceObjectiveName.P1).apply();
  sqlDatabase=sqlServer.databases().get(SQL_DATABASE_NAME);
  Assert.assertEquals(sqlDatabase.edition(),DatabaseEditions.PREMIUM);
  Assert.assertEquals(sqlDatabase.serviceLevelObjective(),ServiceObjectiveName.P1);
  sqlDatabase.update().withServiceObjective(ServiceObjectiveName.P2).apply();
  sqlDatabase=sqlServer.databases().get(SQL_DATABASE_NAME);
  Assert.assertEquals(sqlDatabase.serviceLevelObjective(),ServiceObjectiveName.P2);
  Assert.assertEquals(sqlDatabase.requestedServiceObjectiveName(),ServiceObjectiveName.P2);
  sqlDatabase.update().withMaxSizeBytes(268435456000L).apply();
  sqlDatabase=sqlServer.databases().get(SQL_DATABASE_NAME);
  Assert.assertEquals(sqlDatabase.maxSizeBytes(),268435456000L);
  sqlDatabase.update().withExistingElasticPool(SQL_ELASTIC_POOL_NAME).apply();
  sqlDatabase=sqlServer.databases().get(SQL_DATABASE_NAME);
  Assert.assertEquals(sqlDatabase.elasticPoolName(),SQL_ELASTIC_POOL_NAME);
  Assert.assertNotNull(elasticPool.listActivities());
  Assert.assertNotNull(elasticPool.listDatabaseActivities());
  List<SqlDatabase> databasesInElasticPool=elasticPool.listDatabases();
  Assert.assertNotNull(databasesInElasticPool);
  Assert.assertEquals(databasesInElasticPool.size(),1);
  SqlDatabase databaseInElasticPool=elasticPool.getDatabase(SQL_DATABASE_NAME);
  validateSqlDatabase(databaseInElasticPool,SQL_DATABASE_NAME);
  databaseInElasticPool.refresh();
  SqlDatabase db_which_does_not_exist=elasticPool.getDatabase(""String_Node_Str"");
  Assert.assertNull(db_which_does_not_exist);
  sqlServer.databases().delete(SQL_DATABASE_NAME);
  validateSqlDatabaseNotFound(SQL_DATABASE_NAME);
  SqlElasticPool sqlElasticPool=sqlServer.elasticPools().get(SQL_ELASTIC_POOL_NAME);
  resourceStream=sqlServer.databases().define(""String_Node_Str"").withExistingElasticPool(sqlElasticPool).withCollation(COLLATION).createAsync();
  sqlDatabase=Utils.<SqlDatabase>rootResource(resourceStream).toBlocking().first();
  sqlServer.databases().delete(sqlDatabase.name());
  validateSqlDatabaseNotFound(""String_Node_Str"");
  sqlServer.elasticPools().delete(SQL_ELASTIC_POOL_NAME);
  sqlServerManager.sqlServers().deleteByResourceGroup(sqlServer.resourceGroupName(),sqlServer.name());
  validateSqlServerNotFound(sqlServer);
}","@Test public void canCRUDSqlDatabaseWithElasticPool() throws Exception {
  SqlServer sqlServer=createSqlServer();
  Creatable<SqlElasticPool> sqlElasticPoolCreatable=sqlServer.elasticPools().define(SQL_ELASTIC_POOL_NAME).withEdition(ElasticPoolEditions.STANDARD).withTag(""String_Node_Str"",""String_Node_Str"");
  Observable<Indexable> resourceStream=sqlServer.databases().define(SQL_DATABASE_NAME).withNewElasticPool(sqlElasticPoolCreatable).withCollation(COLLATION).createAsync();
  SqlDatabase sqlDatabase=Utils.<SqlDatabase>rootResource(resourceStream).toBlocking().first();
  validateSqlDatabase(sqlDatabase,SQL_DATABASE_NAME);
  sqlServer=sqlServerManager.sqlServers().getByResourceGroup(RG_NAME,SQL_SERVER_NAME);
  validateSqlServer(sqlServer);
  SqlElasticPool elasticPool=sqlServer.elasticPools().get(SQL_ELASTIC_POOL_NAME);
  validateSqlElasticPool(elasticPool);
  validateSqlDatabaseWithElasticPool(sqlServer.databases().get(SQL_DATABASE_NAME),SQL_DATABASE_NAME);
  validateListSqlDatabase(sqlServer.databases().list());
  sqlDatabase.update().withoutElasticPool().withEdition(DatabaseEditions.STANDARD).withServiceObjective(ServiceObjectiveName.S3).apply();
  sqlDatabase=sqlServer.databases().get(SQL_DATABASE_NAME);
  Assert.assertNull(sqlDatabase.elasticPoolName());
  sqlDatabase.update().withEdition(DatabaseEditions.PREMIUM).withServiceObjective(ServiceObjectiveName.P1).apply();
  sqlDatabase=sqlServer.databases().get(SQL_DATABASE_NAME);
  Assert.assertEquals(sqlDatabase.edition(),DatabaseEditions.PREMIUM);
  Assert.assertEquals(sqlDatabase.serviceLevelObjective(),ServiceObjectiveName.P1);
  sqlDatabase.update().withServiceObjective(ServiceObjectiveName.P2).apply();
  sqlDatabase=sqlServer.databases().get(SQL_DATABASE_NAME);
  Assert.assertEquals(sqlDatabase.serviceLevelObjective(),ServiceObjectiveName.P2);
  Assert.assertEquals(sqlDatabase.requestedServiceObjectiveName(),ServiceObjectiveName.P2);
  sqlDatabase.update().withMaxSizeBytes(268435456000L).apply();
  sqlDatabase=sqlServer.databases().get(SQL_DATABASE_NAME);
  Assert.assertEquals(sqlDatabase.maxSizeBytes(),268435456000L);
  sqlDatabase.update().withExistingElasticPool(SQL_ELASTIC_POOL_NAME).apply();
  sqlDatabase=sqlServer.databases().get(SQL_DATABASE_NAME);
  Assert.assertEquals(sqlDatabase.elasticPoolName(),SQL_ELASTIC_POOL_NAME);
  Assert.assertNotNull(elasticPool.listActivities());
  Assert.assertNotNull(elasticPool.listDatabaseActivities());
  List<SqlDatabase> databasesInElasticPool=elasticPool.listDatabases();
  Assert.assertNotNull(databasesInElasticPool);
  Assert.assertEquals(databasesInElasticPool.size(),1);
  SqlDatabase databaseInElasticPool=elasticPool.getDatabase(SQL_DATABASE_NAME);
  validateSqlDatabase(databaseInElasticPool,SQL_DATABASE_NAME);
  databaseInElasticPool.refresh();
  SqlDatabase db_which_does_not_exist=elasticPool.getDatabase(""String_Node_Str"");
  Assert.assertNull(db_which_does_not_exist);
  sqlServer.databases().delete(SQL_DATABASE_NAME);
  validateSqlDatabaseNotFound(SQL_DATABASE_NAME);
  SqlElasticPool sqlElasticPool=sqlServer.elasticPools().get(SQL_ELASTIC_POOL_NAME);
  resourceStream=sqlServer.databases().define(""String_Node_Str"").withExistingElasticPool(sqlElasticPool).withCollation(COLLATION).createAsync();
  sqlDatabase=Utils.<SqlDatabase>rootResource(resourceStream).toBlocking().first();
  sqlServer.databases().delete(sqlDatabase.name());
  validateSqlDatabaseNotFound(""String_Node_Str"");
  sqlServer.elasticPools().delete(SQL_ELASTIC_POOL_NAME);
  sqlServerManager.sqlServers().deleteByResourceGroup(sqlServer.resourceGroupName(),sqlServer.name());
  validateSqlServerNotFound(sqlServer);
}"
37623,"@Test public void canCRUDSqlElasticPool() throws Exception {
  SqlServer sqlServer=createSqlServer();
  sqlServer=sqlServerManager.sqlServers().getByResourceGroup(RG_NAME,SQL_SERVER_NAME);
  validateSqlServer(sqlServer);
  Observable<Indexable> resourceStream=sqlServer.elasticPools().define(SQL_ELASTIC_POOL_NAME).withEdition(ElasticPoolEditions.STANDARD).createAsync();
  SqlElasticPool sqlElasticPool=Utils.<SqlElasticPool>rootResource(resourceStream).toBlocking().first();
  validateSqlElasticPool(sqlElasticPool);
  Assert.assertEquals(sqlElasticPool.listDatabases().size(),0);
  sqlElasticPool=sqlElasticPool.update().withDtu(100).withDatabaseDtuMax(20).withDatabaseDtuMin(10).withStorageCapacity(102400).withNewDatabase(SQL_DATABASE_NAME).apply();
  validateSqlElasticPool(sqlElasticPool);
  Assert.assertEquals(sqlElasticPool.listDatabases().size(),1);
  validateSqlElasticPool(sqlServer.elasticPools().get(SQL_ELASTIC_POOL_NAME));
  validateListSqlElasticPool(sqlServer.elasticPools().list());
  sqlServer.databases().delete(SQL_DATABASE_NAME);
  sqlServer.elasticPools().delete(SQL_ELASTIC_POOL_NAME);
  validateSqlElasticPoolNotFound(sqlServer,SQL_ELASTIC_POOL_NAME);
  resourceStream=sqlServer.elasticPools().define(""String_Node_Str"").withEdition(ElasticPoolEditions.STANDARD).createAsync();
  sqlElasticPool=Utils.<SqlElasticPool>rootResource(resourceStream).toBlocking().first();
  sqlServer.elasticPools().delete(sqlElasticPool.name());
  validateSqlElasticPoolNotFound(sqlServer,""String_Node_Str"");
  sqlServerManager.sqlServers().deleteByResourceGroup(sqlServer.resourceGroupName(),sqlServer.name());
  validateSqlServerNotFound(sqlServer);
}","@Test public void canCRUDSqlElasticPool() throws Exception {
  SqlServer sqlServer=createSqlServer();
  sqlServer=sqlServerManager.sqlServers().getByResourceGroup(RG_NAME,SQL_SERVER_NAME);
  validateSqlServer(sqlServer);
  Observable<Indexable> resourceStream=sqlServer.elasticPools().define(SQL_ELASTIC_POOL_NAME).withEdition(ElasticPoolEditions.STANDARD).withTag(""String_Node_Str"",""String_Node_Str"").createAsync();
  SqlElasticPool sqlElasticPool=Utils.<SqlElasticPool>rootResource(resourceStream).toBlocking().first();
  validateSqlElasticPool(sqlElasticPool);
  Assert.assertEquals(sqlElasticPool.listDatabases().size(),0);
  sqlElasticPool=sqlElasticPool.update().withDtu(100).withDatabaseDtuMax(20).withDatabaseDtuMin(10).withStorageCapacity(102400).withNewDatabase(SQL_DATABASE_NAME).withTag(""String_Node_Str"",""String_Node_Str"").apply();
  validateSqlElasticPool(sqlElasticPool);
  Assert.assertEquals(sqlElasticPool.listDatabases().size(),1);
  validateSqlElasticPool(sqlServer.elasticPools().get(SQL_ELASTIC_POOL_NAME));
  validateListSqlElasticPool(sqlServer.elasticPools().list());
  sqlServer.databases().delete(SQL_DATABASE_NAME);
  sqlServer.elasticPools().delete(SQL_ELASTIC_POOL_NAME);
  validateSqlElasticPoolNotFound(sqlServer,SQL_ELASTIC_POOL_NAME);
  resourceStream=sqlServer.elasticPools().define(""String_Node_Str"").withEdition(ElasticPoolEditions.STANDARD).createAsync();
  sqlElasticPool=Utils.<SqlElasticPool>rootResource(resourceStream).toBlocking().first();
  sqlServer.elasticPools().delete(sqlElasticPool.name());
  validateSqlElasticPoolNotFound(sqlServer,""String_Node_Str"");
  sqlServerManager.sqlServers().deleteByResourceGroup(sqlServer.resourceGroupName(),sqlServer.name());
  validateSqlServerNotFound(sqlServer);
}"
37624,"/** 
 * @return list with task entries in this task group
 */
private List<TaskGroupEntry<TaskItem>> entriesSnapshot(){
  List<TaskGroupEntry<TaskItem>> entries=new ArrayList<>();
  super.prepareForEnumeration();
  for (TaskGroupEntry<TaskItem> current=super.getNext(); current != null; current=super.getNext()) {
    entries.add(current);
    super.reportCompletion(current);
  }
  return entries;
}","/** 
 * @return list with current task entries in this task group
 */
private List<TaskGroupEntry<TaskItem>> entriesSnapshot(){
  List<TaskGroupEntry<TaskItem>> entries=new ArrayList<>();
  super.prepareForEnumeration();
  for (TaskGroupEntry<TaskItem> current=super.getNext(); current != null; current=super.getNext()) {
    entries.add(current);
    super.reportCompletion(current);
  }
  return entries;
}"
37625,"/** 
 * @return the TaskGroup this invocation context associated with.
 */
public TaskGroup taskGroup(){
  return this.taskGroup;
}","/** 
 * @return the wrapped proxy task group.
 */
TaskGroup taskGroup(){
  return this.proxyTaskGroup;
}"
37626,"@Test public void testTaskGroupInvocationShouldInvokePostRunDependentTaskGroup(){
  final LinkedList<String> group1Items=new LinkedList<>();
  final TaskGroup group1=createSampleTaskGroup(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",group1Items);
  final LinkedList<String> group2Items=new LinkedList<>();
  final TaskGroup group2=createSampleTaskGroup(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",group2Items);
  group1.addPostRunDependentTaskGroup(group2);
  group1Items.addAll(group2Items);
  group1.invokeAsync(group1.newInvocationContext()).subscribe(new Action1<Indexable>(){
    @Override public void call(    Indexable value){
      StringIndexable stringIndexable=toStringIndexable(value);
      Assert.assertTrue(group1Items.contains(stringIndexable.str()));
      group1Items.remove(stringIndexable.str());
    }
  }
);
  Assert.assertEquals(0,group1Items.size());
  Map<String,Set<String>> shouldNotSee=new HashMap<>();
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{}));
  Set<String> seen=new HashSet<>();
  group1.proxyTaskGroupWrapper.proxyTaskGroup().prepareForEnumeration();
  for (TaskGroupEntry<TaskItem> entry=group1.proxyTaskGroupWrapper.proxyTaskGroup().getNext(); entry != null; entry=group1.proxyTaskGroupWrapper.proxyTaskGroup().getNext()) {
    Assert.assertTrue(shouldNotSee.containsKey(entry.key()));
    Assert.assertFalse(seen.contains(entry.key()));
    Sets.SetView<String> common=Sets.intersection(shouldNotSee.get(entry.key()),seen);
    if (common.size() > 0) {
      Assert.assertTrue(""String_Node_Str"" + common + ""String_Node_Str""+ entry.key(),false);
    }
    seen.add(entry.key());
    group1.proxyTaskGroupWrapper.proxyTaskGroup().reportCompletion(entry);
  }
  Assert.assertEquals(13,seen.size());
  Set<String> expectedToSee=new HashSet<>();
  expectedToSee.addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  Sets.SetView<String> diff=Sets.difference(seen,expectedToSee);
  Assert.assertEquals(0,diff.size());
  group1.invokeAsync(group1.newInvocationContext()).subscribe(new Action1<Indexable>(){
    @Override public void call(    Indexable indexable){
      System.out.println(indexable.key());
    }
  }
);
}","@Test public void testTaskGroupInvocationShouldInvokePostRunDependentTaskGroup(){
  final LinkedList<String> group1Items=new LinkedList<>();
  final TaskGroup group1=createSampleTaskGroup(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",group1Items);
  final LinkedList<String> group2Items=new LinkedList<>();
  final TaskGroup group2=createSampleTaskGroup(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",group2Items);
  group1.addPostRunDependentTaskGroup(group2);
  group1Items.addAll(group2Items);
  group1.invokeAsync(group1.newInvocationContext()).subscribe(new Action1<Indexable>(){
    @Override public void call(    Indexable value){
      StringIndexable stringIndexable=toStringIndexable(value);
      Assert.assertTrue(group1Items.contains(stringIndexable.str()));
      group1Items.remove(stringIndexable.str());
    }
  }
);
  Assert.assertEquals(0,group1Items.size());
  Map<String,Set<String>> shouldNotSee=new HashMap<>();
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{}));
  Set<String> seen=new HashSet<>();
  group1.proxyTaskGroupWrapper.taskGroup().prepareForEnumeration();
  for (TaskGroupEntry<TaskItem> entry=group1.proxyTaskGroupWrapper.taskGroup().getNext(); entry != null; entry=group1.proxyTaskGroupWrapper.taskGroup().getNext()) {
    Assert.assertTrue(shouldNotSee.containsKey(entry.key()));
    Assert.assertFalse(seen.contains(entry.key()));
    Sets.SetView<String> common=Sets.intersection(shouldNotSee.get(entry.key()),seen);
    if (common.size() > 0) {
      Assert.assertTrue(""String_Node_Str"" + common + ""String_Node_Str""+ entry.key(),false);
    }
    seen.add(entry.key());
    group1.proxyTaskGroupWrapper.taskGroup().reportCompletion(entry);
  }
  Assert.assertEquals(13,seen.size());
  Set<String> expectedToSee=new HashSet<>();
  expectedToSee.addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  Sets.SetView<String> diff=Sets.difference(seen,expectedToSee);
  Assert.assertEquals(0,diff.size());
  group1.invokeAsync(group1.newInvocationContext()).subscribe(new Action1<Indexable>(){
    @Override public void call(    Indexable indexable){
      System.out.println(indexable.key());
    }
  }
);
}"
37627,"@Test public void testParentReassignmentUponProxyTaskGroupActivation(){
  final LinkedList<String> group1Items=new LinkedList<>();
  final TaskGroup group1=createSampleTaskGroup(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",group1Items);
  final List<String> group2Items=new ArrayList<>();
  final TaskGroup group2=createSampleTaskGroup(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",group2Items);
  group2.addDependencyTaskGroup(group1);
  Assert.assertEquals(1,group1.parentDAGs.size());
  Assert.assertTrue(group1.parentDAGs.contains(group2));
  final LinkedList<String> group3Items=new LinkedList<>();
  final TaskGroup group3=createSampleTaskGroup(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",group3Items);
  group1.addPostRunDependentTaskGroup(group3);
  Assert.assertEquals(2,group1.parentDAGs.size());
  Assert.assertTrue(group1.parentDAGs.contains(group3));
  Assert.assertTrue(group1.parentDAGs.contains(group1.proxyTaskGroupWrapper.proxyTaskGroup()));
  Assert.assertEquals(1,group1.proxyTaskGroupWrapper.proxyTaskGroup().parentDAGs.size());
  Assert.assertTrue(group1.proxyTaskGroupWrapper.proxyTaskGroup().parentDAGs.contains(group2));
  Map<String,Set<String>> shouldNotSee=new HashMap<>();
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str""}));
  Set<String> seen=new HashSet<>();
  group2.prepareForEnumeration();
  for (TaskGroupEntry<TaskItem> entry=group2.getNext(); entry != null; entry=group2.getNext()) {
    Assert.assertTrue(shouldNotSee.containsKey(entry.key()));
    Assert.assertFalse(seen.contains(entry.key()));
    Sets.SetView<String> common=Sets.intersection(shouldNotSee.get(entry.key()),seen);
    if (common.size() > 0) {
      Assert.assertTrue(""String_Node_Str"" + common + ""String_Node_Str""+ entry.key(),false);
    }
    seen.add(entry.key());
    group2.reportCompletion(entry);
  }
  Assert.assertEquals(19,seen.size());
  Set<String> expectedToSee=new HashSet<>();
  expectedToSee.addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  Sets.SetView<String> diff=Sets.difference(seen,expectedToSee);
  Assert.assertEquals(0,diff.size());
  seen.clear();
  TaskGroup group1Proxy=group1.proxyTaskGroupWrapper.proxyTaskGroup();
  group1Proxy.prepareForEnumeration();
  for (TaskGroupEntry<TaskItem> entry=group1Proxy.getNext(); entry != null; entry=group1Proxy.getNext()) {
    Assert.assertTrue(shouldNotSee.containsKey(entry.key()));
    Assert.assertFalse(seen.contains(entry.key()));
    Sets.SetView<String> common=Sets.intersection(shouldNotSee.get(entry.key()),seen);
    if (common.size() > 0) {
      Assert.assertTrue(""String_Node_Str"" + common + ""String_Node_Str""+ entry.key(),false);
    }
    seen.add(entry.key());
    group1Proxy.reportCompletion(entry);
  }
  Assert.assertEquals(13,seen.size());
  expectedToSee.clear();
  expectedToSee.addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
}","@Test public void testParentReassignmentUponProxyTaskGroupActivation(){
  final LinkedList<String> group1Items=new LinkedList<>();
  final TaskGroup group1=createSampleTaskGroup(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",group1Items);
  final List<String> group2Items=new ArrayList<>();
  final TaskGroup group2=createSampleTaskGroup(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",group2Items);
  group2.addDependencyTaskGroup(group1);
  Assert.assertEquals(1,group1.parentDAGs.size());
  Assert.assertTrue(group1.parentDAGs.contains(group2));
  final LinkedList<String> group3Items=new LinkedList<>();
  final TaskGroup group3=createSampleTaskGroup(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",group3Items);
  group1.addPostRunDependentTaskGroup(group3);
  Assert.assertEquals(2,group1.parentDAGs.size());
  Assert.assertTrue(group1.parentDAGs.contains(group3));
  Assert.assertTrue(group1.parentDAGs.contains(group1.proxyTaskGroupWrapper.taskGroup()));
  Assert.assertEquals(1,group1.proxyTaskGroupWrapper.taskGroup().parentDAGs.size());
  Assert.assertTrue(group1.proxyTaskGroupWrapper.taskGroup().parentDAGs.contains(group2));
  Map<String,Set<String>> shouldNotSee=new HashMap<>();
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str""}));
  Set<String> seen=new HashSet<>();
  group2.prepareForEnumeration();
  for (TaskGroupEntry<TaskItem> entry=group2.getNext(); entry != null; entry=group2.getNext()) {
    Assert.assertTrue(shouldNotSee.containsKey(entry.key()));
    Assert.assertFalse(seen.contains(entry.key()));
    Sets.SetView<String> common=Sets.intersection(shouldNotSee.get(entry.key()),seen);
    if (common.size() > 0) {
      Assert.assertTrue(""String_Node_Str"" + common + ""String_Node_Str""+ entry.key(),false);
    }
    seen.add(entry.key());
    group2.reportCompletion(entry);
  }
  Assert.assertEquals(19,seen.size());
  Set<String> expectedToSee=new HashSet<>();
  expectedToSee.addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  Sets.SetView<String> diff=Sets.difference(seen,expectedToSee);
  Assert.assertEquals(0,diff.size());
  seen.clear();
  TaskGroup group1Proxy=group1.proxyTaskGroupWrapper.taskGroup();
  group1Proxy.prepareForEnumeration();
  for (TaskGroupEntry<TaskItem> entry=group1Proxy.getNext(); entry != null; entry=group1Proxy.getNext()) {
    Assert.assertTrue(shouldNotSee.containsKey(entry.key()));
    Assert.assertFalse(seen.contains(entry.key()));
    Sets.SetView<String> common=Sets.intersection(shouldNotSee.get(entry.key()),seen);
    if (common.size() > 0) {
      Assert.assertTrue(""String_Node_Str"" + common + ""String_Node_Str""+ entry.key(),false);
    }
    seen.add(entry.key());
    group1Proxy.reportCompletion(entry);
  }
  Assert.assertEquals(13,seen.size());
  expectedToSee.clear();
  expectedToSee.addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
}"
37628,"@Test public void testParentProxyReassignmentUponProxyTaskGroupActivation(){
  final LinkedList<String> group1Items=new LinkedList<>();
  final TaskGroup group1=createSampleTaskGroup(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",group1Items);
  final List<String> group2Items=new ArrayList<>();
  final TaskGroup group2=createSampleTaskGroup(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",group2Items);
  group2.addDependencyTaskGroup(group1);
  Assert.assertEquals(1,group1.parentDAGs.size());
  Assert.assertTrue(group1.parentDAGs.contains(group2));
  final LinkedList<String> group3Items=new LinkedList<>();
  final TaskGroup group3=createSampleTaskGroup(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",group3Items);
  group1.addPostRunDependentTaskGroup(group3);
  Assert.assertEquals(2,group1.parentDAGs.size());
  Assert.assertTrue(group1.parentDAGs.contains(group3));
  Assert.assertTrue(group1.parentDAGs.contains(group1.proxyTaskGroupWrapper.proxyTaskGroup()));
  Assert.assertEquals(1,group1.proxyTaskGroupWrapper.proxyTaskGroup().parentDAGs.size());
  Assert.assertTrue(group1.proxyTaskGroupWrapper.proxyTaskGroup().parentDAGs.contains(group2));
  final LinkedList<String> group4Items=new LinkedList<>();
  final TaskGroup group4=createSampleTaskGroup(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",group4Items);
  final LinkedList<String> group5Items=new LinkedList<>();
  final TaskGroup group5=createSampleTaskGroup(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",group5Items);
  group4.addPostRunDependentTaskGroup(group5);
  group1.addPostRunDependentTaskGroup(group4);
  Map<String,Set<String>> shouldNotSee=new HashMap<>();
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str""}));
  Set<String> seen=new HashSet<>();
  TaskGroup group1Proxy=group1.proxyTaskGroupWrapper.proxyTaskGroup();
  group1Proxy.prepareForEnumeration();
  for (TaskGroupEntry<TaskItem> entry=group1Proxy.getNext(); entry != null; entry=group1Proxy.getNext()) {
    Assert.assertTrue(shouldNotSee.containsKey(entry.key()));
    Assert.assertFalse(seen.contains(entry.key()));
    Sets.SetView<String> common=Sets.intersection(shouldNotSee.get(entry.key()),seen);
    if (common.size() > 0) {
      Assert.assertTrue(""String_Node_Str"" + common + ""String_Node_Str""+ entry.key(),false);
    }
    seen.add(entry.key());
    group1Proxy.reportCompletion(entry);
  }
  Assert.assertEquals(26,seen.size());
  Set<String> expectedToSee=new HashSet<>();
  expectedToSee.addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  Sets.SetView<String> diff=Sets.difference(seen,expectedToSee);
  Assert.assertEquals(0,diff.size());
  seen.clear();
  TaskGroup group4Proxy=group4.proxyTaskGroupWrapper.proxyTaskGroup();
  group4Proxy.prepareForEnumeration();
  for (TaskGroupEntry<TaskItem> entry=group4Proxy.getNext(); entry != null; entry=group4Proxy.getNext()) {
    Assert.assertTrue(shouldNotSee.containsKey(entry.key()));
    Assert.assertFalse(seen.contains(entry.key()));
    Sets.SetView<String> common=Sets.intersection(shouldNotSee.get(entry.key()),seen);
    if (common.size() > 0) {
      Assert.assertTrue(""String_Node_Str"" + common + ""String_Node_Str""+ entry.key(),false);
    }
    seen.add(entry.key());
    group4Proxy.reportCompletion(entry);
  }
  Assert.assertEquals(19,seen.size());
  expectedToSee.clear();
  expectedToSee.addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  diff=Sets.difference(seen,expectedToSee);
  Assert.assertEquals(0,diff.size());
  seen.clear();
  group2.prepareForEnumeration();
  for (TaskGroupEntry<TaskItem> entry=group2.getNext(); entry != null; entry=group2.getNext()) {
    Assert.assertTrue(shouldNotSee.containsKey(entry.key()));
    Assert.assertFalse(seen.contains(entry.key()));
    Sets.SetView<String> common=Sets.intersection(shouldNotSee.get(entry.key()),seen);
    if (common.size() > 0) {
      Assert.assertTrue(""String_Node_Str"" + common + ""String_Node_Str""+ entry.key(),false);
    }
    seen.add(entry.key());
    group2.reportCompletion(entry);
  }
  expectedToSee.clear();
  expectedToSee.addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  diff=Sets.difference(seen,expectedToSee);
  Assert.assertEquals(0,diff.size());
}","@Test public void testParentProxyReassignmentUponProxyTaskGroupActivation(){
  final LinkedList<String> group1Items=new LinkedList<>();
  final TaskGroup group1=createSampleTaskGroup(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",group1Items);
  final List<String> group2Items=new ArrayList<>();
  final TaskGroup group2=createSampleTaskGroup(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",group2Items);
  group2.addDependencyTaskGroup(group1);
  Assert.assertEquals(1,group1.parentDAGs.size());
  Assert.assertTrue(group1.parentDAGs.contains(group2));
  final LinkedList<String> group3Items=new LinkedList<>();
  final TaskGroup group3=createSampleTaskGroup(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",group3Items);
  group1.addPostRunDependentTaskGroup(group3);
  Assert.assertEquals(2,group1.parentDAGs.size());
  Assert.assertTrue(group1.parentDAGs.contains(group3));
  Assert.assertTrue(group1.parentDAGs.contains(group1.proxyTaskGroupWrapper.taskGroup()));
  Assert.assertEquals(1,group1.proxyTaskGroupWrapper.taskGroup().parentDAGs.size());
  Assert.assertTrue(group1.proxyTaskGroupWrapper.taskGroup().parentDAGs.contains(group2));
  final LinkedList<String> group4Items=new LinkedList<>();
  final TaskGroup group4=createSampleTaskGroup(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",group4Items);
  final LinkedList<String> group5Items=new LinkedList<>();
  final TaskGroup group5=createSampleTaskGroup(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",group5Items);
  group4.addPostRunDependentTaskGroup(group5);
  group1.addPostRunDependentTaskGroup(group4);
  Map<String,Set<String>> shouldNotSee=new HashMap<>();
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str""}));
  shouldNotSee.put(""String_Node_Str"",new HashSet<String>());
  shouldNotSee.get(""String_Node_Str"").addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str""}));
  Set<String> seen=new HashSet<>();
  TaskGroup group1Proxy=group1.proxyTaskGroupWrapper.taskGroup();
  group1Proxy.prepareForEnumeration();
  for (TaskGroupEntry<TaskItem> entry=group1Proxy.getNext(); entry != null; entry=group1Proxy.getNext()) {
    Assert.assertTrue(shouldNotSee.containsKey(entry.key()));
    Assert.assertFalse(seen.contains(entry.key()));
    Sets.SetView<String> common=Sets.intersection(shouldNotSee.get(entry.key()),seen);
    if (common.size() > 0) {
      Assert.assertTrue(""String_Node_Str"" + common + ""String_Node_Str""+ entry.key(),false);
    }
    seen.add(entry.key());
    group1Proxy.reportCompletion(entry);
  }
  Assert.assertEquals(26,seen.size());
  Set<String> expectedToSee=new HashSet<>();
  expectedToSee.addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  Sets.SetView<String> diff=Sets.difference(seen,expectedToSee);
  Assert.assertEquals(0,diff.size());
  seen.clear();
  TaskGroup group4Proxy=group4.proxyTaskGroupWrapper.taskGroup();
  group4Proxy.prepareForEnumeration();
  for (TaskGroupEntry<TaskItem> entry=group4Proxy.getNext(); entry != null; entry=group4Proxy.getNext()) {
    Assert.assertTrue(shouldNotSee.containsKey(entry.key()));
    Assert.assertFalse(seen.contains(entry.key()));
    Sets.SetView<String> common=Sets.intersection(shouldNotSee.get(entry.key()),seen);
    if (common.size() > 0) {
      Assert.assertTrue(""String_Node_Str"" + common + ""String_Node_Str""+ entry.key(),false);
    }
    seen.add(entry.key());
    group4Proxy.reportCompletion(entry);
  }
  Assert.assertEquals(19,seen.size());
  expectedToSee.clear();
  expectedToSee.addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  diff=Sets.difference(seen,expectedToSee);
  Assert.assertEquals(0,diff.size());
  seen.clear();
  group2.prepareForEnumeration();
  for (TaskGroupEntry<TaskItem> entry=group2.getNext(); entry != null; entry=group2.getNext()) {
    Assert.assertTrue(shouldNotSee.containsKey(entry.key()));
    Assert.assertFalse(seen.contains(entry.key()));
    Sets.SetView<String> common=Sets.intersection(shouldNotSee.get(entry.key()),seen);
    if (common.size() > 0) {
      Assert.assertTrue(""String_Node_Str"" + common + ""String_Node_Str""+ entry.key(),false);
    }
    seen.add(entry.key());
    group2.reportCompletion(entry);
  }
  expectedToSee.clear();
  expectedToSee.addAll(Arrays.asList(new String[]{""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""}));
  diff=Sets.difference(seen,expectedToSee);
  Assert.assertEquals(0,diff.size());
}"
37629,"/** 
 * Get the log content for the specified container instance within a container group.
 * @param resourceGroupName the Azure resource group name
 * @param containerName the container instance name
 * @param containerGroupName the container group name
 * @param tailLineCount only get the last log lines up to this
 * @throws IllegalArgumentException thrown if parameters fail the validation
 * @return the log lines from the end, up to the number specified
 */
String getLogContent(String resourceGroupName,String containerName,String containerGroupName,int tailLineCount);","/** 
 * Get the log content for the specified container instance within a container group.
 * @param resourceGroupName the Azure resource group name
 * @param containerGroupName the container group name
 * @param containerName the container instance name
 * @param tailLineCount only get the last log lines up to this
 * @throws IllegalArgumentException thrown if parameters fail the validation
 * @return the log lines from the end, up to the number specified
 */
@Beta(Beta.SinceVersion.V1_5_0) String getLogContent(String resourceGroupName,String containerGroupName,String containerName,int tailLineCount);"
37630,"/** 
 * Get the log content for the specified container instance within a container group.
 * @param resourceGroupName the Azure resource group name
 * @param containerName the container instance name
 * @param containerGroupName the container group name
 * @param tailLineCount only get the last log lines up to this
 * @throws IllegalArgumentException thrown if parameters fail the validation
 * @return a representation of the future computation of this call
 */
Observable<String> getLogContentAsync(String resourceGroupName,String containerName,String containerGroupName,int tailLineCount);","/** 
 * Get the log content for the specified container instance within a container group.
 * @param resourceGroupName the Azure resource group name
 * @param containerGroupName the container group name
 * @param containerName the container instance name
 * @param tailLineCount only get the last log lines up to this
 * @throws IllegalArgumentException thrown if parameters fail the validation
 * @return a representation of the future computation of this call
 */
@Beta(Beta.SinceVersion.V1_5_0) Observable<String> getLogContentAsync(String resourceGroupName,String containerGroupName,String containerName,int tailLineCount);"
37631,"@Override public String getLogContent(String containerName,int tailLineCount){
  return this.manager().containerGroups().getLogContent(this.resourceGroupName(),containerName,this.name(),tailLineCount);
}","@Override public String getLogContent(String containerName,int tailLineCount){
  return this.manager().containerGroups().getLogContent(this.resourceGroupName(),this.name(),containerName,tailLineCount);
}"
37632,"@Override public Observable<String> getLogContentAsync(String containerName,int tailLineCount){
  return this.manager().containerGroups().getLogContentAsync(this.resourceGroupName(),containerName,this.name(),tailLineCount);
}","@Override public Observable<String> getLogContentAsync(String containerName,int tailLineCount){
  return this.manager().containerGroups().getLogContentAsync(this.resourceGroupName(),this.name(),containerName,tailLineCount);
}"
37633,"@Override public String getLogContent(String resourceGroupName,String containerName,String containerGroupName,int tailLineCount){
  LogsInner logsInner=this.manager().inner().containerLogs().list(resourceGroupName,containerName,containerGroupName,tailLineCount);
  return logsInner != null ? logsInner.content() : null;
}","@Override public String getLogContent(String resourceGroupName,String containerGroupName,String containerName,int tailLineCount){
  LogsInner logsInner=this.manager().inner().containerLogs().list(resourceGroupName,containerGroupName,containerName,tailLineCount);
  return logsInner != null ? logsInner.content() : null;
}"
37634,"@Override public Observable<String> getLogContentAsync(String resourceGroupName,String containerName,String containerGroupName,int tailLineCount){
  return this.manager().inner().containerLogs().listAsync(resourceGroupName,containerName,containerGroupName,tailLineCount).map(new Func1<LogsInner,String>(){
    @Override public String call(    LogsInner logsInner){
      return logsInner.content();
    }
  }
);
}","@Override public Observable<String> getLogContentAsync(String resourceGroupName,String containerGroupName,String containerName,int tailLineCount){
  return this.manager().inner().containerLogs().listAsync(resourceGroupName,containerGroupName,containerName,tailLineCount).map(new Func1<LogsInner,String>(){
    @Override public String call(    LogsInner logsInner){
      return logsInner.content();
    }
  }
);
}"
37635,"/** 
 * Get the certificates value.
 * @return the certificates value
 */
public Map<String,AppServiceCertificate> certificates(){
  return this.certificates;
}","/** 
 * Get the certificates value.
 * @return the certificates value
 */
public Map<String,AppServiceCertificateInner> certificates(){
  return this.certificates;
}"
37636,"/** 
 * Set the certificates value.
 * @param certificates the certificates value to set
 * @return the AppServiceCertificateOrderInner object itself.
 */
public AppServiceCertificateOrderInner withCertificates(Map<String,AppServiceCertificate> certificates){
  this.certificates=certificates;
  return this;
}","/** 
 * Set the certificates value.
 * @param certificates the certificates value to set
 * @return the AppServiceCertificateOrderInner object itself.
 */
public AppServiceCertificateOrderInner withCertificates(Map<String,AppServiceCertificateInner> certificates){
  this.certificates=certificates;
  return this;
}"
37637,"FunctionAppsImpl(final AppServiceManager manager){
  super(manager.inner().webApps(),manager);
  converter=new PagedListConverter<SiteInner,FunctionApp>(){
    @Override public Observable<FunctionApp> typeConvertAsync(    final SiteInner siteInner){
      return manager.inner().webApps().getConfigurationAsync(siteInner.resourceGroup(),siteInner.name()).subscribeOn(SdkContext.getRxScheduler()).map(new Func1<SiteConfigResourceInner,FunctionApp>(){
        @Override public FunctionApp call(        SiteConfigResourceInner siteConfigResourceInner){
          return wrapModel(siteInner,siteConfigResourceInner);
        }
      }
);
    }
    @Override protected boolean filter(    SiteInner inner){
      return ""String_Node_Str"".equals(inner.kind());
    }
  }
;
}","FunctionAppsImpl(final AppServiceManager manager){
  super(manager.inner().webApps(),manager);
  converter=new PagedListConverter<SiteInner,FunctionApp>(){
    @Override public Observable<FunctionApp> typeConvertAsync(    final SiteInner siteInner){
      return manager.inner().webApps().getConfigurationAsync(siteInner.resourceGroup(),siteInner.name()).subscribeOn(SdkContext.getRxScheduler()).map(new Func1<SiteConfigResourceInner,FunctionApp>(){
        @Override public FunctionApp call(        SiteConfigResourceInner siteConfigResourceInner){
          return wrapModel(siteInner,siteConfigResourceInner);
        }
      }
);
    }
    @Override protected boolean filter(    SiteInner inner){
      return ""String_Node_Str"".equalsIgnoreCase(inner.kind());
    }
  }
;
}"
37638,"@Override protected boolean filter(SiteInner inner){
  return ""String_Node_Str"".equals(inner.kind());
}","@Override protected boolean filter(SiteInner inner){
  return ""String_Node_Str"".equalsIgnoreCase(inner.kind());
}"
37639,"@Override public Observable<ActiveDirectoryApplication> getByNameAsync(final String name){
  return innerCollection.listWithServiceResponseAsync(String.format(""String_Node_Str"",name)).flatMap(new Func1<ServiceResponse<Page<ApplicationInner>>,Observable<Page<ApplicationInner>>>(){
    @Override public Observable<Page<ApplicationInner>> call(    ServiceResponse<Page<ApplicationInner>> result){
      if (result == null || result.body().items() == null || result.body().items().isEmpty()) {
        return innerCollection.listAsync(String.format(""String_Node_Str"",name));
      }
      return Observable.just(result.body());
    }
  }
).map(new Func1<Page<ApplicationInner>,ActiveDirectoryApplicationImpl>(){
    @Override public ActiveDirectoryApplicationImpl call(    Page<ApplicationInner> result){
      if (result == null || result.items() == null || result.items().isEmpty()) {
        return null;
      }
      return new ActiveDirectoryApplicationImpl(result.items().get(0),manager());
    }
  }
).flatMap(new Func1<ActiveDirectoryApplicationImpl,Observable<ActiveDirectoryApplication>>(){
    @Override public Observable<ActiveDirectoryApplication> call(    ActiveDirectoryApplicationImpl application){
      if (application == null) {
        return null;
      }
      return application.refreshCredentialsAsync();
    }
  }
);
}","@Override public Observable<ActiveDirectoryApplication> getByNameAsync(String name){
  final String trimmed=name.replaceFirst(""String_Node_Str"",""String_Node_Str"").replaceAll(""String_Node_Str"",""String_Node_Str"");
  return innerCollection.listWithServiceResponseAsync(String.format(""String_Node_Str"",trimmed)).flatMap(new Func1<ServiceResponse<Page<ApplicationInner>>,Observable<Page<ApplicationInner>>>(){
    @Override public Observable<Page<ApplicationInner>> call(    ServiceResponse<Page<ApplicationInner>> result){
      if (result == null || result.body().items() == null || result.body().items().isEmpty()) {
        try {
          UUID.fromString(trimmed);
          return innerCollection.listAsync(String.format(""String_Node_Str"",trimmed));
        }
 catch (        IllegalArgumentException e) {
          return null;
        }
      }
      return Observable.just(result.body());
    }
  }
).map(new Func1<Page<ApplicationInner>,ActiveDirectoryApplicationImpl>(){
    @Override public ActiveDirectoryApplicationImpl call(    Page<ApplicationInner> result){
      if (result == null || result.items() == null || result.items().isEmpty()) {
        return null;
      }
      return new ActiveDirectoryApplicationImpl(result.items().get(0),manager());
    }
  }
).flatMap(new Func1<ActiveDirectoryApplicationImpl,Observable<ActiveDirectoryApplication>>(){
    @Override public Observable<ActiveDirectoryApplication> call(    ActiveDirectoryApplicationImpl application){
      if (application == null) {
        return null;
      }
      return application.refreshCredentialsAsync();
    }
  }
);
}"
37640,"@Override protected CdnProfileImpl wrapModel(ProfileInner inner){
  return new CdnProfileImpl(inner.name(),inner,this.manager());
}","@Override protected CdnProfileImpl wrapModel(ProfileInner inner){
  if (inner == null) {
    return null;
  }
  return new CdnProfileImpl(inner.name(),inner,this.manager());
}"
37641,"@Override protected SnapshotImpl wrapModel(SnapshotInner inner){
  return new SnapshotImpl(inner.name(),inner,this.manager());
}","@Override protected SnapshotImpl wrapModel(SnapshotInner inner){
  if (inner == null) {
    return null;
  }
  return new SnapshotImpl(inner.name(),inner,this.manager());
}"
37642,"/** 
 * @return - returns the next Message to be processed out of the queue.
 */
@Override public Message poll(){
  final VirtualSpoutIdentifier nextIndentifier=nextVirtualSpoutIdGenerator.nextVirtualSpoutId();
  final Message nextMessage=messageBuffer.get(nextIndentifier).poll();
  logger.info(""String_Node_Str"",nextIndentifier,nextMessage);
  return nextMessage;
}","/** 
 * @return returns the next Message to be processed out of the queue.
 */
@Override public Message poll(){
  final VirtualSpoutIdentifier nextIndentifier=nextVirtualSpoutIdGenerator.nextVirtualSpoutId();
  return messageBuffer.get(nextIndentifier).poll();
}"
37643,"/** 
 * @return - return a new LinkedBlockingQueue instance with a max size of our configured buffer.
 */
private BlockingQueue<Message> createNewQueue(){
  return new LinkedBlockingQueue<>(getMaxBufferSize());
}","/** 
 * @return return a new LinkedBlockingQueue instance with a max size of our configured buffer.
 */
private BlockingQueue<Message> createNewQueue(){
  return new LinkedBlockingQueue<>(getMaxBufferSize());
}"
37644,"/** 
 * @return - returns the next Message to be processed out of the queue.
 */
@Override public Message poll(){
  if (consumerIdIterator == null || !consumerIdIterator.hasNext()) {
    consumerIdIterator=messageBuffer.keySet().iterator();
  }
  Message returnMsg=null;
  while (returnMsg == null && consumerIdIterator.hasNext()) {
    final VirtualSpoutIdentifier nextConsumerId=consumerIdIterator.next();
    final BlockingQueue<Message> queue=messageBuffer.get(nextConsumerId);
    if (queue == null) {
      logger.info(""String_Node_Str"");
      consumerIdIterator=messageBuffer.keySet().iterator();
      continue;
    }
    returnMsg=queue.poll();
  }
  return returnMsg;
}","/** 
 * @return returns the next Message to be processed out of the queue.
 */
@Override public Message poll(){
  if (consumerIdIterator == null || !consumerIdIterator.hasNext()) {
    consumerIdIterator=messageBuffer.keySet().iterator();
  }
  Message returnMsg=null;
  while (returnMsg == null && consumerIdIterator.hasNext()) {
    final VirtualSpoutIdentifier nextConsumerId=consumerIdIterator.next();
    final BlockingQueue<Message> queue=messageBuffer.get(nextConsumerId);
    if (queue == null) {
      logger.debug(""String_Node_Str"");
      consumerIdIterator=messageBuffer.keySet().iterator();
      continue;
    }
    returnMsg=queue.poll();
  }
  return returnMsg;
}"
37645,"BlockingQueue<Message> createBuffer(final VirtualSpoutIdentifier virtualSpoutIdentifier){
  final Matcher matches=regexPattern.matcher(virtualSpoutIdentifier.toString());
  if (matches.find()) {
    return createNewThrottledQueue();
  }
  return createNewNonThrottledQueue();
}","private BlockingQueue<Message> createBuffer(final VirtualSpoutIdentifier virtualSpoutIdentifier){
  final Matcher matches=regexPattern.matcher(virtualSpoutIdentifier.toString());
  if (matches.find()) {
    logger.debug(""String_Node_Str"",virtualSpoutIdentifier,true);
    return createNewThrottledQueue();
  }
  logger.debug(""String_Node_Str"",virtualSpoutIdentifier,false);
  return createNewNonThrottledQueue();
}"
37646,"/** 
 * @return - return a new LinkedBlockingQueue instance with a max size of our configured buffer.
 */
private BlockingQueue<Message> createNewThrottledQueue(){
  return new LinkedBlockingQueue<>(getThrottledBufferSize());
}","/** 
 * @return return a new LinkedBlockingQueue instance with a max size of our configured buffer.
 */
private BlockingQueue<Message> createNewThrottledQueue(){
  return new LinkedBlockingQueue<>(getThrottledBufferSize());
}"
37647,"/** 
 * @return - return a new LinkedBlockingQueue instance with a max size of our configured buffer.
 */
private BlockingQueue<Message> createNewNonThrottledQueue(){
  return new LinkedBlockingQueue<>(getMaxBufferSize());
}","/** 
 * @return return a new LinkedBlockingQueue instance with a max size of our configured buffer.
 */
private BlockingQueue<Message> createNewNonThrottledQueue(){
  return new LinkedBlockingQueue<>(getMaxBufferSize());
}"
37648,"/** 
 * This method handles when a partition seek/retrieve request was out of bounds. This happens in two scenarios: 1 - The offset is too old and was cleaned up / removed by the broker. 2 - The offset just plain does not exist. This is particularly nasty in that if the poll() was able to pull SOME messages from SOME partitions before the exception was thrown, those messages are considered ""consumed"" by KafkaClient, and there's no way to get them w/o seeking back to them for those partitions. This means when we roll back, we may replay some messages :/
 * @param outOfRangeException The exception that was raised by the consumer.
 */
private void handleOffsetOutOfRange(OffsetOutOfRangeException outOfRangeException){
  final Set<TopicPartition> outOfRangePartitions=outOfRangeException.partitions();
  Set<ConsumerPartition> allAssignedPartitions=getAssignedPartitions();
  for (  ConsumerPartition assignedConsumerPartition : allAssignedPartitions) {
    final TopicPartition assignedTopicPartition=new TopicPartition(assignedConsumerPartition.namespace(),assignedConsumerPartition.partition());
    if (outOfRangePartitions.contains(assignedTopicPartition)) {
      final long offset=outOfRangeException.offsetOutOfRangePartitions().get(assignedTopicPartition);
      logger.error(""String_Node_Str"",offset,assignedConsumerPartition);
      continue;
    }
    final long offset=partitionOffsetsManager.getLastStartedOffset(assignedConsumerPartition);
    logger.info(""String_Node_Str"",assignedConsumerPartition,offset);
    getKafkaConsumer().seek(assignedTopicPartition,offset);
  }
  resetPartitionsToEarliest(outOfRangePartitions);
}","/** 
 * This method handles when a partition seek/retrieve request was out of bounds. This happens in two scenarios: 1 - The offset is too old and was cleaned up / removed by the broker. 2 - The offset just plain does not exist. This is particularly nasty in that if the poll() was able to pull SOME messages from SOME partitions before the exception was thrown, those messages are considered ""consumed"" by KafkaClient, and there's no way to get them w/o seeking back to them for those partitions. This means when we roll back, we may replay some messages :/
 * @param outOfRangeException The exception that was raised by the consumer.
 */
private void handleOffsetOutOfRange(OffsetOutOfRangeException outOfRangeException){
  final Set<TopicPartition> outOfRangePartitions=outOfRangeException.partitions();
  Set<ConsumerPartition> allAssignedPartitions=getAssignedPartitions();
  for (  ConsumerPartition assignedConsumerPartition : allAssignedPartitions) {
    final TopicPartition assignedTopicPartition=new TopicPartition(assignedConsumerPartition.namespace(),assignedConsumerPartition.partition());
    if (outOfRangePartitions.contains(assignedTopicPartition)) {
      final long offset=outOfRangeException.offsetOutOfRangePartitions().get(assignedTopicPartition);
      logger.error(""String_Node_Str"",offset,assignedConsumerPartition);
      continue;
    }
    final long offset=partitionOffsetsManager.getLastStartedOffset(assignedConsumerPartition);
    if (offset == -1) {
      logger.info(""String_Node_Str"",assignedConsumerPartition,offset);
      resetPartitionsToEarliest(Collections.singletonList(assignedTopicPartition));
    }
 else {
      logger.info(""String_Node_Str"",assignedConsumerPartition,offset);
      getKafkaConsumer().seek(assignedTopicPartition,offset);
    }
  }
  resetPartitionsToEarliest(outOfRangePartitions);
}"
37649,"/** 
 * @return - return the largest offset we have started tracking.This is NOT the same as the ""Last Finished Offset""
 */
public long lastStartedOffset(){
  if ((lastFinishedOffset + 1) > lastStartedOffset) {
    return (lastFinishedOffset + 1);
  }
  return lastStartedOffset;
}","/** 
 * @return - return the largest offset we have started tracking.This is NOT the same as the ""Last Finished Offset""
 */
public long lastStartedOffset(){
  if (lastStartedOffset == -1) {
    return lastFinishedOffset;
  }
  return lastStartedOffset;
}"
37650,"/** 
 * Get the kafka consumer, if it has been retried yet, set it up.
 * @return Kafka consumer
 */
private KafkaConsumer<byte[],byte[]> getKafkaConsumer(){
  if (kafkaConsumer == null) {
    kafkaConsumer=new KafkaConsumer<>(getConsumerConfig().getKafkaConsumerProperties());
  }
  return kafkaConsumer;
}","/** 
 * Get the kafka consumer, if it has been retried yet, set it up.
 * @return Kafka consumer
 */
KafkaConsumer<byte[],byte[]> getKafkaConsumer(){
  if (kafkaConsumer == null) {
    kafkaConsumer=new KafkaConsumer<>(getConsumerConfig().getKafkaConsumerProperties());
  }
  return kafkaConsumer;
}"
37651,"/** 
 * This test verifies what happens if you call lastTrackedOffset() when we have been tracking some offsets. It should return the largest value tracked.
 */
@Test public void testLastStartedOffset(){
  long startingOffset=0L;
  PartitionOffsetManager offsetManager=new PartitionOffsetManager(""String_Node_Str"",1,startingOffset);
  offsetManager.startOffset(1L);
  offsetManager.startOffset(2L);
  offsetManager.startOffset(3L);
  offsetManager.startOffset(4L);
  assertEquals(""String_Node_Str"",4L,offsetManager.lastStartedOffset());
  offsetManager.finishOffset(1L);
  long result=offsetManager.lastStartedOffset();
  assertEquals(""String_Node_Str"",4L,result);
  offsetManager.finishOffset(3L);
  result=offsetManager.lastStartedOffset();
  assertEquals(""String_Node_Str"",4L,result);
  offsetManager.finishOffset(4L);
  result=offsetManager.lastStartedOffset();
  assertEquals(""String_Node_Str"",4L,result);
  offsetManager.finishOffset(2L);
  result=offsetManager.lastStartedOffset();
  assertEquals(""String_Node_Str"",5L,result);
}","/** 
 * This test verifies what happens if you call lastTrackedOffset() when we have been tracking some offsets. It should return the largest value tracked.
 */
@Test public void testLastStartedOffset(){
  long startingOffset=0L;
  PartitionOffsetManager offsetManager=new PartitionOffsetManager(""String_Node_Str"",1,startingOffset);
  offsetManager.startOffset(1L);
  offsetManager.startOffset(2L);
  offsetManager.startOffset(3L);
  offsetManager.startOffset(4L);
  assertEquals(""String_Node_Str"",4L,offsetManager.lastStartedOffset());
  offsetManager.finishOffset(1L);
  long result=offsetManager.lastStartedOffset();
  assertEquals(""String_Node_Str"",4L,result);
  offsetManager.finishOffset(3L);
  result=offsetManager.lastStartedOffset();
  assertEquals(""String_Node_Str"",4L,result);
  offsetManager.finishOffset(4L);
  result=offsetManager.lastStartedOffset();
  assertEquals(""String_Node_Str"",4L,result);
  offsetManager.finishOffset(2L);
  result=offsetManager.lastStartedOffset();
  assertEquals(""String_Node_Str"",4L,result);
}"
37652,"/** 
 * This test verifies what happens if you call lastTrackedOffset() when we have nothing being tracked. It should return the last finished offset + 1.
 */
@Test public void testLastStartedOffsetWhenHasNone(){
  long startingOffset=0L;
  PartitionOffsetManager offsetManager=new PartitionOffsetManager(""String_Node_Str"",1,startingOffset);
  assertEquals(""String_Node_Str"",(startingOffset + 1),offsetManager.lastStartedOffset());
  startingOffset=100L;
  offsetManager=new PartitionOffsetManager(""String_Node_Str"",1,startingOffset);
  assertEquals(""String_Node_Str"",(startingOffset + 1),offsetManager.lastStartedOffset());
}","/** 
 * This test verifies what happens if you call lastTrackedOffset() when we have nothing being tracked. It should return the last finished offset + 1.
 */
@Test public void testLastStartedOffsetWhenHasNone(){
  long startingOffset=0L;
  PartitionOffsetManager offsetManager=new PartitionOffsetManager(""String_Node_Str"",1,startingOffset);
  assertEquals(""String_Node_Str"",startingOffset,offsetManager.lastStartedOffset());
  startingOffset=100L;
  offsetManager=new PartitionOffsetManager(""String_Node_Str"",1,startingOffset);
  assertEquals(""String_Node_Str"",startingOffset,offsetManager.lastStartedOffset());
}"
37653,"/** 
 * This tests what happens if we ask to consume from an offset that is invalid (does not exist). Here's what we setup: 2 partitions, produce 4 messages into each. Start a consumer, asking to start at: offset 2 for partition 1, (recorded completed offset = 1) offset 21 for partition 2. (recorded completed offset = 20) Offset 20 does not exist for partition 2, this will raise an exception which by the underlying kafka consumer.  This exception should be handled internally resetting the offset on partition 2 to the earliest available (which happens to be 0). We then consume and expect to receive messages: partition 0 -> messages 2,3      (because we started at offset 2) partition 1 -> messages 0,1,2,3  (because we got reset to earliest) This test also validates that for non-reset partitions, that it does not lose any messages.
 */
@Test public void testWhatHappensIfOffsetIsInvalidShouldResetSmallest(){
  this.topicName=""String_Node_Str"" + System.currentTimeMillis();
  final int numberOfPartitions=2;
  final int numberOfMsgsPerPartition=4;
  final int numberOfExpectedMessages=6;
  final ConsumerPartition topicPartition0=new ConsumerPartition(topicName,0);
  final ConsumerPartition topicPartition1=new ConsumerPartition(topicName,1);
  final long partition0StartingOffset=1L;
  final long partition1StartingOffset=20L;
  kafkaTestServer.createTopic(topicName,numberOfPartitions);
  produceRecords(numberOfMsgsPerPartition,0);
  produceRecords(numberOfMsgsPerPartition,1);
  Map<String,Object> config=getDefaultConfig(topicName);
  PersistenceAdapter persistenceAdapter=new InMemoryPersistenceAdapter();
  persistenceAdapter.open(Maps.newHashMap());
  persistenceAdapter.persistConsumerState(""String_Node_Str"",0,partition0StartingOffset);
  persistenceAdapter.persistConsumerState(""String_Node_Str"",1,partition1StartingOffset);
  Consumer consumer=new Consumer();
  consumer.open(config,getDefaultVSpoutId(),getDefaultConsumerCohortDefinition(),persistenceAdapter,null);
  ConsumerState consumerState=consumer.getCurrentState();
  assertEquals(""String_Node_Str"",(Long)partition0StartingOffset,consumerState.getOffsetForNamespaceAndPartition(topicPartition0));
  assertEquals(""String_Node_Str"",(Long)partition1StartingOffset,consumerState.getOffsetForNamespaceAndPartition(topicPartition1));
  final Set<String> expectedValues=Sets.newHashSet(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"");
  List<Record> records=Lists.newArrayList();
  Record consumerRecord;
  int attempts=0;
  do {
    consumerRecord=consumer.nextRecord();
    if (consumerRecord != null) {
      logger.info(""String_Node_Str"",consumerRecord.getOffset(),consumerRecord.getPartition());
      records.add(consumerRecord);
      expectedValues.remove(""String_Node_Str"" + consumerRecord.getPartition() + ""String_Node_Str""+ consumerRecord.getOffset());
    }
 else {
      attempts++;
    }
  }
 while (attempts <= 2);
  logger.info(""String_Node_Str"",records.size());
  assertEquals(""String_Node_Str"",numberOfExpectedMessages,records.size());
  assertTrue(""String_Node_Str"",expectedValues.isEmpty());
  for (int x=0; x < 2; x++) {
    assertNull(""String_Node_Str"",consumer.nextRecord());
  }
  consumerState=consumer.getCurrentState();
  assertEquals(""String_Node_Str"",(Long)partition0StartingOffset,consumerState.getOffsetForNamespaceAndPartition(topicPartition0));
  assertEquals(""String_Node_Str"",(Long)(-1L),consumerState.getOffsetForNamespaceAndPartition(topicPartition1));
}","/** 
 * This tests what happens if we ask to consume from an offset that is invalid (does not exist). Here's what we setup: 2 partitions, produce 4 messages into each. Start a consumer, asking to start at: offset 2 for partition 1, (recorded completed offset = 1) offset 21 for partition 2. (recorded completed offset = 20) Offset 20 does not exist for partition 2, this will raise an exception which by the underlying kafka consumer.  This exception should be handled internally resetting the offset on partition 2 to the earliest available (which happens to be 0). We then consume and expect to receive messages: partition 0 -> messages 2,3      (because we started at offset 2) partition 1 -> messages 0,1,2,3  (because we got reset to earliest) This test also validates that for non-reset partitions, that it does not lose any messages.
 */
@Test public void testWhatHappensIfOffsetIsInvalidShouldResetSmallest(){
  this.topicName=""String_Node_Str"" + System.currentTimeMillis();
  final int numberOfPartitions=2;
  final int numberOfMsgsPerPartition=4;
  final int numberOfExpectedMessages=6;
  final ConsumerPartition topicPartition0=new ConsumerPartition(topicName,0);
  final ConsumerPartition topicPartition1=new ConsumerPartition(topicName,1);
  final long partition0StartingOffset=1L;
  final long partition1StartingOffset=20L;
  kafkaTestServer.createTopic(topicName,numberOfPartitions);
  produceRecords(numberOfMsgsPerPartition,0);
  produceRecords(numberOfMsgsPerPartition,1);
  Map<String,Object> config=getDefaultConfig(topicName);
  PersistenceAdapter persistenceAdapter=new InMemoryPersistenceAdapter();
  persistenceAdapter.open(Maps.newHashMap());
  persistenceAdapter.persistConsumerState(""String_Node_Str"",0,partition0StartingOffset);
  persistenceAdapter.persistConsumerState(""String_Node_Str"",1,partition1StartingOffset);
  Consumer consumer=new Consumer();
  consumer.open(config,getDefaultVSpoutId(),getDefaultConsumerCohortDefinition(),persistenceAdapter,null);
  ConsumerState consumerState=consumer.getCurrentState();
  assertEquals(""String_Node_Str"",(Long)partition0StartingOffset,consumerState.getOffsetForNamespaceAndPartition(topicPartition0));
  assertEquals(""String_Node_Str"",(Long)partition1StartingOffset,consumerState.getOffsetForNamespaceAndPartition(topicPartition1));
  final Set<String> expectedValues=Sets.newHashSet(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"");
  List<Record> records=Lists.newArrayList();
  Record consumerRecord;
  int attempts=0;
  do {
    consumerRecord=consumer.nextRecord();
    if (consumerRecord != null) {
      logger.info(""String_Node_Str"",consumerRecord.getOffset(),consumerRecord.getPartition());
      records.add(consumerRecord);
      expectedValues.remove(""String_Node_Str"" + consumerRecord.getPartition() + ""String_Node_Str""+ consumerRecord.getOffset());
    }
 else {
      attempts++;
    }
  }
 while (attempts <= 2);
  logger.info(""String_Node_Str"",records.size());
  assertEquals(""String_Node_Str"",numberOfExpectedMessages + 1,records.size());
  assertTrue(""String_Node_Str"",expectedValues.isEmpty());
  for (int x=0; x < 2; x++) {
    assertNull(""String_Node_Str"",consumer.nextRecord());
  }
  consumerState=consumer.getCurrentState();
  assertEquals(""String_Node_Str"",(Long)partition0StartingOffset,consumerState.getOffsetForNamespaceAndPartition(topicPartition0));
  assertEquals(""String_Node_Str"",(Long)(-1L),consumerState.getOffsetForNamespaceAndPartition(topicPartition1));
  consumer.close();
}"
37654,"void onOpen(Map topologyConfig,TopologyContext topologyContext,SpoutOutputCollector spoutOutputCollector){
  if (startingTrigger != null) {
    startingTrigger.setSidelineSpout(new SpoutTriggerProxy(this));
  }
  if (stoppingTrigger != null) {
    stoppingTrigger.setSidelineSpout(new SpoutTriggerProxy(this));
  }
  fireHoseSpout=new VirtualSpout(getSpoutConfig(),getTopologyContext(),getFactoryManager(),getMetricsRecorder());
  fireHoseSpout.setVirtualSpoutId(generateVirtualSpoutId(""String_Node_Str""));
  getCoordinator().addSidelineSpout(fireHoseSpout);
  final ConsumerState currentState=fireHoseSpout.getCurrentState();
  final List<SidelineRequestIdentifier> existingRequestIds=getPersistenceAdapter().listSidelineRequests();
  logger.info(""String_Node_Str"",existingRequestIds.size());
  for (  SidelineRequestIdentifier id : existingRequestIds) {
    final ConsumerState.ConsumerStateBuilder startingStateBuilder=ConsumerState.builder();
    final ConsumerState.ConsumerStateBuilder endingStateStateBuilder=ConsumerState.builder();
    SidelinePayload payload=null;
    for (    final TopicPartition topicPartition : currentState.getTopicPartitions()) {
      payload=getPersistenceAdapter().retrieveSidelineRequest(id,topicPartition.partition());
      if (payload == null) {
        continue;
      }
      startingStateBuilder.withPartition(topicPartition,payload.startingOffset);
      if (payload.endingOffset != null) {
        endingStateStateBuilder.withPartition(topicPartition,payload.endingOffset);
      }
    }
    if (payload == null) {
      logger.warn(""String_Node_Str"",id);
      continue;
    }
    if (payload.type.equals(SidelineType.START)) {
      logger.info(""String_Node_Str"",payload.id,payload.request.step);
      fireHoseSpout.getFilterChain().addStep(payload.id,payload.request.step);
    }
    if (payload.type.equals(SidelineType.STOP)) {
      openVirtualSpout(payload.id,payload.request.step,startingStateBuilder.build(),endingStateStateBuilder.build());
    }
  }
  if (startingTrigger != null) {
    startingTrigger.open(getSpoutConfig());
  }
 else {
    logger.warn(""String_Node_Str"");
  }
  if (stoppingTrigger != null) {
    stoppingTrigger.open(getSpoutConfig());
  }
 else {
    logger.warn(""String_Node_Str"");
  }
}","void onOpen(Map topologyConfig,TopologyContext topologyContext,SpoutOutputCollector spoutOutputCollector){
  if (startingTrigger != null) {
    startingTrigger.setSidelineSpout(new SpoutTriggerProxy(this));
  }
  if (stoppingTrigger != null) {
    stoppingTrigger.setSidelineSpout(new SpoutTriggerProxy(this));
  }
  fireHoseSpout=new VirtualSpout(getSpoutConfig(),getTopologyContext(),getFactoryManager(),getMetricsRecorder());
  fireHoseSpout.setVirtualSpoutId(generateVirtualSpoutId(""String_Node_Str""));
  getCoordinator().addSidelineSpout(fireHoseSpout);
  final String topic=(String)getSpoutConfigItem(SidelineSpoutConfig.KAFKA_TOPIC);
  final List<SidelineRequestIdentifier> existingRequestIds=getPersistenceAdapter().listSidelineRequests();
  logger.info(""String_Node_Str"",existingRequestIds.size());
  for (  SidelineRequestIdentifier id : existingRequestIds) {
    final ConsumerState.ConsumerStateBuilder startingStateBuilder=ConsumerState.builder();
    final ConsumerState.ConsumerStateBuilder endingStateStateBuilder=ConsumerState.builder();
    SidelinePayload payload=null;
    final List<Integer> partitions=getPersistenceAdapter().listSidelineRequestPartitions(id);
    for (    final Integer partition : partitions) {
      payload=getPersistenceAdapter().retrieveSidelineRequest(id,partition);
      if (payload == null) {
        continue;
      }
      final TopicPartition topicPartition=new TopicPartition(topic,partition);
      startingStateBuilder.withPartition(topicPartition,payload.startingOffset);
      if (payload.endingOffset != null) {
        endingStateStateBuilder.withPartition(topicPartition,payload.endingOffset);
      }
    }
    if (payload == null) {
      logger.warn(""String_Node_Str"",id);
      continue;
    }
    if (payload.type.equals(SidelineType.START)) {
      logger.info(""String_Node_Str"",payload.id,payload.request.step);
      fireHoseSpout.getFilterChain().addStep(payload.id,payload.request.step);
    }
    if (payload.type.equals(SidelineType.STOP)) {
      openVirtualSpout(payload.id,payload.request.step,startingStateBuilder.build(),endingStateStateBuilder.build());
    }
  }
  if (startingTrigger != null) {
    startingTrigger.open(getSpoutConfig());
  }
 else {
    logger.warn(""String_Node_Str"");
  }
  if (stoppingTrigger != null) {
    stoppingTrigger.open(getSpoutConfig());
  }
 else {
    logger.warn(""String_Node_Str"");
  }
}"
37655,"private String getSidelineRequestStateKey(final SidelineRequestIdentifier id,final int partitionId){
  return id.toString().concat(""String_Node_Str"").concat(String.valueOf(partitionId));
}","private SidelineRequestStateKey getSidelineRequestStateKey(final SidelineRequestIdentifier id,final int partitionId){
  return new SidelineRequestStateKey(id,partitionId);
}"
37656,"/** 
 * @return - The full zookeeper path to where our consumer state is stored.
 */
String getZkRequestStatePath(final String sidelineIdentifierStr,final int partitionId){
  return getZkRoot() + ""String_Node_Str"" + sidelineIdentifierStr+ ""String_Node_Str""+ partitionId;
}","/** 
 * @return - The full zookeeper path to where our consumer state is stored.
 */
String getZkRequestStatePath(final String sidelineIdentifierStr,final int partitionId){
  return getZkRequestStatePath(sidelineIdentifierStr) + ""String_Node_Str"" + partitionId;
}"
37657,"/** 
 * @return returns a new instance of the configured deserializer.
 */
public synchronized Deserializer createNewDeserializerInstance(){
  if (deserializerClass == null) {
    final String classStr=(String)topologyConfig.get(SidelineSpoutConfig.DESERIALIZER_CLASS);
    if (Strings.isNullOrEmpty(classStr)) {
      throw new IllegalStateException(""String_Node_Str"" + SidelineSpoutConfig.DESERIALIZER_CLASS);
    }
    try {
      deserializerClass=(Class<? extends Deserializer>)Class.forName(classStr);
    }
 catch (    ClassNotFoundException e) {
      throw new RuntimeException(e);
    }
  }
  try {
    return deserializerClass.newInstance();
  }
 catch (  IllegalAccessException|InstantiationException e) {
    throw new RuntimeException(e);
  }
}","/** 
 * @return returns a new instance of the configured deserializer.
 */
public synchronized Deserializer createNewDeserializerInstance(){
  if (deserializerClass == null) {
    final String classStr=(String)spoutConfig.get(SidelineSpoutConfig.DESERIALIZER_CLASS);
    if (Strings.isNullOrEmpty(classStr)) {
      throw new IllegalStateException(""String_Node_Str"" + SidelineSpoutConfig.DESERIALIZER_CLASS);
    }
    try {
      deserializerClass=(Class<? extends Deserializer>)Class.forName(classStr);
    }
 catch (    ClassNotFoundException e) {
      throw new RuntimeException(e);
    }
  }
  try {
    return deserializerClass.newInstance();
  }
 catch (  IllegalAccessException|InstantiationException e) {
    throw new RuntimeException(e);
  }
}"
37658,"/** 
 * @return returns a new instance of the configured Metrics Recorder manager.
 */
public synchronized MetricsRecorder createNewMetricsRecorder(){
  if (metricsRecorderClass == null) {
    String classStr=(String)topologyConfig.get(SidelineSpoutConfig.METRICS_RECORDER_CLASS);
    if (Strings.isNullOrEmpty(classStr)) {
      throw new IllegalStateException(""String_Node_Str"" + SidelineSpoutConfig.METRICS_RECORDER_CLASS);
    }
    try {
      metricsRecorderClass=(Class<? extends MetricsRecorder>)Class.forName(classStr);
    }
 catch (    ClassNotFoundException e) {
      throw new RuntimeException(e);
    }
  }
  try {
    return metricsRecorderClass.newInstance();
  }
 catch (  IllegalAccessException|InstantiationException e) {
    throw new RuntimeException(e);
  }
}","/** 
 * @return returns a new instance of the configured Metrics Recorder manager.
 */
public synchronized MetricsRecorder createNewMetricsRecorder(){
  if (metricsRecorderClass == null) {
    String classStr=(String)spoutConfig.get(SidelineSpoutConfig.METRICS_RECORDER_CLASS);
    if (Strings.isNullOrEmpty(classStr)) {
      throw new IllegalStateException(""String_Node_Str"" + SidelineSpoutConfig.METRICS_RECORDER_CLASS);
    }
    try {
      metricsRecorderClass=(Class<? extends MetricsRecorder>)Class.forName(classStr);
    }
 catch (    ClassNotFoundException e) {
      throw new RuntimeException(e);
    }
  }
  try {
    return metricsRecorderClass.newInstance();
  }
 catch (  IllegalAccessException|InstantiationException e) {
    throw new RuntimeException(e);
  }
}"
37659,"/** 
 * @return returns a new instance of the configured persistence manager.
 */
public synchronized PersistenceAdapter createNewPersistenceAdapterInstance(){
  if (persistenceAdapterClass == null) {
    final String classStr=(String)topologyConfig.get(SidelineSpoutConfig.PERSISTENCE_ADAPTER_CLASS);
    if (Strings.isNullOrEmpty(classStr)) {
      throw new IllegalStateException(""String_Node_Str"" + SidelineSpoutConfig.PERSISTENCE_ADAPTER_CLASS);
    }
    try {
      persistenceAdapterClass=(Class<? extends PersistenceAdapter>)Class.forName(classStr);
    }
 catch (    ClassNotFoundException e) {
      throw new RuntimeException(e);
    }
  }
  try {
    return persistenceAdapterClass.newInstance();
  }
 catch (  IllegalAccessException|InstantiationException e) {
    throw new RuntimeException(e);
  }
}","/** 
 * @return returns a new instance of the configured persistence manager.
 */
public synchronized PersistenceAdapter createNewPersistenceAdapterInstance(){
  if (persistenceAdapterClass == null) {
    final String classStr=(String)spoutConfig.get(SidelineSpoutConfig.PERSISTENCE_ADAPTER_CLASS);
    if (Strings.isNullOrEmpty(classStr)) {
      throw new IllegalStateException(""String_Node_Str"" + SidelineSpoutConfig.PERSISTENCE_ADAPTER_CLASS);
    }
    try {
      persistenceAdapterClass=(Class<? extends PersistenceAdapter>)Class.forName(classStr);
    }
 catch (    ClassNotFoundException e) {
      throw new RuntimeException(e);
    }
  }
  try {
    return persistenceAdapterClass.newInstance();
  }
 catch (  IllegalAccessException|InstantiationException e) {
    throw new RuntimeException(e);
  }
}"
37660,"/** 
 * @return returns a new instance of the configured RetryManager.
 */
public synchronized RetryManager createNewFailedMsgRetryManagerInstance(){
  if (failedMsgRetryManagerClass == null) {
    String classStr=(String)topologyConfig.get(SidelineSpoutConfig.RETRY_MANAGER_CLASS);
    if (Strings.isNullOrEmpty(classStr)) {
      throw new IllegalStateException(""String_Node_Str"" + SidelineSpoutConfig.TUPLE_BUFFER_CLASS);
    }
    try {
      failedMsgRetryManagerClass=(Class<? extends RetryManager>)Class.forName(classStr);
    }
 catch (    ClassNotFoundException e) {
      throw new RuntimeException(e);
    }
  }
  try {
    return failedMsgRetryManagerClass.newInstance();
  }
 catch (  IllegalAccessException|InstantiationException e) {
    throw new RuntimeException(e);
  }
}","/** 
 * @return returns a new instance of the configured RetryManager.
 */
public synchronized RetryManager createNewFailedMsgRetryManagerInstance(){
  if (failedMsgRetryManagerClass == null) {
    String classStr=(String)spoutConfig.get(SidelineSpoutConfig.RETRY_MANAGER_CLASS);
    if (Strings.isNullOrEmpty(classStr)) {
      throw new IllegalStateException(""String_Node_Str"" + SidelineSpoutConfig.TUPLE_BUFFER_CLASS);
    }
    try {
      failedMsgRetryManagerClass=(Class<? extends RetryManager>)Class.forName(classStr);
    }
 catch (    ClassNotFoundException e) {
      throw new RuntimeException(e);
    }
  }
  try {
    return failedMsgRetryManagerClass.newInstance();
  }
 catch (  IllegalAccessException|InstantiationException e) {
    throw new RuntimeException(e);
  }
}"
37661,"/** 
 * @return returns a new instance of the configured TupleBuffer interface.
 */
public synchronized TupleBuffer createNewTupleBufferInstance(){
  if (tupleBufferClass == null) {
    String classStr=(String)topologyConfig.get(SidelineSpoutConfig.TUPLE_BUFFER_CLASS);
    if (Strings.isNullOrEmpty(classStr)) {
      throw new IllegalStateException(""String_Node_Str"" + SidelineSpoutConfig.TUPLE_BUFFER_CLASS);
    }
    try {
      tupleBufferClass=(Class<? extends TupleBuffer>)Class.forName(classStr);
    }
 catch (    ClassNotFoundException e) {
      throw new RuntimeException(e);
    }
  }
  try {
    return tupleBufferClass.newInstance();
  }
 catch (  IllegalAccessException|InstantiationException e) {
    throw new RuntimeException(e);
  }
}","/** 
 * @return returns a new instance of the configured TupleBuffer interface.
 */
public synchronized TupleBuffer createNewTupleBufferInstance(){
  if (tupleBufferClass == null) {
    String classStr=(String)spoutConfig.get(SidelineSpoutConfig.TUPLE_BUFFER_CLASS);
    if (Strings.isNullOrEmpty(classStr)) {
      throw new IllegalStateException(""String_Node_Str"" + SidelineSpoutConfig.TUPLE_BUFFER_CLASS);
    }
    try {
      tupleBufferClass=(Class<? extends TupleBuffer>)Class.forName(classStr);
    }
 catch (    ClassNotFoundException e) {
      throw new RuntimeException(e);
    }
  }
  try {
    return tupleBufferClass.newInstance();
  }
 catch (  IllegalAccessException|InstantiationException e) {
    throw new RuntimeException(e);
  }
}"
37662,"public FactoryManager(Map topologyConfig){
  this.topologyConfig=Tools.immutableCopy(topologyConfig);
}","public FactoryManager(Map spoutConfig){
  this.spoutConfig=Tools.immutableCopy(spoutConfig);
}"
37663,"/** 
 * Generates a VirtualSpoutId using an optional postfix.  It also appends the Task index id.  This will probably cause problems if you decrease the number of instances of the spout.
 * @param id - Id to add after the prefix
 * @return - Generates VirtualSpoutId.
 */
String generateVirtualSpoutId(final String id){
  if (Strings.isNullOrEmpty(id)) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  String newId=(String)getTopologyConfigItem(SidelineSpoutConfig.CONSUMER_ID_PREFIX);
  newId+=""String_Node_Str"" + id;
  return newId;
}","/** 
 * Generates a VirtualSpoutId using an optional postfix.  It also appends the Task index id.  This will probably cause problems if you decrease the number of instances of the spout.
 * @param id - Id to add after the prefix
 * @return - Generates VirtualSpoutId.
 */
String generateVirtualSpoutId(final String id){
  if (Strings.isNullOrEmpty(id)) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  String newId=(String)getSpoutConfigItem(SidelineSpoutConfig.CONSUMER_ID_PREFIX);
  newId+=""String_Node_Str"" + id;
  return newId;
}"
37664,"/** 
 * Open a virtual spout (like when a sideline stop request is made)
 * @param id Id of the sideline request
 * @param step Filter chain step (it will be negate)
 * @param startingState Starting consumer state
 * @param endingState Ending consumer state
 */
private void openVirtualSpout(final SidelineRequestIdentifier id,final FilterChainStep step,final ConsumerState startingState,final ConsumerState endingState){
  final String virtualSpoutId=generateVirtualSpoutId(id.toString());
  logger.debug(""String_Node_Str"",virtualSpoutId,startingState,endingState);
  final VirtualSpout spout=new VirtualSpout(getTopologyConfig(),getTopologyContext(),getFactoryManager(),startingState,endingState);
  spout.setVirtualSpoutId(virtualSpoutId);
  spout.setSidelineRequestIdentifier(id);
  spout.getFilterChain().addStep(id,new NegatingFilterChainStep(step));
  getCoordinator().addSidelineSpout(spout);
}","/** 
 * Open a virtual spout (like when a sideline stop request is made)
 * @param id Id of the sideline request
 * @param step Filter chain step (it will be negate)
 * @param startingState Starting consumer state
 * @param endingState Ending consumer state
 */
private void openVirtualSpout(final SidelineRequestIdentifier id,final FilterChainStep step,final ConsumerState startingState,final ConsumerState endingState){
  final String virtualSpoutId=generateVirtualSpoutId(id.toString());
  logger.debug(""String_Node_Str"",virtualSpoutId,startingState,endingState);
  final VirtualSpout spout=new VirtualSpout(getSpoutConfig(),getTopologyContext(),getFactoryManager(),startingState,endingState);
  spout.setVirtualSpoutId(virtualSpoutId);
  spout.setSidelineRequestIdentifier(id);
  spout.getFilterChain().addStep(id,new NegatingFilterChainStep(step));
  getCoordinator().addSidelineSpout(spout);
}"
37665,"/** 
 * Constructor to create our SidelineSpout.
 * @TODO this method arguments may change to an actual SidelineSpoutConfig object instead of a generic map?
 * @param topologyConfig - Our configuration.
 */
public SidelineSpout(Map topologyConfig){
  this.topologyConfig=Collections.unmodifiableMap(SidelineSpoutConfig.setDefaults(topologyConfig));
  factoryManager=new FactoryManager(getTopologyConfig());
}","/** 
 * Constructor to create our SidelineSpout.
 * @TODO this method arguments may change to an actual SidelineSpoutConfig object instead of a generic map?
 * @param spoutConfig - Our configuration.
 */
public SidelineSpout(Map spoutConfig){
  this.spoutConfig=Collections.unmodifiableMap(SidelineSpoutConfig.setDefaults(spoutConfig));
  factoryManager=new FactoryManager(getSpoutConfig());
}"
37666,"/** 
 * @return - returns the stream that tuples will be emitted out.
 */
String getOutputStreamId(){
  if (outputStreamId == null) {
    if (topologyConfig == null) {
      throw new IllegalStateException(""String_Node_Str"");
    }
    outputStreamId=(String)getTopologyConfigItem(SidelineSpoutConfig.OUTPUT_STREAM_ID);
    if (Strings.isNullOrEmpty(outputStreamId)) {
      outputStreamId=Utils.DEFAULT_STREAM_ID;
    }
  }
  return outputStreamId;
}","/** 
 * @return - returns the stream that tuples will be emitted out.
 */
String getOutputStreamId(){
  if (outputStreamId == null) {
    if (spoutConfig == null) {
      throw new IllegalStateException(""String_Node_Str"");
    }
    outputStreamId=(String)getSpoutConfigItem(SidelineSpoutConfig.OUTPUT_STREAM_ID);
    if (Strings.isNullOrEmpty(outputStreamId)) {
      outputStreamId=Utils.DEFAULT_STREAM_ID;
    }
  }
  return outputStreamId;
}"
37667,"/** 
 * Open is called once the SidelineSpout instance has been deployed to the Storm cluster and is ready to get to work.
 * @param topologyConfig - The Storm Topology configuration.
 * @param topologyContext - The Storm Topology context.
 * @param spoutOutputCollector - The output collector to emit tuples via.
 */
@Override public void open(Map topologyConfig,TopologyContext topologyContext,SpoutOutputCollector spoutOutputCollector){
  this.topologyConfig=Tools.immutableCopy(SidelineSpoutConfig.setDefaults(topologyConfig));
  this.topologyContext=topologyContext;
  this.outputCollector=spoutOutputCollector;
  if (Strings.isNullOrEmpty((String)getTopologyConfigItem(SidelineSpoutConfig.CONSUMER_ID_PREFIX))) {
    throw new IllegalStateException(""String_Node_Str"" + SidelineSpoutConfig.CONSUMER_ID_PREFIX);
  }
  metricsRecorder=getFactoryManager().createNewMetricsRecorder();
  getMetricsRecorder().open(getTopologyConfig(),getTopologyContext());
  if (startingTrigger != null) {
    startingTrigger.setSidelineSpout(new SpoutTriggerProxy(this));
  }
  if (stoppingTrigger != null) {
    stoppingTrigger.setSidelineSpout(new SpoutTriggerProxy(this));
  }
  persistenceAdapter=getFactoryManager().createNewPersistenceAdapterInstance();
  getPersistenceAdapter().open(getTopologyConfig());
  fireHoseSpout=new VirtualSpout(getTopologyConfig(),getTopologyContext(),getFactoryManager());
  fireHoseSpout.setVirtualSpoutId(generateVirtualSpoutId(""String_Node_Str""));
  final TupleBuffer tupleBuffer=getFactoryManager().createNewTupleBufferInstance();
  tupleBuffer.open(getTopologyConfig());
  coordinator=new SpoutCoordinator(fireHoseSpout,getMetricsRecorder(),tupleBuffer);
  getCoordinator().open(getTopologyConfig());
  final ConsumerState currentState=fireHoseSpout.getCurrentState();
  final List<SidelineRequestIdentifier> existingRequestIds=getPersistenceAdapter().listSidelineRequests();
  logger.info(""String_Node_Str"",existingRequestIds.size());
  for (  SidelineRequestIdentifier id : existingRequestIds) {
    final ConsumerState.ConsumerStateBuilder startingStateBuilder=ConsumerState.builder();
    final ConsumerState.ConsumerStateBuilder endingStateStateBuilder=ConsumerState.builder();
    SidelinePayload payload=null;
    for (    final TopicPartition topicPartition : currentState.getTopicPartitions()) {
      payload=getPersistenceAdapter().retrieveSidelineRequest(id,topicPartition.partition());
      if (payload == null) {
        continue;
      }
      startingStateBuilder.withPartition(topicPartition,payload.startingOffset);
      if (payload.endingOffset != null) {
        endingStateStateBuilder.withPartition(topicPartition,payload.endingOffset);
      }
    }
    if (payload == null) {
      logger.warn(""String_Node_Str"",id);
      continue;
    }
    if (payload.type.equals(SidelineType.START)) {
      logger.info(""String_Node_Str"",payload.id,payload.request.step);
      fireHoseSpout.getFilterChain().addStep(payload.id,payload.request.step);
    }
    if (payload.type.equals(SidelineType.STOP)) {
      openVirtualSpout(payload.id,payload.request.step,startingStateBuilder.build(),endingStateStateBuilder.build());
    }
  }
  if (startingTrigger != null) {
    startingTrigger.open(getTopologyConfig());
  }
 else {
    logger.warn(""String_Node_Str"");
  }
  if (stoppingTrigger != null) {
    stoppingTrigger.open(getTopologyConfig());
  }
 else {
    logger.warn(""String_Node_Str"");
  }
  emitCountMetrics=Maps.newHashMap();
}","/** 
 * Open is called once the SidelineSpout instance has been deployed to the Storm cluster and is ready to get to work.
 * @param topologyConfig - The Storm Topology configuration.
 * @param topologyContext - The Storm Topology context.
 * @param spoutOutputCollector - The output collector to emit tuples via.
 */
@Override public void open(Map topologyConfig,TopologyContext topologyContext,SpoutOutputCollector spoutOutputCollector){
  this.topologyConfig=topologyConfig;
  this.topologyContext=topologyContext;
  this.outputCollector=spoutOutputCollector;
  if (Strings.isNullOrEmpty((String)getSpoutConfigItem(SidelineSpoutConfig.CONSUMER_ID_PREFIX))) {
    throw new IllegalStateException(""String_Node_Str"" + SidelineSpoutConfig.CONSUMER_ID_PREFIX);
  }
  metricsRecorder=getFactoryManager().createNewMetricsRecorder();
  getMetricsRecorder().open(getSpoutConfig(),getTopologyContext());
  if (startingTrigger != null) {
    startingTrigger.setSidelineSpout(new SpoutTriggerProxy(this));
  }
  if (stoppingTrigger != null) {
    stoppingTrigger.setSidelineSpout(new SpoutTriggerProxy(this));
  }
  persistenceAdapter=getFactoryManager().createNewPersistenceAdapterInstance();
  getPersistenceAdapter().open(getSpoutConfig());
  fireHoseSpout=new VirtualSpout(getSpoutConfig(),getTopologyContext(),getFactoryManager());
  fireHoseSpout.setVirtualSpoutId(generateVirtualSpoutId(""String_Node_Str""));
  final TupleBuffer tupleBuffer=getFactoryManager().createNewTupleBufferInstance();
  tupleBuffer.open(getSpoutConfig());
  coordinator=new SpoutCoordinator(fireHoseSpout,getMetricsRecorder(),tupleBuffer);
  getCoordinator().open(getSpoutConfig());
  final ConsumerState currentState=fireHoseSpout.getCurrentState();
  final List<SidelineRequestIdentifier> existingRequestIds=getPersistenceAdapter().listSidelineRequests();
  logger.info(""String_Node_Str"",existingRequestIds.size());
  for (  SidelineRequestIdentifier id : existingRequestIds) {
    final ConsumerState.ConsumerStateBuilder startingStateBuilder=ConsumerState.builder();
    final ConsumerState.ConsumerStateBuilder endingStateStateBuilder=ConsumerState.builder();
    SidelinePayload payload=null;
    for (    final TopicPartition topicPartition : currentState.getTopicPartitions()) {
      payload=getPersistenceAdapter().retrieveSidelineRequest(id,topicPartition.partition());
      if (payload == null) {
        continue;
      }
      startingStateBuilder.withPartition(topicPartition,payload.startingOffset);
      if (payload.endingOffset != null) {
        endingStateStateBuilder.withPartition(topicPartition,payload.endingOffset);
      }
    }
    if (payload == null) {
      logger.warn(""String_Node_Str"",id);
      continue;
    }
    if (payload.type.equals(SidelineType.START)) {
      logger.info(""String_Node_Str"",payload.id,payload.request.step);
      fireHoseSpout.getFilterChain().addStep(payload.id,payload.request.step);
    }
    if (payload.type.equals(SidelineType.STOP)) {
      openVirtualSpout(payload.id,payload.request.step,startingStateBuilder.build(),endingStateStateBuilder.build());
    }
  }
  if (startingTrigger != null) {
    startingTrigger.open(getSpoutConfig());
  }
 else {
    logger.warn(""String_Node_Str"");
  }
  if (stoppingTrigger != null) {
    stoppingTrigger.open(getSpoutConfig());
  }
 else {
    logger.warn(""String_Node_Str"");
  }
  emitCountMetrics=Maps.newHashMap();
}"
37668,"public void open(Map topologyConfig){
  persistenceAdapter.open(topologyConfig);
}","public void open(Map spoutConfig){
  persistenceAdapter.open(spoutConfig);
}"
37669,"/** 
 * For testing only! Constructor used in testing to inject SidelineConsumer instance.
 */
protected VirtualSpout(Map topologyConfig,TopologyContext topologyContext,FactoryManager factoryManager,Consumer consumer,ConsumerState startingState,ConsumerState endingState){
  this(topologyConfig,topologyContext,factoryManager,startingState,endingState);
  this.consumer=consumer;
}","/** 
 * For testing only! Constructor used in testing to inject SidelineConsumer instance.
 */
protected VirtualSpout(Map spoutConfig,TopologyContext topologyContext,FactoryManager factoryManager,Consumer consumer,ConsumerState startingState,ConsumerState endingState){
  this(spoutConfig,topologyContext,factoryManager,startingState,endingState);
  this.consumer=consumer;
}"
37670,"/** 
 * Initializes the ""Virtual Spout.""
 */
@Override public void open(){
  if (isOpened) {
    throw new IllegalStateException(""String_Node_Str"");
  }
  isOpened=true;
  logger.info(""String_Node_Str"",startingState);
  logger.info(""String_Node_Str"",endingState);
  deserializer=getFactoryManager().createNewDeserializerInstance();
  retryManager=getFactoryManager().createNewFailedMsgRetryManagerInstance();
  retryManager.open(getTopologyConfig());
  if (consumer == null) {
    final PersistenceAdapter persistenceAdapter=getFactoryManager().createNewPersistenceAdapterInstance();
    persistenceAdapter.open(getTopologyConfig());
    final List<String> kafkaBrokers=(List<String>)getTopologyConfigItem(SidelineSpoutConfig.KAFKA_BROKERS);
    final String topic=(String)getTopologyConfigItem(SidelineSpoutConfig.KAFKA_TOPIC);
    final ConsumerConfig consumerConfig=new ConsumerConfig(kafkaBrokers,getVirtualSpoutId(),topic);
    consumerConfig.setNumberOfConsumers(topologyContext.getComponentTasks(topologyContext.getThisComponentId()).size());
    consumerConfig.setIndexOfConsumer(topologyContext.getThisTaskIndex());
    consumer=new Consumer(consumerConfig,persistenceAdapter);
  }
  consumer.open(startingState);
  nextTupleTimeBuckets.put(""String_Node_Str"",0L);
  nextTupleTimeBuckets.put(""String_Node_Str"",0L);
  nextTupleTimeBuckets.put(""String_Node_Str"",0L);
  nextTupleTimeBuckets.put(""String_Node_Str"",0L);
  nextTupleTimeBuckets.put(""String_Node_Str"",0L);
  nextTupleTimeBuckets.put(""String_Node_Str"",0L);
  nextTupleTimeBuckets.put(""String_Node_Str"",0L);
  nextTupleTimeBuckets.put(""String_Node_Str"",0L);
  nextTupleTimeBuckets.put(""String_Node_Str"",0L);
  ackTimeBuckets.put(""String_Node_Str"",0L);
  ackTimeBuckets.put(""String_Node_Str"",0L);
  ackTimeBuckets.put(""String_Node_Str"",0L);
  ackTimeBuckets.put(""String_Node_Str"",0L);
  ackTimeBuckets.put(""String_Node_Str"",0L);
  ackTimeBuckets.put(""String_Node_Str"",0L);
}","/** 
 * Initializes the ""Virtual Spout.""
 */
@Override public void open(){
  if (isOpened) {
    throw new IllegalStateException(""String_Node_Str"");
  }
  isOpened=true;
  logger.info(""String_Node_Str"",startingState);
  logger.info(""String_Node_Str"",endingState);
  deserializer=getFactoryManager().createNewDeserializerInstance();
  retryManager=getFactoryManager().createNewFailedMsgRetryManagerInstance();
  retryManager.open(getSpoutConfig());
  if (consumer == null) {
    final PersistenceAdapter persistenceAdapter=getFactoryManager().createNewPersistenceAdapterInstance();
    persistenceAdapter.open(getSpoutConfig());
    final List<String> kafkaBrokers=(List<String>)getSpoutConfigItem(SidelineSpoutConfig.KAFKA_BROKERS);
    final String topic=(String)getSpoutConfigItem(SidelineSpoutConfig.KAFKA_TOPIC);
    final ConsumerConfig consumerConfig=new ConsumerConfig(kafkaBrokers,getVirtualSpoutId(),topic);
    consumerConfig.setNumberOfConsumers(topologyContext.getComponentTasks(topologyContext.getThisComponentId()).size());
    consumerConfig.setIndexOfConsumer(topologyContext.getThisTaskIndex());
    consumer=new Consumer(consumerConfig,persistenceAdapter);
  }
  consumer.open(startingState);
  nextTupleTimeBuckets.put(""String_Node_Str"",0L);
  nextTupleTimeBuckets.put(""String_Node_Str"",0L);
  nextTupleTimeBuckets.put(""String_Node_Str"",0L);
  nextTupleTimeBuckets.put(""String_Node_Str"",0L);
  nextTupleTimeBuckets.put(""String_Node_Str"",0L);
  nextTupleTimeBuckets.put(""String_Node_Str"",0L);
  nextTupleTimeBuckets.put(""String_Node_Str"",0L);
  nextTupleTimeBuckets.put(""String_Node_Str"",0L);
  nextTupleTimeBuckets.put(""String_Node_Str"",0L);
  ackTimeBuckets.put(""String_Node_Str"",0L);
  ackTimeBuckets.put(""String_Node_Str"",0L);
  ackTimeBuckets.put(""String_Node_Str"",0L);
  ackTimeBuckets.put(""String_Node_Str"",0L);
  ackTimeBuckets.put(""String_Node_Str"",0L);
  ackTimeBuckets.put(""String_Node_Str"",0L);
}"
37671,"/** 
 * Called to initialize this implementation.
 * @param stormConfig - not used, at least for now.
 */
public void open(Map stormConfig){
  if (stormConfig.containsKey(SidelineSpoutConfig.FAILED_MSG_RETRY_MANAGER_MAX_RETRIES)) {
    maxRetries=((Number)stormConfig.get(SidelineSpoutConfig.FAILED_MSG_RETRY_MANAGER_MAX_RETRIES)).intValue();
  }
  if (stormConfig.containsKey(SidelineSpoutConfig.FAILED_MSG_RETRY_MANAGER_MIN_RETRY_TIME_MS)) {
    minRetryTimeMs=((Number)stormConfig.get(SidelineSpoutConfig.FAILED_MSG_RETRY_MANAGER_MIN_RETRY_TIME_MS)).longValue();
  }
  retriesInFlight=Sets.newHashSet();
  numberOfTimesFailed=Maps.newHashMap();
  failedMessageIds=Maps.newTreeMap();
}","/** 
 * Called to initialize this implementation.
 * @param spoutConfig - not used, at least for now.
 */
public void open(Map spoutConfig){
  if (spoutConfig.containsKey(SidelineSpoutConfig.FAILED_MSG_RETRY_MANAGER_MAX_RETRIES)) {
    maxRetries=((Number)spoutConfig.get(SidelineSpoutConfig.FAILED_MSG_RETRY_MANAGER_MAX_RETRIES)).intValue();
  }
  if (spoutConfig.containsKey(SidelineSpoutConfig.FAILED_MSG_RETRY_MANAGER_MIN_RETRY_TIME_MS)) {
    minRetryTimeMs=((Number)spoutConfig.get(SidelineSpoutConfig.FAILED_MSG_RETRY_MANAGER_MIN_RETRY_TIME_MS)).longValue();
  }
  retriesInFlight=Sets.newHashSet();
  numberOfTimesFailed=Maps.newHashMap();
  failedMessageIds=Maps.newTreeMap();
}"
37672,"@Override public void open(Map stormConfig){
  messageIdsInFlight=Sets.newHashSet();
  failedMessageIds=new LinkedList<>();
}","@Override public void open(Map spoutConfig){
  messageIdsInFlight=Sets.newHashSet();
  failedMessageIds=new LinkedList<>();
}"
37673,"@Override public void open(Map stormConfig){
}","@Override public void open(Map spoutConfig){
}"
37674,"/** 
 * Initialization.
 */
void open(Map stormConfig);","/** 
 * Initialization.
 */
void open(Map spoutConfig);"
37675,"/** 
 * @return - the maximum amount of concurrently running VirtualSpouts we'll start.
 */
int getMaxConcurrentVirtualSpouts(){
  return (int)getTopologyConfig().get(SidelineSpoutConfig.MAX_CONCURRENT_VIRTUAL_SPOUTS);
}","/** 
 * @return - the maximum amount of concurrently running VirtualSpouts we'll start.
 */
int getMaxConcurrentVirtualSpouts(){
  return ((Number)getTopologyConfig().get(SidelineSpoutConfig.MAX_CONCURRENT_VIRTUAL_SPOUTS)).intValue();
}"
37676,"/** 
 * Called to initialize this implementation.
 * @param stormConfig - not used, at least for now.
 */
public void open(Map stormConfig){
  if (stormConfig.containsKey(SidelineSpoutConfig.FAILED_MSG_RETRY_MANAGER_MAX_RETRIES)) {
    maxRetries=(int)stormConfig.get(SidelineSpoutConfig.FAILED_MSG_RETRY_MANAGER_MAX_RETRIES);
  }
  if (stormConfig.containsKey(SidelineSpoutConfig.FAILED_MSG_RETRY_MANAGER_MIN_RETRY_TIME_MS)) {
    minRetryTimeMs=(long)stormConfig.get(SidelineSpoutConfig.FAILED_MSG_RETRY_MANAGER_MIN_RETRY_TIME_MS);
  }
  retriesInFlight=Sets.newHashSet();
  numberOfTimesFailed=Maps.newHashMap();
  failedMessageIds=Maps.newTreeMap();
}","/** 
 * Called to initialize this implementation.
 * @param stormConfig - not used, at least for now.
 */
public void open(Map stormConfig){
  if (stormConfig.containsKey(SidelineSpoutConfig.FAILED_MSG_RETRY_MANAGER_MAX_RETRIES)) {
    maxRetries=((Number)stormConfig.get(SidelineSpoutConfig.FAILED_MSG_RETRY_MANAGER_MAX_RETRIES)).intValue();
  }
  if (stormConfig.containsKey(SidelineSpoutConfig.FAILED_MSG_RETRY_MANAGER_MIN_RETRY_TIME_MS)) {
    minRetryTimeMs=(long)stormConfig.get(SidelineSpoutConfig.FAILED_MSG_RETRY_MANAGER_MIN_RETRY_TIME_MS);
  }
  retriesInFlight=Sets.newHashSet();
  numberOfTimesFailed=Maps.newHashMap();
  failedMessageIds=Maps.newTreeMap();
}"
37677,"/** 
 * Not thread safe.
 * @return
 */
public long lastFinishedOffset(){
  return lastFinishedOffset;
}","/** 
 * Not thread safe.
 * @return - return the last offset considered ""finished"".Here a ""finished"" offset is the highest continuous offset.
 */
public long lastFinishedOffset(){
  return lastFinishedOffset;
}"
37678,"/** 
 * Internal method used to fill internal message buffer from kafka. Maybe this should be marked private.
 */
public void fillBuffer(){
  if (buffer == null || !bufferIterator.hasNext()) {
    buffer=kafkaConsumer.poll(3000);
    bufferIterator=buffer.iterator();
  }
}","/** 
 * Internal method used to fill internal message buffer from kafka. Maybe this should be marked private.
 */
public void fillBuffer(){
  if (buffer == null || !bufferIterator.hasNext()) {
    try {
      buffer=kafkaConsumer.poll(3000);
    }
 catch (    OffsetOutOfRangeException outOfRangeException) {
      handleOffsetOutOfRange(outOfRangeException);
      buffer=null;
      bufferIterator=null;
      fillBuffer();
      return;
    }
    bufferIterator=buffer.iterator();
  }
}"
37679,"/** 
 * Handles connecting to the Kafka cluster, determining which partitions to subscribe to, and based on previously saved state from ConsumerStateManager, seek to the last positions processed on each partition. Warning: Consumes from ALL partitions.
 * @param startingState Starting state of the consumer
 * @param partitions The partitions to consume from
 */
public void open(ConsumerState startingState,List<PartitionInfo> partitions){
  if (isOpen) {
    throw new RuntimeException(""String_Node_Str"");
  }
  isOpen=true;
  if (startingState != null) {
    persistenceManager.persistConsumerState(getConsumerId(),startingState);
  }
  ConsumerState initialState=persistenceManager.retrieveConsumerState(getConsumerId());
  if (initialState == null) {
    initialState=new ConsumerState();
  }
  final KafkaConsumer kafkaConsumer=getKafkaConsumer();
  List<TopicPartition> allTopicPartitions=Lists.newArrayList();
  for (  PartitionInfo partition : partitions) {
    allTopicPartitions.add(new TopicPartition(partition.topic(),partition.partition()));
  }
  kafkaConsumer.assign(allTopicPartitions);
  List<TopicPartition> noStatePartitions=Lists.newArrayList();
  for (  PartitionInfo partition : partitions) {
    final TopicPartition availableTopicPartition=new TopicPartition(partition.topic(),partition.partition());
    Long offset=initialState.getOffsetForTopicAndPartition(availableTopicPartition);
    if (offset == null) {
      noStatePartitions.add(availableTopicPartition);
      offset=-1L;
    }
 else {
      logger.info(""String_Node_Str"",availableTopicPartition.topic(),availableTopicPartition.partition(),(offset + 1));
      kafkaConsumer.seek(availableTopicPartition,offset + 1);
      logger.info(""String_Node_Str"",kafkaConsumer.position(availableTopicPartition));
    }
    partitionStateManagers.put(availableTopicPartition,new PartitionOffsetManager(availableTopicPartition.topic(),availableTopicPartition.partition(),offset));
  }
  if (!noStatePartitions.isEmpty()) {
    logger.info(""String_Node_Str"",noStatePartitions);
    kafkaConsumer.seekToBeginning(noStatePartitions);
  }
}","/** 
 * Handles connecting to the Kafka cluster, determining which partitions to subscribe to, and based on previously saved state from ConsumerStateManager, seek to the last positions processed on each partition. Warning: Consumes from ALL partitions.
 * @param startingState Starting state of the consumer
 * @param partitions The partitions to consume from
 */
public void open(ConsumerState startingState,List<PartitionInfo> partitions){
  if (isOpen) {
    throw new RuntimeException(""String_Node_Str"");
  }
  isOpen=true;
  if (startingState != null) {
    persistenceManager.persistConsumerState(getConsumerId(),startingState);
  }
  ConsumerState initialState=persistenceManager.retrieveConsumerState(getConsumerId());
  if (initialState == null) {
    initialState=new ConsumerState();
  }
  final KafkaConsumer kafkaConsumer=getKafkaConsumer();
  List<TopicPartition> allTopicPartitions=Lists.newArrayList();
  for (  PartitionInfo partition : partitions) {
    allTopicPartitions.add(new TopicPartition(partition.topic(),partition.partition()));
  }
  kafkaConsumer.assign(allTopicPartitions);
  List<TopicPartition> noStatePartitions=Lists.newArrayList();
  for (  PartitionInfo partition : partitions) {
    final TopicPartition availableTopicPartition=new TopicPartition(partition.topic(),partition.partition());
    Long offset=initialState.getOffsetForTopicAndPartition(availableTopicPartition);
    if (offset == null) {
      noStatePartitions.add(availableTopicPartition);
    }
 else {
      logger.info(""String_Node_Str"",availableTopicPartition.topic(),availableTopicPartition.partition(),(offset + 1));
      getKafkaConsumer().seek(availableTopicPartition,offset + 1);
      logger.info(""String_Node_Str"",kafkaConsumer.position(availableTopicPartition));
      partitionStateManagers.put(availableTopicPartition,new PartitionOffsetManager(availableTopicPartition.topic(),availableTopicPartition.partition(),offset));
    }
  }
  if (!noStatePartitions.isEmpty()) {
    logger.info(""String_Node_Str"",noStatePartitions);
    resetPartitionsToEarliest(noStatePartitions);
  }
}"
37680,"/** 
 * Creates and starts ZooKeeper and Kafka server instances.
 * @throws Exception
 */
public void start() throws Exception {
  InstanceSpec zkInstanceSpec=new InstanceSpec(null,21811,-1,-1,true,-1,-1,1000);
  zkServer=new TestingServer(zkInstanceSpec,true);
  String connectionString=getZkServer().getConnectString();
  File logDir=new File(""String_Node_Str"" + Double.toHexString(Math.random()));
  String kafkaPort=String.valueOf(InstanceSpec.getRandomPort());
  Properties p=new Properties();
  p.setProperty(""String_Node_Str"",connectionString);
  p.setProperty(""String_Node_Str"",String.valueOf(new Random().nextInt(Integer.MAX_VALUE)));
  p.setProperty(""String_Node_Str"",kafkaPort);
  p.setProperty(""String_Node_Str"",logDir.getAbsolutePath());
  p.setProperty(""String_Node_Str"",""String_Node_Str"");
  p.setProperty(""String_Node_Str"",""String_Node_Str"");
  p.setProperty(""String_Node_Str"",kafkaPort);
  p.setProperty(""String_Node_Str"",""String_Node_Str"");
  p.setProperty(""String_Node_Str"",""String_Node_Str"");
  p.setProperty(""String_Node_Str"",""String_Node_Str"");
  KafkaConfig config=new KafkaConfig(p);
  kafka=new KafkaServerStartable(config);
  getKafkaServer().startup();
  cli=CuratorFrameworkFactory.newClient(getZkServer().getConnectString(),new RetryOneTime(2000));
}","/** 
 * Creates and starts ZooKeeper and Kafka server instances.
 * @throws Exception
 */
public void start() throws Exception {
  InstanceSpec zkInstanceSpec=new InstanceSpec(null,21811,-1,-1,true,-1,-1,1000);
  zkServer=new TestingServer(zkInstanceSpec,true);
  String connectionString=getZkServer().getConnectString();
  File logDir=new File(""String_Node_Str"" + Double.toHexString(Math.random()));
  String kafkaPort=String.valueOf(InstanceSpec.getRandomPort());
  Properties p=new Properties();
  p.setProperty(""String_Node_Str"",connectionString);
  p.setProperty(""String_Node_Str"",kafkaPort);
  p.setProperty(""String_Node_Str"",logDir.getAbsolutePath());
  p.setProperty(""String_Node_Str"",""String_Node_Str"");
  p.setProperty(""String_Node_Str"",""String_Node_Str"");
  p.setProperty(""String_Node_Str"",kafkaPort);
  p.setProperty(""String_Node_Str"",""String_Node_Str"");
  p.setProperty(""String_Node_Str"",""String_Node_Str"");
  p.setProperty(""String_Node_Str"",""String_Node_Str"");
  KafkaConfig config=new KafkaConfig(p);
  kafka=new KafkaServerStartable(config);
  getKafkaServer().startup();
  cli=CuratorFrameworkFactory.newClient(getZkServer().getConnectString(),new RetryOneTime(2000));
}"
37681,"/** 
 * Start the filter of tracking this offset Not thread safe
 * @param offset
 */
public void startOffset(long offset){
  trackedOffsets.add(offset);
  if (offset > lastStartedOffset) {
    lastStartedOffset=offset;
  }
 else {
    logger.warn(""String_Node_Str"",lastStartedOffset,offset);
  }
}","/** 
 * Start the filter of tracking this offset Not thread safe
 * @param offset
 */
public void startOffset(long offset){
  trackedOffsets.add(offset);
  if (offset >= lastStartedOffset) {
    lastStartedOffset=offset;
  }
 else {
    logger.warn(""String_Node_Str"",lastStartedOffset,offset);
  }
}"
37682,"/** 
 * Internal method that given a collection of topic partitions will find the earliest offset for that partition, seek the underlying consumer to it, and reset its internal offset tracking to that new position. This should be used when no state exists for a given partition, OR if the offset requested was too old.
 * @param topicPartitions - the collection of offsets to reset offsets for to the earliest position.
 */
private void resetPartitionsToEarliest(Collection<TopicPartition> topicPartitions){
  logger.info(""String_Node_Str"",topicPartitions);
  getKafkaConsumer().seekToBeginning(topicPartitions);
  for (  TopicPartition topicPartition : topicPartitions) {
    final long newOffset=getKafkaConsumer().position(topicPartition);
    logger.info(""String_Node_Str"",topicPartition,newOffset);
    partitionStateManagers.put(topicPartition,new PartitionOffsetManager(topicPartition.topic(),topicPartition.partition(),newOffset));
  }
  logger.info(""String_Node_Str"",getKafkaConsumer().assignment());
}","/** 
 * Internal method that given a collection of topic partitions will find the earliest offset for that partition, seek the underlying consumer to it, and reset its internal offset tracking to that new position. This should be used when no state exists for a given partition, OR if the offset requested was too old.
 * @param topicPartitions - the collection of offsets to reset offsets for to the earliest position.
 */
private void resetPartitionsToEarliest(Collection<TopicPartition> topicPartitions){
  logger.info(""String_Node_Str"",topicPartitions);
  getKafkaConsumer().seekToBeginning(topicPartitions);
  for (  TopicPartition topicPartition : topicPartitions) {
    final long newOffset=getKafkaConsumer().position(topicPartition) - 1;
    logger.info(""String_Node_Str"",topicPartition,newOffset);
    partitionStateManagers.put(topicPartition,new PartitionOffsetManager(topicPartition.topic(),topicPartition.partition(),newOffset));
  }
  logger.info(""String_Node_Str"",getKafkaConsumer().assignment());
}"
37683,"/** 
 * We attempt to consume from the topic and get our expected messages. We ack the messages each as we get it, in order, one by one.
 */
@Test public void testSimpleConsumeFromTopicWithAckingInOrderAllAtTheEnd(){
  final int numberOfRecordsToProduce=5;
  final TopicPartition partition0=new TopicPartition(topicName,0);
  final List<ProducerRecord<byte[],byte[]>> producedRecords=produceRecords(numberOfRecordsToProduce);
  List<String> brokerHosts=Lists.newArrayList(kafkaTestServer.getKafkaServer().serverConfig().advertisedHostName() + ""String_Node_Str"" + kafkaTestServer.getKafkaServer().serverConfig().advertisedPort());
  SidelineConsumerConfig config=new SidelineConsumerConfig(brokerHosts,""String_Node_Str"",topicName);
  config.setKafkaConsumerProperty(""String_Node_Str"",""String_Node_Str"");
  PersistenceManager persistenceManager=new InMemoryPersistenceManager();
  persistenceManager.open(Maps.newHashMap());
  SidelineConsumer sidelineConsumer=new SidelineConsumer(config,persistenceManager);
  sidelineConsumer.open(null);
  List<ConsumerRecord> foundRecords=Lists.newArrayList();
  for (int x=0; x < numberOfRecordsToProduce; x++) {
    ConsumerRecord<byte[],byte[]> foundRecord=sidelineConsumer.nextRecord();
    assertNotNull(foundRecord);
    foundRecords.add(foundRecord);
    ProducerRecord<byte[],byte[]> expectedRecord=producedRecords.get(x);
    logger.info(""String_Node_Str"",expectedRecord.key(),foundRecord.key());
    assertEquals(""String_Node_Str"",new String(expectedRecord.key(),Charsets.UTF_8),new String(foundRecord.key(),Charsets.UTF_8));
    assertEquals(""String_Node_Str"",new String(expectedRecord.value(),Charsets.UTF_8),new String(foundRecord.value(),Charsets.UTF_8));
  }
  logger.info(""String_Node_Str"",sidelineConsumer.flushConsumerState());
  validateConsumerState(sidelineConsumer.flushConsumerState(),partition0,-1L);
  for (  ConsumerRecord foundRecord : foundRecords) {
    sidelineConsumer.commitOffset(foundRecord);
  }
  ConsumerState consumerState=sidelineConsumer.flushConsumerState();
  validateConsumerState(consumerState,partition0,(numberOfRecordsToProduce - 1));
  logger.info(""String_Node_Str"",sidelineConsumer.flushConsumerState());
  sidelineConsumer.close();
}","/** 
 * We attempt to consume from the topic and get our expected messages. We ack the messages each as we get it, in order, one by one.
 */
@Test public void testSimpleConsumeFromTopicWithAckingInOrderAllAtTheEnd(){
  final int numberOfRecordsToProduce=5;
  final TopicPartition partition0=new TopicPartition(topicName,0);
  final List<ProducerRecord<byte[],byte[]>> producedRecords=produceRecords(numberOfRecordsToProduce);
  List<String> brokerHosts=Lists.newArrayList(kafkaTestServer.getKafkaServer().serverConfig().advertisedHostName() + ""String_Node_Str"" + kafkaTestServer.getKafkaServer().serverConfig().advertisedPort());
  SidelineConsumerConfig config=new SidelineConsumerConfig(brokerHosts,""String_Node_Str"",topicName);
  PersistenceManager persistenceManager=new InMemoryPersistenceManager();
  persistenceManager.open(Maps.newHashMap());
  SidelineConsumer sidelineConsumer=new SidelineConsumer(config,persistenceManager);
  sidelineConsumer.open(null);
  List<ConsumerRecord> foundRecords=Lists.newArrayList();
  for (int x=0; x < numberOfRecordsToProduce; x++) {
    ConsumerRecord<byte[],byte[]> foundRecord=sidelineConsumer.nextRecord();
    assertNotNull(foundRecord);
    foundRecords.add(foundRecord);
    ProducerRecord<byte[],byte[]> expectedRecord=producedRecords.get(x);
    logger.info(""String_Node_Str"",expectedRecord.key(),foundRecord.key());
    assertEquals(""String_Node_Str"",new String(expectedRecord.key(),Charsets.UTF_8),new String(foundRecord.key(),Charsets.UTF_8));
    assertEquals(""String_Node_Str"",new String(expectedRecord.value(),Charsets.UTF_8),new String(foundRecord.value(),Charsets.UTF_8));
  }
  logger.info(""String_Node_Str"",sidelineConsumer.flushConsumerState());
  validateConsumerState(sidelineConsumer.flushConsumerState(),partition0,-1L);
  for (  ConsumerRecord foundRecord : foundRecords) {
    sidelineConsumer.commitOffset(foundRecord);
  }
  ConsumerState consumerState=sidelineConsumer.flushConsumerState();
  validateConsumerState(consumerState,partition0,(numberOfRecordsToProduce - 1));
  logger.info(""String_Node_Str"",sidelineConsumer.flushConsumerState());
  sidelineConsumer.close();
}"
37684,"private SidelineConsumerConfig getDefaultSidelineConsumerConfig(final String topicName){
  List<String> brokerHosts=Lists.newArrayList(kafkaTestServer.getKafkaServer().serverConfig().advertisedHostName() + ""String_Node_Str"" + kafkaTestServer.getKafkaServer().serverConfig().advertisedPort());
  SidelineConsumerConfig config=new SidelineConsumerConfig(brokerHosts,""String_Node_Str"",topicName);
  config.setKafkaConsumerProperty(""String_Node_Str"",""String_Node_Str"");
  return config;
}","private SidelineConsumerConfig getDefaultSidelineConsumerConfig(final String topicName){
  List<String> brokerHosts=Lists.newArrayList(kafkaTestServer.getKafkaServer().serverConfig().advertisedHostName() + ""String_Node_Str"" + kafkaTestServer.getKafkaServer().serverConfig().advertisedPort());
  SidelineConsumerConfig config=new SidelineConsumerConfig(brokerHosts,""String_Node_Str"",topicName);
  return config;
}"
37685,"/** 
 * Tests the constructor saves off instances of things passed into it properly.
 */
@Test public void testConstructor(){
  List<String> brokerHosts=Lists.newArrayList(kafkaTestServer.getKafkaServer().serverConfig().advertisedHostName() + ""String_Node_Str"" + kafkaTestServer.getKafkaServer().serverConfig().advertisedPort());
  final SidelineConsumerConfig config=new SidelineConsumerConfig(brokerHosts,""String_Node_Str"",topicName);
  config.setKafkaConsumerProperty(""String_Node_Str"",""String_Node_Str"");
  PersistenceManager persistenceManager=new InMemoryPersistenceManager();
  persistenceManager.open(Maps.newHashMap());
  SidelineConsumer sidelineConsumer=new SidelineConsumer(config,persistenceManager);
  assertNotNull(""String_Node_Str"",sidelineConsumer.getConsumerConfig());
  assertEquals(config,sidelineConsumer.getConsumerConfig());
  assertNotNull(""String_Node_Str"",sidelineConsumer.getPersistenceManager());
  assertEquals(persistenceManager,sidelineConsumer.getPersistenceManager());
}","/** 
 * Tests the constructor saves off instances of things passed into it properly.
 */
@Test public void testConstructor(){
  final SidelineConsumerConfig config=getDefaultSidelineConsumerConfig(topicName);
  PersistenceManager persistenceManager=new InMemoryPersistenceManager();
  persistenceManager.open(Maps.newHashMap());
  SidelineConsumer sidelineConsumer=new SidelineConsumer(config,persistenceManager);
  assertNotNull(""String_Node_Str"",sidelineConsumer.getConsumerConfig());
  assertEquals(config,sidelineConsumer.getConsumerConfig());
  assertNotNull(""String_Node_Str"",sidelineConsumer.getPersistenceManager());
  assertEquals(persistenceManager,sidelineConsumer.getPersistenceManager());
}"
37686,"/** 
 * Verifies that when we call connect that it makes the appropriate calls to ConsumerStateManager to initialize. This test has the ConsumerStateManager (a mock) return ConsumerState. We verify that our internal kafka client then knows to start reading its partition from the previously saved off consumer state returned from ConsumerStateManager.
 */
@Test public void testConnectWithSinglePartitionOnTopicWithStateSaved(){
  final String consumerId=""String_Node_Str"";
  final long lastCommittedOffset=12345L;
  final long expectedOffsetToStartConsumeFrom=lastCommittedOffset + 1;
  List<String> brokerHosts=Lists.newArrayList(kafkaTestServer.getKafkaServer().serverConfig().advertisedHostName() + ""String_Node_Str"" + kafkaTestServer.getKafkaServer().serverConfig().advertisedPort());
  final SidelineConsumerConfig config=new SidelineConsumerConfig(brokerHosts,consumerId,topicName);
  config.setKafkaConsumerProperty(""String_Node_Str"",""String_Node_Str"");
  KafkaConsumer<byte[],byte[]> mockKafkaConsumer=mock(KafkaConsumer.class);
  List<PartitionInfo> mockPartitionInfos=Lists.newArrayList(new PartitionInfo(topicName,0,new Node(0,""String_Node_Str"",9092),new Node[0],new Node[0]));
  when(mockKafkaConsumer.partitionsFor(eq(topicName))).thenReturn(mockPartitionInfos);
  PersistenceManager mockPersistenceManager=mock(PersistenceManager.class);
  ConsumerState consumerState=new ConsumerState();
  consumerState.setOffset(new TopicPartition(topicName,0),lastCommittedOffset);
  when(mockPersistenceManager.retrieveConsumerState(eq(consumerId))).thenReturn(consumerState);
  SidelineConsumer sidelineConsumer=new SidelineConsumer(config,mockPersistenceManager,mockKafkaConsumer);
  sidelineConsumer.open(null);
  verify(mockKafkaConsumer,times(1)).assign(eq(Lists.newArrayList(new TopicPartition(topicName,0))));
  verify(mockKafkaConsumer,never()).seekToBeginning(eq(Lists.newArrayList(new TopicPartition(topicName,0))));
  verify(mockKafkaConsumer,times(1)).seek(eq(new TopicPartition(topicName,0)),eq(expectedOffsetToStartConsumeFrom));
}","/** 
 * Verifies that when we call connect that it makes the appropriate calls to ConsumerStateManager to initialize. This test has the ConsumerStateManager (a mock) return ConsumerState. We verify that our internal kafka client then knows to start reading its partition from the previously saved off consumer state returned from ConsumerStateManager.
 */
@Test public void testConnectWithSinglePartitionOnTopicWithStateSaved(){
  final String consumerId=""String_Node_Str"";
  final long lastCommittedOffset=12345L;
  final long expectedOffsetToStartConsumeFrom=lastCommittedOffset + 1;
  List<String> brokerHosts=Lists.newArrayList(kafkaTestServer.getKafkaServer().serverConfig().advertisedHostName() + ""String_Node_Str"" + kafkaTestServer.getKafkaServer().serverConfig().advertisedPort());
  final SidelineConsumerConfig config=new SidelineConsumerConfig(brokerHosts,consumerId,topicName);
  KafkaConsumer<byte[],byte[]> mockKafkaConsumer=mock(KafkaConsumer.class);
  List<PartitionInfo> mockPartitionInfos=Lists.newArrayList(new PartitionInfo(topicName,0,new Node(0,""String_Node_Str"",9092),new Node[0],new Node[0]));
  when(mockKafkaConsumer.partitionsFor(eq(topicName))).thenReturn(mockPartitionInfos);
  PersistenceManager mockPersistenceManager=mock(PersistenceManager.class);
  ConsumerState consumerState=new ConsumerState();
  consumerState.setOffset(new TopicPartition(topicName,0),lastCommittedOffset);
  when(mockPersistenceManager.retrieveConsumerState(eq(consumerId))).thenReturn(consumerState);
  SidelineConsumer sidelineConsumer=new SidelineConsumer(config,mockPersistenceManager,mockKafkaConsumer);
  sidelineConsumer.open(null);
  verify(mockKafkaConsumer,times(1)).assign(eq(Lists.newArrayList(new TopicPartition(topicName,0))));
  verify(mockKafkaConsumer,never()).seekToBeginning(eq(Lists.newArrayList(new TopicPartition(topicName,0))));
  verify(mockKafkaConsumer,times(1)).seek(eq(new TopicPartition(topicName,0)),eq(expectedOffsetToStartConsumeFrom));
}"
37687,"/** 
 * Tests that our logic for flushing consumer state is disabled if auto commit is disabled. This is kind of a weak test for this.
 */
@Test public void testTimedFlushConsumerStateWhenAutoCommitIsDisabled() throws InterruptedException {
  final String expectedConsumerId=""String_Node_Str"";
  List<String> brokerHosts=Lists.newArrayList(kafkaTestServer.getKafkaServer().serverConfig().advertisedHostName() + ""String_Node_Str"" + kafkaTestServer.getKafkaServer().serverConfig().advertisedPort());
  final SidelineConsumerConfig config=new SidelineConsumerConfig(brokerHosts,expectedConsumerId,topicName);
  config.setConsumerStateAutoCommit(false);
  config.setConsumerStateAutoCommitIntervalMs(1000);
  PersistenceManager mockPersistenceManager=mock(PersistenceManager.class);
  Instant instant=Clock.systemUTC().instant();
  Clock mockClock=Clock.fixed(instant,ZoneId.systemDefault());
  SidelineConsumer sidelineConsumer=new SidelineConsumer(config,mockPersistenceManager);
  sidelineConsumer.setClock(mockClock);
  sidelineConsumer.timedFlushConsumerState();
  verify(mockPersistenceManager,never()).persistConsumerState(anyString(),anyObject());
  Thread.sleep(1500);
  sidelineConsumer.timedFlushConsumerState();
  verify(mockPersistenceManager,never()).persistConsumerState(anyString(),anyObject());
  instant=instant.plus(2000,ChronoUnit.MILLIS);
  mockClock=Clock.fixed(instant,ZoneId.systemDefault());
  sidelineConsumer.setClock(mockClock);
  sidelineConsumer.timedFlushConsumerState();
  verify(mockPersistenceManager,never()).persistConsumerState(anyString(),anyObject());
  sidelineConsumer.timedFlushConsumerState();
  verify(mockPersistenceManager,never()).persistConsumerState(anyString(),anyObject());
  instant=instant.plus(1500,ChronoUnit.MILLIS);
  mockClock=Clock.fixed(instant,ZoneId.systemDefault());
  sidelineConsumer.setClock(mockClock);
  sidelineConsumer.timedFlushConsumerState();
  verify(mockPersistenceManager,never()).persistConsumerState(anyString(),anyObject());
}","/** 
 * Tests that our logic for flushing consumer state is disabled if auto commit is disabled. This is kind of a weak test for this.
 */
@Test public void testTimedFlushConsumerStateWhenAutoCommitIsDisabled() throws InterruptedException {
  final SidelineConsumerConfig config=getDefaultSidelineConsumerConfig(topicName);
  config.setConsumerStateAutoCommit(false);
  config.setConsumerStateAutoCommitIntervalMs(1000);
  PersistenceManager mockPersistenceManager=mock(PersistenceManager.class);
  Instant instant=Clock.systemUTC().instant();
  Clock mockClock=Clock.fixed(instant,ZoneId.systemDefault());
  SidelineConsumer sidelineConsumer=new SidelineConsumer(config,mockPersistenceManager);
  sidelineConsumer.setClock(mockClock);
  sidelineConsumer.timedFlushConsumerState();
  verify(mockPersistenceManager,never()).persistConsumerState(anyString(),anyObject());
  Thread.sleep(1500);
  sidelineConsumer.timedFlushConsumerState();
  verify(mockPersistenceManager,never()).persistConsumerState(anyString(),anyObject());
  instant=instant.plus(2000,ChronoUnit.MILLIS);
  mockClock=Clock.fixed(instant,ZoneId.systemDefault());
  sidelineConsumer.setClock(mockClock);
  sidelineConsumer.timedFlushConsumerState();
  verify(mockPersistenceManager,never()).persistConsumerState(anyString(),anyObject());
  sidelineConsumer.timedFlushConsumerState();
  verify(mockPersistenceManager,never()).persistConsumerState(anyString(),anyObject());
  instant=instant.plus(1500,ChronoUnit.MILLIS);
  mockClock=Clock.fixed(instant,ZoneId.systemDefault());
  sidelineConsumer.setClock(mockClock);
  sidelineConsumer.timedFlushConsumerState();
  verify(mockPersistenceManager,never()).persistConsumerState(anyString(),anyObject());
}"
37688,"/** 
 * Verifies that when we call connect that it makes the appropriate calls to ConsumerStateManager to initialize. This test has the ConsumerStateManager (a mock) return an empty ConsumerState. We verify that our internal kafka client then knows to start reading every partition from the earliest available offset.
 */
@Test public void testConnectWithSinglePartitionOnTopicWithNoStateSaved(){
  final String consumerId=""String_Node_Str"";
  List<String> brokerHosts=Lists.newArrayList(kafkaTestServer.getKafkaServer().serverConfig().advertisedHostName() + ""String_Node_Str"" + kafkaTestServer.getKafkaServer().serverConfig().advertisedPort());
  final SidelineConsumerConfig config=new SidelineConsumerConfig(brokerHosts,consumerId,topicName);
  config.setKafkaConsumerProperty(""String_Node_Str"",""String_Node_Str"");
  KafkaConsumer<byte[],byte[]> mockKafkaConsumer=mock(KafkaConsumer.class);
  List<PartitionInfo> mockPartitionInfos=Lists.newArrayList(new PartitionInfo(topicName,0,new Node(0,""String_Node_Str"",9092),new Node[0],new Node[0]));
  when(mockKafkaConsumer.partitionsFor(eq(topicName))).thenReturn(mockPartitionInfos);
  PersistenceManager mockPersistenceManager=mock(PersistenceManager.class);
  ConsumerState emptyConsumerState=new ConsumerState();
  when(mockPersistenceManager.retrieveConsumerState(eq(consumerId))).thenReturn(emptyConsumerState);
  SidelineConsumer sidelineConsumer=new SidelineConsumer(config,mockPersistenceManager,mockKafkaConsumer);
  sidelineConsumer.open(null);
  verify(mockKafkaConsumer,times(1)).assign(eq(Lists.newArrayList(new TopicPartition(topicName,0))));
  verify(mockKafkaConsumer,times(1)).seekToBeginning(eq(Lists.newArrayList(new TopicPartition(topicName,0))));
}","/** 
 * Verifies that when we call connect that it makes the appropriate calls to ConsumerStateManager to initialize. This test has the ConsumerStateManager (a mock) return an empty ConsumerState. We verify that our internal kafka client then knows to start reading every partition from the earliest available offset.
 */
@Test public void testConnectWithSinglePartitionOnTopicWithNoStateSaved(){
  final String consumerId=""String_Node_Str"";
  List<String> brokerHosts=Lists.newArrayList(kafkaTestServer.getKafkaServer().serverConfig().advertisedHostName() + ""String_Node_Str"" + kafkaTestServer.getKafkaServer().serverConfig().advertisedPort());
  final SidelineConsumerConfig config=new SidelineConsumerConfig(brokerHosts,consumerId,topicName);
  KafkaConsumer<byte[],byte[]> mockKafkaConsumer=mock(KafkaConsumer.class);
  List<PartitionInfo> mockPartitionInfos=Lists.newArrayList(new PartitionInfo(topicName,0,new Node(0,""String_Node_Str"",9092),new Node[0],new Node[0]));
  when(mockKafkaConsumer.partitionsFor(eq(topicName))).thenReturn(mockPartitionInfos);
  PersistenceManager mockPersistenceManager=mock(PersistenceManager.class);
  ConsumerState emptyConsumerState=new ConsumerState();
  when(mockPersistenceManager.retrieveConsumerState(eq(consumerId))).thenReturn(emptyConsumerState);
  SidelineConsumer sidelineConsumer=new SidelineConsumer(config,mockPersistenceManager,mockKafkaConsumer);
  sidelineConsumer.open(null);
  verify(mockKafkaConsumer,times(1)).assign(eq(Lists.newArrayList(new TopicPartition(topicName,0))));
  verify(mockKafkaConsumer,times(1)).seekToBeginning(eq(Lists.newArrayList(new TopicPartition(topicName,0))));
}"
37689,"/** 
 * We attempt to consume from the topic and get our expected messages. We ack the messages each as we get it, in order, one by one.
 */
@Test public void testSimpleConsumeFromTopicWithAckingOutOfOrderAllAtTheEnd(){
  final int numberOfRecordsToProduce=9;
  final TopicPartition partition0=new TopicPartition(topicName,0);
  final List<ProducerRecord<byte[],byte[]>> producedRecords=produceRecords(numberOfRecordsToProduce);
  List<String> brokerHosts=Lists.newArrayList(kafkaTestServer.getKafkaServer().serverConfig().advertisedHostName() + ""String_Node_Str"" + kafkaTestServer.getKafkaServer().serverConfig().advertisedPort());
  SidelineConsumerConfig config=new SidelineConsumerConfig(brokerHosts,""String_Node_Str"",topicName);
  config.setKafkaConsumerProperty(""String_Node_Str"",""String_Node_Str"");
  PersistenceManager persistenceManager=new InMemoryPersistenceManager();
  persistenceManager.open(Maps.newHashMap());
  SidelineConsumer sidelineConsumer=new SidelineConsumer(config,persistenceManager);
  sidelineConsumer.open(null);
  List<ConsumerRecord> foundRecords=Lists.newArrayList();
  for (int x=0; x < numberOfRecordsToProduce; x++) {
    ConsumerRecord<byte[],byte[]> foundRecord=sidelineConsumer.nextRecord();
    assertNotNull(foundRecord);
    foundRecords.add(foundRecord);
    ProducerRecord<byte[],byte[]> expectedRecord=producedRecords.get(x);
    logger.info(""String_Node_Str"",expectedRecord.key(),foundRecord.key());
    assertEquals(""String_Node_Str"",new String(expectedRecord.key(),Charsets.UTF_8),new String(foundRecord.key(),Charsets.UTF_8));
    assertEquals(""String_Node_Str"",new String(expectedRecord.value(),Charsets.UTF_8),new String(foundRecord.value(),Charsets.UTF_8));
  }
  logger.info(""String_Node_Str"",sidelineConsumer.flushConsumerState());
  validateConsumerState(sidelineConsumer.flushConsumerState(),partition0,-1L);
  sidelineConsumer.commitOffset(partition0,2L);
  validateConsumerState(sidelineConsumer.flushConsumerState(),partition0,-1L);
  sidelineConsumer.commitOffset(partition0,1L);
  validateConsumerState(sidelineConsumer.flushConsumerState(),partition0,-1L);
  sidelineConsumer.commitOffset(partition0,0L);
  validateConsumerState(sidelineConsumer.flushConsumerState(),partition0,2L);
  sidelineConsumer.commitOffset(partition0,3L);
  validateConsumerState(sidelineConsumer.flushConsumerState(),partition0,3L);
  sidelineConsumer.commitOffset(partition0,4L);
  validateConsumerState(sidelineConsumer.flushConsumerState(),partition0,4L);
  sidelineConsumer.commitOffset(partition0,5L);
  validateConsumerState(sidelineConsumer.flushConsumerState(),partition0,5L);
  sidelineConsumer.commitOffset(partition0,7L);
  validateConsumerState(sidelineConsumer.flushConsumerState(),partition0,5L);
  sidelineConsumer.commitOffset(partition0,8L);
  validateConsumerState(sidelineConsumer.flushConsumerState(),partition0,5L);
  sidelineConsumer.commitOffset(partition0,6L);
  validateConsumerState(sidelineConsumer.flushConsumerState(),partition0,8L);
  logger.info(""String_Node_Str"",sidelineConsumer.flushConsumerState());
  sidelineConsumer.close();
}","/** 
 * We attempt to consume from the topic and get our expected messages. We ack the messages each as we get it, in order, one by one.
 */
@Test public void testSimpleConsumeFromTopicWithAckingOutOfOrderAllAtTheEnd(){
  final int numberOfRecordsToProduce=9;
  final TopicPartition partition0=new TopicPartition(topicName,0);
  final List<ProducerRecord<byte[],byte[]>> producedRecords=produceRecords(numberOfRecordsToProduce);
  List<String> brokerHosts=Lists.newArrayList(kafkaTestServer.getKafkaServer().serverConfig().advertisedHostName() + ""String_Node_Str"" + kafkaTestServer.getKafkaServer().serverConfig().advertisedPort());
  SidelineConsumerConfig config=new SidelineConsumerConfig(brokerHosts,""String_Node_Str"",topicName);
  PersistenceManager persistenceManager=new InMemoryPersistenceManager();
  persistenceManager.open(Maps.newHashMap());
  SidelineConsumer sidelineConsumer=new SidelineConsumer(config,persistenceManager);
  sidelineConsumer.open(null);
  List<ConsumerRecord> foundRecords=Lists.newArrayList();
  for (int x=0; x < numberOfRecordsToProduce; x++) {
    ConsumerRecord<byte[],byte[]> foundRecord=sidelineConsumer.nextRecord();
    assertNotNull(foundRecord);
    foundRecords.add(foundRecord);
    ProducerRecord<byte[],byte[]> expectedRecord=producedRecords.get(x);
    logger.info(""String_Node_Str"",expectedRecord.key(),foundRecord.key());
    assertEquals(""String_Node_Str"",new String(expectedRecord.key(),Charsets.UTF_8),new String(foundRecord.key(),Charsets.UTF_8));
    assertEquals(""String_Node_Str"",new String(expectedRecord.value(),Charsets.UTF_8),new String(foundRecord.value(),Charsets.UTF_8));
  }
  logger.info(""String_Node_Str"",sidelineConsumer.flushConsumerState());
  validateConsumerState(sidelineConsumer.flushConsumerState(),partition0,-1L);
  sidelineConsumer.commitOffset(partition0,2L);
  validateConsumerState(sidelineConsumer.flushConsumerState(),partition0,-1L);
  sidelineConsumer.commitOffset(partition0,1L);
  validateConsumerState(sidelineConsumer.flushConsumerState(),partition0,-1L);
  sidelineConsumer.commitOffset(partition0,0L);
  validateConsumerState(sidelineConsumer.flushConsumerState(),partition0,2L);
  sidelineConsumer.commitOffset(partition0,3L);
  validateConsumerState(sidelineConsumer.flushConsumerState(),partition0,3L);
  sidelineConsumer.commitOffset(partition0,4L);
  validateConsumerState(sidelineConsumer.flushConsumerState(),partition0,4L);
  sidelineConsumer.commitOffset(partition0,5L);
  validateConsumerState(sidelineConsumer.flushConsumerState(),partition0,5L);
  sidelineConsumer.commitOffset(partition0,7L);
  validateConsumerState(sidelineConsumer.flushConsumerState(),partition0,5L);
  sidelineConsumer.commitOffset(partition0,8L);
  validateConsumerState(sidelineConsumer.flushConsumerState(),partition0,5L);
  sidelineConsumer.commitOffset(partition0,6L);
  validateConsumerState(sidelineConsumer.flushConsumerState(),partition0,8L);
  logger.info(""String_Node_Str"",sidelineConsumer.flushConsumerState());
  sidelineConsumer.close();
}"
37690,"/** 
 * Verifies that when we call connect that it makes the appropriate calls to ConsumerStateManager to initialize. This test has the ConsumerStateManager (a mock) return an empty ConsumerState. We verify that our internal kafka client then knows to start reading every partition from the earliest available offset.
 */
@Test public void testConnectWithMultiplePartitionsOnTopicWithNoStateSaved(){
  final String consumerId=""String_Node_Str"";
  List<String> brokerHosts=Lists.newArrayList(kafkaTestServer.getKafkaServer().serverConfig().advertisedHostName() + ""String_Node_Str"" + kafkaTestServer.getKafkaServer().serverConfig().advertisedPort());
  final SidelineConsumerConfig config=new SidelineConsumerConfig(brokerHosts,consumerId,topicName);
  config.setKafkaConsumerProperty(""String_Node_Str"",""String_Node_Str"");
  KafkaConsumer<byte[],byte[]> mockKafkaConsumer=mock(KafkaConsumer.class);
  List<PartitionInfo> mockPartitionInfos=Lists.newArrayList(new PartitionInfo(topicName,0,new Node(0,""String_Node_Str"",9092),new Node[0],new Node[0]),new PartitionInfo(topicName,1,new Node(0,""String_Node_Str"",9092),new Node[0],new Node[0]),new PartitionInfo(topicName,2,new Node(0,""String_Node_Str"",9092),new Node[0],new Node[0]));
  when(mockKafkaConsumer.partitionsFor(eq(topicName))).thenReturn(mockPartitionInfos);
  PersistenceManager mockPersistenceManager=mock(PersistenceManager.class);
  ConsumerState emptyConsumerState=new ConsumerState();
  when(mockPersistenceManager.retrieveConsumerState(eq(consumerId))).thenReturn(emptyConsumerState);
  SidelineConsumer sidelineConsumer=new SidelineConsumer(config,mockPersistenceManager,mockKafkaConsumer);
  sidelineConsumer.open(null);
  verify(mockKafkaConsumer,times(1)).assign(eq(Lists.newArrayList(new TopicPartition(topicName,0),new TopicPartition(topicName,1),new TopicPartition(topicName,2))));
  verify(mockKafkaConsumer,times(1)).seekToBeginning(eq(Lists.newArrayList(new TopicPartition(topicName,0),new TopicPartition(topicName,1),new TopicPartition(topicName,2))));
}","/** 
 * Verifies that when we call connect that it makes the appropriate calls to ConsumerStateManager to initialize. This test has the ConsumerStateManager (a mock) return an empty ConsumerState. We verify that our internal kafka client then knows to start reading every partition from the earliest available offset.
 */
@Test public void testConnectWithMultiplePartitionsOnTopicWithNoStateSaved(){
  final String consumerId=""String_Node_Str"";
  List<String> brokerHosts=Lists.newArrayList(kafkaTestServer.getKafkaServer().serverConfig().advertisedHostName() + ""String_Node_Str"" + kafkaTestServer.getKafkaServer().serverConfig().advertisedPort());
  final SidelineConsumerConfig config=new SidelineConsumerConfig(brokerHosts,consumerId,topicName);
  KafkaConsumer<byte[],byte[]> mockKafkaConsumer=mock(KafkaConsumer.class);
  List<PartitionInfo> mockPartitionInfos=Lists.newArrayList(new PartitionInfo(topicName,0,new Node(0,""String_Node_Str"",9092),new Node[0],new Node[0]),new PartitionInfo(topicName,1,new Node(0,""String_Node_Str"",9092),new Node[0],new Node[0]),new PartitionInfo(topicName,2,new Node(0,""String_Node_Str"",9092),new Node[0],new Node[0]));
  when(mockKafkaConsumer.partitionsFor(eq(topicName))).thenReturn(mockPartitionInfos);
  PersistenceManager mockPersistenceManager=mock(PersistenceManager.class);
  ConsumerState emptyConsumerState=new ConsumerState();
  when(mockPersistenceManager.retrieveConsumerState(eq(consumerId))).thenReturn(emptyConsumerState);
  SidelineConsumer sidelineConsumer=new SidelineConsumer(config,mockPersistenceManager,mockKafkaConsumer);
  sidelineConsumer.open(null);
  verify(mockKafkaConsumer,times(1)).assign(eq(Lists.newArrayList(new TopicPartition(topicName,0),new TopicPartition(topicName,1),new TopicPartition(topicName,2))));
  verify(mockKafkaConsumer,times(1)).seekToBeginning(eq(Lists.newArrayList(new TopicPartition(topicName,0),new TopicPartition(topicName,1),new TopicPartition(topicName,2))));
}"
37691,"/** 
 * This tests what happens if we ask to consume from an offset that is invalid (does not exist). Here's what we setup: 2 partitions, produce 4 messages into each. Start a consumer, asking to start at: offset 2 for partition 1, (recorded completed offset = 1) offset 21 for partition 2. (recorded completed offset = 20) Offset 20 does not exist for partition 2, this will raise an exception which by the underlying kafka consumer.  This exception should be handled internally resetting the offset on partition 2 to the earliest available (which happens to be 0). We then consume and expect to receive messages: partition 0 -> messages 2,3      (because we started at offset 2) partition 1 -> messages 0,1,2,3  (because we got reset to earliest) This test also validates that for non-reset partitions, that it does not lose any messages.
 */
@Test public void testWhatHappensIfOffsetIsInvalidShouldResetSmallest(){
  this.topicName=""String_Node_Str"";
  final int numberOfPartitions=2;
  final int numberOfMsgsPerPartition=4;
  final int numberOfExpectedMessages=6;
  final long partition0StartingOffset=1L;
  final long partition1StartingOffset=20L;
  kafkaTestServer.createTopic(topicName,numberOfPartitions);
  final TopicPartition expectedTopicPartition0=new TopicPartition(topicName,0);
  final TopicPartition expectedTopicPartition1=new TopicPartition(topicName,1);
  produceRecords(numberOfMsgsPerPartition,0);
  produceRecords(numberOfMsgsPerPartition,1);
  SidelineConsumerConfig config=getDefaultSidelineConsumerConfig(topicName);
  config.setKafkaConsumerProperty(""String_Node_Str"",""String_Node_Str"");
  PersistenceManager persistenceManager=new InMemoryPersistenceManager();
  persistenceManager.open(Maps.newHashMap());
  ConsumerState startingState=new ConsumerState();
  startingState.setOffset(expectedTopicPartition0,partition0StartingOffset);
  startingState.setOffset(expectedTopicPartition1,partition1StartingOffset);
  SidelineConsumer sidelineConsumer=new SidelineConsumer(config,persistenceManager);
  sidelineConsumer.open(startingState);
  final Set<String> expectedValues=Sets.newHashSet(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"");
  List<ConsumerRecord> records=Lists.newArrayList();
  ConsumerRecord consumerRecord;
  do {
    consumerRecord=sidelineConsumer.nextRecord();
    if (consumerRecord != null) {
      logger.info(""String_Node_Str"",consumerRecord.offset(),consumerRecord.partition());
      records.add(consumerRecord);
      expectedValues.remove(""String_Node_Str"" + consumerRecord.partition() + ""String_Node_Str""+ consumerRecord.offset());
    }
  }
 while (consumerRecord != null);
  logger.info(""String_Node_Str"",records.size());
  assertEquals(""String_Node_Str"",numberOfExpectedMessages,records.size());
  assertTrue(""String_Node_Str"",expectedValues.isEmpty());
  for (int x=0; x < 2; x++) {
    assertNull(""String_Node_Str"",sidelineConsumer.nextRecord());
  }
}","/** 
 * This tests what happens if we ask to consume from an offset that is invalid (does not exist). Here's what we setup: 2 partitions, produce 4 messages into each. Start a consumer, asking to start at: offset 2 for partition 1, (recorded completed offset = 1) offset 21 for partition 2. (recorded completed offset = 20) Offset 20 does not exist for partition 2, this will raise an exception which by the underlying kafka consumer.  This exception should be handled internally resetting the offset on partition 2 to the earliest available (which happens to be 0). We then consume and expect to receive messages: partition 0 -> messages 2,3      (because we started at offset 2) partition 1 -> messages 0,1,2,3  (because we got reset to earliest) This test also validates that for non-reset partitions, that it does not lose any messages.
 */
@Test public void testWhatHappensIfOffsetIsInvalidShouldResetSmallest(){
  this.topicName=""String_Node_Str"";
  final int numberOfPartitions=2;
  final int numberOfMsgsPerPartition=4;
  final int numberOfExpectedMessages=6;
  final long partition0StartingOffset=1L;
  final long partition1StartingOffset=20L;
  kafkaTestServer.createTopic(topicName,numberOfPartitions);
  final TopicPartition expectedTopicPartition0=new TopicPartition(topicName,0);
  final TopicPartition expectedTopicPartition1=new TopicPartition(topicName,1);
  produceRecords(numberOfMsgsPerPartition,0);
  produceRecords(numberOfMsgsPerPartition,1);
  SidelineConsumerConfig config=getDefaultSidelineConsumerConfig(topicName);
  PersistenceManager persistenceManager=new InMemoryPersistenceManager();
  persistenceManager.open(Maps.newHashMap());
  ConsumerState startingState=new ConsumerState();
  startingState.setOffset(expectedTopicPartition0,partition0StartingOffset);
  startingState.setOffset(expectedTopicPartition1,partition1StartingOffset);
  SidelineConsumer sidelineConsumer=new SidelineConsumer(config,persistenceManager);
  sidelineConsumer.open(startingState);
  final Set<String> expectedValues=Sets.newHashSet(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"");
  List<ConsumerRecord> records=Lists.newArrayList();
  ConsumerRecord consumerRecord;
  do {
    consumerRecord=sidelineConsumer.nextRecord();
    if (consumerRecord != null) {
      logger.info(""String_Node_Str"",consumerRecord.offset(),consumerRecord.partition());
      records.add(consumerRecord);
      expectedValues.remove(""String_Node_Str"" + consumerRecord.partition() + ""String_Node_Str""+ consumerRecord.offset());
    }
  }
 while (consumerRecord != null);
  logger.info(""String_Node_Str"",records.size());
  assertEquals(""String_Node_Str"",numberOfExpectedMessages,records.size());
  assertTrue(""String_Node_Str"",expectedValues.isEmpty());
  for (int x=0; x < 2; x++) {
    assertNull(""String_Node_Str"",sidelineConsumer.nextRecord());
  }
}"
37692,"/** 
 * Verifies that when we call connect that it makes the appropriate calls to ConsumerStateManager to initialize. This test has the ConsumerStateManager (a mock) return ConsumerState for every partition on the topic. We verify that our internal kafka client then knows to start reading from the previously saved consumer state offsets
 */
@Test public void testConnectWithMultiplePartitionsOnTopicWithSomePreviouslySavedState(){
  final String consumerId=""String_Node_Str"";
  final TopicPartition partition0=new TopicPartition(topicName,0);
  final TopicPartition partition1=new TopicPartition(topicName,1);
  final TopicPartition partition2=new TopicPartition(topicName,2);
  final TopicPartition partition3=new TopicPartition(topicName,3);
  final long lastCommittedOffsetPartition0=1234L;
  final long lastCommittedOffsetPartition2=1337L;
  final long expectedPartition0Offset=lastCommittedOffsetPartition0 + 1;
  final long expectedPartition2Offset=lastCommittedOffsetPartition2 + 1;
  List<String> brokerHosts=Lists.newArrayList(kafkaTestServer.getKafkaServer().serverConfig().advertisedHostName() + ""String_Node_Str"" + kafkaTestServer.getKafkaServer().serverConfig().advertisedPort());
  final SidelineConsumerConfig config=new SidelineConsumerConfig(brokerHosts,consumerId,topicName);
  config.setKafkaConsumerProperty(""String_Node_Str"",""String_Node_Str"");
  KafkaConsumer<byte[],byte[]> mockKafkaConsumer=mock(KafkaConsumer.class);
  List<PartitionInfo> mockPartitionInfos=Lists.newArrayList(new PartitionInfo(topicName,0,new Node(0,""String_Node_Str"",9092),new Node[0],new Node[0]),new PartitionInfo(topicName,1,new Node(0,""String_Node_Str"",9092),new Node[0],new Node[0]),new PartitionInfo(topicName,2,new Node(0,""String_Node_Str"",9092),new Node[0],new Node[0]),new PartitionInfo(topicName,3,new Node(0,""String_Node_Str"",9092),new Node[0],new Node[0]));
  when(mockKafkaConsumer.partitionsFor(eq(topicName))).thenReturn(mockPartitionInfos);
  PersistenceManager mockPersistenceManager=mock(PersistenceManager.class);
  ConsumerState consumerState=new ConsumerState();
  consumerState.setOffset(partition0,lastCommittedOffsetPartition0);
  consumerState.setOffset(partition2,lastCommittedOffsetPartition2);
  when(mockPersistenceManager.retrieveConsumerState(eq(consumerId))).thenReturn(consumerState);
  SidelineConsumer sidelineConsumer=new SidelineConsumer(config,mockPersistenceManager,mockKafkaConsumer);
  sidelineConsumer.open(null);
  verify(mockKafkaConsumer,times(1)).assign(eq(Lists.newArrayList(partition0,partition1,partition2,partition3)));
  verify(mockKafkaConsumer,times(1)).seekToBeginning(eq(Lists.newArrayList(partition1,partition3)));
  InOrder inOrderVerification=inOrder(mockKafkaConsumer);
  inOrderVerification.verify(mockKafkaConsumer,times(1)).seek(eq(partition0),eq(expectedPartition0Offset));
  inOrderVerification.verify(mockKafkaConsumer,times(1)).seek(eq(partition2),eq(expectedPartition2Offset));
  verify(mockKafkaConsumer,never()).seek(eq(partition1),anyLong());
  verify(mockKafkaConsumer,never()).seek(eq(partition3),anyLong());
}","/** 
 * Verifies that when we call connect that it makes the appropriate calls to ConsumerStateManager to initialize. This test has the ConsumerStateManager (a mock) return ConsumerState for every partition on the topic. We verify that our internal kafka client then knows to start reading from the previously saved consumer state offsets
 */
@Test public void testConnectWithMultiplePartitionsOnTopicWithSomePreviouslySavedState(){
  final String consumerId=""String_Node_Str"";
  final TopicPartition partition0=new TopicPartition(topicName,0);
  final TopicPartition partition1=new TopicPartition(topicName,1);
  final TopicPartition partition2=new TopicPartition(topicName,2);
  final TopicPartition partition3=new TopicPartition(topicName,3);
  final long lastCommittedOffsetPartition0=1234L;
  final long lastCommittedOffsetPartition2=1337L;
  final long expectedPartition0Offset=lastCommittedOffsetPartition0 + 1;
  final long expectedPartition2Offset=lastCommittedOffsetPartition2 + 1;
  List<String> brokerHosts=Lists.newArrayList(kafkaTestServer.getKafkaServer().serverConfig().advertisedHostName() + ""String_Node_Str"" + kafkaTestServer.getKafkaServer().serverConfig().advertisedPort());
  final SidelineConsumerConfig config=new SidelineConsumerConfig(brokerHosts,consumerId,topicName);
  KafkaConsumer<byte[],byte[]> mockKafkaConsumer=mock(KafkaConsumer.class);
  List<PartitionInfo> mockPartitionInfos=Lists.newArrayList(new PartitionInfo(topicName,0,new Node(0,""String_Node_Str"",9092),new Node[0],new Node[0]),new PartitionInfo(topicName,1,new Node(0,""String_Node_Str"",9092),new Node[0],new Node[0]),new PartitionInfo(topicName,2,new Node(0,""String_Node_Str"",9092),new Node[0],new Node[0]),new PartitionInfo(topicName,3,new Node(0,""String_Node_Str"",9092),new Node[0],new Node[0]));
  when(mockKafkaConsumer.partitionsFor(eq(topicName))).thenReturn(mockPartitionInfos);
  PersistenceManager mockPersistenceManager=mock(PersistenceManager.class);
  ConsumerState consumerState=new ConsumerState();
  consumerState.setOffset(partition0,lastCommittedOffsetPartition0);
  consumerState.setOffset(partition2,lastCommittedOffsetPartition2);
  when(mockPersistenceManager.retrieveConsumerState(eq(consumerId))).thenReturn(consumerState);
  SidelineConsumer sidelineConsumer=new SidelineConsumer(config,mockPersistenceManager,mockKafkaConsumer);
  sidelineConsumer.open(null);
  verify(mockKafkaConsumer,times(1)).assign(eq(Lists.newArrayList(partition0,partition1,partition2,partition3)));
  verify(mockKafkaConsumer,times(1)).seekToBeginning(eq(Lists.newArrayList(partition1,partition3)));
  InOrder inOrderVerification=inOrder(mockKafkaConsumer);
  inOrderVerification.verify(mockKafkaConsumer,times(1)).seek(eq(partition0),eq(expectedPartition0Offset));
  inOrderVerification.verify(mockKafkaConsumer,times(1)).seek(eq(partition2),eq(expectedPartition2Offset));
  verify(mockKafkaConsumer,never()).seek(eq(partition1),anyLong());
  verify(mockKafkaConsumer,never()).seek(eq(partition3),anyLong());
}"
37693,"/** 
 * We attempt to consume from the topic and get our expected messages. We ack the messages each as we get it, in order, one by one.
 */
@Test public void testSimpleConsumeFromTopicWithAckingInOrderOneByOne(){
  final int numberOfRecordsToProduce=5;
  final TopicPartition partition0=new TopicPartition(topicName,0);
  final List<ProducerRecord<byte[],byte[]>> producedRecords=produceRecords(numberOfRecordsToProduce);
  List<String> brokerHosts=Lists.newArrayList(kafkaTestServer.getKafkaServer().serverConfig().advertisedHostName() + ""String_Node_Str"" + kafkaTestServer.getKafkaServer().serverConfig().advertisedPort());
  SidelineConsumerConfig config=new SidelineConsumerConfig(brokerHosts,""String_Node_Str"",topicName);
  config.setKafkaConsumerProperty(""String_Node_Str"",""String_Node_Str"");
  PersistenceManager persistenceManager=new InMemoryPersistenceManager();
  persistenceManager.open(Maps.newHashMap());
  SidelineConsumer sidelineConsumer=new SidelineConsumer(config,persistenceManager);
  sidelineConsumer.open(null);
  for (int x=0; x < numberOfRecordsToProduce; x++) {
    ConsumerRecord<byte[],byte[]> foundRecord=sidelineConsumer.nextRecord();
    assertNotNull(foundRecord);
    ProducerRecord<byte[],byte[]> expectedRecord=producedRecords.get(x);
    logger.info(""String_Node_Str"",expectedRecord.key(),foundRecord.key());
    assertEquals(""String_Node_Str"",new String(expectedRecord.key(),Charsets.UTF_8),new String(foundRecord.key(),Charsets.UTF_8));
    assertEquals(""String_Node_Str"",new String(expectedRecord.value(),Charsets.UTF_8),new String(foundRecord.value(),Charsets.UTF_8));
    sidelineConsumer.commitOffset(foundRecord);
    validateConsumerState(sidelineConsumer.flushConsumerState(),partition0,foundRecord.offset());
  }
  logger.info(""String_Node_Str"",sidelineConsumer.flushConsumerState());
  sidelineConsumer.close();
}","/** 
 * We attempt to consume from the topic and get our expected messages. We ack the messages each as we get it, in order, one by one.
 */
@Test public void testSimpleConsumeFromTopicWithAckingInOrderOneByOne(){
  final int numberOfRecordsToProduce=5;
  final TopicPartition partition0=new TopicPartition(topicName,0);
  final List<ProducerRecord<byte[],byte[]>> producedRecords=produceRecords(numberOfRecordsToProduce);
  List<String> brokerHosts=Lists.newArrayList(kafkaTestServer.getKafkaServer().serverConfig().advertisedHostName() + ""String_Node_Str"" + kafkaTestServer.getKafkaServer().serverConfig().advertisedPort());
  SidelineConsumerConfig config=new SidelineConsumerConfig(brokerHosts,""String_Node_Str"",topicName);
  PersistenceManager persistenceManager=new InMemoryPersistenceManager();
  persistenceManager.open(Maps.newHashMap());
  SidelineConsumer sidelineConsumer=new SidelineConsumer(config,persistenceManager);
  sidelineConsumer.open(null);
  for (int x=0; x < numberOfRecordsToProduce; x++) {
    ConsumerRecord<byte[],byte[]> foundRecord=sidelineConsumer.nextRecord();
    assertNotNull(foundRecord);
    ProducerRecord<byte[],byte[]> expectedRecord=producedRecords.get(x);
    logger.info(""String_Node_Str"",expectedRecord.key(),foundRecord.key());
    assertEquals(""String_Node_Str"",new String(expectedRecord.key(),Charsets.UTF_8),new String(foundRecord.key(),Charsets.UTF_8));
    assertEquals(""String_Node_Str"",new String(expectedRecord.value(),Charsets.UTF_8),new String(foundRecord.value(),Charsets.UTF_8));
    sidelineConsumer.commitOffset(foundRecord);
    validateConsumerState(sidelineConsumer.flushConsumerState(),partition0,foundRecord.offset());
  }
  logger.info(""String_Node_Str"",sidelineConsumer.flushConsumerState());
  sidelineConsumer.close();
}"
37694,"/** 
 * Verifies that when we call connect that it makes the appropriate calls to ConsumerStateManager to initialize. This test has the ConsumerStateManager (a mock) return ConsumerState for every partition on the topic. We verify that our internal kafka client then knows to start reading from the previously saved consumer state offsets
 */
@Test public void testConnectWithMultiplePartitionsOnTopicWithAllPreviouslySavedState(){
  final String consumerId=""String_Node_Str"";
  final TopicPartition partition0=new TopicPartition(topicName,0);
  final TopicPartition partition1=new TopicPartition(topicName,1);
  final TopicPartition partition2=new TopicPartition(topicName,2);
  final long lastCommittedOffsetPartition0=1234L;
  final long lastCommittedOffsetPartition1=4321L;
  final long lastCommittedOffsetPartition2=1337L;
  final long expectedPartition0Offset=lastCommittedOffsetPartition0 + 1;
  final long expectedPartition1Offset=lastCommittedOffsetPartition1 + 1;
  final long expectedPartition2Offset=lastCommittedOffsetPartition2 + 1;
  List<String> brokerHosts=Lists.newArrayList(kafkaTestServer.getKafkaServer().serverConfig().advertisedHostName() + ""String_Node_Str"" + kafkaTestServer.getKafkaServer().serverConfig().advertisedPort());
  final SidelineConsumerConfig config=new SidelineConsumerConfig(brokerHosts,consumerId,topicName);
  config.setKafkaConsumerProperty(""String_Node_Str"",""String_Node_Str"");
  KafkaConsumer<byte[],byte[]> mockKafkaConsumer=mock(KafkaConsumer.class);
  List<PartitionInfo> mockPartitionInfos=Lists.newArrayList(new PartitionInfo(topicName,0,new Node(0,""String_Node_Str"",9092),new Node[0],new Node[0]),new PartitionInfo(topicName,1,new Node(0,""String_Node_Str"",9092),new Node[0],new Node[0]),new PartitionInfo(topicName,2,new Node(0,""String_Node_Str"",9092),new Node[0],new Node[0]));
  when(mockKafkaConsumer.partitionsFor(eq(topicName))).thenReturn(mockPartitionInfos);
  PersistenceManager mockPersistenceManager=mock(PersistenceManager.class);
  ConsumerState consumerState=new ConsumerState();
  consumerState.setOffset(partition0,lastCommittedOffsetPartition0);
  consumerState.setOffset(partition1,lastCommittedOffsetPartition1);
  consumerState.setOffset(partition2,lastCommittedOffsetPartition2);
  when(mockPersistenceManager.retrieveConsumerState(eq(consumerId))).thenReturn(consumerState);
  SidelineConsumer sidelineConsumer=new SidelineConsumer(config,mockPersistenceManager,mockKafkaConsumer);
  sidelineConsumer.open(null);
  verify(mockKafkaConsumer,times(1)).assign(eq(Lists.newArrayList(partition0,partition1,partition2)));
  verify(mockKafkaConsumer,never()).seekToBeginning(anyList());
  InOrder inOrderVerification=inOrder(mockKafkaConsumer);
  inOrderVerification.verify(mockKafkaConsumer,times(1)).seek(eq(partition0),eq(expectedPartition0Offset));
  inOrderVerification.verify(mockKafkaConsumer,times(1)).seek(eq(partition1),eq(expectedPartition1Offset));
  inOrderVerification.verify(mockKafkaConsumer,times(1)).seek(eq(partition2),eq(expectedPartition2Offset));
}","/** 
 * Verifies that when we call connect that it makes the appropriate calls to ConsumerStateManager to initialize. This test has the ConsumerStateManager (a mock) return ConsumerState for every partition on the topic. We verify that our internal kafka client then knows to start reading from the previously saved consumer state offsets
 */
@Test public void testConnectWithMultiplePartitionsOnTopicWithAllPreviouslySavedState(){
  final String consumerId=""String_Node_Str"";
  final TopicPartition partition0=new TopicPartition(topicName,0);
  final TopicPartition partition1=new TopicPartition(topicName,1);
  final TopicPartition partition2=new TopicPartition(topicName,2);
  final long lastCommittedOffsetPartition0=1234L;
  final long lastCommittedOffsetPartition1=4321L;
  final long lastCommittedOffsetPartition2=1337L;
  final long expectedPartition0Offset=lastCommittedOffsetPartition0 + 1;
  final long expectedPartition1Offset=lastCommittedOffsetPartition1 + 1;
  final long expectedPartition2Offset=lastCommittedOffsetPartition2 + 1;
  List<String> brokerHosts=Lists.newArrayList(kafkaTestServer.getKafkaServer().serverConfig().advertisedHostName() + ""String_Node_Str"" + kafkaTestServer.getKafkaServer().serverConfig().advertisedPort());
  final SidelineConsumerConfig config=new SidelineConsumerConfig(brokerHosts,consumerId,topicName);
  KafkaConsumer<byte[],byte[]> mockKafkaConsumer=mock(KafkaConsumer.class);
  List<PartitionInfo> mockPartitionInfos=Lists.newArrayList(new PartitionInfo(topicName,0,new Node(0,""String_Node_Str"",9092),new Node[0],new Node[0]),new PartitionInfo(topicName,1,new Node(0,""String_Node_Str"",9092),new Node[0],new Node[0]),new PartitionInfo(topicName,2,new Node(0,""String_Node_Str"",9092),new Node[0],new Node[0]));
  when(mockKafkaConsumer.partitionsFor(eq(topicName))).thenReturn(mockPartitionInfos);
  PersistenceManager mockPersistenceManager=mock(PersistenceManager.class);
  ConsumerState consumerState=new ConsumerState();
  consumerState.setOffset(partition0,lastCommittedOffsetPartition0);
  consumerState.setOffset(partition1,lastCommittedOffsetPartition1);
  consumerState.setOffset(partition2,lastCommittedOffsetPartition2);
  when(mockPersistenceManager.retrieveConsumerState(eq(consumerId))).thenReturn(consumerState);
  SidelineConsumer sidelineConsumer=new SidelineConsumer(config,mockPersistenceManager,mockKafkaConsumer);
  sidelineConsumer.open(null);
  verify(mockKafkaConsumer,times(1)).assign(eq(Lists.newArrayList(partition0,partition1,partition2)));
  verify(mockKafkaConsumer,never()).seekToBeginning(anyList());
  InOrder inOrderVerification=inOrder(mockKafkaConsumer);
  inOrderVerification.verify(mockKafkaConsumer,times(1)).seek(eq(partition0),eq(expectedPartition0Offset));
  inOrderVerification.verify(mockKafkaConsumer,times(1)).seek(eq(partition1),eq(expectedPartition1Offset));
  inOrderVerification.verify(mockKafkaConsumer,times(1)).seek(eq(partition2),eq(expectedPartition2Offset));
}"
37695,"/** 
 * Starts a sideline request
 * @param startRequest A representation of the request that is being started
 */
public SidelineIdentifier startSidelining(StartRequest startRequest){
  logger.info(""String_Node_Str"");
  final SidelineIdentifier id=new SidelineIdentifier();
  final ConsumerState startingState=fireHoseSpout.getCurrentState();
  for (  TopicPartition topicPartition : startingState.getTopicPartitions()) {
    startingState.setOffset(topicPartition,startingState.getOffsetForTopicAndPartition(topicPartition) + 1);
  }
  persistenceManager.persistSidelineRequestState(id,startingState);
  fireHoseSpout.getFilterChain().addSteps(id,startRequest.steps);
  startingTrigger.start(id);
  metricsRecorder.count(getClass(),""String_Node_Str"",1L);
  return id;
}","/** 
 * Starts a sideline request
 * @param startRequest A representation of the request that is being started
 */
public SidelineIdentifier startSidelining(StartRequest startRequest){
  logger.info(""String_Node_Str"");
  final SidelineIdentifier id=new SidelineIdentifier();
  final ConsumerState startingState=fireHoseSpout.getCurrentState();
  persistenceManager.persistSidelineRequestState(id,startingState);
  fireHoseSpout.getFilterChain().addSteps(id,startRequest.steps);
  startingTrigger.start(id);
  metricsRecorder.count(getClass(),""String_Node_Str"",1L);
  return id;
}"
37696,"/** 
 * Handles connecting to the Kafka cluster, determining which partitions to subscribe to, and based on previously saved state from ConsumerStateManager, seek to the last positions processed on each partition.
 */
public void open(ConsumerState startingState){
  if (hasCalledConnect) {
    throw new RuntimeException(""String_Node_Str"");
  }
  hasCalledConnect=true;
  if (startingState != null) {
    persistenceManager.persistConsumerState(getConsumerId(),startingState);
  }
  ConsumerState initialState=persistenceManager.retrieveConsumerState(getConsumerId());
  if (initialState == null) {
    initialState=new ConsumerState();
  }
  if (kafkaConsumer == null) {
    kafkaConsumer=new KafkaConsumer<>(getConsumerConfig().getKafkaConsumerProperties());
  }
  List<PartitionInfo> availablePartitions=kafkaConsumer.partitionsFor(getConsumerConfig().getTopic());
  logger.info(""String_Node_Str"",availablePartitions);
  List<TopicPartition> allTopicPartitions=Lists.newArrayList();
  for (  PartitionInfo availablePartitionInfo : availablePartitions) {
    allTopicPartitions.add(new TopicPartition(availablePartitionInfo.topic(),availablePartitionInfo.partition()));
  }
  kafkaConsumer.assign(allTopicPartitions);
  List<TopicPartition> noStatePartitions=Lists.newArrayList();
  for (  PartitionInfo availablePartitionInfo : availablePartitions) {
    final TopicPartition availableTopicPartition=new TopicPartition(availablePartitionInfo.topic(),availablePartitionInfo.partition());
    Long offset=initialState.getOffsetForTopicAndPartition(availableTopicPartition);
    if (offset == null) {
      noStatePartitions.add(availableTopicPartition);
      offset=0L;
    }
 else {
      logger.info(""String_Node_Str"",availableTopicPartition.topic(),availableTopicPartition.partition(),offset);
      kafkaConsumer.seek(availableTopicPartition,offset);
      logger.info(""String_Node_Str"",kafkaConsumer.position(availableTopicPartition));
    }
    partitionStateManagers.put(availableTopicPartition,new PartitionOffsetManager(availableTopicPartition.topic(),availableTopicPartition.partition(),offset));
  }
  if (!noStatePartitions.isEmpty()) {
    logger.info(""String_Node_Str"",noStatePartitions);
    kafkaConsumer.seekToBeginning(noStatePartitions);
  }
}","/** 
 * Handles connecting to the Kafka cluster, determining which partitions to subscribe to, and based on previously saved state from ConsumerStateManager, seek to the last positions processed on each partition.
 */
public void open(ConsumerState startingState){
  if (hasCalledConnect) {
    throw new RuntimeException(""String_Node_Str"");
  }
  hasCalledConnect=true;
  if (startingState != null) {
    persistenceManager.persistConsumerState(getConsumerId(),startingState);
  }
  ConsumerState initialState=persistenceManager.retrieveConsumerState(getConsumerId());
  if (initialState == null) {
    initialState=new ConsumerState();
  }
  if (kafkaConsumer == null) {
    kafkaConsumer=new KafkaConsumer<>(getConsumerConfig().getKafkaConsumerProperties());
  }
  List<PartitionInfo> availablePartitions=kafkaConsumer.partitionsFor(getConsumerConfig().getTopic());
  logger.info(""String_Node_Str"",availablePartitions);
  List<TopicPartition> allTopicPartitions=Lists.newArrayList();
  for (  PartitionInfo availablePartitionInfo : availablePartitions) {
    allTopicPartitions.add(new TopicPartition(availablePartitionInfo.topic(),availablePartitionInfo.partition()));
  }
  kafkaConsumer.assign(allTopicPartitions);
  List<TopicPartition> noStatePartitions=Lists.newArrayList();
  for (  PartitionInfo availablePartitionInfo : availablePartitions) {
    final TopicPartition availableTopicPartition=new TopicPartition(availablePartitionInfo.topic(),availablePartitionInfo.partition());
    Long offset=initialState.getOffsetForTopicAndPartition(availableTopicPartition);
    if (offset == null) {
      noStatePartitions.add(availableTopicPartition);
      offset=-1L;
    }
 else {
      logger.info(""String_Node_Str"",availableTopicPartition.topic(),availableTopicPartition.partition(),(offset + 1));
      kafkaConsumer.seek(availableTopicPartition,offset + 1);
      logger.info(""String_Node_Str"",kafkaConsumer.position(availableTopicPartition));
    }
    partitionStateManagers.put(availableTopicPartition,new PartitionOffsetManager(availableTopicPartition.topic(),availableTopicPartition.partition(),offset));
  }
  if (!noStatePartitions.isEmpty()) {
    logger.info(""String_Node_Str"",noStatePartitions);
    kafkaConsumer.seekToBeginning(noStatePartitions);
  }
}"
37697,"@Override public ConsumerState retrieveConsumerState(final String consumerId){
  verifyHasBeenOpened();
  Map<Object,Object> json=readJSON(getZkConsumerStatePath(consumerId));
  logger.info(""String_Node_Str"",json);
  return parseJsonToConsumerState(json);
}","@Override public ConsumerState retrieveConsumerState(final String consumerId){
  verifyHasBeenOpened();
  final String path=getZkConsumerStatePath(consumerId);
  Map<Object,Object> json=readJSON(path);
  logger.info(""String_Node_Str"",path,json);
  return parseJsonToConsumerState(json);
}"
37698,"@Override public ConsumerState retrieveSidelineRequestState(SidelineIdentifier id){
  verifyHasBeenOpened();
  Map<Object,Object> json=readJSON(getZkRequestStatePath(id.toString()));
  logger.info(""String_Node_Str"",json);
  return parseJsonToConsumerState(json);
}","@Override public ConsumerState retrieveSidelineRequestState(SidelineIdentifier id){
  verifyHasBeenOpened();
  final String path=getZkRequestStatePath(id.toString());
  Map<Object,Object> json=readJSON(path);
  logger.info(""String_Node_Str"",path,json);
  return parseJsonToConsumerState(json);
}"
37699,"/** 
 * TODO Calculate the start date and range of dates for the full 7 day week from Sunday to Saturday. Hint: Look at   {@link LocalDate#with(TemporalAdjuster)}Hint: Look at   {@link TemporalAdjusters#previousOrSame(DayOfWeek)}Hint: Look at   {@link LocalDate#plusDays(long)}Hint: Look at   {@link LocalDateRange#of(LocalDate,LocalDate)}Hint: The end date is exclusive in LocalDateRange
 */
public WorkWeek(LocalDate forDate,SortedSetMultimap<LocalDate,Meeting> calendarMeetings){
  LocalDate start=null;
  this.range=null;
  this.meetings=calendarMeetings.selectKeysValues((date,meeting) -> this.range.contains(date));
}","/** 
 * TODO Calculate the start date and range of dates for the 5 day week from Monday to Friday. Hint: Look at   {@link LocalDate#with(TemporalAdjuster)}Hint: Look at   {@link TemporalAdjusters#previousOrSame(DayOfWeek)}Hint: Look at   {@link LocalDate#plusDays(long)}Hint: Look at   {@link LocalDateRange#of(LocalDate,LocalDate)}Hint: The end date is exclusive in LocalDateRange
 */
public WorkWeek(LocalDate forDate,SortedSetMultimap<LocalDate,Meeting> calendarMeetings){
  LocalDate start=null;
  this.range=null;
  this.meetings=calendarMeetings.selectKeysValues((date,meeting) -> this.range.contains(date));
}"
37700,"/** 
 * TODO Calculate the start date and range of dates for the full 7 day week from Sunday to Saturday. Hint: Look at   {@link LocalDate#with(TemporalAdjuster)}Hint: Look at   {@link TemporalAdjusters#previousOrSame(DayOfWeek)}Hint: Look at   {@link LocalDate#plusDays(long)}Hint: Look at   {@link LocalDateRange#of(LocalDate,LocalDate)}Hint: The end date is exclusive in LocalDateRange
 */
public WorkWeek(LocalDate forDate,SortedSetMultimap<LocalDate,Meeting> calendarMeetings){
  LocalDate start=null;
  this.range=null;
  this.meetings=calendarMeetings.selectKeysValues((date,meeting) -> this.range.contains(date));
}","/** 
 * TODO Calculate the start date and range of dates for the 5 day week from Monday to Friday. Hint: Look at   {@link LocalDate#with(TemporalAdjuster)}Hint: Look at   {@link TemporalAdjusters#previousOrSame(DayOfWeek)}Hint: Look at   {@link LocalDate#plusDays(long)}Hint: Look at   {@link LocalDateRange#of(LocalDate,LocalDate)}Hint: The end date is exclusive in LocalDateRange
 */
public WorkWeek(LocalDate forDate,SortedSetMultimap<LocalDate,Meeting> calendarMeetings){
  LocalDate start=null;
  this.range=null;
  this.meetings=calendarMeetings.selectKeysValues((date,meeting) -> this.range.contains(date));
}"
37701,"@Test public void function(){
  var toUppercase=new Function<String,String>(){
    @Override public String apply(    String s){
      return s.toUpperCase();
    }
  }
;
  Assert.assertEquals(""String_Node_Str"",toUppercase.apply(""String_Node_Str""));
  List<String> lowercase=List.of(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"");
  List<String> uppercase=lowercase.stream().map(toUppercase).collect(Collectors.toList());
  Assert.assertEquals(List.of(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""),uppercase);
}","@Test public void function(){
  var toUppercase=new Function<String,String>(){
    @Override public String apply(    String s){
      return s.toUpperCase();
    }
  }
;
  Assert.assertEquals(""String_Node_Str"",toUppercase.apply(""String_Node_Str""));
  List<String> lowercase=List.of(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"");
  Set<String> uppercase=lowercase.stream().map(toUppercase).collect(Collectors.toSet());
  Assert.assertEquals(Set.of(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""),uppercase);
}"
37702,"@Test public void biConsumer(){
  var result=new HashMap<String,String>();
  var biConsumer=new BiConsumer<String,String>(){
    @Override public void accept(    String key,    String value){
      result.put(key.toUpperCase(),value.toUpperCase());
    }
  }
;
  biConsumer.accept(""String_Node_Str"",""String_Node_Str"");
  Assert.assertEquals(this.createSmallMap(new String[]{""String_Node_Str"",""String_Node_Str""}),result);
  this.createSmallMap(new String[]{""String_Node_Str"",""String_Node_Str""},new String[]{""String_Node_Str"",""String_Node_Str""},new String[]{""String_Node_Str"",""String_Node_Str""}).forEach(biConsumer);
  Assert.assertEquals(this.createSmallMap(new String[]{""String_Node_Str"",""String_Node_Str""},new String[]{""String_Node_Str"",""String_Node_Str""},new String[]{""String_Node_Str"",""String_Node_Str""}),result);
}","@Test public void biConsumer(){
  var result=new HashMap<String,String>();
  var biConsumer=new BiConsumer<String,String>(){
    @Override public void accept(    String key,    String value){
      result.put(key.toUpperCase(),value.toUpperCase());
    }
  }
;
  biConsumer.accept(""String_Node_Str"",""String_Node_Str"");
  Assert.assertEquals(Map.of(""String_Node_Str"",""String_Node_Str""),result);
  var lowercaseMap=Map.of(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"");
  lowercaseMap.forEach(biConsumer);
  Assert.assertEquals(Map.of(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""),result);
}"
37703,"@Test public void consumer(){
  var strings=List.of(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"");
  var result=new ArrayList<String>();
  var consumer=new Consumer<String>(){
    @Override public void accept(    String each){
      result.add(each.toUpperCase());
    }
  }
;
  consumer.accept(""String_Node_Str"");
  Assert.assertEquals(List.of(""String_Node_Str""),result);
  strings.forEach(consumer);
  Assert.assertEquals(List.of(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""),result);
}","@Test public void consumer(){
  var strings=List.of(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"");
  final var result=new ArrayList<String>();
  var consumer=new Consumer<String>(){
    @Override public void accept(    String each){
      result.add(each.toUpperCase());
    }
  }
;
  consumer.accept(""String_Node_Str"");
  Assert.assertEquals(List.of(""String_Node_Str""),result);
  strings.forEach(consumer);
  Assert.assertEquals(List.of(""String_Node_Str"",""String_Node_Str"",""String_Node_Str"",""String_Node_Str""),result);
}"
37704,"/** 
 * FAIL_MESSAGE
 * @param message
 * @throws Exception
 */
public void processMessage(Message message) throws Exception {
  String realMessage=new String(message.getBody());
  System.out.println(""String_Node_Str"" + realMessage + ""String_Node_Str"");
  if (Objects.equals(realMessage,FAIL_MESSAGE)) {
    throw new Exception(""String_Node_Str"");
  }
}","/** 
 * FAIL_MESSAGE
 * @param message
 * @throws Exception
 */
public void processMessage(Message message) throws Exception {
  String realMessage=new String(message.getBody());
  logger.info(""String_Node_Str"" + realMessage + ""String_Node_Str"");
  if (Objects.equals(realMessage,FAIL_MESSAGE)) {
    throw new Exception(""String_Node_Str"");
  }
}"
37705,"@Test public void testFailMessage() throws InterruptedException {
  ProcessReceiver.latch=new CountDownLatch(6);
  for (int i=1; i <= 3; i++) {
    rabbitTemplate.convertAndSend(QueueConfig.DELAY_QUEUE_PER_QUEUE_TTL_NAME,ProcessReceiver.FAIL_MESSAGE);
  }
  ProcessReceiver.latch.await();
}","@Test public void testFailMessage() throws InterruptedException {
  ProcessReceiver.latch=new CountDownLatch(6);
  for (int i=1; i <= 3; i++) {
    rabbitTemplate.convertAndSend(QueueConfig.DELAY_PROCESS_QUEUE_NAME,ProcessReceiver.FAIL_MESSAGE);
  }
  ProcessReceiver.latch.await();
}"
37706,"private List<Flow> loadFlows(String whereClause){
  String q=""String_Node_Str"" + whereClause + ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str"";
  logger.debug(""String_Node_Str"",q);
  try (Session session=driver.session(AccessMode.READ)){
    StatementResult queryResults=session.run(q);
    List<Flow> results=new ArrayList<>();
    for (    Record record : queryResults.list()) {
      FlowAdapter adapter=new FlowAdapter(record);
      results.add(adapter.getFlow());
    }
    return results;
  }
 }","private List<Flow> loadFlows(String whereClause,Value parameters){
  String q=""String_Node_Str"" + whereClause + ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str"";
  logger.debug(""String_Node_Str"",q);
  try (Session session=driver.session(AccessMode.READ)){
    StatementResult queryResults=session.run(q,parameters);
    List<Flow> results=new ArrayList<>();
    for (    Record record : queryResults.list()) {
      FlowAdapter adapter=new FlowAdapter(record);
      results.add(adapter.getFlow());
    }
    return results;
  }
 }"
37707,"@Override public List<Flow> getFlows(String flowId){
  String where=""String_Node_Str"" + flowId + ""String_Node_Str"";
  return loadFlows(where);
}","@Override public List<Flow> getFlows(String flowId){
  String where=""String_Node_Str"";
  Value parameters=Values.parameters(""String_Node_Str"",flowId);
  return loadFlows(where,parameters);
}"
37708,"@Override public List<Flow> getAllFlows(){
  String noWhere=""String_Node_Str"";
  return loadFlows(noWhere);
}","@Override public List<Flow> getAllFlows(){
  String noWhere=""String_Node_Str"";
  return loadFlows(noWhere,null);
}"
37709,"@Given(""String_Node_Str"") public void selectARandomSwitch(String switchAlias){
  List<Switch> switches=getUnaliasedSwitches();
  Random r=new Random();
  Switch theSwitch=switches.get(r.nextInt(switches.size()));
  log.info(""String_Node_Str"",theSwitch.getDpId());
  topologyUnderTest.addAlias(switchAlias,theSwitch);
}","@Given(""String_Node_Str"") public void selectARandomSwitch(String switchAlias){
  List<Switch> switches=getUnaliasedSwitches();
  Assume.assumeFalse(""String_Node_Str"",CollectionUtils.isEmpty(switches));
  Switch theSwitch=switches.get(0);
  log.info(""String_Node_Str"",theSwitch.getDpId());
  topologyUnderTest.addAlias(switchAlias,theSwitch);
}"
37710,"/** 
 * Checks if discovery should be suspended for that link.
 * @return true if link should be excluded from discovery plan and discovery packets should not be sent.
 */
public boolean isNewAttemptAllowed(){
  if (consecutiveFailureLimit == ENDLESS_ATTEMPTS) {
    return true;
  }
  return consecutiveFailure < consecutiveFailureLimit;
}","/** 
 * Checks if discovery should be suspended for that link or we can try to discover it.
 * @return true if link should be excluded from discovery plan and discovery packets should not be sent.
 */
public boolean isNewAttemptAllowed(){
  if (consecutiveFailureLimit == ENDLESS_ATTEMPTS) {
    return true;
  }
  return consecutiveFailure < consecutiveFailureLimit;
}"
37711,"/** 
 * This helper function is used with getPath(hint) to confirm the hint path exists 
 */
private SearchNode confirmIsls(List<SimpleIsl> srcIsls){
  int totalCost=0;
  LinkedList<SimpleIsl> confirmedIsls=new LinkedList<>();
  boolean validPath=true;
  for (  SimpleIsl i : srcIsls) {
    boolean foundThisOne=false;
    SimpleSwitch srcSwitch=network.getSimpleSwitch(i.src_dpid);
    if (srcSwitch != null) {
      Set<SimpleIsl> pathsToDst=safeSet(srcSwitch.outbound.get(i.dst_dpid));
      if (pathsToDst.equals(Collections.EMPTY_SET))       logger.debug(""String_Node_Str"",i.src_dpid,i.dst_dpid);
      for (      SimpleIsl orig : pathsToDst) {
        if (i.equals(orig)) {
          foundThisOne=true;
          confirmedIsls.add(orig);
          totalCost+=orig.cost;
          break;
        }
      }
    }
 else {
      logger.warn(""String_Node_Str"",i.src_dpid);
    }
    if (!foundThisOne) {
      validPath=false;
      break;
    }
  }
  if (validPath) {
    return new SearchNode(this.allowedDepth - confirmedIsls.size(),totalCost,network.getSimpleSwitch(confirmedIsls.peekLast().dst_dpid),confirmedIsls);
  }
  return null;
}","/** 
 * This helper function is used with getPath(hint) to confirm the hint path exists. 
 */
private SearchNode confirmIsls(List<SimpleIsl> srcIsls){
  int totalCost=0;
  LinkedList<SimpleIsl> confirmedIsls=new LinkedList<>();
  boolean validPath=true;
  for (  SimpleIsl i : srcIsls) {
    boolean foundThisOne=false;
    SimpleSwitch srcSwitch=network.getSimpleSwitch(i.getSrcDpid());
    if (srcSwitch != null) {
      Set<SimpleIsl> pathsToDst=srcSwitch.outbound.get(i.getDstDpid());
      for (      SimpleIsl orig : pathsToDst) {
        if (i.equals(orig)) {
          foundThisOne=true;
          confirmedIsls.add(orig);
          totalCost+=orig.getCost();
          break;
        }
      }
    }
 else {
      logger.warn(""String_Node_Str"",i.getSrcDpid());
    }
    if (!foundThisOne) {
      validPath=false;
      break;
    }
  }
  if (validPath) {
    return new SearchNode(this.allowedDepth - confirmedIsls.size(),totalCost,network.getSimpleSwitch(confirmedIsls.peekLast().getDstDpid()),confirmedIsls);
  }
  return null;
}"
37712,"/** 
 * This helper function is used with getPath(hint) and will swap the src and dst of each isl in the list 
 */
private List<SimpleIsl> swapSrcDst(List<SimpleIsl> originalIsls){
  List<SimpleIsl> mirrorIsls=new ArrayList<>();
  for (  SimpleIsl original : originalIsls) {
    mirrorIsls.add(new SimpleIsl(original.dst_dpid,original.src_dpid,original.dst_port,original.src_port,original.cost,original.latency));
  }
  return mirrorIsls;
}","/** 
 * This helper function is used with getPath(hint) and will swap the src and dst of each isl in the list. 
 */
private List<SimpleIsl> swapSrcDst(List<SimpleIsl> originalIsls){
  List<SimpleIsl> mirrorIsls=new ArrayList<>();
  for (  SimpleIsl original : originalIsls) {
    mirrorIsls.add(new SimpleIsl(original.getDstDpid(),original.getSrcDpid(),original.getDstPort(),original.getSrcPort(),original.getCost(),original.getLatency()));
  }
  return mirrorIsls;
}"
37713,"public SearchNode addNode(SimpleIsl nextIsl){
  SearchNode newNode=this.clone();
  newNode.parentPath.add(nextIsl);
  newNode.dst_sw=network.getSimpleSwitch(nextIsl.dst_dpid);
  newNode.allowedDepth--;
  newNode.parentCost+=nextIsl.cost;
  return newNode;
}","SearchNode addNode(SimpleIsl nextIsl){
  SearchNode newNode=this.clone();
  newNode.parentPath.add(nextIsl);
  newNode.dstSw=network.getSimpleSwitch(nextIsl.getDstDpid());
  newNode.allowedDepth--;
  newNode.parentCost+=nextIsl.getCost();
  return newNode;
}"
37714,"/** 
 * This is generally called after getPath() to find the path back.  The path back could be asymmetric, but this will increase the odds that we return the symmetric path if it exists. The hint will be used to determine if it exists.  If it does, then use it as the start bestCost and bestPath.  That should help speed things along. Whereas it's possible that could build up the SearchNodes for this path (if found) and put them into the visited bucket, we'll start without that optimization and decide later whether adding it provides any efficiencies
 * @param hint The path to use as a starting point. It can be in reverse order (we'll reverse it)
 * @return An ordered list that represents the path from start to end.
 */
public LinkedList<SimpleIsl> getPath(List<SimpleIsl> hint){
  if (hint != null && hint.size() > 0) {
    SimpleSwitch from=network.getSimpleSwitch(hint.get(0).src_dpid);
    SimpleSwitch to=network.getSimpleSwitch(hint.get(hint.size() - 1).dst_dpid);
    if (start.equals(to) && end.equals(from)) {
      logger.trace(""String_Node_Str"",from,to,to,from);
      hint=swapSrcDst(Lists.reverse(hint));
      from=network.getSimpleSwitch(hint.get(0).src_dpid);
      to=network.getSimpleSwitch(hint.get(hint.size() - 1).dst_dpid);
    }
    if (start.equals(from) && end.equals(to)) {
      logger.trace(""String_Node_Str"",from,to);
      SearchNode best=confirmIsls(hint);
      if (best != null) {
        logger.debug(""String_Node_Str"",from,to);
        bestCost=best.parentCost;
        bestPath=best;
      }
 else {
        logger.info(""String_Node_Str"",from,to);
      }
    }
  }
  return getPath();
}","/** 
 * This is generally called after getPath() to find the path back.  The path back could be asymmetric, but this will increase the odds that we return the symmetric path if it exists. The hint will be used to determine if it exists.  If it does, then use it as the start bestCost and bestPath.  That should help speed things along. <p/> Whereas it's possible that could build up the SearchNodes for this path (if found) and put them into the visited bucket, we'll start without that optimization and decide later whether adding it provides any efficiencies
 * @param hint The path to use as a starting point. It can be in reverse order (we'll reverse it)
 * @return An ordered list that represents the path from start to end.
 */
public LinkedList<SimpleIsl> getPath(List<SimpleIsl> hint){
  if (hint != null && hint.size() > 0) {
    SimpleSwitch from=network.getSimpleSwitch(hint.get(0).getSrcDpid());
    SimpleSwitch to=network.getSimpleSwitch(hint.get(hint.size() - 1).getDstDpid());
    if (start.equals(to) && end.equals(from)) {
      logger.trace(""String_Node_Str"",from,to,to,from);
      hint=swapSrcDst(Lists.reverse(hint));
      from=network.getSimpleSwitch(hint.get(0).getSrcDpid());
      to=network.getSimpleSwitch(hint.get(hint.size() - 1).getDstDpid());
    }
    if (start.equals(from) && end.equals(to)) {
      logger.trace(""String_Node_Str"",from,to);
      SearchNode best=confirmIsls(hint);
      if (best != null) {
        logger.debug(""String_Node_Str"",from,to);
        bestCost=best.parentCost;
        bestPath=best;
      }
 else {
        logger.info(""String_Node_Str"",from,to);
      }
    }
  }
  return getPath();
}"
37715,"@Override @SuppressWarnings(""String_Node_Str"") protected SearchNode clone(){
  return new SearchNode(allowedDepth,parentCost,dst_sw,(LinkedList<SimpleIsl>)parentPath.clone());
}","@Override @SuppressWarnings(""String_Node_Str"") protected SearchNode clone(){
  return new SearchNode(allowedDepth,parentCost,dstSw,(LinkedList<SimpleIsl>)parentPath.clone());
}"
37716,"public SearchNode(int allowedDepth,int parentCost,SimpleSwitch dst_sw,LinkedList<SimpleIsl> parentPath){
  this.dst_sw=dst_sw;
  this.allowedDepth=allowedDepth;
  this.parentCost=parentCost;
  this.parentPath=parentPath;
}","SearchNode(int allowedDepth,int parentCost,SimpleSwitch dstSw,LinkedList<SimpleIsl> parentPath){
  this.dstSw=dstSw;
  this.allowedDepth=allowedDepth;
  this.parentCost=parentCost;
  this.parentPath=parentPath;
}"
37717,"public SimpleGetShortestPath(AvailableNetwork network,String src_dpid,String dst_dpid,int allowedDepth){
  this.network=network;
  this.start=network.getSwitches().get(src_dpid);
  this.end=network.getSwitches().get(dst_dpid);
  this.allowedDepth=allowedDepth;
  if (this.start == null)   logger.warn(""String_Node_Str"",src_dpid);
  if (this.end == null)   logger.warn(""String_Node_Str"",dst_dpid);
}","public SimpleGetShortestPath(AvailableNetwork network,String srcDpid,String dstDpid,int allowedDepth){
  this.network=network;
  this.start=network.getSwitches().get(srcDpid);
  this.end=network.getSwitches().get(dstDpid);
  this.allowedDepth=allowedDepth;
  if (this.start == null) {
    logger.warn(""String_Node_Str"",srcDpid);
  }
  if (this.end == null) {
    logger.warn(""String_Node_Str"",dstDpid);
  }
}"
37718,"/** 
 * Use this comparison if very strong equality is needed (most likely rare; probably only testing)
 * @return true if every field is the same.
 */
public boolean identical(Object o){
  if (this.equals(o)) {
    SimpleIsl simpleIsl=(SimpleIsl)o;
    return cost == simpleIsl.cost && latency == simpleIsl.latency;
  }
  return false;
}","/** 
 * Use this comparison if very strong equality is needed (most likely rare; probably only testing).
 * @return true if every field is the same.
 */
public boolean identical(Object o){
  if (this.equals(o)) {
    SimpleIsl simpleIsl=(SimpleIsl)o;
    return cost == simpleIsl.cost && latency == simpleIsl.latency;
  }
  return false;
}"
37719,"public SimpleIsl(String src_dpid,String dst_dpid,int src_port,int dst_port,int cost,int latency){
  this.src_dpid=src_dpid;
  this.dst_dpid=dst_dpid;
  this.src_port=src_port;
  this.dst_port=dst_port;
  this.cost=(cost == 0) ? DEFAULT_COST : cost;
  this.latency=latency;
}","public SimpleIsl(String srcDpid,String dstDpid,int srcPort,int dstPort,int cost,int latency){
  this.srcDpid=srcDpid;
  this.dstDpid=dstDpid;
  this.srcPort=srcPort;
  this.dstPort=dstPort;
  this.cost=(cost == 0) ? DEFAULT_COST : cost;
  this.latency=latency;
}"
37720,"public SimpleSwitch addOutbound(SimpleIsl isl){
  outbound.computeIfAbsent(isl.dst_dpid,newSet -> new HashSet<>()).add(isl);
  return this;
}","public SimpleSwitch addOutbound(SimpleIsl isl){
  outbound.computeIfAbsent(isl.getDstDpid(),newSet -> new HashSet<>()).add(isl);
  return this;
}"
37721,"@Builder @JsonCreator public LinkProps(@JsonProperty(""String_Node_Str"") NetworkEndpoint source,@JsonProperty(""String_Node_Str"") NetworkEndpoint dest,@JsonProperty(""String_Node_Str"") Map<String,String> props){
  this.source=source;
  this.dest=dest;
  this.props=props;
}","public LinkProps(NetworkEndpoint source,NetworkEndpoint dest,Map<String,String> props){
  this.source=source;
  this.dest=dest;
  this.props=props;
  this.created=null;
  this.modified=null;
}"
37722,"public boolean isReadRequest(){
  return this.getClass().isAnnotationPresent(ReadRequest.class);
}","@JsonIgnore public boolean isReadRequest(){
  return this.getClass().isAnnotationPresent(ReadRequest.class);
}"
37723,"public LinkPropsData(@JsonProperty(""String_Node_Str"") NetworkEndpoint source,@JsonProperty(""String_Node_Str"") NetworkEndpoint destination,@JsonProperty(""String_Node_Str"") Map<String,String> props){
  this.source=source;
  this.destination=destination;
  this.props=props;
}","public LinkPropsData(@JsonProperty(""String_Node_Str"") LinkProps linkProps){
  this.linkProps=linkProps;
}"
37724,"/** 
 * Produce   {@link LinkProps} object with predefined data.
 */
public static LinkProps makeSubject(){
  NetworkEndpoint source=new NetworkEndpoint(""String_Node_Str"",8);
  NetworkEndpoint dest=new NetworkEndpoint(""String_Node_Str"",9);
  HashMap<String,String> props=new HashMap<>();
  props.put(""String_Node_Str"",""String_Node_Str"");
  return new LinkProps(source,dest,props);
}","/** 
 * Produce   {@link LinkProps} object with predefined data.
 */
public static LinkProps makeSubject(){
  NetworkEndpoint source=new NetworkEndpoint(""String_Node_Str"",8);
  NetworkEndpoint dest=new NetworkEndpoint(""String_Node_Str"",9);
  HashMap<String,String> props=new HashMap<>();
  props.put(""String_Node_Str"",""String_Node_Str"");
  long created=System.currentTimeMillis();
  return new LinkProps(source,dest,props,created,created);
}"
37725,"/** 
 * Converts link properties to   {@link LinkPropsDto}.
 */
default LinkPropsDto toDto(LinkPropsData data){
  NetworkEndpoint source=data.getSource();
  NetworkEndpoint destination=data.getDestination();
  return new LinkPropsDto(source.getDatapath(),source.getPortNumber(),destination.getDatapath(),destination.getPortNumber(),data.getProps());
}","/** 
 * Converts link properties to   {@link LinkPropsDto}.
 */
default LinkPropsDto toDto(LinkPropsData data){
  requireNonNull(data.getLinkProps(),""String_Node_Str"");
  NetworkEndpoint source=data.getLinkProps().getSource();
  NetworkEndpoint destination=data.getLinkProps().getDest();
  return new LinkPropsDto(source.getDatapath(),source.getPortNumber(),destination.getDatapath(),destination.getPortNumber(),data.getLinkProps().getProps());
}"
37726,"@Test public void shouldGetPropsList(){
  final String correlationId=""String_Node_Str"";
  LinkPropsData linkProps=new LinkPropsData(new NetworkEndpoint(""String_Node_Str"",1),new NetworkEndpoint(""String_Node_Str"",2),Collections.singletonMap(""String_Node_Str"",""String_Node_Str""));
  Message message=new ChunkedInfoMessage(linkProps,0,correlationId,null);
  messageExchanger.mockResponse(message);
  RequestCorrelationId.create(correlationId);
  List<LinkPropsDto> result=linkService.getLinkProps(null,0,null,0);
  assertFalse(""String_Node_Str"",result.isEmpty());
  LinkPropsDto dto=result.get(0);
  assertThat(dto.getSrcSwitch(),is(linkProps.getSource().getDatapath()));
  assertThat(dto.getSrcPort(),is(linkProps.getSource().getPortNumber()));
  assertThat(dto.getDstSwitch(),is(linkProps.getDestination().getDatapath()));
  assertThat(dto.getDstPort(),is(linkProps.getDestination().getPortNumber()));
}","@Test public void shouldGetPropsList(){
  final String correlationId=""String_Node_Str"";
  LinkProps linkProps=new LinkProps(new NetworkEndpoint(""String_Node_Str"",1),new NetworkEndpoint(""String_Node_Str"",2),Collections.singletonMap(""String_Node_Str"",""String_Node_Str""));
  LinkPropsData linkPropsData=new LinkPropsData(linkProps);
  Message message=new ChunkedInfoMessage(linkPropsData,0,correlationId,null);
  messageExchanger.mockResponse(message);
  RequestCorrelationId.create(correlationId);
  List<LinkPropsDto> result=linkService.getLinkProps(null,0,null,0);
  assertFalse(""String_Node_Str"",result.isEmpty());
  LinkPropsDto dto=result.get(0);
  assertThat(dto.getSrcSwitch(),is(linkPropsData.getLinkProps().getSource().getDatapath()));
  assertThat(dto.getSrcPort(),is(linkPropsData.getLinkProps().getSource().getPortNumber()));
  assertThat(dto.getDstSwitch(),is(linkPropsData.getLinkProps().getDest().getDatapath()));
  assertThat(dto.getDstPort(),is(linkPropsData.getLinkProps().getDest().getPortNumber()));
}"
37727,"private Set<String> availablePermissions(final UserInfo userInfo){
  Set<String> availablePermissions=new HashSet<>();
  Set<String> roles=userInfo.getRoles();
  if (roles != null && roles.size() > 0) {
    List<Role> roleList=roleService.getRoleByName(roles);
    for (    Role role : roleList) {
      if (role.getPermissions() != null) {
        for (        Permission permission : role.getPermissions()) {
          if (Status.ACTIVE.getStatusEntity().getStatus().equalsIgnoreCase(permission.getStatus())) {
            availablePermissions.add(permission.getName());
          }
        }
      }
    }
  }
  return availablePermissions;
}","private Set<String> availablePermissions(final UserInfo userInfo){
  Set<String> availablePermissions=new HashSet<>();
  if (userInfo.getUserId() != 1) {
    Set<String> roles=userInfo.getRoles();
    if (roles != null && roles.size() > 0) {
      List<Role> roleList=roleService.getRoleByName(roles);
      for (      Role role : roleList) {
        if (role.getPermissions() != null) {
          for (          Permission permission : role.getPermissions()) {
            if (Status.ACTIVE.getStatusEntity().getStatus().equalsIgnoreCase(permission.getStatus())) {
              availablePermissions.add(permission.getName());
            }
          }
        }
      }
    }
  }
 else {
    List<Permission> permissions=permissionService.getAllPermission(userInfo.getUserId());
    for (    Permission permission : permissions) {
      availablePermissions.add(permission.getName());
    }
  }
  userInfo.setPermissions(availablePermissions);
  return availablePermissions;
}"
37728,"private void validateAndPopulatePermisssion(final UserInfo userInfo,final Permissions permissions) throws Exception {
  if (!permissions.checkObjectAccessPermissions()) {
    if (!hasPermissions(userInfo,permissions.values())) {
      throw new AccessDeniedException(messageUtils.getUnauthorizedMessage());
    }
  }
}","private void validateAndPopulatePermisssion(final UserInfo userInfo,final Permissions permissions) throws Exception {
  if (!permissions.checkObjectAccessPermissions()) {
    if (!hasPermissions(userInfo,permissions.values())) {
      LOGGER.error(""String_Node_Str"" + userInfo.getUserId() + ""String_Node_Str""+ permissions.values());
      throw new AccessDeniedException(messageUtils.getUnauthorizedMessage());
    }
  }
}"
37729,"@Override public boolean preHandle(final HttpServletRequest request,final HttpServletResponse response,final Object handler) throws Exception {
  String correlationId=request.getParameter(CORRELATION_ID);
  correlationId=correlationId == null ? UUID.randomUUID().toString() : correlationId;
  try {
    MDC.put(CORRELATION_ID,correlationId);
    HttpSession session=request.getSession();
    UserInfo userInfo=null;
    userInfo=(UserInfo)session.getAttribute(IConstants.SESSION_OBJECT);
    if (userInfo != null) {
      if (handler instanceof HandlerMethod) {
        HandlerMethod handlerMethod=(HandlerMethod)handler;
        Permissions permissions=handlerMethod.getMethod().getAnnotation(Permissions.class);
        LOGGER.info(""String_Node_Str"");
        if (permissions != null) {
          LOGGER.info(""String_Node_Str"" + permissions.values());
          validateAndPopulatePermisssion(userInfo,permissions);
        }
      }
      updateRequestContext(correlationId,request,userInfo);
    }
  }
 catch (  IllegalStateException ex) {
    LOGGER.info(""String_Node_Str"" + ex.getLocalizedMessage(),ex);
  }
  return true;
}","@Override public boolean preHandle(final HttpServletRequest request,final HttpServletResponse response,final Object handler) throws Exception {
  String correlationId=request.getParameter(CORRELATION_ID);
  correlationId=correlationId == null ? UUID.randomUUID().toString() : correlationId;
  try {
    MDC.put(CORRELATION_ID,correlationId);
    HttpSession session=request.getSession();
    UserInfo userInfo=null;
    userInfo=(UserInfo)session.getAttribute(IConstants.SESSION_OBJECT);
    if (userInfo != null) {
      if (handler instanceof HandlerMethod) {
        HandlerMethod handlerMethod=(HandlerMethod)handler;
        Permissions permissions=handlerMethod.getMethod().getAnnotation(Permissions.class);
        if (permissions != null) {
          validateAndPopulatePermisssion(userInfo,permissions);
        }
      }
      updateRequestContext(correlationId,request,userInfo);
    }
  }
 catch (  IllegalStateException ex) {
    LOGGER.info(""String_Node_Str"" + ex.getLocalizedMessage(),ex);
  }
  return true;
}"
37730,"/** 
 * Sets request payload.
 * @param payload request payload
 */
public void setPayload(final FlowIdStatusPayload payload){
  if (payload == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  this.payload=payload;
}","/** 
 * Sets request payload.
 * @param payload request payload
 */
public void setPayload(final FlowIdStatusPayload payload){
  this.payload=payload;
}"
37731,"/** 
 * {@inheritDoc}
 */
@Override public List<FlowPayload> getFlows(){
  final String correlationId=RequestCorrelationId.getId();
  LOGGER.debug(""String_Node_Str"",CORRELATION_ID,correlationId);
  FlowsGetRequest data=new FlowsGetRequest(new FlowIdStatusPayload());
  CommandMessage request=new CommandMessage(data,System.currentTimeMillis(),correlationId,Destination.WFM);
  messageConsumer.clear();
  messageProducer.send(topic,request);
  Message message=(Message)messageConsumer.poll(correlationId);
  FlowsResponse response=(FlowsResponse)validateInfoMessage(request,message,correlationId);
  List<FlowPayload> result=collectFlows(response.getFlowIds(),correlationId);
  logger.debug(""String_Node_Str"",CORRELATION_ID,correlationId,result.size());
  return result;
}","/** 
 * {@inheritDoc}
 */
@Override public List<FlowPayload> getFlows(){
  final String correlationId=RequestCorrelationId.getId();
  LOGGER.debug(""String_Node_Str"");
  FlowGetRequest data=new FlowGetRequest();
  CommandMessage request=new CommandMessage(data,System.currentTimeMillis(),correlationId,Destination.WFM);
  messageProducer.send(topic,request);
  List<FlowResponse> result=flowsCollector.getResult(correlationId);
  logger.debug(""String_Node_Str"",result.size());
  return result.stream().map(FlowResponse::getPayload).map(FlowPayloadToFlowConverter::buildFlowPayloadByFlow).collect(Collectors.toList());
}"
37732,"/** 
 * Chooses response by request.
 * @param data received from kafka CommandData message payload
 * @return InfoMassage to be send as response payload
 */
private Message formatResponse(final String correlationId,final CommandData data){
  if (data instanceof FlowCreateRequest) {
    return new InfoMessage(flowResponse,0,correlationId,Destination.NORTHBOUND);
  }
 else   if (data instanceof FlowDeleteRequest) {
    return new InfoMessage(flowResponse,0,correlationId,Destination.NORTHBOUND);
  }
 else   if (data instanceof FlowUpdateRequest) {
    return new InfoMessage(flowResponse,0,correlationId,Destination.NORTHBOUND);
  }
 else   if (data instanceof FlowGetRequest) {
    if (ERROR_FLOW_ID.equals(((FlowGetRequest)data).getPayload().getId())) {
      return new ErrorMessage(new ErrorData(ErrorType.NOT_FOUND,""String_Node_Str"",ERROR_FLOW_ID),0,correlationId,Destination.NORTHBOUND);
    }
 else {
      return new InfoMessage(flowResponse,0,correlationId,Destination.NORTHBOUND);
    }
  }
 else   if (data instanceof FlowsGetRequest) {
    return new InfoMessage(flowsResponse,0,correlationId,Destination.NORTHBOUND);
  }
 else   if (data instanceof FlowStatusRequest) {
    return new InfoMessage(flowStatusResponse,0,correlationId,Destination.NORTHBOUND);
  }
 else   if (data instanceof FlowPathRequest) {
    return new InfoMessage(flowPathResponse,0,correlationId,Destination.NORTHBOUND);
  }
 else   if (data instanceof SwitchRulesDeleteRequest) {
    return new InfoMessage(switchRulesResponse,0,correlationId,Destination.NORTHBOUND);
  }
 else {
    return null;
  }
}","/** 
 * Chooses response by request.
 * @param data received from kafka CommandData message payload
 * @return InfoMassage to be send as response payload
 */
private Message formatResponse(final String correlationId,final CommandData data){
  if (data instanceof FlowCreateRequest) {
    return new InfoMessage(flowResponse,0,correlationId,Destination.NORTHBOUND);
  }
 else   if (data instanceof FlowDeleteRequest) {
    return new InfoMessage(flowResponse,0,correlationId,Destination.NORTHBOUND);
  }
 else   if (data instanceof FlowUpdateRequest) {
    return new InfoMessage(flowResponse,0,correlationId,Destination.NORTHBOUND);
  }
 else   if (data instanceof FlowGetRequest) {
    FlowIdStatusPayload request=((FlowGetRequest)data).getPayload();
    return getFlowResponse(request,correlationId);
  }
 else   if (data instanceof FlowStatusRequest) {
    return new InfoMessage(flowStatusResponse,0,correlationId,Destination.NORTHBOUND);
  }
 else   if (data instanceof FlowPathRequest) {
    return new InfoMessage(flowPathResponse,0,correlationId,Destination.NORTHBOUND);
  }
 else   if (data instanceof SwitchRulesDeleteRequest) {
    return new InfoMessage(switchRulesResponse,0,correlationId,Destination.NORTHBOUND);
  }
 else {
    return null;
  }
}"
37733,"private boolean hasPermissions(final UserInfo userInfo,final String... permissions){
  LOGGER.info(""String_Node_Str"");
  boolean hasPermission=true;
  Set<String> availablePermissions=availablePermissions(userInfo);
  if (!availablePermissions.isEmpty()) {
    for (    String permission : permissions) {
      if (!availablePermissions.contains(permission)) {
        hasPermission=false;
        break;
      }
    }
  }
 else {
    hasPermission=false;
  }
  LOGGER.info(""String_Node_Str"");
  return hasPermission;
}","private boolean hasPermissions(final UserInfo userInfo,final String... permissions){
  boolean hasPermission=true;
  Set<String> availablePermissions=availablePermissions(userInfo);
  if (!availablePermissions.isEmpty()) {
    for (    String permission : permissions) {
      if (!availablePermissions.contains(permission)) {
        hasPermission=false;
        break;
      }
    }
  }
 else {
    hasPermission=false;
  }
  return hasPermission;
}"
37734,"private void validateAndPopulatePermisssion(final UserInfo userInfo,final Permissions permissions) throws Exception {
  if (!permissions.checkObjectAccessPermissions()) {
    if (!hasPermissions(userInfo,permissions.values())) {
      throw new AccessDeniedException(messageUtils.getUnauthorizedMessage());
    }
  }
  LOGGER.info(""String_Node_Str"");
}","private void validateAndPopulatePermisssion(final UserInfo userInfo,final Permissions permissions) throws Exception {
  if (!permissions.checkObjectAccessPermissions()) {
    if (!hasPermissions(userInfo,permissions.values())) {
      throw new AccessDeniedException(messageUtils.getUnauthorizedMessage());
    }
  }
}"
37735,"@Override public boolean preHandle(final HttpServletRequest request,final HttpServletResponse response,final Object handler) throws Exception {
  String correlationId=request.getParameter(CORRELATION_ID);
  correlationId=correlationId == null ? UUID.randomUUID().toString() : correlationId;
  try {
    MDC.put(CORRELATION_ID,correlationId);
    HttpSession session=request.getSession();
    UserInfo userInfo=null;
    userInfo=(UserInfo)session.getAttribute(IConstants.SESSION_OBJECT);
    if (userInfo != null) {
      if (handler instanceof HandlerMethod) {
        HandlerMethod handlerMethod=(HandlerMethod)handler;
        Permissions permissions=handlerMethod.getMethod().getAnnotation(Permissions.class);
        LOGGER.info(""String_Node_Str"");
        if (permissions != null) {
          LOGGER.info(""String_Node_Str"" + permissions.values());
          validateAndPopulatePermisssion(userInfo,permissions);
        }
      }
      updateRequestContext(correlationId,request,userInfo);
      LOGGER.info(""String_Node_Str"");
    }
  }
 catch (  IllegalStateException ex) {
    LOGGER.info(""String_Node_Str"" + ex.getLocalizedMessage(),ex);
  }
  return true;
}","@Override public boolean preHandle(final HttpServletRequest request,final HttpServletResponse response,final Object handler) throws Exception {
  String correlationId=request.getParameter(CORRELATION_ID);
  correlationId=correlationId == null ? UUID.randomUUID().toString() : correlationId;
  try {
    MDC.put(CORRELATION_ID,correlationId);
    HttpSession session=request.getSession();
    UserInfo userInfo=null;
    userInfo=(UserInfo)session.getAttribute(IConstants.SESSION_OBJECT);
    if (userInfo != null) {
      if (handler instanceof HandlerMethod) {
        HandlerMethod handlerMethod=(HandlerMethod)handler;
        Permissions permissions=handlerMethod.getMethod().getAnnotation(Permissions.class);
        LOGGER.info(""String_Node_Str"");
        if (permissions != null) {
          LOGGER.info(""String_Node_Str"" + permissions.values());
          validateAndPopulatePermisssion(userInfo,permissions);
        }
      }
      updateRequestContext(correlationId,request,userInfo);
    }
  }
 catch (  IllegalStateException ex) {
    LOGGER.info(""String_Node_Str"" + ex.getLocalizedMessage(),ex);
  }
  return true;
}"
37736,"/** 
 * Return logged in user information.
 * @param request HttpServletRequest to retrieve logged in user information.
 * @return logged in user information.
 */
protected UserInfo getLoggedInUser(final HttpServletRequest request){
  LOGGER.info(""String_Node_Str"");
  HttpSession session=request.getSession();
  UserInfo userInfo=null;
  try {
    userInfo=(UserInfo)session.getAttribute(IConstants.SESSION_OBJECT);
  }
 catch (  IllegalStateException ex) {
    LOGGER.info(""String_Node_Str"" + ex.getLocalizedMessage(),ex);
  }
 finally {
    if (userInfo == null) {
      session=request.getSession(false);
      userInfo=new UserInfo();
      session.setAttribute(IConstants.SESSION_OBJECT,userInfo);
    }
  }
  return userInfo;
}","/** 
 * Return logged in user information.
 * @param request HttpServletRequest to retrieve logged in user information.
 * @return logged in user information.
 */
protected UserInfo getLoggedInUser(final HttpServletRequest request){
  HttpSession session=request.getSession();
  UserInfo userInfo=null;
  try {
    userInfo=(UserInfo)session.getAttribute(IConstants.SESSION_OBJECT);
  }
 catch (  IllegalStateException ex) {
    LOGGER.info(""String_Node_Str"" + ex.getLocalizedMessage(),ex);
  }
 finally {
    if (userInfo == null) {
      session=request.getSession(false);
      userInfo=new UserInfo();
      session.setAttribute(IConstants.SESSION_OBJECT,userInfo);
    }
  }
  return userInfo;
}"
37737,"/** 
 * Sending message.
 * @param receivers the list of receivers.
 * @param subject mail subject.
 * @param template template.
 * @param context Map with context values for velocity template.
 */
public void send(final String receiver,final String subject,final TemplateService.Template template,final Map<String,Object> context){
  MimeMessage mimeMessage=javaMailSender.createMimeMessage();
  MimeMessageHelper msg=new MimeMessageHelper(mimeMessage);
  if (!StringUtil.isNullOrEmpty(receiver)) {
    try {
      msg.setSubject(subject);
      msg.setTo(receiver);
      msg.setText(templateService.mergeTemplateToString(template,context),true);
    }
 catch (    MessagingException e) {
      e.printStackTrace();
    }
    javaMailSender.send(mimeMessage);
  }
}","/** 
 * Sending message.
 * @param receivers the list of receivers.
 * @param subject mail subject.
 * @param template template.
 * @param context Map with context values for velocity template.
 */
public void send(final String receiver,final String subject,final TemplateService.Template template,final Map<String,Object> context){
  MimeMessage mimeMessage=javaMailSender.createMimeMessage();
  MimeMessageHelper msg=new MimeMessageHelper(mimeMessage);
  if (!StringUtil.isNullOrEmpty(receiver)) {
    try {
      msg.setSubject(subject);
      msg.setTo(receiver);
      msg.setText(templateService.mergeTemplateToString(template,context),true);
      javaMailSender.send(mimeMessage);
      LOGGER.info(""String_Node_Str"" + subject);
    }
 catch (    MessagingException e) {
      LOGGER.error(""String_Node_Str"" + e.getMessage(),e);
    }
  }
}"
37738,"@Override public UserDetails loadUserByUsername(final String username) throws UsernameNotFoundException {
  LOGGER.info(""String_Node_Str"");
  UserEntity user=userRepository.findByUsername(username);
  Set<GrantedAuthority> authorities=new HashSet<GrantedAuthority>(0);
  if (user == null) {
    throw new UsernameNotFoundException(username);
  }
  return new org.springframework.security.core.userdetails.User(username,user.getPassword(),authorities);
}","@Override public UserDetails loadUserByUsername(final String username) throws UsernameNotFoundException {
  UserEntity user=userRepository.findByUsername(username);
  Set<GrantedAuthority> authorities=new HashSet<GrantedAuthority>(0);
  if (user == null) {
    throw new UsernameNotFoundException(username);
  }
  return new org.springframework.security.core.userdetails.User(username,user.getPassword(),authorities);
}"
37739,"@Transactional(propagation=Propagation.REQUIRED,readOnly=false) public UserInfo createUser(final UserInfo userRequest){
  userValidator.validateCreateUser(userRequest);
  Set<RoleEntity> roleEntities=new HashSet<>();
  List<RoleEntity> roleEntityList=roleRepository.findAll();
  for (  Long roleId : userRequest.getRoleIds()) {
    RoleEntity roleEntity=roleEntityList.parallelStream().filter((entity) -> entity.getRoleId().equals(roleId)).findFirst().orElse(null);
    if (!ValidatorUtil.isNull(roleEntity)) {
      roleEntities.add(roleEntity);
    }
 else {
      throw new RequestValidationException(messageUtil.getAttributeNotFound(""String_Node_Str""));
    }
  }
  UserEntity userEntity=UserConversionUtil.toUserEntity(userRequest,roleEntities);
  String password=ValidatorUtil.randomAlphaNumeric(16);
  userEntity.setPassword(StringUtil.encodeString(password));
  userEntity.setIs2FaEnabled(true);
  userEntity=userRepository.save(userEntity);
  if (userEntity.getUserId() != null) {
    Map<String,Object> map=new HashMap<String,Object>();
    map.put(""String_Node_Str"",userEntity.getName());
    map.put(""String_Node_Str"",userEntity.getUsername());
    map.put(""String_Node_Str"",password);
    mailService.send(userEntity.getEmail(),mailUtils.getSubjectAccountUsername(),TemplateService.Template.ACCOUNT_USERNAME,map);
    mailService.send(userEntity.getEmail(),mailUtils.getSubjectAccountPassword(),TemplateService.Template.ACCOUNT_PASSWORD,map);
  }
  return UserConversionUtil.toUserInfo(userEntity);
}","@Transactional(propagation=Propagation.REQUIRED,readOnly=false) public UserInfo createUser(final UserInfo userRequest){
  userValidator.validateCreateUser(userRequest);
  Set<RoleEntity> roleEntities=new HashSet<>();
  List<RoleEntity> roleEntityList=roleRepository.findAll();
  for (  Long roleId : userRequest.getRoleIds()) {
    RoleEntity roleEntity=roleEntityList.parallelStream().filter((entity) -> entity.getRoleId().equals(roleId)).findFirst().orElse(null);
    if (!ValidatorUtil.isNull(roleEntity)) {
      roleEntities.add(roleEntity);
    }
 else {
      throw new RequestValidationException(messageUtil.getAttributeNotFound(""String_Node_Str""));
    }
  }
  UserEntity userEntity=UserConversionUtil.toUserEntity(userRequest,roleEntities);
  String password=ValidatorUtil.randomAlphaNumeric(16);
  userEntity.setPassword(StringUtil.encodeString(password));
  userEntity.setIs2FaEnabled(true);
  userEntity=userRepository.save(userEntity);
  LOGGER.info(""String_Node_Str"" + userEntity.getUsername() + ""String_Node_Str"");
  if (userEntity.getUserId() != null) {
    Map<String,Object> map=new HashMap<String,Object>();
    map.put(""String_Node_Str"",userEntity.getName());
    map.put(""String_Node_Str"",userEntity.getUsername());
    map.put(""String_Node_Str"",password);
    mailService.send(userEntity.getEmail(),mailUtils.getSubjectAccountUsername(),TemplateService.Template.ACCOUNT_USERNAME,map);
    mailService.send(userEntity.getEmail(),mailUtils.getSubjectAccountPassword(),TemplateService.Template.ACCOUNT_PASSWORD,map);
    LOGGER.info(""String_Node_Str"" + userEntity.getUsername() + ""String_Node_Str"");
  }
  return UserConversionUtil.toUserInfo(userEntity);
}"
37740,"private void handleIslEvent(IslInfoData isl,Tuple tuple,String correlationId){
  logger.debug(""String_Node_Str"",isl.getId(),isl.getState());
  Set<ImmutablePair<Flow,Flow>> affectedFlows;
switch (isl.getState()) {
case DISCOVERED:
    if (networkCache.cacheContainsIsl(isl.getId())) {
      networkCache.updateIsl(isl);
    }
 else {
      networkCache.createIsl(isl);
    }
  break;
case FAILED:
case MOVED:
try {
  networkCache.deleteIsl(isl.getId());
}
 catch (CacheException exception) {
  logger.warn(""String_Node_Str"",exception.getErrorMessage(),exception.getErrorDescription());
}
affectedFlows=flowCache.getActiveFlowsWithAffectedPath(isl);
String reason=String.format(""String_Node_Str"",isl.getId());
emitRerouteCommands(affectedFlows,tuple,correlationId,FlowOperation.UPDATE,reason);
break;
case OTHER_UPDATE:
break;
case CACHED:
break;
default :
logger.warn(""String_Node_Str"");
break;
}
}","private void handleIslEvent(IslInfoData isl,Tuple tuple,String correlationId){
  logger.debug(""String_Node_Str"",isl.getId(),isl.getState());
  Set<ImmutablePair<Flow,Flow>> affectedFlows;
switch (isl.getState()) {
case DISCOVERED:
    if (networkCache.cacheContainsIsl(isl.getId())) {
      networkCache.updateIsl(isl);
    }
 else {
      if (networkCache.isSelfLoopedIsl(isl)) {
        logger.warn(""String_Node_Str"",isl);
      }
 else {
        networkCache.createIsl(isl);
      }
    }
  break;
case FAILED:
case MOVED:
try {
  networkCache.deleteIsl(isl.getId());
}
 catch (CacheException exception) {
  logger.warn(""String_Node_Str"",exception.getErrorMessage(),exception.getErrorDescription());
}
affectedFlows=flowCache.getActiveFlowsWithAffectedPath(isl);
String reason=String.format(""String_Node_Str"",isl.getId());
emitRerouteCommands(affectedFlows,tuple,correlationId,FlowOperation.UPDATE,reason);
break;
case OTHER_UPDATE:
break;
case CACHED:
break;
default :
logger.warn(""String_Node_Str"");
break;
}
}"
37741,"private void initNetwork(){
  logger.info(""String_Node_Str"");
  Set<SwitchInfoData> switches=new HashSet<>(pathComputer.getSwitches());
  Set<IslInfoData> links=new HashSet<>(pathComputer.getIsls());
  logger.info(""String_Node_Str"",switches.size());
  logger.info(""String_Node_Str"",links.size());
  switches.forEach(networkCache::createOrUpdateSwitch);
  for (  IslInfoData isl : links) {
    try {
      networkCache.createOrUpdateIsl(isl);
    }
 catch (    Exception e) {
      logger.error(""String_Node_Str"",isl,e);
    }
  }
  logger.info(""String_Node_Str"");
}","private void initNetwork(){
  logger.info(""String_Node_Str"");
  Set<SwitchInfoData> switches=new HashSet<>(pathComputer.getSwitches());
  Set<IslInfoData> links=new HashSet<>(pathComputer.getIsls());
  logger.info(""String_Node_Str"",switches.size());
  logger.info(""String_Node_Str"",links.size());
  switches.forEach(networkCache::createOrUpdateSwitch);
  for (  IslInfoData isl : links) {
    try {
      if (networkCache.isSelfLoopedIsl(isl)) {
        logger.warn(""String_Node_Str"",isl);
      }
 else {
        networkCache.createOrUpdateIsl(isl);
      }
    }
 catch (    Exception e) {
      logger.error(""String_Node_Str"",isl,e);
    }
  }
  logger.info(""String_Node_Str"");
}"
37742,"/** 
 * Gets the switch ports.
 * @return the switch ports
 * @throws IntegrationException
 */
public List<PortInfo> getSwitchPorts(final String switchId) throws IntegrationException {
  HttpResponse response=null;
  try {
    if (RestClientManager.isValidResponse(response)) {
      String responseEntity=IoUtil.toString(response.getEntity().getContent());
      JSONObject jsonObject=JsonUtil.toObject(responseEntity,JSONObject.class);
      return PortConverter.toPortsInfo(jsonObject,switchId);
    }
  }
 catch (  IOException exception) {
    LOGGER.error(""String_Node_Str"" + exception.getMessage(),exception);
    throw new IntegrationException(exception);
  }
  return null;
}","/** 
 * Gets the switch ports.
 * @return the switch ports
 * @throws IntegrationException
 */
public List<PortInfo> getSwitchPorts(final String switchId) throws IntegrationException {
  HttpResponse response=null;
  try {
    if (response != null && RestClientManager.isValidResponse(response)) {
      String responseEntity=IoUtil.toString(response.getEntity().getContent());
      JSONObject jsonObject=JsonUtil.toObject(responseEntity,JSONObject.class);
      return PortConverter.toPortsInfo(jsonObject,switchId);
    }
  }
 catch (  IOException exception) {
    LOGGER.error(""String_Node_Str"" + exception.getMessage(),exception);
    throw new IntegrationException(exception);
  }
  return null;
}"
37743,"/** 
 * Gets the isl link cost.
 * @return the isl link cost
 */
public List<LinkProps> getIslLinkProps(LinkProps keys){
  UriComponentsBuilder builder=UriComponentsBuilder.fromHttpUrl(applicationProperties.getLinkProps());
  builder=setLinkProps(keys,builder);
  String fullUri=builder.build().toUriString();
  HttpResponse response=restClientManager.invoke(fullUri,HttpMethod.GET,""String_Node_Str"",""String_Node_Str"",applicationService.getAuthHeader());
  if (RestClientManager.isValidResponse(response)) {
    List<LinkProps> linkPropsResponses=restClientManager.getResponseList(response,LinkProps.class);
    if (CollectionUtil.isEmpty(linkPropsResponses)) {
      throw new ContentNotFoundException();
    }
 else {
      return linkPropsResponses;
    }
  }
  return null;
}","/** 
 * Gets the isl link cost.
 * @return the isl link cost
 */
public List<LinkProps> getIslLinkProps(LinkProps keys){
  UriComponentsBuilder builder=UriComponentsBuilder.fromHttpUrl(applicationProperties.getLinkProps());
  builder=setLinkProps(keys,builder);
  String fullUri=builder.build().toUriString();
  HttpResponse response=restClientManager.invoke(fullUri,HttpMethod.GET,""String_Node_Str"",""String_Node_Str"",applicationService.getAuthHeader());
  if (RestClientManager.isValidResponse(response)) {
    List<LinkProps> linkPropsResponses=restClientManager.getResponseList(response,LinkProps.class);
    if (!CollectionUtil.isEmpty(linkPropsResponses)) {
      return linkPropsResponses;
    }
  }
  return null;
}"
37744,"private Map<String,String> islCostMap(){
  List<LinkProps> linkProps=getIslLinkProps(null);
  Map<String,String> islCostMap=new HashMap<>();
  linkProps.forEach(linkProp -> {
    String key=linkProp.getSrc_switch() + ""String_Node_Str"" + linkProp.getSrc_port()+ ""String_Node_Str""+ linkProp.getDst_switch()+ ""String_Node_Str""+ linkProp.getDst_port();
    String value=linkProp.getProperty(""String_Node_Str"");
    islCostMap.put(key,value);
  }
);
  return islCostMap;
}","private Map<String,String> islCostMap(){
  List<LinkProps> linkProps=getIslLinkProps(null);
  Map<String,String> islCostMap=new HashMap<>();
  if (linkProps != null) {
    linkProps.forEach(linkProp -> {
      String key=linkProp.getSrc_switch() + ""String_Node_Str"" + linkProp.getSrc_port()+ ""String_Node_Str""+ linkProp.getDst_switch()+ ""String_Node_Str""+ linkProp.getDst_port();
      String value=linkProp.getProperty(""String_Node_Str"");
      islCostMap.put(key,value);
    }
);
  }
  return islCostMap;
}"
37745,"@Get(""String_Node_Str"") @SuppressWarnings(""String_Node_Str"") public Map<Long,Object> getMeters(){
  Map<Long,Object> response=new HashMap<>();
  String switchId=(String)this.getRequestAttributes().get(""String_Node_Str"");
  logger.debug(""String_Node_Str"",switchId);
  ISwitchManager switchManager=(ISwitchManager)getContext().getAttributes().get(ISwitchManager.class.getCanonicalName());
  try {
    OFMeterConfigStatsReply replay=switchManager.dumpMeters(DatapathId.of(switchId));
    logger.debug(""String_Node_Str"",switchId,replay);
    if (replay != null) {
      for (      OFMeterConfig entry : replay.getEntries()) {
        response.put(entry.getMeterId(),entry);
      }
    }
  }
 catch (  UnsupportedSwitchOperationException ex) {
    String messageString=""String_Node_Str"";
    logger.error(""String_Node_Str"",messageString,switchId,ex);
    MessageError responseMessage=new MessageError(DEFAULT_CORRELATION_ID,System.currentTimeMillis(),ErrorType.PARAMETERS_INVALID.toString(),messageString,ex.getMessage());
    response.putAll(MAPPER.convertValue(responseMessage,Map.class));
    getResponse().setStatus(Status.SERVER_ERROR_NOT_IMPLEMENTED);
  }
catch (  IllegalArgumentException|SwitchOperationException exception) {
    String messageString=""String_Node_Str"";
    logger.error(""String_Node_Str"",messageString,switchId,exception);
    MessageError responseMessage=new MessageError(CorrelationContext.getId(),System.currentTimeMillis(),ErrorType.PARAMETERS_INVALID.toString(),messageString,exception.getMessage());
    response.putAll(MAPPER.convertValue(responseMessage,Map.class));
    getResponse().setStatus(Status.CLIENT_ERROR_NOT_FOUND);
  }
  return response;
}","@Get(""String_Node_Str"") @SuppressWarnings(""String_Node_Str"") public Map<Long,Object> getMeters(){
  Map<Long,Object> response=new HashMap<>();
  String switchId=(String)this.getRequestAttributes().get(""String_Node_Str"");
  logger.debug(""String_Node_Str"",switchId);
  ISwitchManager switchManager=(ISwitchManager)getContext().getAttributes().get(ISwitchManager.class.getCanonicalName());
  try {
    OFMeterConfigStatsReply replay=switchManager.dumpMeters(DatapathId.of(switchId));
    logger.debug(""String_Node_Str"",switchId,replay);
    if (replay != null) {
      for (      OFMeterConfig entry : replay.getEntries()) {
        response.put(entry.getMeterId(),entry);
      }
    }
  }
 catch (  UnsupportedSwitchOperationException ex) {
    String messageString=""String_Node_Str"";
    logger.error(""String_Node_Str"",messageString,switchId,ex);
    MessageError responseMessage=new MessageError(CorrelationContext.getId(),System.currentTimeMillis(),ErrorType.PARAMETERS_INVALID.toString(),messageString,ex.getMessage());
    response.putAll(MAPPER.convertValue(responseMessage,Map.class));
    getResponse().setStatus(Status.SERVER_ERROR_NOT_IMPLEMENTED);
  }
catch (  IllegalArgumentException|SwitchOperationException exception) {
    String messageString=""String_Node_Str"";
    logger.error(""String_Node_Str"",messageString,switchId,exception);
    MessageError responseMessage=new MessageError(CorrelationContext.getId(),System.currentTimeMillis(),ErrorType.PARAMETERS_INVALID.toString(),messageString,exception.getMessage());
    response.putAll(MAPPER.convertValue(responseMessage,Map.class));
    getResponse().setStatus(Status.CLIENT_ERROR_NOT_FOUND);
  }
  return response;
}"
37746,"public IslInfoData(@JsonProperty(""String_Node_Str"") List<PathNode> path,@JsonProperty(""String_Node_Str"") IslChangeType state){
  this.path=path;
  this.state=state;
  this.id=String.format(""String_Node_Str"",path.get(0).getSwitchId(),String.valueOf(path.get(0).getPortNo()));
}","/** 
 * Simple constructor for an ISL with only path and state.
 * @param path path of ISL.
 * @param state current state.
 */
public IslInfoData(@JsonProperty(""String_Node_Str"") List<PathNode> path,@JsonProperty(""String_Node_Str"") IslChangeType state){
  this.path=path;
  this.state=state;
  this.id=String.format(""String_Node_Str"",path.get(0).getSwitchId(),String.valueOf(path.get(0).getPortNo()));
}"
37747,"@JsonCreator public DiscoveryLink(@JsonProperty(""String_Node_Str"") final String srcSwitch,@JsonProperty(""String_Node_Str"") final int srcPort,@JsonProperty(""String_Node_Str"") final String dstSwitch,@JsonProperty(""String_Node_Str"") final int dstPort,@JsonProperty(""String_Node_Str"") final int attempts,@JsonProperty(""String_Node_Str"") final int timeCounter,@JsonProperty(""String_Node_Str"") final int checkInterval,@JsonProperty(""String_Node_Str"") final int consecutiveFailure,@JsonProperty(""String_Node_Str"") final int consecutiveSuccess,@JsonProperty(""String_Node_Str"") final int maxAttempts){
  this.srcEndpoint=new NetworkEndpoint(srcSwitch,srcPort);
  this.dstEndpoint=new NetworkEndpoint(dstSwitch,dstPort);
  this.attempts=attempts;
  this.timeCounter=timeCounter;
  this.checkInterval=checkInterval;
  this.maxAttempts=maxAttempts;
  this.consecutiveFailure=consecutiveFailure;
  this.consecutiveSuccess=consecutiveSuccess;
}","/** 
 * Main constructor using for deserialization by jackson.
 */
@JsonCreator public DiscoveryLink(@JsonProperty(""String_Node_Str"") final String srcSwitch,@JsonProperty(""String_Node_Str"") final int srcPort,@JsonProperty(""String_Node_Str"") final String dstSwitch,@JsonProperty(""String_Node_Str"") final int dstPort,@JsonProperty(""String_Node_Str"") final int attempts,@JsonProperty(""String_Node_Str"") final int timeCounter,@JsonProperty(""String_Node_Str"") final int checkInterval,@JsonProperty(""String_Node_Str"") final int consecutiveFailure,@JsonProperty(""String_Node_Str"") final int consecutiveSuccess,@JsonProperty(""String_Node_Str"") final int maxAttempts,@JsonProperty(""String_Node_Str"") final boolean active){
  this.srcEndpoint=new NetworkEndpoint(srcSwitch,srcPort);
  this.dstEndpoint=new NetworkEndpoint(dstSwitch,dstPort);
  this.attempts=attempts;
  this.timeCounter=timeCounter;
  this.checkInterval=checkInterval;
  this.maxAttempts=maxAttempts;
  this.consecutiveFailure=consecutiveFailure;
  this.consecutiveSuccess=consecutiveSuccess;
  this.active=active;
}"
37748,"/** 
 * @return true if link should be excluded from discovery plan and discovery packets should not be sent.
 */
public boolean isExcludedFromDiscovery(){
  if (maxAttempts == ENDLESS_ATTEMPTS) {
    return false;
  }
  return consecutiveFailure > maxAttempts;
}","/** 
 * Checks if ISL should be excluded from discovery.
 * @return true if link should be excluded from discovery plan and discovery packets should not be sent.
 */
public boolean isExcludedFromDiscovery(){
  if (maxAttempts == ENDLESS_ATTEMPTS) {
    return false;
  }
  return consecutiveFailure > maxAttempts;
}"
37749,"/** 
 * @return true if attempts is greater than attemptLimit.
 */
public boolean maxAttempts(Integer attemptLimit){
  return attemptLimit < attempts;
}","/** 
 * Check if we should stop to verify ISL.
 * @return true if attempts is greater than attemptLimit.
 */
public boolean maxAttempts(Integer attemptLimit){
  return attemptLimit < attempts;
}"
37750,"public boolean isDestinationChanged(String dstSwitch,int dstPort){
  if (this.dstEndpoint == null) {
    return false;
  }
  return !Objects.equals(this.dstEndpoint,new NetworkEndpoint(dstSwitch,dstPort));
}","/** 
 * Checks whether destination switch/port of that link differs.
 * @param dstSwitch destination switch.
 * @param dstPort destination port.
 * @return true if destination changed.
 */
public boolean isDestinationChanged(String dstSwitch,int dstPort){
  if (this.dstEndpoint == null) {
    return false;
  }
  return !Objects.equals(this.dstEndpoint,new NetworkEndpoint(dstSwitch,dstPort));
}"
37751,"@Override public boolean equals(Object obj){
  if (this == obj)   return true;
  if (obj == null)   return false;
  if (getClass() != obj.getClass())   return false;
  IslLinkInfo other=(IslLinkInfo)obj;
  if (dstPort != other.dstPort && dstPort != other.srcPort)   return false;
  if (dstSwitch == null) {
    if (other.dstSwitch != null && other.srcSwitch != null)     return false;
  }
 else   if (!dstSwitch.equals(other.dstSwitch) && !dstSwitch.equals(other.srcSwitch))   return false;
  if (srcPort != other.srcPort && srcPort != other.dstPort)   return false;
  if (srcSwitch == null) {
    if (other.srcSwitch != null && other.dstSwitch != null)     return false;
  }
 else   if (!srcSwitch.equals(other.srcSwitch) && !srcSwitch.equals(other.dstSwitch))   return false;
  return true;
}","@Override public boolean equals(Object obj){
  if (this == obj)   return true;
  if (obj == null)   return false;
  if (getClass() != obj.getClass())   return false;
  IslLinkInfo other=(IslLinkInfo)obj;
  if (dstSwitch.equals(other.srcSwitch) && srcPort == other.dstPort && srcSwitch.equals(other.dstSwitch) && dstPort == other.srcPort) {
    return true;
  }
 else {
    return false;
  }
}"
37752,"@JsonCreator public DiscoveryFilterEntity(@JsonProperty(""String_Node_Str"") String switchId,@JsonProperty(""String_Node_Str"") String portId){
  this.switchId=switchId;
  this.portId=portId;
}","@JsonCreator public DiscoveryFilterEntity(@JsonProperty(""String_Node_Str"") String switchId,@JsonProperty(""String_Node_Str"") int portId){
  this.switchId=switchId;
  this.portId=portId;
}"
37753,"@JsonCreator public OFELinkBoltState(@JsonProperty(""String_Node_Str"") List<DiscoveryNode> discovery,@JsonProperty(""String_Node_Str"") Set<?> filtered){
  this.discovery=discovery;
  this.filtered=filtered;
}","@JsonCreator public OFELinkBoltState(@JsonProperty(""String_Node_Str"") List<DiscoveryLink> discovery,@JsonProperty(""String_Node_Str"") Set<?> filtered){
  this.discovery=discovery;
  this.filtered=filtered;
}"
37754,"public static String createIslFail(String switchId,String portId) throws IOException {
  PathNode node=new PathNode(switchId,Integer.parseInt(portId),0,0L);
  InfoData data=new IslInfoData(0L,Collections.singletonList(node),0L,IslChangeType.FAILED,0L);
  InfoMessage message=new InfoMessage(data,System.currentTimeMillis(),UUID.randomUUID().toString());
  return MAPPER.writeValueAsString(message);
}","public static String createIslFail(String switchId,int portId) throws IOException {
  PathNode node=new PathNode(switchId,portId,0,0L);
  InfoData data=new IslInfoData(0L,Collections.singletonList(node),0L,IslChangeType.FAILED,0L);
  InfoMessage message=new InfoMessage(data,System.currentTimeMillis(),UUID.randomUUID().toString());
  return MAPPER.writeValueAsString(message);
}"
37755,"/** 
 * @return a JSON string that can be used to for link event
 */
public static String createIslDiscovery(String switchID,String portID) throws IOException {
  CommandMessage message=new CommandMessage(new DiscoverIslCommandData(switchID,Integer.valueOf(portID)),System.currentTimeMillis(),""String_Node_Str"",Destination.CONTROLLER);
  return MAPPER.writeValueAsString(message);
}","/** 
 * @return a JSON string that can be used to for link event
 */
public static String createIslDiscovery(String switchId,int portId) throws IOException {
  CommandMessage message=new CommandMessage(new DiscoverIslCommandData(switchId,portId),System.currentTimeMillis(),""String_Node_Str"",Destination.CONTROLLER);
  return MAPPER.writeValueAsString(message);
}"
37756,"/** 
 * {@inheritDoc}
 */
@Override public ImmutablePair<PathInfoData,PathInfoData> getPath(Flow flow,Strategy strategy) throws UnroutablePathException, RecoverableException {
  long latency=0L;
  List<PathNode> forwardNodes=new LinkedList<>();
  List<PathNode> reverseNodes=new LinkedList<>();
  if (!flow.isOneSwitchFlow()) {
    try {
      Pair<LinkedList<SimpleIsl>,LinkedList<SimpleIsl>> biPath=getPathFromNetwork(flow,strategy);
      if (biPath.getLeft().size() == 0 || biPath.getRight().size() == 0)       throw new UnroutablePathException(flow);
      int seqId=0;
      LinkedList<SimpleIsl> forwardIsl=biPath.getLeft();
      for (      SimpleIsl isl : forwardIsl) {
        latency+=isl.latency;
        forwardNodes.add(new PathNode(isl.src_dpid,isl.src_port,seqId++,(long)isl.latency));
        forwardNodes.add(new PathNode(isl.dst_dpid,isl.dst_port,seqId++,0L));
      }
      seqId=0;
      LinkedList<SimpleIsl> reverseIsl=biPath.getLeft();
      for (      SimpleIsl isl : reverseIsl) {
        reverseNodes.add(new PathNode(isl.src_dpid,isl.src_port,seqId++,(long)isl.latency));
        reverseNodes.add(new PathNode(isl.dst_dpid,isl.dst_port,seqId++,0L));
      }
    }
 catch (    TransientException e) {
      throw new RecoverableException(""String_Node_Str"",e);
    }
catch (    ClientException e) {
      throw new RecoverableException(""String_Node_Str"",e);
    }
  }
 else {
    logger.info(""String_Node_Str"");
  }
  return new ImmutablePair<>(new PathInfoData(latency,forwardNodes),new PathInfoData(latency,reverseNodes));
}","/** 
 * {@inheritDoc}
 */
@Override public ImmutablePair<PathInfoData,PathInfoData> getPath(Flow flow,Strategy strategy) throws UnroutablePathException, RecoverableException {
  long latency=0L;
  List<PathNode> forwardNodes=new LinkedList<>();
  List<PathNode> reverseNodes=new LinkedList<>();
  if (!flow.isOneSwitchFlow()) {
    try {
      Pair<LinkedList<SimpleIsl>,LinkedList<SimpleIsl>> biPath=getPathFromNetwork(flow,strategy);
      if (biPath.getLeft().size() == 0 || biPath.getRight().size() == 0)       throw new UnroutablePathException(flow);
      int seqId=0;
      LinkedList<SimpleIsl> forwardIsl=biPath.getLeft();
      for (      SimpleIsl isl : forwardIsl) {
        latency+=isl.latency;
        forwardNodes.add(new PathNode(isl.src_dpid,isl.src_port,seqId++,(long)isl.latency));
        forwardNodes.add(new PathNode(isl.dst_dpid,isl.dst_port,seqId++,0L));
      }
      seqId=0;
      LinkedList<SimpleIsl> reverseIsl=biPath.getRight();
      for (      SimpleIsl isl : reverseIsl) {
        reverseNodes.add(new PathNode(isl.src_dpid,isl.src_port,seqId++,(long)isl.latency));
        reverseNodes.add(new PathNode(isl.dst_dpid,isl.dst_port,seqId++,0L));
      }
    }
 catch (    TransientException e) {
      throw new RecoverableException(""String_Node_Str"",e);
    }
catch (    ClientException e) {
      throw new RecoverableException(""String_Node_Str"",e);
    }
  }
 else {
    logger.info(""String_Node_Str"");
  }
  return new ImmutablePair<>(new PathInfoData(latency,forwardNodes),new PathInfoData(latency,reverseNodes));
}"
37757,"/** 
 * Dumps all flows. Dumps all flows with specific status if specified.
 * @return list of flow
 */
@ApiOperation(value=""String_Node_Str"",response=FlowPayload.class) @ApiResponse(code=200,response=FlowPayload.class,responseContainer=""String_Node_Str"",message=""String_Node_Str"") @RequestMapping(value=""String_Node_Str"",method=RequestMethod.GET,produces=MediaType.APPLICATION_JSON_UTF8_VALUE) public ResponseEntity<List<FlowPayload>> getFlows(){
  List<FlowPayload> response=flowService.getFlows();
  return new ResponseEntity<>(response,new HttpHeaders(),HttpStatus.OK);
}","/** 
 * Dumps all flows. Dumps all flows with specific status if specified.
 * @return list of flow
 */
@ApiOperation(value=""String_Node_Str"",response=FlowPayload.class,responseContainer=""String_Node_Str"") @ApiResponse(code=200,response=FlowPayload.class,responseContainer=""String_Node_Str"",message=""String_Node_Str"") @RequestMapping(value=""String_Node_Str"",method=RequestMethod.GET,produces=MediaType.APPLICATION_JSON_UTF8_VALUE) public ResponseEntity<List<FlowPayload>> getFlows(){
  List<FlowPayload> response=flowService.getFlows();
  return new ResponseEntity<>(response,new HttpHeaders(),HttpStatus.OK);
}"
37758,"/** 
 * Delete all flows.
 * @return list of flows that have been deleted
 */
@ApiOperation(value=""String_Node_Str"",response=FlowPayload.class) @ApiResponse(code=200,response=FlowPayload.class,responseContainer=""String_Node_Str"",message=""String_Node_Str"") @RequestMapping(value=""String_Node_Str"",method=RequestMethod.DELETE,produces=MediaType.APPLICATION_JSON_UTF8_VALUE) @ExtraAuthRequired @SuppressWarnings(""String_Node_Str"") public ResponseEntity<List<FlowPayload>> deleteFlows(@RequestHeader(value=EXTRA_AUTH,defaultValue=""String_Node_Str"") long extra_auth){
  long current_auth=System.currentTimeMillis();
  if (Math.abs(current_auth - extra_auth) > 120 * 1000) {
    return new ResponseEntity(""String_Node_Str"" + current_auth,new HttpHeaders(),HttpStatus.UNAUTHORIZED);
  }
  List<FlowPayload> response=flowService.deleteFlows();
  return new ResponseEntity<>(response,new HttpHeaders(),HttpStatus.OK);
}","/** 
 * Delete all flows.
 * @return list of flows that have been deleted
 */
@ApiOperation(value=""String_Node_Str"",response=FlowPayload.class,responseContainer=""String_Node_Str"") @ApiResponse(code=200,response=FlowPayload.class,responseContainer=""String_Node_Str"",message=""String_Node_Str"") @RequestMapping(value=""String_Node_Str"",method=RequestMethod.DELETE,produces=MediaType.APPLICATION_JSON_UTF8_VALUE) @ExtraAuthRequired @SuppressWarnings(""String_Node_Str"") public ResponseEntity<List<FlowPayload>> deleteFlows(@RequestHeader(value=EXTRA_AUTH,defaultValue=""String_Node_Str"") long extra_auth){
  long current_auth=System.currentTimeMillis();
  if (Math.abs(current_auth - extra_auth) > 120 * 1000) {
    return new ResponseEntity(""String_Node_Str"" + current_auth,new HttpHeaders(),HttpStatus.UNAUTHORIZED);
  }
  List<FlowPayload> response=flowService.deleteFlows();
  return new ResponseEntity<>(response,new HttpHeaders(),HttpStatus.OK);
}"
37759,"/** 
 * Compares the Flow from the DB to what is on each switch.
 * @param flowId id of flow to be rerouted.
 * @return flow payload with updated path.
 */
@ApiOperation(value=""String_Node_Str"",response=FlowValidationDto.class,responseContainer=""String_Node_Str"") @ApiResponses(value={@ApiResponse(code=200,response=FlowValidationDto.class,message=""String_Node_Str"")}) @RequestMapping(path=""String_Node_Str"",method=RequestMethod.GET) @ResponseStatus(HttpStatus.OK) public ResponseEntity<List<FlowValidationDto>> validateFlow(@PathVariable(""String_Node_Str"") String flowId){
  logger.debug(""String_Node_Str"",flowId);
  ResponseEntity<List<FlowValidationDto>> response;
  try {
    List<FlowValidationDto> result=flowService.validateFlow(flowId);
    if (result == null) {
      logger.info(""String_Node_Str"",flowId);
      response=ResponseEntity.notFound().build();
    }
 else {
      response=ResponseEntity.ok(result);
    }
  }
 catch (  InvalidPathException e) {
    logger.error(""String_Node_Str"",flowId);
    logger.error(e.getMessage());
    response=ResponseEntity.notFound().build();
  }
  return response;
}","/** 
 * Compares the Flow from the DB to what is on each switch.
 * @param flowId id of flow to be rerouted.
 * @return flow payload with updated path.
 */
@ApiOperation(value=""String_Node_Str"",response=FlowValidationDto.class,responseContainer=""String_Node_Str"") @ApiResponses(value={@ApiResponse(code=200,response=FlowValidationDto.class,responseContainer=""String_Node_Str"",message=""String_Node_Str"")}) @RequestMapping(path=""String_Node_Str"",method=RequestMethod.GET) @ResponseStatus(HttpStatus.OK) public ResponseEntity<List<FlowValidationDto>> validateFlow(@PathVariable(""String_Node_Str"") String flowId){
  logger.debug(""String_Node_Str"",flowId);
  ResponseEntity<List<FlowValidationDto>> response;
  try {
    List<FlowValidationDto> result=flowService.validateFlow(flowId);
    if (result == null) {
      logger.info(""String_Node_Str"",flowId);
      response=ResponseEntity.notFound().build();
    }
 else {
      response=ResponseEntity.ok(result);
    }
  }
 catch (  InvalidPathException e) {
    logger.error(""String_Node_Str"",flowId);
    logger.error(e.getMessage());
    response=ResponseEntity.notFound().build();
  }
  return response;
}"
37760,"/** 
 * Get all available links.
 * @return list of links.
 */
@ApiOperation(value=""String_Node_Str"",response=LinksDto.class) @ApiResponses(value={@ApiResponse(code=200,response=LinksDto.class,message=""String_Node_Str""),@ApiResponse(code=400,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=401,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=403,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=404,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=500,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=503,response=MessageError.class,message=""String_Node_Str"")}) @GetMapping(path=""String_Node_Str"") @ResponseStatus(HttpStatus.OK) public List<LinksDto> getLinks(){
  return linkService.getLinks();
}","/** 
 * Get all available links.
 * @return list of links.
 */
@ApiOperation(value=""String_Node_Str"",response=LinksDto.class,responseContainer=""String_Node_Str"") @ApiResponse(code=200,response=LinksDto.class,responseContainer=""String_Node_Str"",message=""String_Node_Str"") @GetMapping(path=""String_Node_Str"") @ResponseStatus(HttpStatus.OK) public List<LinksDto> getLinks(){
  return linkService.getLinks();
}"
37761,"/** 
 * Delete link properties from the static link properties table.
 * @param keysAndProps if null, get all link props. Otherwise, the link props that much the primary keys.
 * @return list of link properties.
 */
@ApiOperation(value=""String_Node_Str"",response=LinkPropsResult.class) @ApiResponses(value={@ApiResponse(code=200,response=LinkPropsResult.class,message=""String_Node_Str""),@ApiResponse(code=400,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=401,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=403,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=404,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=500,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=503,response=MessageError.class,message=""String_Node_Str"")}) @RequestMapping(path=""String_Node_Str"",method=RequestMethod.DELETE,produces=MediaType.APPLICATION_JSON_UTF8_VALUE) @ResponseStatus(HttpStatus.OK) public LinkPropsResult delLinkProps(@RequestBody List<LinkPropsDto> keysAndProps){
  return linkService.delLinkProps(keysAndProps);
}","/** 
 * Delete link properties from the static link properties table.
 * @param keysAndProps if null, get all link props. Otherwise, the link props that much the primary keys.
 * @return list of link properties.
 */
@ApiOperation(value=""String_Node_Str"",response=LinkPropsResult.class) @ApiResponse(code=200,response=LinkPropsResult.class,message=""String_Node_Str"") @RequestMapping(path=""String_Node_Str"",method=RequestMethod.DELETE,produces=MediaType.APPLICATION_JSON_UTF8_VALUE) @ResponseStatus(HttpStatus.OK) public LinkPropsResult delLinkProps(@RequestBody List<LinkPropsDto> keysAndProps){
  return linkService.delLinkProps(keysAndProps);
}"
37762,"/** 
 * Create/Update link properties in the static link properties table.
 * @param keysAndProps if null, get all link props. Otherwise, the link props that much the primary keys.
 * @return list of link properties.
 */
@ApiOperation(value=""String_Node_Str"",response=LinkPropsResult.class) @ApiResponses(value={@ApiResponse(code=200,response=LinkPropsResult.class,message=""String_Node_Str""),@ApiResponse(code=400,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=401,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=403,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=404,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=500,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=503,response=MessageError.class,message=""String_Node_Str"")}) @RequestMapping(path=""String_Node_Str"",method=RequestMethod.PUT,produces=MediaType.APPLICATION_JSON_UTF8_VALUE) @ResponseStatus(HttpStatus.OK) public LinkPropsResult putLinkProps(@RequestBody List<LinkPropsDto> keysAndProps){
  return linkService.setLinkProps(keysAndProps);
}","/** 
 * Create/Update link properties in the static link properties table.
 * @param keysAndProps if null, get all link props. Otherwise, the link props that much the primary keys.
 * @return list of link properties.
 */
@ApiOperation(value=""String_Node_Str"",response=LinkPropsResult.class) @ApiResponse(code=200,response=LinkPropsResult.class,message=""String_Node_Str"") @RequestMapping(path=""String_Node_Str"",method=RequestMethod.PUT,produces=MediaType.APPLICATION_JSON_UTF8_VALUE) @ResponseStatus(HttpStatus.OK) public LinkPropsResult putLinkProps(@RequestBody List<LinkPropsDto> keysAndProps){
  return linkService.setLinkProps(keysAndProps);
}"
37763,"/** 
 * Get link properties from the static link properties table.
 * @param keys if null, get all link props. Otherwise, the link props that much the primary keys.
 * @return list of link properties.
 */
@ApiOperation(value=""String_Node_Str"",response=LinkPropsDto.class) @ApiResponses(value={@ApiResponse(code=200,response=LinkPropsDto.class,message=""String_Node_Str""),@ApiResponse(code=400,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=401,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=403,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=404,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=500,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=503,response=MessageError.class,message=""String_Node_Str"")}) @RequestMapping(path=""String_Node_Str"",method=RequestMethod.GET,produces=MediaType.APPLICATION_JSON_UTF8_VALUE) @ResponseStatus(HttpStatus.OK) public List<LinkPropsDto> getLinkProps(LinkPropsDto keys){
  return linkService.getLinkProps(keys);
}","/** 
 * Get link properties from the static link properties table.
 * @param keys if null, get all link props. Otherwise, the link props that much the primary keys.
 * @return list of link properties.
 */
@ApiOperation(value=""String_Node_Str"",response=LinkPropsDto.class,responseContainer=""String_Node_Str"") @ApiResponse(code=200,response=LinkPropsDto.class,responseContainer=""String_Node_Str"",message=""String_Node_Str"") @RequestMapping(path=""String_Node_Str"",method=RequestMethod.GET,produces=MediaType.APPLICATION_JSON_UTF8_VALUE) @ResponseStatus(HttpStatus.OK) public List<LinkPropsDto> getLinkProps(LinkPropsDto keys){
  return linkService.getLinkProps(keys);
}"
37764,"/** 
 * Delete switch rules.
 * @param switchId switch id to delete rules from
 * @param deleteAction defines what to do about the default rules
 * @param oneCookie the cookie to use if deleting one rule (could be any rule)
 * @return list of the cookies of the rules that have been deleted
 */
@ApiOperation(value=""String_Node_Str"",response=Long.class,responseContainer=""String_Node_Str"") @DeleteMapping(value=""String_Node_Str"",produces=MediaType.APPLICATION_JSON_UTF8_VALUE) @ExtraAuthRequired public ResponseEntity deleteSwitchRules(@PathVariable(""String_Node_Str"") String switchId,@ApiParam(value=""String_Node_Str"" + ""String_Node_Str"" + ""String_Node_Str"",required=false) @RequestParam(""String_Node_Str"") Optional<DeleteRulesAction> deleteAction,@RequestParam(""String_Node_Str"") Optional<Long> oneCookie){
  List<Long> response=switchService.deleteRules(switchId,deleteAction.orElse(DeleteRulesAction.IGNORE),oneCookie.orElse(0L));
  return ResponseEntity.ok(response);
}","/** 
 * Delete switch rules.
 * @param switchId switch id to delete rules from
 * @param deleteAction defines what to do about the default rules
 * @param oneCookie the cookie to use if deleting one rule (could be any rule)
 * @return list of the cookies of the rules that have been deleted
 */
@ApiOperation(value=""String_Node_Str"",response=Long.class,responseContainer=""String_Node_Str"") @ApiResponse(code=200,response=Long.class,responseContainer=""String_Node_Str"",message=""String_Node_Str"") @DeleteMapping(value=""String_Node_Str"",produces=MediaType.APPLICATION_JSON_UTF8_VALUE) @ExtraAuthRequired public ResponseEntity<List<Long>> deleteSwitchRules(@PathVariable(""String_Node_Str"") String switchId,@ApiParam(value=""String_Node_Str"" + ""String_Node_Str"" + ""String_Node_Str"",required=false) @RequestParam(""String_Node_Str"") Optional<DeleteRulesAction> deleteAction,@RequestParam(""String_Node_Str"") Optional<Long> oneCookie){
  List<Long> response=switchService.deleteRules(switchId,deleteAction.orElse(DeleteRulesAction.IGNORE),oneCookie.orElse(0L));
  return ResponseEntity.ok(response);
}"
37765,"/** 
 * Get switch rules.
 * @param switchId the switch
 * @param cookie filter the response based on this cookie
 * @return list of the cookies of the rules that have been deleted
 */
@ApiOperation(value=""String_Node_Str"",response=Long.class,responseContainer=""String_Node_Str"") @GetMapping(value=""String_Node_Str"",produces=MediaType.APPLICATION_JSON_UTF8_VALUE) @ResponseStatus(HttpStatus.OK) public SwitchFlowEntries getSwitchRules(@PathVariable(""String_Node_Str"") String switchId,@ApiParam(value=""String_Node_Str"",required=false) @RequestParam(""String_Node_Str"") Optional<Long> cookie){
  SwitchFlowEntries response=switchService.getRules(switchId,cookie.orElse(0L));
  return response;
}","/** 
 * Get switch rules.
 * @param switchId the switch
 * @param cookie filter the response based on this cookie
 * @return list of the cookies of the rules that have been deleted
 */
@ApiOperation(value=""String_Node_Str"",response=SwitchFlowEntries.class) @ApiResponse(code=200,response=SwitchFlowEntries.class,message=""String_Node_Str"") @GetMapping(value=""String_Node_Str"",produces=MediaType.APPLICATION_JSON_UTF8_VALUE) @ResponseStatus(HttpStatus.OK) public SwitchFlowEntries getSwitchRules(@PathVariable(""String_Node_Str"") String switchId,@ApiParam(value=""String_Node_Str"",required=false) @RequestParam(""String_Node_Str"") Optional<Long> cookie){
  SwitchFlowEntries response=switchService.getRules(switchId,cookie.orElse(0L));
  return response;
}"
37766,"/** 
 * Get all available links.
 * @return list of links.
 */
@ApiOperation(value=""String_Node_Str"",response=SwitchDto.class) @GetMapping(path=""String_Node_Str"") @ResponseStatus(HttpStatus.OK) public List<SwitchDto> getSwitches(){
  return switchService.getSwitches();
}","/** 
 * Get all available links.
 * @return list of links.
 */
@ApiOperation(value=""String_Node_Str"",response=SwitchDto.class,responseContainer=""String_Node_Str"") @GetMapping(path=""String_Node_Str"") @ResponseStatus(HttpStatus.OK) public List<SwitchDto> getSwitches(){
  return switchService.getSwitches();
}"
37767,"/** 
 * Install switch rules.
 * @param switchId switch id to delete rules from
 * @param installAction defines what to do about the default rules
 * @return list of the cookies of the rules that have been installed
 */
@ApiOperation(value=""String_Node_Str"",response=String.class,responseContainer=""String_Node_Str"") @PutMapping(value=""String_Node_Str"",produces=MediaType.APPLICATION_JSON_UTF8_VALUE) @ExtraAuthRequired public ResponseEntity installSwitchRules(@PathVariable(""String_Node_Str"") String switchId,@ApiParam(value=""String_Node_Str"" + ""String_Node_Str"",required=false) @RequestParam(""String_Node_Str"") Optional<InstallRulesAction> installAction){
  List<Long> response=switchService.installRules(switchId,installAction.orElse(InstallRulesAction.INSTALL_DEFAULTS));
  return ResponseEntity.ok(response);
}","/** 
 * Install switch rules.
 * @param switchId switch id to delete rules from
 * @param installAction defines what to do about the default rules
 * @return list of the cookies of the rules that have been installed
 */
@ApiOperation(value=""String_Node_Str"",response=Long.class,responseContainer=""String_Node_Str"") @ApiResponse(code=200,response=Long.class,responseContainer=""String_Node_Str"",message=""String_Node_Str"") @PutMapping(value=""String_Node_Str"",produces=MediaType.APPLICATION_JSON_UTF8_VALUE) @ExtraAuthRequired public ResponseEntity<List<Long>> installSwitchRules(@PathVariable(""String_Node_Str"") String switchId,@ApiParam(value=""String_Node_Str"" + ""String_Node_Str"",required=false) @RequestParam(""String_Node_Str"") Optional<InstallRulesAction> installAction){
  List<Long> response=switchService.installRules(switchId,installAction.orElse(InstallRulesAction.INSTALL_DEFAULTS));
  return ResponseEntity.ok(response);
}"
37768,"/** 
 * Toggle the global behavior of Floodlight when the switch connects: - AUTO - this is the default. Installs all default rules when a switch connects - SAFE - add the default rules slowly .. monitoring traffic on existing rules - MANUAL - don't install any default rules. Call addRule for that. NOTE: no action is taking with existing, connected switches. This operation will only affect future connections
 * @param mode the connectMode to use. A Null value is a No-Op and can be used to return existing value.
 * @return the value of the toggle in Floodlight.
 */
@ApiOperation(value=""String_Node_Str"",response=ConnectModeRequest.Mode.class) @PutMapping(value=""String_Node_Str"",produces=MediaType.APPLICATION_JSON_UTF8_VALUE) public ResponseEntity toggleSwitchConnectMode(@RequestParam(""String_Node_Str"") ConnectModeRequest.Mode mode){
  ConnectModeRequest.Mode response=switchService.connectMode(mode);
  return ResponseEntity.ok(response);
}","/** 
 * Toggle the global behavior of Floodlight when the switch connects: - AUTO - this is the default. Installs all default rules when a switch connects - SAFE - add the default rules slowly .. monitoring traffic on existing rules - MANUAL - don't install any default rules. Call addRule for that. NOTE: no action is taking with existing, connected switches. This operation will only affect future connections
 * @param mode the connectMode to use. A Null value is a No-Op and can be used to return existing value.
 * @return the value of the toggle in Floodlight.
 */
@ApiOperation(value=""String_Node_Str"",response=ConnectModeRequest.Mode.class) @PutMapping(value=""String_Node_Str"",produces=MediaType.APPLICATION_JSON_UTF8_VALUE) public ResponseEntity<ConnectModeRequest.Mode> toggleSwitchConnectMode(@RequestParam(""String_Node_Str"") ConnectModeRequest.Mode mode){
  ConnectModeRequest.Mode response=switchService.connectMode(mode);
  return ResponseEntity.ok(response);
}"
37769,"/** 
 * @param switchId
 * @return the list of rules on switch, specified what actions were applied.
 */
@ApiOperation(value=""String_Node_Str"",response=SyncRulesOutput.class) @ApiResponses(value={@ApiResponse(code=200,response=FlowPayload.class,message=""String_Node_Str""),@ApiResponse(code=400,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=401,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=403,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=404,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=500,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=503,response=MessageError.class,message=""String_Node_Str"")}) @GetMapping(path=""String_Node_Str"") @ResponseStatus(HttpStatus.OK) public SyncRulesOutput syncRules(@PathVariable(name=""String_Node_Str"") String switchId){
  return switchService.syncRules(switchId);
}","/** 
 * @param switchId
 * @return the list of rules on switch, specified what actions were applied.
 */
@ApiOperation(value=""String_Node_Str"",response=SyncRulesOutput.class) @ApiResponse(code=200,response=SyncRulesOutput.class,message=""String_Node_Str"") @GetMapping(path=""String_Node_Str"") @ResponseStatus(HttpStatus.OK) public SyncRulesOutput syncRules(@PathVariable(name=""String_Node_Str"") String switchId){
  return switchService.syncRules(switchId);
}"
37770,"/** 
 * Checks a flow for endpoints' conflicts.
 * @param requestedFlow a flow to check
 * @throws FlowValidationException is thrown in a case when flow endpoints conflict with existing flows.
 */
public void checkFlowForEndpointConflicts(Flow requestedFlow) throws FlowValidationException {
  Set<Flow> conflictsOnSource;
  if (requestedFlow.getSourceVlan() == 0) {
    conflictsOnSource=flowCache.getFlowsForEndpoint(requestedFlow.getSourceSwitch(),requestedFlow.getSourcePort());
  }
 else {
    conflictsOnSource=flowCache.getFlowsForEndpoint(requestedFlow.getSourceSwitch(),requestedFlow.getSourcePort(),requestedFlow.getSourceVlan());
  }
  Optional<Flow> conflictedFlow=conflictsOnSource.stream().filter(flow -> !flow.getFlowId().equals(requestedFlow.getFlowId())).findAny();
  if (conflictedFlow.isPresent()) {
    throw new FlowValidationException(format(""String_Node_Str"",requestedFlow.getSourcePort(),requestedFlow.getSourceSwitch(),conflictedFlow.get().getFlowId()));
  }
  Set<Flow> conflictsOnDest;
  if (requestedFlow.getSourceVlan() == 0) {
    conflictsOnDest=flowCache.getFlowsForEndpoint(requestedFlow.getDestinationSwitch(),requestedFlow.getDestinationPort());
  }
 else {
    conflictsOnDest=flowCache.getFlowsForEndpoint(requestedFlow.getDestinationSwitch(),requestedFlow.getDestinationPort(),requestedFlow.getDestinationVlan());
  }
  conflictedFlow=conflictsOnDest.stream().filter(flow -> !flow.getFlowId().equals(requestedFlow.getFlowId())).findAny();
  if (conflictedFlow.isPresent()) {
    throw new FlowValidationException(format(""String_Node_Str"",requestedFlow.getDestinationPort(),requestedFlow.getDestinationSwitch(),conflictedFlow.get().getFlowId()));
  }
}","/** 
 * Checks a flow for endpoints' conflicts.
 * @param requestedFlow a flow to check
 * @throws FlowValidationException is thrown in a case when flow endpoints conflict with existing flows.
 */
public void checkFlowForEndpointConflicts(Flow requestedFlow) throws FlowValidationException {
  Set<Flow> conflictsOnSource;
  if (requestedFlow.getSourceVlan() == 0) {
    conflictsOnSource=flowCache.getFlowsForEndpoint(requestedFlow.getSourceSwitch(),requestedFlow.getSourcePort());
  }
 else {
    conflictsOnSource=flowCache.getFlowsForEndpoint(requestedFlow.getSourceSwitch(),requestedFlow.getSourcePort(),requestedFlow.getSourceVlan());
  }
  Optional<Flow> conflictedFlow=conflictsOnSource.stream().filter(flow -> !flow.getFlowId().equals(requestedFlow.getFlowId())).findAny();
  if (conflictedFlow.isPresent()) {
    throw new FlowValidationException(format(""String_Node_Str"",requestedFlow.getSourcePort(),requestedFlow.getSourceSwitch(),conflictedFlow.get().getFlowId()));
  }
  Set<Flow> conflictsOnDest;
  if (requestedFlow.getDestinationVlan() == 0) {
    conflictsOnDest=flowCache.getFlowsForEndpoint(requestedFlow.getDestinationSwitch(),requestedFlow.getDestinationPort());
  }
 else {
    conflictsOnDest=flowCache.getFlowsForEndpoint(requestedFlow.getDestinationSwitch(),requestedFlow.getDestinationPort(),requestedFlow.getDestinationVlan());
  }
  conflictedFlow=conflictsOnDest.stream().filter(flow -> !flow.getFlowId().equals(requestedFlow.getFlowId())).findAny();
  if (conflictedFlow.isPresent()) {
    throw new FlowValidationException(format(""String_Node_Str"",requestedFlow.getDestinationPort(),requestedFlow.getDestinationSwitch(),conflictedFlow.get().getFlowId()));
  }
}"
37771,"/** 
 * {@inheritDoc}
 */
@Override public ImmutablePair<PathInfoData,PathInfoData> getPath(Flow flow,Strategy strategy) throws UnroutablePathException {
  long latency=0L;
  List<PathNode> forwardNodes=new LinkedList<>();
  List<PathNode> reverseNodes=new LinkedList<>();
  if (!flow.isOneSwitchFlow()) {
    Statement statement=getPathQuery(flow,strategy);
    logger.debug(""String_Node_Str"",statement.toString());
    try (Session session=driver.session()){
      StatementResult result=session.run(statement);
      try {
        Record record=result.next();
        LinkedList<Relationship> isls=new LinkedList<>();
        record.get(0).asPath().relationships().forEach(isls::add);
        int seqId=0;
        for (        Relationship isl : isls) {
          latency+=isl.get(""String_Node_Str"").asLong();
          forwardNodes.add(new PathNode(isl.get(""String_Node_Str"").asString(),isl.get(""String_Node_Str"").asInt(),seqId,isl.get(""String_Node_Str"").asLong()));
          seqId++;
          forwardNodes.add(new PathNode(isl.get(""String_Node_Str"").asString(),isl.get(""String_Node_Str"").asInt(),seqId,0L));
          seqId++;
        }
        seqId=0;
        Collections.reverse(isls);
        for (        Relationship isl : isls) {
          reverseNodes.add(new PathNode(isl.get(""String_Node_Str"").asString(),isl.get(""String_Node_Str"").asInt(),seqId,isl.get(""String_Node_Str"").asLong()));
          seqId++;
          reverseNodes.add(new PathNode(isl.get(""String_Node_Str"").asString(),isl.get(""String_Node_Str"").asInt(),seqId,0L));
          seqId++;
        }
      }
 catch (      NoSuchRecordException e) {
        throw new UnroutablePathException(flow);
      }
    }
   }
 else {
    logger.info(""String_Node_Str"");
  }
  return new ImmutablePair<>(new PathInfoData(latency,forwardNodes),new PathInfoData(latency,reverseNodes));
}","/** 
 * {@inheritDoc}
 */
@Override public ImmutablePair<PathInfoData,PathInfoData> getPath(Flow flow,Strategy strategy) throws UnroutablePathException, RecoverableException {
  long latency=0L;
  List<PathNode> forwardNodes=new LinkedList<>();
  List<PathNode> reverseNodes=new LinkedList<>();
  if (!flow.isOneSwitchFlow()) {
    Statement statement=getPathQuery(flow,strategy);
    logger.info(""String_Node_Str"",statement.toString());
    try (Session session=driver.session()){
      StatementResult result=session.run(statement);
      Record record=result.next();
      LinkedList<Relationship> isls=new LinkedList<>();
      record.get(0).asPath().relationships().forEach(isls::add);
      int seqId=0;
      for (      Relationship isl : isls) {
        latency+=isl.get(""String_Node_Str"").asLong();
        forwardNodes.add(new PathNode(isl.get(""String_Node_Str"").asString(),isl.get(""String_Node_Str"").asInt(),seqId,isl.get(""String_Node_Str"").asLong()));
        seqId++;
        forwardNodes.add(new PathNode(isl.get(""String_Node_Str"").asString(),isl.get(""String_Node_Str"").asInt(),seqId,0L));
        seqId++;
      }
      seqId=0;
      Collections.reverse(isls);
      for (      Relationship isl : isls) {
        reverseNodes.add(new PathNode(isl.get(""String_Node_Str"").asString(),isl.get(""String_Node_Str"").asInt(),seqId,isl.get(""String_Node_Str"").asLong()));
        seqId++;
        reverseNodes.add(new PathNode(isl.get(""String_Node_Str"").asString(),isl.get(""String_Node_Str"").asInt(),seqId,0L));
        seqId++;
      }
    }
 catch (    TransientException e) {
      throw new RecoverableException(""String_Node_Str"",e);
    }
catch (    ClientException e) {
      throw new RecoverableException(""String_Node_Str"",e);
    }
catch (    NoSuchRecordException e) {
      throw new UnroutablePathException(flow);
    }
  }
 else {
    logger.info(""String_Node_Str"");
  }
  return new ImmutablePair<>(new PathInfoData(latency,forwardNodes),new PathInfoData(latency,reverseNodes));
}"
37772,"/** 
 * Gets path between source and destination switch.
 * @param flow {@link Flow} instances
 * @return {@link PathInfoData} instances
 */
ImmutablePair<PathInfoData,PathInfoData> getPath(Flow flow,Strategy strategy) throws UnroutablePathException ;","/** 
 * Gets path between source and destination switch.
 * @param flow {@link Flow} instances
 * @return {@link PathInfoData} instances
 */
ImmutablePair<PathInfoData,PathInfoData> getPath(Flow flow,Strategy strategy) throws UnroutablePathException, RecoverableException ;"
37773,"private void handleRerouteRequest(CommandMessage message,Tuple tuple) throws IOException {
  FlowRerouteRequest request=(FlowRerouteRequest)message.getData();
  Flow requestedFlow=request.getPayload();
  final String flowId=requestedFlow.getFlowId();
  ImmutablePair<Flow,Flow> flow;
  logger.warn(""String_Node_Str"",message.getCorrelationId());
switch (request.getOperation()) {
case UPDATE:
    flow=flowCache.getFlow(flowId);
  try {
    logger.warn(""String_Node_Str"",flowId,flow.getLeft().getFlowPath());
    ImmutablePair<PathInfoData,PathInfoData> path=pathComputer.getPath(flow.getLeft(),Strategy.COST);
    logger.warn(""String_Node_Str"",flowId,path.getLeft());
    boolean isFoundNewPath=false;
    if (!path.getLeft().equals(flow.getLeft().getFlowPath()) || !isFlowActive(flow)) {
      isFoundNewPath=true;
      flow.getLeft().setState(FlowState.DOWN);
      flow.getRight().setState(FlowState.DOWN);
      flow=flowCache.updateFlow(flow.getLeft(),path);
      logger.warn(""String_Node_Str"",flow);
      FlowInfoData data=new FlowInfoData(flowId,flow,UPDATE,message.getCorrelationId());
      InfoMessage infoMessage=new InfoMessage(data,System.currentTimeMillis(),message.getCorrelationId());
      Values topology=new Values(MAPPER.writeValueAsString(infoMessage));
      outputCollector.emit(StreamType.UPDATE.toString(),tuple,topology);
    }
 else {
      logger.warn(""String_Node_Str"");
    }
    logger.debug(""String_Node_Str"",message.getCorrelationId());
    FlowRerouteResponse response=new FlowRerouteResponse(flow.left.getFlowPath(),isFoundNewPath);
    Values values=new Values(new InfoMessage(response,message.getTimestamp(),message.getCorrelationId(),Destination.NORTHBOUND));
    outputCollector.emit(StreamType.RESPONSE.toString(),tuple,values);
  }
 catch (  UnroutablePathException e) {
    logger.warn(""String_Node_Str"",flowId);
    flow.getLeft().setState(FlowState.DOWN);
    flow.getRight().setState(FlowState.DOWN);
    throw new MessageException(message.getCorrelationId(),System.currentTimeMillis(),ErrorType.UPDATE_FAILURE,""String_Node_Str"",""String_Node_Str"");
  }
break;
case CREATE:
flow=flowCache.getFlow(flowId);
logger.warn(""String_Node_Str"",flow.getLeft().getFlowId(),FlowState.UP);
flow.getLeft().setState(FlowState.UP);
flow.getRight().setState(FlowState.UP);
break;
case DELETE:
flow=flowCache.getFlow(flowId);
logger.warn(""String_Node_Str"",flow.getLeft().getFlowId(),FlowState.DOWN);
flow.getLeft().setState(FlowState.DOWN);
flow.getRight().setState(FlowState.DOWN);
break;
default :
logger.warn(""String_Node_Str"",request.getOperation());
break;
}
}","private void handleRerouteRequest(CommandMessage message,Tuple tuple) throws IOException, RecoverableException {
  FlowRerouteRequest request=(FlowRerouteRequest)message.getData();
  Flow requestedFlow=request.getPayload();
  final String flowId=requestedFlow.getFlowId();
  ImmutablePair<Flow,Flow> flow;
  logger.warn(""String_Node_Str"",message.getCorrelationId());
switch (request.getOperation()) {
case UPDATE:
    flow=flowCache.getFlow(flowId);
  try {
    logger.warn(""String_Node_Str"",flowId,flow.getLeft().getFlowPath());
    ImmutablePair<PathInfoData,PathInfoData> path=pathComputer.getPath(flow.getLeft(),Strategy.COST);
    logger.warn(""String_Node_Str"",flowId,path.getLeft());
    boolean isFoundNewPath=false;
    if (!path.getLeft().equals(flow.getLeft().getFlowPath()) || !isFlowActive(flow)) {
      isFoundNewPath=true;
      flow.getLeft().setState(FlowState.DOWN);
      flow.getRight().setState(FlowState.DOWN);
      flow=flowCache.updateFlow(flow.getLeft(),path);
      logger.warn(""String_Node_Str"",flow);
      FlowInfoData data=new FlowInfoData(flowId,flow,UPDATE,message.getCorrelationId());
      InfoMessage infoMessage=new InfoMessage(data,System.currentTimeMillis(),message.getCorrelationId());
      Values topology=new Values(MAPPER.writeValueAsString(infoMessage));
      outputCollector.emit(StreamType.UPDATE.toString(),tuple,topology);
    }
 else {
      logger.warn(""String_Node_Str"");
    }
    logger.debug(""String_Node_Str"",message.getCorrelationId());
    FlowRerouteResponse response=new FlowRerouteResponse(flow.left.getFlowPath(),isFoundNewPath);
    Values values=new Values(new InfoMessage(response,message.getTimestamp(),message.getCorrelationId(),Destination.NORTHBOUND));
    outputCollector.emit(StreamType.RESPONSE.toString(),tuple,values);
  }
 catch (  UnroutablePathException e) {
    logger.warn(""String_Node_Str"",flowId);
    flow.getLeft().setState(FlowState.DOWN);
    flow.getRight().setState(FlowState.DOWN);
    throw new MessageException(message.getCorrelationId(),System.currentTimeMillis(),ErrorType.UPDATE_FAILURE,""String_Node_Str"",""String_Node_Str"");
  }
break;
case CREATE:
flow=flowCache.getFlow(flowId);
logger.warn(""String_Node_Str"",flow.getLeft().getFlowId(),FlowState.UP);
flow.getLeft().setState(FlowState.UP);
flow.getRight().setState(FlowState.UP);
break;
case DELETE:
flow=flowCache.getFlow(flowId);
logger.warn(""String_Node_Str"",flow.getLeft().getFlowId(),FlowState.DOWN);
flow.getLeft().setState(FlowState.DOWN);
flow.getRight().setState(FlowState.DOWN);
break;
default :
logger.warn(""String_Node_Str"",request.getOperation());
break;
}
}"
37774,"private void handleRestoreRequest(CommandMessage message,Tuple tuple) throws IOException {
  ImmutablePair<Flow,Flow> requestedFlow=((FlowRestoreRequest)message.getData()).getPayload();
  try {
    ImmutablePair<PathInfoData,PathInfoData> path=pathComputer.getPath(requestedFlow.getLeft(),Strategy.COST);
    logger.info(""String_Node_Str"",path);
    ImmutablePair<Flow,Flow> flow;
    if (flowCache.cacheContainsFlow(requestedFlow.getLeft().getFlowId())) {
      flow=flowCache.updateFlow(requestedFlow,path);
    }
 else {
      flow=flowCache.createFlow(requestedFlow,path);
    }
    logger.info(""String_Node_Str"",flow);
    Values topology=new Values(Utils.MAPPER.writeValueAsString(new FlowInfoData(requestedFlow.getLeft().getFlowId(),flow,UPDATE,message.getCorrelationId())));
    outputCollector.emit(StreamType.UPDATE.toString(),tuple,topology);
  }
 catch (  UnroutablePathException e) {
    throw new MessageException(message.getCorrelationId(),System.currentTimeMillis(),ErrorType.CREATION_FAILURE,""String_Node_Str"",""String_Node_Str"");
  }
}","private void handleRestoreRequest(CommandMessage message,Tuple tuple) throws IOException, RecoverableException {
  ImmutablePair<Flow,Flow> requestedFlow=((FlowRestoreRequest)message.getData()).getPayload();
  try {
    ImmutablePair<PathInfoData,PathInfoData> path=pathComputer.getPath(requestedFlow.getLeft(),Strategy.COST);
    logger.info(""String_Node_Str"",path);
    ImmutablePair<Flow,Flow> flow;
    if (flowCache.cacheContainsFlow(requestedFlow.getLeft().getFlowId())) {
      flow=flowCache.updateFlow(requestedFlow,path);
    }
 else {
      flow=flowCache.createFlow(requestedFlow,path);
    }
    logger.info(""String_Node_Str"",flow);
    Values topology=new Values(Utils.MAPPER.writeValueAsString(new FlowInfoData(requestedFlow.getLeft().getFlowId(),flow,UPDATE,message.getCorrelationId())));
    outputCollector.emit(StreamType.UPDATE.toString(),tuple,topology);
  }
 catch (  UnroutablePathException e) {
    throw new MessageException(message.getCorrelationId(),System.currentTimeMillis(),ErrorType.CREATION_FAILURE,""String_Node_Str"",""String_Node_Str"");
  }
}"
37775,"/** 
 * {@inheritDoc}
 */
@Override public void execute(Tuple tuple){
  if (CtrlAction.boltHandlerEntrance(this,tuple))   return;
  logger.trace(""String_Node_Str"",flowCache);
  ComponentType componentId=ComponentType.valueOf(tuple.getSourceComponent());
  String correlationId=Utils.DEFAULT_CORRELATION_ID;
  StreamType streamId=null;
  String flowId=null;
  if (!componentId.equals(ComponentType.LCM_FLOW_SYNC_BOLT)) {
    streamId=StreamType.valueOf(tuple.getSourceStreamId());
    flowId=tuple.getStringByField(Utils.FLOW_ID);
  }
  try {
    logger.debug(""String_Node_Str"",tuple);
switch (componentId) {
case SPLITTER_BOLT:
      Message msg=(Message)tuple.getValueByField(AbstractTopology.MESSAGE_FIELD);
    correlationId=msg.getCorrelationId();
  CommandMessage cmsg=(msg instanceof CommandMessage) ? (CommandMessage)msg : null;
InfoMessage imsg=(msg instanceof InfoMessage) ? (InfoMessage)msg : null;
logger.info(""String_Node_Str"",Utils.CORRELATION_ID,correlationId,Utils.FLOW_ID,flowId,componentId,streamId);
switch (streamId) {
case CREATE:
handleCreateRequest(cmsg,tuple);
break;
case UPDATE:
handleUpdateRequest(cmsg,tuple);
break;
case DELETE:
handleDeleteRequest(flowId,cmsg,tuple);
break;
case PUSH:
handlePushRequest(flowId,imsg,tuple);
break;
case UNPUSH:
handleUnpushRequest(flowId,imsg,tuple);
break;
case PATH:
handlePathRequest(flowId,cmsg,tuple);
break;
case RESTORE:
handleRestoreRequest(cmsg,tuple);
break;
case REROUTE:
handleRerouteRequest(cmsg,tuple);
break;
case STATUS:
handleStatusRequest(flowId,cmsg,tuple);
break;
case CACHE_SYNC:
handleCacheSyncRequest(cmsg,tuple);
break;
case READ:
if (flowId != null) {
handleReadRequest(flowId,cmsg,tuple);
}
 else {
handleDumpRequest(cmsg,tuple);
}
break;
default :
logger.debug(""String_Node_Str"",componentId,streamId);
break;
}
break;
case SPEAKER_BOLT:
case TRANSACTION_BOLT:
FlowState newStatus=(FlowState)tuple.getValueByField(FlowTopology.STATUS_FIELD);
logger.info(""String_Node_Str"",flowId,newStatus,componentId,streamId);
switch (streamId) {
case STATUS:
handleStateRequest(flowId,newStatus,tuple);
break;
default :
logger.debug(""String_Node_Str"",componentId,streamId);
break;
}
break;
case TOPOLOGY_ENGINE_BOLT:
ErrorMessage errorMessage=(ErrorMessage)tuple.getValueByField(AbstractTopology.MESSAGE_FIELD);
logger.info(""String_Node_Str"",flowId,componentId,streamId);
switch (streamId) {
case STATUS:
handleErrorRequest(flowId,errorMessage,tuple);
break;
default :
logger.debug(""String_Node_Str"",componentId,streamId);
break;
}
break;
case LCM_FLOW_SYNC_BOLT:
logger.debug(""String_Node_Str"");
NetworkInfoData networkDump=(NetworkInfoData)tuple.getValueByField(LcmFlowCacheSyncBolt.FIELD_ID_NETWORK_DUMP);
handleFlowSync(networkDump);
break;
default :
logger.debug(""String_Node_Str"",componentId);
break;
}
}
 catch (CacheException exception) {
String logMessage=format(""String_Node_Str"",exception.getErrorMessage(),exception.getErrorDescription());
logger.error(""String_Node_Str"",logMessage,Utils.CORRELATION_ID,correlationId,Utils.FLOW_ID,flowId,componentId,streamId,exception);
ErrorMessage errorMessage=buildErrorMessage(correlationId,exception.getErrorType(),logMessage,componentId.toString().toLowerCase());
Values error=new Values(errorMessage,exception.getErrorType());
outputCollector.emit(StreamType.ERROR.toString(),tuple,error);
}
catch (IOException exception) {
logger.error(""String_Node_Str"",tuple,exception);
}
catch (Exception e) {
logger.error(String.format(""String_Node_Str"",getClass().getName()),e);
}
 finally {
logger.debug(""String_Node_Str"",tuple.getSourceComponent(),tuple.getSourceStreamId(),tuple);
outputCollector.ack(tuple);
}
logger.trace(""String_Node_Str"",flowCache);
}","/** 
 * {@inheritDoc}
 */
@Override public void execute(Tuple tuple){
  if (CtrlAction.boltHandlerEntrance(this,tuple))   return;
  logger.trace(""String_Node_Str"",flowCache);
  ComponentType componentId=ComponentType.valueOf(tuple.getSourceComponent());
  String correlationId=Utils.DEFAULT_CORRELATION_ID;
  StreamType streamId=null;
  String flowId=null;
  if (!componentId.equals(ComponentType.LCM_FLOW_SYNC_BOLT)) {
    streamId=StreamType.valueOf(tuple.getSourceStreamId());
    flowId=tuple.getStringByField(Utils.FLOW_ID);
  }
  boolean isRecoverable=false;
  try {
    logger.debug(""String_Node_Str"",tuple);
switch (componentId) {
case SPLITTER_BOLT:
      Message msg=(Message)tuple.getValueByField(AbstractTopology.MESSAGE_FIELD);
    correlationId=msg.getCorrelationId();
  CommandMessage cmsg=(msg instanceof CommandMessage) ? (CommandMessage)msg : null;
InfoMessage imsg=(msg instanceof InfoMessage) ? (InfoMessage)msg : null;
logger.info(""String_Node_Str"",Utils.CORRELATION_ID,correlationId,Utils.FLOW_ID,flowId,componentId,streamId);
switch (streamId) {
case CREATE:
handleCreateRequest(cmsg,tuple);
break;
case UPDATE:
handleUpdateRequest(cmsg,tuple);
break;
case DELETE:
handleDeleteRequest(flowId,cmsg,tuple);
break;
case PUSH:
handlePushRequest(flowId,imsg,tuple);
break;
case UNPUSH:
handleUnpushRequest(flowId,imsg,tuple);
break;
case PATH:
handlePathRequest(flowId,cmsg,tuple);
break;
case RESTORE:
handleRestoreRequest(cmsg,tuple);
break;
case REROUTE:
handleRerouteRequest(cmsg,tuple);
break;
case STATUS:
handleStatusRequest(flowId,cmsg,tuple);
break;
case CACHE_SYNC:
handleCacheSyncRequest(cmsg,tuple);
break;
case READ:
if (flowId != null) {
handleReadRequest(flowId,cmsg,tuple);
}
 else {
handleDumpRequest(cmsg,tuple);
}
break;
default :
logger.debug(""String_Node_Str"",componentId,streamId);
break;
}
break;
case SPEAKER_BOLT:
case TRANSACTION_BOLT:
FlowState newStatus=(FlowState)tuple.getValueByField(FlowTopology.STATUS_FIELD);
logger.info(""String_Node_Str"",flowId,newStatus,componentId,streamId);
switch (streamId) {
case STATUS:
handleStateRequest(flowId,newStatus,tuple);
break;
default :
logger.debug(""String_Node_Str"",componentId,streamId);
break;
}
break;
case TOPOLOGY_ENGINE_BOLT:
ErrorMessage errorMessage=(ErrorMessage)tuple.getValueByField(AbstractTopology.MESSAGE_FIELD);
logger.info(""String_Node_Str"",flowId,componentId,streamId);
switch (streamId) {
case STATUS:
handleErrorRequest(flowId,errorMessage,tuple);
break;
default :
logger.debug(""String_Node_Str"",componentId,streamId);
break;
}
break;
case LCM_FLOW_SYNC_BOLT:
logger.debug(""String_Node_Str"");
NetworkInfoData networkDump=(NetworkInfoData)tuple.getValueByField(LcmFlowCacheSyncBolt.FIELD_ID_NETWORK_DUMP);
handleFlowSync(networkDump);
break;
default :
logger.debug(""String_Node_Str"",componentId);
break;
}
}
 catch (RecoverableException e) {
logger.error(""String_Node_Str"",e);
}
catch (CacheException exception) {
String logMessage=format(""String_Node_Str"",exception.getErrorMessage(),exception.getErrorDescription());
logger.error(""String_Node_Str"",logMessage,Utils.CORRELATION_ID,correlationId,Utils.FLOW_ID,flowId,componentId,streamId,exception);
ErrorMessage errorMessage=buildErrorMessage(correlationId,exception.getErrorType(),logMessage,componentId.toString().toLowerCase());
Values error=new Values(errorMessage,exception.getErrorType());
outputCollector.emit(StreamType.ERROR.toString(),tuple,error);
}
catch (IOException exception) {
logger.error(""String_Node_Str"",tuple,exception);
}
catch (Exception e) {
logger.error(String.format(""String_Node_Str"",getClass().getName()),e);
}
 finally {
logger.debug(""String_Node_Str"",tuple.getSourceComponent(),tuple.getSourceStreamId(),tuple);
if (isRecoverable) {
outputCollector.fail(tuple);
}
 else {
outputCollector.ack(tuple);
}
}
logger.trace(""String_Node_Str"",flowCache);
}"
37776,"private void handleUpdateRequest(CommandMessage message,Tuple tuple) throws IOException {
  Flow requestedFlow=((FlowUpdateRequest)message.getData()).getPayload();
  ImmutablePair<PathInfoData,PathInfoData> path;
  try {
    new FlowValidator(flowCache).checkFlowForEndpointConflicts(requestedFlow);
    path=pathComputer.getPath(requestedFlow,Strategy.COST);
    logger.info(""String_Node_Str"",path);
  }
 catch (  FlowValidationException e) {
    throw new MessageException(message.getCorrelationId(),System.currentTimeMillis(),ErrorType.UPDATE_FAILURE,""String_Node_Str"",e.getMessage());
  }
catch (  UnroutablePathException e) {
    throw new MessageException(message.getCorrelationId(),System.currentTimeMillis(),ErrorType.UPDATE_FAILURE,""String_Node_Str"",""String_Node_Str"");
  }
  ImmutablePair<Flow,Flow> flow=flowCache.updateFlow(requestedFlow,path);
  logger.info(""String_Node_Str"",flow);
  FlowInfoData data=new FlowInfoData(requestedFlow.getFlowId(),flow,UPDATE,message.getCorrelationId());
  InfoMessage infoMessage=new InfoMessage(data,System.currentTimeMillis(),message.getCorrelationId());
  Values topology=new Values(MAPPER.writeValueAsString(infoMessage));
  outputCollector.emit(StreamType.UPDATE.toString(),tuple,topology);
  Values northbound=new Values(new InfoMessage(new FlowResponse(buildFlowResponse(flow)),message.getTimestamp(),message.getCorrelationId(),Destination.NORTHBOUND));
  outputCollector.emit(StreamType.RESPONSE.toString(),tuple,northbound);
}","private void handleUpdateRequest(CommandMessage message,Tuple tuple) throws IOException, RecoverableException {
  Flow requestedFlow=((FlowUpdateRequest)message.getData()).getPayload();
  ImmutablePair<PathInfoData,PathInfoData> path;
  try {
    new FlowValidator(flowCache).checkFlowForEndpointConflicts(requestedFlow);
    path=pathComputer.getPath(requestedFlow,Strategy.COST);
    logger.info(""String_Node_Str"",path);
  }
 catch (  FlowValidationException e) {
    throw new MessageException(message.getCorrelationId(),System.currentTimeMillis(),ErrorType.UPDATE_FAILURE,""String_Node_Str"",e.getMessage());
  }
catch (  UnroutablePathException e) {
    throw new MessageException(message.getCorrelationId(),System.currentTimeMillis(),ErrorType.UPDATE_FAILURE,""String_Node_Str"",""String_Node_Str"");
  }
  ImmutablePair<Flow,Flow> flow=flowCache.updateFlow(requestedFlow,path);
  logger.info(""String_Node_Str"",flow);
  FlowInfoData data=new FlowInfoData(requestedFlow.getFlowId(),flow,UPDATE,message.getCorrelationId());
  InfoMessage infoMessage=new InfoMessage(data,System.currentTimeMillis(),message.getCorrelationId());
  Values topology=new Values(MAPPER.writeValueAsString(infoMessage));
  outputCollector.emit(StreamType.UPDATE.toString(),tuple,topology);
  Values northbound=new Values(new InfoMessage(new FlowResponse(buildFlowResponse(flow)),message.getTimestamp(),message.getCorrelationId(),Destination.NORTHBOUND));
  outputCollector.emit(StreamType.RESPONSE.toString(),tuple,northbound);
}"
37777,"private void handleCreateRequest(CommandMessage message,Tuple tuple) throws IOException {
  Flow requestedFlow=((FlowCreateRequest)message.getData()).getPayload();
  ImmutablePair<PathInfoData,PathInfoData> path;
  try {
    new FlowValidator(flowCache).checkFlowForEndpointConflicts(requestedFlow);
    path=pathComputer.getPath(requestedFlow,Strategy.COST);
    logger.info(""String_Node_Str"",path);
  }
 catch (  FlowValidationException e) {
    throw new MessageException(message.getCorrelationId(),System.currentTimeMillis(),ErrorType.CREATION_FAILURE,""String_Node_Str"",e.getMessage());
  }
catch (  UnroutablePathException e) {
    throw new MessageException(message.getCorrelationId(),System.currentTimeMillis(),ErrorType.CREATION_FAILURE,""String_Node_Str"",""String_Node_Str"");
  }
  ImmutablePair<Flow,Flow> flow=flowCache.createFlow(requestedFlow,path);
  logger.info(""String_Node_Str"",flow);
  FlowInfoData data=new FlowInfoData(requestedFlow.getFlowId(),flow,FlowOperation.CREATE,message.getCorrelationId());
  InfoMessage infoMessage=new InfoMessage(data,System.currentTimeMillis(),message.getCorrelationId());
  Values topology=new Values(MAPPER.writeValueAsString(infoMessage));
  outputCollector.emit(StreamType.CREATE.toString(),tuple,topology);
  Values northbound=new Values(new InfoMessage(new FlowResponse(buildFlowResponse(flow)),message.getTimestamp(),message.getCorrelationId(),Destination.NORTHBOUND));
  outputCollector.emit(StreamType.RESPONSE.toString(),tuple,northbound);
}","private void handleCreateRequest(CommandMessage message,Tuple tuple) throws IOException, RecoverableException {
  Flow requestedFlow=((FlowCreateRequest)message.getData()).getPayload();
  ImmutablePair<PathInfoData,PathInfoData> path;
  try {
    new FlowValidator(flowCache).checkFlowForEndpointConflicts(requestedFlow);
    path=pathComputer.getPath(requestedFlow,Strategy.COST);
    logger.info(""String_Node_Str"",path);
  }
 catch (  FlowValidationException e) {
    throw new MessageException(message.getCorrelationId(),System.currentTimeMillis(),ErrorType.CREATION_FAILURE,""String_Node_Str"",e.getMessage());
  }
catch (  UnroutablePathException e) {
    throw new MessageException(message.getCorrelationId(),System.currentTimeMillis(),ErrorType.CREATION_FAILURE,""String_Node_Str"",""String_Node_Str"");
  }
  ImmutablePair<Flow,Flow> flow=flowCache.createFlow(requestedFlow,path);
  logger.info(""String_Node_Str"",flow);
  FlowInfoData data=new FlowInfoData(requestedFlow.getFlowId(),flow,FlowOperation.CREATE,message.getCorrelationId());
  InfoMessage infoMessage=new InfoMessage(data,System.currentTimeMillis(),message.getCorrelationId());
  Values topology=new Values(MAPPER.writeValueAsString(infoMessage));
  outputCollector.emit(StreamType.CREATE.toString(),tuple,topology);
  Values northbound=new Values(new InfoMessage(new FlowResponse(buildFlowResponse(flow)),message.getTimestamp(),message.getCorrelationId(),Destination.NORTHBOUND));
  outputCollector.emit(StreamType.RESPONSE.toString(),tuple,northbound);
}"
37778,"@Then(""String_Node_Str"") public void flowPathCorrect(String flowId,String sourceSwitch,int sourcePort,int sourceVlan,String destinationSwitch,int destinationPort,int destinationVlan,int bandwidth) throws UnroutablePathException, InterruptedException {
  Flow flow=new Flow(FlowUtils.getFlowName(flowId),bandwidth,false,flowId,sourceSwitch,sourcePort,sourceVlan,destinationSwitch,destinationPort,destinationVlan);
  ImmutablePair<PathInfoData,PathInfoData> path=FlowUtils.getFlowPath(flow);
  System.out.println(path);
  assertEquals(expectedShortestPath,path);
}","@Then(""String_Node_Str"") public void flowPathCorrect(String flowId,String sourceSwitch,int sourcePort,int sourceVlan,String destinationSwitch,int destinationPort,int destinationVlan,int bandwidth) throws UnroutablePathException, InterruptedException, RecoverableException {
  Flow flow=new Flow(FlowUtils.getFlowName(flowId),bandwidth,false,flowId,sourceSwitch,sourcePort,sourceVlan,destinationSwitch,destinationPort,destinationVlan);
  ImmutablePair<PathInfoData,PathInfoData> path=FlowUtils.getFlowPath(flow);
  System.out.println(path);
  assertEquals(expectedShortestPath,path);
}"
37779,"/** 
 * Gets flow path.
 * @param flow flow
 * @return flow path
 */
public static ImmutablePair<PathInfoData,PathInfoData> getFlowPath(Flow flow) throws InterruptedException, UnroutablePathException {
  Thread.sleep(1000);
  return pathComputer.getPath(flow,PathComputer.Strategy.COST);
}","/** 
 * Gets flow path.
 * @param flow flow
 * @return flow path
 */
public static ImmutablePair<PathInfoData,PathInfoData> getFlowPath(Flow flow) throws InterruptedException, UnroutablePathException, RecoverableException {
  Thread.sleep(1000);
  return pathComputer.getPath(flow,PathComputer.Strategy.COST);
}"
37780,"@Test public void testGetPathByCostInactiveOnTriangleTopo() throws UnroutablePathException {
  createTriangleTopo(""String_Node_Str"",10,20);
  Driver driver=GraphDatabase.driver(""String_Node_Str"",AuthTokens.basic(""String_Node_Str"",""String_Node_Str""));
  NeoDriver nd=new NeoDriver(driver);
  Flow f=new Flow();
  f.setSourceSwitch(""String_Node_Str"");
  f.setDestinationSwitch(""String_Node_Str"");
  f.setBandwidth(100);
  ImmutablePair<PathInfoData,PathInfoData> path=nd.getPath(f,PathComputer.Strategy.COST);
  Assert.assertNotNull(path);
  Assert.assertEquals(4,path.left.getPath().size());
  Assert.assertEquals(""String_Node_Str"",path.left.getPath().get(1).getSwitchId());
}","@Test public void testGetPathByCostInactiveOnTriangleTopo() throws UnroutablePathException, RecoverableException {
  createTriangleTopo(""String_Node_Str"",10,20);
  Driver driver=GraphDatabase.driver(""String_Node_Str"",AuthTokens.basic(""String_Node_Str"",""String_Node_Str""));
  NeoDriver nd=new NeoDriver(driver);
  Flow f=new Flow();
  f.setSourceSwitch(""String_Node_Str"");
  f.setDestinationSwitch(""String_Node_Str"");
  f.setBandwidth(100);
  ImmutablePair<PathInfoData,PathInfoData> path=nd.getPath(f,PathComputer.Strategy.COST);
  Assert.assertNotNull(path);
  Assert.assertEquals(4,path.left.getPath().size());
  Assert.assertEquals(""String_Node_Str"",path.left.getPath().get(1).getSwitchId());
}"
37781,"@Test public void testGetPathByCostNoCost() throws UnroutablePathException {
  createDiamond(""String_Node_Str"",""String_Node_Str"",-1,2000);
  Driver driver=GraphDatabase.driver(""String_Node_Str"",AuthTokens.basic(""String_Node_Str"",""String_Node_Str""));
  NeoDriver nd=new NeoDriver(driver);
  Flow f=new Flow();
  f.setSourceSwitch(""String_Node_Str"");
  f.setDestinationSwitch(""String_Node_Str"");
  f.setBandwidth(100);
  ImmutablePair<PathInfoData,PathInfoData> path=nd.getPath(f,PathComputer.Strategy.COST);
  Assert.assertNotNull(path);
  Assert.assertEquals(4,path.left.getPath().size());
  Assert.assertEquals(""String_Node_Str"",path.left.getPath().get(1).getSwitchId());
}","@Test public void testGetPathByCostNoCost() throws UnroutablePathException, RecoverableException {
  createDiamond(""String_Node_Str"",""String_Node_Str"",-1,2000);
  Driver driver=GraphDatabase.driver(""String_Node_Str"",AuthTokens.basic(""String_Node_Str"",""String_Node_Str""));
  NeoDriver nd=new NeoDriver(driver);
  Flow f=new Flow();
  f.setSourceSwitch(""String_Node_Str"");
  f.setDestinationSwitch(""String_Node_Str"");
  f.setBandwidth(100);
  ImmutablePair<PathInfoData,PathInfoData> path=nd.getPath(f,PathComputer.Strategy.COST);
  Assert.assertNotNull(path);
  Assert.assertEquals(4,path.left.getPath().size());
  Assert.assertEquals(""String_Node_Str"",path.left.getPath().get(1).getSwitchId());
}"
37782,"@Test public void testGetPathByCostActive() throws UnroutablePathException {
  createDiamond(""String_Node_Str"",""String_Node_Str"",10,20);
  Driver driver=GraphDatabase.driver(""String_Node_Str"",AuthTokens.basic(""String_Node_Str"",""String_Node_Str""));
  NeoDriver nd=new NeoDriver(driver);
  Flow f=new Flow();
  f.setSourceSwitch(""String_Node_Str"");
  f.setDestinationSwitch(""String_Node_Str"");
  f.setBandwidth(100);
  ImmutablePair<PathInfoData,PathInfoData> path=nd.getPath(f,PathComputer.Strategy.COST);
  Assert.assertNotNull(path);
  Assert.assertEquals(4,path.left.getPath().size());
  Assert.assertEquals(""String_Node_Str"",path.left.getPath().get(1).getSwitchId());
}","@Test public void testGetPathByCostActive() throws UnroutablePathException, RecoverableException {
  createDiamond(""String_Node_Str"",""String_Node_Str"",10,20);
  Driver driver=GraphDatabase.driver(""String_Node_Str"",AuthTokens.basic(""String_Node_Str"",""String_Node_Str""));
  NeoDriver nd=new NeoDriver(driver);
  Flow f=new Flow();
  f.setSourceSwitch(""String_Node_Str"");
  f.setDestinationSwitch(""String_Node_Str"");
  f.setBandwidth(100);
  ImmutablePair<PathInfoData,PathInfoData> path=nd.getPath(f,PathComputer.Strategy.COST);
  Assert.assertNotNull(path);
  Assert.assertEquals(4,path.left.getPath().size());
  Assert.assertEquals(""String_Node_Str"",path.left.getPath().get(1).getSwitchId());
}"
37783,"@Test public void testGetPathByCostInactive() throws UnroutablePathException {
  createDiamond(""String_Node_Str"",""String_Node_Str"",10,20);
  Driver driver=GraphDatabase.driver(""String_Node_Str"",AuthTokens.basic(""String_Node_Str"",""String_Node_Str""));
  NeoDriver nd=new NeoDriver(driver);
  Flow f=new Flow();
  f.setSourceSwitch(""String_Node_Str"");
  f.setDestinationSwitch(""String_Node_Str"");
  f.setBandwidth(100);
  ImmutablePair<PathInfoData,PathInfoData> path=nd.getPath(f,PathComputer.Strategy.COST);
  Assert.assertNotNull(path);
  Assert.assertEquals(4,path.left.getPath().size());
  Assert.assertEquals(""String_Node_Str"",path.left.getPath().get(1).getSwitchId());
}","@Test public void testGetPathByCostInactive() throws UnroutablePathException, RecoverableException {
  createDiamond(""String_Node_Str"",""String_Node_Str"",10,20);
  Driver driver=GraphDatabase.driver(""String_Node_Str"",AuthTokens.basic(""String_Node_Str"",""String_Node_Str""));
  NeoDriver nd=new NeoDriver(driver);
  Flow f=new Flow();
  f.setSourceSwitch(""String_Node_Str"");
  f.setDestinationSwitch(""String_Node_Str"");
  f.setBandwidth(100);
  ImmutablePair<PathInfoData,PathInfoData> path=nd.getPath(f,PathComputer.Strategy.COST);
  Assert.assertNotNull(path);
  Assert.assertEquals(4,path.left.getPath().size());
  Assert.assertEquals(""String_Node_Str"",path.left.getPath().get(1).getSwitchId());
}"
37784,"@Test(expected=UnroutablePathException.class) public void testGetPathNoPath() throws UnroutablePathException {
  createDiamond(""String_Node_Str"",""String_Node_Str"",10,30);
  Driver driver=GraphDatabase.driver(""String_Node_Str"",AuthTokens.basic(""String_Node_Str"",""String_Node_Str""));
  NeoDriver nd=new NeoDriver(driver);
  Flow f=new Flow();
  f.setSourceSwitch(""String_Node_Str"");
  f.setDestinationSwitch(""String_Node_Str"");
  f.setBandwidth(100);
  ImmutablePair<PathInfoData,PathInfoData> path=nd.getPath(f,PathComputer.Strategy.COST);
}","@Test(expected=UnroutablePathException.class) public void testGetPathNoPath() throws UnroutablePathException, RecoverableException {
  createDiamond(""String_Node_Str"",""String_Node_Str"",10,30);
  Driver driver=GraphDatabase.driver(""String_Node_Str"",AuthTokens.basic(""String_Node_Str"",""String_Node_Str""));
  NeoDriver nd=new NeoDriver(driver);
  Flow f=new Flow();
  f.setSourceSwitch(""String_Node_Str"");
  f.setDestinationSwitch(""String_Node_Str"");
  f.setBandwidth(100);
  ImmutablePair<PathInfoData,PathInfoData> path=nd.getPath(f,PathComputer.Strategy.COST);
}"
37785,"/** 
 * Creates or updates   {@link SwitchInfoData} instance.
 * @param newSwitch {@link SwitchInfoData} instance
 * @return created {@link SwitchInfoData} instance
 * @throws CacheException if {@link SwitchInfoData} instance with specified id already exists
 */
public SwitchInfoData createOrUpdateSwitch(SwitchInfoData newSwitch){
  logger.debug(""String_Node_Str"",newSwitch);
  if (cacheContainsSwitch(newSwitch.getSwitchId())) {
    return updateSwitch(newSwitch);
  }
 else {
    return createSwitch(newSwitch);
  }
}","/** 
 * Creates or updates   {@link SwitchInfoData} instance.
 * @param newSwitch {@link SwitchInfoData} instance
 * @return created {@link SwitchInfoData} instance
 * @throws CacheException if {@link SwitchInfoData} instance with specified id already exists
 */
public SwitchInfoData createOrUpdateSwitch(SwitchInfoData newSwitch){
  logger.debug(""String_Node_Str"",newSwitch);
  if (newSwitch == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (cacheContainsSwitch(newSwitch.getSwitchId())) {
    return updateSwitch(newSwitch);
  }
 else {
    return createSwitch(newSwitch);
  }
}"
37786,"/** 
 * Creates   {@link IslInfoData} instance.
 * @param isl {@link IslInfoData} instance
 * @return {@link IslInfoData} instance previously associated with {@link IslInfoData} instance id or null otherwise
 * @throws CacheException if {@link SwitchInfoData} related to {@link IslInfoData} instance do not exist
 */
public IslInfoData createOrUpdateIsl(IslInfoData isl){
  logger.debug(""String_Node_Str"",isl);
  if (cacheContainsIsl(isl.getId())) {
    return updateIsl(isl);
  }
 else {
    return createIsl(isl);
  }
}","/** 
 * Creates   {@link IslInfoData} instance.
 * @param isl {@link IslInfoData} instance
 * @return {@link IslInfoData} instance previously associated with {@link IslInfoData} instance id or null otherwise
 * @throws CacheException if {@link SwitchInfoData} related to {@link IslInfoData} instance do not exist
 */
public IslInfoData createOrUpdateIsl(IslInfoData isl){
  logger.debug(""String_Node_Str"",isl);
  if (isl == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (cacheContainsIsl(isl.getId())) {
    return updateIsl(isl);
  }
 else {
    return createIsl(isl);
  }
}"
37787,"@Override public List<IslInfoData> getIsls(){
  String q=""String_Node_Str"" + ""String_Node_Str"" + ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str"";
  logger.debug(""String_Node_Str"",q);
  Session session=driver.session();
  StatementResult queryResults=session.run(q);
  List<IslInfoData> results=new LinkedList<>();
  for (  Record record : queryResults.list()) {
    IslInfoData isl=new IslInfoData();
    List<PathNode> pathNodes=new ArrayList<>();
    PathNode src=new PathNode();
    src.setSwitchId(record.get(""String_Node_Str"").asString());
    src.setPortNo(record.get(""String_Node_Str"").asInt());
    pathNodes.add(src);
    PathNode dst=new PathNode();
    dst.setSwitchId(record.get(""String_Node_Str"").asString());
    dst.setPortNo(record.get(""String_Node_Str"").asInt());
    pathNodes.add(dst);
    isl.setPath(pathNodes);
    isl.setSpeed(record.get(""String_Node_Str"").asInt());
    isl.setLatency(record.get(""String_Node_Str"").asInt());
    isl.setAvailableBandwidth(record.get(""String_Node_Str"").asInt());
    String status=record.get(""String_Node_Str"").asString();
    IslChangeType ct=(""String_Node_Str"".equals(status)) ? IslChangeType.DISCOVERED : IslChangeType.FAILED;
    isl.setState(ct);
    isl.setTimestamp(System.currentTimeMillis());
    results.add(isl);
  }
  return results;
}","@Override public List<IslInfoData> getIsls(){
  String q=""String_Node_Str"" + ""String_Node_Str"" + ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str"";
  logger.debug(""String_Node_Str"",q);
  Session session=driver.session();
  StatementResult queryResults=session.run(q);
  List<IslInfoData> results=new LinkedList<>();
  for (  Record record : queryResults.list()) {
    IslInfoData isl=new IslInfoData();
    List<PathNode> pathNodes=new ArrayList<>();
    PathNode src=new PathNode();
    src.setSwitchId(record.get(""String_Node_Str"").asString());
    src.setPortNo(record.get(""String_Node_Str"").asInt());
    src.setSegLatency(record.get(""String_Node_Str"").asInt());
    pathNodes.add(src);
    PathNode dst=new PathNode();
    dst.setSwitchId(record.get(""String_Node_Str"").asString());
    dst.setPortNo(record.get(""String_Node_Str"").asInt());
    dst.setSegLatency(record.get(""String_Node_Str"").asInt());
    pathNodes.add(dst);
    isl.setPath(pathNodes);
    isl.setSpeed(record.get(""String_Node_Str"").asInt());
    isl.setLatency(record.get(""String_Node_Str"").asInt());
    isl.setAvailableBandwidth(record.get(""String_Node_Str"").asInt());
    String status=record.get(""String_Node_Str"").asString();
    IslChangeType ct=(""String_Node_Str"".equals(status)) ? IslChangeType.DISCOVERED : IslChangeType.FAILED;
    isl.setState(ct);
    isl.setTimestamp(System.currentTimeMillis());
    results.add(isl);
  }
  return results;
}"
37788,"@Override public List<IslInfoData> getIsls(){
  String q=""String_Node_Str"" + ""String_Node_Str"" + ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str"";
  logger.debug(""String_Node_Str"",q);
  Session session=driver.session();
  StatementResult queryResults=session.run(q);
  List<IslInfoData> results=new LinkedList<>();
  for (  Record record : queryResults.list()) {
    IslInfoData isl=new IslInfoData();
    List<PathNode> pathNodes=new ArrayList<>();
    PathNode src=new PathNode();
    src.setSwitchId(record.get(""String_Node_Str"").asString());
    src.setPortNo(record.get(""String_Node_Str"").asInt());
    src.setSegLatency(record.get(""String_Node_Str"").asInt());
    pathNodes.add(src);
    PathNode dst=new PathNode();
    dst.setSwitchId(record.get(""String_Node_Str"").asString());
    dst.setPortNo(record.get(""String_Node_Str"").asInt());
    dst.setSegLatency(record.get(""String_Node_Str"").asInt());
    pathNodes.add(dst);
    isl.setPath(pathNodes);
    isl.setSpeed(record.get(""String_Node_Str"").asInt());
    isl.setLatency(record.get(""String_Node_Str"").asInt());
    isl.setAvailableBandwidth(record.get(""String_Node_Str"").asInt());
    String status=record.get(""String_Node_Str"").asString();
    IslChangeType ct=(""String_Node_Str"".equals(status)) ? IslChangeType.DISCOVERED : IslChangeType.FAILED;
    isl.setState(ct);
    isl.setTimestamp(System.currentTimeMillis());
    results.add(isl);
  }
  return results;
}","@Override public List<IslInfoData> getIsls(){
  String q=""String_Node_Str"" + ""String_Node_Str"" + ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str"";
  logger.debug(""String_Node_Str"",q);
  Session session=driver.session();
  StatementResult queryResults=session.run(q);
  List<IslInfoData> results=new LinkedList<>();
  for (  Record record : queryResults.list()) {
    List<PathNode> pathNodes=new ArrayList<>();
    PathNode src=new PathNode();
    src.setSwitchId(record.get(""String_Node_Str"").asString());
    src.setPortNo(record.get(""String_Node_Str"").asInt());
    src.setSegLatency(record.get(""String_Node_Str"").asInt());
    pathNodes.add(src);
    PathNode dst=new PathNode();
    dst.setSwitchId(record.get(""String_Node_Str"").asString());
    dst.setPortNo(record.get(""String_Node_Str"").asInt());
    dst.setSegLatency(record.get(""String_Node_Str"").asInt());
    pathNodes.add(dst);
    String status=record.get(""String_Node_Str"").asString();
    IslChangeType state=(""String_Node_Str"".equals(status)) ? IslChangeType.DISCOVERED : IslChangeType.FAILED;
    IslInfoData isl=new IslInfoData(record.get(""String_Node_Str"").asInt(),pathNodes,record.get(""String_Node_Str"").asInt(),state,record.get(""String_Node_Str"").asInt());
    isl.setTimestamp(System.currentTimeMillis());
    results.add(isl);
  }
  return results;
}"
37789,"/** 
 * Builds new forward and reverse flow pair.
 * @param flow  source flow
 * @param path  flow path
 * @param cache resource cache
 * @return new forward and reverse flow pair
 */
public ImmutablePair<Flow,Flow> buildFlow(final Flow flow,ImmutablePair<PathInfoData,PathInfoData> path,ResourceCache cache){
  String timestamp=Utils.getIsoTimestamp();
  int cookie=cache.allocateCookie();
  Flow forward=new Flow(flow.getFlowId(),flow.getBandwidth(),flow.isIgnoreBandwidth(),cookie | ResourceCache.FORWARD_FLOW_COOKIE_MASK,flow.getDescription(),timestamp,flow.getSourceSwitch(),flow.getDestinationSwitch(),flow.getSourcePort(),flow.getDestinationPort(),flow.getSourceVlan(),flow.getDestinationVlan(),cache.allocateMeterId(flow.getSourceSwitch()),cache.allocateVlanId(),path.getLeft(),FlowState.ALLOCATED);
  Flow reverse=new Flow(flow.getFlowId(),flow.getBandwidth(),flow.isIgnoreBandwidth(),cookie | ResourceCache.REVERSE_FLOW_COOKIE_MASK,flow.getDescription(),timestamp,flow.getDestinationSwitch(),flow.getSourceSwitch(),flow.getDestinationPort(),flow.getSourcePort(),flow.getDestinationVlan(),flow.getSourceVlan(),cache.allocateMeterId(flow.getDestinationSwitch()),cache.allocateVlanId(),path.getRight(),FlowState.ALLOCATED);
  return new ImmutablePair<>(forward,reverse);
}","/** 
 * Builds new forward and reverse flow pair.
 * @param flow  source flow
 * @param path  flow path
 * @param cache resource cache
 * @return new forward and reverse flow pair
 */
public ImmutablePair<Flow,Flow> buildFlow(final Flow flow,ImmutablePair<PathInfoData,PathInfoData> path,ResourceCache cache){
  String timestamp=Utils.getIsoTimestamp();
  int cookie=cache.allocateCookie();
  int forwardVlan=0;
  int reverseVlan=0;
  if (!flow.isOneSwitchFlow()) {
    forwardVlan=cache.allocateVlanId();
    reverseVlan=cache.allocateVlanId();
  }
  Flow forward=new Flow(flow.getFlowId(),flow.getBandwidth(),flow.isIgnoreBandwidth(),cookie | ResourceCache.FORWARD_FLOW_COOKIE_MASK,flow.getDescription(),timestamp,flow.getSourceSwitch(),flow.getDestinationSwitch(),flow.getSourcePort(),flow.getDestinationPort(),flow.getSourceVlan(),flow.getDestinationVlan(),cache.allocateMeterId(flow.getSourceSwitch()),forwardVlan,path.getLeft(),FlowState.ALLOCATED);
  Flow reverse=new Flow(flow.getFlowId(),flow.getBandwidth(),flow.isIgnoreBandwidth(),cookie | ResourceCache.REVERSE_FLOW_COOKIE_MASK,flow.getDescription(),timestamp,flow.getDestinationSwitch(),flow.getSourceSwitch(),flow.getDestinationPort(),flow.getSourcePort(),flow.getDestinationVlan(),flow.getSourceVlan(),cache.allocateMeterId(flow.getDestinationSwitch()),reverseVlan,path.getRight(),FlowState.ALLOCATED);
  return new ImmutablePair<>(forward,reverse);
}"
37790,"/** 
 * Track and allocate the flow.
 * @param flow The flow to track / allocate.
 */
public void pushFlow(ImmutablePair<Flow,Flow> flow){
  putFlow(flow);
  resourceCache.allocateFlow(flow);
}","/** 
 * Track and allocate the flow.
 * @param flow The flow to track / allocate.
 */
public void pushFlow(ImmutablePair<Flow,Flow> flow){
  resourceCache.allocateFlow(flow);
  putFlow(flow);
}"
37791,"/** 
 * Allocates flow resources.
 * @param flow flow
 */
public void allocateFlow(ImmutablePair<Flow,Flow> flow){
  if (flow.left != null) {
    allocateCookie((int)(FLOW_COOKIE_VALUE_MASK & flow.left.getCookie()));
    allocateVlanId(flow.left.getTransitVlan());
    allocateMeterId(flow.left.getSourceSwitch(),flow.left.getMeterId());
  }
  if (flow.right != null) {
    allocateVlanId(flow.right.getTransitVlan());
    allocateMeterId(flow.right.getSourceSwitch(),flow.right.getMeterId());
  }
}","/** 
 * Allocates flow resources. All flows come here .. single switch and multi switch flows.
 * @param flow flow
 */
public void allocateFlow(ImmutablePair<Flow,Flow> flow){
  if (flow.left != null) {
    allocateCookie((int)(FLOW_COOKIE_VALUE_MASK & flow.left.getCookie()));
    if (!flow.left.isOneSwitchFlow()) {
      allocateVlanId(flow.left.getTransitVlan());
    }
    allocateMeterId(flow.left.getSourceSwitch(),flow.left.getMeterId());
  }
  if (flow.right != null) {
    if (!flow.right.isOneSwitchFlow()) {
      allocateVlanId(flow.right.getTransitVlan());
    }
    allocateMeterId(flow.right.getSourceSwitch(),flow.right.getMeterId());
  }
}"
37792,"@Test public void allocateFlow() throws Exception {
  resourceCache.allocateFlow(new ImmutablePair<>(forwardCreatedFlow,reverseCreatedFlow));
  resourceCache.allocateFlow(new ImmutablePair<>(forwardCreatedFlow,reverseCreatedFlow));
  Set<Integer> allocatedCookies=resourceCache.getAllCookies();
  Set<Integer> allocatedVlanIds=resourceCache.getAllVlanIds();
  Set<Integer> allocatedMeterIds=resourceCache.getAllMeterIds(NetworkTopologyConstants.sw3.getSwitchId());
  Set<Integer> expectedCookies=new HashSet<>(Arrays.asList((int)forwardCreatedFlow.getCookie(),(int)reverseCreatedFlow.getCookie()));
  Set<Integer> expectedVlanIds=new HashSet<>(Arrays.asList(forwardCreatedFlow.getTransitVlan(),reverseCreatedFlow.getTransitVlan()));
  Set<Integer> expectedMeterIds=new HashSet<>(Arrays.asList(forwardCreatedFlow.getMeterId(),reverseCreatedFlow.getMeterId()));
  assertEquals(expectedCookies,allocatedCookies);
  assertEquals(expectedVlanIds,allocatedVlanIds);
  assertEquals(expectedMeterIds,allocatedMeterIds);
}","@Test public void allocateFlow() throws Exception {
  resourceCache.allocateFlow(new ImmutablePair<>(forwardCreatedFlow,reverseCreatedFlow));
  resourceCache.allocateFlow(new ImmutablePair<>(forwardCreatedFlow,reverseCreatedFlow));
  Set<Integer> allocatedCookies=resourceCache.getAllCookies();
  Set<Integer> allocatedVlanIds=resourceCache.getAllVlanIds();
  Set<Integer> allocatedMeterIds=new HashSet<>();
  allocatedMeterIds.addAll(resourceCache.getAllMeterIds(NetworkTopologyConstants.sw3.getSwitchId()));
  allocatedMeterIds.addAll(resourceCache.getAllMeterIds(NetworkTopologyConstants.sw4.getSwitchId()));
  Set<Integer> expectedCookies=new HashSet<>(Arrays.asList((int)forwardCreatedFlow.getCookie(),(int)reverseCreatedFlow.getCookie()));
  Set<Integer> expectedVlanIds=new HashSet<>(Arrays.asList(forwardCreatedFlow.getTransitVlan(),reverseCreatedFlow.getTransitVlan()));
  Set<Integer> expectedMeterIds=new HashSet<>(Arrays.asList(forwardCreatedFlow.getMeterId(),reverseCreatedFlow.getMeterId()));
  assertEquals(expectedCookies,allocatedCookies);
  assertEquals(expectedVlanIds,allocatedVlanIds);
  assertEquals(expectedMeterIds,allocatedMeterIds);
}"
37793,"private void initFlowCache(){
  logger.info(""String_Node_Str"");
  Map<String,BidirectionalFlow> flowPairsMap=new HashMap<>();
  List<Flow> flows=pathComputer.getAllFlows();
  logger.info(""String_Node_Str"",flows.size());
  for (  Flow flow : flows) {
    logger.info(""String_Node_Str"",flow);
    if (!flowPairsMap.containsKey(flow.getFlowId())) {
      flowPairsMap.put(flow.getFlowId(),new BidirectionalFlow());
    }
    BidirectionalFlow pair=flowPairsMap.get(flow.getFlowId());
    try {
      pair.add(flow);
    }
 catch (    IllegalArgumentException e) {
      logger.error(""String_Node_Str"",flow.getFlowId(),e.toString());
    }
  }
  for (  BidirectionalFlow bidirectionalFlow : flowPairsMap.values()) {
    try {
      flowCache.pushFlow(bidirectionalFlow.makeFlowPair());
    }
 catch (    InvalidArgumentException e) {
      logger.error(""String_Node_Str"",bidirectionalFlow.anyDefined().getFlowId(),e.toString());
    }
  }
  logger.info(""String_Node_Str"");
}","private void initFlowCache(){
  logger.info(""String_Node_Str"");
  Map<String,BidirectionalFlow> flowPairsMap=new HashMap<>();
  List<Flow> flows=pathComputer.getAllFlows();
  logger.info(""String_Node_Str"",flows.size());
  for (  Flow flow : flows) {
    if (!flowPairsMap.containsKey(flow.getFlowId())) {
      flowPairsMap.put(flow.getFlowId(),new BidirectionalFlow());
    }
    BidirectionalFlow pair=flowPairsMap.get(flow.getFlowId());
    try {
      pair.add(flow);
    }
 catch (    IllegalArgumentException e) {
      logger.error(""String_Node_Str"",flow.getFlowId(),e.toString());
    }
  }
  for (  BidirectionalFlow bidirectionalFlow : flowPairsMap.values()) {
    try {
      flowCache.pushFlow(bidirectionalFlow.makeFlowPair());
    }
 catch (    InvalidArgumentException e) {
      logger.error(""String_Node_Str"",bidirectionalFlow.anyDefined().getFlowId(),e.toString());
    }
  }
  logger.info(""String_Node_Str"");
}"
37794,"@Override public int hashCode(){
  int result=metric != null ? metric.hashCode() : 0;
  result=31 * result + (tags != null ? tags.hashCode() : 0);
  return result;
}","@Override public int hashCode(){
  int result=metric != null ? metric.hashCode() : 0;
  result=31 * result + (tags != null ? tags.hashCode() : 0);
  result=31 * result + (value != null ? value.hashCode() : 0);
  return result;
}"
37795,"@Override public StormTopology createTopology(){
  LOGGER.info(""String_Node_Str"");
  TopologyBuilder tb=new TopologyBuilder();
  checkAndCreateTopic(topic);
  KafkaSpout kafkaSpout=createKafkaSpout(topic,spoutId);
  tb.setSpout(spoutId,kafkaSpout,config.getOpenTsdbNumSpouts());
  tb.setBolt(parseBoltId,new DatapointParseBolt(),config.getGetDatapointParseBoltExecutors()).setNumTasks(config.getGetDatapointParseBoltWorkers()).shuffleGrouping(spoutId);
  tb.setBolt(boltId,new OpenTSDBFilterBolt(),config.getOpenTsdbFilterBoltExecutors()).fieldsGrouping(parseBoltId,new Fields(""String_Node_Str""));
  return tb.createTopology();
}","@Override public StormTopology createTopology(){
  LOGGER.info(""String_Node_Str"");
  TopologyBuilder tb=new TopologyBuilder();
  checkAndCreateTopic(topic);
  KafkaSpout kafkaSpout=createKafkaSpout(topic,spoutId);
  tb.setSpout(spoutId,kafkaSpout,config.getOpenTsdbNumSpouts());
  tb.setBolt(parseBoltId,new DatapointParseBolt(),config.getGetDatapointParseBoltExecutors()).setNumTasks(config.getGetDatapointParseBoltWorkers()).shuffleGrouping(spoutId);
  tb.setBolt(boltId,new OpenTSDBFilterBolt(),config.getOpenTsdbFilterBoltExecutors()).fieldsGrouping(parseBoltId,new Fields(""String_Node_Str""));
  OpenTsdbClient.Builder tsdbBuilder=OpenTsdbClient.newBuilder(config.getOpenTsDBHosts()).returnDetails();
  if (config.isOpenTsdbClientChunkedRequestsEnabled()) {
    tsdbBuilder.enableChunkedEncoding();
  }
  OpenTsdbBolt openTsdbBolt=new OpenTsdbBolt(tsdbBuilder,Collections.singletonList(TupleOpenTsdbDatapointMapper.DEFAULT_MAPPER));
  openTsdbBolt.withBatchSize(config.getOpenTsdbBatchSize()).withFlushInterval(config.getOpenTsdbFlushInterval());
  tb.setBolt(""String_Node_Str"",openTsdbBolt,config.getOpenTsdbBoltExecutors()).setNumTasks(config.getOpenTsdbBoltWorkers()).shuffleGrouping(boltId);
  return tb.createTopology();
}"
37796,"private boolean isUpdateRequired(Datapoint datapoint){
  boolean update=true;
  if (storage.containsKey(datapoint.hashCode())) {
    Datapoint prevDatapoint=storage.get(datapoint.hashCode());
    update=!prevDatapoint.getValue().equals(datapoint.getValue()) || datapoint.getTime() - prevDatapoint.getTime() >= TEN_MINUTES;
  }
  return update;
}","private boolean isUpdateRequired(Datapoint datapoint){
  boolean update=true;
  if (storage.containsKey(datapoint.simpleHashCode())) {
    Datapoint prevDatapoint=storage.get(datapoint.simpleHashCode());
    update=!prevDatapoint.getValue().equals(datapoint.getValue()) || datapoint.getTime() - prevDatapoint.getTime() >= TEN_MINUTES;
  }
  return update;
}"
37797,"private void addDatapoint(Datapoint datapoint){
  LOGGER.debug(""String_Node_Str"" + datapoint.hashCode());
  LOGGER.debug(""String_Node_Str"" + storage.size());
  storage.put(datapoint.hashCode(),datapoint);
}","private void addDatapoint(Datapoint datapoint){
  LOGGER.debug(""String_Node_Str"" + datapoint.simpleHashCode());
  LOGGER.debug(""String_Node_Str"" + storage.size());
  storage.put(datapoint.simpleHashCode(),datapoint);
}"
37798,"/** 
 * {@inheritDoc}
 */
@Override public FlowValidationDto validateFlow(final String flowId,final String correlationId){
  Flow flow=pathComputer.getFlow(flowId);
  if (flow == null)   return null;
  logger.debug(""String_Node_Str"",flow);
  Set<String> switches=new HashSet<>();
  switches.add(flow.getSourceSwitch());
  if (flow.getFlowPath() == null) {
    throw new InvalidPathException(flowId,""String_Node_Str"");
  }
  for (  PathNode node : flow.getFlowPath().getPath()) {
    switches.add(node.getSwitchId());
  }
  switches.add(flow.getDestinationSwitch());
  Long ignoreCookie=0L;
  int correlation_iter=1;
  Map<String,SwitchFlowEntries> rules=new HashMap<>();
  for (  String switchid : switches) {
    String corr_id=correlationId + ""String_Node_Str"" + correlation_iter++;
    rules.put(switchid,switchService.getRules(switchid,ignoreCookie,corr_id));
  }
  List<PathDiscrepancyDto> discrepencies=new ArrayList<>();
  for (  String switchid : switches) {
    PathDiscrepancyDto disc=new PathDiscrepancyDto();
    disc.setField(""String_Node_Str"" + switchid);
    disc.setExpectedValue(""String_Node_Str"");
    int numRules=(rules.get(switchid) == null) ? 0 : rules.get(switchid).getFlowEntries().size();
    disc.setActualValue(""String_Node_Str"" + numRules);
    disc.setNode(new PathNode());
    discrepencies.add(disc);
  }
  FlowValidationDto result=new FlowValidationDto();
  result.setFlow(flow);
  result.setFlowId(flowId);
  result.setDiscrepancies(discrepencies);
  result.setAsExpected(discrepencies.size() > 0);
  return result;
}","/** 
 * {@inheritDoc}
 */
@Override public FlowValidationDto validateFlow(final String flowId,final String correlationId){
  Flow flow=pathComputer.getFlow(flowId);
  if (flow == null)   return null;
  logger.debug(""String_Node_Str"",flow);
  Set<String> switches=new HashSet<>();
  switches.add(flow.getSourceSwitch());
  if (flow.getFlowPath() == null) {
    throw new InvalidPathException(flowId,""String_Node_Str"");
  }
  for (  PathNode node : flow.getFlowPath().getPath()) {
    switches.add(node.getSwitchId());
  }
  switches.add(flow.getDestinationSwitch());
  Long ignoreCookie=0L;
  int correlation_iter=1;
  Map<String,SwitchFlowEntries> rules=new HashMap<>();
  for (  String switchid : switches) {
    String corr_id=correlationId + ""String_Node_Str"" + correlation_iter++;
    rules.put(switchid,switchService.getRules(switchid,ignoreCookie,corr_id));
  }
  List<PathDiscrepancyDto> discrepencies=new ArrayList<>();
  for (  String switchid : switches) {
    PathDiscrepancyDto disc=new PathDiscrepancyDto();
    disc.setField(""String_Node_Str"" + switchid);
    disc.setExpectedValue(""String_Node_Str"");
    int numRules=(rules.get(switchid) == null) ? 0 : rules.get(switchid).getFlowEntries().size();
    disc.setActualValue(""String_Node_Str"" + numRules);
    disc.setNode(new PathNode());
    discrepencies.add(disc);
  }
  FlowValidationDto result=new FlowValidationDto();
  result.setFlow(flow);
  result.setFlowId(flowId);
  result.setDiscrepancies(discrepencies);
  result.setAsExpected(discrepencies.size() == 0);
  return result;
}"
37799,"public FlowAdapter(Record dbRecord){
  String pathJson=dbRecord.get(""String_Node_Str"").asString();
  if (pathJson.equals(""String_Node_Str"")) {
    pathJson=""String_Node_Str"";
  }
  String remaining=pathJson.substring(2);
  PathInfoData path;
  pathJson=""String_Node_Str"" + remaining;
  try {
    path=Utils.MAPPER.readValue(pathJson,PathInfoData.class);
  }
 catch (  IOException e) {
    throw new IllegalArgumentException(String.format(""String_Node_Str"",pathJson),e);
  }
  flow=new Flow(dbRecord.get(Utils.FLOW_ID).asString(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asBoolean(),dbRecord.get(""String_Node_Str"").asLong(),dbRecord.get(""String_Node_Str"").asString(),dbRecord.get(""String_Node_Str"").asString(),dbRecord.get(""String_Node_Str"").asString(),dbRecord.get(""String_Node_Str"").asString(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),path,FlowState.CACHED);
}","public FlowAdapter(Record dbRecord){
  String pathJson=dbRecord.get(""String_Node_Str"").asString().trim();
  if (pathJson.equals(""String_Node_Str"")) {
    pathJson=""String_Node_Str"";
  }
  String start=pathJson.substring(0,pathJson.length() - 1);
  PathInfoData path;
  pathJson=start + ""String_Node_Str"";
  try {
    path=Utils.MAPPER.readValue(pathJson,PathInfoData.class);
  }
 catch (  IOException e) {
    throw new IllegalArgumentException(String.format(""String_Node_Str"",pathJson),e);
  }
  flow=new Flow(dbRecord.get(Utils.FLOW_ID).asString(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asBoolean(),dbRecord.get(""String_Node_Str"").asLong(),dbRecord.get(""String_Node_Str"").asString(),dbRecord.get(""String_Node_Str"").asString(),dbRecord.get(""String_Node_Str"").asString(),dbRecord.get(""String_Node_Str"").asString(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),path,FlowState.CACHED);
}"
37800,"/** 
 * Gets the flow path.
 * @param flowId the flowid
 * @param FlowPayload the Flow Payload
 * @return the flow path
 */
public static FlowPath getFlowPath(final String flowId,final FlowPayload flowPayload){
  PathInfoData pathInfo=new PathInfoData(setPath(flowPayload.getForward()),setPath(flowPayload.getReverse()));
  return new FlowPath(flowId,pathInfo);
}","/** 
 * Gets the flow path.
 * @param flowId the flowid
 * @param FlowPayload the Flow Payload
 * @return the flow path
 */
public FlowPath getFlowPath(final String flowId,final FlowPayload flowPayload){
  PathInfoData pathInfo=new PathInfoData(setPath(flowPayload.getForward()),setPath(flowPayload.getReverse()));
  return new FlowPath(flowId,pathInfo);
}"
37801,"/** 
 * Sets the path.
 * @param FlowPathInfoData the flow path info data
 * @return the {@link PathNode} list
 */
private static List<PathNode> setPath(final FlowPathInfoData flowPathInfoData){
  List<PathNode> pathNodes=new ArrayList<PathNode>();
  org.openkilda.integration.model.response.PathInfoData flowpath=flowPathInfoData.getFlowpath();
  List<org.openkilda.integration.model.response.PathNode> paths=flowpath.getPath();
  Integer inport=null;
  Integer seq_id=0;
  if (paths != null && !paths.isEmpty()) {
    for (    org.openkilda.integration.model.response.PathNode path : paths) {
      if (path.getSeqId() == 0) {
        pathNodes.add(new PathNode(seq_id,flowPathInfoData.getSrcPort(),path.getPortNo(),flowPathInfoData.getSrcSwitch()));
        seq_id++;
      }
 else {
        if (path.getSeqId() % 2 == 0) {
          pathNodes.add(new PathNode(seq_id,inport,path.getPortNo(),path.getSwitchId()));
          seq_id++;
        }
 else         inport=path.getPortNo();
      }
    }
  }
  pathNodes.add(new PathNode(seq_id,inport,flowPathInfoData.getDstPort(),flowPathInfoData.getDstSwitch()));
  return pathNodes;
}","/** 
 * Sets the path.
 * @param FlowPathInfoData the flow path info data
 * @return the {@link PathNode} list
 */
private List<PathNode> setPath(FlowPathInfoData flowPathInfoData){
  List<PathNode> pathNodes=new ArrayList<PathNode>();
  org.openkilda.integration.model.response.PathInfoData flowpath=flowPathInfoData.getFlowpath();
  List<org.openkilda.integration.model.response.PathNode> paths=flowpath.getPath();
  Integer inport=null;
  Integer seq_id=0;
  Map<String,String> csNames=switchIntegrationService.getCustomSwitchNameFromFile();
  if (paths != null && !paths.isEmpty()) {
    for (    org.openkilda.integration.model.response.PathNode path : paths) {
      if (path.getSeqId() == 1) {
        String switchName=switchIntegrationService.customSwitchName(csNames,flowPathInfoData.getSrcSwitch());
        pathNodes.add(new PathNode(seq_id,flowPathInfoData.getSrcPort(),path.getPortNo(),switchName));
        seq_id++;
      }
 else {
        if (path.getSeqId() % 2 == 1) {
          String switchName=switchIntegrationService.customSwitchName(csNames,path.getSwitchId());
          pathNodes.add(new PathNode(seq_id,inport,path.getPortNo(),switchName));
          seq_id++;
        }
 else         inport=path.getPortNo();
      }
    }
  }
  String switchName=switchIntegrationService.customSwitchName(csNames,flowPathInfoData.getDstSwitch());
  pathNodes.add(new PathNode(seq_id,inport,flowPathInfoData.getDstPort(),switchName));
  return pathNodes;
}"
37802,"/** 
 * Gets the flows.
 * @return the flows
 * @throws IntegrationException
 */
public List<FlowInfo> getFlows(){
  List<Flow> flowList=getAllFlowList();
  if (flowList != null) {
    List<FlowInfo> flows=FlowConverter.toFlowsInfo(flowList);
    if (!CollectionUtil.isEmpty(flows)) {
      flows.forEach(flowInfo -> {
        try {
          String status=getFlowStatus(flowInfo.getFlowid());
          flowInfo.setStatus(status);
        }
 catch (        Exception e) {
          LOGGER.error(""String_Node_Str"" + e,e);
        }
      }
);
    }
 else {
      throw new ContentNotFoundException();
    }
    return flows;
  }
  return null;
}","/** 
 * Gets the flows.
 * @return the flows
 * @throws IntegrationException
 */
public List<FlowInfo> getFlows(){
  List<Flow> flowList=getAllFlowList();
  if (flowList != null) {
    List<FlowInfo> flows=FlowConverter.toFlowsInfo(flowList);
    return flows;
  }
  return null;
}"
37803,"/** 
 * Gets the flow paths.
 * @return the flow paths
 * @throws IntegrationException
 */
public FlowPath getFlowPath(final String flowId){
  try {
    HttpResponse response=restClientManager.invoke(applicationProperties.getTopologyFlows() + ""String_Node_Str"" + flowId,HttpMethod.GET,""String_Node_Str"",""String_Node_Str"",""String_Node_Str"");
    if (RestClientManager.isValidResponse(response)) {
      FlowPayload flowPayload=restClientManager.getResponse(response,FlowPayload.class);
      return FlowPathConverter.getFlowPath(flowId,flowPayload);
    }
 else {
      String content=IoUtil.toString(response.getEntity().getContent());
      throw new InvalidResponseException(response.getStatusLine().getStatusCode(),content);
    }
  }
 catch (  Exception exception) {
    LOGGER.error(""String_Node_Str"" + exception.getMessage());
    throw new IntegrationException(exception);
  }
}","/** 
 * Gets the flow paths.
 * @return the flow paths
 * @throws IntegrationException
 */
public FlowPath getFlowPath(final String flowId){
  try {
    HttpResponse response=restClientManager.invoke(applicationProperties.getTopologyFlows() + ""String_Node_Str"" + flowId,HttpMethod.GET,""String_Node_Str"",""String_Node_Str"",""String_Node_Str"");
    if (RestClientManager.isValidResponse(response)) {
      FlowPayload flowPayload=restClientManager.getResponse(response,FlowPayload.class);
      return flowPathConverter.getFlowPath(flowId,flowPayload);
    }
 else {
      String content=IoUtil.toString(response.getEntity().getContent());
      throw new InvalidResponseException(response.getStatusLine().getStatusCode(),content);
    }
  }
 catch (  Exception exception) {
    LOGGER.error(""String_Node_Str"" + exception.getMessage());
    throw new IntegrationException(exception);
  }
}"
37804,"@SuppressWarnings(""String_Node_Str"") private Map<String,String> getCustomSwitchNameFromFile(){
  Map<String,String> csNames=new HashMap<String,String>();
  InputStream inputStream=null;
  String data=null;
  try {
    inputStream=new URL(applicationProperties.getSwitchDataFilePath()).openStream();
    if (inputStream != null) {
      data=IoUtil.toString(inputStream);
      if (data != null && !StringUtils.isEmpty(data)) {
        csNames=JsonUtil.toObject(data,HashMap.class);
      }
    }
  }
 catch (  Exception ex) {
    LOGGER.error(""String_Node_Str"",ex);
  }
  return csNames;
}","@SuppressWarnings(""String_Node_Str"") public Map<String,String> getCustomSwitchNameFromFile(){
  Map<String,String> csNames=new HashMap<String,String>();
  InputStream inputStream=null;
  String data=null;
  try {
    inputStream=new URL(applicationProperties.getSwitchDataFilePath()).openStream();
    if (inputStream != null) {
      data=IoUtil.toString(inputStream);
      if (data != null && !StringUtils.isEmpty(data)) {
        csNames=JsonUtil.toObject(data,HashMap.class);
      }
    }
  }
 catch (  Exception ex) {
    LOGGER.error(""String_Node_Str"",ex);
  }
  return csNames;
}"
37805,"/** 
 * Gets the SwitchInfoSetName.
 * @return the switches
 * @throws IntegrationException
 */
private List<SwitchInfo> getSwitchInfoSetName(List<SwitchInfo> switches){
  LOGGER.info(""String_Node_Str"");
  if (switches != null && !StringUtils.isEmpty(switches)) {
    Map<String,String> csNames=getCustomSwitchNameFromFile();
    for (    SwitchInfo switchInfo : switches) {
      String switchId=switchInfo.getSwitchId();
      if (csNames != null && !StringUtils.isEmpty(csNames) && csNames.size() > 0) {
        if (csNames.containsKey(switchId.toLowerCase()) || csNames.containsKey(switchId.toUpperCase())) {
          if (!IoUtil.chkStringIsNotEmpty(csNames.get(switchId))) {
            switchInfo.setName(switchId);
          }
 else {
            switchInfo.setName(csNames.get(switchId));
          }
        }
 else {
          switchInfo.setName(switchId);
        }
      }
 else       switchInfo.setName(switchId);
    }
  }
  return switches;
}","/** 
 * Gets the SwitchInfoSetName.
 * @return the switches
 * @throws IntegrationException
 */
private List<SwitchInfo> getSwitchInfoSetName(List<SwitchInfo> switches){
  LOGGER.info(""String_Node_Str"");
  if (switches != null && !StringUtils.isEmpty(switches)) {
    Map<String,String> csNames=getCustomSwitchNameFromFile();
    for (    SwitchInfo switchInfo : switches) {
      switchInfo.setName(customSwitchName(csNames,switchInfo.getSwitchId()));
    }
  }
  return switches;
}"
37806,"public FlowAdapter(Record dbRecord){
  String pathJson=dbRecord.get(""String_Node_Str"").asString();
  PathInfoData path;
  try {
    path=Utils.MAPPER.readValue(pathJson,PathInfoData.class);
  }
 catch (  IOException e) {
    throw new IllegalArgumentException(String.format(""String_Node_Str"",pathJson),e);
  }
  flow=new Flow(dbRecord.get(Utils.FLOW_ID).asString(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asBoolean(),dbRecord.get(""String_Node_Str"").asLong(),dbRecord.get(""String_Node_Str"").asString(),dbRecord.get(""String_Node_Str"").asString(),dbRecord.get(""String_Node_Str"").asString(),dbRecord.get(""String_Node_Str"").asString(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),path,FlowState.CACHED);
}","public FlowAdapter(Record dbRecord){
  String pathJson=dbRecord.get(""String_Node_Str"").asString();
  if (pathJson.equals(""String_Node_Str"")) {
    pathJson=""String_Node_Str"";
  }
  String remaining=pathJson.substring(2);
  PathInfoData path;
  pathJson=""String_Node_Str"" + remaining;
  try {
    path=Utils.MAPPER.readValue(pathJson,PathInfoData.class);
  }
 catch (  IOException e) {
    throw new IllegalArgumentException(String.format(""String_Node_Str"",pathJson),e);
  }
  flow=new Flow(dbRecord.get(Utils.FLOW_ID).asString(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asBoolean(),dbRecord.get(""String_Node_Str"").asLong(),dbRecord.get(""String_Node_Str"").asString(),dbRecord.get(""String_Node_Str"").asString(),dbRecord.get(""String_Node_Str"").asString(),dbRecord.get(""String_Node_Str"").asString(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),path,FlowState.CACHED);
}"
37807,"@Test public void getAllFlows(){
  try (Transaction tx=graphDb.beginTx()){
    Node node1, node2;
    node1=graphDb.createNode(Label.label(""String_Node_Str""));
    node1.setProperty(""String_Node_Str"",""String_Node_Str"");
    node2=graphDb.createNode(Label.label(""String_Node_Str""));
    node2.setProperty(""String_Node_Str"",""String_Node_Str"");
    Relationship rel1=node1.createRelationshipTo(node2,RelationshipType.withName(""String_Node_Str""));
    rel1.setProperty(""String_Node_Str"",""String_Node_Str"");
    rel1.setProperty(""String_Node_Str"",3);
    rel1.setProperty(""String_Node_Str"",2);
    rel1.setProperty(""String_Node_Str"",1);
    rel1.setProperty(""String_Node_Str"",""String_Node_Str"");
    rel1.setProperty(""String_Node_Str"",""String_Node_Str"");
    rel1.setProperty(""String_Node_Str"",1);
    rel1.setProperty(""String_Node_Str"",2);
    rel1.setProperty(""String_Node_Str"",5);
    rel1.setProperty(""String_Node_Str"",5);
    rel1.setProperty(""String_Node_Str"",200);
    rel1.setProperty(""String_Node_Str"",true);
    rel1.setProperty(""String_Node_Str"",""String_Node_Str"");
    rel1.setProperty(""String_Node_Str"",""String_Node_Str"");
    tx.success();
  }
   List<Flow> flows=target.getAllFlows();
  Flow flow=flows.get(0);
  Assert.assertEquals(3,flow.getCookie());
  Assert.assertEquals(""String_Node_Str"",flow.getFlowId());
  Assert.assertEquals(true,flow.isIgnoreBandwidth());
}","@Test public void getAllFlows(){
  try (Transaction tx=graphDb.beginTx()){
    Node node1, node2;
    node1=graphDb.createNode(Label.label(""String_Node_Str""));
    node1.setProperty(""String_Node_Str"",""String_Node_Str"");
    node2=graphDb.createNode(Label.label(""String_Node_Str""));
    node2.setProperty(""String_Node_Str"",""String_Node_Str"");
    Relationship rel1=node1.createRelationshipTo(node2,RelationshipType.withName(""String_Node_Str""));
    rel1.setProperty(""String_Node_Str"",""String_Node_Str"");
    rel1.setProperty(""String_Node_Str"",3);
    rel1.setProperty(""String_Node_Str"",2);
    rel1.setProperty(""String_Node_Str"",1);
    rel1.setProperty(""String_Node_Str"",""String_Node_Str"");
    rel1.setProperty(""String_Node_Str"",""String_Node_Str"");
    rel1.setProperty(""String_Node_Str"",1);
    rel1.setProperty(""String_Node_Str"",2);
    rel1.setProperty(""String_Node_Str"",5);
    rel1.setProperty(""String_Node_Str"",5);
    rel1.setProperty(""String_Node_Str"",""String_Node_Str"");
    rel1.setProperty(""String_Node_Str"",200);
    rel1.setProperty(""String_Node_Str"",true);
    rel1.setProperty(""String_Node_Str"",""String_Node_Str"");
    rel1.setProperty(""String_Node_Str"",""String_Node_Str"");
    tx.success();
  }
   List<Flow> flows=target.getAllFlows();
  Flow flow=flows.get(0);
  Assert.assertEquals(3,flow.getCookie());
  Assert.assertEquals(""String_Node_Str"",flow.getFlowId());
  Assert.assertEquals(true,flow.isIgnoreBandwidth());
}"
37808,"/** 
 * Compares the Flow from the DB to what is on each switch.
 * @param flowId id of flow to be rerouted.
 * @param correlationId correlation ID header value.
 * @return flow payload with updated path.
 */
@ApiOperation(value=""String_Node_Str"",response=FlowPathPayload.class) @ApiResponses(value={@ApiResponse(code=200,response=FlowPathPayload.class,message=""String_Node_Str""),@ApiResponse(code=400,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=401,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=403,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=404,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=500,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=503,response=MessageError.class,message=""String_Node_Str"")}) @RequestMapping(path=""String_Node_Str"",method=RequestMethod.GET) @ResponseStatus(HttpStatus.OK) public ResponseEntity<FlowValidationDto> validateFlow(@PathVariable(""String_Node_Str"") String flowId,@RequestHeader(value=CORRELATION_ID,defaultValue=DEFAULT_CORRELATION_ID) String correlationId){
  if (correlationId.equals(DEFAULT_CORRELATION_ID))   correlationId=getUniqueCorrelation();
  logger.debug(""String_Node_Str"",correlationId,flowId);
  FlowValidationDto result=flowService.validateFlow(flowId,correlationId);
  ResponseEntity<FlowValidationDto> response;
  if (result == null)   response=new ResponseEntity<>(null,new HttpHeaders(),HttpStatus.NOT_FOUND);
 else   response=new ResponseEntity<>(result,new HttpHeaders(),HttpStatus.OK);
  return response;
}","/** 
 * Compares the Flow from the DB to what is on each switch.
 * @param flowId id of flow to be rerouted.
 * @param correlationId correlation ID header value.
 * @return flow payload with updated path.
 */
@ApiOperation(value=""String_Node_Str"",response=FlowPathPayload.class) @ApiResponses(value={@ApiResponse(code=200,response=FlowPathPayload.class,message=""String_Node_Str""),@ApiResponse(code=400,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=401,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=403,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=404,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=500,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=503,response=MessageError.class,message=""String_Node_Str"")}) @RequestMapping(path=""String_Node_Str"",method=RequestMethod.GET) @ResponseStatus(HttpStatus.OK) public ResponseEntity<FlowValidationDto> validateFlow(@PathVariable(""String_Node_Str"") String flowId,@RequestHeader(value=CORRELATION_ID,defaultValue=DEFAULT_CORRELATION_ID) String correlationId){
}"
37809,"/** 
 * Performs validation of specific flow - ie comparing what is in the database with what is on the network.
 * @param flowId id of the flow
 * @param correlationId request correlation Id
 * @return the results of the comparison, or null if the flow isn't found.
 */
FlowValidationDto validateFlow(final String flowId,final String correlationId);","/** 
 * Performs validation of specific flow - ie comparing what is in the database with what is on the network.
 * @param flowId id of the flow
 * @param correlationId request correlation Id
 * @return the results of the comparison, or null if the flow isn't found.
 * @throws java.nio.file.InvalidPathException if the flow doesn't return a path and it should.
 */
FlowValidationDto validateFlow(final String flowId,final String correlationId);"
37810,"/** 
 * {@inheritDoc}
 */
@Override public FlowValidationDto validateFlow(final String flowId,final String correlationId){
  Flow flow=pathComputer.getFlow(flowId);
  if (flow == null)   return null;
  Set<String> switches=new HashSet<>();
  switches.add(flow.getSourceSwitch());
  for (  PathNode node : flow.getFlowPath().getPath()) {
    switches.add(node.getSwitchId());
  }
  switches.add(flow.getDestinationSwitch());
  Long ignoreCookie=0L;
  int correlation_iter=1;
  Map<String,SwitchFlowEntries> rules=new HashMap<>();
  for (  String switchid : switches) {
    String corr_id=correlationId + ""String_Node_Str"" + correlation_iter++;
    rules.put(switchid,switchService.getRules(switchid,ignoreCookie,corr_id));
  }
  List<PathDiscrepancyDto> discrepencies=new ArrayList<>();
  for (  String switchid : switches) {
    PathDiscrepancyDto disc=new PathDiscrepancyDto();
    disc.setField(""String_Node_Str"" + switchid);
    disc.setExpectedValue(""String_Node_Str"");
    int numRules=(rules.get(switchid) == null) ? 0 : rules.get(switchid).getFlowEntries().size();
    disc.setActualValue(""String_Node_Str"" + numRules);
    disc.setNode(new PathNode());
    discrepencies.add(disc);
  }
  FlowValidationDto result=new FlowValidationDto();
  result.setFlow(flow);
  result.setFlowId(flowId);
  result.setDiscrepancies(discrepencies);
  result.setAsExpected(discrepencies.size() > 0);
  return result;
}","/** 
 * {@inheritDoc}
 */
@Override public FlowValidationDto validateFlow(final String flowId,final String correlationId){
  Flow flow=pathComputer.getFlow(flowId);
  if (flow == null)   return null;
  logger.debug(""String_Node_Str"",flow);
  Set<String> switches=new HashSet<>();
  switches.add(flow.getSourceSwitch());
  if (flow.getFlowPath() == null) {
    throw new InvalidPathException(flowId,""String_Node_Str"");
  }
  for (  PathNode node : flow.getFlowPath().getPath()) {
    switches.add(node.getSwitchId());
  }
  switches.add(flow.getDestinationSwitch());
  Long ignoreCookie=0L;
  int correlation_iter=1;
  Map<String,SwitchFlowEntries> rules=new HashMap<>();
  for (  String switchid : switches) {
    String corr_id=correlationId + ""String_Node_Str"" + correlation_iter++;
    rules.put(switchid,switchService.getRules(switchid,ignoreCookie,corr_id));
  }
  List<PathDiscrepancyDto> discrepencies=new ArrayList<>();
  for (  String switchid : switches) {
    PathDiscrepancyDto disc=new PathDiscrepancyDto();
    disc.setField(""String_Node_Str"" + switchid);
    disc.setExpectedValue(""String_Node_Str"");
    int numRules=(rules.get(switchid) == null) ? 0 : rules.get(switchid).getFlowEntries().size();
    disc.setActualValue(""String_Node_Str"" + numRules);
    disc.setNode(new PathNode());
    discrepencies.add(disc);
  }
  FlowValidationDto result=new FlowValidationDto();
  result.setFlow(flow);
  result.setFlowId(flowId);
  result.setDiscrepancies(discrepencies);
  result.setAsExpected(discrepencies.size() > 0);
  return result;
}"
37811,"private void handleFlowEvent(FlowInfoData flowData,Tuple tuple) throws IOException {
switch (flowData.getOperation()) {
case PUSH:
    logger.debug(""String_Node_Str"",flowData);
  flowCache.putFlow(flowData.getPayload());
logger.info(""String_Node_Str"",flowData);
break;
case UNPUSH:
logger.debug(""String_Node_Str"",flowData);
String flowsId=flowData.getPayload().getLeft().getFlowId();
flowCache.removeFlow(flowsId);
reroutedFlows.remove(flowsId);
logger.info(""String_Node_Str"",flowData);
break;
case CREATE:
flowCache.putFlow(flowData.getPayload());
emitFlowMessage(flowData,tuple,flowData.getCorrelationId());
logger.info(""String_Node_Str"",flowData);
break;
case DELETE:
String flowsId=flowData.getPayload().getLeft().getFlowId();
flowCache.removeFlow(flowsId);
reroutedFlows.remove(flowsId);
emitFlowMessage(flowData,tuple,flowData.getCorrelationId());
logger.info(""String_Node_Str"",flowData);
break;
case UPDATE:
processFlowUpdate(flowData.getPayload().getLeft());
flowCache.putFlow(flowData.getPayload());
emitFlowMessage(flowData,tuple,flowData.getCorrelationId());
logger.info(""String_Node_Str"",flowData);
break;
case STATE:
flowCache.putFlow(flowData.getPayload());
logger.info(""String_Node_Str"",flowData);
break;
case CACHE:
break;
default :
logger.warn(""String_Node_Str"",flowData);
break;
}
}","private void handleFlowEvent(FlowInfoData flowData,Tuple tuple) throws IOException {
switch (flowData.getOperation()) {
case PUSH:
    logger.debug(""String_Node_Str"",flowData);
  flowCache.putFlow(flowData.getPayload());
logger.info(""String_Node_Str"",flowData);
break;
case UNPUSH:
logger.debug(""String_Node_Str"",flowData);
String flowsId2=flowData.getPayload().getLeft().getFlowId();
flowCache.removeFlow(flowsId2);
reroutedFlows.remove(flowsId2);
logger.info(""String_Node_Str"",flowData);
break;
case CREATE:
flowCache.putFlow(flowData.getPayload());
emitFlowMessage(flowData,tuple,flowData.getCorrelationId());
logger.info(""String_Node_Str"",flowData);
break;
case DELETE:
String flowsId=flowData.getPayload().getLeft().getFlowId();
flowCache.removeFlow(flowsId);
reroutedFlows.remove(flowsId);
emitFlowMessage(flowData,tuple,flowData.getCorrelationId());
logger.info(""String_Node_Str"",flowData);
break;
case UPDATE:
processFlowUpdate(flowData.getPayload().getLeft());
flowCache.putFlow(flowData.getPayload());
emitFlowMessage(flowData,tuple,flowData.getCorrelationId());
logger.info(""String_Node_Str"",flowData);
break;
case STATE:
flowCache.putFlow(flowData.getPayload());
logger.info(""String_Node_Str"",flowData);
break;
case CACHE:
break;
default :
logger.warn(""String_Node_Str"",flowData);
break;
}
}"
37812,"/** 
 * Installs egress flow on the switch.
 * @param message command message for flow installation
 */
private void doInstallEgressFlow(final CommandMessage message,String replyToTopic,Destination replyDestination) throws FlowCommandException {
  InstallEgressFlow command=(InstallEgressFlow)message.getData();
  logger.debug(""String_Node_Str"",command);
  try {
    context.getSwitchManager().installEgressFlow(DatapathId.of(command.getSwitchId()),command.getId(),command.getCookie(),command.getInputPort(),command.getOutputPort(),command.getTransitVlanId(),command.getOutputVlanId(),command.getOutputVlanType());
    message.setDestination(replyDestination);
    context.getKafkaProducer().postMessage(replyToTopic,message);
  }
 catch (  SwitchOperationException e) {
    throw new FlowCommandException(command.getId(),ErrorType.CREATION_FAILURE,e);
  }
}","/** 
 * Installs egress flow on the switch.
 * @param message command message for flow installation
 */
private void doInstallEgressFlow(final CommandMessage message,String replyToTopic,Destination replyDestination) throws FlowCommandException {
  InstallEgressFlow command=(InstallEgressFlow)message.getData();
  logger.debug(""String_Node_Str"",command);
  try {
    context.getSwitchManager().installEgressFlow(DatapathId.of(command.getSwitchId()),command.getId(),command.getCookie(),command.getInputPort(),command.getOutputPort(),command.getTransitVlanId(),command.getOutputVlanId(),command.getOutputVlanType());
    if (!StringUtils.isBlank(replyToTopic)) {
      message.setDestination(replyDestination);
      context.getKafkaProducer().postMessage(replyToTopic,message);
    }
  }
 catch (  SwitchOperationException e) {
    throw new FlowCommandException(command.getId(),ErrorType.CREATION_FAILURE,e);
  }
}"
37813,"private void doSyncRulesRequest(final CommandMessage message){
  InstallMissedFlowsRequest request=(InstallMissedFlowsRequest)message.getData();
  final String switchId=request.getSwitchId();
  logger.debug(""String_Node_Str"",switchId);
}","private void doSyncRulesRequest(final CommandMessage message) throws FlowCommandException {
  InstallMissedFlowsRequest request=(InstallMissedFlowsRequest)message.getData();
  final String switchId=request.getSwitchId();
  logger.debug(""String_Node_Str"",switchId);
  for (  BaseFlow installCommand : request.getFlowCommands()) {
    logger.debug(""String_Node_Str"",switchId,installCommand);
    handleCommand(message,installCommand,StringUtils.EMPTY,Destination.TOPOLOGY_ENGINE);
  }
}"
37814,"/** 
 * Installs flow through one switch.
 * @param message command message for flow installation
 */
private void doInstallOneSwitchFlow(final CommandMessage message,String replyToTopic,Destination replyDestination) throws FlowCommandException {
  InstallOneSwitchFlow command=(InstallOneSwitchFlow)message.getData();
  logger.debug(""String_Node_Str"",command);
  Long meterId=command.getMeterId();
  if (meterId == null) {
    logger.error(""String_Node_Str"",command.getCookie());
    meterId=(long)meterPool.allocate(command.getSwitchId(),command.getId());
    logger.error(""String_Node_Str"",meterId,command.getCookie());
  }
  try {
    context.getSwitchManager().installMeter(DatapathId.of(command.getSwitchId()),command.getBandwidth(),1024,meterId);
    OutputVlanType directOutputVlanType=command.getOutputVlanType();
    context.getSwitchManager().installOneSwitchFlow(DatapathId.of(command.getSwitchId()),command.getId(),command.getCookie(),command.getInputPort(),command.getOutputPort(),command.getInputVlanId(),command.getOutputVlanId(),directOutputVlanType,meterId);
    message.setDestination(replyDestination);
    context.getKafkaProducer().postMessage(replyToTopic,message);
  }
 catch (  SwitchOperationException e) {
    throw new FlowCommandException(command.getId(),ErrorType.CREATION_FAILURE,e);
  }
}","/** 
 * Installs flow through one switch.
 * @param message command message for flow installation
 */
private void doInstallOneSwitchFlow(final CommandMessage message,String replyToTopic,Destination replyDestination) throws FlowCommandException {
  InstallOneSwitchFlow command=(InstallOneSwitchFlow)message.getData();
  logger.debug(""String_Node_Str"",command);
  Long meterId=command.getMeterId();
  if (meterId == null) {
    logger.error(""String_Node_Str"",command.getCookie());
    meterId=(long)meterPool.allocate(command.getSwitchId(),command.getId());
    logger.error(""String_Node_Str"",meterId,command.getCookie());
  }
  try {
    context.getSwitchManager().installMeter(DatapathId.of(command.getSwitchId()),command.getBandwidth(),1024,meterId);
    OutputVlanType directOutputVlanType=command.getOutputVlanType();
    context.getSwitchManager().installOneSwitchFlow(DatapathId.of(command.getSwitchId()),command.getId(),command.getCookie(),command.getInputPort(),command.getOutputPort(),command.getInputVlanId(),command.getOutputVlanId(),directOutputVlanType,meterId);
    if (!StringUtils.isBlank(replyToTopic)) {
      message.setDestination(replyDestination);
      context.getKafkaProducer().postMessage(replyToTopic,message);
    }
  }
 catch (  SwitchOperationException e) {
    throw new FlowCommandException(command.getId(),ErrorType.CREATION_FAILURE,e);
  }
}"
37815,"protected void doControllerMsg(CommandMessage message){
  final String replyToTopic;
  if (message instanceof CommandWithReplyToMessage) {
    replyToTopic=((CommandWithReplyToMessage)message).getReplyTo();
  }
 else {
    replyToTopic=OUTPUT_FLOW_TOPIC;
  }
  final Destination replyDestination=getDestinationForTopic(replyToTopic);
  try {
    CommandData data=message.getData();
    if (data instanceof DiscoverIslCommandData) {
      doDiscoverIslCommand(data);
    }
 else     if (data instanceof DiscoverPathCommandData) {
      doDiscoverPathCommand(data);
    }
 else     if (data instanceof InstallIngressFlow) {
      doInstallIngressFlow(message,replyToTopic,replyDestination);
    }
 else     if (data instanceof InstallEgressFlow) {
      doInstallEgressFlow(message,replyToTopic,replyDestination);
    }
 else     if (data instanceof InstallTransitFlow) {
      doInstallTransitFlow(message,replyToTopic,replyDestination);
    }
 else     if (data instanceof InstallOneSwitchFlow) {
      doInstallOneSwitchFlow(message,replyToTopic,replyDestination);
    }
 else     if (data instanceof RemoveFlow) {
      doDeleteFlow(message,replyToTopic,replyDestination);
    }
 else     if (data instanceof NetworkCommandData) {
      doNetworkDump(message);
    }
 else     if (data instanceof SwitchRulesDeleteRequest) {
      doDeleteSwitchRules(message,replyToTopic,replyDestination);
    }
 else     if (data instanceof SwitchRulesInstallRequest) {
      doInstallSwitchRules(message,replyToTopic,replyDestination);
    }
 else     if (data instanceof ConnectModeRequest) {
      doConnectMode(message,replyToTopic,replyDestination);
    }
 else     if (data instanceof DumpRulesRequest) {
      doDumpRulesRequest(message);
    }
 else     if (data instanceof InstallMissedFlowsRequest) {
      doSyncRulesRequest(message);
    }
 else {
      logger.error(""String_Node_Str"",data.toString());
    }
  }
 catch (  FlowCommandException e) {
    ErrorMessage error=new ErrorMessage(e.makeErrorResponse(),System.currentTimeMillis(),message.getCorrelationId(),replyDestination);
    context.getKafkaProducer().postMessage(replyToTopic,error);
  }
catch (  Exception e) {
    logger.error(""String_Node_Str"",e);
  }
}","protected void doControllerMsg(CommandMessage message){
  final String replyToTopic;
  if (message instanceof CommandWithReplyToMessage) {
    replyToTopic=((CommandWithReplyToMessage)message).getReplyTo();
  }
 else {
    replyToTopic=OUTPUT_FLOW_TOPIC;
  }
  final Destination replyDestination=getDestinationForTopic(replyToTopic);
  try {
    CommandData data=message.getData();
    handleCommand(message,data,replyToTopic,replyDestination);
  }
 catch (  FlowCommandException e) {
    ErrorMessage error=new ErrorMessage(e.makeErrorResponse(),System.currentTimeMillis(),message.getCorrelationId(),replyDestination);
    context.getKafkaProducer().postMessage(replyToTopic,error);
  }
catch (  Exception e) {
    logger.error(""String_Node_Str"",e);
  }
}"
37816,"/** 
 * Installs ingress flow on the switch.
 * @param message command message for flow installation
 */
private void doInstallIngressFlow(final CommandMessage message,String replyToTopic,Destination replyDestination) throws FlowCommandException {
  InstallIngressFlow command=(InstallIngressFlow)message.getData();
  logger.debug(""String_Node_Str"",command);
  Long meterId=command.getMeterId();
  if (meterId == null) {
    logger.error(""String_Node_Str"",command.getCookie());
    meterId=(long)meterPool.allocate(command.getSwitchId(),command.getId());
    logger.error(""String_Node_Str"",meterId,command.getCookie());
  }
  try {
    context.getSwitchManager().installMeter(DatapathId.of(command.getSwitchId()),command.getBandwidth(),1024,meterId);
    context.getSwitchManager().installIngressFlow(DatapathId.of(command.getSwitchId()),command.getId(),command.getCookie(),command.getInputPort(),command.getOutputPort(),command.getInputVlanId(),command.getTransitVlanId(),command.getOutputVlanType(),meterId);
    message.setDestination(replyDestination);
    context.getKafkaProducer().postMessage(replyToTopic,message);
  }
 catch (  SwitchOperationException e) {
    throw new FlowCommandException(command.getId(),ErrorType.CREATION_FAILURE,e);
  }
}","/** 
 * Installs ingress flow on the switch.
 * @param message command message for flow installation
 */
private void doInstallIngressFlow(final CommandMessage message,String replyToTopic,Destination replyDestination) throws FlowCommandException {
  InstallIngressFlow command=(InstallIngressFlow)message.getData();
  logger.debug(""String_Node_Str"",command);
  Long meterId=command.getMeterId();
  if (meterId == null) {
    logger.error(""String_Node_Str"",command.getCookie());
    meterId=(long)meterPool.allocate(command.getSwitchId(),command.getId());
    logger.error(""String_Node_Str"",meterId,command.getCookie());
  }
  try {
    context.getSwitchManager().installMeter(DatapathId.of(command.getSwitchId()),command.getBandwidth(),1024,meterId);
    context.getSwitchManager().installIngressFlow(DatapathId.of(command.getSwitchId()),command.getId(),command.getCookie(),command.getInputPort(),command.getOutputPort(),command.getInputVlanId(),command.getTransitVlanId(),command.getOutputVlanType(),meterId);
    if (!StringUtils.isBlank(replyToTopic)) {
      message.setDestination(replyDestination);
      context.getKafkaProducer().postMessage(replyToTopic,message);
    }
  }
 catch (  SwitchOperationException e) {
    throw new FlowCommandException(command.getId(),ErrorType.CREATION_FAILURE,e);
  }
}"
37817,"private void doDumpRulesRequest(final CommandMessage message){
  DumpRulesRequest request=(DumpRulesRequest)message.getData();
  final String switchId=request.getSwitchId();
  logger.debug(""String_Node_Str"",switchId);
  OFFlowStatsReply reply=context.getSwitchManager().dumpFlowTable(DatapathId.of(switchId));
  List<FlowEntry> flows=reply.getEntries().stream().map(OFFlowStatsConverter::toFlowEntry).collect(Collectors.toList());
  SwitchFlowEntries response=SwitchFlowEntries.builder().switchId(switchId).flowEntries(flows).build();
  InfoMessage infoMessage=new InfoMessage(response,message.getTimestamp(),message.getCorrelationId());
  context.getKafkaProducer().postMessage(OUTPUT_FLOW_TOPIC,infoMessage);
}","private void doDumpRulesRequest(final CommandMessage message){
  DumpRulesRequest request=(DumpRulesRequest)message.getData();
  final String switchId=request.getSwitchId();
  logger.debug(""String_Node_Str"",switchId);
  OFFlowStatsReply reply=context.getSwitchManager().dumpFlowTable(DatapathId.of(switchId));
  List<FlowEntry> flows=reply.getEntries().stream().map(OFFlowStatsConverter::toFlowEntry).collect(Collectors.toList());
  SwitchFlowEntries response=SwitchFlowEntries.builder().switchId(switchId).flowEntries(flows).build();
  InfoMessage infoMessage=new InfoMessage(response,message.getTimestamp(),message.getCorrelationId());
  context.getKafkaProducer().postMessage(TOPO_ENG_TOPIC,infoMessage);
}"
37818,"/** 
 * Installs transit flow on the switch.
 * @param message command message for flow installation
 */
private void doInstallTransitFlow(final CommandMessage message,String replyToTopic,Destination replyDestination) throws FlowCommandException {
  InstallTransitFlow command=(InstallTransitFlow)message.getData();
  logger.debug(""String_Node_Str"",command);
  try {
    context.getSwitchManager().installTransitFlow(DatapathId.of(command.getSwitchId()),command.getId(),command.getCookie(),command.getInputPort(),command.getOutputPort(),command.getTransitVlanId());
    message.setDestination(replyDestination);
    context.getKafkaProducer().postMessage(replyToTopic,message);
  }
 catch (  SwitchOperationException e) {
    throw new FlowCommandException(command.getId(),ErrorType.CREATION_FAILURE,e);
  }
}","/** 
 * Installs transit flow on the switch.
 * @param message command message for flow installation
 */
private void doInstallTransitFlow(final CommandMessage message,String replyToTopic,Destination replyDestination) throws FlowCommandException {
  InstallTransitFlow command=(InstallTransitFlow)message.getData();
  logger.debug(""String_Node_Str"",command);
  try {
    context.getSwitchManager().installTransitFlow(DatapathId.of(command.getSwitchId()),command.getId(),command.getCookie(),command.getInputPort(),command.getOutputPort(),command.getTransitVlanId());
    if (!StringUtils.isBlank(replyToTopic)) {
      message.setDestination(replyDestination);
      context.getKafkaProducer().postMessage(replyToTopic,message);
    }
  }
 catch (  SwitchOperationException e) {
    throw new FlowCommandException(command.getId(),ErrorType.CREATION_FAILURE,e);
  }
}"
37819,"@After public void verifyMocks(){
  verify(topologyEngineService).getActiveSwitches();
  verify(topologyEngineService).getActiveLinks();
  verify(topologyDefinition,times(3)).getActiveSwitches();
  verify(topologyDefinition).getIslsForActiveSwitches();
}","@After public void verifyMocks(){
  verify(topologyEngineService).getActiveSwitches();
  verify(topologyEngineService).getActiveLinks();
  verify(topologyDefinition,times(2)).getActiveSwitches();
  verify(topologyDefinition).getIslsForActiveSwitches();
}"
37820,"private void handleCacheSyncRequest(CommandMessage message,Tuple tuple) throws IOException {
  logger.info(""String_Node_Str"",message);
  List<String> droppedFlows=new ArrayList<>();
  List<String> addedFlows=new ArrayList<>();
  List<String> modifiedFlows=new ArrayList<>();
  List<String> unchangedFlows=new ArrayList<>();
  List<FlowInfo> flowInfos=pathComputer.getFlowInfo();
  HashMap<String,FlowInfo> flowToInfo=new HashMap<>();
  for (  FlowInfo fi : flowInfos) {
    flowToInfo.put(fi.getFlowId(),fi);
  }
  for (  FlowInfo fi : flowInfos) {
    String flowid=fi.getFlowId();
    if (flowCache.cacheContainsFlow(flowid)) {
      ImmutablePair<Flow,Flow> fc=flowCache.getFlow(flowid);
      if (fi.getCookie() != fc.left.getCookie() || fi.getMeterId() != fc.left.getMeterId() || fi.getTransitVlanId() != fc.left.getTransitVlan() || fi.getSrcSwitchId() != fc.left.getSourceSwitch()) {
        modifiedFlows.add(MAPPER.writeValueAsString(fc));
      }
 else {
        unchangedFlows.add(flowid);
      }
    }
 else {
      addedFlows.add(flowid);
    }
  }
  for (  ImmutablePair<Flow,Flow> flow : flowCache.dumpFlows()) {
    String flowid=flow.left.getFlowId();
    if (!flowToInfo.containsKey(flowid)) {
      String removedFlow=flowCache.removeFlow(flowid).toString();
      String asJson=MAPPER.writeValueAsString(removedFlow);
      droppedFlows.add(asJson);
    }
  }
  FlowCacheSyncResults results=new FlowCacheSyncResults(droppedFlows.toArray(new String[0]),addedFlows.toArray(new String[0]),modifiedFlows.toArray(new String[0]),unchangedFlows.toArray(new String[0]));
  Values northbound=new Values(new InfoMessage(new FlowCacheSyncResponse(results),message.getTimestamp(),message.getCorrelationId(),Destination.NORTHBOUND));
  outputCollector.emit(StreamType.RESPONSE.toString(),tuple,northbound);
}","private void handleCacheSyncRequest(CommandMessage message,Tuple tuple) throws IOException {
  logger.info(""String_Node_Str"",message);
  List<String> droppedFlows=new ArrayList<>();
  List<String> addedFlows=new ArrayList<>();
  List<String> modifiedFlows=new ArrayList<>();
  List<String> unchangedFlows=new ArrayList<>();
  List<FlowInfo> flowInfos=pathComputer.getFlowInfo();
  HashMap<String,FlowInfo> flowToInfo=new HashMap<>();
  for (  FlowInfo fi : flowInfos) {
    flowToInfo.put(fi.getFlowId() + fi.getCookie(),fi);
  }
  for (  FlowInfo fi : flowInfos) {
    String flowid=fi.getFlowId();
    if (flowCache.cacheContainsFlow(flowid)) {
      ImmutablePair<Flow,Flow> fc=flowCache.getFlow(flowid);
      int count=modifiedFlows.size();
      if (fi.getCookie() != fc.left.getCookie() && fi.getCookie() != fc.right.getCookie())       modifiedFlows.add(""String_Node_Str"" + flowid + ""String_Node_Str""+ fi.getCookie()+ ""String_Node_Str""+ fc.left.getCookie()+ ""String_Node_Str""+ fc.right.getCookie());
      if (fi.getMeterId() != fc.left.getMeterId() && fi.getMeterId() != fc.right.getMeterId())       modifiedFlows.add(""String_Node_Str"" + flowid + ""String_Node_Str""+ fi.getMeterId()+ ""String_Node_Str""+ fc.left.getMeterId()+ ""String_Node_Str""+ fc.right.getMeterId());
      if (fi.getTransitVlanId() != fc.left.getTransitVlan() && fi.getTransitVlanId() != fc.right.getTransitVlan())       modifiedFlows.add(""String_Node_Str"" + flowid + ""String_Node_Str""+ fi.getTransitVlanId()+ ""String_Node_Str""+ fc.left.getTransitVlan()+ ""String_Node_Str""+ fc.right.getTransitVlan());
      if (!fi.getSrcSwitchId().equals(fc.left.getSourceSwitch()) && !fi.getSrcSwitchId().equals(fc.right.getSourceSwitch()))       modifiedFlows.add(""String_Node_Str"" + flowid + ""String_Node_Str""+ fi.getSrcSwitchId()+ ""String_Node_Str""+ fc.left.getSourceSwitch()+ ""String_Node_Str""+ fc.right.getSourceSwitch());
      if (count == modifiedFlows.size())       unchangedFlows.add(flowid);
    }
 else {
      addedFlows.add(flowid);
    }
  }
  for (  ImmutablePair<Flow,Flow> flow : flowCache.dumpFlows()) {
    String key=flow.left.getFlowId() + flow.left.getCookie();
    if (!flowToInfo.containsKey(key)) {
      droppedFlows.add(flow.left.getFlowId());
    }
 else {
      key=flow.right.getFlowId() + flow.right.getCookie();
      if (!flowToInfo.containsKey(key)) {
        droppedFlows.add(flow.right.getFlowId());
      }
    }
  }
  FlowCacheSyncResults results=new FlowCacheSyncResults(droppedFlows.toArray(new String[0]),addedFlows.toArray(new String[0]),modifiedFlows.toArray(new String[0]),unchangedFlows.toArray(new String[0]));
  Values northbound=new Values(new InfoMessage(new FlowCacheSyncResponse(results),message.getTimestamp(),message.getCorrelationId(),Destination.NORTHBOUND));
  outputCollector.emit(StreamType.RESPONSE.toString(),tuple,northbound);
}"
37821,"@Override public StormTopology createTopology() throws NameCollisionException {
}","@Override public StormTopology createTopology() throws NameCollisionException {
  final String clazzName=this.getClass().getSimpleName();
  logger.debug(""String_Node_Str"",clazzName);
  TopologyBuilder builder=new TopologyBuilder();
  String topoDiscoTopic=config.getKafkaTopoDiscoTopic();
  checkAndCreateTopic(topoDiscoTopic);
  logger.debug(""String_Node_Str"",topoDiscoTopic);
  builder.setSpout(TOPO_DISCO_SPOUT,createKafkaSpout(topoDiscoTopic,clazzName + topoDiscoTopic));
  TopoDiscoParseBolt topoDiscoParseBolt=new TopoDiscoParseBolt();
  builder.setBolt(TOPO_DISCO_PARSE_BOLT_NAME,topoDiscoParseBolt,config.getParallelism()).shuffleGrouping(TopoDiscoParseBolt.TOPO_TO_PORT_INFO_STREAM,PARSE_PORT_INFO_BOLT_NAME);
  ParsePortInfoBolt parsePortInfoBolt=new ParsePortInfoBolt();
  builder.setBolt(PARSE_PORT_INFO_BOLT_NAME,parsePortInfoBolt,config.getParallelism()).shuffleGrouping(TopoDiscoParseBolt.TOPO_TO_PORT_INFO_STREAM,TOPO_DISCO_PARSE_BOLT_NAME).shuffleGrouping(WfmStatsParseBolt.WFM_TO_PARSE_PORT_INFO_STREAM,WFM_STATS_PARSE_BOLT_NAME);
  final String openTsdbTopic=config.getKafkaOtsdbTopic();
  checkAndCreateTopic(openTsdbTopic);
  KafkaBolt openTsdbBolt=createKafkaBolt(openTsdbTopic);
  builder.setBolt(OtsdbKafkaBoltName,openTsdbBolt,config.getParallelism()).shuffleGrouping(PARSE_PORT_INFO_BOLT_NAME);
  String wfmStatsTopic=config.getKafkaStatsTopic();
  checkAndCreateTopic(wfmStatsTopic);
  logger.debug(""String_Node_Str"",wfmStatsTopic);
  builder.setSpout(WFM_STATS_SPOUT,createKafkaSpout(wfmStatsTopic,clazzName + wfmStatsTopic));
  WfmStatsParseBolt wfmStatsParseBolt=new WfmStatsParseBolt();
  builder.setBolt(WFM_STATS_PARSE_BOLT_NAME,wfmStatsParseBolt,config.getParallelism()).shuffleGrouping(WFM_STATS_SPOUT);
  SwitchPortsSpout switchPortsSpout=new SwitchPortsSpout(JANITOR_REFRESH);
  builder.setSpout(SWITCH_PORTS_SPOUT_NAME,switchPortsSpout);
  final String speakerTopic=config.getKafkaSpeakerTopic();
  checkAndCreateTopic(speakerTopic);
  KafkaBolt speakerBolt=createKafkaBolt(speakerTopic);
  builder.setBolt(SpeakerBoltName,speakerBolt,config.getParallelism()).shuffleGrouping(SWITCH_PORTS_SPOUT_NAME);
  return builder.createTopology();
}"
37822,"@Override public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer){
  outputFieldsDeclarer.declareStream(PARSE_PORT_INFO_STREAM,new Fields(FIELD_NAME));
}","@Override public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer){
  outputFieldsDeclarer.declareStream(TOPO_TO_PORT_INFO_STREAM,new Fields(FIELD_NAME));
}"
37823,"private void doParseMessage(Tuple tuple){
  try {
    InfoData infoData=getInfoData(tuple);
    if (infoData instanceof PortInfoData) {
      collector.emit(PARSE_PORT_INFO_STREAM,new Values((PortInfoData)infoData));
    }
  }
 catch (  IOException e) {
    logger.error(""String_Node_Str"",tuple.toString(),e);
  }
catch (  MessageException e) {
  }
 finally {
    collector.ack(tuple);
  }
}","private void doParseMessage(Tuple tuple){
  try {
    InfoData infoData=getInfoData(tuple);
    if (infoData instanceof PortInfoData) {
      collector.emit(TOPO_TO_PORT_INFO_STREAM,new Values((PortInfoData)infoData));
    }
  }
 catch (  IOException e) {
    logger.error(""String_Node_Str"",tuple.toString(),e);
  }
catch (  MessageException e) {
  }
 finally {
    collector.ack(tuple);
  }
}"
37824,"/** 
 * Chk string is not empty.
 * @param value the value
 * @return true, if successful
 */
public static boolean chkStringIsNotEmpty(Object value){
  boolean flag=false;
  if (value != null) {
    String string=String.valueOf(value);
    if (string != null && !""String_Node_Str"".equalsIgnoreCase(string.trim()) && string.length() > 0 && !""String_Node_Str"".equalsIgnoreCase(string)) {
      flag=true;
    }
  }
  return flag;
}","/** 
 * Chk string is not empty.
 * @param value the value
 * @return true, if successful
 */
public static boolean chkStringIsNotEmpty(String value){
  if (value != null) {
    Predicate<String> predicates=s -> {
      return value.trim().length() > 0;
    }
;
    return predicates.test(value);
  }
  return false;
}"
37825,"@Override public void execute(Tuple input){
  StatsComponentType componentId=StatsComponentType.valueOf(input.getSourceComponent());
  InfoMessage message=(InfoMessage)input.getValueByField(MESSAGE_FIELD);
  if (!Destination.WFM_STATS.equals(message.getDestination())) {
    collector.ack(input);
    return;
  }
  LOGGER.debug(""String_Node_Str"",CORRELATION_ID,message.getCorrelationId(),componentId,StatsStreamType.valueOf(input.getSourceStreamId()));
  PortStatsData data=(PortStatsData)message.getData();
  long timestamp=message.getTimestamp();
  try {
    String switchId=data.getSwitchId().replaceAll(""String_Node_Str"",""String_Node_Str"");
    for (    PortStatsReply reply : data.getStats()) {
      for (      PortStatsEntry entry : reply.getEntries()) {
        emit(entry,timestamp,switchId);
      }
    }
  }
  finally {
    collector.ack(input);
  }
}","@Override public void execute(Tuple input){
  StatsComponentType componentId=StatsComponentType.valueOf(input.getSourceComponent());
  InfoMessage message=(InfoMessage)input.getValueByField(MESSAGE_FIELD);
  if (!Destination.WFM_STATS.equals(message.getDestination())) {
    collector.ack(input);
    return;
  }
  LOGGER.debug(""String_Node_Str"",CORRELATION_ID,message.getCorrelationId(),componentId,StatsStreamType.valueOf(input.getSourceStreamId()));
  PortStatsData data=(PortStatsData)message.getData();
  long timestamp=message.getTimestamp();
  try {
    String switchId=switchNameCache.get(data.getSwitchId());
    if (switchId == null) {
      switchId=""String_Node_Str"" + data.getSwitchId().replaceAll(""String_Node_Str"",""String_Node_Str"").toUpperCase();
      switchNameCache.put(data.getSwitchId(),switchId);
    }
    for (    PortStatsReply reply : data.getStats()) {
      for (      PortStatsEntry entry : reply.getEntries()) {
        emit(entry,timestamp,switchId);
      }
    }
  }
  finally {
    collector.ack(input);
  }
}"
37826,"public void handleFailed(String switchId,String portId){
  Node node=new Node(switchId,portId);
  List<DiscoveryNode> subjectList=filterQueue(node);
  if (subjectList.size() == 0) {
    logger.warn(""String_Node_Str"",node);
  }
 else {
    DiscoveryNode subject=subjectList.get(0);
    subject.countFailure();
    logger.info(""String_Node_Str"",subject);
  }
}","/** 
 * ISL Failure Event
 * @return true if this is new .. ie this isn't a consecutive failure.
 */
public boolean handleFailed(String switchId,String portId){
  boolean stateChanged=false;
  Node node=new Node(switchId,portId);
  List<DiscoveryNode> subjectList=filterQueue(node);
  if (subjectList.size() == 0) {
    logger.warn(""String_Node_Str"",node);
  }
 else {
    DiscoveryNode subject=subjectList.get(0);
    if (subject.isFoundIsl() && subject.getConsecutiveFailure() == 0) {
      stateChanged=true;
      logger.info(""String_Node_Str"",subject);
    }
    subject.renew();
    subject.incConsecutiveFailure();
    subject.clearConsecutiveSuccess();
  }
  return stateChanged;
}"
37827,"public Plan makeDiscoveryPlan(){
  Plan result=new Plan();
  for (  DiscoveryNode subject : pollQueue) {
    Node node=new Node(subject.getSwitchId(),subject.getPortId());
    if (subject.forlorn()) {
      continue;
    }
 else     if (subject.isStale(consecutiveLostTillFail) && subject.timeToCheck()) {
      result.discoveryFailure.add(node);
      subject.resetTickCounter();
      continue;
    }
 else     if (subject.isStale(consecutiveLostTillFail) && !subject.timeToCheck()) {
      subject.logTick();
      continue;
    }
    if (filter.isMatch(subject)) {
      logger.debug(""String_Node_Str"",subject);
      subject.renew();
      subject.resetTickCounter();
      continue;
    }
    subject.incAge();
    subject.resetTickCounter();
    result.needDiscovery.add(node);
  }
  return result;
}","/** 
 * The discovery plan takes into consideration multiple metrics to determine what should be discovered. At present, we want to send Discovery health checks on every ISL every x period. And, if the Discovery fails (either isn't an ISL or ISL is down) then we may want to give up checking. General algorithm: 1) if the node is an ISL (isFoundIsl) .. and is UP .. keep checking 2) if the node is not an ISL (ie !isFoundIsl), then check less frequently 3) if the node is an ISL .. and is DOWN .. keep checking
 */
public Plan makeDiscoveryPlan(){
  Plan result=new Plan();
  for (  DiscoveryNode subject : pollQueue) {
    if (filter.isMatch(subject)) {
      logger.debug(""String_Node_Str"",subject);
      subject.renew();
      subject.resetTickCounter();
      continue;
    }
    if (subject.forlorn()) {
      continue;
    }
    Node node=new Node(subject.getSwitchId(),subject.getPortId());
    if (subject.maxAttempts(consecutiveLostTillFail)) {
      if (subject.isFoundIsl() && subject.getConsecutiveFailure() == 0) {
        result.discoveryFailure.add(node);
        logger.info(""String_Node_Str"",subject);
      }
      subject.incConsecutiveFailure();
    }
    if (subject.timeToCheck()) {
      subject.incAttempts();
      subject.resetTickCounter();
      result.needDiscovery.add(node);
    }
 else {
      subject.logTick();
    }
  }
  return result;
}"
37828,"public void handleDiscovered(String switchId,String portId){
  Node node=new Node(switchId,portId);
  List<DiscoveryNode> subjectList=filterQueue(node);
  if (subjectList.size() == 0) {
    logger.warn(""String_Node_Str"",node);
  }
 else {
    DiscoveryNode subject=subjectList.get(0);
    subject.renew();
    logger.info(""String_Node_Str"",subject);
  }
}","/** 
 * ISL Discovery Event
 * @return true if this is a new event (ie first time discovered or prior failure)
 */
public boolean handleDiscovered(String switchId,String portId){
  boolean stateChanged=false;
  Node node=new Node(switchId,portId);
  List<DiscoveryNode> subjectList=filterQueue(node);
  if (subjectList.size() == 0) {
    logger.warn(""String_Node_Str"",node);
  }
 else {
    DiscoveryNode subject=subjectList.get(0);
    if (!subject.isFoundIsl()) {
      subject.setFoundIsl(true);
      stateChanged=true;
      logger.info(""String_Node_Str"",subject);
    }
    if (subject.getConsecutiveFailure() > 0) {
      stateChanged=true;
      logger.info(""String_Node_Str"",subject);
    }
    subject.renew();
    subject.incConsecutiveSuccess();
    subject.clearConsecutiveFailure();
  }
  return stateChanged;
}"
37829,"public boolean forlorn(){
  if (forlornThreshold == NEVER) {
    return false;
  }
  return consecutiveFailures >= forlornThreshold;
}","public boolean forlorn(){
  if (forlornThreshold == NEVER) {
    return false;
  }
  return consecutiveFailure >= forlornThreshold;
}"
37830,"@Override public String toString(){
  return ""String_Node_Str"" + ""String_Node_Str"" + switchId + '\''+ ""String_Node_Str""+ portId+ '\''+ ""String_Node_Str""+ age+ '}';
}","@Override public String toString(){
  return ""String_Node_Str"" + ""String_Node_Str"" + switchId + '\''+ ""String_Node_Str""+ portId+ '\''+ ""String_Node_Str""+ attempts+ ""String_Node_Str""+ consecutiveFailure+ ""String_Node_Str""+ consecutiveSuccess+ '}';
}"
37831,"public void renew(){
  age=0;
  timeCounter=0;
}","/** 
 * Whereas renew is called when a successful Discovery is received, it isn't the place to put ""foundIsl"". This is out of fear that renew() could be called from somewhere else. The semantics of ""renew"" doesn't say ""found ISL""
 */
public void renew(){
  attempts=0;
  timeCounter=0;
}"
37832,"private void handleIslEvent(Tuple tuple,IslInfoData discoveredIsl){
  PathNode node=discoveredIsl.getPath().get(0);
  String switchID=node.getSwitchId();
  String portID=""String_Node_Str"" + node.getPortNo();
  IslChangeType state=discoveredIsl.getState();
  logger.info(""String_Node_Str"",switchID,portID,state);
  if (IslChangeType.DISCOVERED.equals(state)) {
    discovery.handleDiscovered(switchID,portID);
  }
 else   if (IslChangeType.FAILED.equals(state)) {
    discovery.handleFailed(switchID,portID);
  }
 else {
    logger.warn(""String_Node_Str"",state);
  }
  String json=tuple.getString(0);
  collector.emit(topoEngTopic,tuple,new Values(PAYLOAD,json));
}","private void handleIslEvent(Tuple tuple,IslInfoData discoveredIsl){
  PathNode node=discoveredIsl.getPath().get(0);
  String switchID=node.getSwitchId();
  String portID=""String_Node_Str"" + node.getPortNo();
  IslChangeType state=discoveredIsl.getState();
  boolean stateChanged=false;
  if (IslChangeType.DISCOVERED.equals(state)) {
    stateChanged=discovery.handleDiscovered(switchID,portID);
  }
 else   if (IslChangeType.FAILED.equals(state)) {
    stateChanged=discovery.handleFailed(switchID,portID);
  }
 else {
    logger.warn(""String_Node_Str"",state);
  }
  if (stateChanged) {
    logger.info(""String_Node_Str"",switchID,portID,state);
    String json=tuple.getString(0);
    collector.emit(topoEngTopic,tuple,new Values(PAYLOAD,json));
  }
}"
37833,"@Override public void run(){
  while (true) {
    KafkaConsumer<String,String> consumer=null;
    try {
      consumer=new KafkaConsumer<>(kafkaProps);
      consumer.subscribe(topics);
      while (true) {
        ConsumerRecords<String,String> records=consumer.poll(100);
        logger.debug(""String_Node_Str"",records.count());
        for (        ConsumerRecord<String,String> record : records) {
          logger.trace(""String_Node_Str"",record.offset(),record.value());
          parseRecordExecutor.execute(new ParseRecord(record));
        }
      }
    }
 catch (    Exception e) {
      logger.error(""String_Node_Str"",e);
      if (consumer != null) {
        consumer.close();
      }
    }
  }
}","@Override public void run(){
  while (true) {
    KafkaConsumer<String,String> consumer=null;
    try {
      consumer=new KafkaConsumer<>(kafkaProps);
      consumer.subscribe(topics);
      while (true) {
        ConsumerRecords<String,String> records=consumer.poll(100);
        if (records.count() > 0)         logger.debug(""String_Node_Str"",records.count());
        for (        ConsumerRecord<String,String> record : records) {
          logger.trace(""String_Node_Str"",record.offset(),record.value());
          parseRecordExecutor.execute(new ParseRecord(record));
        }
      }
    }
 catch (    Exception e) {
      logger.error(""String_Node_Str"",e);
      if (consumer != null) {
        consumer.close();
      }
    }
  }
}"
37834,"@Override public boolean sendDiscoveryMessage(DatapathId srcSwId,OFPort port,DatapathId dstSwId){
  IOFSwitch srcSwitch=switchService.getSwitch(srcSwId);
  if (srcSwitch == null) {
    return false;
  }
  if (dstSwId == null) {
    return srcSwitch.write(generateVerificationPacket(srcSwitch,port));
  }
  IOFSwitch dstSwitch=switchService.getSwitch(dstSwId);
  OFPacketOut ofPacketOut=generateVerificationPacket(srcSwitch,port,dstSwitch);
  logger.debug(""String_Node_Str"",srcSwitch.getId().toString(),port.getPortNumber(),Hex.encodeHexString(ofPacketOut.getData()));
  return srcSwitch.write(ofPacketOut);
}","@Override public boolean sendDiscoveryMessage(DatapathId srcSwId,OFPort port,DatapathId dstSwId){
  IOFSwitch srcSwitch=switchService.getSwitch(srcSwId);
  if (srcSwitch == null || srcSwitch.getPort(port) == null) {
    return false;
  }
  if (dstSwId == null) {
    return srcSwitch.write(generateVerificationPacket(srcSwitch,port));
  }
  IOFSwitch dstSwitch=switchService.getSwitch(dstSwId);
  OFPacketOut ofPacketOut=generateVerificationPacket(srcSwitch,port,dstSwitch);
  logger.debug(""String_Node_Str"",srcSwitch.getId().toString(),port.getPortNumber(),Hex.encodeHexString(ofPacketOut.getData()));
  return srcSwitch.write(ofPacketOut);
}"
37835,"public OFPacketOut generateVerificationPacket(IOFSwitch srcSw,OFPort port,IOFSwitch dstSw,boolean sign){
  try {
    OFPortDesc ofPortDesc=srcSw.getPort(port);
    byte[] chassisId=new byte[]{4,0,0,0,0,0,0};
    byte[] portId=new byte[]{2,0,0};
    byte[] ttlValue=new byte[]{0,0x78};
    byte[] dpidTLVValue=new byte[]{0x0,0x26,(byte)0xe1,0,0,0,0,0,0,0,0,0};
    LLDPTLV dpidTLV=new LLDPTLV().setType((byte)127).setLength((short)dpidTLVValue.length).setValue(dpidTLVValue);
    byte[] dpidArray=new byte[8];
    ByteBuffer dpidBB=ByteBuffer.wrap(dpidArray);
    ByteBuffer portBB=ByteBuffer.wrap(portId,1,2);
    DatapathId dpid=srcSw.getId();
    dpidBB.putLong(dpid.getLong());
    System.arraycopy(dpidArray,2,chassisId,1,6);
    System.arraycopy(dpidArray,0,dpidTLVValue,4,8);
    byte[] srcMac=ofPortDesc.getHwAddr().getBytes();
    byte[] zeroMac={0,0,0,0,0,0};
    if (Arrays.equals(srcMac,zeroMac)) {
      logger.warn(""String_Node_Str"",dpid.toString(),ofPortDesc.getPortNo().getPortNumber());
      System.arraycopy(dpidArray,2,srcMac,0,6);
    }
    portBB.putShort(port.getShortPortNumber());
    VerificationPacket vp=new VerificationPacket();
    vp.setChassisId(new LLDPTLV().setType((byte)1).setLength((short)chassisId.length).setValue(chassisId));
    vp.setPortId(new LLDPTLV().setType((byte)2).setLength((short)portId.length).setValue(portId));
    vp.setTtl(new LLDPTLV().setType((byte)3).setLength((short)ttlValue.length).setValue(ttlValue));
    vp.getOptionalTLVList().add(dpidTLV);
    long time=System.currentTimeMillis();
    long swLatency=srcSw.getLatency().getValue();
    byte[] timestampTLVValue=ByteBuffer.allocate(Long.SIZE / 8 + 4).put((byte)0x00).put((byte)0x26).put((byte)0xe1).put((byte)0x01).putLong(time + swLatency).array();
    LLDPTLV timestampTLV=new LLDPTLV().setType((byte)127).setLength((short)timestampTLVValue.length).setValue(timestampTLVValue);
    vp.getOptionalTLVList().add(timestampTLV);
    byte[] typeTLVValue=ByteBuffer.allocate(Integer.SIZE / 8 + 4).put((byte)0x00).put((byte)0x26).put((byte)0xe1).put((byte)0x02).putInt(PathType.ISL.ordinal()).array();
    LLDPTLV typeTLV=new LLDPTLV().setType((byte)127).setLength((short)typeTLVValue.length).setValue(typeTLVValue);
    vp.getOptionalTLVList().add(typeTLV);
    if (sign) {
      String token=JWT.create().withClaim(""String_Node_Str"",dpid.getLong()).withClaim(""String_Node_Str"",time + swLatency).sign(algorithm);
      byte[] tokenBytes=token.getBytes(Charset.forName(""String_Node_Str""));
      byte[] tokenTLVValue=ByteBuffer.allocate(4 + tokenBytes.length).put((byte)0x00).put((byte)0x26).put((byte)0xe1).put((byte)0x03).put(tokenBytes).array();
      LLDPTLV tokenTLV=new LLDPTLV().setType((byte)127).setLength((short)tokenTLVValue.length).setValue(tokenTLVValue);
      vp.getOptionalTLVList().add(tokenTLV);
    }
    MacAddress dstMac=MacAddress.of(VERIFICATION_BCAST_PACKET_DST);
    if (dstSw != null) {
      OFPortDesc sw2OfPortDesc=dstSw.getPort(port);
      dstMac=sw2OfPortDesc.getHwAddr();
    }
    Ethernet l2=new Ethernet().setSourceMACAddress(MacAddress.of(srcMac)).setDestinationMACAddress(dstMac).setEtherType(EthType.IPv4);
    IPv4Address dstIp=IPv4Address.of(VERIFICATION_PACKET_IP_DST);
    if (dstSw != null) {
      dstIp=IPv4Address.of(((InetSocketAddress)dstSw.getInetAddress()).getAddress().getAddress());
    }
    IPv4 l3=new IPv4().setSourceAddress(IPv4Address.of(((InetSocketAddress)srcSw.getInetAddress()).getAddress().getAddress())).setDestinationAddress(dstIp).setTtl((byte)64).setProtocol(IpProtocol.UDP);
    UDP l4=new UDP();
    l4.setSourcePort(TransportPort.of(VERIFICATION_PACKET_UDP_PORT));
    l4.setDestinationPort(TransportPort.of(VERIFICATION_PACKET_UDP_PORT));
    l2.setPayload(l3);
    l3.setPayload(l4);
    l4.setPayload(vp);
    byte[] data=l2.serialize();
    OFPacketOut.Builder pob=srcSw.getOFFactory().buildPacketOut().setBufferId(OFBufferId.NO_BUFFER).setActions(getDiscoveryActions(srcSw,port)).setData(data);
    OFMessageUtils.setInPort(pob,OFPort.CONTROLLER);
    return pob.build();
  }
 catch (  Exception exception) {
    logger.error(""String_Node_Str"",exception);
  }
  return null;
}","public OFPacketOut generateVerificationPacket(IOFSwitch srcSw,OFPort port,IOFSwitch dstSw,boolean sign){
  try {
    OFPortDesc ofPortDesc=srcSw.getPort(port);
    byte[] chassisId=new byte[]{4,0,0,0,0,0,0};
    byte[] portId=new byte[]{2,0,0};
    byte[] ttlValue=new byte[]{0,0x78};
    byte[] dpidTLVValue=new byte[]{0x0,0x26,(byte)0xe1,0,0,0,0,0,0,0,0,0};
    LLDPTLV dpidTLV=new LLDPTLV().setType((byte)127).setLength((short)dpidTLVValue.length).setValue(dpidTLVValue);
    byte[] dpidArray=new byte[8];
    ByteBuffer dpidBB=ByteBuffer.wrap(dpidArray);
    ByteBuffer portBB=ByteBuffer.wrap(portId,1,2);
    DatapathId dpid=srcSw.getId();
    dpidBB.putLong(dpid.getLong());
    System.arraycopy(dpidArray,2,chassisId,1,6);
    System.arraycopy(dpidArray,0,dpidTLVValue,4,8);
    byte[] zeroMac={0,0,0,0,0,0};
    byte[] srcMac=ofPortDesc.getHwAddr().getBytes();
    if (Arrays.equals(srcMac,zeroMac)) {
      int portVal=ofPortDesc.getPortNo().getPortNumber();
      logger.warn(""String_Node_Str"",dpid.toString(),portVal);
      System.arraycopy(dpidArray,2,srcMac,0,6);
    }
    portBB.putShort(port.getShortPortNumber());
    VerificationPacket vp=new VerificationPacket();
    vp.setChassisId(new LLDPTLV().setType((byte)1).setLength((short)chassisId.length).setValue(chassisId));
    vp.setPortId(new LLDPTLV().setType((byte)2).setLength((short)portId.length).setValue(portId));
    vp.setTtl(new LLDPTLV().setType((byte)3).setLength((short)ttlValue.length).setValue(ttlValue));
    vp.getOptionalTLVList().add(dpidTLV);
    long time=System.currentTimeMillis();
    long swLatency=srcSw.getLatency().getValue();
    byte[] timestampTLVValue=ByteBuffer.allocate(Long.SIZE / 8 + 4).put((byte)0x00).put((byte)0x26).put((byte)0xe1).put((byte)0x01).putLong(time + swLatency).array();
    LLDPTLV timestampTLV=new LLDPTLV().setType((byte)127).setLength((short)timestampTLVValue.length).setValue(timestampTLVValue);
    vp.getOptionalTLVList().add(timestampTLV);
    byte[] typeTLVValue=ByteBuffer.allocate(Integer.SIZE / 8 + 4).put((byte)0x00).put((byte)0x26).put((byte)0xe1).put((byte)0x02).putInt(PathType.ISL.ordinal()).array();
    LLDPTLV typeTLV=new LLDPTLV().setType((byte)127).setLength((short)typeTLVValue.length).setValue(typeTLVValue);
    vp.getOptionalTLVList().add(typeTLV);
    if (sign) {
      String token=JWT.create().withClaim(""String_Node_Str"",dpid.getLong()).withClaim(""String_Node_Str"",time + swLatency).sign(algorithm);
      byte[] tokenBytes=token.getBytes(Charset.forName(""String_Node_Str""));
      byte[] tokenTLVValue=ByteBuffer.allocate(4 + tokenBytes.length).put((byte)0x00).put((byte)0x26).put((byte)0xe1).put((byte)0x03).put(tokenBytes).array();
      LLDPTLV tokenTLV=new LLDPTLV().setType((byte)127).setLength((short)tokenTLVValue.length).setValue(tokenTLVValue);
      vp.getOptionalTLVList().add(tokenTLV);
    }
    MacAddress dstMac=MacAddress.of(VERIFICATION_BCAST_PACKET_DST);
    if (dstSw != null) {
      OFPortDesc sw2OfPortDesc=dstSw.getPort(port);
      dstMac=sw2OfPortDesc.getHwAddr();
    }
    Ethernet l2=new Ethernet().setSourceMACAddress(MacAddress.of(srcMac)).setDestinationMACAddress(dstMac).setEtherType(EthType.IPv4);
    IPv4Address dstIp=IPv4Address.of(VERIFICATION_PACKET_IP_DST);
    if (dstSw != null) {
      dstIp=IPv4Address.of(((InetSocketAddress)dstSw.getInetAddress()).getAddress().getAddress());
    }
    IPv4 l3=new IPv4().setSourceAddress(IPv4Address.of(((InetSocketAddress)srcSw.getInetAddress()).getAddress().getAddress())).setDestinationAddress(dstIp).setTtl((byte)64).setProtocol(IpProtocol.UDP);
    UDP l4=new UDP();
    l4.setSourcePort(TransportPort.of(VERIFICATION_PACKET_UDP_PORT));
    l4.setDestinationPort(TransportPort.of(VERIFICATION_PACKET_UDP_PORT));
    l2.setPayload(l3);
    l3.setPayload(l4);
    l4.setPayload(vp);
    byte[] data=l2.serialize();
    OFPacketOut.Builder pob=srcSw.getOFFactory().buildPacketOut().setBufferId(OFBufferId.NO_BUFFER).setActions(getDiscoveryActions(srcSw,port)).setData(data);
    OFMessageUtils.setInPort(pob,OFPort.CONTROLLER);
    return pob.build();
  }
 catch (  Exception exception) {
    logger.error(""String_Node_Str"",exception);
  }
  return null;
}"
37836,"/** 
 * Gets the response.
 * @param < T > the generic type
 * @param < E > the element type
 * @param response the response
 * @param responseClass the response class
 * @param dependentClass the dependent class
 * @return the response
 */
private <T,E>T getResponse(final HttpResponse response,final Class<T> responseClass,final Class<E> dependentClass){
  T obj=null;
  try {
    _log.info(""String_Node_Str"" + response.getStatusLine().getStatusCode());
    if (response.getStatusLine().getStatusCode() != HttpStatus.NO_CONTENT.value()) {
      String responseEntity=IoUtils.toString(response.getEntity().getContent());
      _log.info(""String_Node_Str"" + responseEntity);
      if (!(HttpStatus.valueOf(response.getStatusLine().getStatusCode()).is2xxSuccessful() && response.getEntity() != null)) {
        String errorMessage=null;
        try {
          if (responseEntity.startsWith(""String_Node_Str"")) {
            responseEntity=responseEntity.replaceFirst(""String_Node_Str"",""String_Node_Str"").trim();
          }
          if (responseEntity.endsWith(""String_Node_Str"")) {
            responseEntity=responseEntity.replace(""String_Node_Str"",""String_Node_Str"").trim();
          }
          errorMessage=mapper.readValue(responseEntity,ErrorMessage.class).getMessage();
        }
 catch (        Exception e) {
          if (response.getStatusLine().getStatusCode() == HttpStatus.UNAUTHORIZED.value()) {
            throw new UnauthorizedException(HttpError.UNAUTHORIZED.getMessage());
          }
          _log.error(""String_Node_Str"",e);
          errorMessage=authPropertyService.getError(IAuthConstants.Code.RESPONSE_PARSING_FAIL_ERROR).getMessage();
          throw new RestCallFailedException(errorMessage);
        }
        _log.error(""String_Node_Str"" + responseEntity);
        throw new ExternalSystemException(response.getStatusLine().getStatusCode(),errorMessage);
      }
 else {
        if (dependentClass == null) {
          obj=mapper.readValue(responseEntity,responseClass);
        }
 else {
          obj=mapper.readValue(responseEntity,TypeFactory.defaultInstance().constructCollectionLikeType(responseClass,dependentClass));
        }
      }
    }
  }
 catch (  IOException e) {
    throw new RestCallFailedException(e.getMessage());
  }
  return obj;
}","/** 
 * Gets the response.
 * @param < T > the generic type
 * @param < E > the element type
 * @param response the response
 * @param responseClass the response class
 * @param dependentClass the dependent class
 * @return the response
 */
private <T,E>T getResponse(final HttpResponse response,final Class<T> responseClass,final Class<E> dependentClass){
  T obj=null;
  try {
    LOGGER.info(""String_Node_Str"" + response.getStatusLine().getStatusCode());
    if (response.getStatusLine().getStatusCode() != HttpStatus.NO_CONTENT.value()) {
      String responseEntity=IoUtil.toString(response.getEntity().getContent());
      LOGGER.info(""String_Node_Str"" + responseEntity);
      if (!(HttpStatus.valueOf(response.getStatusLine().getStatusCode()).is2xxSuccessful() && response.getEntity() != null)) {
        String errorMessage=null;
        try {
          if (responseEntity.startsWith(""String_Node_Str"")) {
            responseEntity=responseEntity.replaceFirst(""String_Node_Str"",""String_Node_Str"").trim();
          }
          if (responseEntity.endsWith(""String_Node_Str"")) {
            responseEntity=responseEntity.replace(""String_Node_Str"",""String_Node_Str"").trim();
          }
          errorMessage=mapper.readValue(responseEntity,ErrorMessage.class).getMessage();
        }
 catch (        Exception e) {
          if (response.getStatusLine().getStatusCode() == HttpStatus.UNAUTHORIZED.value()) {
            throw new UnauthorizedException(HttpError.UNAUTHORIZED.getMessage());
          }
          LOGGER.error(""String_Node_Str"",e);
          errorMessage=authPropertyService.getError(IAuthConstants.Code.RESPONSE_PARSING_FAIL_ERROR).getMessage();
          throw new RestCallFailedException(errorMessage);
        }
        LOGGER.error(""String_Node_Str"" + responseEntity);
        throw new ExternalSystemException(response.getStatusLine().getStatusCode(),errorMessage);
      }
 else {
        if (dependentClass == null) {
          obj=mapper.readValue(responseEntity,responseClass);
        }
 else {
          obj=mapper.readValue(responseEntity,TypeFactory.defaultInstance().constructCollectionLikeType(responseClass,dependentClass));
        }
      }
    }
  }
 catch (  IOException e) {
    throw new RestCallFailedException(e.getMessage());
  }
  return obj;
}"
37837,"/** 
 * Checks if is valid response.
 * @param response the response
 * @return true, if is valid response
 */
public static boolean isValidResponse(final HttpResponse response){
  _log.debug(""String_Node_Str"" + response.getStatusLine().getStatusCode());
  return response.getStatusLine().getStatusCode() >= HttpStatus.OK.value() && response.getStatusLine().getStatusCode() < HttpStatus.MULTIPLE_CHOICES.value() && response.getEntity() != null;
}","/** 
 * Checks if is valid response.
 * @param response the response
 * @return true, if is valid response
 */
public static boolean isValidResponse(final HttpResponse response){
  LOGGER.debug(""String_Node_Str"" + response.getStatusLine().getStatusCode());
  return response.getStatusLine().getStatusCode() >= HttpStatus.OK.value() && response.getStatusLine().getStatusCode() < HttpStatus.MULTIPLE_CHOICES.value() && response.getEntity() != null;
}"
37838,"/** 
 * Invoke.
 * @param apiUrl the api url
 * @param httpMethod the http method
 * @param payload the payload
 * @param contentType the content type
 * @param basicAuth the basic auth
 * @return the http response
 */
public HttpResponse invoke(final String apiUrl,final HttpMethod httpMethod,final String payload,final String contentType,final String basicAuth){
  _log.info(""String_Node_Str"");
  HttpResponse httpResponse=null;
  try {
    HttpClient client=HttpClients.createDefault();
    HttpUriRequest httpUriRequest=null;
    HttpEntityEnclosingRequestBase httpEntityEnclosingRequest=null;
    if (HttpMethod.POST.equals(httpMethod)) {
      httpEntityEnclosingRequest=new HttpPost(apiUrl);
    }
 else     if (HttpMethod.PUT.equals(httpMethod)) {
      httpEntityEnclosingRequest=new HttpPut(apiUrl);
    }
 else     if (HttpMethod.DELETE.equals(httpMethod)) {
      httpUriRequest=new HttpDelete(apiUrl);
    }
 else {
      httpUriRequest=new HttpGet(apiUrl);
    }
    if (!HttpMethod.POST.equals(httpMethod) && !HttpMethod.PUT.equals(httpMethod)) {
      if (!StringUtil.isNullOrEmpty(basicAuth)) {
        _log.debug(""String_Node_Str"" + IAuthConstants.Header.AUTHORIZATION);
        httpUriRequest.setHeader(IAuthConstants.Header.AUTHORIZATION,basicAuth);
      }
    }
    if (HttpMethod.POST.equals(httpMethod) || HttpMethod.PUT.equals(httpMethod)) {
      _log.info(""String_Node_Str"" + httpEntityEnclosingRequest + ""String_Node_Str""+ payload);
      httpEntityEnclosingRequest.setHeader(HttpHeaders.CONTENT_TYPE,contentType);
      httpEntityEnclosingRequest.setHeader(IAuthConstants.Header.BASIC_AUTH,basicAuth);
      httpEntityEnclosingRequest.setEntity(new StringEntity(payload));
      httpResponse=client.execute(httpEntityEnclosingRequest);
      _log.debug(""String_Node_Str"");
    }
 else     if (HttpMethod.DELETE.equals(httpMethod) || HttpMethod.GET.equals(httpMethod)) {
      _log.info(""String_Node_Str"" + httpUriRequest);
      httpResponse=client.execute(httpUriRequest);
      _log.info(""String_Node_Str"");
    }
  }
 catch (  Exception e) {
    _log.error(""String_Node_Str"",e);
    throw new RestCallFailedException(e);
  }
  _log.info(""String_Node_Str"");
  return httpResponse;
}","/** 
 * Invoke.
 * @param apiUrl the api url
 * @param httpMethod the http method
 * @param payload the payload
 * @param contentType the content type
 * @param basicAuth the basic auth
 * @return the http response
 */
public HttpResponse invoke(final String apiUrl,final HttpMethod httpMethod,final String payload,final String contentType,final String basicAuth){
  LOGGER.info(""String_Node_Str"");
  HttpResponse httpResponse=null;
  try {
    HttpClient client=HttpClients.createDefault();
    HttpUriRequest httpUriRequest=null;
    HttpEntityEnclosingRequestBase httpEntityEnclosingRequest=null;
    if (HttpMethod.POST.equals(httpMethod)) {
      httpEntityEnclosingRequest=new HttpPost(apiUrl);
    }
 else     if (HttpMethod.PUT.equals(httpMethod)) {
      httpEntityEnclosingRequest=new HttpPut(apiUrl);
    }
 else     if (HttpMethod.DELETE.equals(httpMethod)) {
      httpUriRequest=new HttpDelete(apiUrl);
    }
 else {
      httpUriRequest=new HttpGet(apiUrl);
    }
    if (!HttpMethod.POST.equals(httpMethod) && !HttpMethod.PUT.equals(httpMethod)) {
      if (!StringUtil.isNullOrEmpty(basicAuth)) {
        LOGGER.debug(""String_Node_Str"" + IAuthConstants.Header.AUTHORIZATION);
        httpUriRequest.setHeader(IAuthConstants.Header.AUTHORIZATION,basicAuth);
      }
    }
    if (HttpMethod.POST.equals(httpMethod) || HttpMethod.PUT.equals(httpMethod)) {
      LOGGER.info(""String_Node_Str"" + httpEntityEnclosingRequest + ""String_Node_Str""+ payload);
      httpEntityEnclosingRequest.setHeader(HttpHeaders.CONTENT_TYPE,contentType);
      httpEntityEnclosingRequest.setHeader(IAuthConstants.Header.BASIC_AUTH,basicAuth);
      httpEntityEnclosingRequest.setEntity(new StringEntity(payload));
      httpResponse=client.execute(httpEntityEnclosingRequest);
      LOGGER.debug(""String_Node_Str"");
    }
 else     if (HttpMethod.DELETE.equals(httpMethod) || HttpMethod.GET.equals(httpMethod)) {
      LOGGER.info(""String_Node_Str"" + httpUriRequest);
      httpResponse=client.execute(httpUriRequest);
      LOGGER.info(""String_Node_Str"");
    }
  }
 catch (  Exception e) {
    LOGGER.error(""String_Node_Str"",e);
    throw new RestCallFailedException(e);
  }
  LOGGER.info(""String_Node_Str"");
  return httpResponse;
}"
37839,"@Override public int hashCode(){
  int result=metric != null ? metric.hashCode() : 0;
  result=31 * result + (tags != null ? tags.hashCode() : 0);
  result=31 * result + (value != null ? value.hashCode() : 0);
  return result;
}","@Override public int hashCode(){
  int result=metric != null ? metric.hashCode() : 0;
  result=31 * result + (tags != null ? tags.hashCode() : 0);
  return result;
}"
37840,"public TopologyConfig(PropertiesReader config) throws ConfigurationException {
  isLocal=config.getBoolean(""String_Node_Str"");
  localExecutionTime=(int)(config.getFloat(""String_Node_Str"") * 1000);
  parallelism=config.getInteger(""String_Node_Str"");
  workers=config.getInteger(""String_Node_Str"");
  discoveryInterval=config.getInteger(""String_Node_Str"");
  discoveryTimeout=config.getInteger(""String_Node_Str"");
  filterDirectory=config.getString(""String_Node_Str"");
  loggerLevel=Level.valueOf(config.getString(""String_Node_Str""));
  loggerWatermark=config.getString(""String_Node_Str"");
  zookeeperHosts=config.getString(""String_Node_Str"");
  zookeeperSessionTimeout=(int)(config.getFloat(""String_Node_Str"") * 1000);
  zookeeperConnectTimeout=(int)(config.getFloat(""String_Node_Str"") * 1000);
  kafkaHosts=config.getString(""String_Node_Str"");
  kafkaCtrlTopic=config.getString(""String_Node_Str"");
  kafkaFlowTopic=config.getString(""String_Node_Str"");
  kafkaHealthCheckTopic=config.getString(""String_Node_Str"");
  kafkaNorthboundTopic=config.getString(""String_Node_Str"");
  kafkaOtsdbTopic=config.getString(""String_Node_Str"");
  kafkaSimulatorTopic=config.getString(""String_Node_Str"");
  kafkaSpeakerTopic=config.getString(""String_Node_Str"");
  kafkaStatsTopic=config.getString(""String_Node_Str"");
  kafkaTopoCacheTopic=config.getString(""String_Node_Str"");
  kafkaTopoDiscoTopic=config.getString(""String_Node_Str"");
  kafkaTopoEngTopic=config.getString(""String_Node_Str"");
  openTsDBHosts=config.getString(""String_Node_Str"");
  openTsdbTimeout=(int)(config.getFloat(""String_Node_Str"") * 1000);
  openTsdbNumSpouts=config.getInteger(""String_Node_Str"");
  openTsdbNumOpentasbFilterBolt=config.getInteger(""String_Node_Str"");
  openTsdbNumOpentsdbBolt=config.getInteger(""String_Node_Str"");
  neo4jHost=config.getString(""String_Node_Str"");
  neo4jLogin=config.getString(""String_Node_Str"");
  neo4jPassword=config.getString(""String_Node_Str"");
}","public TopologyConfig(PropertiesReader config) throws ConfigurationException {
  isLocal=config.getBoolean(""String_Node_Str"");
  localExecutionTime=(int)(config.getFloat(""String_Node_Str"") * 1000);
  parallelism=config.getInteger(""String_Node_Str"");
  workers=config.getInteger(""String_Node_Str"");
  discoveryInterval=config.getInteger(""String_Node_Str"");
  discoveryTimeout=config.getInteger(""String_Node_Str"");
  filterDirectory=config.getString(""String_Node_Str"");
  loggerLevel=Level.valueOf(config.getString(""String_Node_Str""));
  loggerWatermark=config.getString(""String_Node_Str"");
  zookeeperHosts=config.getString(""String_Node_Str"");
  zookeeperSessionTimeout=(int)(config.getFloat(""String_Node_Str"") * 1000);
  zookeeperConnectTimeout=(int)(config.getFloat(""String_Node_Str"") * 1000);
  kafkaHosts=config.getString(""String_Node_Str"");
  kafkaCtrlTopic=config.getString(""String_Node_Str"");
  kafkaFlowTopic=config.getString(""String_Node_Str"");
  kafkaHealthCheckTopic=config.getString(""String_Node_Str"");
  kafkaNorthboundTopic=config.getString(""String_Node_Str"");
  kafkaOtsdbTopic=config.getString(""String_Node_Str"");
  kafkaSimulatorTopic=config.getString(""String_Node_Str"");
  kafkaSpeakerTopic=config.getString(""String_Node_Str"");
  kafkaStatsTopic=config.getString(""String_Node_Str"");
  kafkaTopoCacheTopic=config.getString(""String_Node_Str"");
  kafkaTopoDiscoTopic=config.getString(""String_Node_Str"");
  kafkaTopoEngTopic=config.getString(""String_Node_Str"");
  openTsDBHosts=config.getString(""String_Node_Str"");
  openTsdbTimeout=(int)(config.getFloat(""String_Node_Str"") * 1000);
  openTsdbNumSpouts=config.getInteger(""String_Node_Str"");
  openTsdbFilterBoltExecutors=config.getInteger(""String_Node_Str"");
  openTsdbBoltExecutors=config.getInteger(""String_Node_Str"");
  openTsdbBoltWorkers=config.getInteger(""String_Node_Str"");
  openTsdbBatchSize=config.getInteger(""String_Node_Str"");
  openTsdbFlushInterval=config.getInteger(""String_Node_Str"");
  neo4jHost=config.getString(""String_Node_Str"");
  neo4jLogin=config.getString(""String_Node_Str"");
  neo4jPassword=config.getString(""String_Node_Str"");
}"
37841,"@Override public StormTopology createTopology(){
  LOGGER.info(""String_Node_Str"");
  TopologyBuilder tb=new TopologyBuilder();
  final String topic=config.getKafkaOtsdbTopic();
  final String spoutId=topic + ""String_Node_Str"";
  final String boltId=topic + ""String_Node_Str"";
  checkAndCreateTopic(topic);
  KafkaSpout kafkaSpout=createKafkaSpout(topic,spoutId);
  tb.setSpout(spoutId,kafkaSpout,config.getOpenTsdbNumSpouts());
  tb.setBolt(boltId,new OpenTSDBFilterBolt(),config.getOpenTsdbNumOpentasbFilterBolt()).shuffleGrouping(spoutId);
  OpenTsdbClient.Builder tsdbBuilder=OpenTsdbClient.newBuilder(config.getOpenTsDBHosts()).sync(config.getOpenTsdbTimeout()).returnDetails();
  OpenTsdbBolt openTsdbBolt=new OpenTsdbBolt(tsdbBuilder,TupleOpenTsdbDatapointMapper.DEFAULT_MAPPER).withBatchSize(10).withFlushInterval(2).failTupleForFailedMetrics();
  tb.setBolt(""String_Node_Str"",openTsdbBolt,config.getOpenTsdbNumOpentsdbBolt()).shuffleGrouping(boltId);
  return tb.createTopology();
}","@Override public StormTopology createTopology(){
  LOGGER.info(""String_Node_Str"");
  TopologyBuilder tb=new TopologyBuilder();
  final String topic=config.getKafkaOtsdbTopic();
  final String spoutId=topic + ""String_Node_Str"";
  final String boltId=topic + ""String_Node_Str"";
  checkAndCreateTopic(topic);
  KafkaSpout kafkaSpout=createKafkaSpout(topic,spoutId);
  tb.setSpout(spoutId,kafkaSpout,config.getOpenTsdbNumSpouts());
  tb.setBolt(boltId,new OpenTSDBFilterBolt(),config.getOpenTsdbFilterBoltExecutors()).fieldsGrouping(spoutId,new Fields(""String_Node_Str""));
  OpenTsdbClient.Builder tsdbBuilder=OpenTsdbClient.newBuilder(config.getOpenTsDBHosts()).sync(config.getOpenTsdbTimeout()).returnDetails();
  OpenTsdbBolt openTsdbBolt=new OpenTsdbBolt(tsdbBuilder,TupleOpenTsdbDatapointMapper.DEFAULT_MAPPER).withBatchSize(config.getOpenTsdbBatchSize()).withFlushInterval(config.getOpenTsdbFlushInterval()).failTupleForFailedMetrics();
  tb.setBolt(""String_Node_Str"",openTsdbBolt,config.getOpenTsdbBoltExecutors()).setNumTasks(config.getOpenTsdbBoltWorkers()).shuffleGrouping(boltId);
  return tb.createTopology();
}"
37842,"private boolean isUpdateRequired(Datapoint datapoint){
  return !storage.contains(datapoint) || isDatapointOutdated(datapoint);
}","private boolean isUpdateRequired(Datapoint datapoint){
  boolean update=true;
  if (storage.containsKey(datapoint.hashCode())) {
    Datapoint prevDatapoint=storage.get(datapoint.hashCode());
    update=!prevDatapoint.getValue().equals(datapoint.getValue()) || datapoint.getTime() - prevDatapoint.getTime() >= TEN_MINUTES;
  }
  return update;
}"
37843,"private void addDatapoint(Datapoint datapoint){
  if (!storage.add(datapoint)) {
    storage.remove(datapoint);
    storage.add(datapoint);
  }
}","private void addDatapoint(Datapoint datapoint){
  LOGGER.debug(""String_Node_Str"" + datapoint.hashCode());
  storage.put(datapoint.hashCode(),datapoint);
}"
37844,"private void sendDiscoveryFailed(String switchId,String portId,Tuple tuple) throws IOException {
  String discoFail=OFEMessageUtils.createIslFail(switchId,portId);
  Values dataVal=new Values(PAYLOAD,discoFail,switchId,portId,OFEMessageUtils.LINK_DOWN);
  collector.emit(topoEngTopic,tuple,dataVal);
  discovery.handleFailed(switchId,portId);
  logger.warn(""String_Node_Str"",discoFail);
}","private void sendDiscoveryFailed(String switchId,String portId,Tuple tuple) throws IOException {
  String discoFail=OFEMessageUtils.createIslFail(switchId,portId);
  collector.emit(topoEngTopic,tuple,new Values(PAYLOAD,discoFail));
  discovery.handleFailed(switchId,portId);
  logger.warn(""String_Node_Str"",discoFail);
}"
37845,"private void parseRecord(ConsumerRecord record){
  try {
    if (record.value() instanceof String) {
      String value=(String)record.value();
      BaseMessage message=MAPPER.readValue(value,BaseMessage.class);
      if (message instanceof CommandMessage) {
        logger.debug(""String_Node_Str"",value);
        doControllerMsg((CommandMessage)message);
      }
 else {
        logger.trace(""String_Node_Str"",message);
      }
    }
 else {
      logger.error(""String_Node_Str"",record.value());
    }
  }
 catch (  Exception exception) {
    logger.error(""String_Node_Str"",record.value(),exception);
  }
}","private void parseRecord(ConsumerRecord record){
  try {
    if (record.value() instanceof String) {
      String value=(String)record.value();
      CommandMessage message=MAPPER.readValue(value,CommandMessage.class);
      doControllerMsg((CommandMessage)message);
    }
 else {
      logger.error(""String_Node_Str"",record.value());
    }
  }
 catch (  Exception exception) {
    logger.error(""String_Node_Str"",record.value(),exception);
  }
}"
37846,"/** 
 * Returns CommandData entity constructed by data string from json resource file.
 * @param value data string from json resource file
 * @return CommandData entity
 * @throws IOException if mapping fails
 */
private static CommandData prepareData(String value) throws IOException {
  Message message=MAPPER.readValue(value,Message.class);
  CommandMessage commandMessage=(CommandMessage)message;
  return commandMessage.getData();
}","/** 
 * Returns CommandData entity constructed by data string from json resource file.
 * @param value data string from json resource file
 * @return CommandData entity
 * @throws IOException if mapping fails
 */
private static CommandData prepareData(String value) throws IOException {
  CommandMessage message=MAPPER.readValue(value,CommandMessage.class);
  return message.getData();
}"
37847,"/** 
 * Runs test case.
 * @param value       data string from json resource file
 * @param flowCommand OFFlowAdd instance to compare result with
 * @throws InterruptedException if test was interrupted during run
 */
private void runTest(final String value,final OFFlowAdd flowCommand,final OFMeterMod meterCommand,final OFFlowAdd reverseFlowCommand,final OFMeterMod reverseMeterCommand) throws InterruptedException {
  ConsumerRecord<String,String> record=new ConsumerRecord<>(""String_Node_Str"",0,0,""String_Node_Str"",value);
  KafkaMessageCollector.ParseRecord parseRecord=collector.new ParseRecord(record);
  Capture<OFFlowAdd> flowAddCapture=flowCommand == null ? null : newCapture(CaptureType.ALL);
  Capture<OFMeterMod> meterAddCapture=meterCommand == null ? null : newCapture(CaptureType.ALL);
  prepareMocks(flowAddCapture,meterAddCapture,reverseFlowCommand != null,reverseMeterCommand != null);
  parseRecordExecutor.execute(parseRecord);
  parseRecordExecutor.shutdown();
  parseRecordExecutor.awaitTermination(10,TimeUnit.SECONDS);
  if (meterCommand != null) {
    assertEquals(meterCommand,meterAddCapture.getValues().get(0));
    if (reverseMeterCommand != null) {
      assertEquals(reverseMeterCommand,meterAddCapture.getValues().get(1));
    }
  }
  if (flowCommand != null) {
    assertEquals(flowCommand,flowAddCapture.getValues().get(0));
    if (reverseFlowCommand != null) {
      assertEquals(reverseFlowCommand,flowAddCapture.getValues().get(1));
    }
  }
}","/** 
 * Runs test case.
 * @param value       data string from json resource file
 * @param flowCommand OFFlowAdd instance to compare result with
 * @throws InterruptedException if test was interrupted during run
 */
private void runTest(final String value,final OFFlowAdd flowCommand,final OFMeterMod meterCommand,final OFFlowAdd reverseFlowCommand,final OFMeterMod reverseMeterCommand) throws InterruptedException {
  ConsumerRecord<String,String> record=new ConsumerRecord<>(""String_Node_Str"",0,0,""String_Node_Str"",value);
  KafkaMessageCollector.ParseRecord parseRecord=collector.new ParseRecord(record);
  Capture<OFFlowAdd> flowAddCapture=flowCommand == null ? null : newCapture(CaptureType.ALL);
  Capture<OFMeterMod> meterAddCapture=meterCommand == null ? null : newCapture(CaptureType.ALL);
  prepareMocks(flowAddCapture,meterAddCapture,reverseFlowCommand != null,reverseMeterCommand != null);
  parseRecordExecutor.execute(parseRecord);
  parseRecordExecutor.shutdown();
  parseRecordExecutor.awaitTermination(10,TimeUnit.SECONDS);
  if (meterCommand != null) {
    System.out.println(""String_Node_Str"" + meterCommand);
    System.out.println(""String_Node_Str"" + meterAddCapture.getValues());
    assertEquals(meterCommand,meterAddCapture.getValues().get(0));
    if (reverseMeterCommand != null) {
      assertEquals(reverseMeterCommand,meterAddCapture.getValues().get(1));
    }
  }
  if (flowCommand != null) {
    assertEquals(flowCommand,flowAddCapture.getValues().get(0));
    if (reverseFlowCommand != null) {
      assertEquals(reverseFlowCommand,flowAddCapture.getValues().get(1));
    }
  }
}"
37848,"@Test @Ignore public void BasicSwitchPortEventsTest() throws Exception {
  System.out.println(""String_Node_Str"");
  String sw1_up=OFEMessageUtils.createSwitchDataMessage(OFEMessageUtils.SWITCH_UP,""String_Node_Str"");
  String sw2_up=OFEMessageUtils.createSwitchDataMessage(OFEMessageUtils.SWITCH_UP,""String_Node_Str"");
  String sw1p1_up=OFEMessageUtils.createPortDataMessage(OFEMessageUtils.PORT_UP,""String_Node_Str"",""String_Node_Str"");
  String sw2p2_up=OFEMessageUtils.createPortDataMessage(OFEMessageUtils.PORT_UP,""String_Node_Str"",""String_Node_Str"");
  String sw2p2_down=OFEMessageUtils.createPortDataMessage(OFEMessageUtils.PORT_DOWN,""String_Node_Str"",""String_Node_Str"");
  String switch_topic=InfoEventSplitterBolt.I_SWITCH_UPDOWN;
  String port_topic=InfoEventSplitterBolt.I_PORT_UPDOWN;
  kProducer.pushMessage(switch_topic,sw1_up);
  kProducer.pushMessage(switch_topic,sw2_up);
  kProducer.pushMessage(port_topic,sw1p1_up);
  kProducer.pushMessage(port_topic,sw2p2_up);
  kProducer.pushMessage(switch_topic,sw1_up);
  kProducer.pushMessage(switch_topic,sw2_up);
  kProducer.pushMessage(port_topic,sw1p1_up);
  kProducer.pushMessage(port_topic,sw2p2_up);
  Utils.sleep(4 * 1000);
  messagesExpected=8;
  messagesReceived=safeLinesCount(discoFiler.getFiler().getFile());
  Assert.assertEquals(messagesExpected,messagesReceived);
  Utils.sleep(1 * 1000);
  kProducer.pushMessage(port_topic,sw2p2_down);
  Utils.sleep(2 * 1000);
  messagesReceived=safeLinesCount(discoFiler.getFiler().getFile());
  if (messagesReceived == 0) {
    System.out.println(""String_Node_Str"");
    for (    String s : Files.readLines(discoFiler.getFiler().getFile(),Charsets.UTF_8)) {
      System.out.println(""String_Node_Str"" + s);
    }
  }
  Assert.assertTrue(messagesReceived > 0);
  cluster.killTopology(manager.makeTopologyName());
  cluster.killTopology(""String_Node_Str"");
  Utils.sleep(4 * 1000);
}","@Test @Ignore public void BasicSwitchPortEventsTest() throws Exception {
  System.out.println(""String_Node_Str"");
  OFEventWFMTopology manager=new OFEventWFMTopology(makeLaunchEnvironment());
  TopologyConfig config=manager.getConfig();
  String sw1_up=OFEMessageUtils.createSwitchDataMessage(OFEMessageUtils.SWITCH_UP,""String_Node_Str"");
  String sw2_up=OFEMessageUtils.createSwitchDataMessage(OFEMessageUtils.SWITCH_UP,""String_Node_Str"");
  String sw1p1_up=OFEMessageUtils.createPortDataMessage(OFEMessageUtils.PORT_UP,""String_Node_Str"",""String_Node_Str"");
  String sw2p2_up=OFEMessageUtils.createPortDataMessage(OFEMessageUtils.PORT_UP,""String_Node_Str"",""String_Node_Str"");
  String sw2p2_down=OFEMessageUtils.createPortDataMessage(OFEMessageUtils.PORT_DOWN,""String_Node_Str"",""String_Node_Str"");
  String switch_topic=config.getKafkaTopoDiscoTopic();
  String port_topic=config.getKafkaTopoDiscoTopic();
  kProducer.pushMessage(switch_topic,sw1_up);
  kProducer.pushMessage(switch_topic,sw2_up);
  kProducer.pushMessage(port_topic,sw1p1_up);
  kProducer.pushMessage(port_topic,sw2p2_up);
  kProducer.pushMessage(switch_topic,sw1_up);
  kProducer.pushMessage(switch_topic,sw2_up);
  kProducer.pushMessage(port_topic,sw1p1_up);
  kProducer.pushMessage(port_topic,sw2p2_up);
  Utils.sleep(4 * 1000);
  messagesExpected=8;
  messagesReceived=safeLinesCount(discoFiler.getFiler().getFile());
  Assert.assertEquals(messagesExpected,messagesReceived);
  Utils.sleep(1 * 1000);
  kProducer.pushMessage(port_topic,sw2p2_down);
  Utils.sleep(2 * 1000);
  messagesReceived=safeLinesCount(discoFiler.getFiler().getFile());
  if (messagesReceived == 0) {
    System.out.println(""String_Node_Str"");
    for (    String s : Files.readLines(discoFiler.getFiler().getFile(),Charsets.UTF_8)) {
      System.out.println(""String_Node_Str"" + s);
    }
  }
  Assert.assertTrue(messagesReceived > 0);
  cluster.killTopology(manager.makeTopologyName());
  cluster.killTopology(""String_Node_Str"");
  Utils.sleep(4 * 1000);
}"
37849,"/** 
 * BasicLinkDiscoveryTest will exercise the basics of Link Discovery test. The key results should show up in a kafka topic, which are dumped to file.
 */
@Test @Ignore public void basicLinkDiscoveryTest() throws IOException, ConfigurationException, CmdLineException {
  System.out.println(""String_Node_Str"");
  OFEventWFMTopology manager=new OFEventWFMTopology(makeLaunchEnvironment());
  TopologyConfig config=manager.getConfig();
  Tuple tuple;
  KeyValueState<String,Object> state=new InMemoryKeyValueState<>();
  initMocks();
  List<PathNode> nodes=Arrays.asList(new PathNode(""String_Node_Str"",1,0,10L),new PathNode(""String_Node_Str"",2,1,10L));
  InfoData data=new IslInfoData(10L,nodes,10000L,IslChangeType.DISCOVERED,9000L);
  String isl_discovered=MAPPER.writeValueAsString(data);
  OFELinkBolt linkBolt=new OFELinkBolt(config);
  linkBolt.prepare(stormConfig(),topologyContext,outputCollector);
  linkBolt.initState(state);
  ArrayList<DiscoveryFilterEntity> skipNodes=new ArrayList<>(1);
  skipNodes.add(new DiscoveryFilterEntity(""String_Node_Str"",""String_Node_Str""));
  CommandMessage islFilterSetup=new CommandMessage(new DiscoveryFilterPopulateData(skipNodes),1,""String_Node_Str"",Destination.WFM_OF_DISCOVERY);
  String json=MAPPER.writeValueAsString(islFilterSetup);
  tuple=new TupleImpl(topologyContext,Collections.singletonList(json),4,""String_Node_Str"");
  linkBolt.execute(tuple);
  tuple=new TupleImpl(topologyContext,Arrays.asList(""String_Node_Str"",OFEMessageUtils.SWITCH_UP),0,InfoEventSplitterBolt.I_SWITCH_UPDOWN);
  linkBolt.execute(tuple);
  tuple=new TupleImpl(topologyContext,Arrays.asList(""String_Node_Str"",OFEMessageUtils.SWITCH_UP),0,InfoEventSplitterBolt.I_SWITCH_UPDOWN);
  linkBolt.execute(tuple);
  tuple=new TupleImpl(topologyContext,Arrays.asList(""String_Node_Str"",""String_Node_Str"",OFEMessageUtils.PORT_UP),1,InfoEventSplitterBolt.I_PORT_UPDOWN);
  linkBolt.execute(tuple);
  tuple=new TupleImpl(topologyContext,Arrays.asList(""String_Node_Str"",""String_Node_Str"",OFEMessageUtils.PORT_UP),1,InfoEventSplitterBolt.I_PORT_UPDOWN);
  linkBolt.execute(tuple);
  Tuple tickTuple=new TupleImpl(topologyContext,Collections.emptyList(),2,Constants.SYSTEM_TICK_STREAM_ID);
  linkBolt.execute(tickTuple);
  tuple=new TupleImpl(topologyContext,Collections.singletonList(isl_discovered),3,InfoEventSplitterBolt.I_ISL_UPDOWN);
  linkBolt.execute(tuple);
  linkBolt.execute(tickTuple);
  linkBolt.execute(tickTuple);
  messagesExpected=7;
  messagesReceived=outputCollectorMock.getMessagesCount(config.getKafkaTopoDiscoTopic());
  Assert.assertEquals(messagesExpected,messagesReceived);
  messagesExpected=7;
  messagesReceived=outputCollectorMock.getMessagesCount(config.getKafkaTopoDiscoTopic());
  Assert.assertEquals(messagesExpected,messagesReceived);
  linkBolt.execute(tickTuple);
  messagesExpected=7;
  messagesReceived=outputCollectorMock.getMessagesCount(config.getKafkaTopoDiscoTopic());
  Assert.assertEquals(messagesExpected,messagesReceived);
  messagesExpected=7;
  messagesReceived=outputCollectorMock.getMessagesCount(config.getKafkaTopoDiscoTopic());
  Assert.assertEquals(messagesExpected,messagesReceived);
}","/** 
 * BasicLinkDiscoveryTest will exercise the basics of Link Discovery test. The key results should show up in a kafka topic, which are dumped to file.
 */
@Test @Ignore public void basicLinkDiscoveryTest() throws IOException, ConfigurationException, CmdLineException {
  System.out.println(""String_Node_Str"");
  OFEventWFMTopology manager=new OFEventWFMTopology(makeLaunchEnvironment());
  TopologyConfig config=manager.getConfig();
  String topo_input_topic=config.getKafkaTopoDiscoTopic();
  Tuple tuple;
  KeyValueState<String,Object> state=new InMemoryKeyValueState<>();
  initMocks(topo_input_topic);
  List<PathNode> nodes=Arrays.asList(new PathNode(""String_Node_Str"",1,0,10L),new PathNode(""String_Node_Str"",2,1,10L));
  InfoData data=new IslInfoData(10L,nodes,10000L,IslChangeType.DISCOVERED,9000L);
  String isl_discovered=MAPPER.writeValueAsString(data);
  OFELinkBolt linkBolt=new OFELinkBolt(config);
  linkBolt.prepare(stormConfig(),topologyContext,outputCollector);
  linkBolt.initState(state);
  ArrayList<DiscoveryFilterEntity> skipNodes=new ArrayList<>(1);
  skipNodes.add(new DiscoveryFilterEntity(""String_Node_Str"",""String_Node_Str""));
  CommandMessage islFilterSetup=new CommandMessage(new DiscoveryFilterPopulateData(skipNodes),1,""String_Node_Str"",Destination.WFM_OF_DISCOVERY);
  String json=MAPPER.writeValueAsString(islFilterSetup);
  tuple=new TupleImpl(topologyContext,Collections.singletonList(json),4,""String_Node_Str"");
  linkBolt.execute(tuple);
  tuple=new TupleImpl(topologyContext,Arrays.asList(""String_Node_Str"",OFEMessageUtils.SWITCH_UP),0,topo_input_topic);
  linkBolt.execute(tuple);
  tuple=new TupleImpl(topologyContext,Arrays.asList(""String_Node_Str"",OFEMessageUtils.SWITCH_UP),0,topo_input_topic);
  linkBolt.execute(tuple);
  tuple=new TupleImpl(topologyContext,Arrays.asList(""String_Node_Str"",""String_Node_Str"",OFEMessageUtils.PORT_UP),1,topo_input_topic);
  linkBolt.execute(tuple);
  tuple=new TupleImpl(topologyContext,Arrays.asList(""String_Node_Str"",""String_Node_Str"",OFEMessageUtils.PORT_UP),1,topo_input_topic);
  linkBolt.execute(tuple);
  Tuple tickTuple=new TupleImpl(topologyContext,Collections.emptyList(),2,Constants.SYSTEM_TICK_STREAM_ID);
  linkBolt.execute(tickTuple);
  tuple=new TupleImpl(topologyContext,Collections.singletonList(isl_discovered),3,topo_input_topic);
  linkBolt.execute(tuple);
  linkBolt.execute(tickTuple);
  linkBolt.execute(tickTuple);
  messagesExpected=7;
  messagesReceived=outputCollectorMock.getMessagesCount(config.getKafkaTopoDiscoTopic());
  Assert.assertEquals(messagesExpected,messagesReceived);
  messagesExpected=7;
  messagesReceived=outputCollectorMock.getMessagesCount(config.getKafkaTopoDiscoTopic());
  Assert.assertEquals(messagesExpected,messagesReceived);
  linkBolt.execute(tickTuple);
  messagesExpected=7;
  messagesReceived=outputCollectorMock.getMessagesCount(config.getKafkaTopoDiscoTopic());
  Assert.assertEquals(messagesExpected,messagesReceived);
  messagesExpected=7;
  messagesReceived=outputCollectorMock.getMessagesCount(config.getKafkaTopoDiscoTopic());
  Assert.assertEquals(messagesExpected,messagesReceived);
}"
37850,"private void initMocks(){
  Fields switchSchema=new Fields(OFEMessageUtils.FIELD_SWITCH_ID,OFEMessageUtils.FIELD_STATE);
  when(topologyContext.getComponentId(0)).thenReturn(InfoEventSplitterBolt.I_SWITCH_UPDOWN);
  when(topologyContext.getComponentOutputFields(InfoEventSplitterBolt.I_SWITCH_UPDOWN,InfoEventSplitterBolt.I_SWITCH_UPDOWN)).thenReturn(switchSchema);
  Fields portSchema=new Fields(OFEMessageUtils.FIELD_SWITCH_ID,OFEMessageUtils.FIELD_PORT_ID,OFEMessageUtils.FIELD_STATE);
  when(topologyContext.getComponentId(1)).thenReturn(InfoEventSplitterBolt.I_PORT_UPDOWN);
  when(topologyContext.getComponentOutputFields(InfoEventSplitterBolt.I_PORT_UPDOWN,InfoEventSplitterBolt.I_PORT_UPDOWN)).thenReturn(portSchema);
  Fields tickSchema=new Fields();
  when(topologyContext.getComponentId(2)).thenReturn(Constants.SYSTEM_COMPONENT_ID);
  when(topologyContext.getComponentOutputFields(Constants.SYSTEM_COMPONENT_ID,Constants.SYSTEM_TICK_STREAM_ID)).thenReturn(tickSchema);
  Fields islSchema=new Fields(InfoEventSplitterBolt.I_ISL_UPDOWN);
  when(topologyContext.getComponentId(3)).thenReturn(InfoEventSplitterBolt.I_ISL_UPDOWN);
  when(topologyContext.getComponentOutputFields(InfoEventSplitterBolt.I_ISL_UPDOWN,InfoEventSplitterBolt.I_ISL_UPDOWN)).thenReturn(islSchema);
  when(topologyContext.getComponentId(4)).thenReturn(OFEventWFMTopology.SPOUT_ID_INPUT);
  when(topologyContext.getComponentOutputFields(OFEventWFMTopology.SPOUT_ID_INPUT,AbstractTopology.MESSAGE_FIELD)).thenReturn(AbstractTopology.fieldMessage);
}","private void initMocks(String topo_input_topic){
  Fields switchSchema=new Fields(OFEMessageUtils.FIELD_SWITCH_ID,OFEMessageUtils.FIELD_STATE);
  when(topologyContext.getComponentId(0)).thenReturn(topo_input_topic);
  when(topologyContext.getComponentOutputFields(topo_input_topic,topo_input_topic)).thenReturn(switchSchema);
  Fields portSchema=new Fields(OFEMessageUtils.FIELD_SWITCH_ID,OFEMessageUtils.FIELD_PORT_ID,OFEMessageUtils.FIELD_STATE);
  when(topologyContext.getComponentId(1)).thenReturn(topo_input_topic);
  when(topologyContext.getComponentOutputFields(topo_input_topic,topo_input_topic)).thenReturn(portSchema);
  Fields tickSchema=new Fields();
  when(topologyContext.getComponentId(2)).thenReturn(Constants.SYSTEM_COMPONENT_ID);
  when(topologyContext.getComponentOutputFields(Constants.SYSTEM_COMPONENT_ID,Constants.SYSTEM_TICK_STREAM_ID)).thenReturn(tickSchema);
  Fields islSchema=new Fields(topo_input_topic);
  when(topologyContext.getComponentId(3)).thenReturn(topo_input_topic);
  when(topologyContext.getComponentOutputFields(topo_input_topic,topo_input_topic)).thenReturn(islSchema);
  when(topologyContext.getComponentId(4)).thenReturn(OFEventWFMTopology.SPOUT_ID_INPUT);
  when(topologyContext.getComponentOutputFields(OFEventWFMTopology.SPOUT_ID_INPUT,AbstractTopology.MESSAGE_FIELD)).thenReturn(AbstractTopology.fieldMessage);
}"
37851,"@BeforeClass public static void setupOnce() throws Exception {
  System.out.println(""String_Node_Str"");
  makeConfigFile();
  server=new TestUtils.KafkaTestFixture(makeUnboundConfig());
  server.start();
  cluster=new LocalCluster();
  kProducer=new TestKafkaProducer(kafkaProperties());
}","@BeforeClass public static void setupOnce() throws Exception {
  System.out.println(""String_Node_Str"");
  clusterParam=new MkClusterParam();
  clusterParam.setSupervisors(1);
  Config daemonConfig=new Config();
  daemonConfig.put(Config.STORM_LOCAL_MODE_ZMQ,false);
  clusterParam.setDaemonConf(daemonConfig);
  makeConfigFile();
  Config conf=new Config();
  conf.setNumWorkers(1);
  completeTopologyParam=new CompleteTopologyParam();
  completeTopologyParam.setStormConf(conf);
}"
37852,"@Override public void execute(Tuple tuple){
  try {
    String tupleSource=tuple.getSourceComponent();
switch (tupleSource) {
case SimulatorTopology.SIMULATOR_SPOUT:
      doCommand(tuple);
    break;
default :
  logger.error(""String_Node_Str"",tupleSource);
}
}
 catch (Exception e) {
logger.error(e);
}
 finally {
collector.ack(tuple);
}
}","@Override public void execute(Tuple tuple){
  try {
    String tupleSource=tuple.getSourceComponent();
switch (tupleSource) {
case SimulatorTopology.SIMULATOR_SPOUT:
      doCommand(tuple);
    break;
default :
  logger.error(""String_Node_Str"",tupleSource);
}
}
 catch (Exception e) {
logger.error(e.toString());
}
 finally {
collector.ack(tuple);
}
}"
37853,"protected List<Values> addSwitch(SwitchMessage switchMessage) throws Exception {
  ISwitchImpl sw=switches.get(switchMessage.getDpid());
  List<Values> values=new ArrayList<>();
  if (sw == null) {
    logger.info(""String_Node_Str"");
    sw=new ISwitchImpl(switchMessage.getDpid(),switchMessage.getNumOfPorts(),PortStateType.DOWN);
    sw.activate();
    List<LinkMessage> links=switchMessage.getLinks();
    for (    LinkMessage l : links) {
      IPortImpl localPort=sw.getPort(l.getLocalPort());
      localPort.setLatency(l.getLatency());
      localPort.setPeerPortNum(l.getPeerPort());
      localPort.setPeerSwitch(l.getPeerSwitch());
      localPort.enable();
    }
    switches.put(sw.getDpid().toString(),sw);
    values.add(new Values(""String_Node_Str"",makeSwitchMessage(sw,SwitchState.ADDED)));
    values.add(new Values(""String_Node_Str"",makeSwitchMessage(sw,SwitchState.ACTIVATED)));
    for (    IPortImpl p : sw.getPorts()) {
      PortChangeType changeType=p.isActive() ? PortChangeType.UP : PortChangeType.DOWN;
      values.add(new Values(""String_Node_Str"",makePortMessage(sw,p.getNumber(),changeType)));
    }
  }
  return values;
}","protected List<Values> addSwitch(SwitchMessage switchMessage) throws Exception {
  ISwitchImpl sw=switches.get(switchMessage.getDpid());
  List<Values> values=new ArrayList<>();
  if (sw == null) {
    logger.info(""String_Node_Str"");
    sw=new ISwitchImpl(switchMessage.getDpid(),switchMessage.getNumOfPorts(),PortStateType.DOWN);
    sw.activate();
    List<LinkMessage> links=switchMessage.getLinks();
    for (    LinkMessage l : links) {
      IPortImpl localPort=sw.getPort(l.getLocalPort());
      localPort.setLatency(l.getLatency());
      localPort.setPeerPortNum(l.getPeerPort());
      localPort.setPeerSwitch(l.getPeerSwitch());
      localPort.enable();
    }
    switches.put(sw.getDpid().toString(),sw);
    values.add(new Values(""String_Node_Str"",makeSwitchMessage(sw,SwitchState.ADDED)));
    values.add(new Values(""String_Node_Str"",makeSwitchMessage(sw,SwitchState.ACTIVATED)));
    for (    IPortImpl p : sw.getPorts()) {
      PortChangeType changeType=p.isActive() ? PortChangeType.UP : PortChangeType.DOWN;
      if (changeType == PortChangeType.UP) {
        values.add(new Values(""String_Node_Str"",makePortMessage(sw,p.getNumber(),changeType)));
      }
    }
  }
  return values;
}"
37854,"protected void discoverIslPartTwo(Tuple tuple,IslInfoData data) throws Exception {
  ISwitchImpl sw=getSwitch(data.getPath().get(1).getSwitchId());
  if (!sw.isActive()) {
    return;
  }
  IPortImpl port=sw.getPort(data.getPath().get(1).getPortNo());
  if (port.isActiveIsl()) {
    long now=Instant.now().toEpochMilli();
    InfoMessage infoMessage=new InfoMessage(data,now,""String_Node_Str"",null);
    logger.info(""String_Node_Str"",data.toString());
    collector.emit(SimulatorTopology.KAFKA_BOLT_STREAM,tuple,new Values(""String_Node_Str"",Utils.MAPPER.writeValueAsString(infoMessage)));
  }
}","protected void discoverIslPartTwo(Tuple tuple,IslInfoData data) throws Exception {
  ISwitchImpl sw=getSwitch(data.getPath().get(1).getSwitchId());
  if (!sw.isActive()) {
    return;
  }
  IPortImpl port=sw.getPort(data.getPath().get(1).getPortNo());
  if (port.isActiveIsl()) {
    long now=Instant.now().toEpochMilli();
    InfoMessage infoMessage=new InfoMessage(data,now,""String_Node_Str"",null);
    logger.debug(""String_Node_Str"",data.toString());
    collector.emit(SimulatorTopology.KAFKA_BOLT_STREAM,tuple,new Values(""String_Node_Str"",Utils.MAPPER.writeValueAsString(infoMessage)));
  }
}"
37855,"@Override public void execute(Tuple tuple){
  logger.debug(""String_Node_Str"",tuple.toString());
  try {
    String tupleSource=tuple.getSourceComponent();
switch (tupleSource) {
case SimulatorTopology.COMMAND_BOLT:
case SimulatorTopology.SWITCH_BOLT:
      doCommand(tuple);
    break;
case SimulatorTopology.SIMULATOR_COMMAND_BOLT:
  doSimulatorCommand(tuple);
break;
default :
logger.error(""String_Node_Str"",tupleSource);
}
}
 catch (Exception e) {
logger.error(e);
e.printStackTrace();
}
 finally {
collector.ack(tuple);
}
}","@Override public void execute(Tuple tuple){
  logger.debug(""String_Node_Str"",tuple.toString());
  try {
    String tupleSource=tuple.getSourceComponent();
switch (tupleSource) {
case SimulatorTopology.COMMAND_BOLT:
case SimulatorTopology.SWITCH_BOLT:
      doCommand(tuple);
    break;
case SimulatorTopology.SIMULATOR_COMMAND_BOLT:
  doSimulatorCommand(tuple);
break;
default :
logger.error(""String_Node_Str"",tupleSource);
}
}
 catch (Exception e) {
logger.error(e.toString());
e.printStackTrace();
}
 finally {
collector.ack(tuple);
}
}"
37856,"@Test public void getFlowName() throws Exception {
  assertEquals(flowName,flow.getCookie());
}","@Test public void getFlowName() throws Exception {
  assertEquals(flowName,flow.getFlowName());
}"
37857,"/** 
 * Instance constructor.
 * @param flowName        name of the flow
 * @param switchId        switch ID for flow installation
 * @param inputPort       input port of the flow
 * @param outputPort      output port of the flow
 * @param inputVlanId     input vlan id value
 * @param outputVlanId    output vlan id value
 * @param outputVlanType  output vlan tag action
 * @param bandwidth       flow bandwidth
 * @param inputMeterId    allocated meter id
 * @param outputMeterId   allocated meter id
 * @throws IllegalArgumentException if any of arguments is null
 */
@JsonCreator public InstallOneSwitchFlowCommandData(@JsonProperty(""String_Node_Str"") String cookie,@JsonProperty(""String_Node_Str"") String switchId,@JsonProperty(""String_Node_Str"") Number inputPort,@JsonProperty(""String_Node_Str"") Number outputPort,@JsonProperty(""String_Node_Str"") Number inputVlanId,@JsonProperty(""String_Node_Str"") Number outputVlanId,@JsonProperty(""String_Node_Str"") OutputVlanType outputVlanType,@JsonProperty(""String_Node_Str"") Number bandwidth,@JsonProperty(""String_Node_Str"") Number inputMeterId,@JsonProperty(""String_Node_Str"") Number outputMeterId){
  super(cookie,switchId,inputPort,outputPort);
  setInputVlanId(inputVlanId);
  setOutputVlanId(outputVlanId);
  setOutputVlanType(outputVlanType);
  setBandwidth(bandwidth);
  setInputMeterId(inputMeterId);
  setOutputMeterId(outputMeterId);
}","/** 
 * Instance constructor.
 * @param flowName        name of the flow
 * @param switchId        switch ID for flow installation
 * @param inputPort       input port of the flow
 * @param outputPort      output port of the flow
 * @param inputVlanId     input vlan id value
 * @param outputVlanId    output vlan id value
 * @param outputVlanType  output vlan tag action
 * @param bandwidth       flow bandwidth
 * @param inputMeterId    allocated meter id
 * @param outputMeterId   allocated meter id
 * @throws IllegalArgumentException if any of arguments is null
 */
@JsonCreator public InstallOneSwitchFlowCommandData(@JsonProperty(""String_Node_Str"") String flowName,@JsonProperty(""String_Node_Str"") String switchId,@JsonProperty(""String_Node_Str"") Number inputPort,@JsonProperty(""String_Node_Str"") Number outputPort,@JsonProperty(""String_Node_Str"") Number inputVlanId,@JsonProperty(""String_Node_Str"") Number outputVlanId,@JsonProperty(""String_Node_Str"") OutputVlanType outputVlanType,@JsonProperty(""String_Node_Str"") Number bandwidth,@JsonProperty(""String_Node_Str"") Number inputMeterId,@JsonProperty(""String_Node_Str"") Number outputMeterId){
  super(flowName,switchId,inputPort,outputPort);
  setInputVlanId(inputVlanId);
  setOutputVlanId(outputVlanId);
  setOutputVlanType(outputVlanType);
  setBandwidth(bandwidth);
  setInputMeterId(inputMeterId);
  setOutputMeterId(outputMeterId);
}"
37858,"/** 
 * {@inheritDoc}
 */
@Override public String toString(){
  return toStringHelper(this).addValue(cookie).addValue(switchId).addValue(inputPort).addValue(outputPort).addValue(inputVlanId).addValue(outputVlanId).addValue(outputVlanType).addValue(bandwidth).addValue(inputMeterId).addValue(outputMeterId).toString();
}","/** 
 * {@inheritDoc}
 */
@Override public String toString(){
  return toStringHelper(this).addValue(flowName).addValue(switchId).addValue(inputPort).addValue(outputPort).addValue(inputVlanId).addValue(outputVlanId).addValue(outputVlanType).addValue(bandwidth).addValue(inputMeterId).addValue(outputMeterId).toString();
}"
37859,"/** 
 * The data field holds the ""message_type"" and ""state"" fields.
 * @param root the ""data"" field of an ""INFO"" message
 */
private void splitInfoMessage(Map<String,?> root,Tuple tuple) throws JsonProcessingException {
  Values dataVal=new Values(""String_Node_Str"",new ObjectMapper().writeValueAsString(root));
  String key=((String)root.get(""String_Node_Str"")).toLowerCase();
  String state=(String)root.get(""String_Node_Str"");
switch (key) {
case ""String_Node_Str"":
    _collector.emit(I_SWITCH,tuple,dataVal);
  logger.debug(""String_Node_Str"",I_SWITCH,dataVal);
if (state.equals(""String_Node_Str"") || state.equals(""String_Node_Str"")) {
  _collector.emit(I_SWITCH_UPDOWN,tuple,dataVal);
  logger.debug(""String_Node_Str"",I_SWITCH_UPDOWN,dataVal);
}
 else {
  _collector.emit(I_SWITCH_OTHER,tuple,dataVal);
  logger.debug(""String_Node_Str"",I_SWITCH_OTHER,dataVal);
}
break;
case ""String_Node_Str"":
_collector.emit(I_PORT,tuple,dataVal);
if (state.equals(""String_Node_Str"") || state.equals(""String_Node_Str"")) {
_collector.emit(I_PORT_UPDOWN,tuple,dataVal);
}
 else {
_collector.emit(I_PORT_OTHER,tuple,dataVal);
}
break;
case ""String_Node_Str"":
_collector.emit(I_ISL,tuple,dataVal);
if (state.equals(""String_Node_Str"") || state.equals(""String_Node_Str"")) {
_collector.emit(I_ISL_UPDOWN,tuple,dataVal);
}
 else {
_collector.emit(I_ISL_OTHER,tuple,dataVal);
}
break;
default :
_collector.emit(I_OTHER,tuple,dataVal);
logger.warn(""String_Node_Str"",key,root);
}
}","/** 
 * The data field holds the ""message_type"" and ""state"" fields.
 * @param root the ""data"" field of an ""INFO"" message
 */
private void splitInfoMessage(Map<String,?> root,Tuple tuple) throws JsonProcessingException {
  Values dataVal=new Values(""String_Node_Str"",new ObjectMapper().writeValueAsString(root));
  String key=((String)root.get(""String_Node_Str"")).toLowerCase();
  String state=(String)root.get(""String_Node_Str"");
switch (key) {
case ""String_Node_Str"":
    _collector.emit(I_SWITCH,tuple,dataVal);
  logger.debug(""String_Node_Str"",I_SWITCH,dataVal);
if (state.equals(""String_Node_Str"") || state.equals(""String_Node_Str"")) {
  _collector.emit(I_SWITCH_UPDOWN,tuple,dataVal);
  logger.debug(""String_Node_Str"",I_SWITCH_UPDOWN,dataVal);
}
 else {
  _collector.emit(I_SWITCH_OTHER,tuple,dataVal);
  logger.debug(""String_Node_Str"",I_SWITCH_OTHER,dataVal);
}
break;
case ""String_Node_Str"":
_collector.emit(I_PORT,tuple,dataVal);
logger.debug(""String_Node_Str"",I_PORT,dataVal);
if (state.equals(""String_Node_Str"") || state.equals(""String_Node_Str"")) {
_collector.emit(I_PORT_UPDOWN,tuple,dataVal);
}
 else {
_collector.emit(I_PORT_OTHER,tuple,dataVal);
}
break;
case ""String_Node_Str"":
_collector.emit(I_ISL,tuple,dataVal);
logger.debug(""String_Node_Str"",I_ISL,dataVal);
if (state != null && (state.equals(""String_Node_Str"") || state.equals(""String_Node_Str""))) {
_collector.emit(I_ISL_UPDOWN,tuple,dataVal);
}
 else {
_collector.emit(I_ISL_OTHER,tuple,dataVal);
}
break;
default :
_collector.emit(I_OTHER,tuple,dataVal);
logger.warn(""String_Node_Str"",key,root);
}
}"
37860,"/** 
 * This will create all of the topics passed in. - Currently doesn't check to see if they already exist.
 */
public void createTopics(String[] topics,int partitions,int replication){
  int sessionTimeoutMs=5 * 1000;
  int connectionTimeoutMs=5 * 1000;
  ZkClient zkClient=new ZkClient(zookeeperHost,sessionTimeoutMs,connectionTimeoutMs,ZKStringSerializer$.MODULE$);
  boolean isSecureKafkaCluster=false;
  ZkUtils zkUtils=new ZkUtils(zkClient,new ZkConnection(zookeeperHost),isSecureKafkaCluster);
  Properties topicConfig=new Properties();
  for (  String topic : topics) {
    AdminUtils.createTopic(zkUtils,topic,partitions,replication,topicConfig,RackAwareMode.Disabled$.MODULE$);
  }
  zkClient.close();
}","/** 
 * Create the topic, using the default setting for Partitions and Replication
 */
public void createTopics(String[] topics){
  createTopics(topics,1,1);
}"
37861,"public void primeKafkaTopic(String topic){
  kProducer.send(new ProducerRecord<>(topic,""String_Node_Str"",""String_Node_Str""));
}","public void primeKafkaTopic(String topic){
  if (!kutils.topicExists(topic)) {
    kutils.createTopics(new String[]{topic});
  }
}"
37862,"public StormTopology createTopology(){
  logger.debug(""String_Node_Str"" + this.getClass().getSimpleName());
  TopologyBuilder builder=new TopologyBuilder();
  BoltDeclarer kbolt=builder.setBolt(kafkaOutputTopic + ""String_Node_Str"",kutils.createKafkaBolt(kafkaOutputTopic),parallelism);
  BoltDeclarer[] tbolt=new BoltDeclarer[bolts.length];
  for (int i=0; i < topics.length; i++) {
    String topic=topics[i];
    String spoutName=topic + ""String_Node_Str"";
    String boltName=topic + ""String_Node_Str"";
    builder.setSpout(spoutName,kutils.createKafkaSpout(topic));
    tbolt[i]=builder.setBolt(boltName,bolts[i],parallelism).shuffleGrouping(spoutName);
    kbolt=kbolt.shuffleGrouping(boltName,kafkaOutputTopic);
  }
  tbolt[2].shuffleGrouping(topics[0] + ""String_Node_Str"",kafkaOutputTopic).shuffleGrouping(topics[1] + ""String_Node_Str"",kafkaOutputTopic);
  String discoTopic=((OFELinkBolt)bolts[2]).islDiscoTopic;
  builder.setBolt(""String_Node_Str"",kutils.createKafkaBolt(discoTopic),parallelism).shuffleGrouping(topics[2] + ""String_Node_Str"",discoTopic);
  return builder.createTopology();
}","public StormTopology createTopology(){
  logger.debug(""String_Node_Str"" + this.getClass().getSimpleName());
  TopologyBuilder builder=new TopologyBuilder();
  primeTopic(kafkaOutputTopic);
  BoltDeclarer kbolt=builder.setBolt(kafkaOutputTopic + ""String_Node_Str"",kutils.createKafkaBolt(kafkaOutputTopic),parallelism);
  BoltDeclarer[] tbolt=new BoltDeclarer[bolts.length];
  for (int i=0; i < topics.length; i++) {
    String topic=topics[i];
    String spoutName=topic + ""String_Node_Str"";
    String boltName=topic + ""String_Node_Str"";
    primeTopic(topic);
    builder.setSpout(spoutName,kutils.createKafkaSpout(topic));
    tbolt[i]=builder.setBolt(boltName,bolts[i],parallelism).shuffleGrouping(spoutName);
    kbolt=kbolt.shuffleGrouping(boltName,kafkaOutputTopic);
  }
  tbolt[2].shuffleGrouping(topics[0] + ""String_Node_Str"",kafkaOutputTopic).shuffleGrouping(topics[1] + ""String_Node_Str"",kafkaOutputTopic);
  String discoTopic=((OFELinkBolt)bolts[2]).islDiscoTopic;
  builder.setBolt(""String_Node_Str"",kutils.createKafkaBolt(discoTopic),parallelism).shuffleGrouping(topics[2] + ""String_Node_Str"",discoTopic);
  return builder.createTopology();
}"
37863,"private List<Flow> loadFlows(String whereClause){
  String q=""String_Node_Str"" + whereClause + ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str"";
  logger.debug(""String_Node_Str"",q);
  try (Session session=driver.session(AccessMode.READ)){
    StatementResult queryResults=session.run(q);
    List<Flow> results=new ArrayList<>();
    for (    Record record : queryResults.list()) {
      FlowAdapter adapter=new FlowAdapter(record);
      results.add(adapter.getFlow());
    }
    return results;
  }
 }","private List<Flow> loadFlows(String whereClause,Value parameters){
  String q=""String_Node_Str"" + whereClause + ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str"";
  logger.debug(""String_Node_Str"",q);
  try (Session session=driver.session(AccessMode.READ)){
    StatementResult queryResults=session.run(q,parameters);
    List<Flow> results=new ArrayList<>();
    for (    Record record : queryResults.list()) {
      FlowAdapter adapter=new FlowAdapter(record);
      results.add(adapter.getFlow());
    }
    return results;
  }
 }"
37864,"@Override public List<Flow> getFlows(String flowId){
  String where=""String_Node_Str"" + flowId + ""String_Node_Str"";
  return loadFlows(where);
}","@Override public List<Flow> getFlows(String flowId){
  String where=""String_Node_Str"";
  Value parameters=Values.parameters(""String_Node_Str"",flowId);
  return loadFlows(where,parameters);
}"
37865,"@Override public List<Flow> getAllFlows(){
  String noWhere=""String_Node_Str"";
  return loadFlows(noWhere);
}","@Override public List<Flow> getAllFlows(){
  String noWhere=""String_Node_Str"";
  return loadFlows(noWhere,null);
}"
37866,"@Given(""String_Node_Str"") public void selectARandomSwitch(String switchAlias){
  List<Switch> switches=getUnaliasedSwitches();
  Random r=new Random();
  Switch theSwitch=switches.get(r.nextInt(switches.size()));
  log.info(""String_Node_Str"",theSwitch.getDpId());
  topologyUnderTest.addAlias(switchAlias,theSwitch);
}","@Given(""String_Node_Str"") public void selectARandomSwitch(String switchAlias){
  List<Switch> switches=getUnaliasedSwitches();
  Assume.assumeFalse(""String_Node_Str"",CollectionUtils.isEmpty(switches));
  Switch theSwitch=switches.get(0);
  log.info(""String_Node_Str"",theSwitch.getDpId());
  topologyUnderTest.addAlias(switchAlias,theSwitch);
}"
37867,"/** 
 * Checks if discovery should be suspended for that link.
 * @return true if link should be excluded from discovery plan and discovery packets should not be sent.
 */
public boolean isNewAttemptAllowed(){
  if (consecutiveFailureLimit == ENDLESS_ATTEMPTS) {
    return true;
  }
  return consecutiveFailure < consecutiveFailureLimit;
}","/** 
 * Checks if discovery should be suspended for that link or we can try to discover it.
 * @return true if link should be excluded from discovery plan and discovery packets should not be sent.
 */
public boolean isNewAttemptAllowed(){
  if (consecutiveFailureLimit == ENDLESS_ATTEMPTS) {
    return true;
  }
  return consecutiveFailure < consecutiveFailureLimit;
}"
37868,"/** 
 * This helper function is used with getPath(hint) to confirm the hint path exists 
 */
private SearchNode confirmIsls(List<SimpleIsl> srcIsls){
  int totalCost=0;
  LinkedList<SimpleIsl> confirmedIsls=new LinkedList<>();
  boolean validPath=true;
  for (  SimpleIsl i : srcIsls) {
    boolean foundThisOne=false;
    SimpleSwitch srcSwitch=network.getSimpleSwitch(i.src_dpid);
    if (srcSwitch != null) {
      Set<SimpleIsl> pathsToDst=safeSet(srcSwitch.outbound.get(i.dst_dpid));
      if (pathsToDst.equals(Collections.EMPTY_SET))       logger.debug(""String_Node_Str"",i.src_dpid,i.dst_dpid);
      for (      SimpleIsl orig : pathsToDst) {
        if (i.equals(orig)) {
          foundThisOne=true;
          confirmedIsls.add(orig);
          totalCost+=orig.cost;
          break;
        }
      }
    }
 else {
      logger.warn(""String_Node_Str"",i.src_dpid);
    }
    if (!foundThisOne) {
      validPath=false;
      break;
    }
  }
  if (validPath) {
    return new SearchNode(this.allowedDepth - confirmedIsls.size(),totalCost,network.getSimpleSwitch(confirmedIsls.peekLast().dst_dpid),confirmedIsls);
  }
  return null;
}","/** 
 * This helper function is used with getPath(hint) to confirm the hint path exists. 
 */
private SearchNode confirmIsls(List<SimpleIsl> srcIsls){
  int totalCost=0;
  LinkedList<SimpleIsl> confirmedIsls=new LinkedList<>();
  boolean validPath=true;
  for (  SimpleIsl i : srcIsls) {
    boolean foundThisOne=false;
    SimpleSwitch srcSwitch=network.getSimpleSwitch(i.getSrcDpid());
    if (srcSwitch != null) {
      Set<SimpleIsl> pathsToDst=srcSwitch.outbound.get(i.getDstDpid());
      for (      SimpleIsl orig : pathsToDst) {
        if (i.equals(orig)) {
          foundThisOne=true;
          confirmedIsls.add(orig);
          totalCost+=orig.getCost();
          break;
        }
      }
    }
 else {
      logger.warn(""String_Node_Str"",i.getSrcDpid());
    }
    if (!foundThisOne) {
      validPath=false;
      break;
    }
  }
  if (validPath) {
    return new SearchNode(this.allowedDepth - confirmedIsls.size(),totalCost,network.getSimpleSwitch(confirmedIsls.peekLast().getDstDpid()),confirmedIsls);
  }
  return null;
}"
37869,"/** 
 * This helper function is used with getPath(hint) and will swap the src and dst of each isl in the list 
 */
private List<SimpleIsl> swapSrcDst(List<SimpleIsl> originalIsls){
  List<SimpleIsl> mirrorIsls=new ArrayList<>();
  for (  SimpleIsl original : originalIsls) {
    mirrorIsls.add(new SimpleIsl(original.dst_dpid,original.src_dpid,original.dst_port,original.src_port,original.cost,original.latency));
  }
  return mirrorIsls;
}","/** 
 * This helper function is used with getPath(hint) and will swap the src and dst of each isl in the list. 
 */
private List<SimpleIsl> swapSrcDst(List<SimpleIsl> originalIsls){
  List<SimpleIsl> mirrorIsls=new ArrayList<>();
  for (  SimpleIsl original : originalIsls) {
    mirrorIsls.add(new SimpleIsl(original.getDstDpid(),original.getSrcDpid(),original.getDstPort(),original.getSrcPort(),original.getCost(),original.getLatency()));
  }
  return mirrorIsls;
}"
37870,"public SearchNode addNode(SimpleIsl nextIsl){
  SearchNode newNode=this.clone();
  newNode.parentPath.add(nextIsl);
  newNode.dst_sw=network.getSimpleSwitch(nextIsl.dst_dpid);
  newNode.allowedDepth--;
  newNode.parentCost+=nextIsl.cost;
  return newNode;
}","SearchNode addNode(SimpleIsl nextIsl){
  SearchNode newNode=this.clone();
  newNode.parentPath.add(nextIsl);
  newNode.dstSw=network.getSimpleSwitch(nextIsl.getDstDpid());
  newNode.allowedDepth--;
  newNode.parentCost+=nextIsl.getCost();
  return newNode;
}"
37871,"/** 
 * This is generally called after getPath() to find the path back.  The path back could be asymmetric, but this will increase the odds that we return the symmetric path if it exists. The hint will be used to determine if it exists.  If it does, then use it as the start bestCost and bestPath.  That should help speed things along. Whereas it's possible that could build up the SearchNodes for this path (if found) and put them into the visited bucket, we'll start without that optimization and decide later whether adding it provides any efficiencies
 * @param hint The path to use as a starting point. It can be in reverse order (we'll reverse it)
 * @return An ordered list that represents the path from start to end.
 */
public LinkedList<SimpleIsl> getPath(List<SimpleIsl> hint){
  if (hint != null && hint.size() > 0) {
    SimpleSwitch from=network.getSimpleSwitch(hint.get(0).src_dpid);
    SimpleSwitch to=network.getSimpleSwitch(hint.get(hint.size() - 1).dst_dpid);
    if (start.equals(to) && end.equals(from)) {
      logger.trace(""String_Node_Str"",from,to,to,from);
      hint=swapSrcDst(Lists.reverse(hint));
      from=network.getSimpleSwitch(hint.get(0).src_dpid);
      to=network.getSimpleSwitch(hint.get(hint.size() - 1).dst_dpid);
    }
    if (start.equals(from) && end.equals(to)) {
      logger.trace(""String_Node_Str"",from,to);
      SearchNode best=confirmIsls(hint);
      if (best != null) {
        logger.debug(""String_Node_Str"",from,to);
        bestCost=best.parentCost;
        bestPath=best;
      }
 else {
        logger.info(""String_Node_Str"",from,to);
      }
    }
  }
  return getPath();
}","/** 
 * This is generally called after getPath() to find the path back.  The path back could be asymmetric, but this will increase the odds that we return the symmetric path if it exists. The hint will be used to determine if it exists.  If it does, then use it as the start bestCost and bestPath.  That should help speed things along. <p/> Whereas it's possible that could build up the SearchNodes for this path (if found) and put them into the visited bucket, we'll start without that optimization and decide later whether adding it provides any efficiencies
 * @param hint The path to use as a starting point. It can be in reverse order (we'll reverse it)
 * @return An ordered list that represents the path from start to end.
 */
public LinkedList<SimpleIsl> getPath(List<SimpleIsl> hint){
  if (hint != null && hint.size() > 0) {
    SimpleSwitch from=network.getSimpleSwitch(hint.get(0).getSrcDpid());
    SimpleSwitch to=network.getSimpleSwitch(hint.get(hint.size() - 1).getDstDpid());
    if (start.equals(to) && end.equals(from)) {
      logger.trace(""String_Node_Str"",from,to,to,from);
      hint=swapSrcDst(Lists.reverse(hint));
      from=network.getSimpleSwitch(hint.get(0).getSrcDpid());
      to=network.getSimpleSwitch(hint.get(hint.size() - 1).getDstDpid());
    }
    if (start.equals(from) && end.equals(to)) {
      logger.trace(""String_Node_Str"",from,to);
      SearchNode best=confirmIsls(hint);
      if (best != null) {
        logger.debug(""String_Node_Str"",from,to);
        bestCost=best.parentCost;
        bestPath=best;
      }
 else {
        logger.info(""String_Node_Str"",from,to);
      }
    }
  }
  return getPath();
}"
37872,"@Override @SuppressWarnings(""String_Node_Str"") protected SearchNode clone(){
  return new SearchNode(allowedDepth,parentCost,dst_sw,(LinkedList<SimpleIsl>)parentPath.clone());
}","@Override @SuppressWarnings(""String_Node_Str"") protected SearchNode clone(){
  return new SearchNode(allowedDepth,parentCost,dstSw,(LinkedList<SimpleIsl>)parentPath.clone());
}"
37873,"public SearchNode(int allowedDepth,int parentCost,SimpleSwitch dst_sw,LinkedList<SimpleIsl> parentPath){
  this.dst_sw=dst_sw;
  this.allowedDepth=allowedDepth;
  this.parentCost=parentCost;
  this.parentPath=parentPath;
}","SearchNode(int allowedDepth,int parentCost,SimpleSwitch dstSw,LinkedList<SimpleIsl> parentPath){
  this.dstSw=dstSw;
  this.allowedDepth=allowedDepth;
  this.parentCost=parentCost;
  this.parentPath=parentPath;
}"
37874,"public SimpleGetShortestPath(AvailableNetwork network,String src_dpid,String dst_dpid,int allowedDepth){
  this.network=network;
  this.start=network.getSwitches().get(src_dpid);
  this.end=network.getSwitches().get(dst_dpid);
  this.allowedDepth=allowedDepth;
  if (this.start == null)   logger.warn(""String_Node_Str"",src_dpid);
  if (this.end == null)   logger.warn(""String_Node_Str"",dst_dpid);
}","public SimpleGetShortestPath(AvailableNetwork network,String srcDpid,String dstDpid,int allowedDepth){
  this.network=network;
  this.start=network.getSwitches().get(srcDpid);
  this.end=network.getSwitches().get(dstDpid);
  this.allowedDepth=allowedDepth;
  if (this.start == null) {
    logger.warn(""String_Node_Str"",srcDpid);
  }
  if (this.end == null) {
    logger.warn(""String_Node_Str"",dstDpid);
  }
}"
37875,"/** 
 * Use this comparison if very strong equality is needed (most likely rare; probably only testing)
 * @return true if every field is the same.
 */
public boolean identical(Object o){
  if (this.equals(o)) {
    SimpleIsl simpleIsl=(SimpleIsl)o;
    return cost == simpleIsl.cost && latency == simpleIsl.latency;
  }
  return false;
}","/** 
 * Use this comparison if very strong equality is needed (most likely rare; probably only testing).
 * @return true if every field is the same.
 */
public boolean identical(Object o){
  if (this.equals(o)) {
    SimpleIsl simpleIsl=(SimpleIsl)o;
    return cost == simpleIsl.cost && latency == simpleIsl.latency;
  }
  return false;
}"
37876,"public SimpleIsl(String src_dpid,String dst_dpid,int src_port,int dst_port,int cost,int latency){
  this.src_dpid=src_dpid;
  this.dst_dpid=dst_dpid;
  this.src_port=src_port;
  this.dst_port=dst_port;
  this.cost=(cost == 0) ? DEFAULT_COST : cost;
  this.latency=latency;
}","public SimpleIsl(String srcDpid,String dstDpid,int srcPort,int dstPort,int cost,int latency){
  this.srcDpid=srcDpid;
  this.dstDpid=dstDpid;
  this.srcPort=srcPort;
  this.dstPort=dstPort;
  this.cost=(cost == 0) ? DEFAULT_COST : cost;
  this.latency=latency;
}"
37877,"public SimpleSwitch addOutbound(SimpleIsl isl){
  outbound.computeIfAbsent(isl.dst_dpid,newSet -> new HashSet<>()).add(isl);
  return this;
}","public SimpleSwitch addOutbound(SimpleIsl isl){
  outbound.computeIfAbsent(isl.getDstDpid(),newSet -> new HashSet<>()).add(isl);
  return this;
}"
37878,"@Builder @JsonCreator public LinkProps(@JsonProperty(""String_Node_Str"") NetworkEndpoint source,@JsonProperty(""String_Node_Str"") NetworkEndpoint dest,@JsonProperty(""String_Node_Str"") Map<String,String> props){
  this.source=source;
  this.dest=dest;
  this.props=props;
}","public LinkProps(NetworkEndpoint source,NetworkEndpoint dest,Map<String,String> props){
  this.source=source;
  this.dest=dest;
  this.props=props;
  this.created=null;
  this.modified=null;
}"
37879,"public boolean isReadRequest(){
  return this.getClass().isAnnotationPresent(ReadRequest.class);
}","@JsonIgnore public boolean isReadRequest(){
  return this.getClass().isAnnotationPresent(ReadRequest.class);
}"
37880,"public LinkPropsData(@JsonProperty(""String_Node_Str"") NetworkEndpoint source,@JsonProperty(""String_Node_Str"") NetworkEndpoint destination,@JsonProperty(""String_Node_Str"") Map<String,String> props){
  this.source=source;
  this.destination=destination;
  this.props=props;
}","public LinkPropsData(@JsonProperty(""String_Node_Str"") LinkProps linkProps){
  this.linkProps=linkProps;
}"
37881,"/** 
 * Produce   {@link LinkProps} object with predefined data.
 */
public static LinkProps makeSubject(){
  NetworkEndpoint source=new NetworkEndpoint(""String_Node_Str"",8);
  NetworkEndpoint dest=new NetworkEndpoint(""String_Node_Str"",9);
  HashMap<String,String> props=new HashMap<>();
  props.put(""String_Node_Str"",""String_Node_Str"");
  return new LinkProps(source,dest,props);
}","/** 
 * Produce   {@link LinkProps} object with predefined data.
 */
public static LinkProps makeSubject(){
  NetworkEndpoint source=new NetworkEndpoint(""String_Node_Str"",8);
  NetworkEndpoint dest=new NetworkEndpoint(""String_Node_Str"",9);
  HashMap<String,String> props=new HashMap<>();
  props.put(""String_Node_Str"",""String_Node_Str"");
  long created=System.currentTimeMillis();
  return new LinkProps(source,dest,props,created,created);
}"
37882,"/** 
 * Converts link properties to   {@link LinkPropsDto}.
 */
default LinkPropsDto toDto(LinkPropsData data){
  NetworkEndpoint source=data.getSource();
  NetworkEndpoint destination=data.getDestination();
  return new LinkPropsDto(source.getDatapath(),source.getPortNumber(),destination.getDatapath(),destination.getPortNumber(),data.getProps());
}","/** 
 * Converts link properties to   {@link LinkPropsDto}.
 */
default LinkPropsDto toDto(LinkPropsData data){
  requireNonNull(data.getLinkProps(),""String_Node_Str"");
  NetworkEndpoint source=data.getLinkProps().getSource();
  NetworkEndpoint destination=data.getLinkProps().getDest();
  return new LinkPropsDto(source.getDatapath(),source.getPortNumber(),destination.getDatapath(),destination.getPortNumber(),data.getLinkProps().getProps());
}"
37883,"@Test public void shouldGetPropsList(){
  final String correlationId=""String_Node_Str"";
  LinkPropsData linkProps=new LinkPropsData(new NetworkEndpoint(""String_Node_Str"",1),new NetworkEndpoint(""String_Node_Str"",2),Collections.singletonMap(""String_Node_Str"",""String_Node_Str""));
  Message message=new ChunkedInfoMessage(linkProps,0,correlationId,null);
  messageExchanger.mockResponse(message);
  RequestCorrelationId.create(correlationId);
  List<LinkPropsDto> result=linkService.getLinkProps(null,0,null,0);
  assertFalse(""String_Node_Str"",result.isEmpty());
  LinkPropsDto dto=result.get(0);
  assertThat(dto.getSrcSwitch(),is(linkProps.getSource().getDatapath()));
  assertThat(dto.getSrcPort(),is(linkProps.getSource().getPortNumber()));
  assertThat(dto.getDstSwitch(),is(linkProps.getDestination().getDatapath()));
  assertThat(dto.getDstPort(),is(linkProps.getDestination().getPortNumber()));
}","@Test public void shouldGetPropsList(){
  final String correlationId=""String_Node_Str"";
  LinkProps linkProps=new LinkProps(new NetworkEndpoint(""String_Node_Str"",1),new NetworkEndpoint(""String_Node_Str"",2),Collections.singletonMap(""String_Node_Str"",""String_Node_Str""));
  LinkPropsData linkPropsData=new LinkPropsData(linkProps);
  Message message=new ChunkedInfoMessage(linkPropsData,0,correlationId,null);
  messageExchanger.mockResponse(message);
  RequestCorrelationId.create(correlationId);
  List<LinkPropsDto> result=linkService.getLinkProps(null,0,null,0);
  assertFalse(""String_Node_Str"",result.isEmpty());
  LinkPropsDto dto=result.get(0);
  assertThat(dto.getSrcSwitch(),is(linkPropsData.getLinkProps().getSource().getDatapath()));
  assertThat(dto.getSrcPort(),is(linkPropsData.getLinkProps().getSource().getPortNumber()));
  assertThat(dto.getDstSwitch(),is(linkPropsData.getLinkProps().getDest().getDatapath()));
  assertThat(dto.getDstPort(),is(linkPropsData.getLinkProps().getDest().getPortNumber()));
}"
37884,"private Set<String> availablePermissions(final UserInfo userInfo){
  Set<String> availablePermissions=new HashSet<>();
  Set<String> roles=userInfo.getRoles();
  if (roles != null && roles.size() > 0) {
    List<Role> roleList=roleService.getRoleByName(roles);
    for (    Role role : roleList) {
      if (role.getPermissions() != null) {
        for (        Permission permission : role.getPermissions()) {
          if (Status.ACTIVE.getStatusEntity().getStatus().equalsIgnoreCase(permission.getStatus())) {
            availablePermissions.add(permission.getName());
          }
        }
      }
    }
  }
  return availablePermissions;
}","private Set<String> availablePermissions(final UserInfo userInfo){
  Set<String> availablePermissions=new HashSet<>();
  if (userInfo.getUserId() != 1) {
    Set<String> roles=userInfo.getRoles();
    if (roles != null && roles.size() > 0) {
      List<Role> roleList=roleService.getRoleByName(roles);
      for (      Role role : roleList) {
        if (role.getPermissions() != null) {
          for (          Permission permission : role.getPermissions()) {
            if (Status.ACTIVE.getStatusEntity().getStatus().equalsIgnoreCase(permission.getStatus())) {
              availablePermissions.add(permission.getName());
            }
          }
        }
      }
    }
  }
 else {
    List<Permission> permissions=permissionService.getAllPermission(userInfo.getUserId());
    for (    Permission permission : permissions) {
      availablePermissions.add(permission.getName());
    }
  }
  userInfo.setPermissions(availablePermissions);
  return availablePermissions;
}"
37885,"private void validateAndPopulatePermisssion(final UserInfo userInfo,final Permissions permissions) throws Exception {
  if (!permissions.checkObjectAccessPermissions()) {
    if (!hasPermissions(userInfo,permissions.values())) {
      throw new AccessDeniedException(messageUtils.getUnauthorizedMessage());
    }
  }
}","private void validateAndPopulatePermisssion(final UserInfo userInfo,final Permissions permissions) throws Exception {
  if (!permissions.checkObjectAccessPermissions()) {
    if (!hasPermissions(userInfo,permissions.values())) {
      LOGGER.error(""String_Node_Str"" + userInfo.getUserId() + ""String_Node_Str""+ permissions.values());
      throw new AccessDeniedException(messageUtils.getUnauthorizedMessage());
    }
  }
}"
37886,"@Override public boolean preHandle(final HttpServletRequest request,final HttpServletResponse response,final Object handler) throws Exception {
  String correlationId=request.getParameter(CORRELATION_ID);
  correlationId=correlationId == null ? UUID.randomUUID().toString() : correlationId;
  try {
    MDC.put(CORRELATION_ID,correlationId);
    HttpSession session=request.getSession();
    UserInfo userInfo=null;
    userInfo=(UserInfo)session.getAttribute(IConstants.SESSION_OBJECT);
    if (userInfo != null) {
      if (handler instanceof HandlerMethod) {
        HandlerMethod handlerMethod=(HandlerMethod)handler;
        Permissions permissions=handlerMethod.getMethod().getAnnotation(Permissions.class);
        LOGGER.info(""String_Node_Str"");
        if (permissions != null) {
          LOGGER.info(""String_Node_Str"" + permissions.values());
          validateAndPopulatePermisssion(userInfo,permissions);
        }
      }
      updateRequestContext(correlationId,request,userInfo);
    }
  }
 catch (  IllegalStateException ex) {
    LOGGER.info(""String_Node_Str"" + ex.getLocalizedMessage(),ex);
  }
  return true;
}","@Override public boolean preHandle(final HttpServletRequest request,final HttpServletResponse response,final Object handler) throws Exception {
  String correlationId=request.getParameter(CORRELATION_ID);
  correlationId=correlationId == null ? UUID.randomUUID().toString() : correlationId;
  try {
    MDC.put(CORRELATION_ID,correlationId);
    HttpSession session=request.getSession();
    UserInfo userInfo=null;
    userInfo=(UserInfo)session.getAttribute(IConstants.SESSION_OBJECT);
    if (userInfo != null) {
      if (handler instanceof HandlerMethod) {
        HandlerMethod handlerMethod=(HandlerMethod)handler;
        Permissions permissions=handlerMethod.getMethod().getAnnotation(Permissions.class);
        if (permissions != null) {
          validateAndPopulatePermisssion(userInfo,permissions);
        }
      }
      updateRequestContext(correlationId,request,userInfo);
    }
  }
 catch (  IllegalStateException ex) {
    LOGGER.info(""String_Node_Str"" + ex.getLocalizedMessage(),ex);
  }
  return true;
}"
37887,"/** 
 * Sets request payload.
 * @param payload request payload
 */
public void setPayload(final FlowIdStatusPayload payload){
  if (payload == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  this.payload=payload;
}","/** 
 * Sets request payload.
 * @param payload request payload
 */
public void setPayload(final FlowIdStatusPayload payload){
  this.payload=payload;
}"
37888,"/** 
 * {@inheritDoc}
 */
@Override public List<FlowPayload> getFlows(){
  final String correlationId=RequestCorrelationId.getId();
  LOGGER.debug(""String_Node_Str"",CORRELATION_ID,correlationId);
  FlowsGetRequest data=new FlowsGetRequest(new FlowIdStatusPayload());
  CommandMessage request=new CommandMessage(data,System.currentTimeMillis(),correlationId,Destination.WFM);
  messageConsumer.clear();
  messageProducer.send(topic,request);
  Message message=(Message)messageConsumer.poll(correlationId);
  FlowsResponse response=(FlowsResponse)validateInfoMessage(request,message,correlationId);
  List<FlowPayload> result=collectFlows(response.getFlowIds(),correlationId);
  logger.debug(""String_Node_Str"",CORRELATION_ID,correlationId,result.size());
  return result;
}","/** 
 * {@inheritDoc}
 */
@Override public List<FlowPayload> getFlows(){
  final String correlationId=RequestCorrelationId.getId();
  LOGGER.debug(""String_Node_Str"");
  FlowGetRequest data=new FlowGetRequest();
  CommandMessage request=new CommandMessage(data,System.currentTimeMillis(),correlationId,Destination.WFM);
  messageProducer.send(topic,request);
  List<FlowResponse> result=flowsCollector.getResult(correlationId);
  logger.debug(""String_Node_Str"",result.size());
  return result.stream().map(FlowResponse::getPayload).map(FlowPayloadToFlowConverter::buildFlowPayloadByFlow).collect(Collectors.toList());
}"
37889,"/** 
 * Chooses response by request.
 * @param data received from kafka CommandData message payload
 * @return InfoMassage to be send as response payload
 */
private Message formatResponse(final String correlationId,final CommandData data){
  if (data instanceof FlowCreateRequest) {
    return new InfoMessage(flowResponse,0,correlationId,Destination.NORTHBOUND);
  }
 else   if (data instanceof FlowDeleteRequest) {
    return new InfoMessage(flowResponse,0,correlationId,Destination.NORTHBOUND);
  }
 else   if (data instanceof FlowUpdateRequest) {
    return new InfoMessage(flowResponse,0,correlationId,Destination.NORTHBOUND);
  }
 else   if (data instanceof FlowGetRequest) {
    if (ERROR_FLOW_ID.equals(((FlowGetRequest)data).getPayload().getId())) {
      return new ErrorMessage(new ErrorData(ErrorType.NOT_FOUND,""String_Node_Str"",ERROR_FLOW_ID),0,correlationId,Destination.NORTHBOUND);
    }
 else {
      return new InfoMessage(flowResponse,0,correlationId,Destination.NORTHBOUND);
    }
  }
 else   if (data instanceof FlowsGetRequest) {
    return new InfoMessage(flowsResponse,0,correlationId,Destination.NORTHBOUND);
  }
 else   if (data instanceof FlowStatusRequest) {
    return new InfoMessage(flowStatusResponse,0,correlationId,Destination.NORTHBOUND);
  }
 else   if (data instanceof FlowPathRequest) {
    return new InfoMessage(flowPathResponse,0,correlationId,Destination.NORTHBOUND);
  }
 else   if (data instanceof SwitchRulesDeleteRequest) {
    return new InfoMessage(switchRulesResponse,0,correlationId,Destination.NORTHBOUND);
  }
 else {
    return null;
  }
}","/** 
 * Chooses response by request.
 * @param data received from kafka CommandData message payload
 * @return InfoMassage to be send as response payload
 */
private Message formatResponse(final String correlationId,final CommandData data){
  if (data instanceof FlowCreateRequest) {
    return new InfoMessage(flowResponse,0,correlationId,Destination.NORTHBOUND);
  }
 else   if (data instanceof FlowDeleteRequest) {
    return new InfoMessage(flowResponse,0,correlationId,Destination.NORTHBOUND);
  }
 else   if (data instanceof FlowUpdateRequest) {
    return new InfoMessage(flowResponse,0,correlationId,Destination.NORTHBOUND);
  }
 else   if (data instanceof FlowGetRequest) {
    FlowIdStatusPayload request=((FlowGetRequest)data).getPayload();
    return getFlowResponse(request,correlationId);
  }
 else   if (data instanceof FlowStatusRequest) {
    return new InfoMessage(flowStatusResponse,0,correlationId,Destination.NORTHBOUND);
  }
 else   if (data instanceof FlowPathRequest) {
    return new InfoMessage(flowPathResponse,0,correlationId,Destination.NORTHBOUND);
  }
 else   if (data instanceof SwitchRulesDeleteRequest) {
    return new InfoMessage(switchRulesResponse,0,correlationId,Destination.NORTHBOUND);
  }
 else {
    return null;
  }
}"
37890,"private boolean hasPermissions(final UserInfo userInfo,final String... permissions){
  LOGGER.info(""String_Node_Str"");
  boolean hasPermission=true;
  Set<String> availablePermissions=availablePermissions(userInfo);
  if (!availablePermissions.isEmpty()) {
    for (    String permission : permissions) {
      if (!availablePermissions.contains(permission)) {
        hasPermission=false;
        break;
      }
    }
  }
 else {
    hasPermission=false;
  }
  LOGGER.info(""String_Node_Str"");
  return hasPermission;
}","private boolean hasPermissions(final UserInfo userInfo,final String... permissions){
  boolean hasPermission=true;
  Set<String> availablePermissions=availablePermissions(userInfo);
  if (!availablePermissions.isEmpty()) {
    for (    String permission : permissions) {
      if (!availablePermissions.contains(permission)) {
        hasPermission=false;
        break;
      }
    }
  }
 else {
    hasPermission=false;
  }
  return hasPermission;
}"
37891,"private void validateAndPopulatePermisssion(final UserInfo userInfo,final Permissions permissions) throws Exception {
  if (!permissions.checkObjectAccessPermissions()) {
    if (!hasPermissions(userInfo,permissions.values())) {
      throw new AccessDeniedException(messageUtils.getUnauthorizedMessage());
    }
  }
  LOGGER.info(""String_Node_Str"");
}","private void validateAndPopulatePermisssion(final UserInfo userInfo,final Permissions permissions) throws Exception {
  if (!permissions.checkObjectAccessPermissions()) {
    if (!hasPermissions(userInfo,permissions.values())) {
      throw new AccessDeniedException(messageUtils.getUnauthorizedMessage());
    }
  }
}"
37892,"@Override public boolean preHandle(final HttpServletRequest request,final HttpServletResponse response,final Object handler) throws Exception {
  String correlationId=request.getParameter(CORRELATION_ID);
  correlationId=correlationId == null ? UUID.randomUUID().toString() : correlationId;
  try {
    MDC.put(CORRELATION_ID,correlationId);
    HttpSession session=request.getSession();
    UserInfo userInfo=null;
    userInfo=(UserInfo)session.getAttribute(IConstants.SESSION_OBJECT);
    if (userInfo != null) {
      if (handler instanceof HandlerMethod) {
        HandlerMethod handlerMethod=(HandlerMethod)handler;
        Permissions permissions=handlerMethod.getMethod().getAnnotation(Permissions.class);
        LOGGER.info(""String_Node_Str"");
        if (permissions != null) {
          LOGGER.info(""String_Node_Str"" + permissions.values());
          validateAndPopulatePermisssion(userInfo,permissions);
        }
      }
      updateRequestContext(correlationId,request,userInfo);
      LOGGER.info(""String_Node_Str"");
    }
  }
 catch (  IllegalStateException ex) {
    LOGGER.info(""String_Node_Str"" + ex.getLocalizedMessage(),ex);
  }
  return true;
}","@Override public boolean preHandle(final HttpServletRequest request,final HttpServletResponse response,final Object handler) throws Exception {
  String correlationId=request.getParameter(CORRELATION_ID);
  correlationId=correlationId == null ? UUID.randomUUID().toString() : correlationId;
  try {
    MDC.put(CORRELATION_ID,correlationId);
    HttpSession session=request.getSession();
    UserInfo userInfo=null;
    userInfo=(UserInfo)session.getAttribute(IConstants.SESSION_OBJECT);
    if (userInfo != null) {
      if (handler instanceof HandlerMethod) {
        HandlerMethod handlerMethod=(HandlerMethod)handler;
        Permissions permissions=handlerMethod.getMethod().getAnnotation(Permissions.class);
        LOGGER.info(""String_Node_Str"");
        if (permissions != null) {
          LOGGER.info(""String_Node_Str"" + permissions.values());
          validateAndPopulatePermisssion(userInfo,permissions);
        }
      }
      updateRequestContext(correlationId,request,userInfo);
    }
  }
 catch (  IllegalStateException ex) {
    LOGGER.info(""String_Node_Str"" + ex.getLocalizedMessage(),ex);
  }
  return true;
}"
37893,"/** 
 * Return logged in user information.
 * @param request HttpServletRequest to retrieve logged in user information.
 * @return logged in user information.
 */
protected UserInfo getLoggedInUser(final HttpServletRequest request){
  LOGGER.info(""String_Node_Str"");
  HttpSession session=request.getSession();
  UserInfo userInfo=null;
  try {
    userInfo=(UserInfo)session.getAttribute(IConstants.SESSION_OBJECT);
  }
 catch (  IllegalStateException ex) {
    LOGGER.info(""String_Node_Str"" + ex.getLocalizedMessage(),ex);
  }
 finally {
    if (userInfo == null) {
      session=request.getSession(false);
      userInfo=new UserInfo();
      session.setAttribute(IConstants.SESSION_OBJECT,userInfo);
    }
  }
  return userInfo;
}","/** 
 * Return logged in user information.
 * @param request HttpServletRequest to retrieve logged in user information.
 * @return logged in user information.
 */
protected UserInfo getLoggedInUser(final HttpServletRequest request){
  HttpSession session=request.getSession();
  UserInfo userInfo=null;
  try {
    userInfo=(UserInfo)session.getAttribute(IConstants.SESSION_OBJECT);
  }
 catch (  IllegalStateException ex) {
    LOGGER.info(""String_Node_Str"" + ex.getLocalizedMessage(),ex);
  }
 finally {
    if (userInfo == null) {
      session=request.getSession(false);
      userInfo=new UserInfo();
      session.setAttribute(IConstants.SESSION_OBJECT,userInfo);
    }
  }
  return userInfo;
}"
37894,"/** 
 * Sending message.
 * @param receivers the list of receivers.
 * @param subject mail subject.
 * @param template template.
 * @param context Map with context values for velocity template.
 */
public void send(final String receiver,final String subject,final TemplateService.Template template,final Map<String,Object> context){
  MimeMessage mimeMessage=javaMailSender.createMimeMessage();
  MimeMessageHelper msg=new MimeMessageHelper(mimeMessage);
  if (!StringUtil.isNullOrEmpty(receiver)) {
    try {
      msg.setSubject(subject);
      msg.setTo(receiver);
      msg.setText(templateService.mergeTemplateToString(template,context),true);
    }
 catch (    MessagingException e) {
      e.printStackTrace();
    }
    javaMailSender.send(mimeMessage);
  }
}","/** 
 * Sending message.
 * @param receivers the list of receivers.
 * @param subject mail subject.
 * @param template template.
 * @param context Map with context values for velocity template.
 */
public void send(final String receiver,final String subject,final TemplateService.Template template,final Map<String,Object> context){
  MimeMessage mimeMessage=javaMailSender.createMimeMessage();
  MimeMessageHelper msg=new MimeMessageHelper(mimeMessage);
  if (!StringUtil.isNullOrEmpty(receiver)) {
    try {
      msg.setSubject(subject);
      msg.setTo(receiver);
      msg.setText(templateService.mergeTemplateToString(template,context),true);
      javaMailSender.send(mimeMessage);
      LOGGER.info(""String_Node_Str"" + subject);
    }
 catch (    MessagingException e) {
      LOGGER.error(""String_Node_Str"" + e.getMessage(),e);
    }
  }
}"
37895,"@Override public UserDetails loadUserByUsername(final String username) throws UsernameNotFoundException {
  LOGGER.info(""String_Node_Str"");
  UserEntity user=userRepository.findByUsername(username);
  Set<GrantedAuthority> authorities=new HashSet<GrantedAuthority>(0);
  if (user == null) {
    throw new UsernameNotFoundException(username);
  }
  return new org.springframework.security.core.userdetails.User(username,user.getPassword(),authorities);
}","@Override public UserDetails loadUserByUsername(final String username) throws UsernameNotFoundException {
  UserEntity user=userRepository.findByUsername(username);
  Set<GrantedAuthority> authorities=new HashSet<GrantedAuthority>(0);
  if (user == null) {
    throw new UsernameNotFoundException(username);
  }
  return new org.springframework.security.core.userdetails.User(username,user.getPassword(),authorities);
}"
37896,"@Transactional(propagation=Propagation.REQUIRED,readOnly=false) public UserInfo createUser(final UserInfo userRequest){
  userValidator.validateCreateUser(userRequest);
  Set<RoleEntity> roleEntities=new HashSet<>();
  List<RoleEntity> roleEntityList=roleRepository.findAll();
  for (  Long roleId : userRequest.getRoleIds()) {
    RoleEntity roleEntity=roleEntityList.parallelStream().filter((entity) -> entity.getRoleId().equals(roleId)).findFirst().orElse(null);
    if (!ValidatorUtil.isNull(roleEntity)) {
      roleEntities.add(roleEntity);
    }
 else {
      throw new RequestValidationException(messageUtil.getAttributeNotFound(""String_Node_Str""));
    }
  }
  UserEntity userEntity=UserConversionUtil.toUserEntity(userRequest,roleEntities);
  String password=ValidatorUtil.randomAlphaNumeric(16);
  userEntity.setPassword(StringUtil.encodeString(password));
  userEntity.setIs2FaEnabled(true);
  userEntity=userRepository.save(userEntity);
  if (userEntity.getUserId() != null) {
    Map<String,Object> map=new HashMap<String,Object>();
    map.put(""String_Node_Str"",userEntity.getName());
    map.put(""String_Node_Str"",userEntity.getUsername());
    map.put(""String_Node_Str"",password);
    mailService.send(userEntity.getEmail(),mailUtils.getSubjectAccountUsername(),TemplateService.Template.ACCOUNT_USERNAME,map);
    mailService.send(userEntity.getEmail(),mailUtils.getSubjectAccountPassword(),TemplateService.Template.ACCOUNT_PASSWORD,map);
  }
  return UserConversionUtil.toUserInfo(userEntity);
}","@Transactional(propagation=Propagation.REQUIRED,readOnly=false) public UserInfo createUser(final UserInfo userRequest){
  userValidator.validateCreateUser(userRequest);
  Set<RoleEntity> roleEntities=new HashSet<>();
  List<RoleEntity> roleEntityList=roleRepository.findAll();
  for (  Long roleId : userRequest.getRoleIds()) {
    RoleEntity roleEntity=roleEntityList.parallelStream().filter((entity) -> entity.getRoleId().equals(roleId)).findFirst().orElse(null);
    if (!ValidatorUtil.isNull(roleEntity)) {
      roleEntities.add(roleEntity);
    }
 else {
      throw new RequestValidationException(messageUtil.getAttributeNotFound(""String_Node_Str""));
    }
  }
  UserEntity userEntity=UserConversionUtil.toUserEntity(userRequest,roleEntities);
  String password=ValidatorUtil.randomAlphaNumeric(16);
  userEntity.setPassword(StringUtil.encodeString(password));
  userEntity.setIs2FaEnabled(true);
  userEntity=userRepository.save(userEntity);
  LOGGER.info(""String_Node_Str"" + userEntity.getUsername() + ""String_Node_Str"");
  if (userEntity.getUserId() != null) {
    Map<String,Object> map=new HashMap<String,Object>();
    map.put(""String_Node_Str"",userEntity.getName());
    map.put(""String_Node_Str"",userEntity.getUsername());
    map.put(""String_Node_Str"",password);
    mailService.send(userEntity.getEmail(),mailUtils.getSubjectAccountUsername(),TemplateService.Template.ACCOUNT_USERNAME,map);
    mailService.send(userEntity.getEmail(),mailUtils.getSubjectAccountPassword(),TemplateService.Template.ACCOUNT_PASSWORD,map);
    LOGGER.info(""String_Node_Str"" + userEntity.getUsername() + ""String_Node_Str"");
  }
  return UserConversionUtil.toUserInfo(userEntity);
}"
37897,"/** 
 * Gets the switch ports.
 * @return the switch ports
 * @throws IntegrationException
 */
public List<PortInfo> getSwitchPorts(final String switchId) throws IntegrationException {
  HttpResponse response=null;
  try {
    if (RestClientManager.isValidResponse(response)) {
      String responseEntity=IoUtil.toString(response.getEntity().getContent());
      JSONObject jsonObject=JsonUtil.toObject(responseEntity,JSONObject.class);
      return PortConverter.toPortsInfo(jsonObject,switchId);
    }
  }
 catch (  IOException exception) {
    LOGGER.error(""String_Node_Str"" + exception.getMessage(),exception);
    throw new IntegrationException(exception);
  }
  return null;
}","/** 
 * Gets the switch ports.
 * @return the switch ports
 * @throws IntegrationException
 */
public List<PortInfo> getSwitchPorts(final String switchId) throws IntegrationException {
  HttpResponse response=null;
  try {
    if (response != null && RestClientManager.isValidResponse(response)) {
      String responseEntity=IoUtil.toString(response.getEntity().getContent());
      JSONObject jsonObject=JsonUtil.toObject(responseEntity,JSONObject.class);
      return PortConverter.toPortsInfo(jsonObject,switchId);
    }
  }
 catch (  IOException exception) {
    LOGGER.error(""String_Node_Str"" + exception.getMessage(),exception);
    throw new IntegrationException(exception);
  }
  return null;
}"
37898,"/** 
 * Gets the isl link cost.
 * @return the isl link cost
 */
public List<LinkProps> getIslLinkProps(LinkProps keys){
  UriComponentsBuilder builder=UriComponentsBuilder.fromHttpUrl(applicationProperties.getLinkProps());
  builder=setLinkProps(keys,builder);
  String fullUri=builder.build().toUriString();
  HttpResponse response=restClientManager.invoke(fullUri,HttpMethod.GET,""String_Node_Str"",""String_Node_Str"",applicationService.getAuthHeader());
  if (RestClientManager.isValidResponse(response)) {
    List<LinkProps> linkPropsResponses=restClientManager.getResponseList(response,LinkProps.class);
    if (CollectionUtil.isEmpty(linkPropsResponses)) {
      throw new ContentNotFoundException();
    }
 else {
      return linkPropsResponses;
    }
  }
  return null;
}","/** 
 * Gets the isl link cost.
 * @return the isl link cost
 */
public List<LinkProps> getIslLinkProps(LinkProps keys){
  UriComponentsBuilder builder=UriComponentsBuilder.fromHttpUrl(applicationProperties.getLinkProps());
  builder=setLinkProps(keys,builder);
  String fullUri=builder.build().toUriString();
  HttpResponse response=restClientManager.invoke(fullUri,HttpMethod.GET,""String_Node_Str"",""String_Node_Str"",applicationService.getAuthHeader());
  if (RestClientManager.isValidResponse(response)) {
    List<LinkProps> linkPropsResponses=restClientManager.getResponseList(response,LinkProps.class);
    if (!CollectionUtil.isEmpty(linkPropsResponses)) {
      return linkPropsResponses;
    }
  }
  return null;
}"
37899,"private Map<String,String> islCostMap(){
  List<LinkProps> linkProps=getIslLinkProps(null);
  Map<String,String> islCostMap=new HashMap<>();
  linkProps.forEach(linkProp -> {
    String key=linkProp.getSrc_switch() + ""String_Node_Str"" + linkProp.getSrc_port()+ ""String_Node_Str""+ linkProp.getDst_switch()+ ""String_Node_Str""+ linkProp.getDst_port();
    String value=linkProp.getProperty(""String_Node_Str"");
    islCostMap.put(key,value);
  }
);
  return islCostMap;
}","private Map<String,String> islCostMap(){
  List<LinkProps> linkProps=getIslLinkProps(null);
  Map<String,String> islCostMap=new HashMap<>();
  if (linkProps != null) {
    linkProps.forEach(linkProp -> {
      String key=linkProp.getSrc_switch() + ""String_Node_Str"" + linkProp.getSrc_port()+ ""String_Node_Str""+ linkProp.getDst_switch()+ ""String_Node_Str""+ linkProp.getDst_port();
      String value=linkProp.getProperty(""String_Node_Str"");
      islCostMap.put(key,value);
    }
);
  }
  return islCostMap;
}"
37900,"private void handleIslEvent(IslInfoData isl,Tuple tuple,String correlationId){
  logger.debug(""String_Node_Str"",isl.getId(),isl.getState());
  Set<ImmutablePair<Flow,Flow>> affectedFlows;
switch (isl.getState()) {
case DISCOVERED:
    if (networkCache.cacheContainsIsl(isl.getId())) {
      networkCache.updateIsl(isl);
    }
 else {
      networkCache.createIsl(isl);
    }
  break;
case FAILED:
case MOVED:
try {
  networkCache.deleteIsl(isl.getId());
}
 catch (CacheException exception) {
  logger.warn(""String_Node_Str"",exception.getErrorMessage(),exception.getErrorDescription());
}
affectedFlows=flowCache.getActiveFlowsWithAffectedPath(isl);
String reason=String.format(""String_Node_Str"",isl.getId());
emitRerouteCommands(affectedFlows,tuple,correlationId,FlowOperation.UPDATE,reason);
break;
case OTHER_UPDATE:
break;
case CACHED:
break;
default :
logger.warn(""String_Node_Str"");
break;
}
}","private void handleIslEvent(IslInfoData isl,Tuple tuple,String correlationId){
  logger.debug(""String_Node_Str"",isl.getId(),isl.getState());
  Set<ImmutablePair<Flow,Flow>> affectedFlows;
switch (isl.getState()) {
case DISCOVERED:
    if (networkCache.cacheContainsIsl(isl.getId())) {
      networkCache.updateIsl(isl);
    }
 else {
      if (networkCache.isSelfLoopedIsl(isl)) {
        logger.warn(""String_Node_Str"",isl);
      }
 else {
        networkCache.createIsl(isl);
      }
    }
  break;
case FAILED:
case MOVED:
try {
  networkCache.deleteIsl(isl.getId());
}
 catch (CacheException exception) {
  logger.warn(""String_Node_Str"",exception.getErrorMessage(),exception.getErrorDescription());
}
affectedFlows=flowCache.getActiveFlowsWithAffectedPath(isl);
String reason=String.format(""String_Node_Str"",isl.getId());
emitRerouteCommands(affectedFlows,tuple,correlationId,FlowOperation.UPDATE,reason);
break;
case OTHER_UPDATE:
break;
case CACHED:
break;
default :
logger.warn(""String_Node_Str"");
break;
}
}"
37901,"private void initNetwork(){
  logger.info(""String_Node_Str"");
  Set<SwitchInfoData> switches=new HashSet<>(pathComputer.getSwitches());
  Set<IslInfoData> links=new HashSet<>(pathComputer.getIsls());
  logger.info(""String_Node_Str"",switches.size());
  logger.info(""String_Node_Str"",links.size());
  switches.forEach(networkCache::createOrUpdateSwitch);
  for (  IslInfoData isl : links) {
    try {
      networkCache.createOrUpdateIsl(isl);
    }
 catch (    Exception e) {
      logger.error(""String_Node_Str"",isl,e);
    }
  }
  logger.info(""String_Node_Str"");
}","private void initNetwork(){
  logger.info(""String_Node_Str"");
  Set<SwitchInfoData> switches=new HashSet<>(pathComputer.getSwitches());
  Set<IslInfoData> links=new HashSet<>(pathComputer.getIsls());
  logger.info(""String_Node_Str"",switches.size());
  logger.info(""String_Node_Str"",links.size());
  switches.forEach(networkCache::createOrUpdateSwitch);
  for (  IslInfoData isl : links) {
    try {
      if (networkCache.isSelfLoopedIsl(isl)) {
        logger.warn(""String_Node_Str"",isl);
      }
 else {
        networkCache.createOrUpdateIsl(isl);
      }
    }
 catch (    Exception e) {
      logger.error(""String_Node_Str"",isl,e);
    }
  }
  logger.info(""String_Node_Str"");
}"
37902,"public IslInfoData(@JsonProperty(""String_Node_Str"") List<PathNode> path,@JsonProperty(""String_Node_Str"") IslChangeType state){
  this.path=path;
  this.state=state;
  this.id=String.format(""String_Node_Str"",path.get(0).getSwitchId(),String.valueOf(path.get(0).getPortNo()));
}","/** 
 * Simple constructor for an ISL with only path and state.
 * @param path path of ISL.
 * @param state current state.
 */
public IslInfoData(@JsonProperty(""String_Node_Str"") List<PathNode> path,@JsonProperty(""String_Node_Str"") IslChangeType state){
  this.path=path;
  this.state=state;
  this.id=String.format(""String_Node_Str"",path.get(0).getSwitchId(),String.valueOf(path.get(0).getPortNo()));
}"
37903,"@JsonCreator public DiscoveryLink(@JsonProperty(""String_Node_Str"") final String srcSwitch,@JsonProperty(""String_Node_Str"") final int srcPort,@JsonProperty(""String_Node_Str"") final String dstSwitch,@JsonProperty(""String_Node_Str"") final int dstPort,@JsonProperty(""String_Node_Str"") final int attempts,@JsonProperty(""String_Node_Str"") final int timeCounter,@JsonProperty(""String_Node_Str"") final int checkInterval,@JsonProperty(""String_Node_Str"") final int consecutiveFailure,@JsonProperty(""String_Node_Str"") final int consecutiveSuccess,@JsonProperty(""String_Node_Str"") final int maxAttempts){
  this.srcEndpoint=new NetworkEndpoint(srcSwitch,srcPort);
  this.dstEndpoint=new NetworkEndpoint(dstSwitch,dstPort);
  this.attempts=attempts;
  this.timeCounter=timeCounter;
  this.checkInterval=checkInterval;
  this.maxAttempts=maxAttempts;
  this.consecutiveFailure=consecutiveFailure;
  this.consecutiveSuccess=consecutiveSuccess;
}","/** 
 * Main constructor using for deserialization by jackson.
 */
@JsonCreator public DiscoveryLink(@JsonProperty(""String_Node_Str"") final String srcSwitch,@JsonProperty(""String_Node_Str"") final int srcPort,@JsonProperty(""String_Node_Str"") final String dstSwitch,@JsonProperty(""String_Node_Str"") final int dstPort,@JsonProperty(""String_Node_Str"") final int attempts,@JsonProperty(""String_Node_Str"") final int timeCounter,@JsonProperty(""String_Node_Str"") final int checkInterval,@JsonProperty(""String_Node_Str"") final int consecutiveFailure,@JsonProperty(""String_Node_Str"") final int consecutiveSuccess,@JsonProperty(""String_Node_Str"") final int maxAttempts,@JsonProperty(""String_Node_Str"") final boolean active){
  this.srcEndpoint=new NetworkEndpoint(srcSwitch,srcPort);
  this.dstEndpoint=new NetworkEndpoint(dstSwitch,dstPort);
  this.attempts=attempts;
  this.timeCounter=timeCounter;
  this.checkInterval=checkInterval;
  this.maxAttempts=maxAttempts;
  this.consecutiveFailure=consecutiveFailure;
  this.consecutiveSuccess=consecutiveSuccess;
  this.active=active;
}"
37904,"/** 
 * @return true if link should be excluded from discovery plan and discovery packets should not be sent.
 */
public boolean isExcludedFromDiscovery(){
  if (maxAttempts == ENDLESS_ATTEMPTS) {
    return false;
  }
  return consecutiveFailure > maxAttempts;
}","/** 
 * Checks if ISL should be excluded from discovery.
 * @return true if link should be excluded from discovery plan and discovery packets should not be sent.
 */
public boolean isExcludedFromDiscovery(){
  if (maxAttempts == ENDLESS_ATTEMPTS) {
    return false;
  }
  return consecutiveFailure > maxAttempts;
}"
37905,"/** 
 * @return true if attempts is greater than attemptLimit.
 */
public boolean maxAttempts(Integer attemptLimit){
  return attemptLimit < attempts;
}","/** 
 * Check if we should stop to verify ISL.
 * @return true if attempts is greater than attemptLimit.
 */
public boolean maxAttempts(Integer attemptLimit){
  return attemptLimit < attempts;
}"
37906,"public boolean isDestinationChanged(String dstSwitch,int dstPort){
  if (this.dstEndpoint == null) {
    return false;
  }
  return !Objects.equals(this.dstEndpoint,new NetworkEndpoint(dstSwitch,dstPort));
}","/** 
 * Checks whether destination switch/port of that link differs.
 * @param dstSwitch destination switch.
 * @param dstPort destination port.
 * @return true if destination changed.
 */
public boolean isDestinationChanged(String dstSwitch,int dstPort){
  if (this.dstEndpoint == null) {
    return false;
  }
  return !Objects.equals(this.dstEndpoint,new NetworkEndpoint(dstSwitch,dstPort));
}"
37907,"@Get(""String_Node_Str"") @SuppressWarnings(""String_Node_Str"") public Map<Long,Object> getMeters(){
  Map<Long,Object> response=new HashMap<>();
  String switchId=(String)this.getRequestAttributes().get(""String_Node_Str"");
  logger.debug(""String_Node_Str"",switchId);
  ISwitchManager switchManager=(ISwitchManager)getContext().getAttributes().get(ISwitchManager.class.getCanonicalName());
  try {
    OFMeterConfigStatsReply replay=switchManager.dumpMeters(DatapathId.of(switchId));
    logger.debug(""String_Node_Str"",switchId,replay);
    if (replay != null) {
      for (      OFMeterConfig entry : replay.getEntries()) {
        response.put(entry.getMeterId(),entry);
      }
    }
  }
 catch (  UnsupportedSwitchOperationException ex) {
    String messageString=""String_Node_Str"";
    logger.error(""String_Node_Str"",messageString,switchId,ex);
    MessageError responseMessage=new MessageError(DEFAULT_CORRELATION_ID,System.currentTimeMillis(),ErrorType.PARAMETERS_INVALID.toString(),messageString,ex.getMessage());
    response.putAll(MAPPER.convertValue(responseMessage,Map.class));
    getResponse().setStatus(Status.SERVER_ERROR_NOT_IMPLEMENTED);
  }
catch (  IllegalArgumentException|SwitchOperationException exception) {
    String messageString=""String_Node_Str"";
    logger.error(""String_Node_Str"",messageString,switchId,exception);
    MessageError responseMessage=new MessageError(CorrelationContext.getId(),System.currentTimeMillis(),ErrorType.PARAMETERS_INVALID.toString(),messageString,exception.getMessage());
    response.putAll(MAPPER.convertValue(responseMessage,Map.class));
    getResponse().setStatus(Status.CLIENT_ERROR_NOT_FOUND);
  }
  return response;
}","@Get(""String_Node_Str"") @SuppressWarnings(""String_Node_Str"") public Map<Long,Object> getMeters(){
  Map<Long,Object> response=new HashMap<>();
  String switchId=(String)this.getRequestAttributes().get(""String_Node_Str"");
  logger.debug(""String_Node_Str"",switchId);
  ISwitchManager switchManager=(ISwitchManager)getContext().getAttributes().get(ISwitchManager.class.getCanonicalName());
  try {
    OFMeterConfigStatsReply replay=switchManager.dumpMeters(DatapathId.of(switchId));
    logger.debug(""String_Node_Str"",switchId,replay);
    if (replay != null) {
      for (      OFMeterConfig entry : replay.getEntries()) {
        response.put(entry.getMeterId(),entry);
      }
    }
  }
 catch (  UnsupportedSwitchOperationException ex) {
    String messageString=""String_Node_Str"";
    logger.error(""String_Node_Str"",messageString,switchId,ex);
    MessageError responseMessage=new MessageError(CorrelationContext.getId(),System.currentTimeMillis(),ErrorType.PARAMETERS_INVALID.toString(),messageString,ex.getMessage());
    response.putAll(MAPPER.convertValue(responseMessage,Map.class));
    getResponse().setStatus(Status.SERVER_ERROR_NOT_IMPLEMENTED);
  }
catch (  IllegalArgumentException|SwitchOperationException exception) {
    String messageString=""String_Node_Str"";
    logger.error(""String_Node_Str"",messageString,switchId,exception);
    MessageError responseMessage=new MessageError(CorrelationContext.getId(),System.currentTimeMillis(),ErrorType.PARAMETERS_INVALID.toString(),messageString,exception.getMessage());
    response.putAll(MAPPER.convertValue(responseMessage,Map.class));
    getResponse().setStatus(Status.CLIENT_ERROR_NOT_FOUND);
  }
  return response;
}"
37908,"@Override public boolean equals(Object obj){
  if (this == obj)   return true;
  if (obj == null)   return false;
  if (getClass() != obj.getClass())   return false;
  IslLinkInfo other=(IslLinkInfo)obj;
  if (dstPort != other.dstPort && dstPort != other.srcPort)   return false;
  if (dstSwitch == null) {
    if (other.dstSwitch != null && other.srcSwitch != null)     return false;
  }
 else   if (!dstSwitch.equals(other.dstSwitch) && !dstSwitch.equals(other.srcSwitch))   return false;
  if (srcPort != other.srcPort && srcPort != other.dstPort)   return false;
  if (srcSwitch == null) {
    if (other.srcSwitch != null && other.dstSwitch != null)     return false;
  }
 else   if (!srcSwitch.equals(other.srcSwitch) && !srcSwitch.equals(other.dstSwitch))   return false;
  return true;
}","@Override public boolean equals(Object obj){
  if (this == obj)   return true;
  if (obj == null)   return false;
  if (getClass() != obj.getClass())   return false;
  IslLinkInfo other=(IslLinkInfo)obj;
  if (dstSwitch.equals(other.srcSwitch) && srcPort == other.dstPort && srcSwitch.equals(other.dstSwitch) && dstPort == other.srcPort) {
    return true;
  }
 else {
    return false;
  }
}"
37909,"@JsonCreator public DiscoveryFilterEntity(@JsonProperty(""String_Node_Str"") String switchId,@JsonProperty(""String_Node_Str"") String portId){
  this.switchId=switchId;
  this.portId=portId;
}","@JsonCreator public DiscoveryFilterEntity(@JsonProperty(""String_Node_Str"") String switchId,@JsonProperty(""String_Node_Str"") int portId){
  this.switchId=switchId;
  this.portId=portId;
}"
37910,"@JsonCreator public OFELinkBoltState(@JsonProperty(""String_Node_Str"") List<DiscoveryNode> discovery,@JsonProperty(""String_Node_Str"") Set<?> filtered){
  this.discovery=discovery;
  this.filtered=filtered;
}","@JsonCreator public OFELinkBoltState(@JsonProperty(""String_Node_Str"") List<DiscoveryLink> discovery,@JsonProperty(""String_Node_Str"") Set<?> filtered){
  this.discovery=discovery;
  this.filtered=filtered;
}"
37911,"public static String createIslFail(String switchId,String portId) throws IOException {
  PathNode node=new PathNode(switchId,Integer.parseInt(portId),0,0L);
  InfoData data=new IslInfoData(0L,Collections.singletonList(node),0L,IslChangeType.FAILED,0L);
  InfoMessage message=new InfoMessage(data,System.currentTimeMillis(),UUID.randomUUID().toString());
  return MAPPER.writeValueAsString(message);
}","public static String createIslFail(String switchId,int portId) throws IOException {
  PathNode node=new PathNode(switchId,portId,0,0L);
  InfoData data=new IslInfoData(0L,Collections.singletonList(node),0L,IslChangeType.FAILED,0L);
  InfoMessage message=new InfoMessage(data,System.currentTimeMillis(),UUID.randomUUID().toString());
  return MAPPER.writeValueAsString(message);
}"
37912,"/** 
 * @return a JSON string that can be used to for link event
 */
public static String createIslDiscovery(String switchID,String portID) throws IOException {
  CommandMessage message=new CommandMessage(new DiscoverIslCommandData(switchID,Integer.valueOf(portID)),System.currentTimeMillis(),""String_Node_Str"",Destination.CONTROLLER);
  return MAPPER.writeValueAsString(message);
}","/** 
 * @return a JSON string that can be used to for link event
 */
public static String createIslDiscovery(String switchId,int portId) throws IOException {
  CommandMessage message=new CommandMessage(new DiscoverIslCommandData(switchId,portId),System.currentTimeMillis(),""String_Node_Str"",Destination.CONTROLLER);
  return MAPPER.writeValueAsString(message);
}"
37913,"/** 
 * {@inheritDoc}
 */
@Override public ImmutablePair<PathInfoData,PathInfoData> getPath(Flow flow,Strategy strategy) throws UnroutablePathException, RecoverableException {
  long latency=0L;
  List<PathNode> forwardNodes=new LinkedList<>();
  List<PathNode> reverseNodes=new LinkedList<>();
  if (!flow.isOneSwitchFlow()) {
    try {
      Pair<LinkedList<SimpleIsl>,LinkedList<SimpleIsl>> biPath=getPathFromNetwork(flow,strategy);
      if (biPath.getLeft().size() == 0 || biPath.getRight().size() == 0)       throw new UnroutablePathException(flow);
      int seqId=0;
      LinkedList<SimpleIsl> forwardIsl=biPath.getLeft();
      for (      SimpleIsl isl : forwardIsl) {
        latency+=isl.latency;
        forwardNodes.add(new PathNode(isl.src_dpid,isl.src_port,seqId++,(long)isl.latency));
        forwardNodes.add(new PathNode(isl.dst_dpid,isl.dst_port,seqId++,0L));
      }
      seqId=0;
      LinkedList<SimpleIsl> reverseIsl=biPath.getLeft();
      for (      SimpleIsl isl : reverseIsl) {
        reverseNodes.add(new PathNode(isl.src_dpid,isl.src_port,seqId++,(long)isl.latency));
        reverseNodes.add(new PathNode(isl.dst_dpid,isl.dst_port,seqId++,0L));
      }
    }
 catch (    TransientException e) {
      throw new RecoverableException(""String_Node_Str"",e);
    }
catch (    ClientException e) {
      throw new RecoverableException(""String_Node_Str"",e);
    }
  }
 else {
    logger.info(""String_Node_Str"");
  }
  return new ImmutablePair<>(new PathInfoData(latency,forwardNodes),new PathInfoData(latency,reverseNodes));
}","/** 
 * {@inheritDoc}
 */
@Override public ImmutablePair<PathInfoData,PathInfoData> getPath(Flow flow,Strategy strategy) throws UnroutablePathException, RecoverableException {
  long latency=0L;
  List<PathNode> forwardNodes=new LinkedList<>();
  List<PathNode> reverseNodes=new LinkedList<>();
  if (!flow.isOneSwitchFlow()) {
    try {
      Pair<LinkedList<SimpleIsl>,LinkedList<SimpleIsl>> biPath=getPathFromNetwork(flow,strategy);
      if (biPath.getLeft().size() == 0 || biPath.getRight().size() == 0)       throw new UnroutablePathException(flow);
      int seqId=0;
      LinkedList<SimpleIsl> forwardIsl=biPath.getLeft();
      for (      SimpleIsl isl : forwardIsl) {
        latency+=isl.latency;
        forwardNodes.add(new PathNode(isl.src_dpid,isl.src_port,seqId++,(long)isl.latency));
        forwardNodes.add(new PathNode(isl.dst_dpid,isl.dst_port,seqId++,0L));
      }
      seqId=0;
      LinkedList<SimpleIsl> reverseIsl=biPath.getRight();
      for (      SimpleIsl isl : reverseIsl) {
        reverseNodes.add(new PathNode(isl.src_dpid,isl.src_port,seqId++,(long)isl.latency));
        reverseNodes.add(new PathNode(isl.dst_dpid,isl.dst_port,seqId++,0L));
      }
    }
 catch (    TransientException e) {
      throw new RecoverableException(""String_Node_Str"",e);
    }
catch (    ClientException e) {
      throw new RecoverableException(""String_Node_Str"",e);
    }
  }
 else {
    logger.info(""String_Node_Str"");
  }
  return new ImmutablePair<>(new PathInfoData(latency,forwardNodes),new PathInfoData(latency,reverseNodes));
}"
37914,"/** 
 * Dumps all flows. Dumps all flows with specific status if specified.
 * @return list of flow
 */
@ApiOperation(value=""String_Node_Str"",response=FlowPayload.class) @ApiResponse(code=200,response=FlowPayload.class,responseContainer=""String_Node_Str"",message=""String_Node_Str"") @RequestMapping(value=""String_Node_Str"",method=RequestMethod.GET,produces=MediaType.APPLICATION_JSON_UTF8_VALUE) public ResponseEntity<List<FlowPayload>> getFlows(){
  List<FlowPayload> response=flowService.getFlows();
  return new ResponseEntity<>(response,new HttpHeaders(),HttpStatus.OK);
}","/** 
 * Dumps all flows. Dumps all flows with specific status if specified.
 * @return list of flow
 */
@ApiOperation(value=""String_Node_Str"",response=FlowPayload.class,responseContainer=""String_Node_Str"") @ApiResponse(code=200,response=FlowPayload.class,responseContainer=""String_Node_Str"",message=""String_Node_Str"") @RequestMapping(value=""String_Node_Str"",method=RequestMethod.GET,produces=MediaType.APPLICATION_JSON_UTF8_VALUE) public ResponseEntity<List<FlowPayload>> getFlows(){
  List<FlowPayload> response=flowService.getFlows();
  return new ResponseEntity<>(response,new HttpHeaders(),HttpStatus.OK);
}"
37915,"/** 
 * Delete all flows.
 * @return list of flows that have been deleted
 */
@ApiOperation(value=""String_Node_Str"",response=FlowPayload.class) @ApiResponse(code=200,response=FlowPayload.class,responseContainer=""String_Node_Str"",message=""String_Node_Str"") @RequestMapping(value=""String_Node_Str"",method=RequestMethod.DELETE,produces=MediaType.APPLICATION_JSON_UTF8_VALUE) @ExtraAuthRequired @SuppressWarnings(""String_Node_Str"") public ResponseEntity<List<FlowPayload>> deleteFlows(@RequestHeader(value=EXTRA_AUTH,defaultValue=""String_Node_Str"") long extra_auth){
  long current_auth=System.currentTimeMillis();
  if (Math.abs(current_auth - extra_auth) > 120 * 1000) {
    return new ResponseEntity(""String_Node_Str"" + current_auth,new HttpHeaders(),HttpStatus.UNAUTHORIZED);
  }
  List<FlowPayload> response=flowService.deleteFlows();
  return new ResponseEntity<>(response,new HttpHeaders(),HttpStatus.OK);
}","/** 
 * Delete all flows.
 * @return list of flows that have been deleted
 */
@ApiOperation(value=""String_Node_Str"",response=FlowPayload.class,responseContainer=""String_Node_Str"") @ApiResponse(code=200,response=FlowPayload.class,responseContainer=""String_Node_Str"",message=""String_Node_Str"") @RequestMapping(value=""String_Node_Str"",method=RequestMethod.DELETE,produces=MediaType.APPLICATION_JSON_UTF8_VALUE) @ExtraAuthRequired @SuppressWarnings(""String_Node_Str"") public ResponseEntity<List<FlowPayload>> deleteFlows(@RequestHeader(value=EXTRA_AUTH,defaultValue=""String_Node_Str"") long extra_auth){
  long current_auth=System.currentTimeMillis();
  if (Math.abs(current_auth - extra_auth) > 120 * 1000) {
    return new ResponseEntity(""String_Node_Str"" + current_auth,new HttpHeaders(),HttpStatus.UNAUTHORIZED);
  }
  List<FlowPayload> response=flowService.deleteFlows();
  return new ResponseEntity<>(response,new HttpHeaders(),HttpStatus.OK);
}"
37916,"/** 
 * Compares the Flow from the DB to what is on each switch.
 * @param flowId id of flow to be rerouted.
 * @return flow payload with updated path.
 */
@ApiOperation(value=""String_Node_Str"",response=FlowValidationDto.class,responseContainer=""String_Node_Str"") @ApiResponses(value={@ApiResponse(code=200,response=FlowValidationDto.class,message=""String_Node_Str"")}) @RequestMapping(path=""String_Node_Str"",method=RequestMethod.GET) @ResponseStatus(HttpStatus.OK) public ResponseEntity<List<FlowValidationDto>> validateFlow(@PathVariable(""String_Node_Str"") String flowId){
  logger.debug(""String_Node_Str"",flowId);
  ResponseEntity<List<FlowValidationDto>> response;
  try {
    List<FlowValidationDto> result=flowService.validateFlow(flowId);
    if (result == null) {
      logger.info(""String_Node_Str"",flowId);
      response=ResponseEntity.notFound().build();
    }
 else {
      response=ResponseEntity.ok(result);
    }
  }
 catch (  InvalidPathException e) {
    logger.error(""String_Node_Str"",flowId);
    logger.error(e.getMessage());
    response=ResponseEntity.notFound().build();
  }
  return response;
}","/** 
 * Compares the Flow from the DB to what is on each switch.
 * @param flowId id of flow to be rerouted.
 * @return flow payload with updated path.
 */
@ApiOperation(value=""String_Node_Str"",response=FlowValidationDto.class,responseContainer=""String_Node_Str"") @ApiResponses(value={@ApiResponse(code=200,response=FlowValidationDto.class,responseContainer=""String_Node_Str"",message=""String_Node_Str"")}) @RequestMapping(path=""String_Node_Str"",method=RequestMethod.GET) @ResponseStatus(HttpStatus.OK) public ResponseEntity<List<FlowValidationDto>> validateFlow(@PathVariable(""String_Node_Str"") String flowId){
  logger.debug(""String_Node_Str"",flowId);
  ResponseEntity<List<FlowValidationDto>> response;
  try {
    List<FlowValidationDto> result=flowService.validateFlow(flowId);
    if (result == null) {
      logger.info(""String_Node_Str"",flowId);
      response=ResponseEntity.notFound().build();
    }
 else {
      response=ResponseEntity.ok(result);
    }
  }
 catch (  InvalidPathException e) {
    logger.error(""String_Node_Str"",flowId);
    logger.error(e.getMessage());
    response=ResponseEntity.notFound().build();
  }
  return response;
}"
37917,"/** 
 * Get all available links.
 * @return list of links.
 */
@ApiOperation(value=""String_Node_Str"",response=LinksDto.class) @ApiResponses(value={@ApiResponse(code=200,response=LinksDto.class,message=""String_Node_Str""),@ApiResponse(code=400,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=401,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=403,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=404,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=500,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=503,response=MessageError.class,message=""String_Node_Str"")}) @GetMapping(path=""String_Node_Str"") @ResponseStatus(HttpStatus.OK) public List<LinksDto> getLinks(){
  return linkService.getLinks();
}","/** 
 * Get all available links.
 * @return list of links.
 */
@ApiOperation(value=""String_Node_Str"",response=LinksDto.class,responseContainer=""String_Node_Str"") @ApiResponse(code=200,response=LinksDto.class,responseContainer=""String_Node_Str"",message=""String_Node_Str"") @GetMapping(path=""String_Node_Str"") @ResponseStatus(HttpStatus.OK) public List<LinksDto> getLinks(){
  return linkService.getLinks();
}"
37918,"/** 
 * Delete link properties from the static link properties table.
 * @param keysAndProps if null, get all link props. Otherwise, the link props that much the primary keys.
 * @return list of link properties.
 */
@ApiOperation(value=""String_Node_Str"",response=LinkPropsResult.class) @ApiResponses(value={@ApiResponse(code=200,response=LinkPropsResult.class,message=""String_Node_Str""),@ApiResponse(code=400,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=401,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=403,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=404,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=500,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=503,response=MessageError.class,message=""String_Node_Str"")}) @RequestMapping(path=""String_Node_Str"",method=RequestMethod.DELETE,produces=MediaType.APPLICATION_JSON_UTF8_VALUE) @ResponseStatus(HttpStatus.OK) public LinkPropsResult delLinkProps(@RequestBody List<LinkPropsDto> keysAndProps){
  return linkService.delLinkProps(keysAndProps);
}","/** 
 * Delete link properties from the static link properties table.
 * @param keysAndProps if null, get all link props. Otherwise, the link props that much the primary keys.
 * @return list of link properties.
 */
@ApiOperation(value=""String_Node_Str"",response=LinkPropsResult.class) @ApiResponse(code=200,response=LinkPropsResult.class,message=""String_Node_Str"") @RequestMapping(path=""String_Node_Str"",method=RequestMethod.DELETE,produces=MediaType.APPLICATION_JSON_UTF8_VALUE) @ResponseStatus(HttpStatus.OK) public LinkPropsResult delLinkProps(@RequestBody List<LinkPropsDto> keysAndProps){
  return linkService.delLinkProps(keysAndProps);
}"
37919,"/** 
 * Create/Update link properties in the static link properties table.
 * @param keysAndProps if null, get all link props. Otherwise, the link props that much the primary keys.
 * @return list of link properties.
 */
@ApiOperation(value=""String_Node_Str"",response=LinkPropsResult.class) @ApiResponses(value={@ApiResponse(code=200,response=LinkPropsResult.class,message=""String_Node_Str""),@ApiResponse(code=400,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=401,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=403,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=404,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=500,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=503,response=MessageError.class,message=""String_Node_Str"")}) @RequestMapping(path=""String_Node_Str"",method=RequestMethod.PUT,produces=MediaType.APPLICATION_JSON_UTF8_VALUE) @ResponseStatus(HttpStatus.OK) public LinkPropsResult putLinkProps(@RequestBody List<LinkPropsDto> keysAndProps){
  return linkService.setLinkProps(keysAndProps);
}","/** 
 * Create/Update link properties in the static link properties table.
 * @param keysAndProps if null, get all link props. Otherwise, the link props that much the primary keys.
 * @return list of link properties.
 */
@ApiOperation(value=""String_Node_Str"",response=LinkPropsResult.class) @ApiResponse(code=200,response=LinkPropsResult.class,message=""String_Node_Str"") @RequestMapping(path=""String_Node_Str"",method=RequestMethod.PUT,produces=MediaType.APPLICATION_JSON_UTF8_VALUE) @ResponseStatus(HttpStatus.OK) public LinkPropsResult putLinkProps(@RequestBody List<LinkPropsDto> keysAndProps){
  return linkService.setLinkProps(keysAndProps);
}"
37920,"/** 
 * Get link properties from the static link properties table.
 * @param keys if null, get all link props. Otherwise, the link props that much the primary keys.
 * @return list of link properties.
 */
@ApiOperation(value=""String_Node_Str"",response=LinkPropsDto.class) @ApiResponses(value={@ApiResponse(code=200,response=LinkPropsDto.class,message=""String_Node_Str""),@ApiResponse(code=400,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=401,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=403,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=404,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=500,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=503,response=MessageError.class,message=""String_Node_Str"")}) @RequestMapping(path=""String_Node_Str"",method=RequestMethod.GET,produces=MediaType.APPLICATION_JSON_UTF8_VALUE) @ResponseStatus(HttpStatus.OK) public List<LinkPropsDto> getLinkProps(LinkPropsDto keys){
  return linkService.getLinkProps(keys);
}","/** 
 * Get link properties from the static link properties table.
 * @param keys if null, get all link props. Otherwise, the link props that much the primary keys.
 * @return list of link properties.
 */
@ApiOperation(value=""String_Node_Str"",response=LinkPropsDto.class,responseContainer=""String_Node_Str"") @ApiResponse(code=200,response=LinkPropsDto.class,responseContainer=""String_Node_Str"",message=""String_Node_Str"") @RequestMapping(path=""String_Node_Str"",method=RequestMethod.GET,produces=MediaType.APPLICATION_JSON_UTF8_VALUE) @ResponseStatus(HttpStatus.OK) public List<LinkPropsDto> getLinkProps(LinkPropsDto keys){
  return linkService.getLinkProps(keys);
}"
37921,"/** 
 * Delete switch rules.
 * @param switchId switch id to delete rules from
 * @param deleteAction defines what to do about the default rules
 * @param oneCookie the cookie to use if deleting one rule (could be any rule)
 * @return list of the cookies of the rules that have been deleted
 */
@ApiOperation(value=""String_Node_Str"",response=Long.class,responseContainer=""String_Node_Str"") @DeleteMapping(value=""String_Node_Str"",produces=MediaType.APPLICATION_JSON_UTF8_VALUE) @ExtraAuthRequired public ResponseEntity deleteSwitchRules(@PathVariable(""String_Node_Str"") String switchId,@ApiParam(value=""String_Node_Str"" + ""String_Node_Str"" + ""String_Node_Str"",required=false) @RequestParam(""String_Node_Str"") Optional<DeleteRulesAction> deleteAction,@RequestParam(""String_Node_Str"") Optional<Long> oneCookie){
  List<Long> response=switchService.deleteRules(switchId,deleteAction.orElse(DeleteRulesAction.IGNORE),oneCookie.orElse(0L));
  return ResponseEntity.ok(response);
}","/** 
 * Delete switch rules.
 * @param switchId switch id to delete rules from
 * @param deleteAction defines what to do about the default rules
 * @param oneCookie the cookie to use if deleting one rule (could be any rule)
 * @return list of the cookies of the rules that have been deleted
 */
@ApiOperation(value=""String_Node_Str"",response=Long.class,responseContainer=""String_Node_Str"") @ApiResponse(code=200,response=Long.class,responseContainer=""String_Node_Str"",message=""String_Node_Str"") @DeleteMapping(value=""String_Node_Str"",produces=MediaType.APPLICATION_JSON_UTF8_VALUE) @ExtraAuthRequired public ResponseEntity<List<Long>> deleteSwitchRules(@PathVariable(""String_Node_Str"") String switchId,@ApiParam(value=""String_Node_Str"" + ""String_Node_Str"" + ""String_Node_Str"",required=false) @RequestParam(""String_Node_Str"") Optional<DeleteRulesAction> deleteAction,@RequestParam(""String_Node_Str"") Optional<Long> oneCookie){
  List<Long> response=switchService.deleteRules(switchId,deleteAction.orElse(DeleteRulesAction.IGNORE),oneCookie.orElse(0L));
  return ResponseEntity.ok(response);
}"
37922,"/** 
 * Get switch rules.
 * @param switchId the switch
 * @param cookie filter the response based on this cookie
 * @return list of the cookies of the rules that have been deleted
 */
@ApiOperation(value=""String_Node_Str"",response=Long.class,responseContainer=""String_Node_Str"") @GetMapping(value=""String_Node_Str"",produces=MediaType.APPLICATION_JSON_UTF8_VALUE) @ResponseStatus(HttpStatus.OK) public SwitchFlowEntries getSwitchRules(@PathVariable(""String_Node_Str"") String switchId,@ApiParam(value=""String_Node_Str"",required=false) @RequestParam(""String_Node_Str"") Optional<Long> cookie){
  SwitchFlowEntries response=switchService.getRules(switchId,cookie.orElse(0L));
  return response;
}","/** 
 * Get switch rules.
 * @param switchId the switch
 * @param cookie filter the response based on this cookie
 * @return list of the cookies of the rules that have been deleted
 */
@ApiOperation(value=""String_Node_Str"",response=SwitchFlowEntries.class) @ApiResponse(code=200,response=SwitchFlowEntries.class,message=""String_Node_Str"") @GetMapping(value=""String_Node_Str"",produces=MediaType.APPLICATION_JSON_UTF8_VALUE) @ResponseStatus(HttpStatus.OK) public SwitchFlowEntries getSwitchRules(@PathVariable(""String_Node_Str"") String switchId,@ApiParam(value=""String_Node_Str"",required=false) @RequestParam(""String_Node_Str"") Optional<Long> cookie){
  SwitchFlowEntries response=switchService.getRules(switchId,cookie.orElse(0L));
  return response;
}"
37923,"/** 
 * Get all available links.
 * @return list of links.
 */
@ApiOperation(value=""String_Node_Str"",response=SwitchDto.class) @GetMapping(path=""String_Node_Str"") @ResponseStatus(HttpStatus.OK) public List<SwitchDto> getSwitches(){
  return switchService.getSwitches();
}","/** 
 * Get all available links.
 * @return list of links.
 */
@ApiOperation(value=""String_Node_Str"",response=SwitchDto.class,responseContainer=""String_Node_Str"") @GetMapping(path=""String_Node_Str"") @ResponseStatus(HttpStatus.OK) public List<SwitchDto> getSwitches(){
  return switchService.getSwitches();
}"
37924,"/** 
 * Install switch rules.
 * @param switchId switch id to delete rules from
 * @param installAction defines what to do about the default rules
 * @return list of the cookies of the rules that have been installed
 */
@ApiOperation(value=""String_Node_Str"",response=String.class,responseContainer=""String_Node_Str"") @PutMapping(value=""String_Node_Str"",produces=MediaType.APPLICATION_JSON_UTF8_VALUE) @ExtraAuthRequired public ResponseEntity installSwitchRules(@PathVariable(""String_Node_Str"") String switchId,@ApiParam(value=""String_Node_Str"" + ""String_Node_Str"",required=false) @RequestParam(""String_Node_Str"") Optional<InstallRulesAction> installAction){
  List<Long> response=switchService.installRules(switchId,installAction.orElse(InstallRulesAction.INSTALL_DEFAULTS));
  return ResponseEntity.ok(response);
}","/** 
 * Install switch rules.
 * @param switchId switch id to delete rules from
 * @param installAction defines what to do about the default rules
 * @return list of the cookies of the rules that have been installed
 */
@ApiOperation(value=""String_Node_Str"",response=Long.class,responseContainer=""String_Node_Str"") @ApiResponse(code=200,response=Long.class,responseContainer=""String_Node_Str"",message=""String_Node_Str"") @PutMapping(value=""String_Node_Str"",produces=MediaType.APPLICATION_JSON_UTF8_VALUE) @ExtraAuthRequired public ResponseEntity<List<Long>> installSwitchRules(@PathVariable(""String_Node_Str"") String switchId,@ApiParam(value=""String_Node_Str"" + ""String_Node_Str"",required=false) @RequestParam(""String_Node_Str"") Optional<InstallRulesAction> installAction){
  List<Long> response=switchService.installRules(switchId,installAction.orElse(InstallRulesAction.INSTALL_DEFAULTS));
  return ResponseEntity.ok(response);
}"
37925,"/** 
 * Toggle the global behavior of Floodlight when the switch connects: - AUTO - this is the default. Installs all default rules when a switch connects - SAFE - add the default rules slowly .. monitoring traffic on existing rules - MANUAL - don't install any default rules. Call addRule for that. NOTE: no action is taking with existing, connected switches. This operation will only affect future connections
 * @param mode the connectMode to use. A Null value is a No-Op and can be used to return existing value.
 * @return the value of the toggle in Floodlight.
 */
@ApiOperation(value=""String_Node_Str"",response=ConnectModeRequest.Mode.class) @PutMapping(value=""String_Node_Str"",produces=MediaType.APPLICATION_JSON_UTF8_VALUE) public ResponseEntity toggleSwitchConnectMode(@RequestParam(""String_Node_Str"") ConnectModeRequest.Mode mode){
  ConnectModeRequest.Mode response=switchService.connectMode(mode);
  return ResponseEntity.ok(response);
}","/** 
 * Toggle the global behavior of Floodlight when the switch connects: - AUTO - this is the default. Installs all default rules when a switch connects - SAFE - add the default rules slowly .. monitoring traffic on existing rules - MANUAL - don't install any default rules. Call addRule for that. NOTE: no action is taking with existing, connected switches. This operation will only affect future connections
 * @param mode the connectMode to use. A Null value is a No-Op and can be used to return existing value.
 * @return the value of the toggle in Floodlight.
 */
@ApiOperation(value=""String_Node_Str"",response=ConnectModeRequest.Mode.class) @PutMapping(value=""String_Node_Str"",produces=MediaType.APPLICATION_JSON_UTF8_VALUE) public ResponseEntity<ConnectModeRequest.Mode> toggleSwitchConnectMode(@RequestParam(""String_Node_Str"") ConnectModeRequest.Mode mode){
  ConnectModeRequest.Mode response=switchService.connectMode(mode);
  return ResponseEntity.ok(response);
}"
37926,"/** 
 * @param switchId
 * @return the list of rules on switch, specified what actions were applied.
 */
@ApiOperation(value=""String_Node_Str"",response=SyncRulesOutput.class) @ApiResponses(value={@ApiResponse(code=200,response=FlowPayload.class,message=""String_Node_Str""),@ApiResponse(code=400,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=401,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=403,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=404,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=500,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=503,response=MessageError.class,message=""String_Node_Str"")}) @GetMapping(path=""String_Node_Str"") @ResponseStatus(HttpStatus.OK) public SyncRulesOutput syncRules(@PathVariable(name=""String_Node_Str"") String switchId){
  return switchService.syncRules(switchId);
}","/** 
 * @param switchId
 * @return the list of rules on switch, specified what actions were applied.
 */
@ApiOperation(value=""String_Node_Str"",response=SyncRulesOutput.class) @ApiResponse(code=200,response=SyncRulesOutput.class,message=""String_Node_Str"") @GetMapping(path=""String_Node_Str"") @ResponseStatus(HttpStatus.OK) public SyncRulesOutput syncRules(@PathVariable(name=""String_Node_Str"") String switchId){
  return switchService.syncRules(switchId);
}"
37927,"/** 
 * Checks a flow for endpoints' conflicts.
 * @param requestedFlow a flow to check
 * @throws FlowValidationException is thrown in a case when flow endpoints conflict with existing flows.
 */
public void checkFlowForEndpointConflicts(Flow requestedFlow) throws FlowValidationException {
  Set<Flow> conflictsOnSource;
  if (requestedFlow.getSourceVlan() == 0) {
    conflictsOnSource=flowCache.getFlowsForEndpoint(requestedFlow.getSourceSwitch(),requestedFlow.getSourcePort());
  }
 else {
    conflictsOnSource=flowCache.getFlowsForEndpoint(requestedFlow.getSourceSwitch(),requestedFlow.getSourcePort(),requestedFlow.getSourceVlan());
  }
  Optional<Flow> conflictedFlow=conflictsOnSource.stream().filter(flow -> !flow.getFlowId().equals(requestedFlow.getFlowId())).findAny();
  if (conflictedFlow.isPresent()) {
    throw new FlowValidationException(format(""String_Node_Str"",requestedFlow.getSourcePort(),requestedFlow.getSourceSwitch(),conflictedFlow.get().getFlowId()));
  }
  Set<Flow> conflictsOnDest;
  if (requestedFlow.getSourceVlan() == 0) {
    conflictsOnDest=flowCache.getFlowsForEndpoint(requestedFlow.getDestinationSwitch(),requestedFlow.getDestinationPort());
  }
 else {
    conflictsOnDest=flowCache.getFlowsForEndpoint(requestedFlow.getDestinationSwitch(),requestedFlow.getDestinationPort(),requestedFlow.getDestinationVlan());
  }
  conflictedFlow=conflictsOnDest.stream().filter(flow -> !flow.getFlowId().equals(requestedFlow.getFlowId())).findAny();
  if (conflictedFlow.isPresent()) {
    throw new FlowValidationException(format(""String_Node_Str"",requestedFlow.getDestinationPort(),requestedFlow.getDestinationSwitch(),conflictedFlow.get().getFlowId()));
  }
}","/** 
 * Checks a flow for endpoints' conflicts.
 * @param requestedFlow a flow to check
 * @throws FlowValidationException is thrown in a case when flow endpoints conflict with existing flows.
 */
public void checkFlowForEndpointConflicts(Flow requestedFlow) throws FlowValidationException {
  Set<Flow> conflictsOnSource;
  if (requestedFlow.getSourceVlan() == 0) {
    conflictsOnSource=flowCache.getFlowsForEndpoint(requestedFlow.getSourceSwitch(),requestedFlow.getSourcePort());
  }
 else {
    conflictsOnSource=flowCache.getFlowsForEndpoint(requestedFlow.getSourceSwitch(),requestedFlow.getSourcePort(),requestedFlow.getSourceVlan());
  }
  Optional<Flow> conflictedFlow=conflictsOnSource.stream().filter(flow -> !flow.getFlowId().equals(requestedFlow.getFlowId())).findAny();
  if (conflictedFlow.isPresent()) {
    throw new FlowValidationException(format(""String_Node_Str"",requestedFlow.getSourcePort(),requestedFlow.getSourceSwitch(),conflictedFlow.get().getFlowId()));
  }
  Set<Flow> conflictsOnDest;
  if (requestedFlow.getDestinationVlan() == 0) {
    conflictsOnDest=flowCache.getFlowsForEndpoint(requestedFlow.getDestinationSwitch(),requestedFlow.getDestinationPort());
  }
 else {
    conflictsOnDest=flowCache.getFlowsForEndpoint(requestedFlow.getDestinationSwitch(),requestedFlow.getDestinationPort(),requestedFlow.getDestinationVlan());
  }
  conflictedFlow=conflictsOnDest.stream().filter(flow -> !flow.getFlowId().equals(requestedFlow.getFlowId())).findAny();
  if (conflictedFlow.isPresent()) {
    throw new FlowValidationException(format(""String_Node_Str"",requestedFlow.getDestinationPort(),requestedFlow.getDestinationSwitch(),conflictedFlow.get().getFlowId()));
  }
}"
37928,"@Then(""String_Node_Str"") public void flowPathCorrect(String flowId,String sourceSwitch,int sourcePort,int sourceVlan,String destinationSwitch,int destinationPort,int destinationVlan,int bandwidth) throws UnroutablePathException, InterruptedException {
  Flow flow=new Flow(FlowUtils.getFlowName(flowId),bandwidth,false,flowId,sourceSwitch,sourcePort,sourceVlan,destinationSwitch,destinationPort,destinationVlan);
  ImmutablePair<PathInfoData,PathInfoData> path=FlowUtils.getFlowPath(flow);
  System.out.println(path);
  assertEquals(expectedShortestPath,path);
}","@Then(""String_Node_Str"") public void flowPathCorrect(String flowId,String sourceSwitch,int sourcePort,int sourceVlan,String destinationSwitch,int destinationPort,int destinationVlan,int bandwidth) throws UnroutablePathException, InterruptedException, RecoverableException {
  Flow flow=new Flow(FlowUtils.getFlowName(flowId),bandwidth,false,flowId,sourceSwitch,sourcePort,sourceVlan,destinationSwitch,destinationPort,destinationVlan);
  ImmutablePair<PathInfoData,PathInfoData> path=FlowUtils.getFlowPath(flow);
  System.out.println(path);
  assertEquals(expectedShortestPath,path);
}"
37929,"/** 
 * Gets flow path.
 * @param flow flow
 * @return flow path
 */
public static ImmutablePair<PathInfoData,PathInfoData> getFlowPath(Flow flow) throws InterruptedException, UnroutablePathException {
  Thread.sleep(1000);
  return pathComputer.getPath(flow,PathComputer.Strategy.COST);
}","/** 
 * Gets flow path.
 * @param flow flow
 * @return flow path
 */
public static ImmutablePair<PathInfoData,PathInfoData> getFlowPath(Flow flow) throws InterruptedException, UnroutablePathException, RecoverableException {
  Thread.sleep(1000);
  return pathComputer.getPath(flow,PathComputer.Strategy.COST);
}"
37930,"@Test public void testGetPathByCostInactiveOnTriangleTopo() throws UnroutablePathException {
  createTriangleTopo(""String_Node_Str"",10,20);
  Driver driver=GraphDatabase.driver(""String_Node_Str"",AuthTokens.basic(""String_Node_Str"",""String_Node_Str""));
  NeoDriver nd=new NeoDriver(driver);
  Flow f=new Flow();
  f.setSourceSwitch(""String_Node_Str"");
  f.setDestinationSwitch(""String_Node_Str"");
  f.setBandwidth(100);
  ImmutablePair<PathInfoData,PathInfoData> path=nd.getPath(f,PathComputer.Strategy.COST);
  Assert.assertNotNull(path);
  Assert.assertEquals(4,path.left.getPath().size());
  Assert.assertEquals(""String_Node_Str"",path.left.getPath().get(1).getSwitchId());
}","@Test public void testGetPathByCostInactiveOnTriangleTopo() throws UnroutablePathException, RecoverableException {
  createTriangleTopo(""String_Node_Str"",10,20);
  Driver driver=GraphDatabase.driver(""String_Node_Str"",AuthTokens.basic(""String_Node_Str"",""String_Node_Str""));
  NeoDriver nd=new NeoDriver(driver);
  Flow f=new Flow();
  f.setSourceSwitch(""String_Node_Str"");
  f.setDestinationSwitch(""String_Node_Str"");
  f.setBandwidth(100);
  ImmutablePair<PathInfoData,PathInfoData> path=nd.getPath(f,PathComputer.Strategy.COST);
  Assert.assertNotNull(path);
  Assert.assertEquals(4,path.left.getPath().size());
  Assert.assertEquals(""String_Node_Str"",path.left.getPath().get(1).getSwitchId());
}"
37931,"@Test public void testGetPathByCostNoCost() throws UnroutablePathException {
  createDiamond(""String_Node_Str"",""String_Node_Str"",-1,2000);
  Driver driver=GraphDatabase.driver(""String_Node_Str"",AuthTokens.basic(""String_Node_Str"",""String_Node_Str""));
  NeoDriver nd=new NeoDriver(driver);
  Flow f=new Flow();
  f.setSourceSwitch(""String_Node_Str"");
  f.setDestinationSwitch(""String_Node_Str"");
  f.setBandwidth(100);
  ImmutablePair<PathInfoData,PathInfoData> path=nd.getPath(f,PathComputer.Strategy.COST);
  Assert.assertNotNull(path);
  Assert.assertEquals(4,path.left.getPath().size());
  Assert.assertEquals(""String_Node_Str"",path.left.getPath().get(1).getSwitchId());
}","@Test public void testGetPathByCostNoCost() throws UnroutablePathException, RecoverableException {
  createDiamond(""String_Node_Str"",""String_Node_Str"",-1,2000);
  Driver driver=GraphDatabase.driver(""String_Node_Str"",AuthTokens.basic(""String_Node_Str"",""String_Node_Str""));
  NeoDriver nd=new NeoDriver(driver);
  Flow f=new Flow();
  f.setSourceSwitch(""String_Node_Str"");
  f.setDestinationSwitch(""String_Node_Str"");
  f.setBandwidth(100);
  ImmutablePair<PathInfoData,PathInfoData> path=nd.getPath(f,PathComputer.Strategy.COST);
  Assert.assertNotNull(path);
  Assert.assertEquals(4,path.left.getPath().size());
  Assert.assertEquals(""String_Node_Str"",path.left.getPath().get(1).getSwitchId());
}"
37932,"@Test public void testGetPathByCostActive() throws UnroutablePathException {
  createDiamond(""String_Node_Str"",""String_Node_Str"",10,20);
  Driver driver=GraphDatabase.driver(""String_Node_Str"",AuthTokens.basic(""String_Node_Str"",""String_Node_Str""));
  NeoDriver nd=new NeoDriver(driver);
  Flow f=new Flow();
  f.setSourceSwitch(""String_Node_Str"");
  f.setDestinationSwitch(""String_Node_Str"");
  f.setBandwidth(100);
  ImmutablePair<PathInfoData,PathInfoData> path=nd.getPath(f,PathComputer.Strategy.COST);
  Assert.assertNotNull(path);
  Assert.assertEquals(4,path.left.getPath().size());
  Assert.assertEquals(""String_Node_Str"",path.left.getPath().get(1).getSwitchId());
}","@Test public void testGetPathByCostActive() throws UnroutablePathException, RecoverableException {
  createDiamond(""String_Node_Str"",""String_Node_Str"",10,20);
  Driver driver=GraphDatabase.driver(""String_Node_Str"",AuthTokens.basic(""String_Node_Str"",""String_Node_Str""));
  NeoDriver nd=new NeoDriver(driver);
  Flow f=new Flow();
  f.setSourceSwitch(""String_Node_Str"");
  f.setDestinationSwitch(""String_Node_Str"");
  f.setBandwidth(100);
  ImmutablePair<PathInfoData,PathInfoData> path=nd.getPath(f,PathComputer.Strategy.COST);
  Assert.assertNotNull(path);
  Assert.assertEquals(4,path.left.getPath().size());
  Assert.assertEquals(""String_Node_Str"",path.left.getPath().get(1).getSwitchId());
}"
37933,"@Test public void testGetPathByCostInactive() throws UnroutablePathException {
  createDiamond(""String_Node_Str"",""String_Node_Str"",10,20);
  Driver driver=GraphDatabase.driver(""String_Node_Str"",AuthTokens.basic(""String_Node_Str"",""String_Node_Str""));
  NeoDriver nd=new NeoDriver(driver);
  Flow f=new Flow();
  f.setSourceSwitch(""String_Node_Str"");
  f.setDestinationSwitch(""String_Node_Str"");
  f.setBandwidth(100);
  ImmutablePair<PathInfoData,PathInfoData> path=nd.getPath(f,PathComputer.Strategy.COST);
  Assert.assertNotNull(path);
  Assert.assertEquals(4,path.left.getPath().size());
  Assert.assertEquals(""String_Node_Str"",path.left.getPath().get(1).getSwitchId());
}","@Test public void testGetPathByCostInactive() throws UnroutablePathException, RecoverableException {
  createDiamond(""String_Node_Str"",""String_Node_Str"",10,20);
  Driver driver=GraphDatabase.driver(""String_Node_Str"",AuthTokens.basic(""String_Node_Str"",""String_Node_Str""));
  NeoDriver nd=new NeoDriver(driver);
  Flow f=new Flow();
  f.setSourceSwitch(""String_Node_Str"");
  f.setDestinationSwitch(""String_Node_Str"");
  f.setBandwidth(100);
  ImmutablePair<PathInfoData,PathInfoData> path=nd.getPath(f,PathComputer.Strategy.COST);
  Assert.assertNotNull(path);
  Assert.assertEquals(4,path.left.getPath().size());
  Assert.assertEquals(""String_Node_Str"",path.left.getPath().get(1).getSwitchId());
}"
37934,"@Test(expected=UnroutablePathException.class) public void testGetPathNoPath() throws UnroutablePathException {
  createDiamond(""String_Node_Str"",""String_Node_Str"",10,30);
  Driver driver=GraphDatabase.driver(""String_Node_Str"",AuthTokens.basic(""String_Node_Str"",""String_Node_Str""));
  NeoDriver nd=new NeoDriver(driver);
  Flow f=new Flow();
  f.setSourceSwitch(""String_Node_Str"");
  f.setDestinationSwitch(""String_Node_Str"");
  f.setBandwidth(100);
  ImmutablePair<PathInfoData,PathInfoData> path=nd.getPath(f,PathComputer.Strategy.COST);
}","@Test(expected=UnroutablePathException.class) public void testGetPathNoPath() throws UnroutablePathException, RecoverableException {
  createDiamond(""String_Node_Str"",""String_Node_Str"",10,30);
  Driver driver=GraphDatabase.driver(""String_Node_Str"",AuthTokens.basic(""String_Node_Str"",""String_Node_Str""));
  NeoDriver nd=new NeoDriver(driver);
  Flow f=new Flow();
  f.setSourceSwitch(""String_Node_Str"");
  f.setDestinationSwitch(""String_Node_Str"");
  f.setBandwidth(100);
  ImmutablePair<PathInfoData,PathInfoData> path=nd.getPath(f,PathComputer.Strategy.COST);
}"
37935,"/** 
 * Creates or updates   {@link SwitchInfoData} instance.
 * @param newSwitch {@link SwitchInfoData} instance
 * @return created {@link SwitchInfoData} instance
 * @throws CacheException if {@link SwitchInfoData} instance with specified id already exists
 */
public SwitchInfoData createOrUpdateSwitch(SwitchInfoData newSwitch){
  logger.debug(""String_Node_Str"",newSwitch);
  if (cacheContainsSwitch(newSwitch.getSwitchId())) {
    return updateSwitch(newSwitch);
  }
 else {
    return createSwitch(newSwitch);
  }
}","/** 
 * Creates or updates   {@link SwitchInfoData} instance.
 * @param newSwitch {@link SwitchInfoData} instance
 * @return created {@link SwitchInfoData} instance
 * @throws CacheException if {@link SwitchInfoData} instance with specified id already exists
 */
public SwitchInfoData createOrUpdateSwitch(SwitchInfoData newSwitch){
  logger.debug(""String_Node_Str"",newSwitch);
  if (newSwitch == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (cacheContainsSwitch(newSwitch.getSwitchId())) {
    return updateSwitch(newSwitch);
  }
 else {
    return createSwitch(newSwitch);
  }
}"
37936,"/** 
 * Creates   {@link IslInfoData} instance.
 * @param isl {@link IslInfoData} instance
 * @return {@link IslInfoData} instance previously associated with {@link IslInfoData} instance id or null otherwise
 * @throws CacheException if {@link SwitchInfoData} related to {@link IslInfoData} instance do not exist
 */
public IslInfoData createOrUpdateIsl(IslInfoData isl){
  logger.debug(""String_Node_Str"",isl);
  if (cacheContainsIsl(isl.getId())) {
    return updateIsl(isl);
  }
 else {
    return createIsl(isl);
  }
}","/** 
 * Creates   {@link IslInfoData} instance.
 * @param isl {@link IslInfoData} instance
 * @return {@link IslInfoData} instance previously associated with {@link IslInfoData} instance id or null otherwise
 * @throws CacheException if {@link SwitchInfoData} related to {@link IslInfoData} instance do not exist
 */
public IslInfoData createOrUpdateIsl(IslInfoData isl){
  logger.debug(""String_Node_Str"",isl);
  if (isl == null) {
    throw new IllegalArgumentException(""String_Node_Str"");
  }
  if (cacheContainsIsl(isl.getId())) {
    return updateIsl(isl);
  }
 else {
    return createIsl(isl);
  }
}"
37937,"@Override public List<IslInfoData> getIsls(){
  String q=""String_Node_Str"" + ""String_Node_Str"" + ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str"";
  logger.debug(""String_Node_Str"",q);
  Session session=driver.session();
  StatementResult queryResults=session.run(q);
  List<IslInfoData> results=new LinkedList<>();
  for (  Record record : queryResults.list()) {
    IslInfoData isl=new IslInfoData();
    List<PathNode> pathNodes=new ArrayList<>();
    PathNode src=new PathNode();
    src.setSwitchId(record.get(""String_Node_Str"").asString());
    src.setPortNo(record.get(""String_Node_Str"").asInt());
    pathNodes.add(src);
    PathNode dst=new PathNode();
    dst.setSwitchId(record.get(""String_Node_Str"").asString());
    dst.setPortNo(record.get(""String_Node_Str"").asInt());
    pathNodes.add(dst);
    isl.setPath(pathNodes);
    isl.setSpeed(record.get(""String_Node_Str"").asInt());
    isl.setLatency(record.get(""String_Node_Str"").asInt());
    isl.setAvailableBandwidth(record.get(""String_Node_Str"").asInt());
    String status=record.get(""String_Node_Str"").asString();
    IslChangeType ct=(""String_Node_Str"".equals(status)) ? IslChangeType.DISCOVERED : IslChangeType.FAILED;
    isl.setState(ct);
    isl.setTimestamp(System.currentTimeMillis());
    results.add(isl);
  }
  return results;
}","@Override public List<IslInfoData> getIsls(){
  String q=""String_Node_Str"" + ""String_Node_Str"" + ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str"";
  logger.debug(""String_Node_Str"",q);
  Session session=driver.session();
  StatementResult queryResults=session.run(q);
  List<IslInfoData> results=new LinkedList<>();
  for (  Record record : queryResults.list()) {
    IslInfoData isl=new IslInfoData();
    List<PathNode> pathNodes=new ArrayList<>();
    PathNode src=new PathNode();
    src.setSwitchId(record.get(""String_Node_Str"").asString());
    src.setPortNo(record.get(""String_Node_Str"").asInt());
    src.setSegLatency(record.get(""String_Node_Str"").asInt());
    pathNodes.add(src);
    PathNode dst=new PathNode();
    dst.setSwitchId(record.get(""String_Node_Str"").asString());
    dst.setPortNo(record.get(""String_Node_Str"").asInt());
    dst.setSegLatency(record.get(""String_Node_Str"").asInt());
    pathNodes.add(dst);
    isl.setPath(pathNodes);
    isl.setSpeed(record.get(""String_Node_Str"").asInt());
    isl.setLatency(record.get(""String_Node_Str"").asInt());
    isl.setAvailableBandwidth(record.get(""String_Node_Str"").asInt());
    String status=record.get(""String_Node_Str"").asString();
    IslChangeType ct=(""String_Node_Str"".equals(status)) ? IslChangeType.DISCOVERED : IslChangeType.FAILED;
    isl.setState(ct);
    isl.setTimestamp(System.currentTimeMillis());
    results.add(isl);
  }
  return results;
}"
37938,"@Override public List<IslInfoData> getIsls(){
  String q=""String_Node_Str"" + ""String_Node_Str"" + ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str"";
  logger.debug(""String_Node_Str"",q);
  Session session=driver.session();
  StatementResult queryResults=session.run(q);
  List<IslInfoData> results=new LinkedList<>();
  for (  Record record : queryResults.list()) {
    IslInfoData isl=new IslInfoData();
    List<PathNode> pathNodes=new ArrayList<>();
    PathNode src=new PathNode();
    src.setSwitchId(record.get(""String_Node_Str"").asString());
    src.setPortNo(record.get(""String_Node_Str"").asInt());
    src.setSegLatency(record.get(""String_Node_Str"").asInt());
    pathNodes.add(src);
    PathNode dst=new PathNode();
    dst.setSwitchId(record.get(""String_Node_Str"").asString());
    dst.setPortNo(record.get(""String_Node_Str"").asInt());
    dst.setSegLatency(record.get(""String_Node_Str"").asInt());
    pathNodes.add(dst);
    isl.setPath(pathNodes);
    isl.setSpeed(record.get(""String_Node_Str"").asInt());
    isl.setLatency(record.get(""String_Node_Str"").asInt());
    isl.setAvailableBandwidth(record.get(""String_Node_Str"").asInt());
    String status=record.get(""String_Node_Str"").asString();
    IslChangeType ct=(""String_Node_Str"".equals(status)) ? IslChangeType.DISCOVERED : IslChangeType.FAILED;
    isl.setState(ct);
    isl.setTimestamp(System.currentTimeMillis());
    results.add(isl);
  }
  return results;
}","@Override public List<IslInfoData> getIsls(){
  String q=""String_Node_Str"" + ""String_Node_Str"" + ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str""+ ""String_Node_Str"";
  logger.debug(""String_Node_Str"",q);
  Session session=driver.session();
  StatementResult queryResults=session.run(q);
  List<IslInfoData> results=new LinkedList<>();
  for (  Record record : queryResults.list()) {
    List<PathNode> pathNodes=new ArrayList<>();
    PathNode src=new PathNode();
    src.setSwitchId(record.get(""String_Node_Str"").asString());
    src.setPortNo(record.get(""String_Node_Str"").asInt());
    src.setSegLatency(record.get(""String_Node_Str"").asInt());
    pathNodes.add(src);
    PathNode dst=new PathNode();
    dst.setSwitchId(record.get(""String_Node_Str"").asString());
    dst.setPortNo(record.get(""String_Node_Str"").asInt());
    dst.setSegLatency(record.get(""String_Node_Str"").asInt());
    pathNodes.add(dst);
    String status=record.get(""String_Node_Str"").asString();
    IslChangeType state=(""String_Node_Str"".equals(status)) ? IslChangeType.DISCOVERED : IslChangeType.FAILED;
    IslInfoData isl=new IslInfoData(record.get(""String_Node_Str"").asInt(),pathNodes,record.get(""String_Node_Str"").asInt(),state,record.get(""String_Node_Str"").asInt());
    isl.setTimestamp(System.currentTimeMillis());
    results.add(isl);
  }
  return results;
}"
37939,"/** 
 * {@inheritDoc}
 */
@Override public ImmutablePair<PathInfoData,PathInfoData> getPath(Flow flow,Strategy strategy) throws UnroutablePathException {
  long latency=0L;
  List<PathNode> forwardNodes=new LinkedList<>();
  List<PathNode> reverseNodes=new LinkedList<>();
  if (!flow.isOneSwitchFlow()) {
    Statement statement=getPathQuery(flow,strategy);
    logger.debug(""String_Node_Str"",statement.toString());
    try (Session session=driver.session()){
      StatementResult result=session.run(statement);
      try {
        Record record=result.next();
        LinkedList<Relationship> isls=new LinkedList<>();
        record.get(0).asPath().relationships().forEach(isls::add);
        int seqId=0;
        for (        Relationship isl : isls) {
          latency+=isl.get(""String_Node_Str"").asLong();
          forwardNodes.add(new PathNode(isl.get(""String_Node_Str"").asString(),isl.get(""String_Node_Str"").asInt(),seqId,isl.get(""String_Node_Str"").asLong()));
          seqId++;
          forwardNodes.add(new PathNode(isl.get(""String_Node_Str"").asString(),isl.get(""String_Node_Str"").asInt(),seqId,0L));
          seqId++;
        }
        seqId=0;
        Collections.reverse(isls);
        for (        Relationship isl : isls) {
          reverseNodes.add(new PathNode(isl.get(""String_Node_Str"").asString(),isl.get(""String_Node_Str"").asInt(),seqId,isl.get(""String_Node_Str"").asLong()));
          seqId++;
          reverseNodes.add(new PathNode(isl.get(""String_Node_Str"").asString(),isl.get(""String_Node_Str"").asInt(),seqId,0L));
          seqId++;
        }
      }
 catch (      NoSuchRecordException e) {
        throw new UnroutablePathException(flow);
      }
    }
   }
 else {
    logger.info(""String_Node_Str"");
  }
  return new ImmutablePair<>(new PathInfoData(latency,forwardNodes),new PathInfoData(latency,reverseNodes));
}","/** 
 * {@inheritDoc}
 */
@Override public ImmutablePair<PathInfoData,PathInfoData> getPath(Flow flow,Strategy strategy) throws UnroutablePathException, RecoverableException {
  long latency=0L;
  List<PathNode> forwardNodes=new LinkedList<>();
  List<PathNode> reverseNodes=new LinkedList<>();
  if (!flow.isOneSwitchFlow()) {
    Statement statement=getPathQuery(flow,strategy);
    logger.info(""String_Node_Str"",statement.toString());
    try (Session session=driver.session()){
      StatementResult result=session.run(statement);
      Record record=result.next();
      LinkedList<Relationship> isls=new LinkedList<>();
      record.get(0).asPath().relationships().forEach(isls::add);
      int seqId=0;
      for (      Relationship isl : isls) {
        latency+=isl.get(""String_Node_Str"").asLong();
        forwardNodes.add(new PathNode(isl.get(""String_Node_Str"").asString(),isl.get(""String_Node_Str"").asInt(),seqId,isl.get(""String_Node_Str"").asLong()));
        seqId++;
        forwardNodes.add(new PathNode(isl.get(""String_Node_Str"").asString(),isl.get(""String_Node_Str"").asInt(),seqId,0L));
        seqId++;
      }
      seqId=0;
      Collections.reverse(isls);
      for (      Relationship isl : isls) {
        reverseNodes.add(new PathNode(isl.get(""String_Node_Str"").asString(),isl.get(""String_Node_Str"").asInt(),seqId,isl.get(""String_Node_Str"").asLong()));
        seqId++;
        reverseNodes.add(new PathNode(isl.get(""String_Node_Str"").asString(),isl.get(""String_Node_Str"").asInt(),seqId,0L));
        seqId++;
      }
    }
 catch (    TransientException e) {
      throw new RecoverableException(""String_Node_Str"",e);
    }
catch (    ClientException e) {
      throw new RecoverableException(""String_Node_Str"",e);
    }
catch (    NoSuchRecordException e) {
      throw new UnroutablePathException(flow);
    }
  }
 else {
    logger.info(""String_Node_Str"");
  }
  return new ImmutablePair<>(new PathInfoData(latency,forwardNodes),new PathInfoData(latency,reverseNodes));
}"
37940,"/** 
 * Gets path between source and destination switch.
 * @param flow {@link Flow} instances
 * @return {@link PathInfoData} instances
 */
ImmutablePair<PathInfoData,PathInfoData> getPath(Flow flow,Strategy strategy) throws UnroutablePathException ;","/** 
 * Gets path between source and destination switch.
 * @param flow {@link Flow} instances
 * @return {@link PathInfoData} instances
 */
ImmutablePair<PathInfoData,PathInfoData> getPath(Flow flow,Strategy strategy) throws UnroutablePathException, RecoverableException ;"
37941,"private void handleRerouteRequest(CommandMessage message,Tuple tuple) throws IOException {
  FlowRerouteRequest request=(FlowRerouteRequest)message.getData();
  Flow requestedFlow=request.getPayload();
  final String flowId=requestedFlow.getFlowId();
  ImmutablePair<Flow,Flow> flow;
  logger.warn(""String_Node_Str"",message.getCorrelationId());
switch (request.getOperation()) {
case UPDATE:
    flow=flowCache.getFlow(flowId);
  try {
    logger.warn(""String_Node_Str"",flowId,flow.getLeft().getFlowPath());
    ImmutablePair<PathInfoData,PathInfoData> path=pathComputer.getPath(flow.getLeft(),Strategy.COST);
    logger.warn(""String_Node_Str"",flowId,path.getLeft());
    boolean isFoundNewPath=false;
    if (!path.getLeft().equals(flow.getLeft().getFlowPath()) || !isFlowActive(flow)) {
      isFoundNewPath=true;
      flow.getLeft().setState(FlowState.DOWN);
      flow.getRight().setState(FlowState.DOWN);
      flow=flowCache.updateFlow(flow.getLeft(),path);
      logger.warn(""String_Node_Str"",flow);
      FlowInfoData data=new FlowInfoData(flowId,flow,UPDATE,message.getCorrelationId());
      InfoMessage infoMessage=new InfoMessage(data,System.currentTimeMillis(),message.getCorrelationId());
      Values topology=new Values(MAPPER.writeValueAsString(infoMessage));
      outputCollector.emit(StreamType.UPDATE.toString(),tuple,topology);
    }
 else {
      logger.warn(""String_Node_Str"");
    }
    logger.debug(""String_Node_Str"",message.getCorrelationId());
    FlowRerouteResponse response=new FlowRerouteResponse(flow.left.getFlowPath(),isFoundNewPath);
    Values values=new Values(new InfoMessage(response,message.getTimestamp(),message.getCorrelationId(),Destination.NORTHBOUND));
    outputCollector.emit(StreamType.RESPONSE.toString(),tuple,values);
  }
 catch (  UnroutablePathException e) {
    logger.warn(""String_Node_Str"",flowId);
    flow.getLeft().setState(FlowState.DOWN);
    flow.getRight().setState(FlowState.DOWN);
    throw new MessageException(message.getCorrelationId(),System.currentTimeMillis(),ErrorType.UPDATE_FAILURE,""String_Node_Str"",""String_Node_Str"");
  }
break;
case CREATE:
flow=flowCache.getFlow(flowId);
logger.warn(""String_Node_Str"",flow.getLeft().getFlowId(),FlowState.UP);
flow.getLeft().setState(FlowState.UP);
flow.getRight().setState(FlowState.UP);
break;
case DELETE:
flow=flowCache.getFlow(flowId);
logger.warn(""String_Node_Str"",flow.getLeft().getFlowId(),FlowState.DOWN);
flow.getLeft().setState(FlowState.DOWN);
flow.getRight().setState(FlowState.DOWN);
break;
default :
logger.warn(""String_Node_Str"",request.getOperation());
break;
}
}","private void handleRerouteRequest(CommandMessage message,Tuple tuple) throws IOException, RecoverableException {
  FlowRerouteRequest request=(FlowRerouteRequest)message.getData();
  Flow requestedFlow=request.getPayload();
  final String flowId=requestedFlow.getFlowId();
  ImmutablePair<Flow,Flow> flow;
  logger.warn(""String_Node_Str"",message.getCorrelationId());
switch (request.getOperation()) {
case UPDATE:
    flow=flowCache.getFlow(flowId);
  try {
    logger.warn(""String_Node_Str"",flowId,flow.getLeft().getFlowPath());
    ImmutablePair<PathInfoData,PathInfoData> path=pathComputer.getPath(flow.getLeft(),Strategy.COST);
    logger.warn(""String_Node_Str"",flowId,path.getLeft());
    boolean isFoundNewPath=false;
    if (!path.getLeft().equals(flow.getLeft().getFlowPath()) || !isFlowActive(flow)) {
      isFoundNewPath=true;
      flow.getLeft().setState(FlowState.DOWN);
      flow.getRight().setState(FlowState.DOWN);
      flow=flowCache.updateFlow(flow.getLeft(),path);
      logger.warn(""String_Node_Str"",flow);
      FlowInfoData data=new FlowInfoData(flowId,flow,UPDATE,message.getCorrelationId());
      InfoMessage infoMessage=new InfoMessage(data,System.currentTimeMillis(),message.getCorrelationId());
      Values topology=new Values(MAPPER.writeValueAsString(infoMessage));
      outputCollector.emit(StreamType.UPDATE.toString(),tuple,topology);
    }
 else {
      logger.warn(""String_Node_Str"");
    }
    logger.debug(""String_Node_Str"",message.getCorrelationId());
    FlowRerouteResponse response=new FlowRerouteResponse(flow.left.getFlowPath(),isFoundNewPath);
    Values values=new Values(new InfoMessage(response,message.getTimestamp(),message.getCorrelationId(),Destination.NORTHBOUND));
    outputCollector.emit(StreamType.RESPONSE.toString(),tuple,values);
  }
 catch (  UnroutablePathException e) {
    logger.warn(""String_Node_Str"",flowId);
    flow.getLeft().setState(FlowState.DOWN);
    flow.getRight().setState(FlowState.DOWN);
    throw new MessageException(message.getCorrelationId(),System.currentTimeMillis(),ErrorType.UPDATE_FAILURE,""String_Node_Str"",""String_Node_Str"");
  }
break;
case CREATE:
flow=flowCache.getFlow(flowId);
logger.warn(""String_Node_Str"",flow.getLeft().getFlowId(),FlowState.UP);
flow.getLeft().setState(FlowState.UP);
flow.getRight().setState(FlowState.UP);
break;
case DELETE:
flow=flowCache.getFlow(flowId);
logger.warn(""String_Node_Str"",flow.getLeft().getFlowId(),FlowState.DOWN);
flow.getLeft().setState(FlowState.DOWN);
flow.getRight().setState(FlowState.DOWN);
break;
default :
logger.warn(""String_Node_Str"",request.getOperation());
break;
}
}"
37942,"private void handleRestoreRequest(CommandMessage message,Tuple tuple) throws IOException {
  ImmutablePair<Flow,Flow> requestedFlow=((FlowRestoreRequest)message.getData()).getPayload();
  try {
    ImmutablePair<PathInfoData,PathInfoData> path=pathComputer.getPath(requestedFlow.getLeft(),Strategy.COST);
    logger.info(""String_Node_Str"",path);
    ImmutablePair<Flow,Flow> flow;
    if (flowCache.cacheContainsFlow(requestedFlow.getLeft().getFlowId())) {
      flow=flowCache.updateFlow(requestedFlow,path);
    }
 else {
      flow=flowCache.createFlow(requestedFlow,path);
    }
    logger.info(""String_Node_Str"",flow);
    Values topology=new Values(Utils.MAPPER.writeValueAsString(new FlowInfoData(requestedFlow.getLeft().getFlowId(),flow,UPDATE,message.getCorrelationId())));
    outputCollector.emit(StreamType.UPDATE.toString(),tuple,topology);
  }
 catch (  UnroutablePathException e) {
    throw new MessageException(message.getCorrelationId(),System.currentTimeMillis(),ErrorType.CREATION_FAILURE,""String_Node_Str"",""String_Node_Str"");
  }
}","private void handleRestoreRequest(CommandMessage message,Tuple tuple) throws IOException, RecoverableException {
  ImmutablePair<Flow,Flow> requestedFlow=((FlowRestoreRequest)message.getData()).getPayload();
  try {
    ImmutablePair<PathInfoData,PathInfoData> path=pathComputer.getPath(requestedFlow.getLeft(),Strategy.COST);
    logger.info(""String_Node_Str"",path);
    ImmutablePair<Flow,Flow> flow;
    if (flowCache.cacheContainsFlow(requestedFlow.getLeft().getFlowId())) {
      flow=flowCache.updateFlow(requestedFlow,path);
    }
 else {
      flow=flowCache.createFlow(requestedFlow,path);
    }
    logger.info(""String_Node_Str"",flow);
    Values topology=new Values(Utils.MAPPER.writeValueAsString(new FlowInfoData(requestedFlow.getLeft().getFlowId(),flow,UPDATE,message.getCorrelationId())));
    outputCollector.emit(StreamType.UPDATE.toString(),tuple,topology);
  }
 catch (  UnroutablePathException e) {
    throw new MessageException(message.getCorrelationId(),System.currentTimeMillis(),ErrorType.CREATION_FAILURE,""String_Node_Str"",""String_Node_Str"");
  }
}"
37943,"/** 
 * {@inheritDoc}
 */
@Override public void execute(Tuple tuple){
  if (CtrlAction.boltHandlerEntrance(this,tuple))   return;
  logger.trace(""String_Node_Str"",flowCache);
  ComponentType componentId=ComponentType.valueOf(tuple.getSourceComponent());
  String correlationId=Utils.DEFAULT_CORRELATION_ID;
  StreamType streamId=null;
  String flowId=null;
  if (!componentId.equals(ComponentType.LCM_FLOW_SYNC_BOLT)) {
    streamId=StreamType.valueOf(tuple.getSourceStreamId());
    flowId=tuple.getStringByField(Utils.FLOW_ID);
  }
  try {
    logger.debug(""String_Node_Str"",tuple);
switch (componentId) {
case SPLITTER_BOLT:
      Message msg=(Message)tuple.getValueByField(AbstractTopology.MESSAGE_FIELD);
    correlationId=msg.getCorrelationId();
  CommandMessage cmsg=(msg instanceof CommandMessage) ? (CommandMessage)msg : null;
InfoMessage imsg=(msg instanceof InfoMessage) ? (InfoMessage)msg : null;
logger.info(""String_Node_Str"",Utils.CORRELATION_ID,correlationId,Utils.FLOW_ID,flowId,componentId,streamId);
switch (streamId) {
case CREATE:
handleCreateRequest(cmsg,tuple);
break;
case UPDATE:
handleUpdateRequest(cmsg,tuple);
break;
case DELETE:
handleDeleteRequest(flowId,cmsg,tuple);
break;
case PUSH:
handlePushRequest(flowId,imsg,tuple);
break;
case UNPUSH:
handleUnpushRequest(flowId,imsg,tuple);
break;
case PATH:
handlePathRequest(flowId,cmsg,tuple);
break;
case RESTORE:
handleRestoreRequest(cmsg,tuple);
break;
case REROUTE:
handleRerouteRequest(cmsg,tuple);
break;
case STATUS:
handleStatusRequest(flowId,cmsg,tuple);
break;
case CACHE_SYNC:
handleCacheSyncRequest(cmsg,tuple);
break;
case READ:
if (flowId != null) {
handleReadRequest(flowId,cmsg,tuple);
}
 else {
handleDumpRequest(cmsg,tuple);
}
break;
default :
logger.debug(""String_Node_Str"",componentId,streamId);
break;
}
break;
case SPEAKER_BOLT:
case TRANSACTION_BOLT:
FlowState newStatus=(FlowState)tuple.getValueByField(FlowTopology.STATUS_FIELD);
logger.info(""String_Node_Str"",flowId,newStatus,componentId,streamId);
switch (streamId) {
case STATUS:
handleStateRequest(flowId,newStatus,tuple);
break;
default :
logger.debug(""String_Node_Str"",componentId,streamId);
break;
}
break;
case TOPOLOGY_ENGINE_BOLT:
ErrorMessage errorMessage=(ErrorMessage)tuple.getValueByField(AbstractTopology.MESSAGE_FIELD);
logger.info(""String_Node_Str"",flowId,componentId,streamId);
switch (streamId) {
case STATUS:
handleErrorRequest(flowId,errorMessage,tuple);
break;
default :
logger.debug(""String_Node_Str"",componentId,streamId);
break;
}
break;
case LCM_FLOW_SYNC_BOLT:
logger.debug(""String_Node_Str"");
NetworkInfoData networkDump=(NetworkInfoData)tuple.getValueByField(LcmFlowCacheSyncBolt.FIELD_ID_NETWORK_DUMP);
handleFlowSync(networkDump);
break;
default :
logger.debug(""String_Node_Str"",componentId);
break;
}
}
 catch (CacheException exception) {
String logMessage=format(""String_Node_Str"",exception.getErrorMessage(),exception.getErrorDescription());
logger.error(""String_Node_Str"",logMessage,Utils.CORRELATION_ID,correlationId,Utils.FLOW_ID,flowId,componentId,streamId,exception);
ErrorMessage errorMessage=buildErrorMessage(correlationId,exception.getErrorType(),logMessage,componentId.toString().toLowerCase());
Values error=new Values(errorMessage,exception.getErrorType());
outputCollector.emit(StreamType.ERROR.toString(),tuple,error);
}
catch (IOException exception) {
logger.error(""String_Node_Str"",tuple,exception);
}
catch (Exception e) {
logger.error(String.format(""String_Node_Str"",getClass().getName()),e);
}
 finally {
logger.debug(""String_Node_Str"",tuple.getSourceComponent(),tuple.getSourceStreamId(),tuple);
outputCollector.ack(tuple);
}
logger.trace(""String_Node_Str"",flowCache);
}","/** 
 * {@inheritDoc}
 */
@Override public void execute(Tuple tuple){
  if (CtrlAction.boltHandlerEntrance(this,tuple))   return;
  logger.trace(""String_Node_Str"",flowCache);
  ComponentType componentId=ComponentType.valueOf(tuple.getSourceComponent());
  String correlationId=Utils.DEFAULT_CORRELATION_ID;
  StreamType streamId=null;
  String flowId=null;
  if (!componentId.equals(ComponentType.LCM_FLOW_SYNC_BOLT)) {
    streamId=StreamType.valueOf(tuple.getSourceStreamId());
    flowId=tuple.getStringByField(Utils.FLOW_ID);
  }
  boolean isRecoverable=false;
  try {
    logger.debug(""String_Node_Str"",tuple);
switch (componentId) {
case SPLITTER_BOLT:
      Message msg=(Message)tuple.getValueByField(AbstractTopology.MESSAGE_FIELD);
    correlationId=msg.getCorrelationId();
  CommandMessage cmsg=(msg instanceof CommandMessage) ? (CommandMessage)msg : null;
InfoMessage imsg=(msg instanceof InfoMessage) ? (InfoMessage)msg : null;
logger.info(""String_Node_Str"",Utils.CORRELATION_ID,correlationId,Utils.FLOW_ID,flowId,componentId,streamId);
switch (streamId) {
case CREATE:
handleCreateRequest(cmsg,tuple);
break;
case UPDATE:
handleUpdateRequest(cmsg,tuple);
break;
case DELETE:
handleDeleteRequest(flowId,cmsg,tuple);
break;
case PUSH:
handlePushRequest(flowId,imsg,tuple);
break;
case UNPUSH:
handleUnpushRequest(flowId,imsg,tuple);
break;
case PATH:
handlePathRequest(flowId,cmsg,tuple);
break;
case RESTORE:
handleRestoreRequest(cmsg,tuple);
break;
case REROUTE:
handleRerouteRequest(cmsg,tuple);
break;
case STATUS:
handleStatusRequest(flowId,cmsg,tuple);
break;
case CACHE_SYNC:
handleCacheSyncRequest(cmsg,tuple);
break;
case READ:
if (flowId != null) {
handleReadRequest(flowId,cmsg,tuple);
}
 else {
handleDumpRequest(cmsg,tuple);
}
break;
default :
logger.debug(""String_Node_Str"",componentId,streamId);
break;
}
break;
case SPEAKER_BOLT:
case TRANSACTION_BOLT:
FlowState newStatus=(FlowState)tuple.getValueByField(FlowTopology.STATUS_FIELD);
logger.info(""String_Node_Str"",flowId,newStatus,componentId,streamId);
switch (streamId) {
case STATUS:
handleStateRequest(flowId,newStatus,tuple);
break;
default :
logger.debug(""String_Node_Str"",componentId,streamId);
break;
}
break;
case TOPOLOGY_ENGINE_BOLT:
ErrorMessage errorMessage=(ErrorMessage)tuple.getValueByField(AbstractTopology.MESSAGE_FIELD);
logger.info(""String_Node_Str"",flowId,componentId,streamId);
switch (streamId) {
case STATUS:
handleErrorRequest(flowId,errorMessage,tuple);
break;
default :
logger.debug(""String_Node_Str"",componentId,streamId);
break;
}
break;
case LCM_FLOW_SYNC_BOLT:
logger.debug(""String_Node_Str"");
NetworkInfoData networkDump=(NetworkInfoData)tuple.getValueByField(LcmFlowCacheSyncBolt.FIELD_ID_NETWORK_DUMP);
handleFlowSync(networkDump);
break;
default :
logger.debug(""String_Node_Str"",componentId);
break;
}
}
 catch (RecoverableException e) {
logger.error(""String_Node_Str"",e);
}
catch (CacheException exception) {
String logMessage=format(""String_Node_Str"",exception.getErrorMessage(),exception.getErrorDescription());
logger.error(""String_Node_Str"",logMessage,Utils.CORRELATION_ID,correlationId,Utils.FLOW_ID,flowId,componentId,streamId,exception);
ErrorMessage errorMessage=buildErrorMessage(correlationId,exception.getErrorType(),logMessage,componentId.toString().toLowerCase());
Values error=new Values(errorMessage,exception.getErrorType());
outputCollector.emit(StreamType.ERROR.toString(),tuple,error);
}
catch (IOException exception) {
logger.error(""String_Node_Str"",tuple,exception);
}
catch (Exception e) {
logger.error(String.format(""String_Node_Str"",getClass().getName()),e);
}
 finally {
logger.debug(""String_Node_Str"",tuple.getSourceComponent(),tuple.getSourceStreamId(),tuple);
if (isRecoverable) {
outputCollector.fail(tuple);
}
 else {
outputCollector.ack(tuple);
}
}
logger.trace(""String_Node_Str"",flowCache);
}"
37944,"private void handleUpdateRequest(CommandMessage message,Tuple tuple) throws IOException {
  Flow requestedFlow=((FlowUpdateRequest)message.getData()).getPayload();
  ImmutablePair<PathInfoData,PathInfoData> path;
  try {
    new FlowValidator(flowCache).checkFlowForEndpointConflicts(requestedFlow);
    path=pathComputer.getPath(requestedFlow,Strategy.COST);
    logger.info(""String_Node_Str"",path);
  }
 catch (  FlowValidationException e) {
    throw new MessageException(message.getCorrelationId(),System.currentTimeMillis(),ErrorType.UPDATE_FAILURE,""String_Node_Str"",e.getMessage());
  }
catch (  UnroutablePathException e) {
    throw new MessageException(message.getCorrelationId(),System.currentTimeMillis(),ErrorType.UPDATE_FAILURE,""String_Node_Str"",""String_Node_Str"");
  }
  ImmutablePair<Flow,Flow> flow=flowCache.updateFlow(requestedFlow,path);
  logger.info(""String_Node_Str"",flow);
  FlowInfoData data=new FlowInfoData(requestedFlow.getFlowId(),flow,UPDATE,message.getCorrelationId());
  InfoMessage infoMessage=new InfoMessage(data,System.currentTimeMillis(),message.getCorrelationId());
  Values topology=new Values(MAPPER.writeValueAsString(infoMessage));
  outputCollector.emit(StreamType.UPDATE.toString(),tuple,topology);
  Values northbound=new Values(new InfoMessage(new FlowResponse(buildFlowResponse(flow)),message.getTimestamp(),message.getCorrelationId(),Destination.NORTHBOUND));
  outputCollector.emit(StreamType.RESPONSE.toString(),tuple,northbound);
}","private void handleUpdateRequest(CommandMessage message,Tuple tuple) throws IOException, RecoverableException {
  Flow requestedFlow=((FlowUpdateRequest)message.getData()).getPayload();
  ImmutablePair<PathInfoData,PathInfoData> path;
  try {
    new FlowValidator(flowCache).checkFlowForEndpointConflicts(requestedFlow);
    path=pathComputer.getPath(requestedFlow,Strategy.COST);
    logger.info(""String_Node_Str"",path);
  }
 catch (  FlowValidationException e) {
    throw new MessageException(message.getCorrelationId(),System.currentTimeMillis(),ErrorType.UPDATE_FAILURE,""String_Node_Str"",e.getMessage());
  }
catch (  UnroutablePathException e) {
    throw new MessageException(message.getCorrelationId(),System.currentTimeMillis(),ErrorType.UPDATE_FAILURE,""String_Node_Str"",""String_Node_Str"");
  }
  ImmutablePair<Flow,Flow> flow=flowCache.updateFlow(requestedFlow,path);
  logger.info(""String_Node_Str"",flow);
  FlowInfoData data=new FlowInfoData(requestedFlow.getFlowId(),flow,UPDATE,message.getCorrelationId());
  InfoMessage infoMessage=new InfoMessage(data,System.currentTimeMillis(),message.getCorrelationId());
  Values topology=new Values(MAPPER.writeValueAsString(infoMessage));
  outputCollector.emit(StreamType.UPDATE.toString(),tuple,topology);
  Values northbound=new Values(new InfoMessage(new FlowResponse(buildFlowResponse(flow)),message.getTimestamp(),message.getCorrelationId(),Destination.NORTHBOUND));
  outputCollector.emit(StreamType.RESPONSE.toString(),tuple,northbound);
}"
37945,"private void handleCreateRequest(CommandMessage message,Tuple tuple) throws IOException {
  Flow requestedFlow=((FlowCreateRequest)message.getData()).getPayload();
  ImmutablePair<PathInfoData,PathInfoData> path;
  try {
    new FlowValidator(flowCache).checkFlowForEndpointConflicts(requestedFlow);
    path=pathComputer.getPath(requestedFlow,Strategy.COST);
    logger.info(""String_Node_Str"",path);
  }
 catch (  FlowValidationException e) {
    throw new MessageException(message.getCorrelationId(),System.currentTimeMillis(),ErrorType.CREATION_FAILURE,""String_Node_Str"",e.getMessage());
  }
catch (  UnroutablePathException e) {
    throw new MessageException(message.getCorrelationId(),System.currentTimeMillis(),ErrorType.CREATION_FAILURE,""String_Node_Str"",""String_Node_Str"");
  }
  ImmutablePair<Flow,Flow> flow=flowCache.createFlow(requestedFlow,path);
  logger.info(""String_Node_Str"",flow);
  FlowInfoData data=new FlowInfoData(requestedFlow.getFlowId(),flow,FlowOperation.CREATE,message.getCorrelationId());
  InfoMessage infoMessage=new InfoMessage(data,System.currentTimeMillis(),message.getCorrelationId());
  Values topology=new Values(MAPPER.writeValueAsString(infoMessage));
  outputCollector.emit(StreamType.CREATE.toString(),tuple,topology);
  Values northbound=new Values(new InfoMessage(new FlowResponse(buildFlowResponse(flow)),message.getTimestamp(),message.getCorrelationId(),Destination.NORTHBOUND));
  outputCollector.emit(StreamType.RESPONSE.toString(),tuple,northbound);
}","private void handleCreateRequest(CommandMessage message,Tuple tuple) throws IOException, RecoverableException {
  Flow requestedFlow=((FlowCreateRequest)message.getData()).getPayload();
  ImmutablePair<PathInfoData,PathInfoData> path;
  try {
    new FlowValidator(flowCache).checkFlowForEndpointConflicts(requestedFlow);
    path=pathComputer.getPath(requestedFlow,Strategy.COST);
    logger.info(""String_Node_Str"",path);
  }
 catch (  FlowValidationException e) {
    throw new MessageException(message.getCorrelationId(),System.currentTimeMillis(),ErrorType.CREATION_FAILURE,""String_Node_Str"",e.getMessage());
  }
catch (  UnroutablePathException e) {
    throw new MessageException(message.getCorrelationId(),System.currentTimeMillis(),ErrorType.CREATION_FAILURE,""String_Node_Str"",""String_Node_Str"");
  }
  ImmutablePair<Flow,Flow> flow=flowCache.createFlow(requestedFlow,path);
  logger.info(""String_Node_Str"",flow);
  FlowInfoData data=new FlowInfoData(requestedFlow.getFlowId(),flow,FlowOperation.CREATE,message.getCorrelationId());
  InfoMessage infoMessage=new InfoMessage(data,System.currentTimeMillis(),message.getCorrelationId());
  Values topology=new Values(MAPPER.writeValueAsString(infoMessage));
  outputCollector.emit(StreamType.CREATE.toString(),tuple,topology);
  Values northbound=new Values(new InfoMessage(new FlowResponse(buildFlowResponse(flow)),message.getTimestamp(),message.getCorrelationId(),Destination.NORTHBOUND));
  outputCollector.emit(StreamType.RESPONSE.toString(),tuple,northbound);
}"
37946,"/** 
 * Builds new forward and reverse flow pair.
 * @param flow  source flow
 * @param path  flow path
 * @param cache resource cache
 * @return new forward and reverse flow pair
 */
public ImmutablePair<Flow,Flow> buildFlow(final Flow flow,ImmutablePair<PathInfoData,PathInfoData> path,ResourceCache cache){
  String timestamp=Utils.getIsoTimestamp();
  int cookie=cache.allocateCookie();
  Flow forward=new Flow(flow.getFlowId(),flow.getBandwidth(),flow.isIgnoreBandwidth(),cookie | ResourceCache.FORWARD_FLOW_COOKIE_MASK,flow.getDescription(),timestamp,flow.getSourceSwitch(),flow.getDestinationSwitch(),flow.getSourcePort(),flow.getDestinationPort(),flow.getSourceVlan(),flow.getDestinationVlan(),cache.allocateMeterId(flow.getSourceSwitch()),cache.allocateVlanId(),path.getLeft(),FlowState.ALLOCATED);
  Flow reverse=new Flow(flow.getFlowId(),flow.getBandwidth(),flow.isIgnoreBandwidth(),cookie | ResourceCache.REVERSE_FLOW_COOKIE_MASK,flow.getDescription(),timestamp,flow.getDestinationSwitch(),flow.getSourceSwitch(),flow.getDestinationPort(),flow.getSourcePort(),flow.getDestinationVlan(),flow.getSourceVlan(),cache.allocateMeterId(flow.getDestinationSwitch()),cache.allocateVlanId(),path.getRight(),FlowState.ALLOCATED);
  return new ImmutablePair<>(forward,reverse);
}","/** 
 * Builds new forward and reverse flow pair.
 * @param flow  source flow
 * @param path  flow path
 * @param cache resource cache
 * @return new forward and reverse flow pair
 */
public ImmutablePair<Flow,Flow> buildFlow(final Flow flow,ImmutablePair<PathInfoData,PathInfoData> path,ResourceCache cache){
  String timestamp=Utils.getIsoTimestamp();
  int cookie=cache.allocateCookie();
  int forwardVlan=0;
  int reverseVlan=0;
  if (!flow.isOneSwitchFlow()) {
    forwardVlan=cache.allocateVlanId();
    reverseVlan=cache.allocateVlanId();
  }
  Flow forward=new Flow(flow.getFlowId(),flow.getBandwidth(),flow.isIgnoreBandwidth(),cookie | ResourceCache.FORWARD_FLOW_COOKIE_MASK,flow.getDescription(),timestamp,flow.getSourceSwitch(),flow.getDestinationSwitch(),flow.getSourcePort(),flow.getDestinationPort(),flow.getSourceVlan(),flow.getDestinationVlan(),cache.allocateMeterId(flow.getSourceSwitch()),forwardVlan,path.getLeft(),FlowState.ALLOCATED);
  Flow reverse=new Flow(flow.getFlowId(),flow.getBandwidth(),flow.isIgnoreBandwidth(),cookie | ResourceCache.REVERSE_FLOW_COOKIE_MASK,flow.getDescription(),timestamp,flow.getDestinationSwitch(),flow.getSourceSwitch(),flow.getDestinationPort(),flow.getSourcePort(),flow.getDestinationVlan(),flow.getSourceVlan(),cache.allocateMeterId(flow.getDestinationSwitch()),reverseVlan,path.getRight(),FlowState.ALLOCATED);
  return new ImmutablePair<>(forward,reverse);
}"
37947,"/** 
 * Track and allocate the flow.
 * @param flow The flow to track / allocate.
 */
public void pushFlow(ImmutablePair<Flow,Flow> flow){
  putFlow(flow);
  resourceCache.allocateFlow(flow);
}","/** 
 * Track and allocate the flow.
 * @param flow The flow to track / allocate.
 */
public void pushFlow(ImmutablePair<Flow,Flow> flow){
  resourceCache.allocateFlow(flow);
  putFlow(flow);
}"
37948,"/** 
 * Allocates flow resources.
 * @param flow flow
 */
public void allocateFlow(ImmutablePair<Flow,Flow> flow){
  if (flow.left != null) {
    allocateCookie((int)(FLOW_COOKIE_VALUE_MASK & flow.left.getCookie()));
    allocateVlanId(flow.left.getTransitVlan());
    allocateMeterId(flow.left.getSourceSwitch(),flow.left.getMeterId());
  }
  if (flow.right != null) {
    allocateVlanId(flow.right.getTransitVlan());
    allocateMeterId(flow.right.getSourceSwitch(),flow.right.getMeterId());
  }
}","/** 
 * Allocates flow resources. All flows come here .. single switch and multi switch flows.
 * @param flow flow
 */
public void allocateFlow(ImmutablePair<Flow,Flow> flow){
  if (flow.left != null) {
    allocateCookie((int)(FLOW_COOKIE_VALUE_MASK & flow.left.getCookie()));
    if (!flow.left.isOneSwitchFlow()) {
      allocateVlanId(flow.left.getTransitVlan());
    }
    allocateMeterId(flow.left.getSourceSwitch(),flow.left.getMeterId());
  }
  if (flow.right != null) {
    if (!flow.right.isOneSwitchFlow()) {
      allocateVlanId(flow.right.getTransitVlan());
    }
    allocateMeterId(flow.right.getSourceSwitch(),flow.right.getMeterId());
  }
}"
37949,"@Test public void allocateFlow() throws Exception {
  resourceCache.allocateFlow(new ImmutablePair<>(forwardCreatedFlow,reverseCreatedFlow));
  resourceCache.allocateFlow(new ImmutablePair<>(forwardCreatedFlow,reverseCreatedFlow));
  Set<Integer> allocatedCookies=resourceCache.getAllCookies();
  Set<Integer> allocatedVlanIds=resourceCache.getAllVlanIds();
  Set<Integer> allocatedMeterIds=resourceCache.getAllMeterIds(NetworkTopologyConstants.sw3.getSwitchId());
  Set<Integer> expectedCookies=new HashSet<>(Arrays.asList((int)forwardCreatedFlow.getCookie(),(int)reverseCreatedFlow.getCookie()));
  Set<Integer> expectedVlanIds=new HashSet<>(Arrays.asList(forwardCreatedFlow.getTransitVlan(),reverseCreatedFlow.getTransitVlan()));
  Set<Integer> expectedMeterIds=new HashSet<>(Arrays.asList(forwardCreatedFlow.getMeterId(),reverseCreatedFlow.getMeterId()));
  assertEquals(expectedCookies,allocatedCookies);
  assertEquals(expectedVlanIds,allocatedVlanIds);
  assertEquals(expectedMeterIds,allocatedMeterIds);
}","@Test public void allocateFlow() throws Exception {
  resourceCache.allocateFlow(new ImmutablePair<>(forwardCreatedFlow,reverseCreatedFlow));
  resourceCache.allocateFlow(new ImmutablePair<>(forwardCreatedFlow,reverseCreatedFlow));
  Set<Integer> allocatedCookies=resourceCache.getAllCookies();
  Set<Integer> allocatedVlanIds=resourceCache.getAllVlanIds();
  Set<Integer> allocatedMeterIds=new HashSet<>();
  allocatedMeterIds.addAll(resourceCache.getAllMeterIds(NetworkTopologyConstants.sw3.getSwitchId()));
  allocatedMeterIds.addAll(resourceCache.getAllMeterIds(NetworkTopologyConstants.sw4.getSwitchId()));
  Set<Integer> expectedCookies=new HashSet<>(Arrays.asList((int)forwardCreatedFlow.getCookie(),(int)reverseCreatedFlow.getCookie()));
  Set<Integer> expectedVlanIds=new HashSet<>(Arrays.asList(forwardCreatedFlow.getTransitVlan(),reverseCreatedFlow.getTransitVlan()));
  Set<Integer> expectedMeterIds=new HashSet<>(Arrays.asList(forwardCreatedFlow.getMeterId(),reverseCreatedFlow.getMeterId()));
  assertEquals(expectedCookies,allocatedCookies);
  assertEquals(expectedVlanIds,allocatedVlanIds);
  assertEquals(expectedMeterIds,allocatedMeterIds);
}"
37950,"private void initFlowCache(){
  logger.info(""String_Node_Str"");
  Map<String,BidirectionalFlow> flowPairsMap=new HashMap<>();
  List<Flow> flows=pathComputer.getAllFlows();
  logger.info(""String_Node_Str"",flows.size());
  for (  Flow flow : flows) {
    logger.info(""String_Node_Str"",flow);
    if (!flowPairsMap.containsKey(flow.getFlowId())) {
      flowPairsMap.put(flow.getFlowId(),new BidirectionalFlow());
    }
    BidirectionalFlow pair=flowPairsMap.get(flow.getFlowId());
    try {
      pair.add(flow);
    }
 catch (    IllegalArgumentException e) {
      logger.error(""String_Node_Str"",flow.getFlowId(),e.toString());
    }
  }
  for (  BidirectionalFlow bidirectionalFlow : flowPairsMap.values()) {
    try {
      flowCache.pushFlow(bidirectionalFlow.makeFlowPair());
    }
 catch (    InvalidArgumentException e) {
      logger.error(""String_Node_Str"",bidirectionalFlow.anyDefined().getFlowId(),e.toString());
    }
  }
  logger.info(""String_Node_Str"");
}","private void initFlowCache(){
  logger.info(""String_Node_Str"");
  Map<String,BidirectionalFlow> flowPairsMap=new HashMap<>();
  List<Flow> flows=pathComputer.getAllFlows();
  logger.info(""String_Node_Str"",flows.size());
  for (  Flow flow : flows) {
    if (!flowPairsMap.containsKey(flow.getFlowId())) {
      flowPairsMap.put(flow.getFlowId(),new BidirectionalFlow());
    }
    BidirectionalFlow pair=flowPairsMap.get(flow.getFlowId());
    try {
      pair.add(flow);
    }
 catch (    IllegalArgumentException e) {
      logger.error(""String_Node_Str"",flow.getFlowId(),e.toString());
    }
  }
  for (  BidirectionalFlow bidirectionalFlow : flowPairsMap.values()) {
    try {
      flowCache.pushFlow(bidirectionalFlow.makeFlowPair());
    }
 catch (    InvalidArgumentException e) {
      logger.error(""String_Node_Str"",bidirectionalFlow.anyDefined().getFlowId(),e.toString());
    }
  }
  logger.info(""String_Node_Str"");
}"
37951,"@Override public int hashCode(){
  int result=metric != null ? metric.hashCode() : 0;
  result=31 * result + (tags != null ? tags.hashCode() : 0);
  return result;
}","@Override public int hashCode(){
  int result=metric != null ? metric.hashCode() : 0;
  result=31 * result + (tags != null ? tags.hashCode() : 0);
  result=31 * result + (value != null ? value.hashCode() : 0);
  return result;
}"
37952,"@Override public StormTopology createTopology(){
  LOGGER.info(""String_Node_Str"");
  TopologyBuilder tb=new TopologyBuilder();
  checkAndCreateTopic(topic);
  KafkaSpout kafkaSpout=createKafkaSpout(topic,spoutId);
  tb.setSpout(spoutId,kafkaSpout,config.getOpenTsdbNumSpouts());
  tb.setBolt(parseBoltId,new DatapointParseBolt(),config.getGetDatapointParseBoltExecutors()).setNumTasks(config.getGetDatapointParseBoltWorkers()).shuffleGrouping(spoutId);
  tb.setBolt(boltId,new OpenTSDBFilterBolt(),config.getOpenTsdbFilterBoltExecutors()).fieldsGrouping(parseBoltId,new Fields(""String_Node_Str""));
  return tb.createTopology();
}","@Override public StormTopology createTopology(){
  LOGGER.info(""String_Node_Str"");
  TopologyBuilder tb=new TopologyBuilder();
  checkAndCreateTopic(topic);
  KafkaSpout kafkaSpout=createKafkaSpout(topic,spoutId);
  tb.setSpout(spoutId,kafkaSpout,config.getOpenTsdbNumSpouts());
  tb.setBolt(parseBoltId,new DatapointParseBolt(),config.getGetDatapointParseBoltExecutors()).setNumTasks(config.getGetDatapointParseBoltWorkers()).shuffleGrouping(spoutId);
  tb.setBolt(boltId,new OpenTSDBFilterBolt(),config.getOpenTsdbFilterBoltExecutors()).fieldsGrouping(parseBoltId,new Fields(""String_Node_Str""));
  OpenTsdbClient.Builder tsdbBuilder=OpenTsdbClient.newBuilder(config.getOpenTsDBHosts()).returnDetails();
  if (config.isOpenTsdbClientChunkedRequestsEnabled()) {
    tsdbBuilder.enableChunkedEncoding();
  }
  OpenTsdbBolt openTsdbBolt=new OpenTsdbBolt(tsdbBuilder,Collections.singletonList(TupleOpenTsdbDatapointMapper.DEFAULT_MAPPER));
  openTsdbBolt.withBatchSize(config.getOpenTsdbBatchSize()).withFlushInterval(config.getOpenTsdbFlushInterval());
  tb.setBolt(""String_Node_Str"",openTsdbBolt,config.getOpenTsdbBoltExecutors()).setNumTasks(config.getOpenTsdbBoltWorkers()).shuffleGrouping(boltId);
  return tb.createTopology();
}"
37953,"private boolean isUpdateRequired(Datapoint datapoint){
  boolean update=true;
  if (storage.containsKey(datapoint.hashCode())) {
    Datapoint prevDatapoint=storage.get(datapoint.hashCode());
    update=!prevDatapoint.getValue().equals(datapoint.getValue()) || datapoint.getTime() - prevDatapoint.getTime() >= TEN_MINUTES;
  }
  return update;
}","private boolean isUpdateRequired(Datapoint datapoint){
  boolean update=true;
  if (storage.containsKey(datapoint.simpleHashCode())) {
    Datapoint prevDatapoint=storage.get(datapoint.simpleHashCode());
    update=!prevDatapoint.getValue().equals(datapoint.getValue()) || datapoint.getTime() - prevDatapoint.getTime() >= TEN_MINUTES;
  }
  return update;
}"
37954,"private void addDatapoint(Datapoint datapoint){
  LOGGER.debug(""String_Node_Str"" + datapoint.hashCode());
  LOGGER.debug(""String_Node_Str"" + storage.size());
  storage.put(datapoint.hashCode(),datapoint);
}","private void addDatapoint(Datapoint datapoint){
  LOGGER.debug(""String_Node_Str"" + datapoint.simpleHashCode());
  LOGGER.debug(""String_Node_Str"" + storage.size());
  storage.put(datapoint.simpleHashCode(),datapoint);
}"
37955,"/** 
 * {@inheritDoc}
 */
@Override public FlowValidationDto validateFlow(final String flowId,final String correlationId){
  Flow flow=pathComputer.getFlow(flowId);
  if (flow == null)   return null;
  logger.debug(""String_Node_Str"",flow);
  Set<String> switches=new HashSet<>();
  switches.add(flow.getSourceSwitch());
  if (flow.getFlowPath() == null) {
    throw new InvalidPathException(flowId,""String_Node_Str"");
  }
  for (  PathNode node : flow.getFlowPath().getPath()) {
    switches.add(node.getSwitchId());
  }
  switches.add(flow.getDestinationSwitch());
  Long ignoreCookie=0L;
  int correlation_iter=1;
  Map<String,SwitchFlowEntries> rules=new HashMap<>();
  for (  String switchid : switches) {
    String corr_id=correlationId + ""String_Node_Str"" + correlation_iter++;
    rules.put(switchid,switchService.getRules(switchid,ignoreCookie,corr_id));
  }
  List<PathDiscrepancyDto> discrepencies=new ArrayList<>();
  for (  String switchid : switches) {
    PathDiscrepancyDto disc=new PathDiscrepancyDto();
    disc.setField(""String_Node_Str"" + switchid);
    disc.setExpectedValue(""String_Node_Str"");
    int numRules=(rules.get(switchid) == null) ? 0 : rules.get(switchid).getFlowEntries().size();
    disc.setActualValue(""String_Node_Str"" + numRules);
    disc.setNode(new PathNode());
    discrepencies.add(disc);
  }
  FlowValidationDto result=new FlowValidationDto();
  result.setFlow(flow);
  result.setFlowId(flowId);
  result.setDiscrepancies(discrepencies);
  result.setAsExpected(discrepencies.size() > 0);
  return result;
}","/** 
 * {@inheritDoc}
 */
@Override public FlowValidationDto validateFlow(final String flowId,final String correlationId){
  Flow flow=pathComputer.getFlow(flowId);
  if (flow == null)   return null;
  logger.debug(""String_Node_Str"",flow);
  Set<String> switches=new HashSet<>();
  switches.add(flow.getSourceSwitch());
  if (flow.getFlowPath() == null) {
    throw new InvalidPathException(flowId,""String_Node_Str"");
  }
  for (  PathNode node : flow.getFlowPath().getPath()) {
    switches.add(node.getSwitchId());
  }
  switches.add(flow.getDestinationSwitch());
  Long ignoreCookie=0L;
  int correlation_iter=1;
  Map<String,SwitchFlowEntries> rules=new HashMap<>();
  for (  String switchid : switches) {
    String corr_id=correlationId + ""String_Node_Str"" + correlation_iter++;
    rules.put(switchid,switchService.getRules(switchid,ignoreCookie,corr_id));
  }
  List<PathDiscrepancyDto> discrepencies=new ArrayList<>();
  for (  String switchid : switches) {
    PathDiscrepancyDto disc=new PathDiscrepancyDto();
    disc.setField(""String_Node_Str"" + switchid);
    disc.setExpectedValue(""String_Node_Str"");
    int numRules=(rules.get(switchid) == null) ? 0 : rules.get(switchid).getFlowEntries().size();
    disc.setActualValue(""String_Node_Str"" + numRules);
    disc.setNode(new PathNode());
    discrepencies.add(disc);
  }
  FlowValidationDto result=new FlowValidationDto();
  result.setFlow(flow);
  result.setFlowId(flowId);
  result.setDiscrepancies(discrepencies);
  result.setAsExpected(discrepencies.size() == 0);
  return result;
}"
37956,"public FlowAdapter(Record dbRecord){
  String pathJson=dbRecord.get(""String_Node_Str"").asString();
  if (pathJson.equals(""String_Node_Str"")) {
    pathJson=""String_Node_Str"";
  }
  String remaining=pathJson.substring(2);
  PathInfoData path;
  pathJson=""String_Node_Str"" + remaining;
  try {
    path=Utils.MAPPER.readValue(pathJson,PathInfoData.class);
  }
 catch (  IOException e) {
    throw new IllegalArgumentException(String.format(""String_Node_Str"",pathJson),e);
  }
  flow=new Flow(dbRecord.get(Utils.FLOW_ID).asString(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asBoolean(),dbRecord.get(""String_Node_Str"").asLong(),dbRecord.get(""String_Node_Str"").asString(),dbRecord.get(""String_Node_Str"").asString(),dbRecord.get(""String_Node_Str"").asString(),dbRecord.get(""String_Node_Str"").asString(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),path,FlowState.CACHED);
}","public FlowAdapter(Record dbRecord){
  String pathJson=dbRecord.get(""String_Node_Str"").asString().trim();
  if (pathJson.equals(""String_Node_Str"")) {
    pathJson=""String_Node_Str"";
  }
  String start=pathJson.substring(0,pathJson.length() - 1);
  PathInfoData path;
  pathJson=start + ""String_Node_Str"";
  try {
    path=Utils.MAPPER.readValue(pathJson,PathInfoData.class);
  }
 catch (  IOException e) {
    throw new IllegalArgumentException(String.format(""String_Node_Str"",pathJson),e);
  }
  flow=new Flow(dbRecord.get(Utils.FLOW_ID).asString(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asBoolean(),dbRecord.get(""String_Node_Str"").asLong(),dbRecord.get(""String_Node_Str"").asString(),dbRecord.get(""String_Node_Str"").asString(),dbRecord.get(""String_Node_Str"").asString(),dbRecord.get(""String_Node_Str"").asString(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),path,FlowState.CACHED);
}"
37957,"/** 
 * Gets the flow path.
 * @param flowId the flowid
 * @param FlowPayload the Flow Payload
 * @return the flow path
 */
public static FlowPath getFlowPath(final String flowId,final FlowPayload flowPayload){
  PathInfoData pathInfo=new PathInfoData(setPath(flowPayload.getForward()),setPath(flowPayload.getReverse()));
  return new FlowPath(flowId,pathInfo);
}","/** 
 * Gets the flow path.
 * @param flowId the flowid
 * @param FlowPayload the Flow Payload
 * @return the flow path
 */
public FlowPath getFlowPath(final String flowId,final FlowPayload flowPayload){
  PathInfoData pathInfo=new PathInfoData(setPath(flowPayload.getForward()),setPath(flowPayload.getReverse()));
  return new FlowPath(flowId,pathInfo);
}"
37958,"/** 
 * Sets the path.
 * @param FlowPathInfoData the flow path info data
 * @return the {@link PathNode} list
 */
private static List<PathNode> setPath(final FlowPathInfoData flowPathInfoData){
  List<PathNode> pathNodes=new ArrayList<PathNode>();
  org.openkilda.integration.model.response.PathInfoData flowpath=flowPathInfoData.getFlowpath();
  List<org.openkilda.integration.model.response.PathNode> paths=flowpath.getPath();
  Integer inport=null;
  Integer seq_id=0;
  if (paths != null && !paths.isEmpty()) {
    for (    org.openkilda.integration.model.response.PathNode path : paths) {
      if (path.getSeqId() == 0) {
        pathNodes.add(new PathNode(seq_id,flowPathInfoData.getSrcPort(),path.getPortNo(),flowPathInfoData.getSrcSwitch()));
        seq_id++;
      }
 else {
        if (path.getSeqId() % 2 == 0) {
          pathNodes.add(new PathNode(seq_id,inport,path.getPortNo(),path.getSwitchId()));
          seq_id++;
        }
 else         inport=path.getPortNo();
      }
    }
  }
  pathNodes.add(new PathNode(seq_id,inport,flowPathInfoData.getDstPort(),flowPathInfoData.getDstSwitch()));
  return pathNodes;
}","/** 
 * Sets the path.
 * @param FlowPathInfoData the flow path info data
 * @return the {@link PathNode} list
 */
private List<PathNode> setPath(FlowPathInfoData flowPathInfoData){
  List<PathNode> pathNodes=new ArrayList<PathNode>();
  org.openkilda.integration.model.response.PathInfoData flowpath=flowPathInfoData.getFlowpath();
  List<org.openkilda.integration.model.response.PathNode> paths=flowpath.getPath();
  Integer inport=null;
  Integer seq_id=0;
  Map<String,String> csNames=switchIntegrationService.getCustomSwitchNameFromFile();
  if (paths != null && !paths.isEmpty()) {
    for (    org.openkilda.integration.model.response.PathNode path : paths) {
      if (path.getSeqId() == 1) {
        String switchName=switchIntegrationService.customSwitchName(csNames,flowPathInfoData.getSrcSwitch());
        pathNodes.add(new PathNode(seq_id,flowPathInfoData.getSrcPort(),path.getPortNo(),switchName));
        seq_id++;
      }
 else {
        if (path.getSeqId() % 2 == 1) {
          String switchName=switchIntegrationService.customSwitchName(csNames,path.getSwitchId());
          pathNodes.add(new PathNode(seq_id,inport,path.getPortNo(),switchName));
          seq_id++;
        }
 else         inport=path.getPortNo();
      }
    }
  }
  String switchName=switchIntegrationService.customSwitchName(csNames,flowPathInfoData.getDstSwitch());
  pathNodes.add(new PathNode(seq_id,inport,flowPathInfoData.getDstPort(),switchName));
  return pathNodes;
}"
37959,"/** 
 * Gets the flows.
 * @return the flows
 * @throws IntegrationException
 */
public List<FlowInfo> getFlows(){
  List<Flow> flowList=getAllFlowList();
  if (flowList != null) {
    List<FlowInfo> flows=FlowConverter.toFlowsInfo(flowList);
    if (!CollectionUtil.isEmpty(flows)) {
      flows.forEach(flowInfo -> {
        try {
          String status=getFlowStatus(flowInfo.getFlowid());
          flowInfo.setStatus(status);
        }
 catch (        Exception e) {
          LOGGER.error(""String_Node_Str"" + e,e);
        }
      }
);
    }
 else {
      throw new ContentNotFoundException();
    }
    return flows;
  }
  return null;
}","/** 
 * Gets the flows.
 * @return the flows
 * @throws IntegrationException
 */
public List<FlowInfo> getFlows(){
  List<Flow> flowList=getAllFlowList();
  if (flowList != null) {
    List<FlowInfo> flows=FlowConverter.toFlowsInfo(flowList);
    return flows;
  }
  return null;
}"
37960,"/** 
 * Gets the flow paths.
 * @return the flow paths
 * @throws IntegrationException
 */
public FlowPath getFlowPath(final String flowId){
  try {
    HttpResponse response=restClientManager.invoke(applicationProperties.getTopologyFlows() + ""String_Node_Str"" + flowId,HttpMethod.GET,""String_Node_Str"",""String_Node_Str"",""String_Node_Str"");
    if (RestClientManager.isValidResponse(response)) {
      FlowPayload flowPayload=restClientManager.getResponse(response,FlowPayload.class);
      return FlowPathConverter.getFlowPath(flowId,flowPayload);
    }
 else {
      String content=IoUtil.toString(response.getEntity().getContent());
      throw new InvalidResponseException(response.getStatusLine().getStatusCode(),content);
    }
  }
 catch (  Exception exception) {
    LOGGER.error(""String_Node_Str"" + exception.getMessage());
    throw new IntegrationException(exception);
  }
}","/** 
 * Gets the flow paths.
 * @return the flow paths
 * @throws IntegrationException
 */
public FlowPath getFlowPath(final String flowId){
  try {
    HttpResponse response=restClientManager.invoke(applicationProperties.getTopologyFlows() + ""String_Node_Str"" + flowId,HttpMethod.GET,""String_Node_Str"",""String_Node_Str"",""String_Node_Str"");
    if (RestClientManager.isValidResponse(response)) {
      FlowPayload flowPayload=restClientManager.getResponse(response,FlowPayload.class);
      return flowPathConverter.getFlowPath(flowId,flowPayload);
    }
 else {
      String content=IoUtil.toString(response.getEntity().getContent());
      throw new InvalidResponseException(response.getStatusLine().getStatusCode(),content);
    }
  }
 catch (  Exception exception) {
    LOGGER.error(""String_Node_Str"" + exception.getMessage());
    throw new IntegrationException(exception);
  }
}"
37961,"@SuppressWarnings(""String_Node_Str"") private Map<String,String> getCustomSwitchNameFromFile(){
  Map<String,String> csNames=new HashMap<String,String>();
  InputStream inputStream=null;
  String data=null;
  try {
    inputStream=new URL(applicationProperties.getSwitchDataFilePath()).openStream();
    if (inputStream != null) {
      data=IoUtil.toString(inputStream);
      if (data != null && !StringUtils.isEmpty(data)) {
        csNames=JsonUtil.toObject(data,HashMap.class);
      }
    }
  }
 catch (  Exception ex) {
    LOGGER.error(""String_Node_Str"",ex);
  }
  return csNames;
}","@SuppressWarnings(""String_Node_Str"") public Map<String,String> getCustomSwitchNameFromFile(){
  Map<String,String> csNames=new HashMap<String,String>();
  InputStream inputStream=null;
  String data=null;
  try {
    inputStream=new URL(applicationProperties.getSwitchDataFilePath()).openStream();
    if (inputStream != null) {
      data=IoUtil.toString(inputStream);
      if (data != null && !StringUtils.isEmpty(data)) {
        csNames=JsonUtil.toObject(data,HashMap.class);
      }
    }
  }
 catch (  Exception ex) {
    LOGGER.error(""String_Node_Str"",ex);
  }
  return csNames;
}"
37962,"/** 
 * Gets the SwitchInfoSetName.
 * @return the switches
 * @throws IntegrationException
 */
private List<SwitchInfo> getSwitchInfoSetName(List<SwitchInfo> switches){
  LOGGER.info(""String_Node_Str"");
  if (switches != null && !StringUtils.isEmpty(switches)) {
    Map<String,String> csNames=getCustomSwitchNameFromFile();
    for (    SwitchInfo switchInfo : switches) {
      String switchId=switchInfo.getSwitchId();
      if (csNames != null && !StringUtils.isEmpty(csNames) && csNames.size() > 0) {
        if (csNames.containsKey(switchId.toLowerCase()) || csNames.containsKey(switchId.toUpperCase())) {
          if (!IoUtil.chkStringIsNotEmpty(csNames.get(switchId))) {
            switchInfo.setName(switchId);
          }
 else {
            switchInfo.setName(csNames.get(switchId));
          }
        }
 else {
          switchInfo.setName(switchId);
        }
      }
 else       switchInfo.setName(switchId);
    }
  }
  return switches;
}","/** 
 * Gets the SwitchInfoSetName.
 * @return the switches
 * @throws IntegrationException
 */
private List<SwitchInfo> getSwitchInfoSetName(List<SwitchInfo> switches){
  LOGGER.info(""String_Node_Str"");
  if (switches != null && !StringUtils.isEmpty(switches)) {
    Map<String,String> csNames=getCustomSwitchNameFromFile();
    for (    SwitchInfo switchInfo : switches) {
      switchInfo.setName(customSwitchName(csNames,switchInfo.getSwitchId()));
    }
  }
  return switches;
}"
37963,"/** 
 * Compares the Flow from the DB to what is on each switch.
 * @param flowId id of flow to be rerouted.
 * @param correlationId correlation ID header value.
 * @return flow payload with updated path.
 */
@ApiOperation(value=""String_Node_Str"",response=FlowPathPayload.class) @ApiResponses(value={@ApiResponse(code=200,response=FlowPathPayload.class,message=""String_Node_Str""),@ApiResponse(code=400,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=401,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=403,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=404,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=500,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=503,response=MessageError.class,message=""String_Node_Str"")}) @RequestMapping(path=""String_Node_Str"",method=RequestMethod.GET) @ResponseStatus(HttpStatus.OK) public ResponseEntity<FlowValidationDto> validateFlow(@PathVariable(""String_Node_Str"") String flowId,@RequestHeader(value=CORRELATION_ID,defaultValue=DEFAULT_CORRELATION_ID) String correlationId){
  if (correlationId.equals(DEFAULT_CORRELATION_ID))   correlationId=getUniqueCorrelation();
  logger.debug(""String_Node_Str"",correlationId,flowId);
  FlowValidationDto result=flowService.validateFlow(flowId,correlationId);
  ResponseEntity<FlowValidationDto> response;
  if (result == null)   response=new ResponseEntity<>(null,new HttpHeaders(),HttpStatus.NOT_FOUND);
 else   response=new ResponseEntity<>(result,new HttpHeaders(),HttpStatus.OK);
  return response;
}","/** 
 * Compares the Flow from the DB to what is on each switch.
 * @param flowId id of flow to be rerouted.
 * @param correlationId correlation ID header value.
 * @return flow payload with updated path.
 */
@ApiOperation(value=""String_Node_Str"",response=FlowPathPayload.class) @ApiResponses(value={@ApiResponse(code=200,response=FlowPathPayload.class,message=""String_Node_Str""),@ApiResponse(code=400,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=401,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=403,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=404,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=500,response=MessageError.class,message=""String_Node_Str""),@ApiResponse(code=503,response=MessageError.class,message=""String_Node_Str"")}) @RequestMapping(path=""String_Node_Str"",method=RequestMethod.GET) @ResponseStatus(HttpStatus.OK) public ResponseEntity<FlowValidationDto> validateFlow(@PathVariable(""String_Node_Str"") String flowId,@RequestHeader(value=CORRELATION_ID,defaultValue=DEFAULT_CORRELATION_ID) String correlationId){
}"
37964,"/** 
 * Performs validation of specific flow - ie comparing what is in the database with what is on the network.
 * @param flowId id of the flow
 * @param correlationId request correlation Id
 * @return the results of the comparison, or null if the flow isn't found.
 */
FlowValidationDto validateFlow(final String flowId,final String correlationId);","/** 
 * Performs validation of specific flow - ie comparing what is in the database with what is on the network.
 * @param flowId id of the flow
 * @param correlationId request correlation Id
 * @return the results of the comparison, or null if the flow isn't found.
 * @throws java.nio.file.InvalidPathException if the flow doesn't return a path and it should.
 */
FlowValidationDto validateFlow(final String flowId,final String correlationId);"
37965,"/** 
 * {@inheritDoc}
 */
@Override public FlowValidationDto validateFlow(final String flowId,final String correlationId){
  Flow flow=pathComputer.getFlow(flowId);
  if (flow == null)   return null;
  Set<String> switches=new HashSet<>();
  switches.add(flow.getSourceSwitch());
  for (  PathNode node : flow.getFlowPath().getPath()) {
    switches.add(node.getSwitchId());
  }
  switches.add(flow.getDestinationSwitch());
  Long ignoreCookie=0L;
  int correlation_iter=1;
  Map<String,SwitchFlowEntries> rules=new HashMap<>();
  for (  String switchid : switches) {
    String corr_id=correlationId + ""String_Node_Str"" + correlation_iter++;
    rules.put(switchid,switchService.getRules(switchid,ignoreCookie,corr_id));
  }
  List<PathDiscrepancyDto> discrepencies=new ArrayList<>();
  for (  String switchid : switches) {
    PathDiscrepancyDto disc=new PathDiscrepancyDto();
    disc.setField(""String_Node_Str"" + switchid);
    disc.setExpectedValue(""String_Node_Str"");
    int numRules=(rules.get(switchid) == null) ? 0 : rules.get(switchid).getFlowEntries().size();
    disc.setActualValue(""String_Node_Str"" + numRules);
    disc.setNode(new PathNode());
    discrepencies.add(disc);
  }
  FlowValidationDto result=new FlowValidationDto();
  result.setFlow(flow);
  result.setFlowId(flowId);
  result.setDiscrepancies(discrepencies);
  result.setAsExpected(discrepencies.size() > 0);
  return result;
}","/** 
 * {@inheritDoc}
 */
@Override public FlowValidationDto validateFlow(final String flowId,final String correlationId){
  Flow flow=pathComputer.getFlow(flowId);
  if (flow == null)   return null;
  logger.debug(""String_Node_Str"",flow);
  Set<String> switches=new HashSet<>();
  switches.add(flow.getSourceSwitch());
  if (flow.getFlowPath() == null) {
    throw new InvalidPathException(flowId,""String_Node_Str"");
  }
  for (  PathNode node : flow.getFlowPath().getPath()) {
    switches.add(node.getSwitchId());
  }
  switches.add(flow.getDestinationSwitch());
  Long ignoreCookie=0L;
  int correlation_iter=1;
  Map<String,SwitchFlowEntries> rules=new HashMap<>();
  for (  String switchid : switches) {
    String corr_id=correlationId + ""String_Node_Str"" + correlation_iter++;
    rules.put(switchid,switchService.getRules(switchid,ignoreCookie,corr_id));
  }
  List<PathDiscrepancyDto> discrepencies=new ArrayList<>();
  for (  String switchid : switches) {
    PathDiscrepancyDto disc=new PathDiscrepancyDto();
    disc.setField(""String_Node_Str"" + switchid);
    disc.setExpectedValue(""String_Node_Str"");
    int numRules=(rules.get(switchid) == null) ? 0 : rules.get(switchid).getFlowEntries().size();
    disc.setActualValue(""String_Node_Str"" + numRules);
    disc.setNode(new PathNode());
    discrepencies.add(disc);
  }
  FlowValidationDto result=new FlowValidationDto();
  result.setFlow(flow);
  result.setFlowId(flowId);
  result.setDiscrepancies(discrepencies);
  result.setAsExpected(discrepencies.size() > 0);
  return result;
}"
37966,"public FlowAdapter(Record dbRecord){
  String pathJson=dbRecord.get(""String_Node_Str"").asString();
  PathInfoData path;
  try {
    path=Utils.MAPPER.readValue(pathJson,PathInfoData.class);
  }
 catch (  IOException e) {
    throw new IllegalArgumentException(String.format(""String_Node_Str"",pathJson),e);
  }
  flow=new Flow(dbRecord.get(Utils.FLOW_ID).asString(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asBoolean(),dbRecord.get(""String_Node_Str"").asLong(),dbRecord.get(""String_Node_Str"").asString(),dbRecord.get(""String_Node_Str"").asString(),dbRecord.get(""String_Node_Str"").asString(),dbRecord.get(""String_Node_Str"").asString(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),path,FlowState.CACHED);
}","public FlowAdapter(Record dbRecord){
  String pathJson=dbRecord.get(""String_Node_Str"").asString();
  if (pathJson.equals(""String_Node_Str"")) {
    pathJson=""String_Node_Str"";
  }
  String remaining=pathJson.substring(2);
  PathInfoData path;
  pathJson=""String_Node_Str"" + remaining;
  try {
    path=Utils.MAPPER.readValue(pathJson,PathInfoData.class);
  }
 catch (  IOException e) {
    throw new IllegalArgumentException(String.format(""String_Node_Str"",pathJson),e);
  }
  flow=new Flow(dbRecord.get(Utils.FLOW_ID).asString(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asBoolean(),dbRecord.get(""String_Node_Str"").asLong(),dbRecord.get(""String_Node_Str"").asString(),dbRecord.get(""String_Node_Str"").asString(),dbRecord.get(""String_Node_Str"").asString(),dbRecord.get(""String_Node_Str"").asString(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),dbRecord.get(""String_Node_Str"").asInt(),path,FlowState.CACHED);
}"
37967,"@Test public void getAllFlows(){
  try (Transaction tx=graphDb.beginTx()){
    Node node1, node2;
    node1=graphDb.createNode(Label.label(""String_Node_Str""));
    node1.setProperty(""String_Node_Str"",""String_Node_Str"");
    node2=graphDb.createNode(Label.label(""String_Node_Str""));
    node2.setProperty(""String_Node_Str"",""String_Node_Str"");
    Relationship rel1=node1.createRelationshipTo(node2,RelationshipType.withName(""String_Node_Str""));
    rel1.setProperty(""String_Node_Str"",""String_Node_Str"");
    rel1.setProperty(""String_Node_Str"",3);
    rel1.setProperty(""String_Node_Str"",2);
    rel1.setProperty(""String_Node_Str"",1);
    rel1.setProperty(""String_Node_Str"",""String_Node_Str"");
    rel1.setProperty(""String_Node_Str"",""String_Node_Str"");
    rel1.setProperty(""String_Node_Str"",1);
    rel1.setProperty(""String_Node_Str"",2);
    rel1.setProperty(""String_Node_Str"",5);
    rel1.setProperty(""String_Node_Str"",5);
    rel1.setProperty(""String_Node_Str"",200);
    rel1.setProperty(""String_Node_Str"",true);
    rel1.setProperty(""String_Node_Str"",""String_Node_Str"");
    rel1.setProperty(""String_Node_Str"",""String_Node_Str"");
    tx.success();
  }
   List<Flow> flows=target.getAllFlows();
  Flow flow=flows.get(0);
  Assert.assertEquals(3,flow.getCookie());
  Assert.assertEquals(""String_Node_Str"",flow.getFlowId());
  Assert.assertEquals(true,flow.isIgnoreBandwidth());
}","@Test public void getAllFlows(){
  try (Transaction tx=graphDb.beginTx()){
    Node node1, node2;
    node1=graphDb.createNode(Label.label(""String_Node_Str""));
    node1.setProperty(""String_Node_Str"",""String_Node_Str"");
    node2=graphDb.createNode(Label.label(""String_Node_Str""));
    node2.setProperty(""String_Node_Str"",""String_Node_Str"");
    Relationship rel1=node1.createRelationshipTo(node2,RelationshipType.withName(""String_Node_Str""));
    rel1.setProperty(""String_Node_Str"",""String_Node_Str"");
    rel1.setProperty(""String_Node_Str"",3);
    rel1.setProperty(""String_Node_Str"",2);
    rel1.setProperty(""String_Node_Str"",1);
    rel1.setProperty(""String_Node_Str"",""String_Node_Str"");
    rel1.setProperty(""String_Node_Str"",""String_Node_Str"");
    rel1.setProperty(""String_Node_Str"",1);
    rel1.setProperty(""String_Node_Str"",2);
    rel1.setProperty(""String_Node_Str"",5);
    rel1.setProperty(""String_Node_Str"",5);
    rel1.setProperty(""String_Node_Str"",""String_Node_Str"");
    rel1.setProperty(""String_Node_Str"",200);
    rel1.setProperty(""String_Node_Str"",true);
    rel1.setProperty(""String_Node_Str"",""String_Node_Str"");
    rel1.setProperty(""String_Node_Str"",""String_Node_Str"");
    tx.success();
  }
   List<Flow> flows=target.getAllFlows();
  Flow flow=flows.get(0);
  Assert.assertEquals(3,flow.getCookie());
  Assert.assertEquals(""String_Node_Str"",flow.getFlowId());
  Assert.assertEquals(true,flow.isIgnoreBandwidth());
}"
37968,"private void handleFlowEvent(FlowInfoData flowData,Tuple tuple) throws IOException {
switch (flowData.getOperation()) {
case PUSH:
    logger.debug(""String_Node_Str"",flowData);
  flowCache.putFlow(flowData.getPayload());
logger.info(""String_Node_Str"",flowData);
break;
case UNPUSH:
logger.debug(""String_Node_Str"",flowData);
String flowsId=flowData.getPayload().getLeft().getFlowId();
flowCache.removeFlow(flowsId);
reroutedFlows.remove(flowsId);
logger.info(""String_Node_Str"",flowData);
break;
case CREATE:
flowCache.putFlow(flowData.getPayload());
emitFlowMessage(flowData,tuple,flowData.getCorrelationId());
logger.info(""String_Node_Str"",flowData);
break;
case DELETE:
String flowsId=flowData.getPayload().getLeft().getFlowId();
flowCache.removeFlow(flowsId);
reroutedFlows.remove(flowsId);
emitFlowMessage(flowData,tuple,flowData.getCorrelationId());
logger.info(""String_Node_Str"",flowData);
break;
case UPDATE:
processFlowUpdate(flowData.getPayload().getLeft());
flowCache.putFlow(flowData.getPayload());
emitFlowMessage(flowData,tuple,flowData.getCorrelationId());
logger.info(""String_Node_Str"",flowData);
break;
case STATE:
flowCache.putFlow(flowData.getPayload());
logger.info(""String_Node_Str"",flowData);
break;
case CACHE:
break;
default :
logger.warn(""String_Node_Str"",flowData);
break;
}
}","private void handleFlowEvent(FlowInfoData flowData,Tuple tuple) throws IOException {
switch (flowData.getOperation()) {
case PUSH:
    logger.debug(""String_Node_Str"",flowData);
  flowCache.putFlow(flowData.getPayload());
logger.info(""String_Node_Str"",flowData);
break;
case UNPUSH:
logger.debug(""String_Node_Str"",flowData);
String flowsId2=flowData.getPayload().getLeft().getFlowId();
flowCache.removeFlow(flowsId2);
reroutedFlows.remove(flowsId2);
logger.info(""String_Node_Str"",flowData);
break;
case CREATE:
flowCache.putFlow(flowData.getPayload());
emitFlowMessage(flowData,tuple,flowData.getCorrelationId());
logger.info(""String_Node_Str"",flowData);
break;
case DELETE:
String flowsId=flowData.getPayload().getLeft().getFlowId();
flowCache.removeFlow(flowsId);
reroutedFlows.remove(flowsId);
emitFlowMessage(flowData,tuple,flowData.getCorrelationId());
logger.info(""String_Node_Str"",flowData);
break;
case UPDATE:
processFlowUpdate(flowData.getPayload().getLeft());
flowCache.putFlow(flowData.getPayload());
emitFlowMessage(flowData,tuple,flowData.getCorrelationId());
logger.info(""String_Node_Str"",flowData);
break;
case STATE:
flowCache.putFlow(flowData.getPayload());
logger.info(""String_Node_Str"",flowData);
break;
case CACHE:
break;
default :
logger.warn(""String_Node_Str"",flowData);
break;
}
}"
37969,"/** 
 * Installs egress flow on the switch.
 * @param message command message for flow installation
 */
private void doInstallEgressFlow(final CommandMessage message,String replyToTopic,Destination replyDestination) throws FlowCommandException {
  InstallEgressFlow command=(InstallEgressFlow)message.getData();
  logger.debug(""String_Node_Str"",command);
  try {
    context.getSwitchManager().installEgressFlow(DatapathId.of(command.getSwitchId()),command.getId(),command.getCookie(),command.getInputPort(),command.getOutputPort(),command.getTransitVlanId(),command.getOutputVlanId(),command.getOutputVlanType());
    message.setDestination(replyDestination);
    context.getKafkaProducer().postMessage(replyToTopic,message);
  }
 catch (  SwitchOperationException e) {
    throw new FlowCommandException(command.getId(),ErrorType.CREATION_FAILURE,e);
  }
}","/** 
 * Installs egress flow on the switch.
 * @param message command message for flow installation
 */
private void doInstallEgressFlow(final CommandMessage message,String replyToTopic,Destination replyDestination) throws FlowCommandException {
  InstallEgressFlow command=(InstallEgressFlow)message.getData();
  logger.debug(""String_Node_Str"",command);
  try {
    context.getSwitchManager().installEgressFlow(DatapathId.of(command.getSwitchId()),command.getId(),command.getCookie(),command.getInputPort(),command.getOutputPort(),command.getTransitVlanId(),command.getOutputVlanId(),command.getOutputVlanType());
    if (!StringUtils.isBlank(replyToTopic)) {
      message.setDestination(replyDestination);
      context.getKafkaProducer().postMessage(replyToTopic,message);
    }
  }
 catch (  SwitchOperationException e) {
    throw new FlowCommandException(command.getId(),ErrorType.CREATION_FAILURE,e);
  }
}"
37970,"private void doSyncRulesRequest(final CommandMessage message){
  InstallMissedFlowsRequest request=(InstallMissedFlowsRequest)message.getData();
  final String switchId=request.getSwitchId();
  logger.debug(""String_Node_Str"",switchId);
}","private void doSyncRulesRequest(final CommandMessage message) throws FlowCommandException {
  InstallMissedFlowsRequest request=(InstallMissedFlowsRequest)message.getData();
  final String switchId=request.getSwitchId();
  logger.debug(""String_Node_Str"",switchId);
  for (  BaseFlow installCommand : request.getFlowCommands()) {
    logger.debug(""String_Node_Str"",switchId,installCommand);
    handleCommand(message,installCommand,StringUtils.EMPTY,Destination.TOPOLOGY_ENGINE);
  }
}"
37971,"/** 
 * Installs flow through one switch.
 * @param message command message for flow installation
 */
private void doInstallOneSwitchFlow(final CommandMessage message,String replyToTopic,Destination replyDestination) throws FlowCommandException {
  InstallOneSwitchFlow command=(InstallOneSwitchFlow)message.getData();
  logger.debug(""String_Node_Str"",command);
  Long meterId=command.getMeterId();
  if (meterId == null) {
    logger.error(""String_Node_Str"",command.getCookie());
    meterId=(long)meterPool.allocate(command.getSwitchId(),command.getId());
    logger.error(""String_Node_Str"",meterId,command.getCookie());
  }
  try {
    context.getSwitchManager().installMeter(DatapathId.of(command.getSwitchId()),command.getBandwidth(),1024,meterId);
    OutputVlanType directOutputVlanType=command.getOutputVlanType();
    context.getSwitchManager().installOneSwitchFlow(DatapathId.of(command.getSwitchId()),command.getId(),command.getCookie(),command.getInputPort(),command.getOutputPort(),command.getInputVlanId(),command.getOutputVlanId(),directOutputVlanType,meterId);
    message.setDestination(replyDestination);
    context.getKafkaProducer().postMessage(replyToTopic,message);
  }
 catch (  SwitchOperationException e) {
    throw new FlowCommandException(command.getId(),ErrorType.CREATION_FAILURE,e);
  }
}","/** 
 * Installs flow through one switch.
 * @param message command message for flow installation
 */
private void doInstallOneSwitchFlow(final CommandMessage message,String replyToTopic,Destination replyDestination) throws FlowCommandException {
  InstallOneSwitchFlow command=(InstallOneSwitchFlow)message.getData();
  logger.debug(""String_Node_Str"",command);
  Long meterId=command.getMeterId();
  if (meterId == null) {
    logger.error(""String_Node_Str"",command.getCookie());
    meterId=(long)meterPool.allocate(command.getSwitchId(),command.getId());
    logger.error(""String_Node_Str"",meterId,command.getCookie());
  }
  try {
    context.getSwitchManager().installMeter(DatapathId.of(command.getSwitchId()),command.getBandwidth(),1024,meterId);
    OutputVlanType directOutputVlanType=command.getOutputVlanType();
    context.getSwitchManager().installOneSwitchFlow(DatapathId.of(command.getSwitchId()),command.getId(),command.getCookie(),command.getInputPort(),command.getOutputPort(),command.getInputVlanId(),command.getOutputVlanId(),directOutputVlanType,meterId);
    if (!StringUtils.isBlank(replyToTopic)) {
      message.setDestination(replyDestination);
      context.getKafkaProducer().postMessage(replyToTopic,message);
    }
  }
 catch (  SwitchOperationException e) {
    throw new FlowCommandException(command.getId(),ErrorType.CREATION_FAILURE,e);
  }
}"
37972,"protected void doControllerMsg(CommandMessage message){
  final String replyToTopic;
  if (message instanceof CommandWithReplyToMessage) {
    replyToTopic=((CommandWithReplyToMessage)message).getReplyTo();
  }
 else {
    replyToTopic=OUTPUT_FLOW_TOPIC;
  }
  final Destination replyDestination=getDestinationForTopic(replyToTopic);
  try {
    CommandData data=message.getData();
    if (data instanceof DiscoverIslCommandData) {
      doDiscoverIslCommand(data);
    }
 else     if (data instanceof DiscoverPathCommandData) {
      doDiscoverPathCommand(data);
    }
 else     if (data instanceof InstallIngressFlow) {
      doInstallIngressFlow(message,replyToTopic,replyDestination);
    }
 else     if (data instanceof InstallEgressFlow) {
      doInstallEgressFlow(message,replyToTopic,replyDestination);
    }
 else     if (data instanceof InstallTransitFlow) {
      doInstallTransitFlow(message,replyToTopic,replyDestination);
    }
 else     if (data instanceof InstallOneSwitchFlow) {
      doInstallOneSwitchFlow(message,replyToTopic,replyDestination);
    }
 else     if (data instanceof RemoveFlow) {
      doDeleteFlow(message,replyToTopic,replyDestination);
    }
 else     if (data instanceof NetworkCommandData) {
      doNetworkDump(message);
    }
 else     if (data instanceof SwitchRulesDeleteRequest) {
      doDeleteSwitchRules(message,replyToTopic,replyDestination);
    }
 else     if (data instanceof SwitchRulesInstallRequest) {
      doInstallSwitchRules(message,replyToTopic,replyDestination);
    }
 else     if (data instanceof ConnectModeRequest) {
      doConnectMode(message,replyToTopic,replyDestination);
    }
 else     if (data instanceof DumpRulesRequest) {
      doDumpRulesRequest(message);
    }
 else     if (data instanceof InstallMissedFlowsRequest) {
      doSyncRulesRequest(message);
    }
 else {
      logger.error(""String_Node_Str"",data.toString());
    }
  }
 catch (  FlowCommandException e) {
    ErrorMessage error=new ErrorMessage(e.makeErrorResponse(),System.currentTimeMillis(),message.getCorrelationId(),replyDestination);
    context.getKafkaProducer().postMessage(replyToTopic,error);
  }
catch (  Exception e) {
    logger.error(""String_Node_Str"",e);
  }
}","protected void doControllerMsg(CommandMessage message){
  final String replyToTopic;
  if (message instanceof CommandWithReplyToMessage) {
    replyToTopic=((CommandWithReplyToMessage)message).getReplyTo();
  }
 else {
    replyToTopic=OUTPUT_FLOW_TOPIC;
  }
  final Destination replyDestination=getDestinationForTopic(replyToTopic);
  try {
    CommandData data=message.getData();
    handleCommand(message,data,replyToTopic,replyDestination);
  }
 catch (  FlowCommandException e) {
    ErrorMessage error=new ErrorMessage(e.makeErrorResponse(),System.currentTimeMillis(),message.getCorrelationId(),replyDestination);
    context.getKafkaProducer().postMessage(replyToTopic,error);
  }
catch (  Exception e) {
    logger.error(""String_Node_Str"",e);
  }
}"
37973,"/** 
 * Installs ingress flow on the switch.
 * @param message command message for flow installation
 */
private void doInstallIngressFlow(final CommandMessage message,String replyToTopic,Destination replyDestination) throws FlowCommandException {
  InstallIngressFlow command=(InstallIngressFlow)message.getData();
  logger.debug(""String_Node_Str"",command);
  Long meterId=command.getMeterId();
  if (meterId == null) {
    logger.error(""String_Node_Str"",command.getCookie());
    meterId=(long)meterPool.allocate(command.getSwitchId(),command.getId());
    logger.error(""String_Node_Str"",meterId,command.getCookie());
  }
  try {
    context.getSwitchManager().installMeter(DatapathId.of(command.getSwitchId()),command.getBandwidth(),1024,meterId);
    context.getSwitchManager().installIngressFlow(DatapathId.of(command.getSwitchId()),command.getId(),command.getCookie(),command.getInputPort(),command.getOutputPort(),command.getInputVlanId(),command.getTransitVlanId(),command.getOutputVlanType(),meterId);
    message.setDestination(replyDestination);
    context.getKafkaProducer().postMessage(replyToTopic,message);
  }
 catch (  SwitchOperationException e) {
    throw new FlowCommandException(command.getId(),ErrorType.CREATION_FAILURE,e);
  }
}","/** 
 * Installs ingress flow on the switch.
 * @param message command message for flow installation
 */
private void doInstallIngressFlow(final CommandMessage message,String replyToTopic,Destination replyDestination) throws FlowCommandException {
  InstallIngressFlow command=(InstallIngressFlow)message.getData();
  logger.debug(""String_Node_Str"",command);
  Long meterId=command.getMeterId();
  if (meterId == null) {
    logger.error(""String_Node_Str"",command.getCookie());
    meterId=(long)meterPool.allocate(command.getSwitchId(),command.getId());
    logger.error(""String_Node_Str"",meterId,command.getCookie());
  }
  try {
    context.getSwitchManager().installMeter(DatapathId.of(command.getSwitchId()),command.getBandwidth(),1024,meterId);
    context.getSwitchManager().installIngressFlow(DatapathId.of(command.getSwitchId()),command.getId(),command.getCookie(),command.getInputPort(),command.getOutputPort(),command.getInputVlanId(),command.getTransitVlanId(),command.getOutputVlanType(),meterId);
    if (!StringUtils.isBlank(replyToTopic)) {
      message.setDestination(replyDestination);
      context.getKafkaProducer().postMessage(replyToTopic,message);
    }
  }
 catch (  SwitchOperationException e) {
    throw new FlowCommandException(command.getId(),ErrorType.CREATION_FAILURE,e);
  }
}"
37974,"private void doDumpRulesRequest(final CommandMessage message){
  DumpRulesRequest request=(DumpRulesRequest)message.getData();
  final String switchId=request.getSwitchId();
  logger.debug(""String_Node_Str"",switchId);
  OFFlowStatsReply reply=context.getSwitchManager().dumpFlowTable(DatapathId.of(switchId));
  List<FlowEntry> flows=reply.getEntries().stream().map(OFFlowStatsConverter::toFlowEntry).collect(Collectors.toList());
  SwitchFlowEntries response=SwitchFlowEntries.builder().switchId(switchId).flowEntries(flows).build();
  InfoMessage infoMessage=new InfoMessage(response,message.getTimestamp(),message.getCorrelationId());
  context.getKafkaProducer().postMessage(OUTPUT_FLOW_TOPIC,infoMessage);
}","private void doDumpRulesRequest(final CommandMessage message){
  DumpRulesRequest request=(DumpRulesRequest)message.getData();
  final String switchId=request.getSwitchId();
  logger.debug(""String_Node_Str"",switchId);
  OFFlowStatsReply reply=context.getSwitchManager().dumpFlowTable(DatapathId.of(switchId));
  List<FlowEntry> flows=reply.getEntries().stream().map(OFFlowStatsConverter::toFlowEntry).collect(Collectors.toList());
  SwitchFlowEntries response=SwitchFlowEntries.builder().switchId(switchId).flowEntries(flows).build();
  InfoMessage infoMessage=new InfoMessage(response,message.getTimestamp(),message.getCorrelationId());
  context.getKafkaProducer().postMessage(TOPO_ENG_TOPIC,infoMessage);
}"
37975,"/** 
 * Installs transit flow on the switch.
 * @param message command message for flow installation
 */
private void doInstallTransitFlow(final CommandMessage message,String replyToTopic,Destination replyDestination) throws FlowCommandException {
  InstallTransitFlow command=(InstallTransitFlow)message.getData();
  logger.debug(""String_Node_Str"",command);
  try {
    context.getSwitchManager().installTransitFlow(DatapathId.of(command.getSwitchId()),command.getId(),command.getCookie(),command.getInputPort(),command.getOutputPort(),command.getTransitVlanId());
    message.setDestination(replyDestination);
    context.getKafkaProducer().postMessage(replyToTopic,message);
  }
 catch (  SwitchOperationException e) {
    throw new FlowCommandException(command.getId(),ErrorType.CREATION_FAILURE,e);
  }
}","/** 
 * Installs transit flow on the switch.
 * @param message command message for flow installation
 */
private void doInstallTransitFlow(final CommandMessage message,String replyToTopic,Destination replyDestination) throws FlowCommandException {
  InstallTransitFlow command=(InstallTransitFlow)message.getData();
  logger.debug(""String_Node_Str"",command);
  try {
    context.getSwitchManager().installTransitFlow(DatapathId.of(command.getSwitchId()),command.getId(),command.getCookie(),command.getInputPort(),command.getOutputPort(),command.getTransitVlanId());
    if (!StringUtils.isBlank(replyToTopic)) {
      message.setDestination(replyDestination);
      context.getKafkaProducer().postMessage(replyToTopic,message);
    }
  }
 catch (  SwitchOperationException e) {
    throw new FlowCommandException(command.getId(),ErrorType.CREATION_FAILURE,e);
  }
}"
37976,"@After public void verifyMocks(){
  verify(topologyEngineService).getActiveSwitches();
  verify(topologyEngineService).getActiveLinks();
  verify(topologyDefinition,times(3)).getActiveSwitches();
  verify(topologyDefinition).getIslsForActiveSwitches();
}","@After public void verifyMocks(){
  verify(topologyEngineService).getActiveSwitches();
  verify(topologyEngineService).getActiveLinks();
  verify(topologyDefinition,times(2)).getActiveSwitches();
  verify(topologyDefinition).getIslsForActiveSwitches();
}"
37977,"private void handleCacheSyncRequest(CommandMessage message,Tuple tuple) throws IOException {
  logger.info(""String_Node_Str"",message);
  List<String> droppedFlows=new ArrayList<>();
  List<String> addedFlows=new ArrayList<>();
  List<String> modifiedFlows=new ArrayList<>();
  List<String> unchangedFlows=new ArrayList<>();
  List<FlowInfo> flowInfos=pathComputer.getFlowInfo();
  HashMap<String,FlowInfo> flowToInfo=new HashMap<>();
  for (  FlowInfo fi : flowInfos) {
    flowToInfo.put(fi.getFlowId(),fi);
  }
  for (  FlowInfo fi : flowInfos) {
    String flowid=fi.getFlowId();
    if (flowCache.cacheContainsFlow(flowid)) {
      ImmutablePair<Flow,Flow> fc=flowCache.getFlow(flowid);
      if (fi.getCookie() != fc.left.getCookie() || fi.getMeterId() != fc.left.getMeterId() || fi.getTransitVlanId() != fc.left.getTransitVlan() || fi.getSrcSwitchId() != fc.left.getSourceSwitch()) {
        modifiedFlows.add(MAPPER.writeValueAsString(fc));
      }
 else {
        unchangedFlows.add(flowid);
      }
    }
 else {
      addedFlows.add(flowid);
    }
  }
  for (  ImmutablePair<Flow,Flow> flow : flowCache.dumpFlows()) {
    String flowid=flow.left.getFlowId();
    if (!flowToInfo.containsKey(flowid)) {
      String removedFlow=flowCache.removeFlow(flowid).toString();
      String asJson=MAPPER.writeValueAsString(removedFlow);
      droppedFlows.add(asJson);
    }
  }
  FlowCacheSyncResults results=new FlowCacheSyncResults(droppedFlows.toArray(new String[0]),addedFlows.toArray(new String[0]),modifiedFlows.toArray(new String[0]),unchangedFlows.toArray(new String[0]));
  Values northbound=new Values(new InfoMessage(new FlowCacheSyncResponse(results),message.getTimestamp(),message.getCorrelationId(),Destination.NORTHBOUND));
  outputCollector.emit(StreamType.RESPONSE.toString(),tuple,northbound);
}","private void handleCacheSyncRequest(CommandMessage message,Tuple tuple) throws IOException {
  logger.info(""String_Node_Str"",message);
  List<String> droppedFlows=new ArrayList<>();
  List<String> addedFlows=new ArrayList<>();
  List<String> modifiedFlows=new ArrayList<>();
  List<String> unchangedFlows=new ArrayList<>();
  List<FlowInfo> flowInfos=pathComputer.getFlowInfo();
  HashMap<String,FlowInfo> flowToInfo=new HashMap<>();
  for (  FlowInfo fi : flowInfos) {
    flowToInfo.put(fi.getFlowId() + fi.getCookie(),fi);
  }
  for (  FlowInfo fi : flowInfos) {
    String flowid=fi.getFlowId();
    if (flowCache.cacheContainsFlow(flowid)) {
      ImmutablePair<Flow,Flow> fc=flowCache.getFlow(flowid);
      int count=modifiedFlows.size();
      if (fi.getCookie() != fc.left.getCookie() && fi.getCookie() != fc.right.getCookie())       modifiedFlows.add(""String_Node_Str"" + flowid + ""String_Node_Str""+ fi.getCookie()+ ""String_Node_Str""+ fc.left.getCookie()+ ""String_Node_Str""+ fc.right.getCookie());
      if (fi.getMeterId() != fc.left.getMeterId() && fi.getMeterId() != fc.right.getMeterId())       modifiedFlows.add(""String_Node_Str"" + flowid + ""String_Node_Str""+ fi.getMeterId()+ ""String_Node_Str""+ fc.left.getMeterId()+ ""String_Node_Str""+ fc.right.getMeterId());
      if (fi.getTransitVlanId() != fc.left.getTransitVlan() && fi.getTransitVlanId() != fc.right.getTransitVlan())       modifiedFlows.add(""String_Node_Str"" + flowid + ""String_Node_Str""+ fi.getTransitVlanId()+ ""String_Node_Str""+ fc.left.getTransitVlan()+ ""String_Node_Str""+ fc.right.getTransitVlan());
      if (!fi.getSrcSwitchId().equals(fc.left.getSourceSwitch()) && !fi.getSrcSwitchId().equals(fc.right.getSourceSwitch()))       modifiedFlows.add(""String_Node_Str"" + flowid + ""String_Node_Str""+ fi.getSrcSwitchId()+ ""String_Node_Str""+ fc.left.getSourceSwitch()+ ""String_Node_Str""+ fc.right.getSourceSwitch());
      if (count == modifiedFlows.size())       unchangedFlows.add(flowid);
    }
 else {
      addedFlows.add(flowid);
    }
  }
  for (  ImmutablePair<Flow,Flow> flow : flowCache.dumpFlows()) {
    String key=flow.left.getFlowId() + flow.left.getCookie();
    if (!flowToInfo.containsKey(key)) {
      droppedFlows.add(flow.left.getFlowId());
    }
 else {
      key=flow.right.getFlowId() + flow.right.getCookie();
      if (!flowToInfo.containsKey(key)) {
        droppedFlows.add(flow.right.getFlowId());
      }
    }
  }
  FlowCacheSyncResults results=new FlowCacheSyncResults(droppedFlows.toArray(new String[0]),addedFlows.toArray(new String[0]),modifiedFlows.toArray(new String[0]),unchangedFlows.toArray(new String[0]));
  Values northbound=new Values(new InfoMessage(new FlowCacheSyncResponse(results),message.getTimestamp(),message.getCorrelationId(),Destination.NORTHBOUND));
  outputCollector.emit(StreamType.RESPONSE.toString(),tuple,northbound);
}"
37978,"@Override public StormTopology createTopology() throws NameCollisionException {
}","@Override public StormTopology createTopology() throws NameCollisionException {
  final String clazzName=this.getClass().getSimpleName();
  logger.debug(""String_Node_Str"",clazzName);
  TopologyBuilder builder=new TopologyBuilder();
  String topoDiscoTopic=config.getKafkaTopoDiscoTopic();
  checkAndCreateTopic(topoDiscoTopic);
  logger.debug(""String_Node_Str"",topoDiscoTopic);
  builder.setSpout(TOPO_DISCO_SPOUT,createKafkaSpout(topoDiscoTopic,clazzName + topoDiscoTopic));
  TopoDiscoParseBolt topoDiscoParseBolt=new TopoDiscoParseBolt();
  builder.setBolt(TOPO_DISCO_PARSE_BOLT_NAME,topoDiscoParseBolt,config.getParallelism()).shuffleGrouping(TopoDiscoParseBolt.TOPO_TO_PORT_INFO_STREAM,PARSE_PORT_INFO_BOLT_NAME);
  ParsePortInfoBolt parsePortInfoBolt=new ParsePortInfoBolt();
  builder.setBolt(PARSE_PORT_INFO_BOLT_NAME,parsePortInfoBolt,config.getParallelism()).shuffleGrouping(TopoDiscoParseBolt.TOPO_TO_PORT_INFO_STREAM,TOPO_DISCO_PARSE_BOLT_NAME).shuffleGrouping(WfmStatsParseBolt.WFM_TO_PARSE_PORT_INFO_STREAM,WFM_STATS_PARSE_BOLT_NAME);
  final String openTsdbTopic=config.getKafkaOtsdbTopic();
  checkAndCreateTopic(openTsdbTopic);
  KafkaBolt openTsdbBolt=createKafkaBolt(openTsdbTopic);
  builder.setBolt(OtsdbKafkaBoltName,openTsdbBolt,config.getParallelism()).shuffleGrouping(PARSE_PORT_INFO_BOLT_NAME);
  String wfmStatsTopic=config.getKafkaStatsTopic();
  checkAndCreateTopic(wfmStatsTopic);
  logger.debug(""String_Node_Str"",wfmStatsTopic);
  builder.setSpout(WFM_STATS_SPOUT,createKafkaSpout(wfmStatsTopic,clazzName + wfmStatsTopic));
  WfmStatsParseBolt wfmStatsParseBolt=new WfmStatsParseBolt();
  builder.setBolt(WFM_STATS_PARSE_BOLT_NAME,wfmStatsParseBolt,config.getParallelism()).shuffleGrouping(WFM_STATS_SPOUT);
  SwitchPortsSpout switchPortsSpout=new SwitchPortsSpout(JANITOR_REFRESH);
  builder.setSpout(SWITCH_PORTS_SPOUT_NAME,switchPortsSpout);
  final String speakerTopic=config.getKafkaSpeakerTopic();
  checkAndCreateTopic(speakerTopic);
  KafkaBolt speakerBolt=createKafkaBolt(speakerTopic);
  builder.setBolt(SpeakerBoltName,speakerBolt,config.getParallelism()).shuffleGrouping(SWITCH_PORTS_SPOUT_NAME);
  return builder.createTopology();
}"
37979,"@Override public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer){
  outputFieldsDeclarer.declareStream(PARSE_PORT_INFO_STREAM,new Fields(FIELD_NAME));
}","@Override public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer){
  outputFieldsDeclarer.declareStream(TOPO_TO_PORT_INFO_STREAM,new Fields(FIELD_NAME));
}"
37980,"private void doParseMessage(Tuple tuple){
  try {
    InfoData infoData=getInfoData(tuple);
    if (infoData instanceof PortInfoData) {
      collector.emit(PARSE_PORT_INFO_STREAM,new Values((PortInfoData)infoData));
    }
  }
 catch (  IOException e) {
    logger.error(""String_Node_Str"",tuple.toString(),e);
  }
catch (  MessageException e) {
  }
 finally {
    collector.ack(tuple);
  }
}","private void doParseMessage(Tuple tuple){
  try {
    InfoData infoData=getInfoData(tuple);
    if (infoData instanceof PortInfoData) {
      collector.emit(TOPO_TO_PORT_INFO_STREAM,new Values((PortInfoData)infoData));
    }
  }
 catch (  IOException e) {
    logger.error(""String_Node_Str"",tuple.toString(),e);
  }
catch (  MessageException e) {
  }
 finally {
    collector.ack(tuple);
  }
}"
37981,"/** 
 * Chk string is not empty.
 * @param value the value
 * @return true, if successful
 */
public static boolean chkStringIsNotEmpty(Object value){
  boolean flag=false;
  if (value != null) {
    String string=String.valueOf(value);
    if (string != null && !""String_Node_Str"".equalsIgnoreCase(string.trim()) && string.length() > 0 && !""String_Node_Str"".equalsIgnoreCase(string)) {
      flag=true;
    }
  }
  return flag;
}","/** 
 * Chk string is not empty.
 * @param value the value
 * @return true, if successful
 */
public static boolean chkStringIsNotEmpty(String value){
  if (value != null) {
    Predicate<String> predicates=s -> {
      return value.trim().length() > 0;
    }
;
    return predicates.test(value);
  }
  return false;
}"
37982,"@Override public void execute(Tuple input){
  StatsComponentType componentId=StatsComponentType.valueOf(input.getSourceComponent());
  InfoMessage message=(InfoMessage)input.getValueByField(MESSAGE_FIELD);
  if (!Destination.WFM_STATS.equals(message.getDestination())) {
    collector.ack(input);
    return;
  }
  LOGGER.debug(""String_Node_Str"",CORRELATION_ID,message.getCorrelationId(),componentId,StatsStreamType.valueOf(input.getSourceStreamId()));
  PortStatsData data=(PortStatsData)message.getData();
  long timestamp=message.getTimestamp();
  try {
    String switchId=data.getSwitchId().replaceAll(""String_Node_Str"",""String_Node_Str"");
    for (    PortStatsReply reply : data.getStats()) {
      for (      PortStatsEntry entry : reply.getEntries()) {
        emit(entry,timestamp,switchId);
      }
    }
  }
  finally {
    collector.ack(input);
  }
}","@Override public void execute(Tuple input){
  StatsComponentType componentId=StatsComponentType.valueOf(input.getSourceComponent());
  InfoMessage message=(InfoMessage)input.getValueByField(MESSAGE_FIELD);
  if (!Destination.WFM_STATS.equals(message.getDestination())) {
    collector.ack(input);
    return;
  }
  LOGGER.debug(""String_Node_Str"",CORRELATION_ID,message.getCorrelationId(),componentId,StatsStreamType.valueOf(input.getSourceStreamId()));
  PortStatsData data=(PortStatsData)message.getData();
  long timestamp=message.getTimestamp();
  try {
    String switchId=switchNameCache.get(data.getSwitchId());
    if (switchId == null) {
      switchId=""String_Node_Str"" + data.getSwitchId().replaceAll(""String_Node_Str"",""String_Node_Str"").toUpperCase();
      switchNameCache.put(data.getSwitchId(),switchId);
    }
    for (    PortStatsReply reply : data.getStats()) {
      for (      PortStatsEntry entry : reply.getEntries()) {
        emit(entry,timestamp,switchId);
      }
    }
  }
  finally {
    collector.ack(input);
  }
}"
37983,"public void handleFailed(String switchId,String portId){
  Node node=new Node(switchId,portId);
  List<DiscoveryNode> subjectList=filterQueue(node);
  if (subjectList.size() == 0) {
    logger.warn(""String_Node_Str"",node);
  }
 else {
    DiscoveryNode subject=subjectList.get(0);
    subject.countFailure();
    logger.info(""String_Node_Str"",subject);
  }
}","/** 
 * ISL Failure Event
 * @return true if this is new .. ie this isn't a consecutive failure.
 */
public boolean handleFailed(String switchId,String portId){
  boolean stateChanged=false;
  Node node=new Node(switchId,portId);
  List<DiscoveryNode> subjectList=filterQueue(node);
  if (subjectList.size() == 0) {
    logger.warn(""String_Node_Str"",node);
  }
 else {
    DiscoveryNode subject=subjectList.get(0);
    if (subject.isFoundIsl() && subject.getConsecutiveFailure() == 0) {
      stateChanged=true;
      logger.info(""String_Node_Str"",subject);
    }
    subject.renew();
    subject.incConsecutiveFailure();
    subject.clearConsecutiveSuccess();
  }
  return stateChanged;
}"
37984,"public Plan makeDiscoveryPlan(){
  Plan result=new Plan();
  for (  DiscoveryNode subject : pollQueue) {
    Node node=new Node(subject.getSwitchId(),subject.getPortId());
    if (subject.forlorn()) {
      continue;
    }
 else     if (subject.isStale(consecutiveLostTillFail) && subject.timeToCheck()) {
      result.discoveryFailure.add(node);
      subject.resetTickCounter();
      continue;
    }
 else     if (subject.isStale(consecutiveLostTillFail) && !subject.timeToCheck()) {
      subject.logTick();
      continue;
    }
    if (filter.isMatch(subject)) {
      logger.debug(""String_Node_Str"",subject);
      subject.renew();
      subject.resetTickCounter();
      continue;
    }
    subject.incAge();
    subject.resetTickCounter();
    result.needDiscovery.add(node);
  }
  return result;
}","/** 
 * The discovery plan takes into consideration multiple metrics to determine what should be discovered. At present, we want to send Discovery health checks on every ISL every x period. And, if the Discovery fails (either isn't an ISL or ISL is down) then we may want to give up checking. General algorithm: 1) if the node is an ISL (isFoundIsl) .. and is UP .. keep checking 2) if the node is not an ISL (ie !isFoundIsl), then check less frequently 3) if the node is an ISL .. and is DOWN .. keep checking
 */
public Plan makeDiscoveryPlan(){
  Plan result=new Plan();
  for (  DiscoveryNode subject : pollQueue) {
    if (filter.isMatch(subject)) {
      logger.debug(""String_Node_Str"",subject);
      subject.renew();
      subject.resetTickCounter();
      continue;
    }
    if (subject.forlorn()) {
      continue;
    }
    Node node=new Node(subject.getSwitchId(),subject.getPortId());
    if (subject.maxAttempts(consecutiveLostTillFail)) {
      if (subject.isFoundIsl() && subject.getConsecutiveFailure() == 0) {
        result.discoveryFailure.add(node);
        logger.info(""String_Node_Str"",subject);
      }
      subject.incConsecutiveFailure();
    }
    if (subject.timeToCheck()) {
      subject.incAttempts();
      subject.resetTickCounter();
      result.needDiscovery.add(node);
    }
 else {
      subject.logTick();
    }
  }
  return result;
}"
37985,"public void handleDiscovered(String switchId,String portId){
  Node node=new Node(switchId,portId);
  List<DiscoveryNode> subjectList=filterQueue(node);
  if (subjectList.size() == 0) {
    logger.warn(""String_Node_Str"",node);
  }
 else {
    DiscoveryNode subject=subjectList.get(0);
    subject.renew();
    logger.info(""String_Node_Str"",subject);
  }
}","/** 
 * ISL Discovery Event
 * @return true if this is a new event (ie first time discovered or prior failure)
 */
public boolean handleDiscovered(String switchId,String portId){
  boolean stateChanged=false;
  Node node=new Node(switchId,portId);
  List<DiscoveryNode> subjectList=filterQueue(node);
  if (subjectList.size() == 0) {
    logger.warn(""String_Node_Str"",node);
  }
 else {
    DiscoveryNode subject=subjectList.get(0);
    if (!subject.isFoundIsl()) {
      subject.setFoundIsl(true);
      stateChanged=true;
      logger.info(""String_Node_Str"",subject);
    }
    if (subject.getConsecutiveFailure() > 0) {
      stateChanged=true;
      logger.info(""String_Node_Str"",subject);
    }
    subject.renew();
    subject.incConsecutiveSuccess();
    subject.clearConsecutiveFailure();
  }
  return stateChanged;
}"
37986,"public boolean forlorn(){
  if (forlornThreshold == NEVER) {
    return false;
  }
  return consecutiveFailures >= forlornThreshold;
}","public boolean forlorn(){
  if (forlornThreshold == NEVER) {
    return false;
  }
  return consecutiveFailure >= forlornThreshold;
}"
37987,"@Override public String toString(){
  return ""String_Node_Str"" + ""String_Node_Str"" + switchId + '\''+ ""String_Node_Str""+ portId+ '\''+ ""String_Node_Str""+ age+ '}';
}","@Override public String toString(){
  return ""String_Node_Str"" + ""String_Node_Str"" + switchId + '\''+ ""String_Node_Str""+ portId+ '\''+ ""String_Node_Str""+ attempts+ ""String_Node_Str""+ consecutiveFailure+ ""String_Node_Str""+ consecutiveSuccess+ '}';
}"
37988,"public void renew(){
  age=0;
  timeCounter=0;
}","/** 
 * Whereas renew is called when a successful Discovery is received, it isn't the place to put ""foundIsl"". This is out of fear that renew() could be called from somewhere else. The semantics of ""renew"" doesn't say ""found ISL""
 */
public void renew(){
  attempts=0;
  timeCounter=0;
}"
37989,"private void handleIslEvent(Tuple tuple,IslInfoData discoveredIsl){
  PathNode node=discoveredIsl.getPath().get(0);
  String switchID=node.getSwitchId();
  String portID=""String_Node_Str"" + node.getPortNo();
  IslChangeType state=discoveredIsl.getState();
  logger.info(""String_Node_Str"",switchID,portID,state);
  if (IslChangeType.DISCOVERED.equals(state)) {
    discovery.handleDiscovered(switchID,portID);
  }
 else   if (IslChangeType.FAILED.equals(state)) {
    discovery.handleFailed(switchID,portID);
  }
 else {
    logger.warn(""String_Node_Str"",state);
  }
  String json=tuple.getString(0);
  collector.emit(topoEngTopic,tuple,new Values(PAYLOAD,json));
}","private void handleIslEvent(Tuple tuple,IslInfoData discoveredIsl){
  PathNode node=discoveredIsl.getPath().get(0);
  String switchID=node.getSwitchId();
  String portID=""String_Node_Str"" + node.getPortNo();
  IslChangeType state=discoveredIsl.getState();
  boolean stateChanged=false;
  if (IslChangeType.DISCOVERED.equals(state)) {
    stateChanged=discovery.handleDiscovered(switchID,portID);
  }
 else   if (IslChangeType.FAILED.equals(state)) {
    stateChanged=discovery.handleFailed(switchID,portID);
  }
 else {
    logger.warn(""String_Node_Str"",state);
  }
  if (stateChanged) {
    logger.info(""String_Node_Str"",switchID,portID,state);
    String json=tuple.getString(0);
    collector.emit(topoEngTopic,tuple,new Values(PAYLOAD,json));
  }
}"
37990,"@Override public void run(){
  while (true) {
    KafkaConsumer<String,String> consumer=null;
    try {
      consumer=new KafkaConsumer<>(kafkaProps);
      consumer.subscribe(topics);
      while (true) {
        ConsumerRecords<String,String> records=consumer.poll(100);
        logger.debug(""String_Node_Str"",records.count());
        for (        ConsumerRecord<String,String> record : records) {
          logger.trace(""String_Node_Str"",record.offset(),record.value());
          parseRecordExecutor.execute(new ParseRecord(record));
        }
      }
    }
 catch (    Exception e) {
      logger.error(""String_Node_Str"",e);
      if (consumer != null) {
        consumer.close();
      }
    }
  }
}","@Override public void run(){
  while (true) {
    KafkaConsumer<String,String> consumer=null;
    try {
      consumer=new KafkaConsumer<>(kafkaProps);
      consumer.subscribe(topics);
      while (true) {
        ConsumerRecords<String,String> records=consumer.poll(100);
        if (records.count() > 0)         logger.debug(""String_Node_Str"",records.count());
        for (        ConsumerRecord<String,String> record : records) {
          logger.trace(""String_Node_Str"",record.offset(),record.value());
          parseRecordExecutor.execute(new ParseRecord(record));
        }
      }
    }
 catch (    Exception e) {
      logger.error(""String_Node_Str"",e);
      if (consumer != null) {
        consumer.close();
      }
    }
  }
}"
37991,"@Override public boolean sendDiscoveryMessage(DatapathId srcSwId,OFPort port,DatapathId dstSwId){
  IOFSwitch srcSwitch=switchService.getSwitch(srcSwId);
  if (srcSwitch == null) {
    return false;
  }
  if (dstSwId == null) {
    return srcSwitch.write(generateVerificationPacket(srcSwitch,port));
  }
  IOFSwitch dstSwitch=switchService.getSwitch(dstSwId);
  OFPacketOut ofPacketOut=generateVerificationPacket(srcSwitch,port,dstSwitch);
  logger.debug(""String_Node_Str"",srcSwitch.getId().toString(),port.getPortNumber(),Hex.encodeHexString(ofPacketOut.getData()));
  return srcSwitch.write(ofPacketOut);
}","@Override public boolean sendDiscoveryMessage(DatapathId srcSwId,OFPort port,DatapathId dstSwId){
  IOFSwitch srcSwitch=switchService.getSwitch(srcSwId);
  if (srcSwitch == null || srcSwitch.getPort(port) == null) {
    return false;
  }
  if (dstSwId == null) {
    return srcSwitch.write(generateVerificationPacket(srcSwitch,port));
  }
  IOFSwitch dstSwitch=switchService.getSwitch(dstSwId);
  OFPacketOut ofPacketOut=generateVerificationPacket(srcSwitch,port,dstSwitch);
  logger.debug(""String_Node_Str"",srcSwitch.getId().toString(),port.getPortNumber(),Hex.encodeHexString(ofPacketOut.getData()));
  return srcSwitch.write(ofPacketOut);
}"
37992,"public OFPacketOut generateVerificationPacket(IOFSwitch srcSw,OFPort port,IOFSwitch dstSw,boolean sign){
  try {
    OFPortDesc ofPortDesc=srcSw.getPort(port);
    byte[] chassisId=new byte[]{4,0,0,0,0,0,0};
    byte[] portId=new byte[]{2,0,0};
    byte[] ttlValue=new byte[]{0,0x78};
    byte[] dpidTLVValue=new byte[]{0x0,0x26,(byte)0xe1,0,0,0,0,0,0,0,0,0};
    LLDPTLV dpidTLV=new LLDPTLV().setType((byte)127).setLength((short)dpidTLVValue.length).setValue(dpidTLVValue);
    byte[] dpidArray=new byte[8];
    ByteBuffer dpidBB=ByteBuffer.wrap(dpidArray);
    ByteBuffer portBB=ByteBuffer.wrap(portId,1,2);
    DatapathId dpid=srcSw.getId();
    dpidBB.putLong(dpid.getLong());
    System.arraycopy(dpidArray,2,chassisId,1,6);
    System.arraycopy(dpidArray,0,dpidTLVValue,4,8);
    byte[] srcMac=ofPortDesc.getHwAddr().getBytes();
    byte[] zeroMac={0,0,0,0,0,0};
    if (Arrays.equals(srcMac,zeroMac)) {
      logger.warn(""String_Node_Str"",dpid.toString(),ofPortDesc.getPortNo().getPortNumber());
      System.arraycopy(dpidArray,2,srcMac,0,6);
    }
    portBB.putShort(port.getShortPortNumber());
    VerificationPacket vp=new VerificationPacket();
    vp.setChassisId(new LLDPTLV().setType((byte)1).setLength((short)chassisId.length).setValue(chassisId));
    vp.setPortId(new LLDPTLV().setType((byte)2).setLength((short)portId.length).setValue(portId));
    vp.setTtl(new LLDPTLV().setType((byte)3).setLength((short)ttlValue.length).setValue(ttlValue));
    vp.getOptionalTLVList().add(dpidTLV);
    long time=System.currentTimeMillis();
    long swLatency=srcSw.getLatency().getValue();
    byte[] timestampTLVValue=ByteBuffer.allocate(Long.SIZE / 8 + 4).put((byte)0x00).put((byte)0x26).put((byte)0xe1).put((byte)0x01).putLong(time + swLatency).array();
    LLDPTLV timestampTLV=new LLDPTLV().setType((byte)127).setLength((short)timestampTLVValue.length).setValue(timestampTLVValue);
    vp.getOptionalTLVList().add(timestampTLV);
    byte[] typeTLVValue=ByteBuffer.allocate(Integer.SIZE / 8 + 4).put((byte)0x00).put((byte)0x26).put((byte)0xe1).put((byte)0x02).putInt(PathType.ISL.ordinal()).array();
    LLDPTLV typeTLV=new LLDPTLV().setType((byte)127).setLength((short)typeTLVValue.length).setValue(typeTLVValue);
    vp.getOptionalTLVList().add(typeTLV);
    if (sign) {
      String token=JWT.create().withClaim(""String_Node_Str"",dpid.getLong()).withClaim(""String_Node_Str"",time + swLatency).sign(algorithm);
      byte[] tokenBytes=token.getBytes(Charset.forName(""String_Node_Str""));
      byte[] tokenTLVValue=ByteBuffer.allocate(4 + tokenBytes.length).put((byte)0x00).put((byte)0x26).put((byte)0xe1).put((byte)0x03).put(tokenBytes).array();
      LLDPTLV tokenTLV=new LLDPTLV().setType((byte)127).setLength((short)tokenTLVValue.length).setValue(tokenTLVValue);
      vp.getOptionalTLVList().add(tokenTLV);
    }
    MacAddress dstMac=MacAddress.of(VERIFICATION_BCAST_PACKET_DST);
    if (dstSw != null) {
      OFPortDesc sw2OfPortDesc=dstSw.getPort(port);
      dstMac=sw2OfPortDesc.getHwAddr();
    }
    Ethernet l2=new Ethernet().setSourceMACAddress(MacAddress.of(srcMac)).setDestinationMACAddress(dstMac).setEtherType(EthType.IPv4);
    IPv4Address dstIp=IPv4Address.of(VERIFICATION_PACKET_IP_DST);
    if (dstSw != null) {
      dstIp=IPv4Address.of(((InetSocketAddress)dstSw.getInetAddress()).getAddress().getAddress());
    }
    IPv4 l3=new IPv4().setSourceAddress(IPv4Address.of(((InetSocketAddress)srcSw.getInetAddress()).getAddress().getAddress())).setDestinationAddress(dstIp).setTtl((byte)64).setProtocol(IpProtocol.UDP);
    UDP l4=new UDP();
    l4.setSourcePort(TransportPort.of(VERIFICATION_PACKET_UDP_PORT));
    l4.setDestinationPort(TransportPort.of(VERIFICATION_PACKET_UDP_PORT));
    l2.setPayload(l3);
    l3.setPayload(l4);
    l4.setPayload(vp);
    byte[] data=l2.serialize();
    OFPacketOut.Builder pob=srcSw.getOFFactory().buildPacketOut().setBufferId(OFBufferId.NO_BUFFER).setActions(getDiscoveryActions(srcSw,port)).setData(data);
    OFMessageUtils.setInPort(pob,OFPort.CONTROLLER);
    return pob.build();
  }
 catch (  Exception exception) {
    logger.error(""String_Node_Str"",exception);
  }
  return null;
}","public OFPacketOut generateVerificationPacket(IOFSwitch srcSw,OFPort port,IOFSwitch dstSw,boolean sign){
  try {
    OFPortDesc ofPortDesc=srcSw.getPort(port);
    byte[] chassisId=new byte[]{4,0,0,0,0,0,0};
    byte[] portId=new byte[]{2,0,0};
    byte[] ttlValue=new byte[]{0,0x78};
    byte[] dpidTLVValue=new byte[]{0x0,0x26,(byte)0xe1,0,0,0,0,0,0,0,0,0};
    LLDPTLV dpidTLV=new LLDPTLV().setType((byte)127).setLength((short)dpidTLVValue.length).setValue(dpidTLVValue);
    byte[] dpidArray=new byte[8];
    ByteBuffer dpidBB=ByteBuffer.wrap(dpidArray);
    ByteBuffer portBB=ByteBuffer.wrap(portId,1,2);
    DatapathId dpid=srcSw.getId();
    dpidBB.putLong(dpid.getLong());
    System.arraycopy(dpidArray,2,chassisId,1,6);
    System.arraycopy(dpidArray,0,dpidTLVValue,4,8);
    byte[] zeroMac={0,0,0,0,0,0};
    byte[] srcMac=ofPortDesc.getHwAddr().getBytes();
    if (Arrays.equals(srcMac,zeroMac)) {
      int portVal=ofPortDesc.getPortNo().getPortNumber();
      logger.warn(""String_Node_Str"",dpid.toString(),portVal);
      System.arraycopy(dpidArray,2,srcMac,0,6);
    }
    portBB.putShort(port.getShortPortNumber());
    VerificationPacket vp=new VerificationPacket();
    vp.setChassisId(new LLDPTLV().setType((byte)1).setLength((short)chassisId.length).setValue(chassisId));
    vp.setPortId(new LLDPTLV().setType((byte)2).setLength((short)portId.length).setValue(portId));
    vp.setTtl(new LLDPTLV().setType((byte)3).setLength((short)ttlValue.length).setValue(ttlValue));
    vp.getOptionalTLVList().add(dpidTLV);
    long time=System.currentTimeMillis();
    long swLatency=srcSw.getLatency().getValue();
    byte[] timestampTLVValue=ByteBuffer.allocate(Long.SIZE / 8 + 4).put((byte)0x00).put((byte)0x26).put((byte)0xe1).put((byte)0x01).putLong(time + swLatency).array();
    LLDPTLV timestampTLV=new LLDPTLV().setType((byte)127).setLength((short)timestampTLVValue.length).setValue(timestampTLVValue);
    vp.getOptionalTLVList().add(timestampTLV);
    byte[] typeTLVValue=ByteBuffer.allocate(Integer.SIZE / 8 + 4).put((byte)0x00).put((byte)0x26).put((byte)0xe1).put((byte)0x02).putInt(PathType.ISL.ordinal()).array();
    LLDPTLV typeTLV=new LLDPTLV().setType((byte)127).setLength((short)typeTLVValue.length).setValue(typeTLVValue);
    vp.getOptionalTLVList().add(typeTLV);
    if (sign) {
      String token=JWT.create().withClaim(""String_Node_Str"",dpid.getLong()).withClaim(""String_Node_Str"",time + swLatency).sign(algorithm);
      byte[] tokenBytes=token.getBytes(Charset.forName(""String_Node_Str""));
      byte[] tokenTLVValue=ByteBuffer.allocate(4 + tokenBytes.length).put((byte)0x00).put((byte)0x26).put((byte)0xe1).put((byte)0x03).put(tokenBytes).array();
      LLDPTLV tokenTLV=new LLDPTLV().setType((byte)127).setLength((short)tokenTLVValue.length).setValue(tokenTLVValue);
      vp.getOptionalTLVList().add(tokenTLV);
    }
    MacAddress dstMac=MacAddress.of(VERIFICATION_BCAST_PACKET_DST);
    if (dstSw != null) {
      OFPortDesc sw2OfPortDesc=dstSw.getPort(port);
      dstMac=sw2OfPortDesc.getHwAddr();
    }
    Ethernet l2=new Ethernet().setSourceMACAddress(MacAddress.of(srcMac)).setDestinationMACAddress(dstMac).setEtherType(EthType.IPv4);
    IPv4Address dstIp=IPv4Address.of(VERIFICATION_PACKET_IP_DST);
    if (dstSw != null) {
      dstIp=IPv4Address.of(((InetSocketAddress)dstSw.getInetAddress()).getAddress().getAddress());
    }
    IPv4 l3=new IPv4().setSourceAddress(IPv4Address.of(((InetSocketAddress)srcSw.getInetAddress()).getAddress().getAddress())).setDestinationAddress(dstIp).setTtl((byte)64).setProtocol(IpProtocol.UDP);
    UDP l4=new UDP();
    l4.setSourcePort(TransportPort.of(VERIFICATION_PACKET_UDP_PORT));
    l4.setDestinationPort(TransportPort.of(VERIFICATION_PACKET_UDP_PORT));
    l2.setPayload(l3);
    l3.setPayload(l4);
    l4.setPayload(vp);
    byte[] data=l2.serialize();
    OFPacketOut.Builder pob=srcSw.getOFFactory().buildPacketOut().setBufferId(OFBufferId.NO_BUFFER).setActions(getDiscoveryActions(srcSw,port)).setData(data);
    OFMessageUtils.setInPort(pob,OFPort.CONTROLLER);
    return pob.build();
  }
 catch (  Exception exception) {
    logger.error(""String_Node_Str"",exception);
  }
  return null;
}"
37993,"@Override public int hashCode(){
  int result=metric != null ? metric.hashCode() : 0;
  result=31 * result + (tags != null ? tags.hashCode() : 0);
  result=31 * result + (value != null ? value.hashCode() : 0);
  return result;
}","@Override public int hashCode(){
  int result=metric != null ? metric.hashCode() : 0;
  result=31 * result + (tags != null ? tags.hashCode() : 0);
  return result;
}"
37994,"public TopologyConfig(PropertiesReader config) throws ConfigurationException {
  isLocal=config.getBoolean(""String_Node_Str"");
  localExecutionTime=(int)(config.getFloat(""String_Node_Str"") * 1000);
  parallelism=config.getInteger(""String_Node_Str"");
  workers=config.getInteger(""String_Node_Str"");
  discoveryInterval=config.getInteger(""String_Node_Str"");
  discoveryTimeout=config.getInteger(""String_Node_Str"");
  filterDirectory=config.getString(""String_Node_Str"");
  loggerLevel=Level.valueOf(config.getString(""String_Node_Str""));
  loggerWatermark=config.getString(""String_Node_Str"");
  zookeeperHosts=config.getString(""String_Node_Str"");
  zookeeperSessionTimeout=(int)(config.getFloat(""String_Node_Str"") * 1000);
  zookeeperConnectTimeout=(int)(config.getFloat(""String_Node_Str"") * 1000);
  kafkaHosts=config.getString(""String_Node_Str"");
  kafkaCtrlTopic=config.getString(""String_Node_Str"");
  kafkaFlowTopic=config.getString(""String_Node_Str"");
  kafkaHealthCheckTopic=config.getString(""String_Node_Str"");
  kafkaNorthboundTopic=config.getString(""String_Node_Str"");
  kafkaOtsdbTopic=config.getString(""String_Node_Str"");
  kafkaSimulatorTopic=config.getString(""String_Node_Str"");
  kafkaSpeakerTopic=config.getString(""String_Node_Str"");
  kafkaStatsTopic=config.getString(""String_Node_Str"");
  kafkaTopoCacheTopic=config.getString(""String_Node_Str"");
  kafkaTopoDiscoTopic=config.getString(""String_Node_Str"");
  kafkaTopoEngTopic=config.getString(""String_Node_Str"");
  openTsDBHosts=config.getString(""String_Node_Str"");
  openTsdbTimeout=(int)(config.getFloat(""String_Node_Str"") * 1000);
  openTsdbNumSpouts=config.getInteger(""String_Node_Str"");
  openTsdbNumOpentasbFilterBolt=config.getInteger(""String_Node_Str"");
  openTsdbNumOpentsdbBolt=config.getInteger(""String_Node_Str"");
  neo4jHost=config.getString(""String_Node_Str"");
  neo4jLogin=config.getString(""String_Node_Str"");
  neo4jPassword=config.getString(""String_Node_Str"");
}","public TopologyConfig(PropertiesReader config) throws ConfigurationException {
  isLocal=config.getBoolean(""String_Node_Str"");
  localExecutionTime=(int)(config.getFloat(""String_Node_Str"") * 1000);
  parallelism=config.getInteger(""String_Node_Str"");
  workers=config.getInteger(""String_Node_Str"");
  discoveryInterval=config.getInteger(""String_Node_Str"");
  discoveryTimeout=config.getInteger(""String_Node_Str"");
  filterDirectory=config.getString(""String_Node_Str"");
  loggerLevel=Level.valueOf(config.getString(""String_Node_Str""));
  loggerWatermark=config.getString(""String_Node_Str"");
  zookeeperHosts=config.getString(""String_Node_Str"");
  zookeeperSessionTimeout=(int)(config.getFloat(""String_Node_Str"") * 1000);
  zookeeperConnectTimeout=(int)(config.getFloat(""String_Node_Str"") * 1000);
  kafkaHosts=config.getString(""String_Node_Str"");
  kafkaCtrlTopic=config.getString(""String_Node_Str"");
  kafkaFlowTopic=config.getString(""String_Node_Str"");
  kafkaHealthCheckTopic=config.getString(""String_Node_Str"");
  kafkaNorthboundTopic=config.getString(""String_Node_Str"");
  kafkaOtsdbTopic=config.getString(""String_Node_Str"");
  kafkaSimulatorTopic=config.getString(""String_Node_Str"");
  kafkaSpeakerTopic=config.getString(""String_Node_Str"");
  kafkaStatsTopic=config.getString(""String_Node_Str"");
  kafkaTopoCacheTopic=config.getString(""String_Node_Str"");
  kafkaTopoDiscoTopic=config.getString(""String_Node_Str"");
  kafkaTopoEngTopic=config.getString(""String_Node_Str"");
  openTsDBHosts=config.getString(""String_Node_Str"");
  openTsdbTimeout=(int)(config.getFloat(""String_Node_Str"") * 1000);
  openTsdbNumSpouts=config.getInteger(""String_Node_Str"");
  openTsdbFilterBoltExecutors=config.getInteger(""String_Node_Str"");
  openTsdbBoltExecutors=config.getInteger(""String_Node_Str"");
  openTsdbBoltWorkers=config.getInteger(""String_Node_Str"");
  openTsdbBatchSize=config.getInteger(""String_Node_Str"");
  openTsdbFlushInterval=config.getInteger(""String_Node_Str"");
  neo4jHost=config.getString(""String_Node_Str"");
  neo4jLogin=config.getString(""String_Node_Str"");
  neo4jPassword=config.getString(""String_Node_Str"");
}"
37995,"@Override public StormTopology createTopology(){
  LOGGER.info(""String_Node_Str"");
  TopologyBuilder tb=new TopologyBuilder();
  final String topic=config.getKafkaOtsdbTopic();
  final String spoutId=topic + ""String_Node_Str"";
  final String boltId=topic + ""String_Node_Str"";
  checkAndCreateTopic(topic);
  KafkaSpout kafkaSpout=createKafkaSpout(topic,spoutId);
  tb.setSpout(spoutId,kafkaSpout,config.getOpenTsdbNumSpouts());
  tb.setBolt(boltId,new OpenTSDBFilterBolt(),config.getOpenTsdbNumOpentasbFilterBolt()).shuffleGrouping(spoutId);
  OpenTsdbClient.Builder tsdbBuilder=OpenTsdbClient.newBuilder(config.getOpenTsDBHosts()).sync(config.getOpenTsdbTimeout()).returnDetails();
  OpenTsdbBolt openTsdbBolt=new OpenTsdbBolt(tsdbBuilder,TupleOpenTsdbDatapointMapper.DEFAULT_MAPPER).withBatchSize(10).withFlushInterval(2).failTupleForFailedMetrics();
  tb.setBolt(""String_Node_Str"",openTsdbBolt,config.getOpenTsdbNumOpentsdbBolt()).shuffleGrouping(boltId);
  return tb.createTopology();
}","@Override public StormTopology createTopology(){
  LOGGER.info(""String_Node_Str"");
  TopologyBuilder tb=new TopologyBuilder();
  final String topic=config.getKafkaOtsdbTopic();
  final String spoutId=topic + ""String_Node_Str"";
  final String boltId=topic + ""String_Node_Str"";
  checkAndCreateTopic(topic);
  KafkaSpout kafkaSpout=createKafkaSpout(topic,spoutId);
  tb.setSpout(spoutId,kafkaSpout,config.getOpenTsdbNumSpouts());
  tb.setBolt(boltId,new OpenTSDBFilterBolt(),config.getOpenTsdbFilterBoltExecutors()).fieldsGrouping(spoutId,new Fields(""String_Node_Str""));
  OpenTsdbClient.Builder tsdbBuilder=OpenTsdbClient.newBuilder(config.getOpenTsDBHosts()).sync(config.getOpenTsdbTimeout()).returnDetails();
  OpenTsdbBolt openTsdbBolt=new OpenTsdbBolt(tsdbBuilder,TupleOpenTsdbDatapointMapper.DEFAULT_MAPPER).withBatchSize(config.getOpenTsdbBatchSize()).withFlushInterval(config.getOpenTsdbFlushInterval()).failTupleForFailedMetrics();
  tb.setBolt(""String_Node_Str"",openTsdbBolt,config.getOpenTsdbBoltExecutors()).setNumTasks(config.getOpenTsdbBoltWorkers()).shuffleGrouping(boltId);
  return tb.createTopology();
}"
37996,"private boolean isUpdateRequired(Datapoint datapoint){
  return !storage.contains(datapoint) || isDatapointOutdated(datapoint);
}","private boolean isUpdateRequired(Datapoint datapoint){
  boolean update=true;
  if (storage.containsKey(datapoint.hashCode())) {
    Datapoint prevDatapoint=storage.get(datapoint.hashCode());
    update=!prevDatapoint.getValue().equals(datapoint.getValue()) || datapoint.getTime() - prevDatapoint.getTime() >= TEN_MINUTES;
  }
  return update;
}"
37997,"private void addDatapoint(Datapoint datapoint){
  if (!storage.add(datapoint)) {
    storage.remove(datapoint);
    storage.add(datapoint);
  }
}","private void addDatapoint(Datapoint datapoint){
  LOGGER.debug(""String_Node_Str"" + datapoint.hashCode());
  storage.put(datapoint.hashCode(),datapoint);
}"
37998,"/** 
 * Gets the response.
 * @param < T > the generic type
 * @param < E > the element type
 * @param response the response
 * @param responseClass the response class
 * @param dependentClass the dependent class
 * @return the response
 */
private <T,E>T getResponse(final HttpResponse response,final Class<T> responseClass,final Class<E> dependentClass){
  T obj=null;
  try {
    _log.info(""String_Node_Str"" + response.getStatusLine().getStatusCode());
    if (response.getStatusLine().getStatusCode() != HttpStatus.NO_CONTENT.value()) {
      String responseEntity=IoUtils.toString(response.getEntity().getContent());
      _log.info(""String_Node_Str"" + responseEntity);
      if (!(HttpStatus.valueOf(response.getStatusLine().getStatusCode()).is2xxSuccessful() && response.getEntity() != null)) {
        String errorMessage=null;
        try {
          if (responseEntity.startsWith(""String_Node_Str"")) {
            responseEntity=responseEntity.replaceFirst(""String_Node_Str"",""String_Node_Str"").trim();
          }
          if (responseEntity.endsWith(""String_Node_Str"")) {
            responseEntity=responseEntity.replace(""String_Node_Str"",""String_Node_Str"").trim();
          }
          errorMessage=mapper.readValue(responseEntity,ErrorMessage.class).getMessage();
        }
 catch (        Exception e) {
          if (response.getStatusLine().getStatusCode() == HttpStatus.UNAUTHORIZED.value()) {
            throw new UnauthorizedException(HttpError.UNAUTHORIZED.getMessage());
          }
          _log.error(""String_Node_Str"",e);
          errorMessage=authPropertyService.getError(IAuthConstants.Code.RESPONSE_PARSING_FAIL_ERROR).getMessage();
          throw new RestCallFailedException(errorMessage);
        }
        _log.error(""String_Node_Str"" + responseEntity);
        throw new ExternalSystemException(response.getStatusLine().getStatusCode(),errorMessage);
      }
 else {
        if (dependentClass == null) {
          obj=mapper.readValue(responseEntity,responseClass);
        }
 else {
          obj=mapper.readValue(responseEntity,TypeFactory.defaultInstance().constructCollectionLikeType(responseClass,dependentClass));
        }
      }
    }
  }
 catch (  IOException e) {
    throw new RestCallFailedException(e.getMessage());
  }
  return obj;
}","/** 
 * Gets the response.
 * @param < T > the generic type
 * @param < E > the element type
 * @param response the response
 * @param responseClass the response class
 * @param dependentClass the dependent class
 * @return the response
 */
private <T,E>T getResponse(final HttpResponse response,final Class<T> responseClass,final Class<E> dependentClass){
  T obj=null;
  try {
    LOGGER.info(""String_Node_Str"" + response.getStatusLine().getStatusCode());
    if (response.getStatusLine().getStatusCode() != HttpStatus.NO_CONTENT.value()) {
      String responseEntity=IoUtil.toString(response.getEntity().getContent());
      LOGGER.info(""String_Node_Str"" + responseEntity);
      if (!(HttpStatus.valueOf(response.getStatusLine().getStatusCode()).is2xxSuccessful() && response.getEntity() != null)) {
        String errorMessage=null;
        try {
          if (responseEntity.startsWith(""String_Node_Str"")) {
            responseEntity=responseEntity.replaceFirst(""String_Node_Str"",""String_Node_Str"").trim();
          }
          if (responseEntity.endsWith(""String_Node_Str"")) {
            responseEntity=responseEntity.replace(""String_Node_Str"",""String_Node_Str"").trim();
          }
          errorMessage=mapper.readValue(responseEntity,ErrorMessage.class).getMessage();
        }
 catch (        Exception e) {
          if (response.getStatusLine().getStatusCode() == HttpStatus.UNAUTHORIZED.value()) {
            throw new UnauthorizedException(HttpError.UNAUTHORIZED.getMessage());
          }
          LOGGER.error(""String_Node_Str"",e);
          errorMessage=authPropertyService.getError(IAuthConstants.Code.RESPONSE_PARSING_FAIL_ERROR).getMessage();
          throw new RestCallFailedException(errorMessage);
        }
        LOGGER.error(""String_Node_Str"" + responseEntity);
        throw new ExternalSystemException(response.getStatusLine().getStatusCode(),errorMessage);
      }
 else {
        if (dependentClass == null) {
          obj=mapper.readValue(responseEntity,responseClass);
        }
 else {
          obj=mapper.readValue(responseEntity,TypeFactory.defaultInstance().constructCollectionLikeType(responseClass,dependentClass));
        }
      }
    }
  }
 catch (  IOException e) {
    throw new RestCallFailedException(e.getMessage());
  }
  return obj;
}"
37999,"/** 
 * Checks if is valid response.
 * @param response the response
 * @return true, if is valid response
 */
public static boolean isValidResponse(final HttpResponse response){
  _log.debug(""String_Node_Str"" + response.getStatusLine().getStatusCode());
  return response.getStatusLine().getStatusCode() >= HttpStatus.OK.value() && response.getStatusLine().getStatusCode() < HttpStatus.MULTIPLE_CHOICES.value() && response.getEntity() != null;
}","/** 
 * Checks if is valid response.
 * @param response the response
 * @return true, if is valid response
 */
public static boolean isValidResponse(final HttpResponse response){
  LOGGER.debug(""String_Node_Str"" + response.getStatusLine().getStatusCode());
  return response.getStatusLine().getStatusCode() >= HttpStatus.OK.value() && response.getStatusLine().getStatusCode() < HttpStatus.MULTIPLE_CHOICES.value() && response.getEntity() != null;
}"
38000,"/** 
 * Invoke.
 * @param apiUrl the api url
 * @param httpMethod the http method
 * @param payload the payload
 * @param contentType the content type
 * @param basicAuth the basic auth
 * @return the http response
 */
public HttpResponse invoke(final String apiUrl,final HttpMethod httpMethod,final String payload,final String contentType,final String basicAuth){
  _log.info(""String_Node_Str"");
  HttpResponse httpResponse=null;
  try {
    HttpClient client=HttpClients.createDefault();
    HttpUriRequest httpUriRequest=null;
    HttpEntityEnclosingRequestBase httpEntityEnclosingRequest=null;
    if (HttpMethod.POST.equals(httpMethod)) {
      httpEntityEnclosingRequest=new HttpPost(apiUrl);
    }
 else     if (HttpMethod.PUT.equals(httpMethod)) {
      httpEntityEnclosingRequest=new HttpPut(apiUrl);
    }
 else     if (HttpMethod.DELETE.equals(httpMethod)) {
      httpUriRequest=new HttpDelete(apiUrl);
    }
 else {
      httpUriRequest=new HttpGet(apiUrl);
    }
    if (!HttpMethod.POST.equals(httpMethod) && !HttpMethod.PUT.equals(httpMethod)) {
      if (!StringUtil.isNullOrEmpty(basicAuth)) {
        _log.debug(""String_Node_Str"" + IAuthConstants.Header.AUTHORIZATION);
        httpUriRequest.setHeader(IAuthConstants.Header.AUTHORIZATION,basicAuth);
      }
    }
    if (HttpMethod.POST.equals(httpMethod) || HttpMethod.PUT.equals(httpMethod)) {
      _log.info(""String_Node_Str"" + httpEntityEnclosingRequest + ""String_Node_Str""+ payload);
      httpEntityEnclosingRequest.setHeader(HttpHeaders.CONTENT_TYPE,contentType);
      httpEntityEnclosingRequest.setHeader(IAuthConstants.Header.BASIC_AUTH,basicAuth);
      httpEntityEnclosingRequest.setEntity(new StringEntity(payload));
      httpResponse=client.execute(httpEntityEnclosingRequest);
      _log.debug(""String_Node_Str"");
    }
 else     if (HttpMethod.DELETE.equals(httpMethod) || HttpMethod.GET.equals(httpMethod)) {
      _log.info(""String_Node_Str"" + httpUriRequest);
      httpResponse=client.execute(httpUriRequest);
      _log.info(""String_Node_Str"");
    }
  }
 catch (  Exception e) {
    _log.error(""String_Node_Str"",e);
    throw new RestCallFailedException(e);
  }
  _log.info(""String_Node_Str"");
  return httpResponse;
}","/** 
 * Invoke.
 * @param apiUrl the api url
 * @param httpMethod the http method
 * @param payload the payload
 * @param contentType the content type
 * @param basicAuth the basic auth
 * @return the http response
 */
public HttpResponse invoke(final String apiUrl,final HttpMethod httpMethod,final String payload,final String contentType,final String basicAuth){
  LOGGER.info(""String_Node_Str"");
  HttpResponse httpResponse=null;
  try {
    HttpClient client=HttpClients.createDefault();
    HttpUriRequest httpUriRequest=null;
    HttpEntityEnclosingRequestBase httpEntityEnclosingRequest=null;
    if (HttpMethod.POST.equals(httpMethod)) {
      httpEntityEnclosingRequest=new HttpPost(apiUrl);
    }
 else     if (HttpMethod.PUT.equals(httpMethod)) {
      httpEntityEnclosingRequest=new HttpPut(apiUrl);
    }
 else     if (HttpMethod.DELETE.equals(httpMethod)) {
      httpUriRequest=new HttpDelete(apiUrl);
    }
 else {
      httpUriRequest=new HttpGet(apiUrl);
    }
    if (!HttpMethod.POST.equals(httpMethod) && !HttpMethod.PUT.equals(httpMethod)) {
      if (!StringUtil.isNullOrEmpty(basicAuth)) {
        LOGGER.debug(""String_Node_Str"" + IAuthConstants.Header.AUTHORIZATION);
        httpUriRequest.setHeader(IAuthConstants.Header.AUTHORIZATION,basicAuth);
      }
    }
    if (HttpMethod.POST.equals(httpMethod) || HttpMethod.PUT.equals(httpMethod)) {
      LOGGER.info(""String_Node_Str"" + httpEntityEnclosingRequest + ""String_Node_Str""+ payload);
      httpEntityEnclosingRequest.setHeader(HttpHeaders.CONTENT_TYPE,contentType);
      httpEntityEnclosingRequest.setHeader(IAuthConstants.Header.BASIC_AUTH,basicAuth);
      httpEntityEnclosingRequest.setEntity(new StringEntity(payload));
      httpResponse=client.execute(httpEntityEnclosingRequest);
      LOGGER.debug(""String_Node_Str"");
    }
 else     if (HttpMethod.DELETE.equals(httpMethod) || HttpMethod.GET.equals(httpMethod)) {
      LOGGER.info(""String_Node_Str"" + httpUriRequest);
      httpResponse=client.execute(httpUriRequest);
      LOGGER.info(""String_Node_Str"");
    }
  }
 catch (  Exception e) {
    LOGGER.error(""String_Node_Str"",e);
    throw new RestCallFailedException(e);
  }
  LOGGER.info(""String_Node_Str"");
  return httpResponse;
}"
