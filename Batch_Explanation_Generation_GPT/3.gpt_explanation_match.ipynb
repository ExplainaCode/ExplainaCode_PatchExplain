{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined custom_id and content values saved to ../Data/new_source_data/output/gpt_explaination_with_id.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Specify the folder containing JSONL files\n",
    "folder_path = '../Data/new_source_data/processing/gpt'\n",
    "output_csv_path = '../Data/new_source_data/output/gpt_explaination_with_id.csv'\n",
    "\n",
    "# Initialize a list to store the custom_id and content values from all files\n",
    "records = []\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.jsonl'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Read each JSONL file and extract custom_id and content values\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                record = json.loads(line)\n",
    "                if 'custom_id' in record and 'response' in record:\n",
    "                    custom_id_value = record['custom_id']\n",
    "                    content_value = record['response'].get('body', {}).get('choices', [{}])[0].get('message', {}).get('content', '')\n",
    "                    # Extract only the numerical part of the custom_id value\n",
    "                    if 'record_' in custom_id_value:\n",
    "                        records.append({\n",
    "                            'custom_id': custom_id_value.split('_')[-1],\n",
    "                            'content': content_value\n",
    "                        })\n",
    "\n",
    "# Create a DataFrame from the extracted values\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "df = df.rename(columns={'custom_id': 'record_number', 'content': 'gpt_explanation'})\n",
    "\n",
    "df = df.drop_duplicates(subset='record_number')\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Combined custom_id and content values saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path_bug_fix_dataset = '../Data/new_source_data/bug_fix_dataset.csv'\n",
    "gpt_match_dataset = '../Data/new_source_data/output/gpt_explaination_with_id.csv'\n",
    "\n",
    "bug_fix_df = pd.read_csv(input_path_bug_fix_dataset)\n",
    "gpt_id_match_df = pd.read_csv(gpt_match_dataset)\n",
    "bug_fix_gpt_df = bug_fix_df.merge(gpt_id_match_df, on='record_number', how='left')\n",
    "\n",
    "bug_fix_gpt_df.to_csv(\"../Data/new_source_data/bug_fix_gpt.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
