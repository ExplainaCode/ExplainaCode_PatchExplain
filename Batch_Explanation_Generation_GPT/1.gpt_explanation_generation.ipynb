{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DataFrame...\n",
      "\n",
      "Processing Batch 1...\n",
      "Batch Job Created: batch_6763a1d61e3881908b7e93a6457cd309\n",
      "Batch 1 Submitted. Batch ID: batch_6763a1d61e3881908b7e93a6457cd309\n",
      "Checking status for Batch ID: batch_6763a1d61e3881908b7e93a6457cd309\n",
      "Batch batch_6763a1d61e3881908b7e93a6457cd309 Status: validating\n",
      "Batch batch_6763a1d61e3881908b7e93a6457cd309 Status: failed\n",
      "Batch batch_6763a1d61e3881908b7e93a6457cd309 failed.\n",
      "\n",
      "Processing Batch 2...\n",
      "Batch Job Created: batch_6763a216e3e4819085ca85fadcb8b30d\n",
      "Batch 2 Submitted. Batch ID: batch_6763a216e3e4819085ca85fadcb8b30d\n",
      "Checking status for Batch ID: batch_6763a216e3e4819085ca85fadcb8b30d\n",
      "Batch batch_6763a216e3e4819085ca85fadcb8b30d Status: validating\n",
      "Batch batch_6763a216e3e4819085ca85fadcb8b30d Status: in_progress\n",
      "Batch batch_6763a216e3e4819085ca85fadcb8b30d Status: completed\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "download_and_process_batch() missing 1 required positional argument: 'output_file_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 224\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Status: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 224\u001b[0m     \u001b[43mdownload_and_process_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m status \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: download_and_process_batch() missing 1 required positional argument: 'output_file_id'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPEN_AI_API_KEY\")\n",
    "\n",
    "# OpenAI API Constants\n",
    "API_BASE_URL = \"https://api.openai.com/v1\"\n",
    "HEADERS = {\"Authorization\": f\"Bearer {OPENAI_API_KEY}\"}\n",
    "\n",
    "# Step 1: Load the DataFrame\n",
    "print(\"Loading DataFrame...\")\n",
    "df = pd.read_csv('../Data/new_source_data/bug_fix_dataset.csv')  # Adjust the path\n",
    "sample_size = 40\n",
    "df = df.sample(sample_size)\n",
    "\n",
    "# Text file to store batch IDs\n",
    "batch_id_file = \"batch_ids.txt\"\n",
    "open(batch_id_file, \"w\").close()  # Clear the file before starting\n",
    "\n",
    "# Function to create JSONL file\n",
    "def create_jsonl_file(data, batch_number):\n",
    "    jsonl_file_path = f\"../Data/new_source_data/processing/gpt/batch_requests_{batch_number}.jsonl\"\n",
    "    with open(jsonl_file_path, \"w\") as f:\n",
    "        for index, row in data.iterrows():\n",
    "            prompt = f\"\"\"You are a senior software engineer explaining a bug fix to a junior developer. \n",
    "            Your task is to provide a concise explanation of the changes made to fix the bug in the provided code snippets. Follow these guidelines:\n",
    "\n",
    "            ### Guidelines:\n",
    "            1. **Bug Identification**: Describe the error in the original code, including its type (e.g., logic error, runtime error) and its impact.\n",
    "            2. **Problem Analysis**: Explain why the bug is problematic and under what conditions it causes issues.\n",
    "            3. **Fix Explanation**: Describe the changes in the fixed code and how they address the issue.\n",
    "            4. **Justification**: Justify why the fix is necessary and how it resolves the problem.\n",
    "            5. **Improvement Highlight**: Summarize how the fix improves code reliability, functionality, or performance.\n",
    "\n",
    "            ### Constraints:\n",
    "            - The explanation must be **concise**, using no more than **100 words**.\n",
    "            - The explanation should consist of **exactly three sentences**:\n",
    "            1. Why the buggy code is incorrect.\n",
    "            2. What changes were made in the fixed code and why they are correct.\n",
    "            3. How the fixed code improves upon the buggy code.\n",
    "            - Do not include meta-descriptions such as \"This is a three-sentence explanation\" or mention word counts in the response.\n",
    "            - Ensure your explanation aligns with the code context and focuses solely on technical details relevant to the fix.\n",
    "\n",
    "            ### Example Explanations:\n",
    "\n",
    "            #### Example 1:\n",
    "            **Buggy Code:**\n",
    "            @Override protected void afterTests(){{\n",
    "                try {{\n",
    "                    context.shutdown();\n",
    "                }}\n",
    "                catch (Exception e) {{\n",
    "                    throw new RuntimeException(\"String_Node_Str\", e);\n",
    "                }}\n",
    "                super.afterTests();\n",
    "            }}\n",
    "\n",
    "            **Fixed Code:**\n",
    "            @Override protected void afterTests(){{\n",
    "                try {{\n",
    "                    context.shutdown();\n",
    "                }}\n",
    "                catch (Exception e) {{\n",
    "                    throw new RuntimeException(\"String_Node_Str\", e);\n",
    "                }}\n",
    "            }}\n",
    "\n",
    "            **Explanation:**\n",
    "            The bug in the original code is the unconditional call to super.afterTests(), which executes even if context.shutdown() fails, risking inconsistent state. \n",
    "            The fixed code removes this call, ensuring super.afterTests() is not invoked when an exception occurs, preventing potential errors. \n",
    "            This fix ensures predictable cleanup behavior, improving code reliability.\n",
    "\n",
    "            #### Example 2:\n",
    "            **Buggy Code:**\n",
    "            private void updateTreeView(Tree tree){{\n",
    "                Iterator it = tree.getDepthFirstIterator(false);\n",
    "                while (it.hasNext()) {{\n",
    "                    ((Tree<JsonTreeNode>) it.next()).setExpanded(true);\n",
    "                }}\n",
    "                editorTreeView.setModel(tree.copy());\n",
    "            }}\n",
    "\n",
    "            **Fixed Code:**\n",
    "            private void updateTreeView(JsonTree tree){{\n",
    "                JsonTree fixedTree = JsonTreeConverter.serialize(JsonTreeConverter.deserialize(tree));\n",
    "                Iterator it = fixedTree.getDepthFirstIterator(false);\n",
    "                while (it.hasNext()) {{\n",
    "                    ((JsonTree) it.next()).setExpanded(true);\n",
    "                }}\n",
    "                editorTreeView.setModel(fixedTree.copy());\n",
    "            }}\n",
    "\n",
    "            **Explanation:**\n",
    "            The original code has a bug where it improperly casts a generic Tree to Tree<JsonTreeNode>, which can cause runtime errors if the types donâ€™t match. \n",
    "            The fix uses a JsonTree with serialization and deserialization to ensure the tree structure is correct and safe to work with. \n",
    "            This makes the code more reliable and prevents runtime type errors.\n",
    "            **Buggy Code:** {row['buggy_code']}\n",
    "            **Fixed Code:** {row['fixed_code']}\n",
    "            **Why the fixed code is correct:**\"\"\"\n",
    "            json_obj = {\n",
    "                \"method\": \"POST\",\n",
    "                \"custom_id\": f\"batch_{batch_number}_record_{index}\",\n",
    "                \"url\": \"/v1/chat/completions\",\n",
    "                \"body\": {\n",
    "                    \"model\": \"gpt-4o\",\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"system\", \"content\": \"You are a helpful assistant that explains bug fixes clearly.\"},\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "            f.write(json.dumps(json_obj) + \"\\n\")\n",
    "    return jsonl_file_path\n",
    "\n",
    "# Function to upload file and create batch job\n",
    "def process_batch(jsonl_file_path):\n",
    "    # Step 1: Upload the JSONL file\n",
    "    with open(jsonl_file_path, \"rb\") as file:\n",
    "        upload_response = requests.post(\n",
    "            f\"{API_BASE_URL}/files\",\n",
    "            headers=HEADERS,\n",
    "            files={\"file\": file},\n",
    "            data={\"purpose\": \"batch\"}\n",
    "        )\n",
    "    if upload_response.status_code != 200:\n",
    "        print(f\"File upload failed: {upload_response.json()}\")\n",
    "        return None\n",
    "    file_id = upload_response.json()[\"id\"]\n",
    "\n",
    "    # Step 2: Create a Batch Job\n",
    "    batch_payload = {\n",
    "        \"input_file_id\": file_id,\n",
    "        \"endpoint\": \"/v1/chat/completions\",\n",
    "        \"completion_window\": \"24h\"\n",
    "    }\n",
    "    batch_response = requests.post(\n",
    "        f\"{API_BASE_URL}/batches\",\n",
    "        headers=HEADERS,\n",
    "        json=batch_payload\n",
    "    )\n",
    "    if batch_response.status_code != 200:\n",
    "        print(f\"Batch creation failed: {batch_response.json()}\")\n",
    "        return None\n",
    "    batch_id = batch_response.json()[\"id\"]\n",
    "    print(f\"Batch Job Created: {batch_id}\")\n",
    "    return batch_id\n",
    "\n",
    "# Function to download batch results\n",
    "def download_and_process_batch(batch_id, output_file_id):\n",
    "    print(f\"Downloading results for Batch ID: {batch_id}...\")\n",
    "\n",
    "    # Step 1: Download output file content\n",
    "    output_response = requests.get(\n",
    "        f\"{API_BASE_URL}/files/{output_file_id}/content\",\n",
    "        headers=HEADERS\n",
    "    )\n",
    "    if output_response.status_code != 200:\n",
    "        print(f\"Error downloading results for {batch_id}: {output_response.json()}\")\n",
    "        return\n",
    "\n",
    "    # Step 2: Save output to a JSONL file\n",
    "    output_jsonl_path = f\"../Data/new_source_data/processing/gpt/batch_output_{batch_id}.jsonl\"\n",
    "    with open(output_jsonl_path, \"wb\") as f:\n",
    "        f.write(output_response.content)\n",
    "    print(f\"Results saved to: {output_jsonl_path}\")\n",
    "\n",
    "    # Step 3: Parse JSONL and append results to the final CSV\n",
    "    explanations = []\n",
    "    with open(output_jsonl_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                response = json.loads(line)\n",
    "                print(response)  # Debugging: See actual JSON structure\n",
    "                custom_id = response.get(\"custom_id\", \"N/A\")\n",
    "                explanation = response.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"No explanation found\")\n",
    "                explanations.append({\"custom_id\": custom_id, \"explanation\": explanation})\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSON decode error: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error: {e}\")\n",
    "\n",
    "# Process batches sequentially\n",
    "batch_size = 20\n",
    "num_batches = (len(df) // batch_size) + 1\n",
    "\n",
    "for batch_num in range(num_batches):\n",
    "    start_idx = batch_num * batch_size\n",
    "    end_idx = start_idx + batch_size\n",
    "    chunk = df.iloc[start_idx:end_idx]\n",
    "    \n",
    "    if chunk.empty:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nProcessing Batch {batch_num + 1}...\")\n",
    "    jsonl_path = create_jsonl_file(chunk, batch_num + 1)\n",
    "    batch_id = process_batch(jsonl_path)\n",
    "\n",
    "    if batch_id:\n",
    "        # Write batch_id to the text file\n",
    "        with open(batch_id_file, \"a\") as f:\n",
    "            f.write(f\"{batch_id}\\n\")\n",
    "        print(f\"Batch {batch_num + 1} Submitted. Batch ID: {batch_id}\")\n",
    "\n",
    "        # Monitor the batch job\n",
    "        print(f\"Checking status for Batch ID: {batch_id}\")\n",
    "        while True:\n",
    "            status_response = requests.get(\n",
    "                f\"{API_BASE_URL}/batches/{batch_id}\",\n",
    "                headers=HEADERS\n",
    "            )\n",
    "            if status_response.status_code != 200:\n",
    "                print(f\"Error checking batch status: {status_response.json()}\")\n",
    "                break\n",
    "            \n",
    "            status = status_response.json().get(\"status\")\n",
    "            print(f\"Batch {batch_id} Status: {status}\")\n",
    "            if status == \"completed\":\n",
    "                download_and_process_batch(batch_id)\n",
    "                break\n",
    "            elif status == \"failed\":\n",
    "                print(f\"Batch {batch_id} failed.\")\n",
    "                break\n",
    "            time.sleep(60)  # Check every 60 seconds\n",
    "    else:\n",
    "        print(f\"Failed to submit Batch {batch_num + 1}. Skipping...\")\n",
    "\n",
    "print(\"\\nAll Batches Processed!\")\n",
    "print(f\"Batch IDs have been saved to {batch_id_file}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
